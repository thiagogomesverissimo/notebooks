@inproceedings{10.1145/3706468.3706491,
author = {Wang, Zuo and Lin, Weiyue and Hu, Xiao},
title = {Self-service Teacher-facing Learning Analytics Dashboard with Large Language Models},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706491},
doi = {10.1145/3706468.3706491},
abstract = {With the rise of online learning platforms, the need for effective learning analytics (LA) has become critical for teachers. However, the development of traditional LA dashboards often requires technical expertise and a certain level of data literacy, preventing many teachers from integrating LA dashboards effectively and flexibly into their teaching practice. This paper explores the development of a self-service teacher-facing learning analytics dashboard powered by large language models (LLMs), for improving teaching practices. By leveraging LLMs, the self-service system aims to simplify the implementation of data queries and visualizations, allowing teachers to create personalized LA dashboards using natural languages. This study also investigates the capabilities of LLMs in generating charts for LA dashboards and evaluates the effectiveness of the self-service system through usability tests with 15 teachers. Preliminary findings suggest that LLMs demonstrate high capabilities in generating charts for LA dashboards, and the LLM-powered self-service system can effectively address participating teachers’ pedagogical needs for LA. This research contributes to the ongoing research on the intersection of LLMs and education, emphasizing the potential of self-service systems to empower teachers in daily teaching practices.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {824–830},
numpages = {7},
keywords = {data visualization, large language models, learning analytics dashboard, self-service learning analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706468.3706525,
author = {Li, Zaibei and Yamaguchi, Shunpei and Spikol, Daniel},
title = {OpenMMLA: an IoT-based Multimodal Data Collection Toolkit for Learning Analytics},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706525},
doi = {10.1145/3706468.3706525},
abstract = {Multimodal Learning Analytics (MMLA) expands traditional learning analytics into the digital and physical learning environment, using diverse sensors and systems to collect information about education in more real-world environments. Challenges remain in making these technologies practical for capturing data in authentic learning situations. With the advent of readily accessible powerful artificial intelligence that includes multimodal large language models, new opportunities are available. However, few approaches allow access to these technologies, and most systems are developed for specific environments. Recent work has begun to make toolkits with access to collecting data from sensors, processing, and analyzing, yet these tools are challenging to integrate into a system. This paper introduces OpenMMLA, a toolkit approach that provides programming interfaces for harnessing these technologies into an MMLA platform with prebuilt pipelines, including the audio analyzer, indoor positioning, and video frame analyzer, offering multimodal data collection and visualizations and analytics. The paper provides an initial evaluation of the functionalities of the toolkit in data capturing and the implemented pipelines’ performances.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {872–879},
numpages = {8},
keywords = {Multimodal Learning Analytics, Group Work, Internet of Thing, Smart Badges},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706468.3706543,
author = {Ahrar, Arash and Doroodian, Mohammadreza and Hatala, Marek},
title = {Exploring Eye-tracking Features to Understand Students' Sensemaking of Learning Analytics Dashboards},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706543},
doi = {10.1145/3706468.3706543},
abstract = {Learning analytics dashboards (LADs) are widely used in learning analytics as visual tools to present information about learning activities and outcomes. However, only few studies have explored how students make sense from LAD elements and what cognitive processes follow after viewing each element. In this study, we explore how eye-tracking data can help researchers to identify salient LAD elements critical to students’ sensemaking process. Our findings reveal that the eye-tracking derived features, including fixation duration and eye movement patterns, are highly indicative of students’ social comparison tendencies and offer valuable insights into their sensemaking processes.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {931–937},
numpages = {7},
keywords = {learning analytics dashboards, eye tracking, sensemaking, motivation},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3636555.3636856,
author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Gasevic, Dragan},
title = {Generative Artificial Intelligence in Learning Analytics: Contextualising Opportunities and Challenges through the Learning Analytics Cycle},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636856},
doi = {10.1145/3636555.3636856},
abstract = {Generative artificial intelligence (GenAI), exemplified by ChatGPT, Midjourney, and other state-of-the-art large language models and diffusion models, holds significant potential for transforming education and enhancing human productivity. While the prevalence of GenAI in education has motivated numerous research initiatives, integrating these technologies within the learning analytics (LA) cycle and their implications for practical interventions remain underexplored. This paper delves into the prospective opportunities and challenges GenAI poses for advancing LA. We present a concise overview of the current GenAI landscape and contextualise its potential roles within Clow’s generic framework of the LA cycle. We posit that GenAI can play pivotal roles in analysing unstructured data, generating synthetic learner data, enriching multimodal learner interactions, advancing interactive and explanatory analytics, and facilitating personalisation and adaptive interventions. As the lines blur between learners and GenAI tools, a renewed understanding of learners is needed. Future research can delve deep into frameworks and methodologies that advocate for human-AI collaboration. The LA community can play a pivotal role in capturing data about human and AI contributions and exploring how they can collaborate most effectively. As LA advances, it is essential to consider the pedagogical implications and broader socioeconomic impact of GenAI for ensuring an inclusive future.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {101–111},
numpages = {11},
keywords = {ChatGPT, Midjourney, educational technology, generative artificial intelligence, human-AI collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706468.3706541,
author = {Claassen, Alrike and Mirriahi, Negin and Kovanovi\'{c}, Vitomir and Dawson, Shane},
title = {From Data to Design: Integrating Learning Analytics into Educational Design for Effective Decision-Making: From Data to Design},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706541},
doi = {10.1145/3706468.3706541},
abstract = {Learning Analytics (LA) aims to provide university instructors with meaningful data and insights that can be used to improve courses. However, instructors are often met with challenges that arise when wanting to use LA to inform their educational design decisions. For instance, there may be a misalignment between instructors’ needs and the data and insights LA systems provide. Further research is required to understand instructors’ expectations of LA and how it can support the diversity of educational designs. This case study addresses this gap by investigating the role of LA in instructors’ educational decision-making processes. The study employs self-determination theory's constructs to examine instructors’ existing practices when using LA to support their decision-making. The study reveals that LA enables instructors to make data-informed iterative educational design decisions, supporting their need for competence and relatedness. The emotional aspect of LA is an important consideration that can easily lead to demotivation and avoidance of LA. Support is needed to address instructors’ psychological needs so instructors can fully utilise LA to make effective educational design decisions. The findings inform a framework for considering how instructors’ data-informed educational decision-making can be understood. The implications of our findings and opportunities for the future are discussed.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {558–567},
numpages = {10},
keywords = {Learning analytics, data-informed decision-making, educational design, higher education, self-determination theory},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706598.3713395,
author = {Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela E and Jin, Yueqiao and Abel, Sophie and Fan, Jie Xiang and Yan, Lixiang and Dix, Samantha and Wotherspoon, Rosie and Li, Xinyu and Jaggard, Hollie A and Osborne, Abra and Buckingham Shum, Simon and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {TeamVision: An AI-powered Learning Analytics System for Supporting Reflection in Team-based Healthcare Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713395},
doi = {10.1145/3706598.3713395},
abstract = {Healthcare simulations help learners develop teamwork and clinical skills in a risk-free setting, promoting reflection on real-world practices through structured debriefs. However, despite video’s potential, it is hard to use, leaving a gap in providing concise, data-driven summaries for supporting effective debriefing. Addressing this, we present TeamVision, an AI-powered multimodal learning analytics (MMLA) system that captures voice presence, automated transcriptions, body rotation, and positioning data, offering educators a dashboard to guide debriefs immediately after simulations. We conducted an in-the-wild study with 56 teams (221 students) and recorded debriefs led by six teachers using TeamVision. Follow-up interviews with 15 students and five teachers explored perceptions of its usefulness, accuracy, and trustworthiness. This paper examines: i) how TeamVision was used in debriefing, ii) what educators found valuable/challenging, and iii) perceptions of its effectiveness. Results suggest TeamVision enables flexible debriefing and highlights the challenges and implications of using AI-powered systems in healthcare simulation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {22},
keywords = {teamwork, large-language models, AI, sensors, healthcare, learning analytics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3636555.3636844,
author = {Sloan-Lynch, Jay and Morse, Robert},
title = {Equity-Forward Learning Analytics: Designing a Dashboard to Support Marginalized Student Success},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636844},
doi = {10.1145/3636555.3636844},
abstract = {Student outcomes in US higher education exhibit deep and persistent inequities. The continued underperformance of historically marginalized students remains a serious concern across higher education, reflected in increasing efforts among institutions to infuse diversity, equity, and inclusion into their academic and social communities. Yet despite widespread recognition of these inequities, few studies in the learning analytics literature engage in practical ways with issues of educational equity or DEI considerations. In this paper, we share our work supporting a large college's strategic DEI goals through the creation of a Course Diversity Dashboard informed by research into how students’ study behaviors and performance interact with their gender and ethnic identities to impact course outcomes. The dashboard enables users to explore inequalities in course outcomes and take concrete actions to improve student study strategies, time management, and prior knowledge. Results from our research revealed the existence of previously hidden learner inequities in all courses included in our study as well as critical differences in underrepresented minority students’ prior knowledge. And while we did not find evidence of meaningful differences in the study behaviors of student subgroups, our findings further validate the effectiveness of evidence-informed study strategies in an authentic educational setting.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {1–11},
numpages = {11},
keywords = {DEI, educational equity, learning analytics dashboards, study strategies},
location = {Kyoto, Japan},
series = {LAK '24}
}

@proceedings{10.1145/3706468,
title = {LAK '25: Proceedings of the 15th International Learning Analytics and Knowledge Conference},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3636555.3636847,
author = {Alfredo, Riordan and Echeverria, Vanessa and Jin, Yueqiao and Swiecki, Zachari and Ga\v{s}evi\'{c}, Dragan and Martinez-Maldonado, Roberto},
title = {SLADE: A Method for Designing Human-Centred Learning Analytics Systems},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636847},
doi = {10.1145/3636555.3636847},
abstract = {There is a growing interest in creating Learning Analytics (LA) systems that incorporate student perspectives. Yet, many LA systems still lean towards a technology-centric approach, potentially overlooking human values and the necessity of human oversight in automation. Although some recent LA studies have adopted a human-centred design stance, there is still limited research on establishing safe, reliable, and trustworthy systems during the early stages of LA design. Drawing from a newly proposed framework for human-centred artificial intelligence, we introduce SLADE, a method for ideating and identifying features of human-centred LA systems that balance human control and computer automation. We illustrate SLADE’s application in designing LA systems to support collaborative learning in healthcare. Twenty-one third-year students participated in design sessions through SLADE’s four steps: i) identifying challenges and corresponding LA systems; ii) prioritising these LA systems; iii) ideating human control and automation features; and iv) refining features emphasising safety, reliability, and trustworthiness. Our results demonstrate SLADE’s potential to assist researchers and designers in: 1) aligning authentic student challenges with LA systems through both divergent ideation and convergent prioritisation; 2) understanding students’ perspectives on personal agency and delegation to teachers; and 3) fostering discussions about the safety, reliability, and trustworthiness of LA solutions.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {24–34},
numpages = {11},
keywords = {Design Thinking, Double Diamond, Human-centered AI, Human-centered learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706468.3706545,
author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie Xiang and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706545},
doi = {10.1145/3706468.3706545},
abstract = {Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners’ varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners’ ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners’ GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners’ GenAI literacy.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {579–590},
numpages = {12},
keywords = {learning analytics dashboard, generative AI literacy, generative AI chatbots, data visualisation},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3636555.3636886,
author = {Alcock, Sarah and Rienties, Bart and Aristeidou, Maria and Kouadri Most\'{e}faoui, Soraya},
title = {How do visualizations and automated personalized feedback engage professional learners in a Learning Analytics Dashboard?},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636886},
doi = {10.1145/3636555.3636886},
abstract = {Learning Analytics Dashboards (LAD) are the subject of research in a multitude of schools and higher education institutions, but a lack of research into learner-facing dashboards in professional learning has been identified. This study took place in an authentic professional learning context and aims to contribute insights into LAD design by using an academic approach in a practice-based environment. An existing storytelling LAD created to support 81 accountants was evaluated using Technology Acceptance Model, finding a learner expectation for clarity, conciseness, understanding and guidance on next steps. High usage levels and a ‘take what you need’ approach was identified, with all visualizations and automated personalized feedback being considered useful although to varying degrees. Professional learners in this study focus on understanding and acting upon weaknesses rather than celebrating strengths. The lessons for LAD design are to offer choice and create elements which support learners to take action to improve performance at a multitude of time points and levels of success.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {316–325},
numpages = {10},
keywords = {LAD, Learning Analytics Dashboard, Technology Acceptance Model, accountancy, assessment, data storytelling, feedback, personalization, professional learning},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706468.3706549,
author = {Mun, Soyeon and Jo, Il-Hyun},
title = {Evolving the 4C/ID model through learning analytics approaches: Teaching and learning system design framework for supporting learners' complex problem-solving},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706549},
doi = {10.1145/3706468.3706549},
abstract = {In recent years, there has been a surge in studies focusing on learning analytics (LA) aimed to collecting and analyzing learning trace data from various digital learning platforms. However, there is a need for these platforms to be designed from the ground up by LA experts, ensuring that data collection and analysis procedures align with the objectives and activities of teaching and learning as informed by established instructional theories. As a result, we developed a novel framework that integrates the 4C/ID model with LA approaches to enhance learners’ complex problem-solving abilities within online and blended learning environments. In developing this framework, we focused on the four core components of the original 4C/ID model along with the P-A-S cycle to determine optimal timing and methods for data collection and analysis. Our aim is to propose a framework that not only revisits and reinterprets the 4C/ID model but also fosters the development of a LA system embedded within digital learning platforms and closely tied to educational goals and learning activities. The findings of this study can serve as a valuable resource for designing and constructing adaptive teaching and learning systems, ultimately supporting learners in effectively cultivating their problem-solving skills.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {611–619},
numpages = {9},
keywords = {4C/ID model, Adaptive learning system design, Complex problem-solving, Data-informed decision-making, Learning analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3576050.3576141,
author = {Divjak, Blazenka and Svetec, Barbi and Horvat, Damir},
title = {Learning analytics dashboards: What do students actually ask for?},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576141},
doi = {10.1145/3576050.3576141},
abstract = {Learning analytics (LA) has been opening new opportunities to support learning in higher education (HE). LA dashboards are an important tool in providing students with insights into their learning progress, and predictions, leading to reflection and adaptation of learning plans and habits. Based on a human-centered approach, we present a perspective of students, as essential stakeholders, on LA dashboards. We describe a longitudinal study, based on survey methodology. The study included two iterations of a survey, conducted with second-year ICT students in 2017 (N = 222) and 2022 (N = 196). The study provided insights into the LA dashboard features the students find the most useful to support their learning. The students highly appreciated features related to short-term planning and organization of learning, while they were cautious about comparison and competition with other students, finding such features possibly demotivating. We compared the 2017 and 2022 results to establish possible changes in the students’ perspectives with the COVID-19 pandemic. The students’ awareness of the benefits of LA has increased, which may be related to the strong focus on online learning during the pandemic. Finally, a factor analysis yielded a dashboard model with five underlying factors: comparison, planning, predictions, extracurricular, and teachers.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {44–56},
numpages = {13},
keywords = {dashboard, higher education, human-centered, learning analytics, students’ perspectives},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3636555.3636914,
author = {Jung, Yeonji and Wise, Alyssa Friend},
title = {Probing Actionability in Learning Analytics: The Role of Routines, Timing, and Pathways},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636914},
doi = {10.1145/3636555.3636914},
abstract = {Actionability is a critical, but understudied, issue in learning analytics for driving impact on learning. This study investigated access and action-taking of 91 students in an online undergraduate statistics course who received analytics designed for actionability twice a week for five weeks in the semester. Findings showed high levels of access, but little direct action through the provided links. The major contribution of the study was the identification of unexpected indirect actions taken by students in response to the analytics which requires us to think (and look for evidence of impact) more broadly than has been done previously. The study also found that integrating analytics into existing learning tools and routines can increase access rates to the analytics, but may not guarantee meaningful engagement without better strategies to manage analytic timing. Together, this study advances an understanding of analytic actionability, calling for a broader examination of both direct and indirect actions within a larger learning ecosystem.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {871–877},
numpages = {7},
keywords = {Actionability, data-informed learning, formative feedback, learning analytics implementation},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3636555.3636865,
author = {Milesi, Mikaela Elizabeth and Martinez-Maldonado, Roberto},
title = {Data Storytelling in Learning Analytics? A Qualitative Investigation into Educators’ Perceptions of Benefits and Risks},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636865},
doi = {10.1145/3636555.3636865},
abstract = {Emerging research has begun to explore the incorporation of data storytelling (DS) elements to enhance the design of learning analytics (LA) dashboards. This involves using visual features, such as text annotations and visual highlights, to help educators and learners focus their attention on key insights derived from data and act upon them. Previous studies have often overlooked the perspectives of educators and other stakeholders on the potential value and risks associated with implementing DS in LA to guide attention. We address this gap by presenting a case study examining how educators perceive the: i) potential value of DS features for teaching and learning design; ii) role of the visualisation designer in delivering a contextually appropriate data story; and iii) ethical implications of utilising DS to communicate insights. We asked educators from a first-year undergraduate program to explore and discuss DS and the visualisation designer by reviewing sample data stories using their students’ data and crafting their own data stories. Our findings suggest that educators were receptive to DS features, especially meaningful use of annotations and highlighting important data points to easily identify critical information. Every participant acknowledged the potential for DS features to be exploited for harmful or self-serving purposes.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {167–177},
numpages = {11},
keywords = {data storytelling, information visualisation, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3636555.3636930,
author = {Fernandez-Nieto, Gloria Milena and Martinez-Maldonado, Roberto and Echeverria, Vanessa and Kitto, Kirsty and Ga\v{s}evi\'{c}, Dragan and Buckingham Shum, Simon},
title = {Data Storytelling Editor: A Teacher-Centred Tool for Customising Learning Analytics Dashboard Narratives},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636930},
doi = {10.1145/3636555.3636930},
abstract = {Dashboards are increasingly used in education to provide teachers and students with insights into learning. Yet, existing dashboards are often criticised for their failure to provide the contextual information or explanations necessary to help students interpret these data. Data Storytelling (DS) is emerging as an alternative way to communicate insights providing guidance and context to facilitate students’ interpretations. However, while data stories have proven effective in prompting students’ reflections, to date, it has been necessary for researchers to craft the stories rather than enabling teachers to do this by themselves. This can make this approach more feasible and scalable while also respecting teachers’ agency. Based on the notion of DS, this paper presents a DS editor for teachers. A study was conducted in two universities to examine whether the editor could enable teachers to create stories adapted to their learning designs. Results showed that teachers appreciated how the tool enabled them to contextualise automated feedback to their teaching needs, generating data stories to support student reflection.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {678–689},
numpages = {12},
keywords = {LA Dashboards, data storytelling, teacher-centered tool},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3636555.3636845,
author = {Bourguet, Marie-Luce},
title = {Demonstrating the impact of study regularity on academic success using learning analytics},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636845},
doi = {10.1145/3636555.3636845},
abstract = {Students can be described as self-regulated learners when they are meta-cognitively, motivationally, and behaviourally active participants in their own learning. Flipping the classroom requires from students good self-regulated learning skills, primarily time management and study regularity, as they must have engaged in learning activities prior to attending live classes. In this short paper, we describe our approach of using learning analytics to demonstrate the impact of study regularity on academic success in a flipped learning environment. Our key contribution is the definition of a measure of study regularity that can uncover various students’ learning profiles during flipped learning. We are showing that the regularity measure correlate strongly with academic success and that it can be used to predict students’ performance. We then discuss how such a measure can also be used to raise student’s awareness about their learning behaviour and lack of appropriate strategy, to nudge the students into modifying their learning behaviour, and to monitor class behaviour, such as detecting a worrying students’ disengagement trend.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {736–741},
numpages = {6},
keywords = {Flipped learning, Grade predictions, Learning pathways, Learning traces, Self-regulated learning, Study regularity},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3636555.3636888,
author = {Brezack, Natalie and Chan, Wynnie and Feng, Mingyu},
title = {Student Effort and Progress Learning Analytics Data Inform Teachers’ SEL Discussions in Math Class},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636888},
doi = {10.1145/3636555.3636888},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {338–348},
numpages = {11},
keywords = {learning analytics data, math instruction, online math problem-solving, socioemotional learning},
location = {Kyoto, Japan},
series = {LAK '24}
}

@proceedings{10.1145/3636555,
title = {LAK '24: Proceedings of the 14th Learning Analytics and Knowledge Conference},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@inproceedings{10.1145/3448139.3448210,
author = {Wise, Alyssa Friend and Sarmiento, Juan Pablo and Boothe Jr., Maurice},
title = {Subversive Learning Analytics},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448210},
doi = {10.1145/3448139.3448210},
abstract = {This paper puts forth the idea of a subversive stance on learning analytics as a theoretically-grounded means of engaging with issues of power and equity in education and the ways in which they interact with the usage of data on learning processes. The concept draws on efforts from fields such as socio-technical systems and critical race studies that have a long history of examining the role of data in issues of race, gender and class. To illustrate the value that such a stance offers the field of learning analytics, we provide examples of how taking a subversive perspective can help us to identify tacit assumptions-in-practice, ask generative questions about our design processes and consider new modes of creation to produce tools that operate differently in the world.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {639–645},
numpages = {7},
keywords = {subversive stance, educational equity, critical frameworks},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3706468.3706484,
author = {Borchers, Conrad and Ooge, Jeroen and Peng, Cindy and Aleven, Vincent},
title = {How Learner Control and Explainable Learning Analytics About Skill Mastery Shape Student Desires to Finish and Avoid Loss in Tutored Practice},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706484},
doi = {10.1145/3706468.3706484},
abstract = {Personalized problem selection enhances student practice in tutoring systems. Prior research has focused on transparent problem selection that supports learner control but rarely engages learners in selecting practice materials. We explored how different levels of control (i.e., full AI control, shared control, and full learner control), combined with showing learning analytics on skill mastery and visual what-if explanations, can support students in practice contexts requiring high degrees of self-regulation, such as homework. Semi-structured interviews with six middle school students revealed three key insights: (1)&nbsp;participants highly valued learner control for an enhanced learning experience and better self-regulation, especially because most wanted to avoid losses in skill mastery; (2)&nbsp;only seeing their skill mastery estimates often made participants base problem selection on their weaknesses; and (3)&nbsp;what-if explanations stimulated participants to focus more on their strengths and improve skills until they were mastered. These findings show how explainable learning analytics could shape students’ selection strategies when they have control over what to practice. They suggest promising avenues for helping students learn to regulate their effort, motivation, and goals during practice with tutoring systems.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {810–816},
numpages = {7},
keywords = {explainable AI, mastery learning, intelligent tutoring systems, design-based research, K-12, self-regulated learning},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3576050.3576061,
author = {Herodotou, Christothea and Maguire, Claire and Hlosta, Martin and Mulholland, Paul},
title = {Predictive Learning Analytics and University Teachers: Usage and perceptions three years post implementation},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576061},
doi = {10.1145/3576050.3576061},
abstract = {Predictive learning analytics (PLA) dashboards have been used by teachers to identify students at risk of failing their studies and provide proactive support. Yet, very few of them have been deployed at a large scale or had their use studied at a mature level of implementation. In this study, we surveyed 366 distance learning university teachers across four faculties three years after PLA has been made available across university as business as usual. Informed by the Unified Theory of Acceptance and Use of Technology (UTAUT), we present a context-specific version of UTAUT that reflects teachers’ perceptions of PLA in distance learning higher education. The adoption and use of PLA was shown to be positively influenced by less experience in teaching, performance expectancy, self-efficacy, positive attitudes, and low anxiety, while negatively influenced by a lack of facilitating conditions and low effort expectancy, indicating that the type of technology and context within which it is used are significant factors determining our understanding of technology usage and adoption. This study provides significant insights as to how to design, apply and implement PLA with teachers in higher education.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {68–78},
numpages = {11},
keywords = {Predictive learning analytics, Technology Adoption, UTAUT, University teachers},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3643479.3662053,
author = {Le, Lai Hoang and Nguyen, Hoang D. and Crane, Martin and Mai, Tai Tan},
title = {Multimedia learning analytics feedback in simulation-based training: A brief review},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662053},
doi = {10.1145/3643479.3662053},
abstract = {Learning analytics has gained significant attention in recent years, particularly in the healthcare field. This area of research offers valuable insights to educators, students, and researchers to enhance the quality of education. One area of focus in learning analytics is how stakeholders provide feedback to each other during training in operating theatres. With the availability of diverse multimedia elements, such as text, images, and spoken language, as data, employing effective feedback methods can bring substantial benefits to teachers, students, and researchers. This study synthesizes various approaches that apply multimedia to provide feedback in teaching, comparing and exploring their potential application in simulation-based medical training. The feasibility of input data, the effectiveness of feedback on recipients, and the AI method of generating or synthesizing feedback using existing data efficiency are also discussed in line with ethical standards. Finally, a multimedia feedback framework is proposed, which utilizes diverse multimedia formats and can be effectively implemented in various real-world scenarios.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {25–30},
numpages = {6},
keywords = {Learning analytics, Multimedia feedback, Simulation-based learning},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@inproceedings{10.1145/3576050.3576076,
author = {Zhao, Linxuan and Swiecki, Zachari and Gasevic, Dragan and Yan, Lixiang and Dix, Samantha and Jaggard, Hollie and Wotherspoon, Rosie and Osborne, Abra and Li, Xinyu and Alfredo, Riordan and Martinez-Maldonado, Roberto},
title = {METS: Multimodal Learning Analytics of Embodied Teamwork Learning},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576076},
doi = {10.1145/3576050.3576076},
abstract = {Embodied team learning is a form of group learning that occurs in co-located settings where students need to interact with others while actively using resources in the physical learning space to achieve a common goal. In such situations, communication dynamics can be complex as team discourse segments can happen in parallel at different locations of the physical space with varied team member configurations. This can make it hard for teachers to assess the effectiveness of teamwork and for students to reflect on their own experiences. To address this problem, we propose METS (Multimodal Embodied Teamwork Signature), a method to model team dialogue content in combination with spatial and temporal data to generate a signature of embodied teamwork. We present a study in the context of a highly dynamic healthcare team simulation space where students can freely move. We illustrate how signatures of embodied teamwork can help to identify key differences between high and low performing teams: i) across the whole learning session; ii) at different phases of learning sessions; and iii) at particular spaces of interest in the learning space.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {186–196},
numpages = {11},
keywords = {Collaborative learning, Communication, Healthcare simulation, Multimodality, Teamwork},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3636555.3636884,
author = {Kaliisa, Rogers and Misiejuk, Kamila and L\'{o}pez-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636884},
doi = {10.1145/3636555.3636884},
abstract = {While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students’ learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {295–304},
numpages = {10},
keywords = {Learning analytics dashboards (LADs), impact, learning outcomes, systematic review},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3593663.3593686,
author = {Sapsai, Iryna and Valencia Usme, Yeimy Paola and Abke, Joerg},
title = {Learning Analytics Dashboard for Educators: Proposed Project to Design with Pedagogical Background},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593686},
doi = {10.1145/3593663.3593686},
abstract = {In this article, the authors describe a prototype of a Learning Analytics Dashboard (LAD) for educators. It is based on the analysis of pedagogical actions and taking into the process and learning style of students in an online environment based on learning analytics (LA). A description of the Dashboard structure, divided into levels and categories based on available learning analytics, will allow the educator to dive deeper into the online course themselves and explore more. It will also allow them to determine the level of student performance, identify gaps in learning materials, and research student data.The authors have identified further directions for the development of a LAD for a professor, including modeling algorithms for researching student behavior and learning style using Artificial Intelligence and presenting LA in a visualized form. This paper shows the stages of creating a professor's LAD prototype as a functional part of the adaptive learning system in the HASKI-System to analyze visual information obtained from LA and the possibilities to monitor the learning process, learning progress, student activity, and make decisions on careful intervention in the students’ learning process.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {38–47},
numpages = {10},
keywords = {Learning Analytics Dashboard, adaptive learning system, distance education pedagogy, information visualization, learning analytics, pedagogical actions, pedagogical knowledge},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3636555.3636932,
author = {Wang, Chao and Hu, Xiao and Hern\'{a}ndez L\'{o}pez, Nora Patricia and Ng, Jeremy Tzi Dong},
title = {Needs Analysis of Learning Analytics Dashboard for College Teacher Online Professional Learning in an International Training Initiative for the Global South},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636932},
doi = {10.1145/3636555.3636932},
abstract = {Online courses enable wide access to educational resources and thus provide a feasible platform for cross-regional teacher professional learning. Learning analytics dashboards (LAD) can support online learners by providing fine-grained feedback generated from learners’ interactions with platforms. Nevertheless, most studies on teacher online professional learning focus on resource-rich and technology-advanced regions, with scarce attention to the Global South. Furthermore, existing studies on LAD design mainly target students’ learning, rather than teachers’ professional learning. Therefore, it is much needed to develop LAD for teacher-learners online professional learning in the Global South. Contextualized in an international online professional training initiative, this study conducted in-depth interviews with 42 teacher-learners from 19 countries in the Global South, aiming to identify their needs for 1) support on their self-regulated learning (SRL), and 2) potential LA components in dashboards. Findings indicated that teacher-learners needed support for self-regulated learning strategies, including motivation maintenance, time management, environment structuring, help-seeking, and self-evaluation. Nine LA features were identified to design the LADs to support SRL preliminarily. This co-designed LAD study with interviewees improved our understanding on the needs of college teachers in the Global South for LA support during their online professional learning, generating practical insights into needs-driven LAD designs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {915–921},
numpages = {7},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3576050.3576085,
author = {Bond, Melissa and Viberg, Olga and Bergdahl, Nina},
title = {The current state of using learning analytics to measure and support K-12 student engagement: A scoping review},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576085},
doi = {10.1145/3576050.3576085},
abstract = {Student engagement has been identified as a critical construct for understanding and predicting educational success. However, research has shown that it can be hard to align data-driven insights of engagement with observed and self-reported levels of engagement. Given the emergence and increasing application of learning analytics (LA) within K-12 education, further research is needed to understand how engagement is being conceptualized and measured within LA research. This scoping review identifies and synthesizes literature published between 2011-2022, focused on LA and student engagement in K-12 contexts, and indexed in five international databases. 27 articles and conference papers from 13 different countries were included for review. We found that most of the research was undertaken in middle school years within STEM subjects. The results show that there is a wide discrepancy in researchers’ understanding and operationalization of engagement and little evidence to suggest that LA improves learning outcomes and support. However, the potential to do so remains strong. Guidance is provided for future LA engagement research to better align with these goals.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {240–249},
numpages = {10},
keywords = {K-12, Learning Analytics, Scoping Review, Student Engagement},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3678957.3688613,
author = {Joshi, Vasundhara},
title = {Enhancing Collaboration and Performance among EMS Students through Multimodal Learning Analytics},
year = {2024},
isbn = {9798400704628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678957.3688613},
doi = {10.1145/3678957.3688613},
abstract = {Physiological synchrony plays an important role in measuring collaboration and performance within teams. However, there has been little investigation into awareness of physiological synchrony and its impact on the collaboration and performance. In my dissertation, I am proposing a study to investigate the impact of awareness of near real-time physiological synchrony, through multimodal learning analytic dashboard, on Emergency Medical Services (EMS) students’ perceived collaboration and performance. Also, I plan to investigate the best practices for presenting multimodal data to EMS trainees in collaborative learning environment. The research aims to enhance students’ engagement and reflection on their collaborative interactions and performance.},
booktitle = {Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {607–611},
numpages = {5},
keywords = {Multimodal data visualization, collaboration, electrodermal activity, learning analytics dashboards, physiological synchrony},
location = {San Jose, Costa Rica},
series = {ICMI '24}
}

@inproceedings{10.1145/3506860.3506910,
author = {Sarmiento, Juan Pablo and Wise, Alyssa Friend},
title = {Participatory and Co-Design of Learning Analytics: An Initial Review of the Literature},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506910},
doi = {10.1145/3506860.3506910},
abstract = {Participatory Design (PD), and Co-design (Co-D), can be effective ways to improve technological innovation and to incorporate users’ needs in the development of learning analytics (LA). However, these methods can be difficult to implement and there has yet to be a synopsis of how its and techniques have been applied to the specific needs of LA. This study reviewed 90 papers that described 52 cases of PD of LA between 2010 and 2020 to address the research question “How is participatory design (PD) being used within LA?”. It focuses on examining which groups of participants are normally included in PD for LA, in what phases of the design process it is used, and what specific tools and techniques have LA designers adapted or developed to co-create with design partners. Findings show that there is a growing number of researchers using these methods in recent years, particularly in higher education and with instructor stakeholders. However, it was also found that often the literature would describe the PD activities only superficially, and that some aspects of PD, such as recruitment, were seldom considered overtly in the descriptions of these processes.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {535–541},
numpages = {7},
keywords = {Co-Design, Learning Analytics, Literature Review, Participatory Design},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3576050.3576110,
author = {Lang, Charles and Davis, Laura},
title = {Learning Analytics and Stakeholder Inclusion: What do We Mean When We Say "Human-Centered"?},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576110},
doi = {10.1145/3576050.3576110},
abstract = {Given the growth in interest in human-centeredness within the learning analytics community - a workshop at LAK, a special issue in the Journal of Learning Analytics and multiple papers published on the topic - it seems an appropriate time to critically evaluate the popular design approach. Using a corpus of 165 publications that have substantial reference to both learning analytics and human-centeredness, the following paper delineates what is meant by "human-centered" and then discusses what the implications are for this approach. The conclusion reached through this analysis is that when authors refer to human-centeredness in learning analytics they are largely referring to stakeholder inclusion and the means by which this can be achieved (methodologically, politically and logistically). Furthermore, the justification for stakeholder inclusion is often coached in terms of its ability to develop more effective learning analytics applications along several dimensions (efficiency, efficacy, impact). With reference to human-centered design in other fields a discussion follows of the issues with such an approach and a prediction that LA will likely move toward a more neutral stance on stakeholder inclusion, as has occurred in both human-centered design and stakeholder engagement research in the past. A more stakeholder-neutral stance is defined as one in which stakeholder inclusion is one of many tools utilized in developing learning analytics applications.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {411–417},
numpages = {7},
keywords = {Human-centered design, co-design, participatory, user-centered design},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3576050.3576143,
author = {Chejara, Pankaj and Prieto, Luis P. and Rodriguez-Triana, Maria Jesus and Ruiz-Calleja, Adolfo and Khalil, Mohammad},
title = {Impact of window size on the generalizability of collaboration quality estimation models developed using Multimodal Learning Analytics},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576143},
doi = {10.1145/3576050.3576143},
abstract = {Multimodal Learning Analytics (MMLA) has been applied to collaborative learning, often to estimate collaboration quality with the use of multimodal data, which often have uneven time scales. The difference in time scales is usually handled by dividing and aggregating data using a fixed-size time window. So far, the current MMLA research lacks a systematic exploration of whether and how much window size affects the generalizability of collaboration quality estimation models. In this paper, we investigate the impact of different window sizes (e.g., 30 seconds, 60s, 90s, 120s, 180s, 240s) on the generalizability of classification models for collaboration quality and its underlying dimensions (e.g., argumentation). Our results from an MMLA study involving the use of audio and log data showed that a 60 seconds window size enabled the development of more generalizable models for collaboration quality (AUC 61%) and argumentation (AUC 64%). In contrast, for modeling dimensions focusing on coordination, interpersonal relationship, and joint information processing, a window size of 180 seconds led to better performance in terms of across-context generalizability (on average from 56% AUC to 63% AUC). These findings have implications for the eventual application of MMLA in authentic practice.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {559–565},
numpages = {7},
keywords = {Collaboration Quality, Generalizability, Machine Learning, MultiModal Learning Analytics, Temporal Window},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3613905.3651111,
author = {Milesi, Mikaela E and Alfredo, Riordan and Echeverria, Vanessa and Yan, Lixiang and Zhao, Linxuan and Tsai, Yi-Shan and Martinez-Maldonado, Roberto},
title = {"It's Really Enjoyable to See Me Solve the Problem like a Hero": GenAI-enhanced Data Comics as a Learning Analytics Tool},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651111},
doi = {10.1145/3613905.3651111},
abstract = {Data comics are an emergent storytelling format that can enable non-experts to consume salient insights from data. Despite some research investigating the use of comic strips in education, there is limited evidence relating to how students perceive data comics about their own data as a way to reflect on their learning experience. In this paper, we summarise nursing students’ perceptions of the advantages and limitations of data comics by presenting personalised Multimodal Learning Analytics (LA) data in data comics form. We present GenAI-enhanced data comic prototypes created using a combination of the generative artificial intelligence tool, Midjourney, and graphics illustration software. Our findings indicate that while students see the potential of data comics as an engaging and enjoyable visualisation technique, concerns remain regarding the perceived lack of professionalism associated with this format.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {4},
numpages = {7},
keywords = {data comics, information visualisation, learning analytics},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3375462.3375504,
author = {Verbert, Katrien and Ochoa, Xavier and De Croon, Robin and Dourado, Raphael A. and De Laet, Tinne},
title = {Learning analytics dashboards: the past, the present and the future},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375504},
doi = {10.1145/3375462.3375504},
abstract = {Learning analytics dashboards are at the core of the LAK vision to involve the human into the decision-making process. The key focus of these dashboards is to support better human sense-making and decision-making by visualising data about learners to a variety of stakeholders. Early research on learning analytics dashboards focused on the use of visualisation and prediction techniques and demonstrates the rich potential of dashboards in a variety of learning settings. Present research increasingly uses participatory design methods to tailor dashboards to the needs of stakeholders, employs multimodal data acquisition techniques, and starts to research theoretical underpinnings of dashboards. In this paper, we present these past and present research efforts as well as the results of the VISLA19 workshop on "Visual approaches to Learning Analytics" that was held at LAK19 with experts in the domain to identify and articulate common practices and challenges for the domain. Based on an analysis of the results, we present a research agenda to help shape the future of learning analytics dashboards.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {35–40},
numpages = {6},
keywords = {evaluation, interaction, learning analytics dashboards, visualisation},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3506860.3506895,
author = {Fernandez Nieto, Gloria Milena and Kitto, Kirsty and Buckingham Shum, Simon and Martinez-Maldonado, Roberto},
title = {Beyond the Learning Analytics Dashboard: Alternative Ways to Communicate Student Data Insights Combining Visualisation, Narrative and Storytelling},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506895},
doi = {10.1145/3506860.3506895},
abstract = {Learning Analytics (LA) dashboards have become a popular medium for communicating to teachers analytical insights obtained from student data. However, recent research indicates that LA dashboards can be complex to interpret, are often not grounded in educational theory, and frequently provide little or no guidance on how to interpret them. Despite these acknowledged problems, few suggestions have been made as to how we might improve the visual design of LA tools to support richer and alternative ways to communicate student data insights. In this paper, we explore three design alternatives to represent student multimodal data insights by combining data visualisation, narratives and storytelling principles. Based on foundations in data storytelling, three visual-narrative interfaces were designed with teachers: i) visual data slices, ii) a tabular visualisation, and iii) a written report. These were validated as a part of an authentic study where teachers explored activity logs and physiological data from co-located collaborative learning classes in the context of healthcare education. Results suggest that alternatives to LA dashboards can be considered as effective tools to support teachers’ reflection, and that LA designers should identify the representation type that best fits teachers’ needs.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {219–229},
numpages = {11},
keywords = {multimodal data, qualitative analysis, visual learning analytics},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3711403.3711432,
author = {Xin, Hua and Yang, Fan},
title = {Research on Visual Monitoring and Feedback of Online Learning for College Students from the Perspective of Learning Analytics},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711432},
doi = {10.1145/3711403.3711432},
abstract = {Big data and learning analytics technologies use log data recorded by learning systems, track learning tasks, and provide visual reports to help teachers improve their practices, encourage students to learn and improve their academic performance. This study, grounded in learning analytics technology, delves into the influence of visual monitoring and feedback mechanisms on students' online learning performance and their capacity for self-regulated learning within digital environments. Ultimately, it seeks to offer insightful guidance for the evolution and application of learning analytics and visualization technologies.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {44–48},
numpages = {5},
keywords = {Learning analytics, Learning behavior, Online self-regulated learning, Visual monitoring and feedback},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3657604.3664715,
author = {Li, Qiujie and Zhou, Xuehan and Xu, Di and Baker, Rachel B. and Holton, Amanda J.},
title = {Varying Impacts: The Role of Student Self-Evaluation in Navigating Learning Analytics},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664715},
doi = {10.1145/3657604.3664715},
abstract = {The enthusiasm for student-facing analytics as tools for supporting student self-regulation is overshadowed by uncertainties about their actual impact on student outcomes. This study aims to fill the gap in experimental evidence concerning student-facing analytics by implementing a randomized control trial. Specifically, we investigated the effects of data visualizations that display student level of content mastery in comparison to their peers, alongside recommendations for learning strategies. The preliminary results reveal that the intervention impacts student attribution and motivation in varying ways, based on their self-evaluation of their current course performance. Further analysis, including coding students' interpretation of the data visualization, will be conducted to uncover the diverse ways students might interpret the analytics.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {535–538},
numpages = {4},
keywords = {attribution, higher education, learning analytics, online learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3448139.3448162,
author = {Gray, Geraldine and Schalk, Ana and Rooney, Pauline and Lang, Charles},
title = {A Stakeholder Informed Professional Development Framework to Support Engagement with Learning Analytics},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448162},
doi = {10.1145/3448139.3448162},
abstract = {This paper reports on a study aimed at identifying training requirements for both staff and students in higher education to enable more widespread use of learning analytics. Opinions of staff and students were captured through ten focus groups (37 students; 40 staff) and two surveys (1,390 students; 160 staff). Participants were predominantly from two higher education institutions in Ireland. Analysis of the results informed a framework for continuous professional development in learning analytics focusing on aspects of using data, legal and ethical considerations, policy, and workload. The framework presented here differentiates between the training needs of students, academic staff and professional services staff.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {237–247},
numpages = {11},
keywords = {Learning analytics, continuous professional development, higher education, stakeholder perspectives},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3506860.3506861,
author = {Nazaretsky, Tanya and Bar, Carmel and Walter, Michal and Alexandron, Giora},
title = {Empowering Teachers with AI: Co-Designing a Learning Analytics Tool for Personalized Instruction in the Science Classroom},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506861},
doi = {10.1145/3506860.3506861},
abstract = {AI-powered educational technology that is designed to support teachers in providing personalized instruction can enhance their ability to address the needs of individual students, hopefully leading to better learning gains. This paper presents results from a participatory research aimed at co-designing with science teachers a learning analytics tool that will assist them in implementing a personalized pedagogy in blended learning contexts. The development process included three stages. In the first, we interviewed a group of teachers to identify where and how personalized instruction may be integrated into their teaching practices. This yielded a clustering-based personalization strategy. Next, we designed a mock-up of a learning analytics tool that supports this strategy and worked with another group of teachers to define an ‘explainable learning analytics’ scheme that explains each cluster in a way that is both pedagogically meaningful and can be generated automatically. Third, we developed an AI algorithm that supports this ‘explainable clusters’ pedagogy and conducted a controlled experiment that evaluated its contribution to teachers’ ability to plan personalized learning sequences. The planned sequences were evaluated in a blinded fashion by an expert, and the results demonstrated that the experimental group – teachers who received the clusters with the explanations – designed sequences that addressed the difficulties exhibited by different groups of students better than those designed by teachers who received the clusters without explanations. The main contribution of this study is twofold. First, it presents an effective personalization approach that fits blended learning in the science classroom, which combines a real-time clustering algorithm with an explainable-AI scheme that can automatically build pedagogically meaningful explanations from item-level meta-data (Q Matrix). Second, it demonstrates how such an end-to-end learning analytics solution can be built with teachers through a co-design process and highlights the types of knowledge that teachers add to system-provided analytics in order to apply them to their local context. As a practical contribution, this process informed the design of a new learning analytics tool that was integrated into a free online learning platform that is being used by more than 1000 science teachers.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {1–12},
numpages = {12},
keywords = {Blended Learning, Learning Analytics, Participatory Design, Personalized Instruction, Teacher Dashboards},
location = {Online, USA},
series = {LAK22}
}

@article{10.1145/3622784,
author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Fernandez-Nieto, Gloria and Yan, Lixiang and Zhao, Linxuan and Alfredo, Riordan and Li, Xinyu and Dix, Samantha and Jaggard, Hollie and Wotherspoon, Rosie and Osborne, Abra and Shum, Simon Buckingham and Ga\v{s}evi\'{c}, Dragan},
title = {Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-Wild},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3622784},
doi = {10.1145/3622784},
abstract = {Multimodal Learning Analytics (MMLA) innovations make use of rapidly evolving sensing and artificial intelligence algorithms to collect rich data about learning activities that unfold in physical spaces. The analysis of these data is opening exciting new avenues for both studying and supporting learning. Yet, practical and logistical challenges commonly appear while deploying MMLA innovations “in-the-wild”. These can span from technical issues related to enhancing the learning space with sensing capabilities, to the increased complexity of teachers’ tasks. These practicalities have been rarely investigated. This article addresses this gap by presenting a set of lessons learnt from a 2-year human-centred MMLA in-the-wild study conducted with 399 students and 17 educators in the context of nursing education. The lessons learnt were synthesised into topics related to (i) technological/physical aspects of the deployment; (ii) multimodal data and interfaces; (iii) the design process; (iv) participation, ethics and privacy; and (v) sustainability of the deployment.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {8},
numpages = {41},
keywords = {Learning analytics, sensors, ubiquitous computing, human-centred design, CSCW}
}

@inproceedings{10.1145/3636555.3636855,
author = {Zhao, Linxuan and Echeverria, Vanessa and Swiecki, Zachari and Yan, Lixiang and Alfredo, Riordan and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {Epistemic Network Analysis for End-users: Closing the Loop in the Context of Multimodal Analytics for Collaborative Team Learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636855},
doi = {10.1145/3636555.3636855},
abstract = {Effective collaboration and team communication are critical across many sectors. However, the complex dynamics of collaboration in physical learning spaces, with overlapping dialogue segments and varying participant interactions, pose assessment challenges for educators and self-reflection difficulties for students. Epistemic network analysis (ENA) is a relatively novel technique that has been used in learning analytics (LA) to unpack salient aspects of group communication. Yet, most LA works based on ENA have primarily sought to advance research knowledge rather than directly aid teachers and students by closing the LA loop. We address this gap by conducting a study in which we i) engaged teachers in designing human-centred versions of epistemic networks; ii) formulated an NLP methodology to code physically distributed dialogue segments of students based on multimodal (audio and positioning) data, enabling automatic generation of epistemic networks; and iii) deployed the automatically generated epistemic networks in 28 authentic learning sessions and investigated how they can support teaching. The results indicate the viability of completing the analytics loop through the design of streamlined epistemic network representations that enable teachers to support students’ reflections.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {90–100},
numpages = {11},
keywords = {Collaborative learning, Human-centred, Learning Analytics, Multimodality, Teamwork},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3631700.3665228,
author = {Colling, Leona and Kholin, Mareike and Meurers, Detmar},
title = {A Learning Analytics Dashboard for K-12 English Teachers - Bridging the Gap Between Student Process Data and Teacher Needs},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665228},
doi = {10.1145/3631700.3665228},
abstract = {Educational technologies are being used more and more in secondary school settings. This increases the amount of students’ learning related data produced and stored. To keep up with this rise and to get most out of the collected data, teachers need digital tools that support and facilitate their pedagogical decision-making process. Learning analytics dashboards can be a good source to provide teachers with necessary insights into their students’ learning processes. However, for such tools to be effective and actionable, they have to be aligned with teachers’ needs and thus, provide and visualize data in a concise and structured way. We therefore conducted a survey study with 11 English teachers from K-12 secondary schools in Germany who evaluated the assumed usefulness of possible dashboard features. Based on these findings, we developed a teacher dashboard incorporating the most desired functionalities, such as a quickly accessible summary of strengths, weaknesses and support needs, or an overview of current misconceptions and competencies alongside additional metrics in order to support multiple teaching practices. The implementation and the underlying calculations are described, focusing on the importance of learners’ process data to provide teachers with a detailed and revealing view on their students’ and class learning states. In an evaluation study of the dashboard’s prototype with mock data, teachers (n=6) gave high ratings for the dashboard’s usability.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {538–548},
numpages = {11},
keywords = {computer-assisted language learning, intelligent tutoring systems, learning analytics, teacher dashboard},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3375462.3375507,
author = {Michos, Konstantinos and Lang, Charles and Hern\'{a}ndez-Leo, Davinia and Price-Dennis, Detra},
title = {Involving teachers in learning analytics design: lessons learned from two case studies},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375507},
doi = {10.1145/3375462.3375507},
abstract = {Involving teachers in the design of technology-enhanced learning environments is a useful method towards bridging the gap between research and practice. This is especially relevant for learning analytics tools, wherein the presentation of educational data to teachers or students requires meaningful sense-making to effectively support data-driven actions. In this paper, we present two case studies carried out in the context of two research projects in the USA and Spain which aimed to involve teachers in the co-design of learning analytics tools through professional development programs. The results of a cross-case analysis highlight lessons learned around challenges and principles regarding the meaningful involvement of teachers in learning analytics tooling design.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {94–99},
numpages = {6},
keywords = {case studies, co-design, learning analytics, teacher professional development, teachers},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3448139.3448187,
author = {Dourado, Raphael A. and Rodrigues, Rodrigo Lins and Ferreira, Nivan and Mello, Rafael Ferreira and Gomes, Alex Sandro and Verbert, Katrien},
title = {A Teacher-facing Learning Analytics Dashboard for Process-oriented Feedback in Online Learning},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448187},
doi = {10.1145/3448139.3448187},
abstract = {In online learning, teachers need constant feedback about their students’ progress and regulation needs. Learning Analytics Dashboards for process-oriented feedback can be a valuable tool for this purpose. However, few such dashboards have been proposed in literature, and most of them lack empirical validation or grounding in learning theories. We present a teacher-facing dashboard for process-oriented feedback in online learning, co-designed and evaluated through an iterative design process involving teachers and visualization experts. We also reflect on our design process by discussing the challenges, pitfalls, and successful strategies for building this type of dashboard.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {482–489},
numpages = {8},
keywords = {learning analytics dashboards, process-oriented feedback, online learning, visualization},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3612783.3612813,
author = {Becerra, \'{A}Lvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
title = {User Experience Study using a System for Generating MultiModal Learning Analytics Dashboards},
year = {2024},
isbn = {9798400707902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3612783.3612813},
doi = {10.1145/3612783.3612813},
abstract = {In the article, we present a Web-based System called M2LADS, which supports the integration and visualization of multimodal data recorded in user experiences (UX) in a Learning Analytics (LA) system in the form of Web-based Dashboards. Based on the edBB platform, the multimodal data gathered contains biometric and behavioral signals including electroencephalogram data to measure learners’ cognitive attention, heart rate for affective measures and visual attention from the video recordings. Additionally, learners’ static background data and their learning performance measures are tracked using LOGGE tool. M2LADS provides opportunities to capture learners’ holistic experience during their interactions with the learning analytic system in order to improve the system and the user experience of the learners.},
booktitle = {Proceedings of the XXIII International Conference on Human Computer Interaction},
articleno = {29},
numpages = {2},
keywords = {Biometrics and Behavior, Dashboard, MOOC, Multimodal Learning Analytics, User Experience (UX), e-Learning},
location = {Lleida, Spain},
series = {Interacci\'{o}n '23}
}

@inproceedings{10.1145/3576050.3576144,
author = {Chejara, Pankaj and Prieto, Luis P. and Rodriguez-Triana, Maria Jesus and Kasepalu, Reet and Ruiz-Calleja, Adolfo and Shankar, Shashi Kant},
title = {How to Build More Generalizable Models for Collaboration Quality? Lessons Learned from Exploring Multi-Context Audio-Log Datasets using Multimodal Learning Analytics},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576144},
doi = {10.1145/3576050.3576144},
abstract = {Multimodal learning analytics (MMLA) research for building collaboration quality estimation models has shown significant progress. However, the generalizability of such models is seldom addressed. In this paper, we address this gap by systematically evaluating the across-context generalizability of collaboration quality models developed using a typical MMLA pipeline. This paper further presents a methodology to explore modelling pipelines with different configurations to improve the generalizability of the model. We collected 11 multimodal datasets (audio and log data) from face-to-face collaborative learning activities in six different classrooms with five different subject teachers. Our results showed that the models developed using the often-employed MMLA pipeline degraded in terms of Kappa from Fair (.20 &lt; Kappa &lt; .40) to Poor (Kappa &lt; .20) when evaluated across contexts. This degradation in performance was significantly ameliorated with pipelines that emerged as high-performing from our exploration of 32 pipelines. Furthermore, our exploration of pipelines provided statistical evidence that often-overlooked contextual data features improve the generalizability of a collaboration quality model. With these findings, we make recommendations for the modelling pipeline which can potentially help other researchers in achieving better generalizability in their collaboration quality estimation models.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {111–121},
numpages = {11},
keywords = {Collaboration Quality, Generalizability, Machine Learning, MultiModal Learning Analytics},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3448139.3448165,
author = {Hakami, Eyad and Hernandez-Leo, Davinia},
title = {Investigating the Well-being Impacts of Educational Technologies Supported by Learning Analytics: An application of the initial phase of IEEE P7010 recommended practice to a set of cases},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448165},
doi = {10.1145/3448139.3448165},
abstract = {The accelerated adoption of digital technologies by people and communities results in a close relation between, on one hand, the state of individual and societal well-being and, on the other hand, the state of the digital technologies that underpin our life experiences. The ethical concerns and questions about the impact of such technologies on human well-being become more crucial when data analytics and intelligent competences are integrated. To investigate how learning technologies could impact human well-being considering the promising and concerning roles of learning analytics, we apply the initial phase of the recently produced IEEE P7010 Well-being Impact Assessment, a methodology and a set of metrics, to allow the digital well-being of a set of educational technologies to be more comprehensively tackled and evaluated. We posit that the use of IEEE P7010 well-being metrics could help identify where educational technologies supported by learning analytics would increase or decrease well-being, providing new routes to future technological innovation in Learning Analytics research.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {269–279},
numpages = {11},
keywords = {Digital well-being, Ethics, Learning analytics, Values},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3568739.3568758,
author = {Tran, Tich Phuoc and Jan, Tony and Kew, Si Na},
title = {Learning Analytics for Improved Course Delivery: Applications and Techniques},
year = {2023},
isbn = {9781450398091},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568739.3568758},
doi = {10.1145/3568739.3568758},
abstract = {Learning Analytics (LA) is an emerging research field that harnesses the power of data modelling, data mining and visualization to enhance the understanding of teaching and learning as well as supporting the personalization of education. Typical LA applications include dashboards displaying course progress, intelligence reports tracking the use of educational resources, and systems that predict students' academic performance and identify struggling students. In this article, we review the major elements of LA applications, including typical workflows, data types, and approaches to analytics. In addition to the basic reporting tools available in Learning Management Systems (LMSs), the article provides insights into how Machine Learning (ML) can detect the students at risk of failing. Finally, six educational applications in which data analytics helps improve course delivery are discussed.},
booktitle = {Proceedings of the 6th International Conference on Digital Technology in Education},
pages = {100–106},
numpages = {7},
keywords = {Learning analytics, Machine learning, Student at risk detection, Visual analytics},
location = {Hangzhou, China},
series = {ICDTE '22}
}

@inproceedings{10.1145/3506860.3506900,
author = {Williamson, Kimberly and Kizilcec, Rene},
title = {A Review of Learning Analytics Dashboard Research in Higher Education: Implications for Justice, Equity, Diversity, and Inclusion},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506900},
doi = {10.1145/3506860.3506900},
abstract = {Learning analytics dashboards (LADs) are becoming more prevalent in higher education to help students, faculty, and staff make data-informed decisions. Despite extensive research on the design and implementation of LADs, few studies have investigated their relation to justice, equity, diversity, and inclusion (JEDI). Excluding these issues in LAD research limits the potential benefits of LADs generally and risks reinforcing long-standing inequities in education. We conducted a critical literature review, identifying 45 relevant papers to answer three research questions: how is LAD research improving JEDI, ii. how might it maintain or exacerbate inequitable outcomes, and iii. what opportunities exist in this space to improve JEDI in higher education. Using thematic analysis, we identified four common themes: (1) participant identities and researcher positionality, (2) surveillance concerns, (3) implicit pedagogies, and (4) software development resources. While we found very few studies directly addressing or mentioning JEDI concepts, we used these themes to explore ways researchers could consider JEDI in their studies. Our investigation highlights several opportunities to intentionally incorporate JEDI into LAD research by sharing software resources and conducting cross-border collaborations, better incorporating user needs, and centering considerations of justice in LAD efforts to improve historical inequities.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {260–270},
numpages = {11},
keywords = {Dashboards, Diversity, Equity, Higher Education, Inclusion, Justice, Literature Review},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3549737.3549774,
author = {Tsoni, Rozita and Kalles, Dimitris and Verykios, Vassilios},
title = {A Data Pipeline Approach for Building Learning Analytics Dashboards},
year = {2022},
isbn = {9781450395977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549737.3549774},
doi = {10.1145/3549737.3549774},
abstract = {In the era of data abundance, the ability to leverage data to assess the learning process is of great importance. Learning Analytics has been widely used and different approaches of deployment methods have been proposed, aiming to improve teaching and learning. Learning Analytics Dashboards (LAD), as the most dominant method to communicate results to the educational stakeholders, are found to be very effective. However, building a flexible and informative LAD is a complex procedure that incorporates several consecutive steps. The data pipeline framework which is used as a blueprint for generating LADs in this paper offers an important abstraction that helps the non-technical users to appreciate the effectiveness of the approach, as for every insight and report that is generated by a data scientist, there are most probably large such pipelines that implement the underlying functionality. This paper discusses the utility of data pipelines and presents the implementation of a LAD based on a data pipeline in Distance Learning students’ data for summative assessment, along with some preliminary results.},
booktitle = {Proceedings of the 12th Hellenic Conference on Artificial Intelligence},
articleno = {33},
numpages = {6},
keywords = {Data Pipelines, Distance Learning, Learning Analytics Dashboards, Summative Assessment},
location = {Corfu, Greece},
series = {SETN '22}
}

@inproceedings{10.1145/3612783.3612785,
author = {Pel\'{a}ez, Carlos Alberto and Solano, Andr\'{e}s and De La Rosa, Emma Adriana and L\'{o}pez, Jes\'{u}s Alfonso and Parra, Jorge Andrick and Ospina, Johann Alexis and Ram\'{\i}rez, Gabriel Mauricio and Moreira, Fernando},
title = {Learning analytics in the design of interactive multimedia experiences for elementary education: a systematic review},
year = {2024},
isbn = {9798400707902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3612783.3612785},
doi = {10.1145/3612783.3612785},
abstract = {Interactive multimedia experiences are interesting for students because they stimulate several of their senses, provide assorted styles of interaction, and the user can modify the development of the experience thanks to the interactions with it, among other benefits. Moreover, this interaction produces data that can be used to improve the teaching-learning process of students using Learning Analytics techniques. In this sense, this paper presents a review of the state of the art on the impact of Learning Analytics in the development of multimedia technologies and evolution in the design process in the context of elementary education. A systematic literature review methodology has been applied to carry out this research. The results show the need for a well-defined process and a series of specific guidelines to include Learning Analytics in the solutions for this context.},
booktitle = {Proceedings of the XXIII International Conference on Human Computer Interaction},
articleno = {1},
numpages = {6},
keywords = {Elementary education, Interactive multimedia experience, Learning analytics},
location = {Lleida, Spain},
series = {Interacci\'{o}n '23}
}

@inproceedings{10.1145/3375462.3375539,
author = {Shabaninejad, Shiva and Khosravi, Hassan and Indulska, Marta and Bakharia, Aneesha and Isaias, Pedro},
title = {Automated insightful drill-down recommendations for learning analytics dashboards},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375539},
doi = {10.1145/3375462.3375539},
abstract = {The big data revolution is an exciting opportunity for universities, which typically have rich and complex digital data on their learners. It has motivated many universities around the world to invest in the development and implementation of learning analytics dashboards (LADs). These dashboards commonly make use of interactive visualisation widgets to assist educators in understanding and making informed decisions about the learning process. A common operation in analytical dashboards is a 'drill-down', which in an educational setting allows users to explore the behaviour of sub-populations of learners by progressively adding filters. Nevertheless, drill-down challenges exist, which hamper the most effective use of the data, especially by users without a formal background in data analysis. Accordingly, in this paper, we address this problem by proposing an approach that recommends insightful drill-downs to LAD users. We present results from an application of our proposed approach using an existing LAD. A set of insightful drill-down criteria from a course with 875 students are explored and discussed.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {41–46},
numpages = {6},
keywords = {decision trees, drill-down analysis, exploratory data analysis, learning analytics dashboards},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3448139.3448174,
author = {Lim, Lisa-Angelique and Gasevic, Dragan and Matcha, Wannisa and Ahmad Uzir, Nora'Ayu and Dawson, Shane},
title = {Impact of learning analytics feedback on self-regulated learning: Triangulating behavioural logs with students’ recall},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448174},
doi = {10.1145/3448139.3448174},
abstract = {Learning analytics (LA) has been presented as a viable solution for scaling timely and personalised feedback to support students’ self-regulated learning (SRL). Research is emerging that shows some positive associations between personalised feedback with students’ learning tactics and strategies as well as time management strategies, both important aspects of SRL. However, the definitive role of feedback on students’ SRL adaptations is under-researched; this requires an examination of students’ recalled experiences with their personalised feedback. Furthermore, an important consideration in feedback impact is the course context, comprised of the learning design and delivery modality. This mixed-methods study triangulates learner trace data from two different course contexts, with students’ qualitative data collected from focus group discussions, to more fully understand the impact of their personalised feedback and to explicate the role of this feedback on students’ SRL adaptations. The quantitative analysis showed the contextualised impact of the feedback on students’ learning and time management strategies in the different courses, while the qualitative analysis highlighted specific ways in which students used their feedback to adjust these and other SRL processes.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {364–374},
numpages = {11},
keywords = {learning analytics, learning strategies, mixed methods, personalised feedback, self-regulated learning, time management strategies},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3386527.3406751,
author = {Pan, Zilong and Li, Chenglu and Liu, Min},
title = {Learning Analytics Dashboard for Problem-based Learning},
year = {2020},
isbn = {9781450379519},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386527.3406751},
doi = {10.1145/3386527.3406751},
abstract = {This study examined two machine learning models for de- signing a learning analytics dashboard to assist teachers in facilitating problem-based learning. Specifically, we used BERT to automatically process a large amount of textual data to understand students' scientific argumentation. We then used Hidden Markov Model (HMM) to find students' cognitive state transition with time-series data. Preliminary results showed the models achieved high accuracy and were coherent with related theories, indicating the models can provide teachers with interpretable information to identify in-need students.},
booktitle = {Proceedings of the Seventh ACM Conference on Learning @ Scale},
pages = {393–396},
numpages = {4},
keywords = {artificial intelligence, learning analytics dashboard, machine learning, problem-based learning (pbl)},
location = {Virtual Event, USA},
series = {L@S '20}
}

@inproceedings{10.1145/3375462.3375483,
author = {Viberg, Olga and Khalil, Mohammad and Baars, Martine},
title = {Self-regulated learning and learning analytics in online learning environments: a review of empirical research},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375483},
doi = {10.1145/3375462.3375483},
abstract = {Self-regulated learning (SRL) can predict academic performance. Yet, it is difficult for learners. The ability to self-regulate learning becomes even more important in emerging online learning settings. To support learners in developing their SRL, learning analytics (LA), which can improve learning practice by transforming the ways we support learning, is critical. This scoping review is based on the analysis of 54 papers on LA empirical research for SRL in online learning contexts published between 2011 and 2019. The research question is: What is the current state of the applications of learning analytics to measure and support students' SRL in online learning environments? The focus is on SRL phases, methods, forms of SRL support, evidence for LA and types of online learning settings. Zimmerman's model (2002) was used to examine SRL phases. The evidence about LA was examined in relation to four propositions: whether LA i) improve learning outcomes, ii) improve learning support and teaching, iii) are deployed widely, and iv) used ethically. Results showed most studies focused on SRL parts from the forethought and performance phase but much less focus on reflection. We found little evidence for LA that showed i) improvements in learning outcomes (20%), ii) improvements in learning support and teaching (22%). LA was also found iii) not used widely and iv) few studies (15%) approached research ethically. Overall, the findings show LA research was conducted mainly to measure rather than to support SRL. Thus, there is a critical need to exploit the LA support mechanisms further in order to ultimately use them to foster student SRL in online learning environments.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {524–533},
numpages = {10},
keywords = {learning analytics, literature review, self-regulated learning},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3421590.3421662,
author = {Kesselbacher, Max and Wiltschnig, Kevin and Bollin, Andreas},
title = {Block-based learning analytics repository and dashboard: towards an interface between researcher and educator},
year = {2020},
isbn = {9781450387590},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421590.3421662},
doi = {10.1145/3421590.3421662},
abstract = {The collection of programming session data is a cornerstone of programming learning analytics research. For text-based programming, there are data collection projects, like BlueJ's Blackbox, which provide access to the data and thereby facilitate additional research as well as verification. For block-based programming, only data sets of finished projects but not of programming sessions are available. We introduce a data repository that is extendable by implementing instrumentation plugins for various IDEs. The currently supported features are: data collection of text-based and block-based programming sessions, curated user self-registration and filtered data download. This then enables us to implement an educator dashboard in the future, making use of live programming session data to incorporate educators and students into learning analytics research.},
booktitle = {Proceedings of the 15th Workshop on Primary and Secondary Computing Education},
articleno = {33},
numpages = {2},
keywords = {data repository, learning analytics, programming education},
location = {Virtual Event, Germany},
series = {WiPSCE '20}
}

@inproceedings{10.1145/3170358.3170379,
author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Santos, Olga C. and Santos, Augusto Dias Pereira Dos and Yacef, Kalina},
title = {Physical learning analytics: a multimodal perspective},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170379},
doi = {10.1145/3170358.3170379},
abstract = {The increasing progress in ubiquitous technology makes it easier and cheaper to track students' physical actions unobtrusively, making it possible to consider such data for supporting research, educator interventions, and provision of feedback to students. In this paper, we reflect on the underexplored, yet important area of learning analytics applied to physical/motor learning tasks and to the physicality aspects of `traditional' intellectual tasks that often occur in physical learning spaces. Based on Distributed Cognition theory, the concept of Internet of Things and multimodal learning analytics, this paper introduces a theoretical perspective for bringing learning analytics into physical spaces. We present three prototypes that serve to illustrate the potential of physical analytics for teaching and learning. These studies illustrate advances in proximity, motion and location analytics in collaborative learning, dance education and healthcare training.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {375–379},
numpages = {5},
keywords = {classroom, indoor positioning, internet of things, mobility tracking, motor learning, physical spaces, wearables},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/3303772.3303793,
author = {de Quincey, Ed and Briggs, Chris and Kyriacou, Theocharis and Waller, Richard},
title = {Student Centred Design of a Learning Analytics System},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303793},
doi = {10.1145/3303772.3303793},
abstract = {Current Learning Analytics (LA) systems are primarily designed with University staff members as the target audience; very few are aimed at students, with almost none being developed with direct student involvement and undertaking a comprehensive evaluation. This paper describes a HEFCE funded project that has employed a variety of methods to engage students in the design, development and evaluation of a student facing LA dashboard. LA was integrated into the delivery of 4 undergraduate modules with 169 student sign-ups. The design of the dashboard uses a novel approach of trying to understand the reasons why students want to study at university and maps their engagement and predicted outcomes to these motivations, with weekly personalised notifications and feedback. Students are also given the choice of how to visualise the data either via a chart-based view or to be represented as themselves. A mixed-methods evaluation has shown that students' feelings of dependability and trust of the underlying analytics and data is variable. However, students were mostly positive about the usability and interface design of the system and almost all students once signed-up did interact with their LA. The majority of students could see how the LA system could support their learning and said that it would influence their behaviour. In some cases, this has had a direct impact on their levels of engagement. The main contribution of this paper is the transparent documentation of a User Centred Design approach that has produced forms of LA representation, recommendation and interaction design that go beyond those used in current similar systems and have been shown to motivate students and impact their learning behaviour.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {353–362},
numpages = {10},
keywords = {Laddering, Learning Analytics, Usability, User Centred Design, User Experience, Visualisation},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3448139.3448145,
author = {Ahn, June and Campos, Fabio and Nguyen, Ha and Hays, Maria and Morrison, Jan},
title = {Co-Designing for Privacy, Transparency, and Trust in K-12 Learning Analytics},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448145},
doi = {10.1145/3448139.3448145},
abstract = {The process of using Learning Analytics (LA) to improve teaching works from the assumption that data should be readily shared between stakeholders in an educational organization. However, the design of LA tools often does not account for considerations such as data privacy, transparency and trust among stakeholders. Research in human-centered design of LA does attend to these questions, specifically with a focus on including direct input from K-12 educators. In this paper, we present a series of design studies to articulate and refine conjectures about how privacy and transparency might influence better trust-building and data sharing within four school districts in the United States. By presenting the development of four sequential prototypes, our findings illuminate the tensions between designing for existing norms versus potentially challenging these norms by promoting meaningful discussions around the use of data. We conclude with a discussion about practical and methodological implications of our work to the LA community.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {55–65},
numpages = {11},
keywords = {Co-Design, Dashboards, Ethics, HCI, K-12 Education, Privacy},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3448139.3448203,
author = {Hilliger, Isabel and Miranda, Constanza and Schuit, Gregory and Duarte, Fernando and Anselmo, Martin and Parra, Denis},
title = {Evaluating a Learning Analytics Dashboard to Visualize Student Self-Reports of Time-on-task: A Case Study in a Latin American University},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448203},
doi = {10.1145/3448139.3448203},
abstract = {In recent years, instructional design has become even more challenging for teaching staff members in higher education institutions. If instructional design causes student overload, it could lead to superficial learning and decreased student well-being. A strategy to avoid overload is reflecting upon the effectiveness of teaching practices in terms of time-on-task. This article presents a Work-In-Progress conducted to provide teachers with a dashboard to visualize student self-reports of time-on-task regarding subject activities. A questionnaire was applied to 15 instructors during a set trial period to evaluate the perceived usability and usefulness of the dashboard. Preliminary findings reveal that the dashboard helped instructors became aware about the number of hours spent outside of class time. Furthermore, data visualizations of time-on-task evidence enabled them to redesign subject activities. Currently, the dashboard has been adopted by 106 engineering instructors. Future work involves the development of a framework to incorporate user-based improvements.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {592–598},
numpages = {7},
keywords = {Higher Education, Instructional Design, Learning Analytics Dashboards, Time-on-task},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3027385.3027400,
author = {Tsai, Yi-Shan and Gasevic, Dragan},
title = {Learning analytics in higher education --- challenges and policies: a review of eight learning analytics policies},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027400},
doi = {10.1145/3027385.3027400},
abstract = {This paper presents the results of a review of eight policies for learning analytics of relevance for higher education, and discusses how these policies have tried to address prominent challenges in the adoption of learning analytics, as identified in the literature. The results show that more considerations need to be given to establishing communication channels among stakeholders and adopting pedagogy-based approaches to learning analytics. It also reveals the shortage of guidance for developing data literacy among end-users and evaluating the progress and impact of learning analytics. Moreover, the review highlights the need to establish formalised guidelines to monitor the soundness, effectiveness, and legitimacy of learning analytics. As interest in learning analytics among higher education institutions continues to grow, this review will provide insights into policy and strategic planning for the adoption of learning analytics.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {233–242},
numpages = {10},
keywords = {challenge, code of practice, higher education, learning analytics, policy, strategy},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3511861.3511878,
author = {Ott, Claudia and Liesaputra, Veronica},
title = {Using Affective Learning Analytics in Industry-focused Projects: Experiences and Challenges},
year = {2022},
isbn = {9781450396431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511861.3511878},
doi = {10.1145/3511861.3511878},
abstract = {Project-based learning (PJBL) with real world clients provides students with the skills and knowledge required by industry. Similar to asynchronous online learning environments, PJBL students typically work in self-directed teams at times and places of their choice. Thus, it is difficult for the educators to identify technical and emotional challenges that students experience—especially with large cohorts. To bridge the disconnect between educators and students in such learning situations and to be able to provide students with timely feedback and support, we have experimented with the use of an emotion detection tool to automatically recognise students’ emotional states and the issues that they might face. Our results show that the detected emotions moderately to strongly correlate with students’ issues as observed by the academic coordinators and also with students’ final marks. However, our explorations also highlighted ethical challenges when using emotion-aware learning analytics. This paper describes our experiences and discusses possible ways to address those challenges.},
booktitle = {Proceedings of the 24th Australasian Computing Education Conference},
pages = {153–162},
numpages = {10},
keywords = {emotions, learning analytics, mindsets, project-based learning},
location = {Virtual Event, Australia},
series = {ACE '22}
}

@inproceedings{10.1145/3375462.3375537,
author = {Vezzoli, Yvonne and Mavrikis, Manolis and Vasalou, Asimina},
title = {Inspiration cards workshops with primary teachers in the early co-design stages of learning analytics},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375537},
doi = {10.1145/3375462.3375537},
abstract = {Despite the recognition of the need to include practitioners in the design of learning analytics (LA), especially teacher input tends to come later in the design process rather than in the definition of the initial design agenda. This paper presents a case study of a design project tasked with developing LA tools for a reading game for primary school children. Taking a co-design approach, we use the Inspiration Cards Workshop to promote meaningful teacher involvement even for participants with low background in data literacy or experience in using learning analytics. We discuss opportunities and limitations of using the Inspiration Cards Workshops methodology, and particularly Inspiration Cards as a design tool, to inform future LA design efforts.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {73–82},
numpages = {10},
keywords = {co-design methods, emerging technology, inspiration cards, learning analytics},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3170358.3170413,
author = {Kitto, Kirsty and Buckingham Shum, Simon and Gibson, Andrew},
title = {Embracing imperfection in learning analytics},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170413},
doi = {10.1145/3170358.3170413},
abstract = {Learning Analytics (LA) sits at the confluence of many contributing disciplines, which brings the risk of hidden assumptions inherited from those fields. Here, we consider a hidden assumption derived from computer science, namely, that improving computational accuracy in classification is always a worthy goal. We demonstrate that this assumption is unlikely to hold in some important educational contexts, and argue that embracing computational "imperfection" can improve outcomes for those scenarios. Specifically, we show that learner-facing approaches aimed at "learning how to learn" require more holistic validation strategies. We consider what information must be provided in order to reasonably evaluate algorithmic tools in LA, to facilitate transparency and realistic performance comparisons.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {451–460},
numpages = {10},
keywords = {accuracy, hidden assumptions, pedagogy, performance, validation},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/3170358.3170409,
author = {Bodily, Robert and Kay, Judy and Aleven, Vincent and Jivet, Ioana and Davis, Dan and Xhakaj, Franceska and Verbert, Katrien},
title = {Open learner models and learning analytics dashboards: a systematic review},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170409},
doi = {10.1145/3170358.3170409},
abstract = {This paper aims to link student facing Learning Analytics Dashboards (LADs) to the corpus of research on Open Learner Models (OLMs), as both have similar goals. We conducted a systematic review of literature on OLMs and compared the results with a previously conducted review of LADs for learners in terms of (i) data use and modelling, (ii) key publication venues, (iii) authors and articles, (iv) key themes, and (v) system evaluation. We highlight the similarities and differences between the research on LADs and OLMs. Our key contribution is a bridge between these two areas as a foundation for building upon the strengths of each. We report the following key results from the review: in reports of new OLMs, almost 60% are based on a single type of data; 33% use behavioral metrics; 39% support input from the user; 37% have complex models; and just 6% involve multiple applications. Key associated themes include intelligent tutoring systems, learning analytics, and self-regulated learning. Notably, compared with LADs, OLM research is more likely to be interactive (81% of papers compared with 31% for LADs), report evaluations (76% versus 59%), use assessment data (100% versus 37%), provide a comparison standard for students (52% versus 38%), but less likely to use behavioral metrics, or resource use data (33% against 75% for LADs). In OLM work, there was a heightened focus on learner control and access to their own data.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {41–50},
numpages = {10},
keywords = {learning analytics dashboards, literature review, open learner models, open student models},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/3378184.3378229,
author = {Chicaiza, Janneth and Cabrera-Loayza, Ma. Carmen and Elizalde, Rene and Piedra, Nelson},
title = {Application of data anonymization in Learning Analytics},
year = {2020},
isbn = {9781450376303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3378184.3378229},
doi = {10.1145/3378184.3378229},
abstract = {Thanks to the proliferation of academic services on the Web and the opening of educational content, today, students can access a large number of free learning resources, and interact with value-added services. In this context, Learning Analytics can be carried out on a large scale thanks to the proliferation of open practices that promote the sharing of datasets. However, the opening or sharing of data managed through platforms and educational services, without considering the protection of users' sensitive data, could cause some privacy issues. Data anonymization is a strategy that should be adopted during lifecycle of data processing to reduce security risks. In this research, we try to characterize how much and how the anonymization techniques have been used in learning analytics proposals. From an initial exploration made in the Scopus database, we found that less than 6% of the papers focused on LA have also covered the privacy issue. Finally, through a specific case, we applied data anonymization and learning analytics to demonstrate that both technique can be integrated, in a reliably and effectively way, to support decision making in educational institutions.},
booktitle = {Proceedings of the 3rd International Conference on Applications of Intelligent Systems},
articleno = {33},
numpages = {6},
keywords = {data anonymization, learning analytics, personal data, privacy},
location = {Las Palmas de Gran Canaria, Spain},
series = {APPIS 2020}
}

@inproceedings{10.1145/3286689.3286693,
author = {Gilliot, Jean-Marie and Iksal, S\'{e}bastien and Medou, Daniel Magloire and Dabbebi, In\`{e}s},
title = {Participatory design of learning analytics dashboards},
year = {2018},
isbn = {9781450360784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286689.3286693},
doi = {10.1145/3286689.3286693},
abstract = {While the field of Learning Analytics is in full development, potential users are just discovering the opportunities offered by these tools. One of the major difficulties consists in proposing a visual data representation which makes sense to the users. After refining our method to identify user needs in terms of visualization, and to define the main dimensions of a learning dashboard, we propose a tool to support participatory design. This tool is based on a canvas and cards to help dashboards' creation using Learning Analytics. It allows users to support creativity around decision making, characterize their context, and draw a dashboard's mockup using existing content.},
booktitle = {Proceedings of the 30th Conference on l'Interaction Homme-Machine},
pages = {119–127},
numpages = {9},
keywords = {canvas, dashboard, learning analytics, participatory design},
location = {Brest, France},
series = {IHM '18}
}

@inproceedings{10.1145/3491140.3528271,
author = {Li, Xiaotian Vivian and Rosson, Mary Beth and Robert, Jenay},
title = {A Scenario-based Exploration of Expected Usefulness, Privacy Concerns, and Adoption Likelihood of Learning Analytics},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528271},
doi = {10.1145/3491140.3528271},
abstract = {Learning analytics has become a robust research area in the last decade, as innovative analytic models of learning data have been created with the goal of enhancing teaching and learning. However, barriers to large scale adoption of such technologies in higher education still exist. In recent years, a strand of research has begun to investigate stakeholders' expectations of learning analytics, hoping to find ways to integrate the innovations into everyday teaching practices. For instance, studies have investigated instructors' ideas about how learning analytics might be helpful, as well as concerns about student data privacy. However, most studies have taken a general approach rather than considering instructors' day-to-day experiences. Using survey methods, we presented instructors with hypothetical scenarios of learning analytics in use across disciplines, class sizes, teaching activities, and types of student data. We asked for ratings of both usefulness and privacy concerns for each proposed teaching situation. Our respondents considered scenarios involving learning outcomes-related data (e.g. grades) to be more useful than those that involve student interactions (e.g. language, social activity). In contrast, privacy concerns were lower for outcomes-oriented scenarios than interactions-focused scenarios. An interesting new finding was a negative correlation of usefulness and privacy; we discuss this in the context of instructors' possible cost-benefit reasoning. We reflect on our findings with respect to future efforts in developing and fielding learning analytics tools.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {48–59},
numpages = {12},
keywords = {adoption, design, higher education, instructors, learning analytics, privacy, scenarios, survey},
location = {New York City, NY, USA},
series = {L@S '22}
}

@inproceedings{10.1145/2883851.2883881,
author = {Kitto, Kirsty and Bakharia, Aneesha and Lupton, Mandy and Mallet, Dann and Banks, John and Bruza, Peter and Pardo, Abelardo and Buckingham Shum, Simon and Dawson, Shane and Ga\v{s}evi\'{c}, Dragan and Siemens, George and Lynch, Grace},
title = {The connected learning analytics toolkit},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883881},
doi = {10.1145/2883851.2883881},
abstract = {This demonstration introduces the Connected Learning Analytics (CLA) Toolkit. The CLA toolkit harvests data about student participation in specified learning activities across standard social media environments, and presents information about the nature and quality of the learning interactions.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {548–549},
numpages = {2},
keywords = {dashboards, sensemaking, social learning analytics},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3491140.3528292,
author = {Shabaninejad, Shiva and Khosravi, Hassan and Abdi, Solmaz and Indulska, Marta and Sadiq, Shazia},
title = {Incorporating Explainable Learning Analytics to Assist Educators with Identifying Students in Need of Attention},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528292},
doi = {10.1145/3491140.3528292},
abstract = {Increased enrolments in higher education, and the shift to online learning that has been escalated by the recent COVID pandemic, have made it challenging for instructors to assist their students with their learning needs. Contributing to the growing literature on instructor-facing systems, this paper reports on the development of a learning analytics (LA) technique called Student Inspection Facilitator (SIF) that provides an explainable interpretation of students learning behaviour to support instructors with the identification of students in need of attention. Unlike many previous predictive systems that automatically label students, our approach provides explainable recommendations to guide data exploration while still reserving judgement about interpreting student learning to instructors. The insights derived from applying SIF in an introductory Information Systems course with 407 enrolled students suggest that SIF can be utilised independent of the context and can provide a meaningful interpretation of students' learning behaviour towards facilitating proactive support of students.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {384–388},
numpages = {5},
keywords = {at-risk students, explainable learning analytics, learning analytics dashboards},
location = {New York City, NY, USA},
series = {L@S '22}
}

@inproceedings{10.1145/3706468.3706508,
author = {Herodotou, Christothea and Carr, Jessica and Shrestha, Sagun and Comfort, Catherine and Bayer, Vaclav and Maguire, Claire and Lee, John and Mulholland, Paul and Fernandez, Miriam},
title = {Prescriptive analytics motivating distance learning students to take remedial action: A case study of a student-facing dashboard},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706508},
doi = {10.1145/3706468.3706508},
abstract = {Student-facing learning analytics dashboards aim to help students to monitor their study progress, achieve learning goals and develop self-regulation skills. Only few of them present personalised data visualisations and aim to develop agentic students who take remedial action to improve their study habits, learning and performance. In this paper, a student-facing dashboard, designed following principles of participatory research, was tested with 30 undergraduate students, who engaged with it over a period of 4 to 15 weeks and while studying an online course. This is one of the few dashboards available that presents all different types of analytics to students: descriptive, predictive and prescriptive. A mixed methods approach was used to assess its usefulness and impact on motivation to study and take remedial action to support learning. Data analysis showcased that such a dashboard can be “a roadmap to success” by motivating students to study more and improve their performance, in addition to helping with monitoring, planning and reflection. While all dashboard features were perceived as being useful, special value was placed on prescriptive elements, in particular material recommendations and contacting tutors and university support teams, emphasizing the significance of making explicit on a dashboard the actions students should take to improve their performance. Implications for future studies are discussed.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {306–316},
numpages = {11},
keywords = {learning analytics dashboards, student-facing dashboards, prescriptive analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3027385.3029472,
author = {Olivares, Daniel M. and Hundhausen, Christopher D.},
title = {Supporting learning analytics in computing education},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029472},
doi = {10.1145/3027385.3029472},
abstract = {As is the case for many undergraduate STEM degree programs, computing degree programs are plagued by high attrition rates. This is especially true in early computing courses, in which failure and drop-out rates in the 35 to 50 percent range are common. By collecting learning process data as students engage in computer programming assignments, computing educators can place themselves in a position not only to better understand students' struggles, but also to better tailor instructional interventions to students' needs. We have developed OSBLE+, a learning management and analytics environment that interfaces with a computer programming environment to support the automatic collection of learners' programming process and social data as they work on programming assignments, while also providing an interactive environment for the analysis and visualization of those data. In ongoing work, we are using OSBLE+ to explore two possibilities: (a) leveraging learning and social data to strategically deliver automated learning interventions, and (b) presenting learners with visual representations of their learning data in order to prompt them to reflect on and discuss their learning processes.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {584–585},
numpages = {2},
keywords = {OSBLE, computing education research, data collection, learning analytics, learning management system, social learning, visualizations},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3027385.3027406,
author = {Prinsloo, Paul and Slade, Sharon},
title = {An elephant in the learning analytics room: the obligation to act},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027406},
doi = {10.1145/3027385.3027406},
abstract = {As higher education increasingly moves to online and digital learning spaces, we have access not only to greater volumes of student data, but also to increasingly fine-grained and nuanced data. A significant body of research and existing practice are used to convince key stakeholders within higher education of the potential of the collection, analysis and use of student data to positively impact on student experiences in these environments. Much of the recent focus in learning analytics is around predictive modeling and uses of artificial intelligence to both identify learners at risk, and to personalize interventions to increase the chance of success.In this paper we explore the moral and legal basis for the obligation to act on our analyses of student data. The obligation to act entails not only the protection of student privacy and the ethical collection, analysis and use of student data, but also, the effective allocation of resources to ensure appropriate and effective interventions to increase effective teaching and learning.The obligation to act is, however tempered by a number of factors, including inter and intra-departmental operational fragmentation and the constraints imposed by changing funding regimes. Increasingly higher education institutions allocate resources in areas that promise the greatest return. Choosing (not) to respond to the needs of specific student populations then raises questions regarding the scope and nature of the moral and legal obligation to act. There is also evidence that students who are at risk of failing often do not respond to institutional interventions to assist them.In this paper we build and expand on recent research by, for example, the LACE and EP4LA workshops to conceptually map the obligation to act which flows from both higher education's mandate to ensure effective and appropriate teaching and learning and its fiduciary duty to provide an ethical and enabling environment for students to achieve success. We examine how the collection and analysis of student data links to both the availability of resources and the will to act and also to the obligation to act. Further, we examine how that obligation unfolds in two open distance education providers from the perspective of a key set of stakeholders - those in immediate contact with students and their learning journeys - the tutors or adjunct faculty.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {46–55},
numpages = {10},
keywords = {learning analytics, obligation to act ethics},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3303772.3303804,
author = {Lim, Lisa and Dawson, Shane and Joksimovic, Srecko and Ga\v{s}evi\'{c}, Dragan},
title = {Exploring students' sensemaking of learning analytics dashboards: Does frame of reference make a difference?},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303804},
doi = {10.1145/3303772.3303804},
abstract = {Learning Analytics Dashboards (LAD) are becoming an increasingly popular way to provide students with personalised feedback. Despite the number of LADs being developed, significant research gaps exist around the student perspective, especially how students make sense of graphics provided in LADs, and how they intend to act on the feedback provided therein. This study employed a randomized-controlled trial to examine students' sense-making of LADs showing four different frames of reference, and to what extent the impact of LADs was mediated by baseline self-regulation. Using a mix of quantitative and qualitative data analysis, the results revealed rather distinct patterns in students' sense-making across the four LADs. These patterns involved the intersection of visual salience and planned learning actions. However, collectively, across all four LADs a consistent theme emerged around students planned learning actions. This theme was classified as time and study environment management. A key finding of the study is that the use of LADs as a primary feedback process should be personalized and include training and support to aid student sensemaking.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {250–259},
numpages = {10},
keywords = {Learning dashboards, epistemic network analysis, sensemaking, social comparison},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3382507.3421151,
author = {Ciordas-Hertel, George-Petru},
title = {How to Complement Learning Analytics with Smartwatches? Fusing Physical Activities, Environmental Context, and Learning Activities},
year = {2020},
isbn = {9781450375818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382507.3421151},
doi = {10.1145/3382507.3421151},
abstract = {To obtain a holistic perspective on learning, a multimodal technical infrastructure for Learning Analytics (LA) can be beneficial. Recent studies have investigated various aspects of technical LA infrastructure. However, it has not yet been explored how LA indicators can be complemented with Smartwatch sensor data to detect physical activity and the environmental context. Sensor data, such as the accelerometer, are often used in related work to infer a specific behavior and environmental context, thus triggering interventions on a just-in-time basis. In this dissertation project, we plan to use Smartwatch sensor data to explore further indicators for learning from blended learning sessions conducted in-the-wild, e.g., at home. Such indicators could be used within learning sessions to suggest breaks, or afterward to support learners in reflection processes.We plan to investigate the following three research questions: (RQ1) How can multimodal learning analytics infrastructure be designed to support real-time data acquisition and processing effectively?; (RQ2) how to use smartwatch sensor data to infer environmental context and physical activities to complement learning analytics indicators for blended learning sessions; and (RQ3) how can we align the extracted multimodal indicators with pedagogical interventions.RQ1 was investigated by a structured literature review and by conducting eleven semi-structured interviews with LA infrastructure developers. According to RQ2, we are currently designing and implementing a multimodal learning analytics infrastructure to collect and process sensor and experience data from Smartwatches. Finally, according to RQ3, an exploratory field study will be conducted to extract multimodal learning indicators and examine them with learners and pedagogical experts to develop effective interventions.Researchers, educators, and learners can use and adapt our contributions to gain new insights into learners' time and learning tactics, and physical learning spaces from learning sessions taking place in-the-wild.},
booktitle = {Proceedings of the 2020 International Conference on Multimodal Interaction},
pages = {708–712},
numpages = {5},
keywords = {environmental context, hand activities, infrastructure, mobile sensing, multimodal learning analytics, smartwatch},
location = {Virtual Event, Netherlands},
series = {ICMI '20}
}

@inproceedings{10.1145/2723576.2723627,
author = {Kitto, Kirsty and Cross, Sebastian and Waters, Zak and Lupton, Mandy},
title = {Learning analytics beyond the LMS: the connected learning analytics toolkit},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723627},
doi = {10.1145/2723576.2723627},
abstract = {We present a Connected Learning Analytics (CLA) toolkit, which enables data to be extracted from social media and imported into a Learning Record Store (LRS), as defined by the new xAPI standard. A number of implementation issues are discussed, and a mapping that will enable the consistent storage and then analysis of xAPI verb/object/activity statements across different social media and online environments is introduced. A set of example learning activities are proposed, each facilitated by the Learning Analytics beyond the LMS that the toolkit enables.},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {11–15},
numpages = {5},
keywords = {connected learning, data ownership, integration, xAPI},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1145/3027385.3027407,
author = {Fu, Xinyu and Shimada, Atsushi and Ogata, Hiroaki and Taniguchi, Yuta and Suehiro, Daiki},
title = {Real-time learning analytics for C programming language courses},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027407},
doi = {10.1145/3027385.3027407},
abstract = {Many universities choose the C programming language (C) as the first one they teach their students, early on in their program. However, students often consider programming courses difficult, and these courses often have among the highest dropout rates of computer science courses offered. It is therefore critical to provide more effective instruction to help students understand the syntax of C and prevent them losing interest in programming. In addition, homework and paper-based exams are still the main assessment methods in the majority of classrooms. It is difficult for teachers to grasp students' learning situation due to the large amount of evaluation work. To facilitate teaching and learning of C, in this article we propose a system---LAPLE (Learning Analytics in Programming Language Education)---that provides a learning dashboard to capture the behavior of students in the classroom and identify the different difficulties faced by different students looking at different knowledge. With LAPLE, teachers may better grasp students' learning situation in real time and better improve educational materials using analysis results. For their part, novice undergraduate programmers may use LAPLE to locate syntax errors in C and get recommendations from educational materials on how to fix them.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {280–288},
numpages = {9},
keywords = {C programming, information visualization, learning analytics, learning dashboard, programming education},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3491140.3528324,
author = {Tulha, Carinna Nunes and Carvalho, Marco Antonio G. and de Castro, Leandro N.},
title = {LEDA: A Learning Analytics Based Framework to Analyze Remote Labs Interaction},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528324},
doi = {10.1145/3491140.3528324},
abstract = {In order to support the application of digital technologies in the educational context, it is important to understand the relationships between learners and the technologies they use during a practice. Among educational technologies are remote laboratories, tools that provide the manipulation of real experiments through an online platform, available 24/7, overcoming constraints of time and space. To extract information of the large amount of data generated during interactions, it is necessary to use technology-supported representations, in order to apply techniques capable of analyzing and extracting information from the data generated from interactions with technologies and, finally, enabling learning interventions. Learning Analytics (LA) consist of on measuring, collecting, analyzing and reporting student data during practices. LA combines data mining techniques to extract information and pedagogical intervention. This project proposes to develop an educational data mining framework based on Learning Analytics interventions, called LEDA (Laboratory Experimentation Data Analysis). The LEDA framework aims to extract information of interaction data with remote laboratories to relate students' interaction behavior with their learning progress. Our approach will apply association rules and clustering techniques using learning data, including clicks, number of controlled components, and time spent during the activity.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {379–383},
numpages = {5},
keywords = {association rules, clustering, data mining, educational datasets},
location = {New York City, NY, USA},
series = {L@S '22}
}

@inproceedings{10.1145/3436756.3437032,
author = {Islam, Shareeful and Mahmud, Hasan},
title = {An Intelligence Learner Management System using Learning Analytics and Machine learning},
year = {2021},
isbn = {9781450388276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3436756.3437032},
doi = {10.1145/3436756.3437032},
abstract = {Learner Management System (LMS) facilitates educational institutions to offer e-learning through web-based applications. LMS provides many benefits from cost saving to flexible learning opportunities independent of any location with cloud-based deployment. Hence, LMS organizes learning data and learners detail in a central repository, helps to improve resource allocation, and facilitates access to the learning resources. These benefits drive the LMS market growth at a rapid rate and it is now deployed across the industry of any size. Despite of these significant benefits of using LMS, the traditional LMS system cannot fully support with modern learning needs in terms of learners' progression, retention rate, prediction of assessment outcomes to improve overall teaching and learning experience. Learning analytics can effectively support for a better learning experience by analyzing and correlating learner data to predicate the future needs. This work as a part of the Knowledge Transfer Project (KTP) develops an intelligence Learner Management System(iLMS) that integrates learning analytics into the learner management system. We use Machine Learning(ML) techniques for descriptive, predictive, and prescriptive analytics of learners’ data. This paper presents the key iLMS features including user interfaces, reports and learning analytics.},
booktitle = {Proceedings of the 12th International Conference on Education Technology and Computers},
pages = {120–125},
numpages = {6},
keywords = {Decision Tree, Learning Analytics, Learning Management System, Machine Learning, Predictive Analytics},
location = {London, United Kingdom},
series = {ICETC '20}
}

@inproceedings{10.1145/2883851.2883874,
author = {van Leeuwen, Anouschka},
title = {Learning analytics in a flipped university course},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883874},
doi = {10.1145/2883851.2883874},
abstract = {In this poster, we describe the design of a university course with a blended learning character. Learning analytics were used both within the course to facilitate effective teacher-student interaction, as well as after the course to examine patterns between students' activities during the course and their performance on the test and the group assignment at the end of the course.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {514–515},
numpages = {2},
keywords = {blended learning, formative assessment, higher education, learning analytics, web lectures},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3027385.3027403,
author = {Bodily, Robert and Verbert, Katrien},
title = {Trends and issues in student-facing learning analytics reporting systems research},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027403},
doi = {10.1145/3027385.3027403},
abstract = {We conducted a literature review on systems that track learning analytics data (e.g., resource use, time spent, assessment data, etc.) and provide a report back to students in the form of visualizations, feedback, or recommendations. This review included a rigorous article search process; 945 articles were identified in the initial search. After filtering out articles that did not meet the inclusion criteria, 94 articles were included in the final analysis. Articles were coded on five categories chosen based on previous work done in this area: functionality, data sources, design analysis, perceived effects, and actual effects. The purpose of this review is to identify trends in the current student-facing learning analytics reporting system literature and provide recommendations for learning analytics researchers and practitioners for future work.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {309–318},
numpages = {10},
keywords = {educational recommender systems, learning analytics, learning analytics dashboards, literature review, student-facing systems},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3573051.3596165,
author = {Ochoa, Xavier and Echeverria, Vanessa and Carrillo, Gladys and Heredia, Vanessa and Chiluiza, Katherine},
title = {Supporting Online Collaborative Work at Scale: A Mixed-Methods Study of a Learning Analytics Tool},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3596165},
doi = {10.1145/3573051.3596165},
abstract = {Collaborative Learning Analytics (CLA) tools have recently emerged as a potential solution to address the onerous process of monitoring and providing timely feedback on collaboration skills in higher education students. However, prior studies on the efficacy of such tools have mainly been carried out in small, controlled settings. This study aims to measure the impact of a specific CLA tool that can be easily deployed on a larger scale with minimal instructor effort in real-world online group work activities. Additionally, this research examines the potential influence that the characteristics of the collaborative activity may have on the tool's effectiveness. The CLA tool under investigation displays speaking participation time and peer evaluation scores from students engaged in online collaborative activities as part of their regular courses. The tool was evaluated with five instructors and 156 students over the course of one semester. The effects of the tool on students' speaking participation and peer evaluation scores were quantitatively measured and tested. A qualitative analysis of reflections from both students and instructors provided supplementary information on the quantitative results. The main finding of this study indicates that the tool has an overall small positive impact. The effectiveness of the CLA tool is primarily modulated by the synchronous or asynchronous presence of the instructor, as students tend to interact more naturally and feel less scrutinized in the absence of instructor evaluation. Based on the discussion of the findings, this research suggests design insights to enhance future CLA tools at scale for the purpose of supporting the development of online collaboration skills.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {237–247},
numpages = {11},
keywords = {collaboration skills, online collaboration, participation time},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3231644.3231704,
author = {Gruzd, Anatoliy and Conroy, Nadia},
title = {Designing a learning analytics dashboard for twitter-facilitated teaching},
year = {2018},
isbn = {9781450358866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231644.3231704},
doi = {10.1145/3231644.3231704},
abstract = {Social media sites are increasingly being adopted to support teaching practice in higher education. Learning Analytics (LA) dashboards can be used to reveal how students engage with course material and others in the class. However, research on the best practices of designing, developing, and evaluating such dashboards to support teaching and learning with social media has been limited. Considering the increasing use of Twitter for both formal and informal learning processes, this paper presents our design process and a LA prototype dashboard developed based on a comprehensive literature review and an online survey among 54 higher education instructors who have used Twitter in their teaching.},
booktitle = {Proceedings of the Fifth Annual ACM Conference on Learning at Scale},
articleno = {46},
numpages = {4},
keywords = {dashboards, learning analytics, survey, teaching},
location = {London, United Kingdom},
series = {L@S '18}
}

@inproceedings{10.1145/3430895.3460160,
author = {Williamson, Kimberly and Kizilcec, Ren\'{e} F.},
title = {Learning Analytics Dashboard Research Has Neglected Diversity, Equity and Inclusion},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460160},
doi = {10.1145/3430895.3460160},
abstract = {Learning analytic dashboards (LADs) have become more prevalent in higher education to help students, faculty, and staff make data-informed decisions. Despite extensive research on the design and usability of LADs, few studies have examined them in relation to issues of diversity, equity, and inclusion. We conducted a critical literature review to address three research questions: How does LAD research contribute to improving diversity, equity, and inclusion? How might LADs contribute to maintaining or exacerbating inequitable outcomes? And what future opportunities exist in this research space? Our review showed little use of LADs to address or improve issues of diversity, equity, and inclusion in the literature thus far. We argue that excluding these issues from LAD research is not an isolated oversight and it risks reinforcing existing inequities within the higher education system. We argue that LADs can be designed, researched, and deployed intentionally to advance equitable outcomes and help dismantle inequities in education. We highlight opportunities for future LAD research to address issues of diversity, equity, and inclusion.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {287–290},
numpages = {4},
keywords = {diversity, equity, inclusion, learning analytic dashboards, literature review},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1145/2883851.2883921,
author = {Muslim, Arham and Chatti, Mohamed Amine and Mahapatra, Tanmaya and Schroeder, Ulrik},
title = {A rule-based indicator definition tool for personalized learning analytics},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883921},
doi = {10.1145/2883851.2883921},
abstract = {In the last few years, there has been a growing interest in learning analytics (LA) in technology-enhanced learning (TEL). Generally, LA deals with the development of methods that harness educational data sets to support the learning process. Recently, the concept of open learning analytics (OLA) has received a great deal of attention from LA community, due to the growing demand for self-organized, networked, and lifelong learning opportunities. A key challenge in OLA is to follow a personalized and goal-oriented LA model that tailors the LA task to the needs and goals of multiple stakeholders. Current implementations of LA rely on a predefined set of questions and indicators. There is, however, a need to adopt a personalized LA approach that engages end users in the indicator definition process by supporting them in setting goals, posing questions, and self-defining the indicators that help them achieve their goals. In this paper, we address the challenge of personalized LA and present the conceptual, design, and implementation details of a rule-based indicator definition tool to support flexible definition and dynamic generation of indicators to meet the needs of different stakeholders with diverse goals and questions in the LA exercise.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {264–273},
numpages = {10},
keywords = {indicator, learning analytics, open learning analytics, personalized learning analytics},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/2883851.2883944,
author = {Bakharia, Aneesha and Corrin, Linda and de Barba, Paula and Kennedy, Gregor and Ga\v{s}evi\'{c}, Dragan and Mulder, Raoul and Williams, David and Dawson, Shane and Lockyer, Lori},
title = {A conceptual framework linking learning design with learning analytics},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883944},
doi = {10.1145/2883851.2883944},
abstract = {In this paper we present a learning analytics conceptual framework that supports enquiry-based evaluation of learning designs. The dimensions of the proposed framework emerged from a review of existing analytics tools, the analysis of interviews with teachers, and user scenarios to understand what types of analytics would be useful in evaluating a learning activity in relation to pedagogical intent. The proposed framework incorporates various types of analytics, with the teacher playing a key role in bringing context to the analysis and making decisions on the feedback provided to students as well as the scaffolding and adaptation of the learning design. The framework consists of five dimensions: temporal analytics, tool-specific analytics, cohort dynamics, comparative analytics and contingency. Specific metrics and visualisations are defined for each dimension of the conceptual framework. Finally the development of a tool that partially implements the conceptual framework is discussed.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {329–338},
numpages = {10},
keywords = {intervention design, learning analytics, learning design},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@article{10.1145/3105759,
author = {Hundhausen, C. D. and Olivares, D. M. and Carter, A. S.},
title = {IDE-Based Learning Analytics for Computing Education: A Process Model, Critical Review, and Research Agenda},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
url = {https://doi.org/10.1145/3105759},
doi = {10.1145/3105759},
abstract = {In recent years, learning process data have become increasingly easy to collect through computer-based learning environments. This has led to increased interest in the field of learning analytics, which is concerned with leveraging learning process data in order to better understand, and ultimately to improve, teaching and learning. In computing education, the logical place to collect learning process data is through integrated development environments (IDEs), where computing students typically spend large amounts of time working on programming assignments. While the primary purpose of IDEs is to support computer programming, they might also be used as a mechanism for delivering learning interventions designed to enhance student learning. The possibility of using IDEs both to collect learning process data, and to strategically intervene in the learning process, suggests an exciting design space for computing education research: that of IDE-based learning analytics. In order to facilitate the systematic exploration of this design space, we present an IDE-based data analytics process model with four primary activities: (1) Collect data, (2) Analyze data, (3) Design intervention, and (4) Deliver intervention. For each activity, we identify key design dimensions and review relevant computing education literature. To provide guidance on designing effective interventions, we describe four relevant learning theories, and consider their implications for design. Based on our review, we present a call-to-action for future research into IDE-based learning analytics.},
journal = {ACM Trans. Comput. Educ.},
month = aug,
articleno = {11},
numpages = {26},
keywords = {Learning analytics, learning interventions, learning process data}
}

@inproceedings{10.1145/2883851.2883873,
author = {Martinez-Maldonado, Roberto and Schneider, Bertrand and Charleer, Sven and Buckingham Shum, Simon and Klerkx, Joris and Duval, Erik},
title = {Interactive surfaces and learning analytics: data, orchestration aspects, pedagogical uses and challenges},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883873},
doi = {10.1145/2883851.2883873},
abstract = {The proliferation of varied types of multi-user interactive surfaces (such as digital whiteboards, tabletops and tangible interfaces) is opening a new range of applications in face-to-face (f2f) contexts. They offer unique opportunities for Learning Analytics (LA) by facilitating multi-user sensemaking of automatically captured digital footprints of students' f2f interactions. This paper presents an analysis of current research exploring learning analytics associated with the use of surface devices. We use a framework to analyse our first-hand experiences, and the small number of related deployments according to four dimensions: the orchestration aspects involved; the phases of the pedagogical practice that are supported; the target actors; and the levels of iteration of the LA process. The contribution of the paper is twofold: 1) a synthesis of conclusions that identify the degree of maturity, challenges and pedagogical opportunities of the existing applications of learning analytics and interactive surfaces; and 2) an analysis framework that can be used to characterise the design space of similar areas and LA applications.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {124–133},
numpages = {10},
keywords = {awareness, dashboard, design, face-to-face, groupware, studies in the wild, visualizations},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3144826.3145397,
author = {Mart\'{\i}nez-Mon\'{e}s, Alejandra and Reffay, Christophe and Tor\'{\i}o, Javier Hoyos and Crist\'{o}bal, Juan A. Mu\~{n}oz},
title = {Learning Analytics with Google Classroom: Exploring the possibilities},
year = {2017},
isbn = {9781450353861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3144826.3145397},
doi = {10.1145/3144826.3145397},
abstract = {Google Classroom (GC) is gaining momentum in the educational milieu, but its functionalities are limited. Learning analytics applications integrated with GC can help to face these limitations, but to reach this aim, developers need access to the data generated by GC's users. This paper reports on the results of an analysis of the existing alternatives to collect data from GC. The study is based on the analysis of the documentation provided by the involved tools. The analysis shows that GC's API is a potential source of data about the activity of the users in GC-enabled settings, but that the information it provides is limited. Further work is needed to explore if Chrome OS synchronization functions can deliver more detailed information about GC usage, thus enabling for more advanced learning analytics applications.},
booktitle = {Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality},
articleno = {47},
numpages = {6},
keywords = {Google Classroom, Learning Analytics, Teachers' adoption},
location = {C\'{a}diz, Spain},
series = {TEEM 2017}
}

@inproceedings{10.1145/3290605.3300824,
author = {Sun, Kaiwen and Mhaidli, Abraham H. and Watel, Sonakshi and Brooks, Christopher A. and Schaub, Florian},
title = {It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300824},
doi = {10.1145/3290605.3300824},
abstract = {Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {early warning dashboards, ethics, higher education, learning analytics, privacy, student data},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3375462.3375476,
author = {Alvarez, Carlos Prieto and Martinez-Maldonado, Roberto and Buckingham Shum, Simon},
title = {LA-DECK: a card-based learning analytics co-design tool},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375476},
doi = {10.1145/3375462.3375476},
abstract = {Human-centred software design gives all stakeholders an active voice in the design of the systems that they are expected to use. However, this is not yet commonplace in Learning Analytics (LA). Co-design techniques from other domains therefore have much to offer to LA, in principle, but there are few detailed accounts of exactly how such sessions unfold. This paper presents the rationale driving a card-based co-design tool specifically tuned for LA, called LA-DECK. In the context of a pilot study with students, educators, LA researchers and developers, we provide qualitative and quantitative accounts of how participants used the cards. Using three different forms of analysis (transcript-centric design vignettes, card-graphs and time-on-topic), we characterise in what ways the sessions were "participatory" in nature, and argue that the cards succeeded in playing very similar roles to those documented in the literature on successful card-based design tools.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {63–72},
numpages = {10},
keywords = {cards, co-design, learning analytics, participatory design},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/2567574.2567613,
author = {Swenson, Jenni},
title = {Establishing an ethical literacy for learning analytics},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567613},
doi = {10.1145/2567574.2567613},
abstract = {This paper borrows multiple frameworks from the field of technical communication in order to review theory, research, practice, and ethics of the Learning Analytics and Knowledge (LAK) discipline. These frameworks also guide discussion on the ethics of learning analytics "artifacts" (data visualizations, dashboards, and methodology), and the ethical consequences of using learning analytics (classification, social power moves, and absence of voice). Finally, the author suggests a literacy for learning analytics that includes an ethical viewpoint.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {246–250},
numpages = {5},
keywords = {ethics, higher education, learning analytics, literacy},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/2883851.2883892,
author = {Molenaar, Inge and van Campen, Carolien Knoop},
title = {Learning analytics in practice: the effects of adaptive educational technology Snappet on students' arithmetic skills},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883892},
doi = {10.1145/2883851.2883892},
abstract = {Even though the recent influx of tablets in primary education goes together with the vision that educational technology empowered with learning analytics will revolutionize education, empirical results supporting this claim are scares. Adaptive educational technology Snappet combines extracted and embedded learning analytics daily in classrooms. While students make exercises on the tablet this technology displays real-time data of learner performance in a teacher dashboard (extracted analytics). At the same time, learner performance is used to adaptively adjust exercises to students' progress (embedded analytics). This quasiexperimental study compares the development of students' arithmetic skills over one schoolyear (grade 2 and 4) in a traditional paper based setting to learning with the adaptive educational technology Snappet. The results indicate that students in the Snappet condition make significantly more progress on arithmetic skills in grade 4. Moreover, in this grade students with a high ability level, benefit the most from working with this adaptive educational technology. Overall the development pattern of students with different abilities was more divergent in the AET condition compared to the control condition. These results indicate that adaptive educational technologies combining extracted and embedded learning analytics are indeed creating new education scenarios that contribute to personalized learning in primary education.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {538–539},
numpages = {2},
keywords = {ability levels, arithmetic's, educational technologies, primary education},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3027385.3027397,
author = {Herodotou, Christothea and Rienties, Bart and Boroowa, Avinash and Zdrahal, Zdenek and Hlosta, Martin and Naydenova, Galina},
title = {Implementing predictive learning analytics on a large scale: the teacher's perspective},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027397},
doi = {10.1145/3027385.3027397},
abstract = {In this paper, we describe a large-scale study about the use of predictive learning analytics data with 240 teachers in 10 modules at a distance learning higher education institution. The aim of the study was to illuminate teachers' uses and practices of predictive data, in particular identify how predictive data was used to support students at risk of not completing or failing a module. Data were collected from statistical analysis of 17,033 students' performance by the end of the intervention, teacher usage statistics, and five individual semi-structured interviews with teachers. Findings revealed that teachers endorse the use of predictive data to support their practice yet in diverse ways and raised the need for devising appropriate intervention strategies to support students at risk.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {267–271},
numpages = {5},
keywords = {higher education, perceptions, predictive analytics, retention, teachers},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3027385.3027414,
author = {Hoel, Tore and Griffiths, Dai and Chen, Weiqin},
title = {The influence of data protection and privacy frameworks on the design of learning analytics systems},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027414},
doi = {10.1145/3027385.3027414},
abstract = {Learning analytics open up a complex landscape of privacy and policy issues, which, in turn, influence how learning analytics systems and practices are designed. Research and development is governed by regulations for data storage and management, and by research ethics. Consequently, when moving solutions out the research labs implementers meet constraints defined in national laws and justified in privacy frameworks. This paper explores how the OECD, APEC and EU privacy frameworks seek to regulate data privacy, with significant implications for the discourse of learning, and ultimately, an impact on the design of tools, architectures and practices that now are on the drawing board. A detailed list of requirements for learning analytics systems is developed, based on the new legal requirements defined in the European General Data Protection Regulation, which from 2018 will be enforced as European law. The paper also gives an initial account of how the privacy discourse in Europe, Japan, South-Korea and China is developing and reflects upon the possible impact of the different privacy frameworks on the design of LA privacy solutions in these countries. This research contributes to knowledge of how concerns about privacy and data protection related to educational data can drive a discourse on new approaches to privacy engineering based on the principles of Privacy by Design. For the LAK community, this study represents the first attempt to conceptualise the issues of privacy and learning analytics in a cross-cultural context. The paper concludes with a plan to follow up this research on privacy policies and learning analytics systems development with a new international study.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {243–252},
numpages = {10},
keywords = {data protection, data protection by default, data protection by design, learning analytics, learning analytics process requirements, learning analytics systems design, personal information, privacy by design, privacy frameworks},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3355402.3355407,
author = {Rueangprathum, Atchara and Witosurapot, Suntorn},
title = {Design of Modular Learning Analytics Framework for Early Childhood Education: A Case Study},
year = {2019},
isbn = {9781450372282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3355402.3355407},
doi = {10.1145/3355402.3355407},
abstract = {On the provision of early childhood education, education-oriented software for enabling parent and teacher collaboration becomes popular. However, by providing merely on the asynchronous communication support, this sort of software overlooks a feature allowing parents (or teachers) to trace their child's physical development or learning progress. In this paper, it is argued that the missing feature is indeed necessary, and should be realized through the use of learning analytics technology. In this regard, a service-oriented design framework for rapid application development is suggested by a means of web mashup of open source software. Based on the minimum viable product, it is clearly the graph visualization of learning analytics can potentially empower parents on their early childhood education so that actions can be taken in time accordingly if necessary.},
booktitle = {Proceedings of the 2019 International Conference on Information Technology and Computer Communications},
pages = {24–28},
numpages = {5},
keywords = {Early Childhood Education, Headless CMS, Learning Analytics, Service-Oriented Architectures},
location = {Singapore, Singapore},
series = {ITCC '19}
}

@inproceedings{10.1145/2330601.2330616,
author = {Ferguson, Rebecca and Buckingham Shum, Simon},
title = {Social learning analytics: five approaches},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330616},
doi = {10.1145/2330601.2330616},
abstract = {This paper proposes that Social Learning Analytics (SLA) can be usefully thought of as a subset of learning analytics approaches. SLA focuses on how learners build knowledge together in their cultural and social settings. In the context of online social learning, it takes into account both formal and informal educational environments, including networks and communities. The paper introduces the broad rationale for SLA by reviewing some of the key drivers that make social learning so important today. Five forms of SLA are identified, including those which are inherently social, and others which have social dimensions. The paper goes on to describe early work towards implementing these analytics on SocialLearn, an online learning space in use at the UK's Open University, and the challenges that this is raising. This work takes an iterative approach to analytics, encouraging learners to respond to and help to shape not only the analytics but also their associated recommendations.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {23–33},
numpages = {11},
keywords = {21st century skills, SocialLearn, discourse analytics, educational assessment, learning analytics, learning how to learn, social learning, social learning analytics, transferable skills},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/3386527.3406732,
author = {Haynes, Carl C.},
title = {The Role of Self-Regulated Learning in the Design, Implementation, and Evaluation of Learning Analytics Dashboards},
year = {2020},
isbn = {9781450379519},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386527.3406732},
doi = {10.1145/3386527.3406732},
abstract = {Learning technologies are generating a vast quantity of data every day. This data is often presented to students through learning analytics dashboards (LADs) with a goal of improving learners' self-regulated learning. However, are students actually using these dashboards, and do they perceive that using dashboards lead to any changes in their behavior? In this paper we report on the development and implementation of several dashboard views, which we call My Learning Analytics (MyLA). This study found that students thought using the dashboard would have more of an effect on the way they planned their course activity at pre-use (after a demo) than post use. Low self-regulated learners believed so significantly less post-use and used the grade distribution view the least. Students made several suggestions for ways to improve the grade distribution view and rated MyLA's usability more positively at pre- than post-use. Given the low use and low perceived impact of the current dashboard, we suggest that researchers use participatory design to illicit students' needs and better incorporate student suggestions.},
booktitle = {Proceedings of the Seventh ACM Conference on Learning @ Scale},
pages = {297–300},
numpages = {4},
keywords = {dashboards, learning analytics, self-regulated learning},
location = {Virtual Event, USA},
series = {L@S '20}
}

@inproceedings{10.1145/2567574.2567610,
author = {Gibson, Andrew and Kitto, Kirsty and Willis, Jill},
title = {A cognitive processing framework for learning analytics},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567610},
doi = {10.1145/2567574.2567610},
abstract = {Incorporating a learner's level of cognitive processing into Learning Analytics presents opportunities for obtaining rich data on the learning process. We propose a framework called COPA that provides a basis for mapping levels of cognitive operation into a learning analytics system. We utilise Bloom's taxonomy, a theoretically respected conceptualisation of cognitive processing, and apply it in a flexible structure that can be implemented incrementally and with varying degree of complexity within an educational organisation. We outline how the framework is applied, and its key benefits and limitations. Finally, we apply COPA to a University undergraduate unit, and demonstrate its utility in identifying key missing elements in the structure of the course.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {212–216},
numpages = {5},
keywords = {Bloom's revised taxonomy, cognitive processing, curriculum design, learning analytics},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/2460296.2460340,
author = {Dyckhoff, A. L. and Lukarov, V. and Muslim, A. and Chatti, M. A. and Schroeder, U.},
title = {Supporting action research with learning analytics},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460340},
doi = {10.1145/2460296.2460340},
abstract = {Learning analytics tools should be useful, i.e., they should be usable and provide the functionality for reaching the goals attributed to learning analytics. This paper seeks to unite learning analytics and action research. Based on this, we investigate how the multitude of questions that arise during technology-enhanced teaching and learning systematically can be mapped to sets of indicators. We examine, which questions are not yet supported and propose concepts of indicators that have a high potential of positively influencing teachers' didactical considerations. Our investigation shows that many questions of teachers cannot be answered with currently available research tools. Furthermore, few learning analytics studies report about measuring impact. We describe which effects learning analytics should have on teaching and discuss how this could be evaluated.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {220–229},
numpages = {10},
keywords = {action research, impact analysis, indicators, learning analytics},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/2460296.2460298,
author = {Suthers, Dan and Verbert, Katrien},
title = {Learning analytics as a "middle space"},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460298},
doi = {10.1145/2460296.2460298},
abstract = {Learning Analytics, an emerging field concerned with analyzing the vast data "given off" by learners in technology supported settings to inform educational theory and practice, has from its inception taken a multidisciplinary approach that integrates studies of learning with technological capabilities. In this introduction to the Proceedings of the Third International Learning Analytics &amp; Knowledge Conference, we discuss how Learning Analytics must function in the "middle space" where learning and analytic concerns meet. Dialogue in this middle space involves diverse stakeholders from multiple disciplines with various conceptions of the agency and nature of learning. We hold that a singularly unified field is not possible nor even desirable if we are to leverage the potential of this diversity, but progress is possible if we support "productive multivocality" between the diverse voices involved, facilitated by appropriate use of boundary objects. We summarize the submitted papers and contents of these Proceedings to characterize the voices and topics involved in the multivocal discourse of Learning Analytics.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {1–4},
numpages = {4},
keywords = {boundary objects, learning analytics, multidisciplinarity, productive multivocality},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/3375462.3375540,
author = {Wiley, Korah J. and Dimitriadis, Yannis and Bradford, Allison and Linn, Marica C.},
title = {From theory to action: developing and evaluating learning analytics for learning design},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375540},
doi = {10.1145/3375462.3375540},
abstract = {The effectiveness of using learning analytics for learning design primarily depends upon two concepts: grounding and alignment. This is the primary conjecture for the study described in this paper. In our design-based research study, we design, test, and evaluate teacher-facing learning analytics for an online inquiry science unit on global climate change. We design our learning analytics in accordance with a socioconstructivism-based pedagogical framework, called Knowledge Integration, and the principles of learning analytics Implementation Design. Our methodology for the design process draws upon the principle of the Orchestrating for Learning Analytics framework to engage stakeholders (i.e. teachers, researchers, and developers). The resulting learning analytics were aligned to unit activities that engaged students in key aspects of the knowledge integration process. They provided teachers with actionable insight into their students' understanding at critical junctures in the learning process. We demonstrate the efficacy of the learning analytics in supporting the optimization of the unit's learning design. We conclude by synthesizing the principles that guided our design process into a framework for developing and evaluating learning analytics for learning design.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {569–578},
numpages = {10},
keywords = {TEL environment, design-based research, learning analytics, learning design, theory},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/2567574.2567588,
author = {Wise, Alyssa Friend},
title = {Designing pedagogical interventions to support student use of learning analytics},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567588},
doi = {10.1145/2567574.2567588},
abstract = {This article addresses a relatively unexplored area in the emerging field of learning analytics, the design of learning analytics interventions. A learning analytics intervention is defined as the surrounding frame of activity through which analytic tools, data, and reports are taken up and used. It is a soft technology that involves the orchestration of the human process of engaging with the analytics as part of the larger teaching and learning activity. This paper first makes the case for the overall importance of intervention design, situating it within the larger landscape of the learning analytics field, and then considers the specific issues of intervention design for student use of learning analytics. Four principles of pedagogical learning analytics intervention design that can be used by teachers and course developers to support the productive use of learning analytics by students are introduced: Integration, Agency, Reference Frame and Dialogue. In addition three core processes in which to engage students are described: Grounding, Goal-Setting and Reflection. These principles and processes are united in a preliminary model of pedagogical learning analytics intervention design for students, presented as a starting point for further inquiry.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {203–211},
numpages = {9},
keywords = {intervention design, learning analytics, student participation},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/3284179.3284233,
author = {Villama\~{n}e, Mikel and \'{A}lvarez, Ainhoa and Larra\~{n}aga, Mikel and Caballero, Jessica and Hern\'{a}ndez-Rivas, Oscar},
title = {Using Visual Learning Analytics to Support Competence-based Learning},
year = {2018},
isbn = {9781450365185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284179.3284233},
doi = {10.1145/3284179.3284233},
abstract = {Competence-based Learning has become more and more popular in the last few years and some researchers have claimed that formative assessment should be followed to improve the learning processes. In order to achieve the mastery of competencies, many lecturers have been required to adopt various and diverse applications in their courses to work on those competences. The use of several applications brings new challenges, as the information of the learning processes is distributed among these systems and getting a global picture of the evolution becomes much harder. Therefore, systems that enable gathering and unifying formative assessment information coming from various sources in order to extract significant information about the global learning process are needed. In this paper, we present a system called COBLE (Competence-Based Learning Environment) that supports Competence-based Learning and combines Visual Learning Analytics and recommendation aspects in order to promote the students' and lecturers' self-reflection about the learning and teaching processes. COBLE supports data from different sources to be integrated, providing the users with the complete report of what is going on in their courses.},
booktitle = {Proceedings of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {333–338},
numpages = {6},
keywords = {Competency-based Learning, Feedback, Visual learning analytics},
location = {Salamanca, Spain},
series = {TEEM'18}
}

@inproceedings{10.1145/2330601.2330636,
author = {Clow, Doug},
title = {The learning analytics cycle: closing the loop effectively},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330636},
doi = {10.1145/2330601.2330636},
abstract = {This paper develops Campbell and Oblinger's [4] five-step model of learning analytics (Capture, Report, Predict, Act, Refine) and other theorisations of the field, and draws on broader educational theory (including Kolb and Sch\"{o}n) to articulate an incrementally more developed, explicit and theoretically-grounded Learning Analytics Cycle.This cycle conceptualises successful learning analytics work as four linked steps: learners (1) generating data (2) that is used to produce metrics, analytics or visualisations (3). The key step is 'closing the loop' by feeding back this product to learners through one or more interventions (4).This paper seeks to begin to place learning analytics practice on a base of established learning theory, and draws several implications from this theory for the improvement of learning analytics projects. These include speeding up or shortening the cycle so feedback happens more quickly, and widening the audience for feedback (in particular, considering learners and teachers as audiences for analytics) so that it can have a larger impact.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {134–138},
numpages = {5},
keywords = {academic analytics, analytics, feedback, learning analytics, policy},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/3085585.3085586,
author = {Hui, Bowen and Farvolden, Shannon},
title = {How Can Learning Analytics Improve a Course?},
year = {2017},
isbn = {9781450350662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3085585.3085586},
doi = {10.1145/3085585.3085586},
abstract = {Despite much excitement with learning analytics, there is still a lack of adoption in the classrooms. Possible reasons may include not having enough time to incorporate the use of analytics, not being familiar enough with specific techniques to readily apply them, or not knowing how data can help shape a curriculum or the classroom experience altogether. Learning analytics is a problem-driven research field, where the domain problem -- the people involved, the subject matter, and the learning environment -- drives the techniques and the solutions that are used. From this perspective, we propose a new framework with a suite of pedagogical questions that can be addressed using data to support decisions made about the curriculum or classroom structure. In addition, we present a case study with 69 participants in a CS1 course as a way to demonstrate how some of these questions are addressed. Our ultimate goal is to improve the quality of the students' learning experience using an evidence-based approach.},
booktitle = {Proceedings of the 22nd Western Canadian Conference on Computing Education},
articleno = {1},
numpages = {6},
keywords = {CS1, evidence-based course design, learning analytics, needs analysis},
location = {Abbotsford, BC, Canada},
series = {WCCCE '17}
}

@inproceedings{10.1145/3706468.3706520,
author = {Albuquerque, Josmario and Rienties, Bart and Divjak, Bla\v{z}enka},
title = {Decoding Learning Design Decisions: A Cluster Analysis of 12,749 Teaching and Learning Activities},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706520},
doi = {10.1145/3706468.3706520},
abstract = {Substantial progress has been made in how educators can be supported to implement effective learning design (LD) with learning analytics (LA). However, how educators make micro-decisions about designing individual teaching and learning activities (TLAs) and how these are related to wider pedagogical approaches has received limited empirical support. This study explored how 165 educators designed and integrated 12,749 TLA in 218 LDs using clustering, pattern-mining, and correlational analysis. The findings suggest most educators use a combination of four common LD TLAs (i.e., Collaboration, Generating independent learning, Assessment, and Traditional classroom activities). The four common TLAs could be used to develop LA and Generative Artificial Intelligence (Gen-AI) approaches to support educators in making more informed and evidence-based design decisions for effective learning and teaching.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {407–417},
numpages = {11},
keywords = {Learning Design, Learning Analytics, Cluster Analysis, Teaching and Learning Activities, Artificial Intelligence},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706468.3706475,
author = {Alfredo, Riordan and Mejia-Domenzain, Paola and Echeverria, Vanessa and Rahayu, Dwi and Zhao, Linxuan and Alajlan, Haya and Swiecki, Zachari and K\"{a}ser, Tanja and Ga\v{s}evi\'{c}, Dragan and Martinez-Maldonado, Roberto},
title = {TeamTeachingViz: Benefits, Challenges, and Ethical Considerations of Using a Multimodal Analytics Dashboard to Support Team Teaching Reflection},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706475},
doi = {10.1145/3706468.3706475},
abstract = {Team teaching in higher education can be challenging, especially for educators managing large classes with limited pedagogical training and few opportunities to reflect on their practices. Emerging sensing technologies and analytics can capture and analyse patterns of collaboration, communication, and movement of team teaching. Yet, few studies have presented these data to educators for reflection. To address this gap, we examine the benefits, challenges, and concerns of presenting multimodal teaching data (positional, audio, and spatial pedagogy observations) to educators via the TeamTeachingViz dashboard. We evaluated TeamTeachingViz in an authentic classroom context where educators explored their own data and team teaching strategies. Multimodal data was collected from 36 in-the-wild classroom sessions involving 12 educators grouped in various combinations over 4 weeks, followed by semi-structured interviews to reflect on their practices. Findings suggest that educators improved their self-awareness by using data-driven insights to understand their movements and interactions, enabling continuous improvement in team teaching. However, they noted the need for additional data, such as student behaviours and speech content, to better contextualise these insights.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {58–69},
numpages = {12},
keywords = {teaching analytics, LA dashboard, multimodal learning analytics, co-teaching, teaching reflection, spatial pedagogy, in-the-wild},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3369255.3369288,
author = {Cahyani, Andharini D. and Marshall, Lindsay and Forshaw, Matthew},
title = {Students' Perception on Data Sources from Outside Virtual Learning Environment for Learning Analytics},
year = {2020},
isbn = {9781450372541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369255.3369288},
doi = {10.1145/3369255.3369288},
abstract = {Every time a student interacts during their learning, they leave behind a digital footprint. The process of using this data to improve learning and teaching is called as Learning Analytics. Researches in this field grow and are more popular, specifically that usage of data outside the Virtual Learning Environment. Although often proposed data in previous research use students' personal data, their perception of the usage of those data is still underexplored. This study investigates higher education students' understanding of how useful the proposed data might be helpful as their input. Our study reveals that each degree-level student response differently regarding the usefulness each data sources. Therefore, we need to consider students' perception when we design personal learning analytics for students, so the app can fit to their preference and needs.},
booktitle = {Proceedings of the 11th International Conference on Education Technology and Computers},
pages = {165–170},
numpages = {6},
keywords = {Learning Analytics data sources, students' perception, usefulness},
location = {Amsterdam, Netherlands},
series = {ICETC '19}
}

@inproceedings{10.1145/3206157.3206177,
author = {Yanhui, Wu},
title = {Language E-learning based on Learning Analytics in Big Data Era},
year = {2018},
isbn = {9781450363587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3206157.3206177},
doi = {10.1145/3206157.3206177},
abstract = {Language E-learning, an online language learning mode, completely transforms the traditional learning and teaching mode. However, with the coming of Big Data era, it not only enjoys some benefits, but also is confronted with great challenges. The article first concludes the reforms Big Data brought to the world, and then introduces the definition, key elements, the applying model, main analyzing methods and tools of learning analytics. Finally, the article fully shows the implementation of learning analytics to the study of language E-learning. Through the study of learning analytics, the designer of Language E-learning can learn the learners' learning behaviors and provide the efficient learning material, tools and systems.},
booktitle = {Proceedings of the 2018 International Conference on Big Data and Education},
pages = {106–111},
numpages = {6},
keywords = {Big Data, language E-learning, learning analytics},
location = {Honolulu, HI, USA},
series = {ICBDE '18}
}

@inproceedings{10.1145/2883851.2883965,
author = {Tan, Jennifer Pei-Ling and Yang, Simon and Koh, Elizabeth and Jonathan, Christin},
title = {Fostering 21st century literacies through a collaborative critical reading and learning analytics environment: user-perceived benefits and problematics},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883965},
doi = {10.1145/2883851.2883965},
abstract = {The affordances of learning analytics (LA) are being increasingly harnessed to enhance 21st century (21C) pedagogy and learning. Relatively rare, however, are use cases and empirically based understandings of students' actual experiences with LA tools and environments at fostering 21C literacies, especially in secondary schooling and Asian education contexts. This paper addresses this knowledge gap by 1) presenting a first iteration design of a computer-supported collaborative critical reading and LA environment and its 16-week implementation in a Singapore high school; and 2) foregrounding students' quantitative and qualitative accounts of the benefits and problematics associated with this learning innovation. We focus the analytic lens on the LA dashboard components that provided visualizations of students' reading achievement, 21C learning dispositions, critical literacy competencies and social learning network positioning within the class. The paper aims to provide insights into the potentialities, paradoxes and pathways forward for designing LA that take into consideration the voices of learners as critical stakeholders.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {430–434},
numpages = {5},
keywords = {21st century skills, CSCL, critical literacy, learning analytics},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3506860.3506885,
author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Cukurova, Mutlu and Bartindale, Tom and Chen, Peter and Marshall, Harrison and Richardson, Dan and Gasevic, Dragan},
title = {The Question-driven Dashboard: How Can We Design Analytics Interfaces Aligned to Teachers’ Inquiry?},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506885},
doi = {10.1145/3506860.3506885},
abstract = {One of the ultimate goals of several learning analytics (LA) initiatives is to close the loop and support students’ and teachers’ reflective practices. Although there has been a proliferation of end-user interfaces (often in the form of dashboards), various limitations have already been identified in the literature such as key stakeholders not being involved in their design, little or no account for sense-making needs, and unclear effects on teaching and learning. There has been a recent call for human-centred design practices to create LA interfaces in close collaboration with educational stakeholders to consider the learning design, and their authentic needs and pedagogical intentions. This paper addresses the call by proposing a question-driven LA design approach to ensure that end-user LA interfaces explicitly address teachers’ questions. We illustrate the approach in the context of synchronous online activities, orchestrated by pairs of teachers using audio-visual and text-based tools (namely Zoom and Google Docs). This study led to the design and deployment of an open-source monitoring tool to be used in real-time by teachers when students work collaboratively in breakout rooms, and across learning spaces.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {175–185},
numpages = {11},
keywords = {CSCL, dashboard, human-centred design, inquiry-driven practice, learning analytics, online learning},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3636555.3636872,
author = {Li, Zaibei and Jensen, Martin Thoft and Nolte, Alexander and Spikol, Daniel},
title = {Field report for Platform mBox: Designing an Open MMLA Platform},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636872},
doi = {10.1145/3636555.3636872},
abstract = {Multimodal Learning Analytics (MMLA) is an evolving sector within learning analytics that has become increasingly useful for examining complex learning and collaboration dynamics for group work across all educational levels. The availability of low-cost sensors and affordable computational power allows researchers to investigate different modes of group work. However, the field faces challenges stemming from the complexity and specialization of the systems required for capturing diverse interaction modalities, with commercial systems often being expensive or narrow in scope and researcher-developed systems needing to be more specialized and difficult to deploy. Therefore, more user-friendly, adaptable, affordable, open-source, and easy-to-deploy systems are needed to advance research and application in the MMLA field. The paper presents a field report on the design of mBox that aims to support group work across different contexts. We share the progress of mBox, a low-cost, easy-to-use platform grounded on learning theories to investigate collaborative learning settings. Our approach has been guided by iterative design processes that let us rapidly prototype different solutions for these settings.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {785–791},
numpages = {7},
keywords = {Multimodal Learning Analytics, Prototyping, Sociometric Wearable Devices},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3170358.3170421,
author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
title = {License to evaluate: preparing learning analytics dashboards for educational practice},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170421},
doi = {10.1145/3170358.3170421},
abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {31–40},
numpages = {10},
keywords = {competition, evaluation, learning analytics, learning dashboards, learning science, learning theory, social comparison, systematic review},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/2787622.2787746,
author = {Olivares, Daniel},
title = {Exploring Learning Analytics for Computing Education},
year = {2015},
isbn = {9781450336307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2787622.2787746},
doi = {10.1145/2787622.2787746},
abstract = {Student retention in STEM disciplines is a growing problem. The number of students receiving undergraduate STEM degrees will need to increase by about 34% annually in order to meet projected needs [6]. One way to address this problem is by leveraging the emerging field of learning analytics, a data-driven approach to designing learning interventions based on continuously-updated data on learning processes and outcomes. Through an iterative, user-centered, design approach, we propose to develop a learning dashboard tailored for computing courses. The dashboard will collect, analyze, and present learning process and outcome data to instructors and students, thus providing an empirical basis for automated, teacher-initiated, and learner-initiated interventions to positively influence learning outcomes and retention. Through a series of mixed-method empirical studies, we will determine what data should be made available to instructors, how that data can be best displayed, how effective teaching interventions can be fashioned from the data, and how such interventions affect student grades and persistence in introductory computing science courses.},
booktitle = {Proceedings of the Eleventh Annual International Conference on International Computing Education Research},
pages = {271–272},
numpages = {2},
keywords = {computing education, learning analytics, learning dashboard, social learning theory, social programming},
location = {Omaha, Nebraska, USA},
series = {ICER '15}
}

@inproceedings{10.1145/3576050.3576063,
author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Echeverria, Vanessa and Srivastava, Namrata and Gasevic, Dragan},
title = {How Do Teachers Use Dashboards Enhanced with Data Storytelling Elements According to their Data Visualisation Literacy Skills?},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576063},
doi = {10.1145/3576050.3576063},
abstract = {There is a proliferation of learning analytics (LA) dashboards aimed at supporting teachers. Yet, teachers still find it challenging to make sense of LA dashboards, thereby making informed decisions. Two main strategies to address this are emerging: i) upskilling teachers’ data literacy; ii) improving the explanatory design features of current dashboards (e.g., adding visual cues or text) to minimise the skills required by teachers to effectively use dashboards. While each approach has its own trade-offs, no previous work has explored the interplay between the dashboard design and such "data skills". In this paper, we explore how teachers with varying visualisation literacy (VL) skills use LA dashboards enhanced with (explanatory) data storytelling elements. We conducted a quasi-experimental study with 23 teachers of varied VL inspecting two versions of an authentic multichannel dashboard enhanced with data storytelling elements. We used an eye-tracking device while teachers inspected the students’ data captured from Zoom and Google Docs, followed by interviews. Results suggest that high VL teachers adopted complex exploratory strategies and were more sensitive to subtle inconsistencies in the design; while low VL teachers benefited the most from more explicit data storytelling guidance such as accompanying complex graphs with narrative and semantic colour encoding.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {89–99},
numpages = {11},
keywords = {dashboard, data literacy, data storytelling, human-centred design, learning analytics},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/2460296.2460308,
author = {Wise, Alyssa Friend and Zhao, Yuting and Hausknecht, Simone Nicole},
title = {Learning analytics for online discussions: a pedagogical model for intervention with embedded and extracted analytics},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460308},
doi = {10.1145/2460296.2460308},
abstract = {This paper describes an application of learning analytics that builds on an existing research program investigating how students contribute and attend to the messages of others in online discussions. A pedagogical model that translates the concepts and findings of the research program into guidelines for practice and analytics with which students and instructors can assess their discussion participation are presented. The analytics are both embedded in the learning environment and extracted from it, allowing for integrated and reflective metacognitive activity. The pedagogical intervention is based on the principles of (1) Integration (2) Diversity (of Metrics) (3) Agency (4) Reflection (5) Parity and (6) Dialogue. Details of an initial implementation of this approach and preliminary findings are described. Initial results strongly support the value of student-teacher dialogue around the analytics. In contrast, instructor parity in analytics use did not seem as important to students as was expected. Analytics were reported as useful in validating invisible discussion activity, but at times triggered emotionally-charged responses.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {48–56},
numpages = {9},
keywords = {asynchronous discussion groups, computer mediated communication, learning analytics, online learning, student participation},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/3636555.3636857,
author = {Echeverria, Vanessa and Yan, Lixiang and Zhao, Linxuan and Abel, Sophie and Alfredo, Riordan and Dix, Samantha and Jaggard, Hollie and Wotherspoon, Rosie and Osborne, Abra and Buckingham Shum, Simon and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {TeamSlides: a Multimodal Teamwork Analytics Dashboard for Teacher-guided Reflection in a Physical Learning Space},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636857},
doi = {10.1145/3636555.3636857},
abstract = {Advancements in Multimodal Learning Analytics (MMLA) have the potential to enhance the development of effective teamwork skills and foster reflection on collaboration dynamics in physical learning environments. Yet, only a few MMLA studies have closed the learning analytics loop by making MMLA solutions immediately accessible to educators to support reflective practices, especially in authentic settings. Moreover, deploying MMLA solutions in authentic settings can bring new challenges beyond logistic and privacy issues. This paper reports the design and use of TeamSlides, a multimodal teamwork analytics dashboard to support teacher-guided reflection. We conducted an in-the-wild classroom study involving 11 teachers and 138 students. Multimodal data were collected from students working in team healthcare simulations. We examined how teachers used the dashboard in 22 debrief sessions to aid their reflective practices. We also interviewed teachers to discuss their perceptions of the dashboard’s value and the challenges faced during its use. Our results suggest that the dashboard effectively reinforced discussions and augmented teacher-guided reflection practices. However, teachers encountered interpretation conflicts, sometimes leading to mistrust or misrepresenting the information. We discuss the considerations needed to overcome these challenges in MMLA research.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {112–122},
numpages = {11},
keywords = {MMLA, dashboards, reflection, team dynamics, teamwork analytics, visualisation},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/2656719.2656729,
author = {Shoukry, Laila and G\"{o}bel, Stefan and Steinmetz, Ralf},
title = {Learning Analytics and Serious Games: Trends and Considerations},
year = {2014},
isbn = {9781450331210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2656719.2656729},
doi = {10.1145/2656719.2656729},
abstract = {This paper reviews the current status of Learning Analytics with special focus on their application in Serious Games. After presenting the advantages of incorporating Learning Analytics into game-based learning applications, different aspects regarding the integration process including modeling, tracing, aggregation, visualisation, analysis and employment of gameplay data are discussed. Associated challenges in this field as well as examples of best practices are also examined.},
booktitle = {Proceedings of the 2014 ACM International Workshop on Serious Games},
pages = {21–26},
numpages = {6},
keywords = {game-based learning, learning analytics, serious games},
location = {Orlando, Florida, USA},
series = {SeriousGames '14}
}

@inproceedings{10.1145/3636555.3636877,
author = {Chejara, Pankaj and Kasepalu, Reet and Prieto, Luis and Rodr\'{\i}guez-Triana, Mar\'{\i}a Jes\'{u}s and Ruiz-Calleja, Adolfo},
title = {Bringing Collaborative Analytics using Multimodal Data to Masses: Evaluation and Design Guidelines for Developing a MMLA System for Research and Teaching Practices in CSCL},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636877},
doi = {10.1145/3636555.3636877},
abstract = {The Multimodal Learning Analytics (MMLA) research community has significantly grown in the past few years. Researchers in this field have harnessed diverse data collection devices such as eye-trackers, motion sensors, and microphones to capture rich multimodal data about learning. This data, when analyzed, has been proven highly valuable for understanding learning processes across a variety of educational settings. Notwithstanding this progress, an ubiquitous use of MMLA in education is still limited by challenges such as technological complexity, high costs, etc. In this paper, we introduce CoTrack, a MMLA system for capturing the multimodality of a group’s interaction in terms of audio, video, and writing logs in online and co-located collaborative learning settings. The system offers a user-friendly interface, designed to cater to the needs of teachers and students without specialized technical expertise. Our usability evaluation with 2 researchers, 2 teachers and 24 students has yielded promising results regarding the system’s ease of use. Furthermore, this paper offers design guidelines for the development of more user-friendly MMLA systems. These guidelines have significant implications for the broader aim of making MMLA tools accessible to a wider audience, particularly for non-expert MMLA users.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {800–806},
numpages = {7},
keywords = {CSCL, MMLA, Multimodal Learning Analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706468.3706571,
author = {Deininger, Hannah and Parrisius, Cora and Lavelle-Hill, Rosa and Meurers, Detmar and Trautwein, Ulrich and Nagengast, Benjamin and Kasneci, Gjergji},
title = {Who Did What to Succeed? Individual Differences in Which Learning Behaviors Are Linked to Achievement},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706571},
doi = {10.1145/3706468.3706571},
abstract = {It is commonly assumed that digital learning environments such as intelligent tutoring systems facilitate learning and positively impact achievement. This study explores how different groups of students exhibit distinct relationships between learning behaviors and academic achievement in an intelligent tutoring system for English as a foreign language. We examined whether these differences are linked to students’ prior knowledge, personality traits, and motivation. We collected behavioral trace data from 507 German seventh-grade students during the 2021/22 school year and applied machine learning models to predict English performance based on learning behaviors (best-performing model’s R2 =.41). To understand the impact of specific behaviors, we applied the explainable AI method SHAP and identified three student clusters with distinct learning behavior patterns. Subsequent analyses revealed that these clusters also varied in prior knowledge and motivation: one with high prior knowledge and average motivation, another with low prior knowledge and average motivation, and a third with both low prior knowledge and low motivation. Our findings suggest that learning behaviors are linked differently to academic success across students and are closely tied to their prior knowledge and motivation. This hints towards the importance of personalizing learning systems to support individual learning needs better.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {771–782},
numpages = {12},
keywords = {Learning Analytics, Behavioral Trace Data, Academic Performance, Interindividual Differences},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3313831.3376148,
author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Fernandez Nieto, Gloria and Buckingham Shum, Simon},
title = {From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376148},
doi = {10.1145/3313831.3376148},
abstract = {Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is na\"{\i}ve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {CSCW, data storytelling, teamwork, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3027385.3029478,
author = {Jeremic, Zoran and Kumar, Vive and Graf, Sabine},
title = {MORPH: supporting the integration of learning analytics at institutional level},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029478},
doi = {10.1145/3027385.3029478},
abstract = {While there is high potential in using learning analytics to provide educational institutions as well as teachers and learners with actionable information and improve learning experiences, currently only very few learning analytics tools are actually used in educational institutions. In this paper, we introduce MORPH, a platform that facilitates the integration of learning analytics modules and tools into institutional learning systems. MORPH provides a robust distributed architecture which combines batch, stream and real-time data processing using a parallel processing model to enable and support efficient processing of large amounts of data. Furthermore, it provides common management and administration features that enable the seamless integration of learning analytics research modules and tools into existing institutional learning systems.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {596–597},
numpages = {2},
keywords = {batch processing, dashboards, data streaming, institutional learning environments, learning analytics, real-time processing},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/2090116.2090146,
author = {Bader-Natal, Ari and Lotze, Thomas},
title = {Evolving a learning analytics platform},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090146},
doi = {10.1145/2090116.2090146},
abstract = {Web-based learning systems offer researchers the ability to collect and analyze fine-grained educational data on the performance and activity of students, as a basis for better understanding and supporting learning among those students. The availability of this data enables stakeholders to pose a variety of interesting questions, often specifically focused on some subset of students. As a system matures, the number of stakeholders, the number of interesting questions, and the number of relevant sub-populations of students also grow, adding complexity to the data analysis task. In this work, we describe an internal analytics system designed and developed to address this challenge, adding flexibility and scalability. Here we present several examples of typical examples of analysis, discuss a few uncommon but powerful use-cases, and share lessons learned from the first two years of iteratively developing the platform.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {180–185},
numpages = {6},
keywords = {collaborative learning, learning analytics platform, web-based learning},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2460296.2460343,
author = {Lonn, Steven and Aguilar, Stephen and Teasley, Stephanie D.},
title = {Issues, challenges, and lessons learned when scaling up a learning analytics intervention},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460343},
doi = {10.1145/2460296.2460343},
abstract = {This paper describes an intra-institutional partnership between a research team and a technology service group that was established to facilitate the scaling up of a learning analytics intervention. Our discussion focuses on the benefits and challenges that arose from this partnership in order to provide useful information for similar partnerships developed to support scaling up learning analytics interventions.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {235–239},
numpages = {5},
keywords = {design-research, higher education, learning analytics, scale},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/2729094.2742613,
author = {Tarmazdi, Hamid and Vivian, Rebecca and Szabo, Claudia and Falkner, Katrina and Falkner, Nickolas},
title = {Using Learning Analytics to Visualise Computer Science Teamwork},
year = {2015},
isbn = {9781450334402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2729094.2742613},
doi = {10.1145/2729094.2742613},
abstract = {Industry has called upon academia to better prepare Computer Science graduates for teamwork, especially in developing the soft skills necessary for collaborative work. However, the teaching and assessment of teamwork is not easy, with instructors being pressed for time and a lack of tools available to efficiently analyse student teamwork, where large cohorts are involved. We have developed a teamwork dashboard, founded on learning analytics, learning theory and teamwork models that analyses students' online teamwork discussion data and visualises the team mood, role distribution and emotional climate. This tool allows educators to easily monitor teams in real-time. Educators may use the tool to provide students with feedback about team interactions as well as to identify problematic teams. We present a case study, trialing the dashboard on one university Computer Science course and include reflections from the course lecturer to determine its utility in monitoring online student teamwork.},
booktitle = {Proceedings of the 2015 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {165–170},
numpages = {6},
keywords = {collaboration, computer science education, learning analytics},
location = {Vilnius, Lithuania},
series = {ITiCSE '15}
}

@inproceedings{10.1145/3576050.3576107,
author = {Aghaei, Kimia and Hatala, Marek and Mogharrab, Alireza},
title = {How Students’ Emotion and Motivation Changes After Viewing Dashboards with Varied Social Comparison Group: A Qualitative Study},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576107},
doi = {10.1145/3576050.3576107},
abstract = {The need to personalize learning analytics dashboards (LADs) is getting more recognized in learning analytics research community. In order to study the impact of these dashboards on learners, various types of prototypes have been designed and deployed in different settings. Applying Weiner’s attribution theory, our goal in this study was to understand the effect of dashboard information content on learners. We wanted to understand how elements of assignment grade, time spent on an assignment, assignment view, and proficiency in the dashboard affect students’ attribution of achievement and motivation for future work. We designed a qualitative study in which we analyzed participants’ responses and indicated behavioural changes after viewing the dashboard. Through in-depth interviews, we aimed to understand students’ interpretations of the designed dashboard, and to what extent social comparison impacts their judgments of learning. Students used multiple dimensions to attribute their success or failure to their ability and effort. Our results indicate that to maximize the benefits of dashboards as a vehicle for motivating change in students learning, the dashboard should promote effort in both personal and social comparison capacities.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {663–669},
numpages = {7},
keywords = {attribution theory, learning analytics dashboard, motivation, qualitative analysis, social comparison},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3268808.3268827,
author = {Nguyen, Viet Anh and Nguyen, Quang Bach and Nguyen, Vuong Thinh},
title = {A Model to Forecast Learning Outcomes for Students in Blended Learning Courses Based On Learning Analytics},
year = {2018},
isbn = {9781450365284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3268808.3268827},
doi = {10.1145/3268808.3268827},
abstract = {One of the difficulties experienced by online learners is the lack of regular supervision as well as the need to provide instructions to support the learning process more effectively. The analysis of the learning data in the online courses is not only becoming increasingly important in forecasting learning outcomes but also providing effective instructional strategies for learners to help them get the best results. In this paper, we propose a forecast learning outcomes model based on learners' interaction with online learning systems by providing learning analytics dashboard for both learners and teachers to monitor and orient online learners. This approach is mainly based on some machine learning and data mining techniques. This research aims to answer two research questions: (1) Is it possible to accurately predict learners' learning outcomes based on their interactive activities? (2) How to monitor and guide learners in an effective online learning environment? To answer these two questions, our model has been developed and tested by learners participating in the Moodle LMS system. The results show that 75% of students have outcomes close to the predicted results with an accuracy of over 50%. These positive results, though done on a small scale, can also be considered as suggestions for studies of using learning analytics in predicting learning outcomes of learners through learning activities.},
booktitle = {Proceedings of the 2nd International Conference on E-Society, E-Education and E-Technology},
pages = {35–41},
numpages = {7},
keywords = {Learning analytics, forecast model, learning activities, learning outcomes, predictive modeling},
location = {Taipei, Taiwan},
series = {ICSET 2018}
}

@inproceedings{10.1145/3448139.3448172,
author = {Li, Qiujie and Jung, Yeonji and Friend Wise, Alyssa},
title = {Beyond First Encounters with Analytics: Questions, Techniques and Challenges in Instructors’ Sensemaking},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448172},
doi = {10.1145/3448139.3448172},
abstract = {Despite growing implementation of teacher-facing analytics in higher education, relatively little is known about the detailed processes through which instructors make sense of analytics in their teaching practices beyond their initial encounters with tools. This study unpacked the sensemaking process of thirteen instructors with analytic experience, using interviews that included walkthroughs of their analytics use. Qualitative inductive analysis was used to identify themes related to (1) the questions they asked of the analytics, (2) the techniques they used to interpret them, and (3) the challenges they encountered. Findings indicated that instructors went beyond a general curiosity to develop three types of questions of the analytics (goal-oriented, problem-oriented, and instruction modification questions). Instructors also used specific techniques to read and explain data by (a) developing expectations about the answers the analytics would provide, and (b) making comparisons to reveal student diversity, identify effects of instructional revision and diagnose issues. The study found instructors faced an initial learning curve when seeking and making use of relevant information, but also continued to revisit these challenges when they were not able to develop a routine of analytics use. These findings both contribute to a conceptual understanding of instructor analytic sensemaking and have practical implications for its systematic support.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {344–353},
numpages = {10},
keywords = {Analytic sensemaking, Data-informed instruction, Human-centered analytics, Instructional dashboards},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3027063.3053256,
author = {Dazo, Suzanne L. and Stepanek, Nicholas R. and Chauhan, Aarjav and Dorn, Brian},
title = {Examining Instructor Use of Learning Analytics},
year = {2017},
isbn = {9781450346566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027063.3053256},
doi = {10.1145/3027063.3053256},
abstract = {This study takes an instructor-centric approach to Learning Analytic (LA) research by analyzing instructor use of the LA within an educational streaming video platform called TrACE. The goal of this study is to understand how instructors naturally interact with analytic dashboards through an empirical analysis. To accomplish this, data of 14 instructors from three institutions that used TrACE from Spring 2015 to Spring 2016 was collected. Data was analyzed to identify frequency of analytic visits, duration of analytic use, differences in analytic use, and differences in use between semesters. Instructors demonstrated preferences for some analytics over others, but the majority of teachers generate short sessions that may not allow for in-depth exploration in analytics. Finally, instructor activity is not always consistent between semesters. Focus groups were conducted to explore motivations behind these findings and future work includes developing LA that address discovered issues.},
booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {2504–2510},
numpages = {7},
keywords = {analytics usage trends, instructor support},
location = {Denver, Colorado, USA},
series = {CHI EA '17}
}

@inproceedings{10.1145/3027385.3027396,
author = {Ferguson, Rebecca and Clow, Doug},
title = {Where is the evidence? a call to action for learning analytics},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027396},
doi = {10.1145/3027385.3027396},
abstract = {Where is the evidence for learning analytics? In particular, where is the evidence that it improves learning in practice? Can we rely on it? Currently, there are vigorous debates about the quality of research evidence in medicine and psychology, with particular issues around statistical good practice, the 'file drawer effect', and ways in which incentives for stakeholders in the research process reward the quantity of research produced rather than the quality. In this paper, we present the Learning Analytics Community Exchange (LACE) project's Evidence Hub, an effort to relate research evidence in learning analytics to four propositions about learning analytics: whether they support learning, support teaching, are deployed widely, and are used ethically. Surprisingly little evidence in this strong, specific sense was found, and very little was negative (7%, N=123), suggesting that learning analytics is not immune from the pressures in other areas. We explore the evidence in one particular area in detail (whether learning analytics improve teaching and learners support in the university sector), and set out some of the weaknesses of the evidence available. We conclude that there is considerable scope for improving the evidence base for learning analytics, and set out some suggestions of ways for various stakeholders to achieve this.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {56–65},
numpages = {10},
keywords = {access, ethics, evidence, evidence hub, generalisability, learning analytics cycle, reliability, validity},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3576050.3576077,
author = {Poquet, Oleksandra and Jovanovic, Jelena and Pardo, Abelardo},
title = {Student Profiles of Change in a University Course: A Complex Dynamical Systems Perspective},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576077},
doi = {10.1145/3576050.3576077},
abstract = {Learning analytics approaches to profiling students based on their study behaviour remain limited in how they integrate temporality and change. To advance this area of work, the current study examines profiles of change in student study behaviour in a blended undergraduate engineering course. The study is conceptualised through complex dynamical systems theory and its applications in psychological and cognitive science research. Students were profiled based on the changes in their behaviour as observed in clickstream data. Measure of entropy in the recurrence of student behaviour was used to indicate the change of a student state, consistent with the evidence from cognitive sciences. Student trajectories of weekly entropy values were clustered to identify distinct profiles. Three patterns were identified: stable weekly study, steep changes in weekly study, and moderate changes in weekly study. The students with steep changes in their weekly study activity had lower exam grades and showed destabilisation of weekly behaviour earlier in the course. The study investigated the relationships between these profiles of change, student performance, and other approaches to learner profiling, such as self-reported measures of self-regulated learning, and profiles based on the sequences of learning actions.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {197–207},
numpages = {11},
keywords = {complex dynamical systems, learning analytics, self-regulated learning},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3027385.3027419,
author = {Whitelock-Wainwright, Alexander and Ga\v{s}evi\'{c}, Dragan and Tejeiro, Ricardo},
title = {What do students want? towards an instrument for students' evaluation of quality of learning analytics services},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027419},
doi = {10.1145/3027385.3027419},
abstract = {Quality assurance in any organization is important for ensuring that service users are satisfied with the service offered. For higher education institutes, the use of service quality measures allows for ideological gaps to be both identified and resolved. The learning analytic community, however, has rarely addressed the concept of service quality. A potential outcome of this is the provision of a learning analytics service that only meets the expectations of certain stakeholders (e.g., managers), whilst overlooking those who are most important (e.g., students). In order to resolve this issue, we outline a framework and our current progress towards developing a scale to assess student expectations and perceptions of learning analytics as a service.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {368–372},
numpages = {5},
keywords = {action research, learning analytics, service quality},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3576050.3576146,
author = {Poellhuber, Louis-Vincent and Poellhuber, Bruno and Desmarais, Michel and Leger, Christian and Roy, Normand and Manh-Chien Vu, Mathieu},
title = {Cluster-Based Performance of Student Dropout Prediction as a Solution for Large Scale Models in a Moodle LMS},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576146},
doi = {10.1145/3576050.3576146},
abstract = {Learning management systems provide a wide breadth of data waiting to be analyzed and utilized to enhance student and faculty experience in higher education. As universities struggle to support students’ engagement, success and retention, learning analytics is being used to build predictive models and develop dashboards to support learners and help them stay engaged, to help teachers identify students needing support, and to predict and prevent dropout. Learning with Big Data has its challenges, however: managing great quantities of data requires time and expertise. To predict students at risk, many institutions use machine learning algorithms with LMS data for a given course or type of course, but only a few are trying to make predictions for a large subset of courses. This begs the question: “How can student dropout be predicted on a very large set of courses in an institution Moodle LMS?” In this paper, we use automation to improve student dropout prediction for a very large subset of courses, by clustering them based on course design and similarity, then by automatically training, testing, and selecting machine learning algorithms for each cluster. We developed a promising methodology that outlines a basic framework that can be adjusted and optimized in many ways and that further studies can easily build on and improve.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {592–598},
numpages = {7},
keywords = {Moodle LMS, dropout prediction, engagement, learning analytics},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/2536536.2536579,
author = {Fulantelli, Giovanni and Taibi, Davide and Arrigo, Marco},
title = {A semantic approach to mobile learning analytics},
year = {2013},
isbn = {9781450323451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2536536.2536579},
doi = {10.1145/2536536.2536579},
abstract = {Mobile learning has reached a considerable level of maturity in recent years, and its role is widely acknowledged in school contexts, university, vocational training, formal and non-formal learning settings, and more generally as an opportunity for lifelong learning. Despite its maturity, evaluation of mobile learning remains an open research issue, especially as regards the activities that take place outside the classroom. In this context, Learning Analytics can provide answers, and offer the appropriate tools to enhance mobile learning experiences. In recent years Learning Analytics has been highly successful in different contexts, but mobile learning exhibits particular characteristics related to the technologies used, student mobility, the possibility of having localized data and information and the social dynamics that characterize the context in which learning takes place. In this paper we propose an innovative approach to support analytics of learners' activities in a mobile learning setting based on the Semantic Web paradigm and on the semantic relationships expressed in the Linked Open Data cloud. MeLOD, a mobile environment for learning with Linked Open Data, is also introduced as a demonstrator for the ideas illustrated in the paper. Potentials and pitfalls of the proposed approach, both for teachers and learners, are reported in the conclusions.},
booktitle = {Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality},
pages = {287–292},
numpages = {6},
keywords = {learning analytics, linked open data, mobile learning, semantic web},
location = {Salamanca, Spain},
series = {TEEM '13}
}

@inproceedings{10.1145/3706468.3706518,
author = {Hern\'{a}ndez-Campos, M\'{o}nica and Hilliger, Isabel and Garc\'{\i}a-Pe\~{n}alvo, Francisco-Jos\'{e}},
title = {Evaluating Learning Outcomes Through Curriculum Analytics: Actionable Insights for Curriculum Decision-making: A Design-based research approach to assess learning outcomes in higher education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706518},
doi = {10.1145/3706468.3706518},
abstract = {Learning analytics (LA) emerged with the promise of improving student learning outcomes (LOs), however, its effectiveness in informing actionable insights remains a challenge. Curriculum analytics (CA), a subfield of LA, seeks to address this by using data to inform curriculum development. This study explores using CA to evaluate LOs through direct standardized measures at the subject level, examining how this process informs curriculum decision-making. Conducted at an engineering-focused higher education institution, the research involved 32 administrators and 153 faculty members, serving 9.906 students across nine programs. By utilizing the Integrative Learning Design Framework, we conducted three phases of this framework and present key results. Findings confirm the importance of stakeholder involvement throughout different design phases, highlighting the need for ongoing training and support. Among the actionable insights that emerged from LOs assessments, we identified faculty reflections regarding the need to incorporate active learning strategies, improve course planning, and acknowledge the need for education-specific training for faculty development. Although the study does not demonstrate whether these insights lead to improvements in LOs, this paper contributes to the CA field by offering a practical approach to evaluating LOs and translating these assessments into actionable improvements within an actual-world educational context.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {384–394},
numpages = {11},
keywords = {Additional Keywords and Phrases},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3506860.3506880,
author = {Tzi-Dong Ng, Jeremy and Wang, Zuo and Hu, Xiao},
title = {Needs Analysis and Prototype Evaluation of Student-facing LA Dashboard for Virtual Reality Content Creation},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506880},
doi = {10.1145/3506860.3506880},
abstract = {Being a promising constructionist pedagogy in recent years, maker education empowers students to take agency of their learning process through constructing both knowledge and real-world physical or digital products and fosters peer interactions for collective innovation. Learning Analytics (LA) excels at generating personalized, fine-grained feedback in near real-time and holds much potential in supporting process-oriented and peer-supported learning activities, including maker activities. In the context of virtual reality (VR) content creation for cultural heritage education, this study qualitatively solicited 27 students’ needs on progress monitoring, reflection, and feedback during their making process. Findings have inspired the prototype design of a student-facing LA dashboard (LAVR). Leveraging multimodal learning analytics (MmLA) such as text and audio analytics to fulfill students’ needs, the prototype has various features and functions including automatic task reminders, content quality detection, and real-time feedback on quality of audio-visual elements. A preliminary evaluation of the prototype with 10 students confirms its potential in supporting students’ self-regulated learning during the making process and for improving the quality of VR content. Implications on LA design for supporting maker education are discussed. Future work is planned to include implementation and evaluation of the dashboard in classrooms.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {444–450},
numpages = {7},
keywords = {Dashboard, Needs analysis, Prototype evaluation, VR content creation},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/2669711.2669914,
author = {Ruiz, Javier Santofimia and D\'{\i}az, H\'{e}ctor J. Pijeira and Ruip\'{e}rez-Valiente, Jos\'{e} A. and Mu\~{n}oz-Merino, Pedro J. and Kloos, Carlos Delgado},
title = {Towards the development of a learning analytics extension in open edX},
year = {2014},
isbn = {9781450328968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669711.2669914},
doi = {10.1145/2669711.2669914},
abstract = {The emergence of platforms to support MOOCs (Massive Open Online Courses) strengthens the need of a powerful learning analytics support since teachers cannot be aware of so many students. However, the learning analytics support in MOOC platforms is in an early stage nowadays. The edX platform, one of the most important MOOC platforms, has few learning analytics functionalities at present. In this paper, we analyze the learning analytics support given by the edX platform, and the main initiatives to implement learning analytics in edX. We also present our initial steps to implement a learning analytics extension in edX. We review technical aspects, difficulties, solutions, the architecture and the different elements involved. Finally, we present some new visualizations in the edX platform for teachers and students to help them understand the learning process.},
booktitle = {Proceedings of the Second International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {299–306},
numpages = {8},
keywords = {MOOCs, learning analytics, visualizations},
location = {Salamanca, Spain},
series = {TEEM '14}
}

@inproceedings{10.1145/3576050.3576058,
author = {Alfredo, Riordan Dervin and Nie, Lanbing and Kennedy, Paul and Power, Tamara and Hayes, Carolyn and Chen, Hui and McGregor, Carolyn and Swiecki, Zachari and Ga\v{s}evi\'{c}, Dragan and Martinez-Maldonado, Roberto},
title = {"That Student Should be a Lion Tamer!" StressViz: Designing a Stress Analytics Dashboard for Teachers},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576058},
doi = {10.1145/3576050.3576058},
abstract = {In recent years, there has been a growing interest in creating multimodal learning analytics (LA) systems that automatically analyse students’ states that are hard to see with the "naked eye", such as cognitive load and stress levels, but that can considerably shape their learning experience. A rich body of research has focused on detecting such aspects by capturing bodily signals from students using wearables and computer vision. Yet, little work has aimed at designing end-user interfaces that visualise physiological data to support tasks deliberately designed for students to learn from stressful situations. This paper addresses this gap by designing a stress analytics dashboard that encodes students’ physiological data into stress levels during different phases of an authentic team simulation in the context of nursing education. We conducted a qualitative study with teachers to understand (i) how they made sense of the stress analytics dashboard; (ii) the extent to which they trusted the dashboard in relation to students’ cortisol data; and (iii) the potential adoption of this tool to communicate insights and aid teaching practices.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {57–67},
numpages = {11},
keywords = {Affective computing, Healthcare education, LA dashboard, Multimodal dataset, Stress detection, Visualisation},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3012430.3012536,
author = {Filv\`{a}, Daniel Amo and Alier, Marc and Casany, Mar\'{\i}a Jos\'{e} and Mayol, Enric},
title = {A learning analytics tool with hybrid graphical and textual interpretation generation},
year = {2016},
isbn = {9781450347471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3012430.3012536},
doi = {10.1145/3012430.3012536},
abstract = {The introduction and use of on-line learning resources has improved students learning process in several aspects. But at the same time, it also introduced more complexity and made more difficult to teachers how to analyze learning evolution and improvement of students. In this paper, we propose a first approach how to visualize and analyze student interaction with on-line learning systems and Virtual Learning Environments (VLE).We present a piece of software that collects information on the interaction of the students with the Moodle VLE and that it displays to teachers in a more analytical way. The interaction data is displayed to support teacher interpretation from a learning point of view, with the inclusion of automatically generated textual explanations about the analysis of such data.},
booktitle = {Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {327–333},
numpages = {7},
keywords = {learning analytics, learning management systems, moodle, student interactions, virtual learning environments},
location = {Salamanca, Spain},
series = {TEEM '16}
}

@inproceedings{10.1145/2876034.2893380,
author = {Lewkow, Nicholas and Feild, Jacqueline and Zimmerman, Neil and Riedesel, Mark and Essa, Alfred and Boulanger, David and Seanosky, Jeremie and Kumar, Vive and Kinshuk and Kode, Sandhya},
title = {A Scalable Learning Analytics Platform for Automated Writing Feedback},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2893380},
doi = {10.1145/2876034.2893380},
abstract = {In this paper, we describe a scalable learning analytics platform which runs generalized analytics models on educational data in parallel. As a proof of concept, we use this platform as a base for an end-to-end automated writing feedback system. The system allows students to view feedback on their writing in near real-time, edit their writing based on the feedback provided, and observe the progression of their performance over time. Providing students with detailed feedback is an important part of improving writing skills and an essential component towards solving Bloom's "two sigma" problem in education. We evaluate the effectiveness of the feedback for students with an ongoing pilot study with 800 students who are using the learning analytics platform in a college English course.},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {109–112},
numpages = {4},
keywords = {analytic tools for learners, automatic essay feedback, natural language processing, performance feedback, scalable analytics},
location = {Edinburgh, Scotland, UK},
series = {L@S '16}
}

@inproceedings{10.1145/2876034.2893430,
author = {Cobos, Ruth and Gil, Silvia and Lareo, Angel and Vargas, Francisco A.},
title = {Open-DLAs: An Open Dashboard for Learning Analytics},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2893430},
doi = {10.1145/2876034.2893430},
abstract = {In this paper a learning analytics dashboard for MOOCs is proposed. It visualises the progress of learners' activity taking into account navigation, social interactions and interaction with educational resources. This approach was tested with the MOOCs created by the University Auton\'{o}ma of Madrid (Spain) in the edX platform. Nowadays, the dashboard is being improved taking into account the received feedback from MOOCs instructors and assistants. Finally, a new version is presented to work along with edX and Open edX.},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {265–268},
numpages = {4},
keywords = {dashboard, learning analytics, moocs},
location = {Edinburgh, Scotland, UK},
series = {L@S '16}
}

@inproceedings{10.1145/2669711.2669913,
author = {Ray\'{o}n, Alex and Guenaga, Mariluz and N\'{u}\~{n}ez, Asier},
title = {Supporting competency-assessment through a learning analytics approach using enriched rubrics},
year = {2014},
isbn = {9781450328968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669711.2669913},
doi = {10.1145/2669711.2669913},
abstract = {Universities have increasingly emphasized competencies as central elements of students' development. However, the assessment of these competencies is not an easy task. The availability of data that learners generate in computer mediated learning offers great potential to study how learning takes place, and thus, to gather evidences for competency-assessment using enriched rubrics. The lack of data interoperability and the decentralization of those educational applications set out a challenge to exploit trace data. To face these problems we have designed and developed SCALA (Scalable Competence Assessment through a Learning Analytics approach), an analytics system that integrates usage -how the user interacts with resources- and social -how students and teachers interact among them-trace data to support competency assessment. The case study of SCALA presents teachers a dashboard with enriched rubrics of blended datasets obtained from six assessment learning activities, performed with a group of 28 students working teamwork competency. In terms of knowledge discovery, we obtain results applying clustering and association rule mining algorithms. Thus, we provide a visual analytics tool ready to support competency-assessment.},
booktitle = {Proceedings of the Second International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {291–298},
numpages = {8},
keywords = {data integration, information retrieval, large-scale interoperability, learning analytics, learning dashboard},
location = {Salamanca, Spain},
series = {TEEM '14}
}

@inproceedings{10.1145/2567574.2567607,
author = {Harfield, Timothy D.},
title = {Teaching the unteachable: on the compatibility of learning analytics and humane education},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567607},
doi = {10.1145/2567574.2567607},
abstract = {This paper is an exploratory effort to find a place for learning analytics in humane education. After distinguishing humane education from training on the basis of the Aristotelian model of intellectual capabilities, and arguing that humane education is distinct by virtue of its interest in cultivating prudence, which is unteachable, an account of three key characteristics of humane education is provided. Appealing to thinkers of the Italian Renaissance, it is argued that ingenium, eloquence, and self-knowledge constitute the what, how, and why of humane education. Lastly, looking to several examples from recent learning analytics literature, it is demonstrated that learning analytics is not only helpful as set of aids for ensuring success in scientific and technical disciplines, but in the humanities as well. In order to function effectively as an aid to humane education, however, learning analytics must be embedded within a context that encourages continuous reflection, responsiveness, and personal responsibility for learning.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {241–245},
numpages = {5},
keywords = {aristotle, humanism, humanities, learning analytics, pedagogy, renaissance},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/3636555.3636896,
author = {Thomas, Danielle R and Lin, Jionghao and Gatz, Erin and Gurung, Ashish and Gupta, Shivang and Norberg, Kole and Fancsali, Stephen E and Aleven, Vincent and Branstetter, Lee and Brunskill, Emma and Koedinger, Kenneth R},
title = {Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study Quasi-Experimental Investigation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636896},
doi = {10.1145/3636555.3636896},
abstract = {Artificial intelligence (AI) applications to support human tutoring have potential to significantly improve learning outcomes, but engagement issues persist, especially among students from low-income backgrounds. We introduce an AI-assisted tutoring model that combines human and AI tutoring and hypothesize this synergy will have positive impacts on learning processes. To investigate this hypothesis, we conduct a three-study quasi-experiment across three urban and low-income middle schools: 1) 125 students in a Pennsylvania school; 2) 385 students (50% Latinx) in a California school, and 3) 75 students (100% Black) in a Pennsylvania charter school, all implementing analogous tutoring models. We compare learning analytics of students engaged in human-AI tutoring compared to students using math software only. We find human-AI tutoring has positive effects, particularly in student’s proficiency and usage, with evidence suggesting lower achieving students may benefit more compared to higher achieving students. We illustrate the use of quasi-experimental methods adapted to the particulars of different schools and data-availability contexts so as to achieve the rapid data-driven iteration needed to guide an inspired creation into effective innovation. Future work focuses on improving the tutor dashboard and optimizing tutor-student ratios, while maintaining annual costs per student of approximately $700 annually.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {404–415},
numpages = {12},
keywords = {AI-assisted tutoring, Design-based research, Human-AI tutoring, Tutoring},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/2567574.2567585,
author = {Dawson, Shane and Ga\v{s}evi\'{c}, Dragan and Siemens, George and Joksimovic, Srecko},
title = {Current state and future trends: a citation network analysis of the learning analytics field},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567585},
doi = {10.1145/2567574.2567585},
abstract = {This paper provides an evaluation of the current state of the field of learning analytics through analysis of articles and citations occurring in the LAK conferences and identified special issue journals. The emerging field of learning analytics is at the intersection of numerous academic disciplines, and therefore draws on a diversity of methodologies, theories and underpinning scientific assumptions. Through citation analysis and structured mapping we aimed to identify the emergence of trends and disciplinary hierarchies that are influencing the development of the field to date. The results suggest that there is some fragmentation in the major disciplines (computer science and education) regarding conference and journal representation. The analyses also indicate that the commonly cited papers are of a more conceptual nature than empirical research reflecting the need for authors to define the learning analytics space. An evaluation of the current state of learning analytics provides numerous benefits for the development of the field, such as a guide for under-represented areas of research and to identify the disciplines that may require more strategic and targeted support and funding opportunities.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {231–240},
numpages = {10},
keywords = {author networks, citation analysis, learning analytics, social network analysis},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/3636555.3636871,
author = {Paik, Jae H. and Himelfarb, Igor and Yoo, Seung Hee and Yoo, KyoungMi and Ha, Hoyong},
title = {The relationships among school engagement, students' emotions, and academic performance in an elementary online learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636871},
doi = {10.1145/3636555.3636871},
abstract = {This study investigated the relationship among school engagement, students’ emotions, and academic performance of students in grades 3-6 in South Korea. A random sampling approach was used to extract data from 1,075 students out of a total of 141,926 students who used the educational learning platform, I-TokTok, adapted as the primary Learning Management System (LMS) at the provincial level. The present study aimed to identify dimensions of school engagement by exploring the behaviors consistent with IMS Caliper Analytics Specifications, a common standard utilized for collecting learning data from digital resources. Exploratory and Confirmatory Factor Analyses revealed a three-factor model of school engagement among the 13 learning behavioral indicators: behavioral engagement, social engagement, and cognitive engagement.&nbsp;Students’ emotions were measured through voluntary daily activities in the platform involving reflecting on, recognizing, and recording of their emotions. Students’ academic performance was assessed with performance in math tests administered within the platform. Consistent with current literature, results demonstrated that dimensions of school engagement (i.e., behavioral and social engagement) and students’ emotions positively predicted their math performance. Lastly, school engagement mediated the relationship between students’ emotions and math performance. The present study emphasizes the importance of investigating the underlying mechanisms through which elementary students emotions and school engagement predict academic achievement in an online learning environment. This relatively new area of educational research deserves attention in the field of learning analytics. We highlight the importance of considering ways to improve both students’ emotions and their school engagement to maximize the student learning outcomes.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {219–230},
numpages = {12},
keywords = {Academic Performance, Elementary Education, Learning Management System, School Engagement, Students’ Emotions},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3041021.3054175,
author = {de Freitas, Sara and Gibson, David and Alvarez, Victor and Irving, Leah and Star, Kam and Charleer, Sven and Verbert, Katrien},
title = {How to Use Gamified Dashboards and Learning Analytics for Providing Immediate Student Feedback and Performance Tracking in Higher Education},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054175},
doi = {10.1145/3041021.3054175},
abstract = {With the wide use of the Internet and digital data sources, there has been a recent emergence of easy access to student data within learning management systems (LMS), grade data through student information systems (SIS) and broader sector data through benchmarking metrics and standards. Learning analytics on top of this data has introduced greater capabilities for improving student performance through immediate feedback. Current literature considers the role of dashboards for student performance and feedback, but few papers consider the efficacy of fast feedback to students or other ways that information can be fed back to learners. In this paper, we consider the work done by three leading groups addressing the impact of gamification in university education, with a specific focus on how data is presented to the learner, that is using elements such as points, levelling up, narrative and progression to scaffold learning. Results indicate increases in student motivation, engagement, satisfaction, retention and performance enhancements.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {429–434},
numpages = {6},
keywords = {dashboards, game-based learning, higher education, learning analytics, serious games},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3706468.3706569,
author = {Oh, Hyunju and Liu, Zifeng and Xing, Wanli},
title = {Do Actions Speak Louder Than Words? Unveiling Linguistic Patterns in Online Learning Communities Using Cross Recurrence Quantification Analysis},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706569},
doi = {10.1145/3706468.3706569},
abstract = {This study explores the dynamics of engagement in online learning communities (OLCs), focusing on online math discussion forums. It employs Social Network Analysis (SNA) and Cross-Recurrence Quantification Analysis (CRQA) to examine interaction patterns and linguistic synchrony across participant clusters with varying levels of engagement. SNA reveals three distinct participant groups—core, intermediate, and peripheral—each exhibiting different interaction levels. The study’s findings highlight the significance of coordinated discourse in fostering collaborative learning and engagement in OLCs. This research contributes to the theoretical framework of Social Capital Theory by emphasizing the role of shared language in promoting cohesive communication. The results offer valuable insights for designing more effective online learning environments that encourage sustained student participation and knowledge construction.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {992–998},
numpages = {7},
keywords = {Online Learning Communities, Social Network Analysis, Cross-Recurrence Quantification Analysis},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3341215.3356335,
author = {Pastushenko, Olena},
title = {Gamification in Assignments: Using Dynamic Difficulty Adjustment and Learning Analytics to Enhance Education},
year = {2019},
isbn = {9781450368711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341215.3356335},
doi = {10.1145/3341215.3356335},
abstract = {This paper discusses the opportunities for gamification and dynamic difficulty adjustment based on multimodal learning analytics in assignments. Altogether this covers a broader term of personalized education, which is getting more attention among the researchers in recent years. The difference of this work from other similar researches is that it suggests combining several domains to achieve better results: gamification (in order to improve student's motivation and involvements), and dynamic difficulty adjustment. All this is made possible by applying multimodal learning analytics and creating useful learning dashboards for the teachers.},
booktitle = {Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts},
pages = {47–53},
numpages = {7},
keywords = {dynamic difficulty adjustment, gamification, multimodal learning analytics, personalizedlearning},
location = {Barcelona, Spain},
series = {CHI PLAY '19 Extended Abstracts}
}

@inproceedings{10.1145/3136907.3136939,
author = {Su\'{a}rez, Angel and Ternier, Stefaan and Helbig, Ren\'{e} and Specht, Marcus},
title = {DojoAnalytics: A Learning Analytics interoperable component for DojoIBL},
year = {2017},
isbn = {9781450352550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136907.3136939},
doi = {10.1145/3136907.3136939},
abstract = {DojoIBL1 is a cloud based platform that provides flexible support for collaborative inquiry-based learning processes. It expands the learning process beyond the classroom walls and brings it to an online setting. Such transition requires teachers and learners to have more means to track and to follow up their progress. Learning Analytics dashboards provide such functionality in form of meaningful visualizations. In this paper we present the DojoAnalytics, a new module of DojoIBL that enables connections with third party Learning Analytics dashboards. In order to demonstrate interoperability with the external dashboards, two use case implementations will be described.},
booktitle = {Proceedings of the 16th World Conference on Mobile and Contextual Learning},
articleno = {2},
numpages = {8},
keywords = {Inquiry-based learning, interoperability, learners', learning analytics, performance},
location = {Larnaca, Cyprus},
series = {mLearn 2017}
}

@inproceedings{10.1145/3576050.3576087,
author = {Dood, Amber and Das, Kapotaksha and Qian, Zhen and Finkenstaedt-Quinn, Solaire and Gere, Anne and Shultz, Ginger},
title = {A Dashboard to Provide Instructors with Automated Feedback on Students’ Peer Review Comments},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576087},
doi = {10.1145/3576050.3576087},
abstract = {Writing-to-Learn (WTL) is an evidence-based instructional practice which can help students construct knowledge across many disciplines. Though it is known to be an effective practice, many instructors do not implement WTL in their courses due to time constraints and inability to provide students with personalized feedback. One way to address this is to include peer review, which allows students to receive feedback on their writing and benefits them as they act as reviewers. To further ease the implementation of peer review and provide instructors with feedback on their students’ work, we labeled students’ peer review comments across courses for type of feedback provided and trained a machine learning model to automatically classify those comments, improving upon models reported in prior work. We then created a dashboard which takes students’ comments, labels the comments using the model, and allows instructors to filter through their students’ comments based on how the model labels the comments. This dashboard can be used by instructors to monitor the peer review collaborations occurring in their courses. The dashboard will allow them to efficiently use information provided by peers to identify common issues in their students’ writing and better evaluate the quality of their students’ peer review.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {619–625},
numpages = {7},
keywords = {Writing-to-Learn, automated feedback, instructor dashboards, machine learning, peer review},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/2330601.2330642,
author = {Leony, Derick and Pardo, Abelardo and de la Fuente Valent\'{\i}n, Luis and de Castro, David S\'{a}nchez and Kloos, Carlos Delgado},
title = {GLASS: a learning analytics visualization tool},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330642},
doi = {10.1145/2330601.2330642},
abstract = {The use of technology in every day tasks enables the possibility to collect large amounts of observations of events taking place in different environments. Most tools are capable of storing a detailed account of the operations executed by users in certain files commonly known as logs. These files can be further analyzed to infer information that is not directly visible such as the most popular applications, times of the day with highest activity, calories burnt after a running session, etc. Graphic visualizations of this data can be used to support this type of analysis as shown in [1]. Visualization can also be applied in the domain of learning experiences to track and analyse the data obtained from both learners and instructors. There are several tools that have been proposed in specific environments such as, for example, in personal learning environments [5], to foster self-reflection and awareness [2], and to support instructors in web-based distance learning [3]. These visualizations need to take into account aspects such as how to access and protect personal data, filter management, multi-user support and availability. In this paper, the web-based visualization platform GLASS (Gradient's Learning Analytics System) is presented. The architecture of the tool has been conceived to support a large number of modular visualizations derived from a common dataset containing a large number of recorded events. The tool was developed following a bottom-up methodology to provide a set of basic operations required by any visualization. The design goal is to provide a highly versatile, modular platform that simplifies the implementation of new visualizations.The main functionality elements considered in GLASS are database access, module management, visualization parameters, and the web interface. The platform uses datasets stored using the CAM schema (Contextualized Attention Metadata) [6]. This schema allows to capture events occurring during the use of various computer applications which, in our case, are the tools used by students when working in a learning environment. The process to obtain events from learning environments has been described in [4]. GLASS is able to connect to more than one CAM database, thus allowing access to events obtained in different contexts.The tool is extensible through the installation of modules. A module is a structured set of scripts and resources that, given a dataset of events and a set of filters, generates at least one visualization. In order to simplify the development of new modules, the platform provides an API to manage common visualizations settings such as the date range and other typical filters. A visualization may include a simpler version suitable to be displayed in the user's Dashboard, which is the entry page of the application. Figure 1 shows an example of dashboard in GLASS. Additionally, visualizations can be exported as HTML code to be embedded in another website.The GLASS architecture consists of four layers: data layer, code base, modules and visualizations, as depicted in Figure 2. The data layer is composed of a set of CAM databases and a database to store the platform parameters. The code base is in charge of the main functionalities of GLASS regarding module and user management and interfaces. Modules must comply with the platform specifications to generate visualizations and the settings that can affect their appearance. Currently, the tool includes a default module that provides two visualizations as shown in Figure 1): a frequency time line of activity events and a bar-chart with grouped bars of events generated by different user groups (e.g. events from students individually, or groups). The default module also serves as an example of how to develop a additional modules.Currently, GLASS is able to support new visualizations and is undergoing additional testing in different learning scenarios. Preliminary results obtained from user tests indicate that visualizations need to be very intuitive for both instructors and learners. The current development effort is focused on providing visualizations that show the most-common learners events and the most active learners in a given context. To encourage its use in other institutions, the tool has been released with an open source license and can be obtained from http://glass.mozart.gast.it.uc3m.es. A video demonstrating the tool is available at http://bit.ly/glass-lak12.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {162–163},
numpages = {2},
keywords = {learning analytics, visualization framework, visualization system},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/3506860.3506922,
author = {Praharaj, Sambit and Scheffel, Maren and Schmitz, Marcel and Specht, Marcus and Drachsler, Hendrik},
title = {Towards Collaborative Convergence: Quantifying Collaboration Quality with Automated Co-located Collaboration Analytics},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506922},
doi = {10.1145/3506860.3506922},
abstract = {Collaboration is one of the four important 21st-century skills. With the pervasive use of sensors, interest on co-located collaboration (CC) has increased lately. Most related literature used the audio modality to detect indicators of collaboration (such as total speaking time and turn taking). CC takes place in physical spaces where group members share their social (i.e., non-verbal audio indicators like speaking time, gestures) and epistemic space (i.e., verbal audio indicators like the content of the conversation). Past literature has mostly focused on the social space to detect the quality of collaboration. In this study, we focus on both social and epistemic space with an emphasis on the epistemic space to understand different evolving collaboration patterns and collaborative convergence and quantify collaboration quality. We conduct field trials by collecting audio recordings in 14 different sessions in a university setting while the university staff and students collaborate over playing a board game to design a learning activity. This collaboration task consists of different phases with each collaborating member having been assigned a pre-fixed role. We analyze the collected group speech data to do role-based profiling and visualize it with the help of a dashboard.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {358–369},
numpages = {12},
keywords = {co-located collaboration, collaboration, collaboration analytics, multimodal learning analytics},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3027385.3027428,
author = {Scheffel, Maren and Drachsler, Hendrik and Kreijns, Karel and de Kraker, Joop and Specht, Marcus},
title = {Widget, widget as you lead, I am performing well indeed! using results from an exploratory offline study to inform an empirical online study about a learning analytics widget in a collaborative learning environment},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027428},
doi = {10.1145/3027385.3027428},
abstract = {The collaborative learning processes of students in online learning environments can be supported by providing learning analytics-based visualisations that foster awareness and reflection about an individual's as well as the team's behaviour and their learning and collaboration processes. For this empirical study we implemented an activity widget into the online learning environment of a live five-months Master course and investigated the predictive power of the widget indicators towards the students' grades and compared the results to those from an exploratory study with data collected in previous runs of the same course where the widget had not been in use. Together with information gathered from a quantitative as well as a qualitative evaluation of the activity widget during the course, the findings of this current study show that there are indeed predictive relations between the widget indicators and the grades, especially those regarding responsiveness, and indicate that some of the observed differences in the last run could be attributed to the implemented activity widget.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {289–298},
numpages = {10},
keywords = {learning analytics, statistical analysis, tool evaluation},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/2460296.2460339,
author = {Monroy, Carlos and Rangel, Virginia Snodgrass and Whitaker, Reid},
title = {STEMscopes: contextualizing learning analytics in a K-12 science curriculum},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460339},
doi = {10.1145/2460296.2460339},
abstract = {In this paper, we discuss a scalable approach for integrating learning analytics into an online K-12 science curriculum. A description of the curriculum and the underlying pedagogical framework is followed by a discussion of the challenges to be tackled as part of this integration. We also include examples of data visualization based on real student and teacher data. With more than one million students and fifty thousand teachers using the curriculum, a massive and rich dataset is continuously updated. This repository depicts teacher and students usage of an inquiry-based science program, and offers exciting opportunities to leverage research to improve both teaching and learning. The growing dataset, with more than a hundred million items of activity in six months, also poses technical challenges such as data storage, complex aggregation and analysis with broader implications for pedagogy, big data, and learning.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {210–219},
numpages = {10},
keywords = {STEM education, big data, learning analytics, online curriculum},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/3576050.3576092,
author = {Quick, Joshua Dallas and Motz, Benjamin and Morrone, Anastasia},
title = {Lost in Translation: Determining the Generalizability of Temporal Models across Course Contexts&nbsp;},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576092},
doi = {10.1145/3576050.3576092},
abstract = {A common activity in learning analytics research is to demonstrate a new analytical technique by applying it to data from a single course.&nbsp; We explore whether the value of an analytical approach might generalize across course contexts.&nbsp; Accordingly, we conduct a conceptual replication of a well-cited temporal modeling study using self-regulated learning (SRL) taxonomies. We attempt to conceptually replicate this previous work through the analysis of 411 students across 19 courses’ trace event data. Using established SRL categorizations, learner actions are sequenced to identify regular clusters of interaction through hierarchical clustering methods. These clusters are then compared with the entire data corpus and each other through the development of first-order Markov models to develop process maps. Our findings indicate that, although some general patterns of SRL can generalize, these results are more limited at higher scales. Comparing these clusters of interaction along students’ performance in courses also indicates some relationships between activity and outcomes, though this finding is also limited in relation to the complexity introduced by scaling out these methods. We discuss how these temporal models should be viewed when making descriptive and qualitative inferences about students’ activity in digital learning environments.&nbsp;&nbsp;},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {273–283},
numpages = {11},
keywords = {Generalizability, Process Modeling, Replication, Self-regulated Learning, Trace Data},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3448139.3448194,
author = {Guillain, L\'{e}onore V. and Schneider, Bertrand},
title = {Facilitators First: Building a Tool With Facilitators to Foster a More Collaborative Makerspace Community Through Movement Traces},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448194},
doi = {10.1145/3448139.3448194},
abstract = {Research indicates that makerspaces equip students with the practical skills needed to build their own projects and thrive in the twenty-first-century workforce. While the appeal of makerspaces lies in their spirit of tinkering and community-driven ethos, these same attributes make it difficult to monitor and facilitate learning. Makerspaces also attract students from diverse backgrounds and skills, further challenging facilitators to accommodate the needs of each student and their self-directed projects. We propose a dashboard interface that visualizes Kinect sensor data to aid facilitators in monitoring student collaboration. The tool was designed with an iterative and participatory approach. Five facilitators were involved at each phase of the design process, from need-finding to prototyping to implementation and evaluation. Insights derived from interviews were used to inform the design decisions of the final interface. The final evaluation suggests that the use of normalized summary scores and an interactive network graph can successfully support facilitators in tasks related to improving collaboration. Moreover, the use of a red-green color scheme and the inclusion of student photos improved the usability for facilitators, but issues of trustworthiness need to be further examined.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {533–539},
numpages = {7},
keywords = {human-computer interaction, learning analytics dashboards, physical learning analytics},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/2090116.2090118,
author = {Duval, Erik},
title = {Attention please! learning analytics for visualization and recommendation},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090118},
doi = {10.1145/2090116.2090118},
abstract = {This paper will present the general goal of and inspiration for our work on learning analytics, that relies on attention metadata for visualization and recommendation. Through information visualization techniques, we can provide a dashboard for learners and teachers, so that they no longer need to "drive blind". Moreover, recommendation can help to deal with the "paradox of choice" and turn abundance from a problem into an asset for learning.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {9–17},
numpages = {9},
keywords = {learning analytics, recommendation, visualization},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/3152771.3156171,
author = {Gibson, Andrew and Martinez-Maldonado, Roberto},
title = {That dashboard looks nice, but what does it mean? towards making meaning explicit in learning analytics design},
year = {2017},
isbn = {9781450353793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152771.3156171},
doi = {10.1145/3152771.3156171},
abstract = {As learning analytics (LA) systems become more common, teachers and students are often required to not only make sense of the user interface (UI) elements of a system, but also to make meaning that is pedagogically appropriate to the learning context. However, we suggest that the dominant way of thinking about the relationship between representation and meaning results in an overemphasis on the UI, and that re-thinking this relationship is necessary to create systems that can facilitate deeper meaning making. We propose a conceptual view as a basis for discussion among the LA and HCI communities around a different way of thinking about meaning making, specifically that it should be explicit in the design process, provoking greater consideration of system level elements such as algorithms, data structures and information flow. We illustrate the application of the conceptualisation with two cases of LA design in the areas of Writing Analytics and Multi-modal Dashboards.},
booktitle = {Proceedings of the 29th Australian Conference on Computer-Human Interaction},
pages = {528–532},
numpages = {5},
keywords = {embodied cognition, information systems, learning analytics, meaning making, user interface design},
location = {Brisbane, Queensland, Australia},
series = {OzCHI '17}
}

@inproceedings{10.1145/3506860.3506916,
author = {Aguilar, Stephen J},
title = {Experimental Evidence of Performance Feedback vs. Mastery Feedback on Students’ Academic Motivation},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506916},
doi = {10.1145/3506860.3506916},
abstract = {Work throughout the learning analytics community has examined associations between Learning Analytics Dashboard (LAD) features and a number of important student outcomes, including academic motivation and self-regulated learning strategies. While there are many potential implications of visualized academic information within a LAD on student outcomes, there remains an unanswered question: are there causal differences between showing performance information (e.g., comparing students’ progress to the class average) vs. mastery information (e.g., their individual score) on students’ motivation? Grounded in Achievement Goal Theory, this study answers this question experimentally by analyzing the difference between college students’ (n=445) reported achievement goal orientations as well as their motivated information seeking orientations after being presented with performance or mastery feedback. Results indicate that students in a performance condition which displayed ”above average” achievement on an academic measure reported lower performance-avoidance goals (e.g., not wanting to do worse than everyone else), and performance-avoidance information-seeking goals (e.g., not wanting to seek out information showing that one does worse than peers) when compared to students in the mastery control condition. This study contributes to our understanding of the motivational implications of academic feedback presented to students, and suggests that comparative information has direct effects on student motivation. Results thus uncover a potential tension between what might seem intuitive feedback to give students versus what might be more motivationally appropriate. The implications of this work point to the need to understand LADs not simply as feedback mechanisms, but as embedded features of a learning environment that influence how students engage with course content.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {556–562},
numpages = {7},
keywords = {Higher Education, Motivation, Non-cognitive factors, Visualizations},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3706468.3706494,
author = {Jansen, Thorben and Horbach, Andrea and Meyer, Jennifer},
title = {Feedback from Generative AI: Correlates of Student Engagement in Text Revision from 655 Classes from Primary and Secondary School},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706494},
doi = {10.1145/3706468.3706494},
abstract = {Writing is fundamental in knowledge-based societies, and engaging students in text revision through feedback is critical for developing students’ writing skills. Automated feedback offers a promising solution to teachers’ time constraints creating feedback. However, prior research indicates that 20 to 71 percent of students receiving feedback do not engage in any text revision. Despite these concerning figures, students’ non-engagement has not received widespread attention, likely due to fragmented evidence from a few grade levels and writing tasks disconnected from regular teaching. Further, whether the issue persists when generative AI generates the feedback is unclear. The present study investigates what percentage of students behaviorally engage with feedback from generative AI in authentic classroom learning contexts. We analyzed data from an educational technology company, including 655 teacher-generated writing tasks involving 14,236 students across grades 1-12. Our findings show that around half of the students did not revise a single character in the text after receiving feedback. The percentage was similar across grade levels, task types, or feedback characteristics. We discuss the importance of including the percentage of engaged students as an additional metric in feedback research to achieve the goal that no student is left behind.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {831–836},
numpages = {6},
keywords = {student engagement, automated feedback, writing, generative AI},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/2462476.2462496,
author = {Fernandez-Medina, Carlos and P\'{e}rez-P\'{e}rez, Juan Ram\'{o}n and \'{A}lvarez-Garc\'{\i}a, V\'{\i}ctor M. and Paule-Ruiz, M. del Puerto},
title = {Assistance in computer programming learning using educational data mining and learning analytics},
year = {2013},
isbn = {9781450320788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462476.2462496},
doi = {10.1145/2462476.2462496},
abstract = {The learning of programming presents many difficulties for students. Nowadays, a number of software tools are available that enable students in programming courses to develop and exercise their knowledge and skills. However, these tools do not examine their work or provide students with indications on their learning process. In this paper we introduce a learning approach for programming based on the analysis of students' mistakes during practical lessons in programming subjects. This approach makes use of compiler messages to analyse their quantity and semantic value, and report the individual and comparative learning progress. This approach is illustrated in practice by a case study conducted in a class of undergraduate students of computer science. This study makes it possible to provide an analytic representation of reflective learning practice, giving us a better understanding on programming learning processes.},
booktitle = {Proceedings of the 18th ACM Conference on Innovation and Technology in Computer Science Education},
pages = {237–242},
numpages = {6},
keywords = {e-learning, eclipse plug-ins, integrated development environment, learning analytics, programming errors, programming language},
location = {Canterbury, England, UK},
series = {ITiCSE '13}
}

@inproceedings{10.1145/3375462.3375472,
author = {Kia, Fatemeh Salehian and Teasley, Stephanie D. and Hatala, Marek and Karabenick, Stuart A. and Kay, Matthew},
title = {How patterns of students dashboard use are related to their achievement and self-regulatory engagement},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375472},
doi = {10.1145/3375462.3375472},
abstract = {The aim of student-facing dashboards is to support learning by providing students with actionable information and promoting self-regulated learning. We created a new dashboard design aligned with SRL theory, called MyLA, to better understand how students use a learning analytics tool. We conducted sequence analysis on students' interactions with three different visualizations in the dashboard, implemented in a LMS, for a large number of students (860) in ten courses representing different disciplines. To evaluate different students' experiences with the dashboard, we computed chi-squared tests of independence on dashboard users (52%) to find frequent patterns that discriminate students by their differences in academic achievement and self-regulated learning behaviors. The results revealed discriminating patterns in dashboard use among different levels of academic achievement and self-regulated learning, particularly for low achieving students and high self-regulated learners. Our findings highlight the importance of differences in students' experience with a student-facing dashboard, and emphasize that one size does not fit all in the design of learning analytics tools.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {340–349},
numpages = {10},
keywords = {academic achievement, self-regulated learning, sequential pattern mining, student-facing dashboard},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3706468.3706499,
author = {Lee, Melissa and Huang, Chun-Wei and Collins, Kelly and Feng, Mingyu},
title = {Examining the Relationship between Math Anxiety, Effort, and Learning Outcomes Using Latent Class Analysis},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706499},
doi = {10.1145/3706468.3706499},
abstract = {Math anxiety has been found to negatively correlate with math achievement, affecting students’ choices to take fewer math classes and avoid math educational opportunities. Educational technology tools can ameliorate some of the negative effects of math anxiety. We examined students’ math anxiety, effort in an educational technology platform, and their relationship with students’ math achievement. Multilevel latent class analysis was used to identify student profiles of math anxiety. Regression analysis was used to examine how students of different profiles interacted with MathSpring, an adaptive intelligent tutor that provides affective supports to students during math problem-solving. The student's math achievement was measured by a standardized test. Our analysis indicated heterogeneity in math anxiety, and students could fall into one of three groups: Highly Anxious, Performance Anxious, and Calm. Highly Anxious students tended to give up more often when solving questions in MathSpring and had the lowest math achievement outcomes. For these students, using hints to solve problems in MathSpring was significantly associated with increased math outcomes. These findings have implications for the field's understanding of how students of different math anxiety profiles can demonstrate varying efforts in math educational technology platforms, and different math learning outcomes.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {227–237},
numpages = {11},
keywords = {latent class analysis, math anxiety, math learning, social-emotional learning},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/2330601.2330666,
author = {Arnold, Kimberly E. and Pistilli, Matthew D.},
title = {Course signals at Purdue: using learning analytics to increase student success},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330666},
doi = {10.1145/2330601.2330666},
abstract = {In this paper, an early intervention solution for collegiate faculty called Course Signals is discussed. Course Signals was developed to allow instructors the opportunity to employ the power of learner analytics to provide real-time feedback to a student. Course Signals relies not only on grades to predict students' performance, but also demographic characteristics, past academic history, and students' effort as measured by interaction with Blackboard Vista, Purdue's learning management system. The outcome is delivered to the students via a personalized email from the faculty member to each student, as well as a specific color on a stoplight -- traffic signal -- to indicate how each student is doing. The system itself is explained in detail, along with retention and performance outcomes realized since its implementation. In addition, faculty and student perceptions will be shared.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {267–270},
numpages = {4},
keywords = {college student success, early intervention, learning analytics, retention},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/3506860.3506905,
author = {Li, Qiujie and Jung, Yeonji and d'Anjou, Bernice and Wise, Alyssa Friend},
title = {Unpacking Instructors’ Analytics Use: Two Distinct Profiles for Informing Teaching},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506905},
doi = {10.1145/3506860.3506905},
abstract = {This study addresses the gap in knowledge about differences in how instructors use analytics to inform teaching by examining the ways that thirteen college instructors engaged with a set of university-provided analytics. Using multiple walk-through interviews with the instructors and qualitative inductive coding, two profiles of instructor analytics use were identified that were distinct from each other in terms of the goals of analytics use, how instructors made sense of and took actions upon the analytics, and the ways that ethical concerns were conceived. Specifically, one group of instructors used analytics to help students get aligned to and engaged in the course, whereas the other group used analytics to align the course to meet students’ needs. Instructors in both profiles saw ethical questions as central to their learning analytics use, with instructors in one profile focusing on transparency and the other on student privacy and agency. These findings suggest the need to view analytics use as an integrated component of instructor teaching practices and envision complementary sets of technical and pedagogical support that can best facilitate the distinct activities aligned with each profile.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {528–534},
numpages = {7},
keywords = {Data-informed teaching, Instructional dashboards, Teacher inquiry},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3375462.3375510,
author = {Torre, Manuel Valle and Tan, Esther and Hauff, Claudia},
title = {edX log data analysis made easy: introducing ELAT: An open-source, privacy-aware and browser-based edX log data analysis tool},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375510},
doi = {10.1145/3375462.3375510},
abstract = {Massive Open Online Courses (MOOCs), delivered on platforms such as edX and Coursera, have led to a surge in large-scale learning research. MOOC platforms gather a continuous stream of learner traces, which can amount to several Gigabytes per MOOC, that learning analytics researchers use to conduct exploratory analyses as well as to evaluate deployed interventions. edX has proven to be a popular platform for such experiments, as the data each MOOC generates is easily accessible to the institution running the MOOC. One of the issues researchers face is the preprocessing, cleaning and formatting of those large-scale learner traces. It is a tedious process that requires considerable computational skills. To reduce this burden, a number of tools have been proposed and released with the aim of simplifying this process. Those tools though still have a significant setup cost, are already out-of-date or require already preprocessed data as a starting point. In contrast, in this paper we introduce ELAT, the edX Log file Analysis Tool, which is browser-based (i.e., no setup costs), keeps the data local (i.e., no server is necessary and the privacy-sensitive learner data is not send anywhere) and takes edX data dumps as input. ELAT does not only process the raw data, but also generates semantically meaningful units (learner sessions instead of just click events) that are visualized in various ways (learning paths, forum participation, video watching sequences). We report on two evaluations we conducted: (i) a technological evaluation and a (ii) user study with potential end users of ELAT. ELAT is open-source and available at https://mvallet91.github.io/ELAT/.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {502–511},
numpages = {10},
keywords = {edX log, learning analytics, log data analysis, massive open online course},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3375462.3375487,
author = {Saint, John and Ga\v{s}evi\'{c}, Dragan and Matcha, Wannisa and Uzir, Nora'Ayu Ahmad and Pardo, Abelardo},
title = {Combining analytic methods to unlock sequential and temporal patterns of self-regulated learning},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375487},
doi = {10.1145/3375462.3375487},
abstract = {The temporal and sequential nature of learning is receiving increasing focus in Learning Analytics circles. The desire to embed studies in recognised theories of self-regulated learning (SRL) has led researchers to conceptualise learning as a process that unfolds and changes over time. To that end, a body of research knowledge is growing which states that traditional frequency-based correlational studies are limited in narrative impact. To further explore this, we analysed trace data collected from online activities of a sample of 239 computer engineering undergraduate students enrolled on a course that followed a flipped class-room pedagogy. We employed SRL categorisation of micro-level processes based on a recognised model of learning, and then analysed the data using: 1) simple frequency measures; 2) epistemic network analysis; 3) temporal process mining; and 4) stochastic process mining. We found that a combination of analyses provided us with a richer insight into SRL behaviours than any one single method. We found that better performing learners employed more optimal behaviours in their navigation through the course's learning management system.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {402–411},
numpages = {10},
keywords = {epistemic network analysis, learning analytics, micro-level processes, process mining, self-regulated learning},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/2876034.2893402,
author = {Pijeira D\'{\i}az, H\'{e}ctor J. and Santofimia Ruiz, Javier and Ruip\'{e}rez-Valiente, Jos\'{e} A. and Mu\~{n}oz-Merino, Pedro J. and Delgado Kloos, Carlos},
title = {A Demonstration of ANALYSE: A Learning Analytics Tool for Open edX},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2893402},
doi = {10.1145/2876034.2893402},
abstract = {Education is being powered by technology in many ways. One of the main advantages is making use of data to improve the learning process. The massive open online course (MOOC) phenomenon became viral some years ago, and with it many different platforms emerged. However most of them are proprietary solutions (i.e. Coursera, Udacity) and cannot be used by interested stakeholders. At the moment Open edX is placed as the primary open source application to support MOOCs. The community using Open edX is growing at a fast pace with many interested institutions. Nevertheless, the learning analytics support of Open edX is still in its first steps. In this paper we present an overview and demonstration of ANALYSE, an open source learning analytics tool for Open edX. ANALYSE includes currently 12 new visualizations that can be used by both instructors and students.},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {329–330},
numpages = {2},
keywords = {learning analytics, moocs, open edx, visualizations},
location = {Edinburgh, Scotland, UK},
series = {L@S '16}
}

@inproceedings{10.1145/3506860.3506913,
author = {Rotelli, Daniela and Monreale, Anna},
title = {Time-on-Task Estimation by data-driven Outlier Detection based on Learning Activities},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506913},
doi = {10.1145/3506860.3506913},
abstract = {Temporal analysis has been demonstrated to be relevant in Learning Analytics research, and capturing time-on-task, i.e., the amount of time spent by students in quality learning, as a proxy to model learning behaviour, predict performance, and avoid drop-out has been the focus of a number of investigations. Nonetheless, most studies do not provide enough information on how their data were prepared for their findings to be easily replicated, even though data pre-processing decisions have an impact on the analysis’ outcomes and can lead to inaccurate predictions. One of the key aspects in the preparation of learning data for temporal analysis is the detection of anomalous values of temporal duration of students’ activities. Most of the works in the literature address this problem without taking into account the fact that different activities can have very different typical execution times. In this paper, we propose a methodology for estimating time-on-task that starts with a well-defined data consolidation and then applies an outlier detection strategy to the data based on a distinct study of each learning activity and its peculiarities. Our real-world data experiments show that the proposed methodology outperforms the current state of the art, providing more accurate time estimations for students’ learning tasks.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {336–346},
numpages = {11},
keywords = {Data consolidation, Data pre-processing, Learning log data, Outlier detection., Time-on-task},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3303772.3303776,
author = {Di Mitri, Daniele and Schneider, Jan and Klemke, Roland and Specht, Marcus and Drachsler, Hendrik},
title = {Read Between the Lines: An Annotation Tool for Multimodal Data for Learning},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303776},
doi = {10.1145/3303772.3303776},
abstract = {This paper introduces the Visual Inspection Tool (VIT) which supports researchers in the annotation of multimodal data as well as the processing and exploitation for learning purposes. While most of the existing Multimodal Learning Analytics (MMLA) solutions are tailor-made for specific learning tasks and sensors, the VIT addresses the data annotation for different types of learning tasks that can be captured with a customisable set of sensors in a flexible way. The VIT supports MMLA researchers in 1) triangulating multimodal data with video recordings; 2) segmenting the multimodal data into time-intervals and adding annotations to the time-intervals; 3) downloading the annotated dataset and using it for multimodal data analysis. The VIT is a crucial component that was so far missing in the available tools for MMLA research. By filling this gap we also identified an integrated workflow that characterises current MMLA research. We call this workflow the Multimodal Learning Analytics Pipeline, a toolkit for orchestration, the use and application of various MMLA tools.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {51–60},
numpages = {10},
keywords = {Internet of Things, Learning Analytics, Multimodal data, sensors},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3636555.3636937,
author = {Booth, Brandon M. and Jacobs, Jennifer and Bush, Jeffrey B. and Milne, Brent and Fischaber, Tom and DMello, Sidney K.},
title = {Human-tutor Coaching Technology (HTCT): Automated Discourse Analytics in a Coached Tutoring Model},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636937},
doi = {10.1145/3636555.3636937},
abstract = {High-dosage tutoring has become an effective strategy for bolstering K-12 academic performance and combating education declines accelerated by the COVID-19 pandemic. To achieve high-dosage tutoring at scale, tutoring programs often rely on paraprofessional tutors—recruited tutors with college degrees who lack formal training in education—however, these tutors may require consistent and targeted feedback from instructional coaches for improvement. Accordingly, we developed a human-tutor coaching technology (HTCT) system to automatically extract discourse analytics pertaining to accountable talk moves (or academically productive talk) from tutoring sessions and provide feedback visualizations to coaches to aid their coaching sessions with tutors. We deployed HTCT in a user study using a virtual tutoring platform with 11 real coaches, 40 tutors, and their students to investigate coaches’ usage patterns with HTCT, perceptions of its utility, and changes in tutors’ talk. Overall, we found that coaches had positive perceptions of the system. We also observed an increase in accountable talk from tutors whose coaches used HTCT compared to tutors whose coaches did not. We discuss implications for AI-based applications which offer coaches a promising way to provide personalized, automated, and data-driven feedback to scale high-dosage tutoring.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {725–735},
numpages = {11},
keywords = {coached tutoring, discourse analytics, in situ user study, natural language processing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3576050.3576100,
author = {Hutchins, Nicole and Biswas, Gautam},
title = {Using Teacher Dashboards to Customize Lesson Plans for a Problem-Based, Middle School STEM Curriculum},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576100},
doi = {10.1145/3576050.3576100},
abstract = {Keeping K-12 teachers engaged during students’ learning and problem solving in technology-enhanced, integrated problem-based learning (PBL) has been shown to support deeper student involvement, and, therefore, better success learning difficult science, computing, and engineering concepts and practices. However, students’ learning processes and corresponding difficulties are not easily noticed by teachers as students learn from these environments as processes are captured through mouse clicks, drag and drop actions, and other low-level activities. As such, teachers find it difficult to set up meaningful interactions with students while also maintaining the focus on student-centered learning. Little research has examined dashboard-supported responsive teaching practices for K-12 PBL. This study examined 8 teachers as they used a co-designed teacher dashboard to assess and respond to students’ learning and strategies during an integrated, PBL STEM curriculum. Teachers completed a series of 5 “planning period simulations” leveraging the dashboard and think-aloud protocols were implemented, supported by semi-structured interview questions, to enable the teachers to verbalize their thought and evaluation processes. Content analysis and epistemic network analysis were conducted to analyze the simulations. Understanding how teachers use dashboards to support evidence-based teaching practices during technology-enhanced curricula is critical for improving teacher support and preparation.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {324–332},
numpages = {9},
keywords = {co-design, computational modeling, responsive teaching, teacher dashboards},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3303772.3303825,
author = {Mangaroska, Katerina and Vesin, Boban and Giannakos, Michail},
title = {Cross-Platform Analytics: A step towards Personalization and Adaptation in Education},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303825},
doi = {10.1145/3303772.3303825},
abstract = {Learning analytics are used to track learners' progress and empower educators and learners to make well-informed data-driven decisions. However, due to the distributed nature of the learning process, analytics need to be combined to offer broader insights into learner's behavior and experiences. Consequently, this paper presents an architecture of a learning ecosystem, that integrates and utilizes cross-platform analytics. The proposed cross-platform architecture has been put into practice via a Java programming course. After a series of studies, a proof of concept was derived that shows how cross-platform analytics amplify the relevant analytics for the learning process. Such analytics could improve educators' and learners' understanding of their own actions and the environments in which learning occurs.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {71–75},
numpages = {5},
keywords = {architecture, learning analytics, multimodal systems},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3170358.3170419,
author = {Broos, Tom and Verbert, Katrien and Langie, Greet and Van Soom, Carolien and De Laet, Tinne},
title = {Multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in flanders},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170419},
doi = {10.1145/3170358.3170419},
abstract = {Our work focuses on a multi-institutional implementation and evaluation of a Learning Analytics Dashboards (LAD) at scale, providing feedback to N=337 aspiring STEM (science, technology, engineering and mathematics) students participating in a region-wide positioning test before entering the study program. Study advisors were closely involved in the design and evaluation of the dashboard. The multi-institutional context of our case study requires careful consideration of external stakeholders and data ownership and portability issues, which gives shape to the technical design of the LAD. Our approach confirms students as active agents with data ownership, using an anonymous feedback code to access the LAD and to enable students to share their data with institutions at their discretion. Other distinguishing features of the LAD are the support for active content contribution by study advisors and LATEX type-setting of question item feedback to enhance visual recognizability. We present our lessons learnt from a first iteration in production.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {51–55},
numpages = {5},
keywords = {case study, feedback, higher education, learning analytics, positioning test, student dashboard},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/3375462.3375499,
author = {Lecailliez, Louis and Flanagan, Brendan and Chen, Mei-Rong Alice and Ogata, Hiroaki},
title = {Smart dictionary for e-book reading analytics},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375499},
doi = {10.1145/3375462.3375499},
abstract = {Reading, be it intensive or extensive, is one of the key skills required to master English as a foreign language (EFL) learner. Computerized e-book systems provide convenient access to learning materials inside and outside class. Students may regularly check the meaning of a word or expression using a separate tool to progress on their reading, which is not only disruptive but can lead to other learning problems. An example of a particular issue faced in EFL is when a student learns an inappropriate meaning of a polysemous word for the context in which it is presented. This is also a problem for teachers as they often need to investigate the cause. In this paper, we propose a smart dictionary integrated into an e-book reading platform. It allows the learner to search and note word definitions directly with the purpose of reducing context switching and improve vocabulary retention. Finally, we propose that learner interactions with the system can be analyzed to support EFL teachers in identifying possible problems that arise through dictionary use while reading.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {89–93},
numpages = {5},
keywords = {dictionary, e-book, english education, learning analytics},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3630970.3631007,
author = {Martinez-Maldonado, Roberto},
title = {Data Storytelling: Revolutionising Human-Data Interaction or Just Passing Hype?},
year = {2024},
isbn = {9798400716577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630970.3631007},
doi = {10.1145/3630970.3631007},
abstract = {Supporting stakeholders in various sectors to interpret dashboards and visualisations presents significant design challenges that might often be overlooked. The interpretation of visualised data by decision-makers and professionals is essentially the construction of a narrative about the underlying processes. Implementing data storytelling techniques in the design of these visualisations can foster deeper insights by aligning the intended objectives, goals, and outcomes with visual elements. The purpose of this tutorial is to guide participants in integrating data storytelling techniques into their visualisation and dashboard designs, ensuring the communication of meaningful insights.},
booktitle = {Proceedings of the XI Latin American Conference on Human Computer Interaction},
articleno = {37},
numpages = {2},
keywords = {data storytelling, data visualisation, human-data interaction},
location = {Puebla, Mexico},
series = {CLIHC '23}
}

@inproceedings{10.1145/3636555.3636902,
author = {Baucks, Frederik and Schmucker, Robin and Wiskott, Laurenz},
title = {Gaining Insights into Course Difficulty Variations Using Item Response Theory},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636902},
doi = {10.1145/3636555.3636902},
abstract = {Curriculum analytics (CA) studies curriculum structure and student data to ensure the quality of educational programs. To gain statistical robustness, most existing CA techniques rely on the assumption of time-invariant course difficulty, preventing them from capturing variations that might occur over time. However, ensuring low temporal variation in course difficulty is crucial to warrant fairness in treating individual student cohorts and consistency in degree outcomes. We introduce item response theory (IRT) as a CA methodology that enables us to address the open problem of monitoring course difficulty variations over time. We use statistical criteria to quantify the degree to which course performance data meets IRT’s theoretical assumptions and verify validity and reliability of IRT-based course difficulty estimates. Using data from 664 Computer Science and 1,355 Mechanical Engineering undergraduate students, we show how IRT can yield valuable CA insights: First, by revealing temporal variations in course difficulty over several years, we find that course difficulty has systematically shifted downward during the COVID-19 pandemic. Second, time-dependent course difficulty and cohort performance variations confound conventional course pass rate measures. We introduce IRT-adjusted pass rates as an alternative to account for these factors. Our findings affect policymakers, student advisors, accreditation, and course articulation.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {450–461},
numpages = {12},
keywords = {curriculum analytics, fairness., item response theory},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3448139.3448160,
author = {Matz, Rebecca and Schulz, Kyle and Hanley, Elizabeth and Derry, Holly and Hayward, Benjamin and Koester, Benjamin and Hayward, Caitlin and McKay, Timothy},
title = {Analyzing the Efficacy of ECoach in Supporting Gateway Course Success Through Tailored Support},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448160},
doi = {10.1145/3448139.3448160},
abstract = {Large courses act as gateways for college students and often have poor outcomes, particularly in STEM fields where the pace of improvement has been glacial. Students encounter barriers to persistence like low grades, competitive cultures, and a lack of motivation and belonging. Tailored technology systems offer one promising path forward. In this observational study, we report on the use of one such system, called ECoach, that provides students resources based on their psychosocial profile, performance metrics, and pattern of ECoach usage. We investigated ECoach efficacy in five courses enrolling 3,599 students using a clustering method to group users by engagement level and subsequent regression analyses. We present results showing significant positive relationships with small effect sizes between ECoach engagement and final course grade as well as grade anomaly, a performance measure that takes into account prior course grades. The courses with the strongest relationship between ECoach engagement and performance offered nominal extra credit incentives yet show improved grades well above this “investment” from instructors. Such small incentives may act as a catalyst that spurs deeper engagement with the platform. The impact of specific ECoach features and areas for future study are discussed.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {216–225},
numpages = {10},
keywords = {Academic achievement, STEM, educational technology, feedback, higher education, large enrollment courses, learning analytics, undergraduate education},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3375462.3375489,
author = {Hilliger, Isabel and Aguirre, Camila and Miranda, Constanza and Celis, Sergio and P\'{e}rez-Sanagust\'{\i}n, Mar},
title = {Design of a curriculum analytics tool to support continuous improvement processes in higher education},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375489},
doi = {10.1145/3375462.3375489},
abstract = {Curriculum analytics (CA) emerged as a sub-field of learning analytics, aiming to use evidence to drive curriculum decision-making and program improvement. However, its overall impact on program outcomes remains unknown. In this context, this paper presents work-in-progress of a large research project to understand how CA could support continuous improvement processes at a program-level. We followed an approach based on design-based research to develop a CA tool: The Integrative Learning Design Framework. This paper describes three out of four phases of this framework and its main results, including the evaluation of the local impact of this CA tool. This evaluation consisted of an instrumental case study to evaluate its use to support 124 teaching staff in a 3-year continuous improvement process in a Latin American university. Lessons learned indicate that the tool helped staff to collect information for curriculum discussions, facilitating the availability of evidence regarding student competency attainment. To generalize these lessons, future work will consist of evaluating the tool in different university settings.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {181–186},
numpages = {6},
keywords = {curriculum analytics, higher education, learning analytics},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3303772.3303787,
author = {Matcha, Wannisa and Ga\v{s}evi\'{c}, Dragan and Uzir, Nora'Ayu Ahmad and Jovanovi\'{c}, Jelena and Pardo, Abelardo},
title = {Analytics of Learning Strategies: Associations with Academic Performance and Feedback},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303787},
doi = {10.1145/3303772.3303787},
abstract = {Learning analytics has the potential to detect and explain characteristics of learning strategies through analysis of trace data and communicate the findings via feedback. However, the role of learning analytics-based feedback in selection and regulation of learning strategies is still insufficiently explored and understood. This research aims to examine the sequential and temporal characteristics of learning strategies and investigate their association with feedback. Three years of trace data were collected from online pre-class activities of a flipped classroom, where different types of feedback were employed in each year. Clustering, sequence mining, and process mining were used to detect and interpret learning tactics and strategies. Inferential statistics were used to examine the association of feedback with the learning performance and the detected learning strategies. The results suggest a positive association between the personalised feedback and the effective strategies.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {461–470},
numpages = {10},
keywords = {Data Mining, Feedback, Learning Analytics, Learning Strategies, Learning Tactics, Self-regulated Learning},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3375462.3375494,
author = {Van Goidsenhoven, Steven and Bogdanova, Daria and Deeva, Galina and Broucke, Seppe vanden and De Weerdt, Jochen and Snoeck, Monique},
title = {Predicting student success in a blended learning environment},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375494},
doi = {10.1145/3375462.3375494},
abstract = {Blended learning is gaining ground in contemporary education. However, studies on predictive learning analytics in the context of blended learning remain relatively scarce compared to Massive Open Online Courses (MOOCs), where such applications have gained a strong foothold. Data sets obtained from blended learning environments suffer from a high dimensionality and typically expose a limited number of instances, which makes predictive analysis a challenging task. In this work, we explore the log data of a master-level blended course to predict the students' grades based entirely on the data obtained from an online module (a small private online course), using and comparing logistic regression and random forest-based predictive models. The results of the analysis show that, despite the limited data, success vs. fail predictions can be made as early as in the middle of the course. This could be used in the future for timely interventions, both for failure prevention as well as for reinforcing positive learning behaviours of students.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {17–25},
numpages = {9},
keywords = {blended learning, e-learning, feature extraction, grade prediction, learning analytics, logistic regression, machine learning, random forest classification},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3448139.3448179,
author = {Jivet, Ioana and Wong, Jacqueline and Scheffel, Maren and Valle Torre, Manuel and Specht, Marcus and Drachsler, Hendrik},
title = {Quantum of Choice: How learners’ feedback monitoring decisions, goals and self-regulated learning skills are related},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448179},
doi = {10.1145/3448139.3448179},
abstract = {Learning analytics dashboards (LADs) are designed as feedback tools for learners, but until recently, learners rarely have had a say in how LADs are designed and what information they receive through LADs. To overcome this shortcoming, we have developed a customisable LAD for Coursera MOOCs on which learners can set goals and choose indicators to monitor. Following a mixed-methods approach, we analyse 401 learners’ indicator selection behaviour in order to understand the decisions they make on the LAD and whether learner goals and self-regulated learning skills influence these decisions. We found that learners overwhelmingly chose indicators about completed activities. Goals are not associated with indicator selection behaviour, while help-seeking skills predict learners’ choice of monitoring their engagement in discussions and time management skills predict learners’ interest in procrastination indicators. The findings have implications for our understanding of learners’ use of LADs and their design.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {416–427},
numpages = {12},
keywords = {customisable dashboard, feedback, learner goal, learning dashboard, self-regulated learning},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/2883851.2883911,
author = {Khan, Imran and Pardo, Abelardo},
title = {Data2U: scalable real time student feedback in active learning environments},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883911},
doi = {10.1145/2883851.2883911},
abstract = {The majority of applications and products that use learning analytics to understand and improve learning experiences assume the creation of actionable items that will affect students through an intermediary. Much less focus is devoted to exploring how to provide insight directly to students. Furthermore, student engagement has always been a relevant aspect to increase the quality of a learning experience. Learning analytics techniques can be used to provide real-time insight tightly integrated with the learning outcomes directly to the students. This paper describes a case study deployed in a first year engineering course using a flipped learning strategy to explore the behavior of students interacting with a dashboard updated in real time providing indicators of their engagement with the course activities. The results show different patterns of use and their evolution throughout the experience and shed some light on how students perceived this resource.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {249–253},
numpages = {5},
keywords = {dashboard, feedback, learning analytics, visualizations},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3706468.3706528,
author = {Fang, Yu and Huang, Shihong and Ogan, Amy},
title = {A Cross-Cultural Confusion Model for Detecting and Evaluating Students’ Confusion In a Large Classroom},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706528},
doi = {10.1145/3706468.3706528},
abstract = {In traditional lecture delivery setting, it is very challenging to identify which part of the lecture material that students are struggling with. One approach to identify difficult concepts is to capture students’ confusion during class time. However, most existing confusion detectors focus on an individual student rather than a classroom, and only on a single ethnicity group which could propagate bias when developing pedagogical technologies. In this paper, we leverage two existing ‘Confused’ facial expression datasets (DAiSEE and DevEmo) with an East Asian ‘Confused’ facial expression dataset that we collected. Through model performance and explainableAI, we address potential cultural biases in detecting emotions, particularly in confusion, and identified culturally-specific features that align with prior research. As a proof-of-concept, we deployed this cross-cultural confusion machine learning model in a live semester-long class. This work to integrate cross-cultural facial features highlights the importance of fostering inclusivity in educational technologies.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {473–483},
numpages = {11},
keywords = {Cross-cultural models, Confusion, Affective computing, Retrieval-augmented generation},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3375462.3375502,
author = {Fadljevi\'{c}, Leon and Maitz, Katharina and Kowald, Dominik and Pammer-Schindler, Viktoria and Gasteiger-Klicpera, Barbara},
title = {Slow is good: the effect of diligence on student performance in the case of an adaptive learning system for health literacy},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375502},
doi = {10.1145/3375462.3375502},
abstract = {This paper describes the analysis of temporal behavior of 11--15 year old students in a heavily instructionally designed adaptive e-learning environment. The e-learning system is designed to support student's acquisition of health literacy. The system adapts text difficulty depending on students' reading competence, grouping students into four competence levels. Content for the four levels of reading competence was created by clinical psychologists, pedagogues and medicine students. The e-learning system consists of an initial reading competence assessment, texts about health issues, and learning tasks related to these texts. The research question we investigate in this work is whether temporal behavior is a differentiator between students despite the system's adaptation to students' reading competence, and despite students having comparatively little freedom of action within the system. Further, we also investigated the correlation of temporal behaviour with performance. Unsupervised clustering clearly separates students into slow and fast students with respect to the time they take to complete tasks. Furthermore, topic completion time is linearly correlated with performance in the tasks. This means that we interpret working slowly in this case as diligence, which leads to more correct answers, even though the level of text difficulty matches student's reading competence. This result also points to the design opportunity to integrate advice on overarching learning strategies, such as working diligently instead of rushing through, into the student's overall learning activity. This can be done either by teachers, or via additional adaptive learning guidance within the system.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {112–117},
numpages = {6},
keywords = {adaptive e-learning system, clustering, differentiation, diversity, health literacy, learning analytics, reading competence},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3027385.3029483,
author = {Hu, Xiao and Hou, Xiangyu and Lei, Chi-Un and Yang, Chengrui and Ng, Jeremy},
title = {An outcome-based dashboard for moodle and Open edX},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029483},
doi = {10.1145/3027385.3029483},
abstract = {This poster presents a cross-platform learning analytics dashboard on Moodle and Open edX for monitoring outcome-based learning progress. The dashboard visualizes students' interactions with the platforms in near real-time, aiming to help teachers and students monitor students' learning progress. The dashboard has been used in four large-size general education courses in a comprehensive university in Hong Kong, undergoing evaluation and improvement.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {604–605},
numpages = {2},
keywords = {Open edX, dashboard, moodle, outcome-based learning},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3636555.3636933,
author = {Szymanski, Maxwell and Ooge, Jeroen and De Croon, Robin and Vanden Abeele, Vero and Verbert, Katrien},
title = {Feedback, Control, or Explanations? Supporting Teachers With Steerable Distractor-Generating AI},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636933},
doi = {10.1145/3636555.3636933},
abstract = {Recent advancements in Educational AI have focused on models for automatic question generation. Yet, these advancements face challenges: (1) their "black-box" nature limits transparency, thereby obscuring the decision-making process; and (2) their novelty sometimes causes inaccuracies due to limited feedback systems. Explainable AI (XAI) aims to address the first limitation by clarifying model decisions, while Interactive Machine Learning (IML) emphasises user feedback and model refinement. However, both XAI and IML solutions primarily serve AI experts, often neglecting novices like teachers. Such oversights lead to issues like misaligned expectations and reduced trust. Following the user-centred design method, we collaborated with teachers and ed-tech experts to develop an AI-aided system for generating multiple-choice question distractors, which incorporates feedback, control, and visual explanations. Evaluating these through semi-structured interviews with 12 teachers, we found a strong preference for the feedback feature, enabling teacher-guided AI improvements. Control and explanations’ usefulness was largely dependent on model performance: they were valued when the model performed well. If the model did not perform well, teachers sought context over AI-centric explanations, suggesting a tilt towards data-centric explanations. Based on these results, we propose guidelines for creating tools that enable teachers to steer and interact with question-generating AI models.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {690–700},
numpages = {11},
keywords = {Interactive Machine Learning, XAI, automated question generation, user control, user studies},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3027385.3029433,
author = {Vigentini, Lorenzo and Le\'{o}n Urrutia, Manuel and Fields, Ben},
title = {FutureLearn data: what we currently have, what we are learning and how it is demonstrating learning in MOOCs},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029433},
doi = {10.1145/3027385.3029433},
abstract = {Compared to other platforms such as Coursera and EdX, FutureLearn is a relatively new player in the MOOC arena and received limited coverage in the Learning Analytics and Educational Data Mining research. Founded by a partnership between the Open University in the UK, the BBC, The British Library and (originally) 12 universities in the UK, FutureLearn has two distinctive features relevant to the way their data is displayed and analyzed: 1) it was designed with a specific educational philosophy in mind which focuses on the social dimension of learning and 2) every learning activity provide opportunities for formal discussion and commenting. This workshop provides an opportunity to invite contributions and connect individual and groups to share their research activities on an international stage. As the first of its kind, this workshop will bring in a number of scholars and practitioners, as well as data scientists and analyst involved in the reporting, researching and developments emerging from the data offered by the platform.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {512–513},
numpages = {2},
keywords = {MOOCs, learning analytics, visualization dashboard},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3375462.3375527,
author = {Iraj, Hamideh and Fudge, Anthea and Faulkner, Margaret and Pardo, Abelardo and Kovanovi\'{c}, Vitomir},
title = {Understanding students' engagement with personalised feedback messages},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375527},
doi = {10.1145/3375462.3375527},
abstract = {Feedback is a major factor of student success within higher education learning. However, recent changes - such as increased class sizes and socio-economic diversity of the student population - challenged the provision of effective student feedback. Although the use of educational technology for personalised feedback to diverse students has gained traction, the feedback gap still exists: educators wonder which students respond to feedback and which do not. In this study, a set of trackable Call to Action (CTA) links was embedded in two sets of feedback messages focusing on students' time management, with the goal of (1) examining the association between feedback engagement and course success and (2), to predict students' reaction to provided feedback. We also conducted two focus groups to further examine students' perception of provided feedback messages. Our results revealed that early engagement with the feedback was associated with higher chances of succeeding in the course. Likewise, previous engagement with feedback was highly predictive of students' engagement in the future, and also that certain student sub-populations, (e.g., female students), were more likely to engage than others. Such insight enables instructors to ask "why" questions, improve feedback processes and narrow the feedback gap. Practical implications of our findings are further discussed.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {438–447},
numpages = {10},
keywords = {data-driven approaches, feedback, feedback gap, higher education, learning analytics},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/2669711.2669909,
author = {Hern\'{a}ndez-Garc\'{\i}a, \'{A}ngel and Conde, Miguel \'{A}ngel},
title = {Dealing with complexity: educational data and tools for learning analytics},
year = {2014},
isbn = {9781450328968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669711.2669909},
doi = {10.1145/2669711.2669909},
abstract = {The evolution of information technologies and their widespread use have caused an increase in complexity of the educational landscape, as institutions and instructors try to absorb and incorporate these innovations to learning processes. This in turn poses new and countless new challenges to educational research in general, and to new disciplines based on educational data analysis such as learning analytics in particular. In this paper, we introduce the Track on Learning Analytics within the Technological Ecosystems for Enhancing Multiculturality 2014 Conference, a track that aims to present new approaches that allow dealing with this complexity and solving some of these challenges.The paper provides an overview of the motivations behind the proposal of this track, with a general introduction to learning analytics in this complex context and a presentation of the main challenges in current learning analytics research, both from a data analysis perspective and a tool analysis approach; this introduction is followed by an insight of the submission management and participants' selection process. Then, a detailed summary of the manuscripts accepted for participation in the conference is presented.},
booktitle = {Proceedings of the Second International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {263–268},
numpages = {6},
keywords = {academic analytics, educational data mining, educational technologies, knowledge management, learning analytics, predictive analytics, visual analytics},
location = {Salamanca, Spain},
series = {TEEM '14}
}

@inproceedings{10.1145/3506860.3506939,
author = {Tsai, Yi-Shan and Singh, Shaveen and Rakovic, Mladen and Lim, Lisa-Angelique and Roychoudhury, Anushka and Gasevic, Dragan},
title = {Charting Design Needs and Strategic Approaches for Academic Analytics Systems through Co-Design},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506939},
doi = {10.1145/3506860.3506939},
abstract = {Academic analytics focuses on collecting, analysing and visualising educational data to generate institutional insights and improve decision-making for academic purposes. However, challenges that arise from navigating a complex organisational structure when introducing analytics systems have called for the need to engage key stakeholders widely to cultivate a shared vision and ensure that implemented systems create desired value. This paper presents a study that takes co-design steps to identify design needs and strategic approaches for the adoption of academic analytics, which serves the purpose of enhancing the measurement of educational quality utilising institutional data. Through semi-structured interviews with 54 educational stakeholders at a large research university, we identified particular interest in measuring student engagement and the performance of courses and programmes. Based on the observed perceptions and concerns regarding data use to measure or evaluate these areas, implications for adoption strategy of academic analytics, such as leadership involvement, communication, and training, are discussed.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {381–391},
numpages = {11},
keywords = {academic analytics, co-design, educational quality, higher education, implementation strategy},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3576050.3576072,
author = {Han, Songhee and Ji, Hyangeun and Jiang, Zilu and West, Michael and Liu, Min},
title = {What do students want to know while taking massive open online courses? Examining massive open online course students’ needs based on online forum discussions from the Universal Design for Learning approach},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576072},
doi = {10.1145/3576050.3576072},
abstract = {We identified the nine most dominant massive open online course (MOOC) students’ needs by topic modeling and qualitative analysis of forum discussion posts (n = 3645) among students, staff, and instructors from 21 courses. We examined the implications of these needs using three main Universal Design for Learning (UDL) principles (representation, action and expression, and engagement). We then offered suggestions for what course providers can do to promote an equitable learning experience for MOOC students. The three suggestions are as follows: (1) providing tools such as a direct messaging application to encourage students’ socializing behaviors, (2) modifying course activities to promote more hands-on projects and sharing them, and (3) implementing a bidirectional channel, such as a natural language processing-based chatbot so that students can access useful information whenever they feel the need. We argue that it is critical to include minority students’ voices when examining needs in courses, and our methodology reflects this purpose. We also discuss how the UDL approach helped us recognize students’ needs, create more accessible MOOC learning experiences, and explore future research directions.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {572–578},
numpages = {7},
keywords = {Massive open online courses, Natural language processing, Universal Design for Learning},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/2883851.2883930,
author = {Schwendimann, Beat A. and Rodr\'{\i}guez-Triana, Mar\'{\i}a Jes\'{u}s and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
title = {Understanding learning at a glance: an overview of learning dashboard studies},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883930},
doi = {10.1145/2883851.2883930},
abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the final analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dashboard design options.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {532–533},
numpages = {2},
keywords = {dashboards, educational data mining, information visualization, learning analytics, systematic review},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3506860.3506882,
author = {Takami, Kyosuke and Dai, Yiling and Flanagan, Brendan and Ogata, Hiroaki},
title = {Educational Explainable Recommender Usage and its Effectiveness in High School Summer Vacation Assignment},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506882},
doi = {10.1145/3506860.3506882},
abstract = {Explainable recommendations, which provide explanations about why an item is recommended, help to improve the transparency, persuasiveness, and trustworthiness. However, few research in educational technology utilize explainable recommendations. We developed an explanation generator using the parameters from Bayesian knowledge tracing models. We used this educational explainable recommendation system to investigate the effects of explanation on the summer vacation assignment for high school students. Comparing the click counts of recommended quizzes with and without explanations, we found that the number of clicks was significantly higher for quizzes with explanations. Furthermore, system usage pattern mining revealed that students can be divided to three clusters— none, steady and late users. In the cluster of steady users, recommended quizzes with explanations were continuously used. These results suggest the effectiveness of an explainable recommendation system in the field of education.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {458–464},
numpages = {7},
keywords = {A/B test, Effectiveness of explanation, Explainable recommendation, Long vacation period, Pattern mining},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3027385.3027441,
author = {Diana, Nicholas and Eagle, Michael and Stamper, John and Grover, Shuchi and Bienkowski, Marie and Basu, Satabdi},
title = {An instructor dashboard for real-time analytics in interactive programming assignments},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027441},
doi = {10.1145/3027385.3027441},
abstract = {Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {272–279},
numpages = {8},
keywords = {dashboards, introductory programming, learning analytics, machine learning, peer tutors},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3448139.3448192,
author = {Jang, JiWoong and Lee, Jaewook and Echeverria, Vanessa and Lawrence, LuEttaMae and Aleven, Vincent},
title = {Explorations of Designing Spatial Classroom Analytics with Virtual Prototyping},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448192},
doi = {10.1145/3448139.3448192},
abstract = {Despite the potential of spatial displays for supporting teachers’ classroom orchestration through real-time classroom analytics, the process to design these displays is a challenging and under-explored topic in the learning analytics (LA) community. This paper proposes a mid-fidelity Virtual Prototyping method (VPM), which involves simulating a classroom environment and candidate designs in virtual space to address these challenges. VPM allows for rapid prototyping of spatial features, requires no specialized hardware, and enables teams to conduct remote evaluation sessions. We report observations and findings from an initial exploration with five potential users through a design process utilizing VPM to validate designs for an AR-based spatial display in the context of middle-school orchestration tools. We found that designs created using virtual prototyping sufficiently conveyed a sense of three-dimensionality to address subtle design issues like occlusion and depth perception. We discuss the opportunities and limitations of applying virtual prototyping, particularly its potential to allow for more robust co-design with stakeholders earlier in the design process.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {518–524},
numpages = {7},
keywords = {augmented reality, classroom analytics, mixed reality, spatial classroom displays, virtual prototyping},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3506860.3506887,
author = {Zhang, Tom and Taub, Michelle and Chen, Zhongzhou},
title = {A Multi-Level Trace Clustering Analysis Scheme for Measuring Students’ Self-Regulated Learning Behavior in a Mastery-Based Online Learning Environment},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506887},
doi = {10.1145/3506860.3506887},
abstract = {This study introduces a new analysis scheme to analyze trace data and visualize students’ self-regulated learning strategies in a mastery-based online learning modules platform. The pedagogical design of the platform resulted in fewer event types and less variability in student trace data. The current analysis scheme overcomes those challenges by conducting three levels of clustering analysis. On the event level, mixture-model fitting is employed to distinguish between abnormally short and normal assessment attempts and study events. On the module level, trace level clustering is performed with three different methods for generating distance metrics between traces, with the best performing output used in the next step. On the sequence level, trace level clustering is performed on top of module-level clusters to reveal students’ change of learning strategy over time. We demonstrated that distance metrics generated based on learning theory produced better clustering results than pure data-driven or hybrid methods. The analysis showed that most students started the semester with productive learning strategies, but a significant fraction shifted to a multitude of less productive strategies in response to increasing content difficulty and stress. The observations could prompt instructors to rethink conventional course structure and implement interventions to improve self-regulation at optimal times.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {197–207},
numpages = {11},
keywords = {Click-stream data, Online learning environments, Self-regulated learning},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3506860.3506917,
author = {Tavakoli, Mohammadreza and Faraji, Abdolali and Molavi, Mohammadreza and T. Mol, Stefan and Kismih\'{o}k, G\'{a}bor},
title = {Hybrid Human-AI Curriculum Development for Personalised Informal Learning Environments},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506917},
doi = {10.1145/3506860.3506917},
abstract = {Informal learning procedures have been changing extremely fast over the recent decades not only due to the advent of online learning, but also due to changes in what humans need to learn to meet their various life and career goals. Consequently, online, educational platforms are expected to provide personalized, up-to-date curricula to assist learners. Therefore, in this paper, we propose an Artificial Intelligence (AI) and Crowdsourcing based approach to create and update curricula for individual learners. We show the design of this curriculum development system prototype, in which contributors receive AI-based recommendations to be able to define and update high-level learning goals, skills, and learning topics together with associated learning content. This curriculum development system was also integrated into our personalized online learning platform. To evaluate our prototype we compared experts’ opinion with our system’s recommendations, and resulted in 89%, 79%, and 93% F1-scores when recommending skills, learning topics, and educational materials respectively. Also, we interviewed eight senior level experts from educational institutions and career consulting organizations. Interviewees agreed that our curriculum development method has high potential to support authoring activities in dynamic, personalized learning environments.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {563–569},
numpages = {7},
keywords = {Artificial Intelligence, Crowdsourcing, Curriculum Development, Informal Learning},
location = {Online, USA},
series = {LAK22}
}

@article{10.1145/3593240,
author = {Sabuncuoglu, Alpay and Sezgin, T. Metin},
title = {Developing a Multimodal Classroom Engagement Analysis Dashboard for Higher-Education},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593240},
doi = {10.1145/3593240},
abstract = {Developing learning analytics dashboards (LADs) is a growing research interest as online learning tools have become more accessible in K-12 and higher education settings. This paper reports our multimodal classroom engagement data analysis and dashboard design process and the resulting engagement dashboard. Our work stems from the importance of monitoring classroom engagement, which refers to students' active physical and cognitive involvement in learning that influences their motivation and success in a given course. To monitor this vital facade of learning, we developed an engagement dashboard using an iterative and user-centered process. We first created a multimodal machine learning model that utilizes face and pose features obtained from recent deep learning models. Then, we created a dashboard where users can view their engagement over time and discover their learning/teaching patterns. Finally, we conducted user studies with undergraduate and graduate-level participants to obtain feedback on our dashboard design. Our paper makes three contributions by (1) presenting a student-centric, open-source dashboard, (2) demonstrating a baseline architecture for engagement analysis using our open-access data, and (3) presenting user insights and design takeaways to inspire future LADs. We expect our research to guide the development of tools for novice teacher education, student self-evaluation, and engagement evaluation in crowded classrooms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {188},
numpages = {23},
keywords = {classroom engagement, interactive learning analytics dashboard, multimodal data analysis pipeline, multimodal learning dataset}
}

@inproceedings{10.1145/3170358.3170417,
author = {Millecamp, Martijn and Guti\'{e}rrez, Francisco and Charleer, Sven and Verbert, Katrien and De Laet, Tinne},
title = {A qualitative evaluation of a learning dashboard to support advisor-student dialogues},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170417},
doi = {10.1145/3170358.3170417},
abstract = {This paper presents an evaluation of a learning dashboard that supports the dialogue between a student and a study advisor. The dashboard was designed, developed, and evaluated in collaboration with study advisers. To ensure scalability to other contexts, the dashboard uses data that is commonly available at any higher education institute. It visualizes the grades of the student, an overview of the progress through the year, his/her position in comparison with peers, sliders to plan the next years and a prediction of the length of the bachelor program for this student in years based on historic data. The dashboard was deployed at KU Leuven, Belgium and used in September 2017 to support 224 sessions between students and study advisers. We observed twenty of these conversations. We also collected feedback from 101 students with questionnaires. Results of our observations indicate that the dashboard primarily triggers insights at the beginning of a conversation. The number of insights and the level of these insights (factual, interpretative and reflective) depends on the context of the conversation. Most insights were triggered in conversations with students doubting to continue the program, indicating that our dashboard is useful to support difficult decision-making processes.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {56–60},
numpages = {5},
keywords = {information visualization, insights, learning analytics dashboards, learning technologies},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/2883851.2883968,
author = {Berg, Alan and Scheffel, Maren and Drachsler, Hendrik and Ternier, Stefaan and Specht, Marcus},
title = {The dutch xAPI experience},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883968},
doi = {10.1145/2883851.2883968},
abstract = {We present the collected experiences since 2012 of the Dutch Special Interest Group (SIG) for Learning Analytics in the application of the xAPI standard. We have been experimenting and exchanging best practices around the application of xAPI in various contexts. The practices include different design patterns centered around Learning Record Stores. We present three projects that apply xAPI in very different ways and publish a consistent set of xAPI recipes.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {544–545},
numpages = {2},
keywords = {data silos, data standardization, learning analytics, learning record store, xAPI},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3448139.3448141,
author = {G\"{u}nther, Sebastian A.},
title = {The impact of social norms on students’ online learning behavior: Insights from two randomized controlled trials},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448141},
doi = {10.1145/3448139.3448141},
abstract = {The provision of comparative feedback is a promising approach in digital learning environments to support learners’ self-regulated learning. Yet, empirical evidence suggests that such feedback can sometimes backfire or may only help learners with relatively high self-regulated learning skills, potentially exacerbating educational inequality. In this paper, we try to overcome such drawbacks by re-evaluating a feedback system based on the social norms theory that has previously led to intriguing results: A social comparison component embedded into the learning platform of a blended learning course (elective module, 58 participants) considerably encouraged online learning during the semester. Moreover, there was no heterogeneity in the behavioral response, suggesting that all subgroups responded similarly to the feedback. To further shed light on the generalizability of these results, this paper presents a follow-up study. Specifically, we conducted a second experiment during the COVID-19 pandemic with a different university course (compulsory module, 118 participants) and a non-overlapping sample and find similar results. The feedback shifted students’ online learning from the end towards the middle of the semester. Overall, the findings suggest that our feedback system has a large impact on students’ online learning and that this desirable impact is present in all subgroup analyses.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {12–21},
numpages = {10},
keywords = {Online learning, behavioral intervention, feedback, field experiment, generalizability, replication study, social norms},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/3375462.3375475,
author = {Prestigiacomo, Rita and Hadgraft, Roger and Hunter, Jane and Locker, Lori and Knight, Simon and van den Hoven, Elise and Martinez-Maldonado, Roberto},
title = {Learning-centred translucence: an approach to understand how teachers talk about classroom data},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375475},
doi = {10.1145/3375462.3375475},
abstract = {Teachers are increasingly being encouraged to embrace evidence-based practices. Learning analytics (LA) offer great promise in supporting these by providing evidence for teachers and learners to make informed decisions and transform the educational experience. However, LA limitations and their uptake by educators are coming under critical scrutiny. This is in part due to the lack of involvement of teachers and learners in the design of LA tools. In this paper, we propose a human-centred approach to generate understanding of teachers' data needs through the lens of three key principles of translucence: visibility, awareness and accountability. We illustrate our approach through a participatory design sprint to identify how teachers talk about classroom data. We describe teachers' perspectives on the evidence they need for making better-informed decisions and discuss the implications of our approach for the design of human-centred LA in the next years.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {100–105},
numpages = {6},
keywords = {evidence-based decision-making, human-centred design},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3027385.3029461,
author = {Hansen, Cecilie Johanne Slokvik and Wasson, Barbara and Skretting, Hans and Netteland, Grete and Hirnstein, Marina},
title = {When learning is high stake},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029461},
doi = {10.1145/3027385.3029461},
abstract = {Firefighter learning is high stake. They need to maintain certain competence levels related to physical, mental, and firefighting and rescue skills in order to provide the public with a high level of emergency service. Fire and Rescue Services need to maintain an overview of the current competences of their personnel and to react when there is a competence gap. This poster presents our approach to using competence modelling, learner models, learning analytics, and visualisations in order provide insight into competence status and development on the individual, team, and organisation level, and to provide early-alerts and automated messages to instructors responsible for planning training activities, as well as to team leaders responsible for making decisions about teams in high stakes situations.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {564–565},
numpages = {2},
keywords = {competence development, learning analytics, open learner model, visualization},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3506860.3506892,
author = {Dood, Amber and Winograd, Blair and Finkenstaedt-Quinn, Solaire and Gere, Anne and Shultz, Ginger},
title = {PeerBERT: Automated Characterization of Peer Review Comments across Courses},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506892},
doi = {10.1145/3506860.3506892},
abstract = {Writing-to-learn pedagogies are an evidence-based practice known to aid students in constructing knowledge. Barriers exist for the implementation of such assignments; namely, instructors feel they do not have time to provide each student with feedback. To ease implementation of writing-to-learn assignments at scale, we have incorporated automated peer review, which facilitates peer review without input from the instructor. Participating in peer review can positively impact students’ learning and allow students to receive feedback on their writing. Instructors may want to monitor these peer interactions and gain insight into their students’ understanding using the feedback generated by their peers. To facilitate instructors’ use of the content from students’ peer review comments, we pre-trained a transformer model called PeerBERT. PeerBERT was fine-tuned on several downstream tasks to categorize students’ peer review comments as praise, problem/solution, or verification/summary. The model exhibits high accuracy, even across different peer review prompts, assignments, and courses. Additional downstream tasks label problem/solution peer review comments as one or more types: writing/formatting, missing content/needs elaboration, and incorrect content. This approach can help instructors pinpoint common issues in student writing by parsing out which comments are problem/solution and which type of problem/solution students identify.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {492–499},
numpages = {8},
keywords = {peer review, undergraduate education, writing-to-learn},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3576050.3576082,
author = {Song, Yukyeong and Xing, Wanli and Tian, Xiaoyi and Li, Chenglu},
title = {Are We on the Same Page? Modeling Linguistic Synchrony and Math Literacy in Mathematical Discussions},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576082},
doi = {10.1145/3576050.3576082},
abstract = {Mathematical discussions have become a popular educational strategy to promote math literacy. While some studies have associated math literacy with linguistic factors such as verbal ability and phonological skills, no studies have examined the relationship between linguistic synchrony and math literacy. In this study, we modeled linguistic synchrony and students’ math literacy from 20,776 online mathematical discussion threads between students and facilitators. We conducted Cross-Recurrence Quantification Analysis (CRQA) to calculate linguistic synchrony within each thread. The statistical testing result comparing CRQA indices between high and low math literacy groups shows that students with high math literacy have a significantly higher Recurrence Rate (RR), Number of Recurrence Lines (NRLINE), and the average Length of lines (L), but lower Determinism (DET) and normalized Entropy (rENTR). This result implies that students with high math literacy are more likely to share common words with facilitators, but they would paraphrase them. On the other hand, students with low math literacy tend to repeat the exact same phrases from the facilitators. The findings provide a better understanding of mathematical discussions and can potentially guide teachers in promoting effective mathematical discussions.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {599–605},
numpages = {7},
keywords = {cross-recurrence quantification analysis, linguistic synchrony, math literacy, mathematical discussion},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/2883851.2883945,
author = {McPherson, Jen and Tong, Huong Ly and Fatt, Scott J. and Liu, Danny Y. T.},
title = {Student perspectives on data provision and use: starting to unpack disciplinary differences},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883945},
doi = {10.1145/2883851.2883945},
abstract = {How can we best align learning analytics practices with disciplinary knowledge practices in order to support student learning? Although learning analytics itself is an interdisciplinary field, it tends to take a 'one-size-fits-all' approach to the collection, measurement, and reporting of data, overlooking disciplinary knowledge practices. In line with a recent trend in higher education research, this paper considers the contribution of a realist sociology of education to the field of learning analytics, drawing on findings from recent student focus groups at an Australian university. It examines what learners say about their data needs with reference to organizing principles underlying knowledge practices within their disciplines. The key contribution of this paper is a framework that could be used as the basis for aligning the provision and/or use of data in relation to curriculum, pedagogy, and assessment with disciplinary knowledge practices. The framework extends recent research in Legitimation Code Theory, which understands disciplinary differences in terms of the principles that underpin knowledge-building. The preliminary analysis presented here both provides a tool for ensuring a fit between learning analytics practices and disciplinary practices and standards for achievement, and signals disciplinarity as an important consideration in learning analytics practices.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {158–167},
numpages = {10},
keywords = {disciplinary differences, knowledge, learning analytics, legitimation code theory, sociology of education, student needs},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3448139.3448190,
author = {Xu, Yang and Wilson, Kevin},
title = {Early Alert Systems During a Pandemic: A Simulation Study on the Impact of Concept Drift},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448190},
doi = {10.1145/3448139.3448190},
abstract = {Predictions from early alert systems are increasingly being used by institutions to assist decision-making and support at-risk individuals. Concept drifts caused by the 2020 SARS-CoV-2 pandemic are threatening the performance and usefulness of the machine learning models that power these systems. In this paper, we present an analytical framework that uses imputation-based simulations to perform preliminary evaluation on the extent to which data quality and availability issues impact the performance of machine learning models. Guided by this framework, we studied how these issues would impact the performance of the high school dropout prediction model implemented in the Early Warning System (EWS). Results show that despite the disruptions, this model can still be reasonably useful in assisting decision-making. We discuss the implications of these findings in more general educational contexts and recommend steps in countering the challenges of using predictions from imperfect machine learning models in early alert systems and, more broadly, learning analytic research that uses longitudinal data.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {504–510},
numpages = {7},
keywords = {concept drift, dropout prediction, early alert system, imputation, pandemic, simulation},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/2883851.2883883,
author = {Pardo, Abelardo and Han, Feifei and Ellis, Robert A.},
title = {Exploring the relation between self-regulation, online activities, and academic performance: a case study},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883883},
doi = {10.1145/2883851.2883883},
abstract = {The areas of educational data mining and learning analytics focus on the extraction of knowledge and actionable items from data sets containing detailed information about students. However, the potential impact from these techniques is increased when properly contextualized within a learning environment. More studies are needed to explore the connection between student interactions, approaches to learning, and academic performance. Self-regulated learning (SRL) is defined as the extent to which a student is able to motivationally, metacognitively, and cognitively engage in a learning experience. SRL has been the focus of research in traditional classroom learning and is also argued to play a vital role in the online or blended learning contexts. In this paper, we study how SRL affects students' online interactions with various learning activities and its influence in academic performance. The results derived from a naturalistic experiment among a cohort of first year engineering students showed that positive self-regulated strategies (PSRS) and negative self-regulated strategies (NSRS) affected both the interaction with online activities and academic performance. NSRS directly predicted academic outcomes, whereas PSRS only contributed indirectly to academic performance via the interactions with online activities. These results point to concrete avenues to promote self-regulation among students in this type of learning contexts.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {422–429},
numpages = {8},
keywords = {SEM, higher education, learning analytics, self-regulation},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/2723576.2723625,
author = {Pardo, Abelardo and Ellis, Robert A. and Calvo, Rafael A.},
title = {Combining observational and experiential data to inform the redesign of learning activities},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723625},
doi = {10.1145/2723576.2723625},
abstract = {A main goal for learning analytics is to inform the design of a learning experience to improve its quality. The increasing presence of solutions based on big data has even questioned the validity of current scientific methods. Is this going to happen in the area of learning analytics? In this paper we postulate that if changes are driven solely by a digital footprint, there is a risk of focusing only on factors that are directly connected to numeric methods. However, if the changes are complemented with an understanding about how students approach their learning, the quality of the evidence used in the redesign is significantly increased. This reasoning is illustrated with a case study in which an initial set of activities for a first year engineering course were shaped based only on the student's digital footprint. These activities were significantly modified after collecting qualitative data about the students approach to learning. We conclude the paper arguing that the interpretation of the meaning of learning analytics is improved when combined with qualitative data which reveals how and why students engaged with the learning tasks in qualitatively different ways, which together provide a more informed basis for designing learning activities.},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {305–309},
numpages = {5},
keywords = {active learning, approaches to learning, interventions, learning analytics, mixed methods analysis},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1145/2883851.2883897,
author = {Pijeira-D\'{\i}az, H\'{e}ctor J. and Drachsler, Hendrik and J\"{a}rvel\"{a}, Sanna and Kirschner, Paul A.},
title = {Investigating collaborative learning success with physiological coupling indices based on electrodermal activity},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883897},
doi = {10.1145/2883851.2883897},
abstract = {Collaborative learning is considered a critical 21st century skill. Much is known about its contribution to learning, but still investigating a process of collaboration remains a challenge. This paper approaches the investigation on collaborative learning from a psychophysiological perspective. An experiment was set up to explore whether biosensors can play a role in analysing collaborative learning. On the one hand, we identified five physiological coupling indices (PCIs) found in the literature: 1) Signal Matching (SM), 2) Instantaneous Derivative Matching (IDM), 3) Directional Agreement (DA), 4) Pearson's correlation coefficient (PCC) and the 5) Fisher's z-transform (FZT) of the PCC. On the other hand, three collaborative learning measurements were used: 1) collaborative will (CW), 2) collaborative learning product (CLP) and 3) dual learning gain (DLG). Regression analyses showed that out of the five PCIs, IDM related the most to CW and was the best predictor of the CLP. Meanwhile, DA predicted DLG the best. These results play a role in determining informative collaboration measures for designing a learning analytics, biofeedback dashboard.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {64–73},
numpages = {10},
keywords = {biosensors, collaborative learning, electrodermal activity, learning analytics, physiological coupling indices},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3027385.3027447,
author = {Di Mitri, Daniele and Scheffel, Maren and Drachsler, Hendrik and B\"{o}rner, Dirk and Ternier, Stefaan and Specht, Marcus},
title = {Learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027447},
doi = {10.1145/3027385.3027447},
abstract = {Learning Pulse explores whether using a machine learning approach on multimodal data such as heart rate, step count, weather condition and learning activity can be used to predict learning performance in self-regulated learning settings. An experiment was carried out lasting eight weeks involving PhD students as participants, each of them wearing a Fitbit HR wristband and having their application on their computer recorded during their learning and working activities throughout the day. A software infrastructure for collecting multimodal learning experiences was implemented. As part of this infrastructure a Data Processing Application was developed to pre-process, analyse and generate predictions to provide feedback to the users about their learning performance. Data from different sources were stored using the xAPI standard into a cloud-based Learning Record Store. The participants of the experiment were asked to rate their learning experience through an Activity Rating Tool indicating their perceived level of productivity, stress, challenge and abilities. These self-reported performance indicators were used as markers to train a Linear Mixed Effect Model to generate learner-specific predictions of the learning performance. We discuss the advantages and the limitations of the used approach, highlighting further development points.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {188–197},
numpages = {10},
keywords = {biosensors, learning analytics, machine learning, multimodal data, wearable enhanced learning},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3613905.3650936,
author = {Anthraper, Nisha and Javiya, Prachee and Iluru, Sai and Chen, Lujie Karen and Kleinsmith, Andrea},
title = {PeerConnect: Co-Designing a Peer-Mentoring Support System with Computing Transfer Students},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650936},
doi = {10.1145/3613905.3650936},
abstract = {In the US, nearly half of the STEM undergraduates begin their academic careers at community colleges. Transferring to four-year institutions can be challenging. Evidence suggests that mentoring can help by increasing a sense of belonging and retention. We engaged mentors and mentees from a pilot mentoring program for new transfer students in computing majors at a minority-serving institution in the Northeastern US in a co-design workshop to understand their needs and requirements for a peer-mentoring system, PeerConnect. PeerConnect aims to foster transfer students’ academic and social engagement, increase self-efficacy and belonging, and develop students’ self-regulated learning skills. Preliminary results show that students want features that push the system beyond merely measuring engagement to actively promoting it. This study contributes to HCI and CSCW work in designing support systems for mentoring and peer support programs in educational settings and to the emerging literature on student-centered learning analytics systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {262},
numpages = {7},
keywords = {co-design, learning analytics, peer mentoring, sense of belonging},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/2723576.2723662,
author = {Corrin, Linda and de Barba, Paula},
title = {How do students interpret feedback delivered via dashboards?},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723662},
doi = {10.1145/2723576.2723662},
abstract = {Providing feedback directly to students on their engagement and performance in educational activities is important to supporting students' learning. However, questions have been raised whether such data representations are adequate to inform reflection, planning and monitoring of students' learning strategies. In this poster we present an investigation of how students interpret feedback delivered via learning analytics dashboards. The findings indicated that most students were able to articulate an interpretation of the feedback presented through the dashboard to identify gaps between their expected and actual performance to inform changes to their study strategies. However, there was also evidence of uncertain interpretation both in terms of the format of the visualization of the feedback and their inability to understand the connection between the feedback and their current strategies. The findings have been used to inform recommendations for ways to enhance the effectiveness of the delivery of feedback through dashboards to provide value to students in developing effective learning strategies to meet their educational goals.},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {430–431},
numpages = {2},
keywords = {dashboards, feedback, learning analytics, self-regulated learning},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1145/3027385.3027395,
author = {Mutahi, Juliet and Kinai, Andrew and Bore, Nelson and Diriye, Abdigani and Weldemariam, Komminist},
title = {Studying engagement and performance with learning technology in an African classroom},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027395},
doi = {10.1145/3027385.3027395},
abstract = {In this paper, we study the engagement and performance of students in a classroom using a system the Cognitive Learning Companion (CLC). CLC is designed to keep track of the relationship between the student, content interaction and learning progression. It also provides evidence-based engagement-oriented actionable insights to teachers by assessing information from a sensor-rich instrumented learning environment in order to infer a learner's cognitive and affective states. Data captured from the instrumented environment is aggregated and analyzed to create interlinked insights helping teachers identify how students engage with learning content and view their performance records on selected assignments. We conducted a 1 month pilot with 27 learners in a primary school in Nairobi, Kenya during their maths and science instructional periods. We present our primary analysis of content-level interactions and engagement at the individual student and classroom level.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {148–152},
numpages = {5},
keywords = {developing countries, education, engagement, learning analytics, mobile development},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3027385.3027411,
author = {Davis, Dan and Jivet, Ioana and Kizilcec, Ren\'{e} F. and Chen, Guanliang and Hauff, Claudia and Houben, Geert-Jan},
title = {Follow the successful crowd: raising MOOC completion rates through social comparison at scale},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027411},
doi = {10.1145/3027385.3027411},
abstract = {Social comparison theory asserts that we establish our social and personal worth by comparing ourselves to others. In in-person learning environments, social comparison offers students critical feedback on how to behave and be successful. By contrast, online learning environments afford fewer social cues to facilitate social comparison. Can increased availability of such cues promote effective self-regulatory behavior and achievement in Massive Open Online Courses (MOOCs)? We developed a personalized feedback system that facilitates social comparison with previously successful learners based on an interactive visualization of multiple behavioral indicators. Across four randomized controlled trials in MOOCs (overall N = 33, 726), we find: (1) the availability of social comparison cues significantly increases completion rates, (2) this type of feedback benefits highly educated learners, and (3) learners' cultural context plays a significant role in their course engagement and achievement.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {454–463},
numpages = {10},
keywords = {cultural differences, feedback, framing, learning analytics, massive open online course, social comparison},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3448139.3448175,
author = {Lall\'{e}, S\'{e}bastien and Yal\c{c}\i{}n, \"{O}zge Nilay and Conati, Cristina},
title = {Combining Data-Driven Models and Expert Knowledge for Personalized Support to Foster Computational Thinking Skills},
year = {2021},
isbn = {9781450389358},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448139.3448175},
doi = {10.1145/3448139.3448175},
abstract = {Game-Design (GD) environments show promise in fostering Computational Thinking (CT) skills at a young age. However, such environments can be challenging to some students due to their highly open-ended nature. We propose to alleviate this difficulty by learning interpretable student models from data that can drive personalization of a real-world GD learning environment to the student’s needs. We apply our approach on a dataset collected in ecological settings and evaluate the ability of the generated student models at predicting ineffective learning behaviors over the course of the interaction. We then discuss how these behaviors can be used to define personalized support in GD learning activities, by conducting extensive interviews with experienced instructors.},
booktitle = {LAK21: 11th International Learning Analytics and Knowledge Conference},
pages = {375–385},
numpages = {11},
keywords = {Computational Thinking, Educational Data Mining, Game Design, Open-Ended Learning Environments, Student Modeling},
location = {Irvine, CA, USA},
series = {LAK21}
}

@inproceedings{10.1145/2883851.2883859,
author = {Mol, Stefan and Kobayashi, Vladimer and Kismih\'{o}k, G\'{a}bor and Zhao, Catherine},
title = {Learning through goal setting},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883859},
doi = {10.1145/2883851.2883859},
abstract = {Despite the mounting evidence supporting the role that goal setting has on the learning process, there seems to be only a handful of studies that directly investigate goal setting in the context of Learning Analytics (LA). Although investigations have incorporated elements of goal setting, the attention afforded to theory and operationalization have been modest. In this workshop we plan to position goal setting at the forefront of LA research. The workshop will serve as a venue to bring together researchers interested in advancing Goal Setting (GS) research in the LA field. Topics include: (1) GS theory and measurement; (2) analysis and visualization of GS data; (3) strategies for integrating GS in the learning experience; and (4) implementation of GS technologies. Participants who need tools to execute their GS ideas and those who already have tools and are exploring better ways to integrate a goal setting feature can gain a lot from this workshop. Moreover, participants will have the opportunity to contribute to the conceptualization and staging of GS ideas in LA research.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {512–513},
numpages = {2},
keywords = {goal setting, learning analytics, learning record store},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3303772.3303811,
author = {Chua, Yi Han Victoria and Dauwels, Justin and Tan, Seng Chee},
title = {Technologies for automated analysis of co-located, real-life, physical learning spaces: Where are we now?},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303811},
doi = {10.1145/3303772.3303811},
abstract = {The motivation for this paper is derived from the fact that there has been increasing interest among researchers and practitioners in developing technologies that capture, model and analyze learning and teaching experiences that take place beyond computer-based learning environments. In this paper, we review case studies of tools and technologies developed to collect and analyze data in educational settings, quantify learning and teaching processes and support assessment of learning and teaching in an automated fashion. We focus on pipelines that leverage information and data harnessed from physical spaces and/or integrates collected data across physical and digital spaces. Our review reveals a promising field of physical classroom analysis. We describe some trends and suggest potential future directions. Specifically, more research should be geared towards a) deployable and sustainable data collection set-ups in physical learning environments, b) teacher assessment, c) developing feedback and visualization systems and d) promoting inclusivity and generalizability of models across populations.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {11–20},
numpages = {10},
keywords = {Face-to-face classroom analysis, co-located learning, educational data mining, educational technologies, physical learning analytics},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3506860.3506894,
author = {Pugh, Samuel L. and Rao, Arjun and Stewart, Angela E.B. and D'Mello, Sidney K.},
title = {Do Speech-Based Collaboration Analytics Generalize Across Task Contexts?},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506894},
doi = {10.1145/3506860.3506894},
abstract = {We investigated the generalizability of language-based analytics models across two collaborative problem solving (CPS) tasks: an educational physics game and a block programming challenge. We analyzed a dataset of 95 triads (N=285) who used videoconferencing to collaborate on both tasks for an hour. We trained supervised natural language processing classifiers on automatic speech recognition transcripts to predict the human-coded CPS facets (skills) of constructing shared knowledge, negotiation / coordination, and maintaining team function. We tested three methods for representing collaborative discourse: (1) deep transfer learning (using BERT), (2) n-grams (counts of words/phrases), and (3) word categories (using the Linguistic Inquiry Word Count [LIWC] dictionary). We found that the BERT and LIWC methods generalized across tasks with only a small degradation in performance (Transfer Ratio of .93 with 1 indicating perfect transfer), while the n-grams had limited generalizability (Transfer Ratio of .86), suggesting overfitting to task-specific language. We discuss the implications of our findings for deploying language-based collaboration analytics in authentic educational environments.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {208–218},
numpages = {11},
keywords = {Collaboration analytics, Collaborative problem solving, Natural language processing},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3375462.3375512,
author = {Faucon, Louis and Olsen, Jennifer K. and Dillenbourg, Pierre},
title = {A bayesian model of individual differences and flexibility in inductive reasoning for categorization of examples},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375512},
doi = {10.1145/3375462.3375512},
abstract = {Inductive reasoning is an important educational practice but can be difficult for teachers to support in the classroom due to the high level of preparation and classroom time needed to choose the teaching materials that challenge students' current views. Intelligent tutoring systems can potentially facilitate this work for teachers by supporting the automatic adaptation of examples based on a student model of the induction process. However, current models of inductive reasoning usually lack two main characteristics helpful to adaptive learning environments, individual differences of students and tracing of students' learning as they receive feedback. In this paper, we describe a model to predict and simulate inductive reasoning of students for a categorization task. Our approach uses a Bayesian model for describing the reasoning processes of students. This model allows us to predict students' choices in categorization questions by accounting for their feature biases. Using data gathered from 222 students categorizing three topics, we find that our model has a 75% accuracy, which is 10% greater than a baseline model. Our model is a contribution to learning analytics by enabling us to assign different bias profiles to individual students and tracking these profile changes over time through which we can gain a better understanding of students' learning processes. This model may be relevant for systematically analysing students' differences and evolution in inductive reasoning strategies while supporting the design of adaptive inductive learning environments.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {285–294},
numpages = {10},
keywords = {adaptive learning environment, inductive reasoning, process mining, student modeling},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/2883851.2883955,
author = {Buckingham Shum, Simon and S\'{a}ndor, \'{A}gnes and Goldsmith, Rosalie and Wang, Xiaolong and Bass, Randall and McWilliams, Mindy},
title = {Reflecting on reflective writing analytics: assessment challenges and iterative evaluation of a prototype tool},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883955},
doi = {10.1145/2883851.2883955},
abstract = {When used effectively, reflective writing tasks can deepen learners' understanding of key concepts, help them critically appraise their developing professional identity, and build qualities for lifelong learning. As such, reflecting writing is attracting substantial interest from universities concerned with experiential learning, reflective practice, and developing a holistic conception of the learner. However, reflective writing is for many students a novel genre to compose in, and tutors may be inexperienced in its assessment. While these conditions set a challenging context for automated solutions, natural language processing may also help address the challenge of providing real time, formative feedback on draft writing. This paper reports progress in designing a writing analytics application, detailing the methodology by which informally expressed rubrics are modelled as formal rhetorical patterns, a capability delivered by a novel web application. This has been through iterative evaluation on an independently human-annotated corpus, showing improvements from the first to second version. We conclude by discussing the reasons why classifying reflective writing has proven complex, and reflect on the design processes enabling work across disciplinary boundaries to develop the prototype to its current state.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {213–222},
numpages = {10},
keywords = {education, learning analytics, metadiscourse, natural language processing, reflection, rhetoric, writing analytics},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3027385.3029434,
author = {Arnold, Kimberly E. and Karcher, Brandon and Wright, Casey V. and McKay, James},
title = {Student empowerment, awareness, and self-regulation through a quantified-self student tool},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029434},
doi = {10.1145/3027385.3029434},
abstract = {The purpose of this paper is to examine the cross institutional use of a quantified-self application called Pattern, which is designed to promote self-regulation and reflective learning in learners. This paper provides a brief look into how learners report spending their time and react to in-app recommendations. Initial data is encouraging; however, there are limitations of Pattern, and additional research and development must be undertaken.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {526–527},
numpages = {2},
keywords = {higher education, learning analytics, mobile application, quantified-self student, real-time feedback, recommendation engine, reflective learning practices, self-regulated learning},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3170358.3170377,
author = {Holstein, Kenneth and Hong, Gena and Tegene, Mera and McLaren, Bruce M. and Aleven, Vincent},
title = {The classroom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170377},
doi = {10.1145/3170358.3170377},
abstract = {When used in classrooms, personalized learning software allows students to work at their own pace, while freeing up the teacher to spend more time working one-on-one with students. Yet such personalized classrooms also pose unique challenges for teachers, who are tasked with monitoring classes working on divergent activities, and prioritizing help-giving in the face of limited time. This paper reports on the co-design, implementation, and evaluation of a wearable classroom orchestration tool for K-12 teachers: mixed-reality smart glasses that augment teachers' realtime perceptions of their students' learning, metacognition, and behavior, while students work with personalized learning software. The main contributions are: (1) the first exploration of the use of smart glasses to support orchestration of personalized classrooms, yielding design findings that may inform future work on real-time orchestration tools; (2) Replay Enactments: a new prototyping method for real-time orchestration tools; and (3) an in-lab evaluation and classroom pilot using a prototype of teacher smart glasses (Lumilo), with early findings suggesting that Lumilo can direct teachers' time to students who may need it most.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {79–88},
numpages = {10},
keywords = {K-12, awareness, co-design, mixed-reality, orchestration, personalized classrooms, prototyping, real-time analytics},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/2883851.2883915,
author = {Hsiao, I-Han and Pandhalkudi Govindarajan, Sesha Kumar and Lin, Yi-Ling},
title = {Semantic visual analytics for today's programming courses},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883915},
doi = {10.1145/2883851.2883915},
abstract = {We designed and studied an innovative semantic visual learning analytics for orchestrating today's programming classes. The visual analytics integrates sources of learning activities by their content semantics. It automatically processs paper-based exams by associating sets of concepts to the exam questions. Results indicated the automatic concept extraction from exams were promising and could be a potential technological solution to address a real world issue. We also discovered that indexing effectiveness was especially prevalent for complex content by covering more comprehensive semantics. Subjective evaluation revealed that the dynamic concept indexing provided teachers with immediate feedback on producing more balanced exams.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {48–53},
numpages = {6},
keywords = {auto grading, dashboard, intelligent authoring, orchestration technology, programming, semantic analytics, visual analytics},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3027385.3029435,
author = {Cooper, Adam and Berg, Alan and Sclater, Niall and Dorey-Elias, Tanya and Kitto, Kirsty},
title = {LAK17 hackathon: getting the right information to the right people so they can take the right action},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029435},
doi = {10.1145/3027385.3029435},
abstract = {The hackathon is intended to be a practical hands-on workshop involving participants from academia and commercial organizations with both technical and practitioner expertise. It will consider the outstanding challenge of visualizations which are effective for the intended audience: informing action, not likely to be misinterpreted, and embodying contextual appropriacy, etc. It will surface particular issues as workshop challenges and explore responses to these challenges as visualizations resting upon interoperability standards and API-oriented open architectures.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {514–515},
numpages = {2},
keywords = {actionable insights, contextual appropriacy, hackathon, interoperability, open learning analytics, visualization},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3649217.3653561,
author = {Karaka\v{s}, Aleksandar and Helic, Denis},
title = {Combining Local Testing with Automatic Commits: Benefits for Progress Tracking and CS2 Students' Learning Experience},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653561},
doi = {10.1145/3649217.3653561},
abstract = {Many instructors in introductory programming courses experience high dropout and failure rates. Identifying struggling students early is a prerequisite to target this problem. To this end, instructors and learning analytics researchers may leverage version control by analyzing the students' commit histories. This approach relies on frequent pushes to the version control platform, which many instructors incentivize by offering test results each time a student pushes a commit. However, instructors who provide test cases that can be run locally (i.e., without creating a commit) may face coarse-grained commit histories.In this study, we analyze a CS2 course which offers both local and remote testing. Students were provided with tools that automatically create and push a commit on each local test run. We investigate to what extent these automatically created snapshots contribute to obtaining fine-grained commit histories and early initial push events. Our analysis uncovers distinct commit patterns among high- and low-performing students. Furthermore, we find that despite the commit automation and encouraging students to start early, many students pushed their first commit late. We triangulate this observation with survey results which confirm the late start of many students. The survey also identified reasons for students to opt out of automatic commit creation. Moreover, many students expressed a positive attitude towards testing their programs locally. Thus, our survey results underline that instructors should strive for providing students with comprehensive feedback that students can conveniently obtain.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {108–114},
numpages = {7},
keywords = {computer science education, cs2, educational data mining, git, learning analytics, version control},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3631700.3664899,
author = {Akhuseyinoglu, Kamil and McDonald, Emma and Klasnja Milicevic, Aleksandra and Demmans Epp, Carrie and Brusilovsky, Peter},
title = {Exploring Adaptive Social Comparison for Online Practice},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3664899},
doi = {10.1145/3631700.3664899},
abstract = {Students experience motivational issues during online learning which has led to explorations of how to better support their self-regulated learning. One way to support students uses social reference frames or social comparison in student-facing learning analytics dashboards (LADs) and open learner models (OLMs). Usually, the social reference frame communicates class averages. Despite the positive effects of class-average-based social comparison on students’ activity levels and learning behaviors, comparison to class average can be misleading for some students and offer an irrelevant reference frame, motivating only low or high performers. Such conflicting findings highlight a need for an investigation of social reference frames that are not based on the “average” student. We extend the research on social comparison in education by conducting two complementary classroom studies. The first explores the effects of different fixed social reference frames in a non-mandatory practice system, while the second introduces an adaptive social reference frame that dynamically selects the peers who serve as a comparison group when students are engaged in online programming practice. We reported our analyses from both studies and shared students’ subjective evaluations of the system and its adaptive comparison functionality.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {374–379},
numpages = {6},
keywords = {OLM, adaptive educational systems, classroom experiment, computer science education, learning analytics, self-regulated learning},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3027385.3027413,
author = {Avila, Cecilia and Baldiris, Silvia and Fabregat, Ramon and Graf, Sabine},
title = {ATCE: an analytics tool to trace the creation and evaluation of inclusive and accessible open educational resources},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027413},
doi = {10.1145/3027385.3027413},
abstract = {The creation of Inclusive and Accessible Open Educational Resources (IA-OERs) is a challenge for teachers because they have to invest time and effort to create learning contents considering students' learning needs and preferences. An IA-OER is characterized by its alignment with the Universal Design Learning (UDL) principles, the quality on its contents and the web accessibility as a way to address the diversity of students. Creating an IA-OER with these characteristics is not a straightforward task, especially when teachers do not have enough information/feedback to make decisions on how to improve the learning contents. In this paper we introduce ATCE - an Analytics Tool to Trace the Creation and Evaluation of IA-OERs. This tool focuses in particular on the accessibility and quality of the IA-OERs. ATCE was developed as a module within the ATutor Learning Management System (LMS). An analytics dashboard with visualizations related to the teachers' competences in the creation and evaluation of IA-OERs was included as part of the tool. This paper also presents a use case of the visualizations obtained from the creation and evaluation of one IA-OER after using our analytics tool.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {183–187},
numpages = {5},
keywords = {competences, learning analytics, open educational resources, quality, teachers, web accessibility},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/2723576.2723583,
author = {Martinez-Maldonado, Roberto and Pardo, Abelardo and Mirriahi, Negin and Yacef, Kalina and Kay, Judy and Clayphan, Andrew},
title = {The LATUX workflow: designing and deploying awareness tools in technology-enabled learning settings},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723583},
doi = {10.1145/2723576.2723583},
abstract = {Designing, deploying and validating learning analytics tools for instructors or students is a challenge requiring techniques and methods from different disciplines, such as software engineering, human-computer interaction, educational design and psychology. Whilst each of these disciplines has consolidated design methodologies, there is a need for more specific methodological frameworks within the cross-disciplinary space defined by learning analytics. In particular there is no systematic workflow for producing learning analytics tools that are both technologically feasible and truly underpin the learning experience. In this paper, we present the LATUX workflow, a five-stage workflow to design, deploy and validate awareness tools in technology-enabled learning environments. LATUX is grounded on a well-established design process for creating, testing and re-designing user interfaces. We extend this process by integrating the pedagogical requirements to generate visual analytics to inform instructors' pedagogical decisions or intervention strategies. The workflow is illustrated with a case study in which collaborative activities were deployed in a real classroom.},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {1–10},
numpages = {10},
keywords = {awareness, dashboard, design, groupware, visualisations},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1145/2883851.2883853,
author = {Bull, Susan and Ginon, Blandine and Boscolo, Clelia and Johnson, Matthew},
title = {Introduction of learning visualisations and metacognitive support in a persuadable open learner model},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883853},
doi = {10.1145/2883851.2883853},
abstract = {This paper describes open learner models as visualisations of learning for learners, with a particular focus on how information about their learning can be used to help them reflect on their skills, identify gaps in their skills, and plan their future learning. We offer an approach that, in addition to providing visualisations of their learning, allows learners to propose changes to their learner model. This aims to help improve the accuracy of the learner model by taking into account student viewpoints on their learning, while also promoting learner reflection on their learning as part of a discussion of the content of their learner model. This aligns well with recent calls for learning analytics for learners. Building on previous research showing that learners will use open learner models, we here investigate their initial reactions to open learner model features to identify the likelihood of uptake in contexts where an open learner model is offered on an optional basis. We focus on university students' perceptions of a range of visualisations and their stated preferences for a facility to view evidence for the learner model data and to propose changes to the values.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {30–39},
numpages = {10},
keywords = {learning analytics for learners, open learner models, persuading the learner model, visual learning analytics},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3303772.3303805,
author = {Aguilar, Stephen J. and Baek, Clare},
title = {Motivated Information Seeking and Graph Comprehension Among College Students},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303805},
doi = {10.1145/3303772.3303805},
abstract = {Learning Analytics Dashboards (LADs) are predicated on the notion that access to more academic information can help students regulate their academic behaviors, but what is the association between information seeking preferences and help-seeking practices among college students? If given access to more information, what might college students do with it?We investigated these questions in a series of two studies. Study 1 validates a measure of information-seeking preferences---the Motivated Information-Seeking Questionnaire (MISQ)----using a college student sample drawn from across the country (n = 551). In a second study, we used the MISQ to measure college students' (n=210) performance-avoid (i.e., avoiding seeming incompetent in relation to one's peers) and performance-approach (i.e., wishing to outperform one's peers) information seeking preferences, their help-seeking behaviors, and their ability to comprehend line graphs and bar graphs---two common graphs types for LADs.Results point to a negative relationship between graph comprehension and help-seeking strategies, such as attending office hours, emailing one's professor for help, or visiting a study center---even after controlling for academic performance and demographic characteristics. This suggests that students more capable of readings graphs might not seek help when needed. Further results suggest a positive relationship between performance-approach information-seeking preferences, and how often students compare themselves to their peers.This study contributes to our understanding of the motivational implications of academic data visualizations in academic settings, and increases our knowledge of the way students interpret visualizations. It uncovers tensions between what students want to see, versus what it might be more motivationally appropriate for them to see. Importantly, the MISQ and graph comprehension measure can be used in future studies to better understand the role of students' information seeking tendencies with regard to their interpretation of various kinds of feedback present in LADs.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {280–289},
numpages = {10},
keywords = {Higher Education, Instrument Validation, Motivation, Non-cognitive factors, Visualizations},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/2883851.2883941,
author = {Kevan, Jonathan M. and Menchaca, Michael P. and Hoffman, Ellen S.},
title = {Designing MOOCs for success: a student motivation-oriented framework},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883941},
doi = {10.1145/2883851.2883941},
abstract = {Considerable literature exists regarding MOOCs. Evaluations of MOOCs range from ringing endorsements to its vilification as a delivery model. Much evaluation focuses on completion rates and/or participant satisfaction. Overall, MOOCs are ill-defined and researchers struggle with appropriate evaluation criteria beyond attrition rates. In this paper, we provide a brief history of MOOCs, a summary of some evaluation research, and we propose a new model for evaluation with an example from a previously-delivered MOOC. Measurement of the MOOC success framework through four student satisfaction types is proposed in this paper with a model for informal learning satisfaction, one of the proposed types, theorized and tested. Results indicated theoretical underpinnings, while intended to improve instruction, might not have influenced the same satisfaction construct. Therefore, future research into alternative satisfaction factor models is needed.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {274–278},
numpages = {5},
keywords = {MOOC, confirmatory factor analysis, framework, learning analytics, motivation, structural equation modeling},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3170358.3170411,
author = {Long, Yanjin and Holstein, Kenneth and Aleven, Vincent},
title = {What exactly do students learn when they practice equation solving? refining knowledge components with the additive factors model},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170411},
doi = {10.1145/3170358.3170411},
abstract = {Accurately modeling individual students' knowledge growth is important in many applications of learning analytics. A key step is to decompose the knowledge targeted in the instruction into detailed knowledge components (KCs). We search for an accurate KC model for basic equation solving skills, using data from an intelligent tutoring system (ITS), Lynnette. Key criteria are data fit and predictive accuracy based on a standard logistic model called the Additive Factors Model (AFM). We focus on three difficulty factors for equation solving: understanding of variables, the negative sign, and the complexity of the equation. Fine-grained KC models were found to have greater fit and predictive accuracy than an "ideal," more abstract model, indicating that there is substantial under-generalization in students' equation-solving skill related to all three difficulty factors. The work enhances scientific understanding of the challenges students face in learning equation solving. It illustrates how learning analytics could inform the improvement of technology-enhanced learning environments.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {399–408},
numpages = {10},
keywords = {K-12, educational data mining, equation solving, intelligent tutoring systems, knowledge components, student modeling},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/2883851.2883940,
author = {Jayaprakash, Sandeep M. and Laur\'{\i}a, Eitel J. M. and Gandhi, Pritesh and Mendhe, Dinesh},
title = {Benchmarking student performance and engagement in an early alert predictive system using interactive radar charts},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883940},
doi = {10.1145/2883851.2883940},
abstract = {This poster synthesizes the design features of a visualization layer applied on the Open Academic Analytics Initiative (OAAI), an open source academic early alert system based on predictive analytics. The poster explores ways to convey the predictive model outputs and benchmark student performances using visually intuitive radar plots.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {526–527},
numpages = {2},
keywords = {benchmarking, data mining, information visualizations, instructional assessment, intervention, interventions, learning analytics, open source, predictive analytics, visualization},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3027385.3027434,
author = {Ez-zaouia, Mohamed and Lavou\'{e}, Elise},
title = {EMODA: a tutor oriented multimodal and contextual emotional dashboard},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027434},
doi = {10.1145/3027385.3027434},
abstract = {Learners' emotional state has proven to be a key factor for successful learning. Visualizing learners' emotions during synchronous on-line learning activities can help tutors in creating and maintaining socio-affective relationships with their learners. However, few dashboards offer emotional information on the learning activity. The current study focuses on synchronous interactions via a videoconferencing tool dedicated to foreign language training. We collected data on learners' emotions in real conditions during ten sessions (five sessions for two learners). We propose to adopt and combine different models of emotions (discrete and dimensional) and to use heterogeneous APIs for measuring learners' emotions from different data sources (audio, video, self-reporting and interaction traces). Based on a thorough data analysis, we propose an approach to combine different cues to infer information on learners' emotional states. We finally present the EMODA dashboard, an affective multimodal and contextual visual analytics dashboard, which allows the tutor to monitor learners' emotions and better understand their evolution during the synchronous learning activity.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {429–438},
numpages = {10},
keywords = {emotions, interactive visualizations, language training, learner monitoring, multimodal data, tutor dashboard},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/2460296.2460350,
author = {Holman, Caitlin and Aguilar, Stephen and Fishman, Barry},
title = {GradeCraft: what can we learn from a game-inspired learning management system?},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460350},
doi = {10.1145/2460296.2460350},
abstract = {The "gamification" of courses (i.e., designing courses that leverage motivational mechanisms found in videogames) is a movement that is gaining traction in educational research communities and universities. Two game-inspired courses were developed at a high-enrollment public university in an effort to increase student engagement, and to provide students with more personalized learning experiences. We designed a learning management system, GradeCraft, to foreground the affordances of these grading systems, and to enhance the "game-like" experience for students. Along with serving as a translation layer for the grading systems of these courses, GradeCraft is also designed with an eye towards learning analytics, and captures information that can be described as student "process" data. Currently this data includes what types of assignments students choose to complete; how students assign percentage weights to their chosen assignments; how often and how accurately students check or model their course grades; and how successfully assignments are completed by students individually and the class as a whole across a structured grading rubric. We hope GradeCraft will give instructors new insight into student engagement, and provide data-driven ideas about how to tailor courses to student needs.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {260–264},
numpages = {5},
keywords = {game-inspired instruction, gamification, learning analytics, syllabus design},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/2567574.2567622,
author = {Grann, Jeff and Bushway, Deborah},
title = {Competency map: visualizing student learning to promote student success},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567622},
doi = {10.1145/2567574.2567622},
abstract = {Adult students often struggle to appreciate the relevance of their higher educational experiences to their careers. Capella University's competency map is a dashboard that visually indicates each student's status relative to specific assessed competencies. MBA students who utilize their competency map demonstrate competencies at slightly higher levels and persist in their program at greater rates, even after statistically controlling for powerful covariates, such as course engagement.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {168–172},
numpages = {5},
keywords = {competency, evaluation, learning analytics, visualization},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/2723576.2723661,
author = {Shehata, Shady and Arnold, Kimberly E.},
title = {Measuring student success using predictive engine},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723661},
doi = {10.1145/2723576.2723661},
abstract = {A basic challenge in delivering global education is improving student success. Institutions of education are increasingly focused on improving graduation and retention rates of their students. In this poster, we describe Student Success System (S3) that can measure student performance starting from the first weeks of the semester and the adoption process for S3 by University of Wisconsin System (UWS).},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {416–417},
numpages = {2},
keywords = {algorithms, data mining, learning analytics, machine learning, predictive modeling, regression analysis, student success},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1145/3375462.3375471,
author = {van Leeuwen, Anouschka and Rummel, Nikol},
title = {Comparing teachers' use of mirroring and advising dashboards},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375471},
doi = {10.1145/3375462.3375471},
abstract = {Teachers play an essential role during collaborative learning. To provide effective support, teachers have to be constantly aware of students' activities and make fast decisions about which group to offer support, without disrupting students' collaborative process. Teacher dashboards are visual displays that provide analytics about learners to help teachers increase their awareness of the situation. However, if teachers are not able to efficiently and effectively distill information from the dashboard, the dashboard can become an obstacle instead of an aid. In the present study, we compared dashboards that provide information (mirroring) to dashboards that provide information and alert the teacher to groups that are in need of support (advising). Teachers were shown standardized, fictitious collaborative situations on one of the types of dashboards and were asked to detect the group that was in need of support. The results showed that teachers in the advising condition more often detected the problematic group, needed less effort to do so, and were more confident of their decisions. The teacher-dashboard interaction patterns showed that teachers in the advising condition generally started by checking the given alert, but also that they tried to look at as much information about other groups as they could. In the mirroring condition, teachers generally started by examining information from class overviews, but did not always have time to check information for individual groups. These findings are discussed in light of the role of a teacher dashboard in teachers' decision making in the context of student collaboration.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {26–34},
numpages = {9},
keywords = {cooperative/collaborative learning, elementary education, human-computer interface, improving classroom teaching, teaching/learning strategies},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/3641554.3701971,
author = {Cai, Zhenyu and Davis, Richard Lee and Mari\'{e}tan, Rapha\"{e}l and Tormey, Roland and Dillenbourg, Pierre},
title = {Jupyter Analytics: A Toolkit for Collecting, Analyzing, and Visualizing Distributed Student Activity in Jupyter Notebooks},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701971},
doi = {10.1145/3641554.3701971},
abstract = {Jupyter is a web-based, interactive computing environment that supports many commonly-used programming languages. It has been widely adopted in the CS education community and is now rapidly expanding to other STEM disciplines due to the growing integration of programming in STEM education. However, unlike other educational platforms, there is currently no integrated way to capture, analyze, and visualize student interaction data in Jupyter notebooks. This means that teachers have limited to no visibility into student activity, preventing them from drawing insights from these data and providing timely interventions on the fly. In this paper, we present Jupyter Analytics, an end-to-end solution for teachers to collect, analyze, and visualize both synchronous and asynchronous learning activities in Jupyter. The Jupyter Analytics system consists of two JupyterLab extensions connected via a cloud-based backend. On the student side, we introduce the Jupyter Analytics Telemetry extension to anonymously capture students' interaction activity with more structure and higher granularity than log data. On the teacher side, we introduce the Jupyter Analytics Dashboard extension, which visualizes real-time student data directly in the notebook interface. The Jupyter Analytics system was developed through an iterative co-design process with university instructors and teaching assistants, and has been implemented and tested in several university STEM courses. We report two use cases where Jupyter Analytics impacted teaching and learning in the context of exercise sessions, and discuss the potential value of our tools for CS education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {educational dashboards, jupyter, learning analytics, programming, stem education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/2723576.2723619,
author = {Aguiar, Everaldo and Lakkaraju, Himabindu and Bhanpuri, Nasir and Miller, David and Yuhas, Ben and Addison, Kecia L.},
title = {Who, when, and why: a machine learning approach to prioritizing students at risk of not graduating high school on time},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723619},
doi = {10.1145/2723576.2723619},
abstract = {Several hundred thousand students drop out of high school every year in the United States. Interventions can help those who are falling behind in their educational goals, but given limited resources, such programs must focus on the right students, at the right time, and with the right message. In this paper, we describe an incremental approach that can be used to select and prioritize students who may be at risk of not graduating high school on time, and to suggest what may be the predictors of particular students going off-track. These predictions can then be used to inform targeted interventions for these students, hopefully leading to better outcomes.},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {93–102},
numpages = {10},
keywords = {early intervention, learning analytics, predictive analytics, secondary education, student retention},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1145/3716554.3716602,
author = {Garefalakis, Manos and Kamarianakis, Zacharias and Panagiotakis, Spyros},
title = {Remote Laboratory for developing an IoT system},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716602},
doi = {10.1145/3716554.3716602},
abstract = {The rapid evolution of Industry 4.0, driven by the Internet of Things (IoT), has revolutionized education, necessitating innovative platforms for the practical training of trainees. On the other hand, Remote Laboratories (RLs) have proven their worth, offering a safe and controlled environment for users to work in from the comfort of their working space at any time. This paper attempts to address two research questions: (1) What structure should a remote laboratory designed for IoT education have? and (2) Can Machine Learning (ML) assist the learning procedure in evaluating the programming code submitted by trainees? A literature review was conducted to answer the first question, highlighting the essential components of IoT education, including the development and programming of low-cost, open-source microcontrollers like Arduino, the development and programming of flexible server solutions like those based on Node-RED, and efficient Machine-to-Machine (M2M) protocols, such as MQTT, for client-server communication. The review also underscored the growing demand for hands-on, remote learning environments to enhance IoT skill acquisition. In this context, we developed the RLP-HMU2, an upgraded remote laboratory platform for teaching IoT application development. RLP-HMU2 employs a unique two-step process where students program Arduino microcontrollers and develop Node-RED applications, with continuously monitored progress. To address the second question, this platform integrates machine learning for automated code evaluation, providing personalized feedback and learning analytics via an xAPI framework. The ML module, implemented using decision tree algorithms, assesses student code accuracy and adaptively improves its classification model based on new submissions. Our findings demonstrate that this approach fosters practical IoT skills while empowering educators with tools for tailored instruction. This work represents a significant step toward scalable, effective IoT education by combining structured curriculum design, advanced remote labs, and innovative assessment technologies.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {315–323},
numpages = {9},
keywords = {Arduino, Educational Technology, Internet of Things, IoT Education, Learning Analytics, Learning Management System (LMS), Machine Learning, Node-RED, Personalized Learning, Real-Time Control, Remote Laboratory, Remote Learning, xAPI},
location = {
},
series = {PCI '24}
}

@inproceedings{10.1145/3492724.3492731,
author = {Hern\'{a}ndez-Calder\'{o}n, Jose-Guillermo and Soto-Mendoza, Valeria and Montan\'{e}-Jim\'{e}nez, Luis Gerardo and Meunier Colula, Marion Alain and Tello-Carrillo, Janeth},
title = {Designing an information visualization dashboard to proctor test-takers during language certification online testing},
year = {2022},
isbn = {9781450387170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492724.3492731},
doi = {10.1145/3492724.3492731},
abstract = {The learning mechanisms and the evaluation process have been moved to an online mode in order to maintain social distancing and reduce the spread of the COVID-19. E-learning initiatives (including assessment and proctoring) produce a large amount of data, so visualization mechanisms are required to support the decision-making process. This problem is addressed from a practical context of study: the English Language Certification Tests of a University in the southeast of Mexico. The conceptual design of four conceptual dashboards are presented using a mixed methodology: the UCD process and a conceptual model for a dashboard generator process. The four conceptual dashboards were evaluated by five experts. Although the design proposals were simple and reflected most initial user requirements, the experts suggested to include more elements in all the dashboards to provide the information needed for the intended users and improve the decision-making process.},
booktitle = {Proceedings of the 8th Mexican Conference on Human-Computer Interaction},
articleno = {7},
numpages = {5},
keywords = {information visualization, language, learning analytics, test-takers},
location = {Online, Mexico},
series = {MexIHC '21}
}

@inproceedings{10.1145/2330601.2330639,
author = {Santos, Jose Luis and Govaerts, Sten and Verbert, Katrien and Duval, Erik},
title = {Goal-oriented visualizations of activity tracking: a case study with engineering students},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330639},
doi = {10.1145/2330601.2330639},
abstract = {Increasing motivation of students and helping them to reflect on their learning processes is an important driver for learning analytics research. This paper presents our research on the development of a dashboard that enables self-reflection on activities and comparison with peers. We describe evaluation results of four iterations of a design based research methodology that assess the usability, use and usefulness of different visualizations. Lessons learned from the different evaluations performed during each iteration are described. In addition, these evaluations illustrate that the dashboard is a useful tool for students. However, further research is needed to assess the impact on the learning process.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {143–152},
numpages = {10},
keywords = {learning analytics, reflection, visualization},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/3375462.3375465,
author = {Molenaar, Inge and Horvers, Anne and Dijkstra, Rick and Baker, Ryan S.},
title = {Personalized visualizations to promote young learners' SRL: the learning path app},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375465},
doi = {10.1145/3375462.3375465},
abstract = {This paper describes the design and evaluation of personalized visualizations to support young learners' Self-Regulated Learning (SRL) in Adaptive Learning Technologies (ALTs). Our learning path app combines three Personalized Visualizations (PV) that are designed as an external reference to support learners' internal regulation process. The personalized visualizations are based on three pillars: grounding in SRL theory, the usage of trace data and the provision of clear actionable recommendations for learners to improve regulation. This quasi-experimental pre-posttest study finds that learners in the personalized visualization condition improved the regulation of their practice behavior, as indicated by higher accuracy and less complex moment-by-moment learning curves compared to learners in the control group. Learners in the PV condition showed better transfer on learning. Finally, students in the personalized visualizations condition were more likely to under-estimate instead of over-estimate their performance. Overall, these findings indicates that the personalized visualizations improved regulation of practice behavior, transfer of learning and changed the bias in relative monitoring accuracy.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {330–339},
numpages = {10},
keywords = {adaptive learning technologies, hybrid human-system intelligence, learner-faced dashboards, self-regulated learning},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@inproceedings{10.1145/2460296.2460301,
author = {Santos, Jose Luis and Verbert, Katrien and Govaerts, Sten and Duval, Erik},
title = {Addressing learner issues with StepUp! an evaluation},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460301},
doi = {10.1145/2460296.2460301},
abstract = {This paper reports on our research on the use of learning analytics dashboards to support awareness, self-reflection, sensemaking and impact for learners. So far, little research has been done to evaluate such dashboards with students and to assess their impact on learning. In this paper, we present the results of an evaluation study of our dashboard, called StepUp!, and the extent to which it addresses issues and needs of our students. Through brainstorming sessions with our students, we identified and prioritized learning issues and needs. In a second step, we deployed StepUp! during one month and we evaluated to which extent our dashboard addresses the issues and needs identified earlier in different courses. The results show that our tool has potentially higher impact for students working in groups and sharing a topic than students working individually on different topics.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {14–22},
numpages = {9},
keywords = {design based research, evaluation, learning analytics, reflection, visualization},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/3303772.3303818,
author = {Martinez-Maldonado, Roberto},
title = {"I Spent More Time with that Team": Making Spatial Pedagogy Visible Using Positioning Sensors},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303818},
doi = {10.1145/3303772.3303818},
abstract = {Teachers are often encouraged to adopt different positioning strategies at various stages of a classroom lesson as each can influence learners in different ways. However, little work has been done to make evidence of the use of classrooms visible to teachers and students. As sensors drop in price, it is becoming more viable to capture traces of the use of the physical classroom space automatically. In this paper, we build on the notion of spatial pedagogy to propose an approach to visualise digital traces of teacher positioning in the classroom. We illustrate our approach through an authentic case study of a teacher enacting three distinctive learning designs. We document the teacher's and students' reactions to visual representations of positioning data to explore their potential as proxies of spatial pedagogy.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {21–25},
numpages = {5},
keywords = {IoT, classroom, learning spaces, mobility tracking, wearables},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3303772.3303789,
author = {Motz, Benjamin and Quick, Joshua and Schroeder, Noah and Zook, Jordon and Gunkel, Matthew},
title = {The validity and utility of activity logs as a measure of student engagement},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303789},
doi = {10.1145/3303772.3303789},
abstract = {Learning management system (LMS) web logs provide granular, near-real-time records of student behavior as learners interact with online course materials in digital learning environments. However, it remains unclear whether LMS activity indeed reflects behavioral properties of student engagement, and it also remains unclear how to deal with variability in LMS usage across a diversity of courses. In this study, we evaluate whether instructors' subjective ratings of their students' engagement are related to features of LMS activity for 9,021 students enrolled in 473 for-credit courses. We find that estimators derived from LMS web logs are closely related to instructor ratings of engagement, however, we also observe that there is not a single generic relationship between activity and engagement, and what constitutes the behavioral components of "engagement" will be contingent on course structure. However, for many of these courses, modeled engagement scores are comparable to instructors' ratings in their sensitivity for predicting academic performance. As long as they are tuned to the differences between courses, activity indices from LMS web logs can provide a valid and useful proxy measure of student engagement.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {300–309},
numpages = {10},
keywords = {LMS, student engagement, trace data, web logs},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3170358.3170380,
author = {Echeverria, Vanessa and Martinez-Maldonado, Roberto and Granda, Roger and Chiluiza, Katherine and Conati, Cristina and Buckingham Shum, Simon},
title = {Driving data storytelling from learning design},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170380},
doi = {10.1145/3170358.3170380},
abstract = {Data science is now impacting the education sector, with a growing number of commercial products and research prototypes providing learning dashboards. From a human-centred computing perspective, the end-user's interpretation of these visualisations is a critical challenge to design for, with empirical evidence already showing that `usable' visualisations are not necessarily effective from a learning perspective. Since an educator's interpretation of visualised data is essentially the construction of a narrative about student progress, we draw on the growing body of work on Data Storytelling (DS) as the inspiration for a set of enhancements that could be applied to data visualisations to improve their communicative power. We present a pilot study that explores the effectiveness of these DS elements based on educators' responses to paper prototypes. The dual purpose is understanding the contribution of each visual element for data storytelling, and the effectiveness of the enhancements when combined.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {131–140},
numpages = {10},
keywords = {dashboards, data storytelling, visual design, visualisations},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/3303772.3303815,
author = {Gal, Tomer and Hershkovitz, Arnon},
title = {Different Types of Response-Based Feedback in Mathematics: The case of textual and symbolic messages},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303815},
doi = {10.1145/3303772.3303815},
abstract = {The current study compares textual and symbolic elaborated, response-based feedback in mathematics. We use a randomized experiment in Khan Academy to measure feedback effect in four different topics. Overall, we point out to the superiority of symbolic feedback.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {265–269},
numpages = {5},
keywords = {Response-based feedback, computer-based learning, log analysis, mathematics education},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3303772.3303777,
author = {Niaki, Sahba Akhavan and George, Clint P. and Michailidis, George and Beal, Carole R.},
title = {The Impact of an Online Tutoring Program for Algebra Readiness on Mathematics Achievements; Results of a Randomized Experiment},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303777},
doi = {10.1145/3303772.3303777},
abstract = {We study the impact of an online tutoring program, AnimalWatch, for algebra readiness on mathematics achievements of grade 6 students. We use the data from a randomized experimental design conducted on 69 teachers and 2025 students in California in the academic years 2011-2012. After a brief description of the experimental design and the system implementation, we analyze the treatment effect of employing AnimalWatch using the popular hierarchical linear models and find a small positive effect. We further use the logged system usage data such as time spent in the system, modules completed, correct/incorrect/no-answers records of students in each login to analyze how system implementation and usage helped different students. Our results provide insights into the limitations in implementing such a study in a real world setting and suggests recommendations for future research.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {363–372},
numpages = {10},
keywords = {Hierarchical linear models, Matheducation, Online tutoring platform, Randomized control trial(RCT)},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@article{10.1145/3120259,
author = {Carter, Adam S. and Hundhausen, Christopher D. and Adesope, Olusola},
title = {Blending Measures of Programming and Social Behavior into Predictive Models of Student Achievement in Early Computing Courses},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
url = {https://doi.org/10.1145/3120259},
doi = {10.1145/3120259},
abstract = {Analyzing the process data of students as they complete programming assignments has the potential to provide computing educators with insights into both their students and the processes by which they learn to program. In prior research, we explored the relationship between (a) students’ programming behaviors and course outcomes, and (b) students’ participation within an online social learning environment and course outcomes. In both studies, we developed statistical measures derived from our data that significantly correlate with students’ course grades. Encouraged both by social theories of learning and a desire to improve the accuracy of our statistical models, we explore here the impact of incorporating our predictive measure derived from social behavior into three separate predictive measures derived from programming behaviors. We find that, in combining the measures, we are able to improve the overall predictive power of each measure. This finding affirms the importance of social interaction in the learning process, and provides evidence that predictive models derived from multiple sources of learning process data can provide significantly better predictive power by accounting for multiple factors responsible for student success.},
journal = {ACM Trans. Comput. Educ.},
month = aug,
articleno = {12},
numpages = {20},
keywords = {Learning analytics, learning interventions, learning process data}
}

@inproceedings{10.1145/3702163.3702433,
author = {Narimani, Amir and Barbera, Elena and Lundqvist, Karsten \O{}ster},
title = {Academic Advising for Online Higher Education Enrolment Based on Course Association Rules},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702433},
doi = {10.1145/3702163.3702433},
abstract = {Course enrolment is a critical aspect of a student's academic journey, and the ability to make informed decisions about which courses to take can greatly impact their educational success. A key factor that often goes unnoticed is the sequence in which courses are enrolled, which can significantly affect a student's ability to excel in their studies. This study delves into the relationship between course enrolment patterns and students’ performance. This paper presents an innovative approach that combines course enrolment association rule mining with the incorporation of grade score measures, aiming to provide a robust framework for informed academic decision support. Association rule mining is applied to identify patterns and relationships among the courses students have previously enrolled in. These patterns reveal the popularity of certain courses being chosen after the other. Interestingly enough, it has been observed that following a common enrolment pattern can cause a big drop or increase in different student groups. The extracted association rules not only assist with course recommendations but also enable academic advisors to caution students or prevent them from enrolling in courses where lower grades are predicted, particularly for students at risk of dropping out of studies. This paper presents a framework for improving the course selection process to advise students with different academic performances to enroll in a course or avoid it, benefiting both students and educational institutions. We used the dataset of Universitat Oberta de Catalunya on Informatics undergraduate studies for eight academic semesters to implement and evaluate the proposed method. The initial results show that integrating association rule mining with grade score measures in course enrolment decision-making offers a promising avenue for enhancing the quality of academic advising for course enrolment recommendations.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {324–331},
numpages = {8},
keywords = {Academic Advising, Association Rule Mining, Course Enrolment, Course Recommendations, Learning Analytics},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3512731.3534208,
author = {Gan, Wenbin and Dao, Minh Son and Zettsu, Koji and Sun, Yuan},
title = {IoT-based Multimodal Analysis for Smart Education: Current Status, Challenges and Opportunities},
year = {2022},
isbn = {9781450392419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512731.3534208},
doi = {10.1145/3512731.3534208},
abstract = {IoT-based multimodal learning analytics promises to obtain an in-depth understanding of the learning process. It provides the insights for not only the explicit learning indicators but also the implicit attributes of learners, based on which further potential learning support can be timely provided in both physical and cyber world accordingly. In this paper, we present a systematic review of the existing studies for examining the empirical evidences on the usage of IoT data in education and the capabilities of multimodal analysis to provide useful insights for smarter education. In particular, we classify the multimodal data into four categories based on the data sources (data from digital, physical, physiological and environmental spaces). Moreover, we propose a concept framework for better understanding the current state of the filed and summarize the insights into six main themes (learner behavior understanding, learner affection computing, smart learning environment, learning performance prediction, group collaboration modeling and intelligent feedback) based on the objectives for intelligent learning. The associations between different combinations of data modalities and various learning indicators are comprehensively discussed. Finally, the challenges and future directions are also presented from three aspects.},
booktitle = {Proceedings of the 3rd ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
pages = {32–40},
numpages = {9},
keywords = {IoT in education, internet of things, learning analytics, multimodal analysis, smart education},
location = {Newark, NJ, USA},
series = {ICDAR '22}
}

@inproceedings{10.1145/3170358.3170418,
author = {Cooper, Kendra and Khosravi, Hassan},
title = {Graph-based visual topic dependency models: supporting assessment design and delivery at scale},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170418},
doi = {10.1145/3170358.3170418},
abstract = {Educational environments continue to rapidly evolve to address the needs of diverse, growing student populations, while embracing advances in pedagogy and technology. In this changing landscape ensuring the consistency among the assessments for different offerings of a course (within or across terms), providing meaningful feedback about students' achievements, and tracking students' progression over time are all challenging tasks, particularly at scale. Here, a collection of visual Topic Dependency Models (TDMs) is proposed to help address these challenges. It visualises the required topics and their dependencies at a course level (e.g., CS 100) and assessment achievement data at the classroom level (e.g., students in CS 100 Term 1 2016 Section 001) both at one point in time (static) and over time (dynamic). The collection of TDMs share a common, two-weighted graph foundation. An algorithm is presented to create a TDM (static achievement for a cohort). An open-source, proof of concept implementation of the TDMs is under development; the current version is described briefly in terms of its support for visualising existing (historical, test) and synthetic data generated on demand.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {11–15},
numpages = {5},
keywords = {graph algorithms, student assessment, visual analytics},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/3421682.3421698,
author = {Chong, Sylvia and Lee, Yew Haur and Tang, Yoke Wah},
title = {Data Analytics and Visualization to Support the Adult Learner in Higher Education},
year = {2020},
isbn = {9781450388771},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421682.3421698},
doi = {10.1145/3421682.3421698},
abstract = {Data analytics can be used by higher education to have a deeper understanding of the learners and their learning. As the use of data analytics become more common, educators are often required not only to make sense of the analytics, but also make meaning pedagogically to better support the learner and the learning. This paper discusses the conceptualization and implementation of targeted learner support and intervention with the use of learning analytics and data visualization for the adult learner in higher education. The key objective is to leverage on learners’ metrics in a format with visual indicators that give an overview of various aspects of the learning so that higher education institutions can profile their adult learners and anticipate their needs with customized advisories and intervention approaches. The learner metrics is presented in two different dashboards, applying both descriptive and predictive analytics, to provide deeper insights.},
booktitle = {2020 The 4th International Conference on E-Society, E-Education and E-Technology},
pages = {126–131},
numpages = {6},
keywords = {Learning analytics, adult learners, data visualization},
location = {Taipei, Taiwan},
series = {ICSET'20}
}

@inproceedings{10.1145/3027385.3029451,
author = {Manai, Ouajdi and Yamada, Hiroyuki},
title = {How can we accelerate dissemination of knowledge and learning? developing an online knowledge management platform for networked improvement communities},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029451},
doi = {10.1145/3027385.3029451},
abstract = {The Networked Improvement Learning and Support (NILS) platform is an online tool designed to accelerate the initiation and development of Networked Improvement Communities in a disciplined manner. Its main goal is to promote social, organizational learning through curation and synthesis and tacit to explicit knowledge conversion to facilitate knowledge construction and ownership by the communities regarding improvement practice in education. In this proposal we will discuss the NILS platform, a few use cases, and a plan of analytics development that advances knowledge dissemination and monitors the health status of networks.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {548–549},
numpages = {2},
keywords = {behavior modeling, curation, dissemination, improvement, improvement science, knowledge management systems, machine learning, networked improvement community, recommender engine, social network analysis, social pressure, statistical analysis},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3303772.3303797,
author = {Harpstead, Erik and Richey, J. Elizabeth and Nguyen, Huy and McLaren, Bruce M.},
title = {Exploring the Subtleties of Agency and Indirect Control in Digital Learning Games},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303797},
doi = {10.1145/3303772.3303797},
abstract = {How do the features of a learning environment's user interface impact learners' agency and, further, their learning? We explored this question in the context of Decimal Point, a digital learning game designed to support middle school students in learning decimals. Previous studies of the game showed that giving students the ability to choose the order and number of mini-games to play did not significantly impact their learning outcomes compared to a condition without choice. In this paper we explore whether some elements of the game's interface may have inadvertently exerted indirect control over students' choice, leading to the previous effects. We conducted a classroom study using a new version of the game that varied whether students saw a visual path connecting mini-games on the game map to modulate the level of indirect control students would experience with an implied ordering. Ultimately, we found that students in the no-line condition exercised significantly more agency but did not learn any less than the line condition. These results suggest that indirect control can be a subtle but powerful way to direct student attention in digital learning games.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {121–129},
numpages = {9},
keywords = {Digital learning games, agency, indirect control, self-regulated learning},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3649217.3653639,
author = {\v{S}v\'{a}bensk\'{y}, Valdemar and Vykopal, Jan and Hor\'{a}k, Martin and Hofbauer, Martin and \v{C}eleda, Pavel},
title = {From Paper to Platform: Evolution of a Novel Learning Environment for Tabletop Exercises},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653639},
doi = {10.1145/3649217.3653639},
abstract = {For undergraduate students of computing, learning to solve complex practical problems in a team is an essential skill for their future careers. This skill is needed in various fields, such as in cybersecurity and IT governance. Tabletop exercises are an innovative teaching method used in practice for training teams in incident response and evaluation of contingency plans. However, tabletop exercises are not yet widely established in university education. This paper presents data and teaching experience from a cybersecurity course that introduces tabletop exercises in classrooms using a novel technology: INJECT Exercise Platform (IXP), a web-based learning environment for delivering and evaluating the exercises. This technology substantially improves the prior practice, since tabletop exercises worldwide have usually been conducted using pen and paper. Unlike in traditional tabletop exercises, which are difficult to evaluate manually, IXP provides insights into students' behavior and learning based on automated analysis of interaction data. We demonstrate IXP's capabilities and evolution by comparing exercise sessions hosted throughout three years at different stages of the platform's readiness. The analysis of student data is supplemented by the discussion of the lessons learned from employing IXP in computing education contexts. The data analytics enabled a detailed comparison of the teams' performance and behavior. Instructors who consider innovating their classes with tabletop exercises may use IXP and benefit from the insights in this paper.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {213–219},
numpages = {7},
keywords = {INJECT, cybersecurity, hands-on training, incident response, learning analytics, tabletop exercise, team collaboration},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3643655.3643876,
author = {Rossi, Maria Teresa and Tundo, Alessandro and Mariani, Leonardo},
title = {Towards Model-Driven Dashboard Generation for Systems-of-Systems},
year = {2024},
isbn = {9798400705571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643655.3643876},
doi = {10.1145/3643655.3643876},
abstract = {Configuring and evolving dashboards in complex and large-scale Systems-of-Systems (SoS) can be an expensive and cumbersome task due to the many Key Performance Indicators (KPIs) that are usually collected and have to be arranged in a number of visualizations. Unfortunately, setting up dashboards is still a largely manual and error-prone task requiring extensive human intervention.This short paper describes emerging results about the definition of a model-driven technology-agnostic approach that can automatically transform a simple list of KPIs into a dashboard model, and then translate the model into an actual dashboard for a target dashboard technology. Dashboard customization can be efficiently obtained by solely modifying the abstract model representation, freeing operators from expensive interactions with actual dashboards.},
booktitle = {Proceedings of the 12th ACM/IEEE International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
pages = {9–12},
numpages = {4},
keywords = {automatic dashboard generation, model-driven engineering, model-based dashboard, systems of systems, monitoring dashboard},
location = {Lisbon, Portugal},
series = {SESoS '24}
}

@inproceedings{10.1145/3027385.3029464,
author = {Stoeffler, Kristin and Rosen, Yigal and von Davier, Alina},
title = {Exploring the measurement of collaborative problem solving using a human-agent educational game},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029464},
doi = {10.1145/3027385.3029464},
abstract = {Collaborative problem solving (CPS) is a process that relies on both cognitive and social skills contributions by those involved in the joint activity. If a student is matched with a problematic group of peers, then there will be no valid measurement of the CPS skills. In the human-agent settings, CPS skills are measured by pairing each individual student with a computer agent or agents that can be programmed to act as team members with varying characteristics relevant to different CPS skills and contexts. This paper describes current research on measuring CPS skills through human-agent interactions in a prototype of a collaborative educational game.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {570–571},
numpages = {2},
keywords = {collaborative problem solving, computer agent, performance assessment, teamwork},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3027385.3027451,
author = {Holstein, Kenneth and McLaren, Bruce M. and Aleven, Vincent},
title = {Intelligent tutors as teachers' aides: exploring teacher needs for real-time analytics in blended classrooms},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027451},
doi = {10.1145/3027385.3027451},
abstract = {Intelligent tutoring systems (ITSs) are commonly designed to enhance student learning. However, they are not typically designed to meet the needs of teachers who use them in their classrooms. ITSs generate a wealth of analytics about student learning and behavior, opening a rich design space for real-time teacher support tools such as dashboards. Whereas real-time dashboards for teachers have become popular with many learning technologies, we are not aware of projects that have designed dashboards for ITSs based on a broad investigation of teachers' needs. We conducted design interviews with ten middle school math teachers to explore their needs for on-the-spot support during blended class sessions, as a first step in a user-centered design process of a real-time dashboard. Based on multi-methods analyses of this interview data, we identify several opportunities for ITSs to better support teachers' needs, noting that the analytics commonly generated by existing teacher support tools do not strongly align with the analytics teachers expect to be most useful. We highlight key tensions and tradeoffs in the design of such real-time supports for teachers, as revealed by "Speed Dating" possible futures with teachers. This paper has implications for our ongoing co-design of a real-time dashboard for ITSs, as well as broader implications for the design of ITSs that can effectively collaborate with teachers in classroom settings.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {257–266},
numpages = {10},
keywords = {adoption, blended learning, classrooms, intelligent tutoring systems, pedagogical decision-making, real-time analytics, teachers},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3027385.3027450,
author = {Holstein, Kenneth and McLaren, Bruce M. and Aleven, Vincent},
title = {SPACLE: investigating learning across virtual and physical spaces using spatial replays},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027450},
doi = {10.1145/3027385.3027450},
abstract = {Classroom experiments that evaluate the effectiveness of educational technologies do not typically examine the effects of classroom contextual variables (e.g., out-of-software help-giving and external distractions). Yet these variables may influence students' instructional outcomes. In this paper, we introduce the Spatial Classroom Log Explorer (SPACLE): a prototype tool that facilitates the rapid discovery of relationships between within-software and out-of-software events. Unlike previous tools for retrospective analysis, SPACLE replays moment-by-moment analytics about student and teacher behaviors in their original spatial context. We present a data analysis workflow using SPACLE and demonstrate how this workflow can support causal discovery. We share the results of our initial replay analyses using SPACLE, which highlight the importance of considering spatial factors in the classroom when analyzing ITS log data. We also present the results of an investigation into the effects of student-teacher interactions on student learning in K-12 blended classrooms, using our workflow, which combines replay analysis with SPACLE and causal modeling. Our findings suggest that students' awareness of being monitored by their teachers may promote learning, and that "gaming the system" behaviors may extend outside of educational software use.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {358–367},
numpages = {10},
keywords = {blended learning, causal modeling, classroom, intelligent tutoring systems, teachers, visualizations},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3594739.3610769,
author = {Watanabe, Ko and Dengel, Andreas and Ishimaru, Shoya},
title = {Accelerating Knowledge Transfer by Sensing and Actuating Social-Cognitive States},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610769},
doi = {10.1145/3594739.3610769},
abstract = {Knowledge Transfer is one of the essential principles in education. The teacher’s knowledge is encoded through speech and writing and transmitted to the student. The student then decodes the transmitted information according to individual capabilities and absorbs it as knowledge. This paper presents an approach to accelerate knowledge transfer using sensor technology and social-cognitive states. So far, we have worked on quantifying meeting discussions, analyzing lecture studies, and estimating domain knowledge from web browsing. The contribution of this study is to estimate the degree of achievement of knowledge transfer and to accelerate it based on the estimated results.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing &amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {258–262},
numpages = {5},
keywords = {Education, Knowledge Transfer, Learning Analytics, e-Learning},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3027385.3029458,
author = {Sluijter, J. and Otten, M.},
title = {Business intelligence (BI) for personalized student dashboards},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3029458},
doi = {10.1145/3027385.3029458},
abstract = {At Stenden University students from all over the world study together; all these different nationalities and cultures result in different ideas concerning academic success. The basis of this project was to develop a personalized dashboard for students via Microsoft Office 365 Power BI in which students can set their own personal KPI's. The raw data from the Student Information System (SIS) was transformed into clear visualizations that will help students gain better insight into their academic performance. This information can be used either independently or in consultation with their student advisor.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {562–563},
numpages = {2},
keywords = {business intelligence, excel, grade goals, personalized dashboards, power BI, power query},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/2883851.2883888,
author = {Ruiz, Samara and Charleer, Sven and Urretavizcaya, Maite and Klerkx, Joris and Fern\'{a}ndez-Castro, Isabel and Duval, Erik},
title = {Supporting learning by considering emotions: tracking and visualization a case study},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883888},
doi = {10.1145/2883851.2883888},
abstract = {The adequate emotional state of students has proved to be essential for favoring learning. This paper explores the possibility of obtaining students' feedback about the emotions they feel in class in order to discover potential emotion patterns that might indicate learning fails. This paper presents a visual dashboard that allows students to track their emotions and follow up on their evolution during the course. We have compiled the principal classroom related emotions and developed a two-phase inquiry process to: verify the possibility to measure students' emotions in classroom; discover how emotions can be displayed to promote self-reflection; and confirm the impact of emotions on learning performance. Our results suggest that students' emotions in class are related to evaluation marks. This shows that early information about students' emotions can be useful for teachers and students to improve classroom results and learning outcomes.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {254–263},
numpages = {10},
keywords = {face to face interactions, quantified-self, self-reflection, students' emotions, visual dashboards, visualization},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3341525.3387410,
author = {Singh, Shaveen and Meyer, Bernd and Wybrow, Michael},
title = {UserFlow: A Tool for Visualizing Fine-grained Contextual Analytics in Teaching Documents},
year = {2020},
isbn = {9781450368742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341525.3387410},
doi = {10.1145/3341525.3387410},
abstract = {The adoption of innovative online teaching tools in Computer Science (CS) courses provides opportunities for data-informed instruction as a regular teaching practice in CS classrooms. In this paper, we present a design study for an interactive visual analytics dashboard, called UserFlow, that supports feedback collection from teaching documents and assists instructors in interpreting feedback and acting on it in a timely manner. The design study is conducted with eight domain experts comprising of four teaching instructors, two learning analytics (LA) experts and two instructional designers. UserFlow offers a set of novel visualization designs for presenting the four interleaving aspects of document engagement (i.e., annotations, document traversal path, reading/focus time and student information). We evaluated UserFlow in an undergraduate computer science course with over 700 students. Our results demonstrate the usefulness and need for such a tool for CS educators to inform teaching approaches and courseware improvement.},
booktitle = {Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {384–390},
numpages = {7},
keywords = {annotations, dashboards, digital education, engagement, learning analytics},
location = {Trondheim, Norway},
series = {ITiCSE '20}
}

@inproceedings{10.1145/2330601.2330637,
author = {Laur\'{\i}a, Eitel J. M. and Baron, Joshua D. and Devireddy, Mallika and Sundararaju, Venniraiselvi and Jayaprakash, Sandeep M.},
title = {Mining academic data to improve college student retention: an open source perspective},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330637},
doi = {10.1145/2330601.2330637},
abstract = {In this paper we report ongoing research on the Open Academic Analytics Initiative (OAAI), a project aimed at increasing college student retention by performing early detection of academic risk using data mining methods. The paper describes the goals and objectives of the OAAI, and lays out a methodological framework to develop models that can be used to perform inferential queries on student performance using open source course management system data and student academic records. Preliminary results on initial model development using several data mining algorithms for classification are presented.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {139–142},
numpages = {4},
keywords = {course management systems, data mining, learning analytics, open source},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/3334480.3382947,
author = {Britain, Gabriel and Jain, Ajit and Lupfer, Nic and Kerne, Andruid and Perrine, Aaron and Seo, Jinsil and Sungkajun, Annie},
title = {Design is (A)live: An Environment Integrating Ideation and Assessment},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382947},
doi = {10.1145/3334480.3382947},
abstract = {Design coursework is iterative and continuously-evolving. Separation of digital tools used in design courses disaffects instructors' and students' iterative process experiences.We present a system that integrates support for design ideation with a learning analytics dashboard. A preliminary study deployed the system in two courses, each with ~15 students and 1 instructor, for three months. We conducted semi-structured interviews to understand user experiences.Findings indicate benefits when systems contextualize creative work with assessment by integrating support for ideation with a learning analytics dashboard. Instructors are better able to track students and their work. Students are supported in reflecting on relationships among deliverables. We derive implications for contextualizing design with feedback to support creativity, learning, and teaching.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {creativity, design assessment, design education, design ideation, iterative design, learning analytics dashboard},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/2883851.2883876,
author = {Renz, Jan and Hoffmann, Daniel and Staubitz, Thomas and Meinel, Christoph},
title = {Using A/B testing in MOOC environments},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883876},
doi = {10.1145/2883851.2883876},
abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon offering the possibility to teach thousands of participants simultaneously. In the same time the platforms used to deliver these courses are still in their fledgling stages. While course content and didactics of those massive courses are the primary key factors for the success of courses, still a smart platform may increase or decrease the learners experience and his learning outcome. The paper at hand proposes the usage of an A/B testing framework that is able to be used within an micro-service architecture to validate hypotheses about how learners use the platform and to enable data-driven decisions about new features and settings. To evaluate this framework three new features (Onboarding Tour, Reminder Mails and a Pinboard Digest) have been identified based on a user survey. They have been implemented and introduced on two large MOOC platforms and their influence on the learners behavior have been measured. Finally this paper proposes a data driven decision workflow for the introduction of new features and settings on e-learning platforms.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {304–313},
numpages = {10},
keywords = {A/B testing, MOOC, controlled online tests, e-learning, microservice},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3434780.3436562,
author = {Gomez, Manuel J. and Ruip\'{e}rez-Valiente, Jos\'{e} A. and Martinez, Pedro A. and Kim, Yoon Jeon},
title = {Exploring the Affordances of Sequence Mining in Educational Games},
year = {2021},
isbn = {9781450388504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3434780.3436562},
doi = {10.1145/3434780.3436562},
abstract = {Games have become one of the most popular mediums across cultures and ages and the use of educational games is growing. There is ample evidence that supports the benefits of using games for learning and assessment. However, we do not usually find games incorporated into educational environments. One of the main problems that teachers face is to actually know how students are interacting with the game as they cannot analyze properly the effect of the activity on the students. To improve this issue, we can use the data generated by the interaction of students with such educational games to analyze the sequences and errors by transforming raw data into meaningful sequences that are interpretable and actionable for teachers. In this study we use a data collection from our game Shadowspect and implement learning analytics with process and sequence mining techniques to generate two metrics that aim to help teachers make proper assessment and better understand the process.},
booktitle = {Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {648–654},
numpages = {7},
keywords = {Educational games, game-based assessment, learning analytics, sequence mining},
location = {Salamanca, Spain},
series = {TEEM'20}
}

@inproceedings{10.1145/3231644.3231669,
author = {Bassen, Jonathan and Howley, Iris and Fast, Ethan and Mitchell, John and Thille, Candace},
title = {OARS: exploring instructor analytics for online learning},
year = {2018},
isbn = {9781450358866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231644.3231669},
doi = {10.1145/3231644.3231669},
abstract = {Learning analytics systems have the potential to bring enormous value to online education. Unfortunately, many instructors and platforms do not adequately leverage learning analytics in their courses today. In this paper, we report on the value of these systems from the perspective of course instructors. We study these ideas through OARS, a modular and real-time learning analytics system that we deployed across more than ten online courses with tens of thousands of learners. We leverage this system as a starting point for semi-structured interviews with a diverse set of instructors. Our study suggests new design goals for learning analytics systems, the importance of real-time analytics to many instructors, and the value of flexibility in data selection and aggregation for an instructor when working with an analytics system.},
booktitle = {Proceedings of the Fifth Annual ACM Conference on Learning at Scale},
articleno = {55},
numpages = {10},
keywords = {instructor-centered design, learning analytics, real-time systems},
location = {London, United Kingdom},
series = {L@S '18}
}

@inproceedings{10.1145/3536220.3558037,
author = {Ciordas-Hertel, George-Petru and Biedermann, Daniel and Winter, Marc and Mordel, Julia and Drachsler, Hendrik},
title = {How can Interaction Data be Contextualized with Mobile Sensing to Enhance Learning Engagement Assessment in Distance Learning?},
year = {2022},
isbn = {9781450393898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3536220.3558037},
doi = {10.1145/3536220.3558037},
abstract = {Multimodal learning analytics can enrich interaction data with contextual information through mobile sensing. Information about, for example, the physical environment, movement, physiological signals, or smart wearable usage. Through the use of smart wearables, contextual information can thus be captured and made available again to students in further processing steps so that they can reflect and annotate it. This paper describes a software infrastructure and a study design that successfully captured contextual information utilizing mobile sensing using students’ smart wearables in distance learning. In the conducted study, data was collected from the smartphones of 76 students as they self-directedly participated in an online learning unit using a learning management system (LMS) over a two-week period. During the students’ active phases in the LMS, interaction data as well as state and trait measurements were collected by the LMS. Simultaneously, hardware sensor data, app usage data, interaction with notifications, and ecological momentary assessments (EMA) were automatically but transparently collected from the students’ smartphones. Finally, this paper describes some preliminary insights from the study process and their implications for further data processing.},
booktitle = {Companion Publication of the 2022 International Conference on Multimodal Interaction},
pages = {105–112},
numpages = {8},
keywords = {context-awareness, distance learning, learning engagement, mobile sensing, multimodal learning analytics, physical learning environment},
location = {Bengaluru, India},
series = {ICMI '22 Companion}
}

@inproceedings{10.1145/2637748.2638435,
author = {Ray\'{o}n, Alex and Guenaga, Mariluz and N\'{u}\~{n}ez, Asier},
title = {Integrating and visualizing learner and social data to elicit higher-order indicators in SCALA dashboard},
year = {2014},
isbn = {9781450327695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2637748.2638435},
doi = {10.1145/2637748.2638435},
abstract = {The assessment of competencies is a difficult task; on one hand due to its subjective nature, and, on the other one, because of the difficulties to make it scalable and simple. Since ICT are becoming increasingly important learning mediating tools, data stored in learning tools could yield a wealth of information that could serve as an indicator to measure students' progress and the development of competencies. However, the lack of data interoperability among different educational applications imposes a challenge to data mining and analytics that rely on diverse and distributed data. Besides, these educational technologies do neither usually provide a statistics module in which the teacher can obtain specific reports about students' performance, nor visualization tools to summarize student usage data. In response to this weakness, and based on the limitations encountered in existing tools, we have developed an integrated and extensible web tool called SCALA (Scalable Competency Assessment through a Learning Analytics approach) that not only shows but also mines using analytics techniques for the discovery of student patterns and metric relations in web-based educational systems.},
booktitle = {Proceedings of the 14th International Conference on Knowledge Technologies and Data-Driven Business},
articleno = {28},
numpages = {4},
keywords = {dashboard, data integration, information retrieval, large-scale interoperability, learning analytics, visual analytics},
location = {Graz, Austria},
series = {i-KNOW '14}
}

@inproceedings{10.1145/2883851.2883958,
author = {Hagood, Danielle and Ching, Cynthia Carter and Schaefer, Sara},
title = {Integrating physical activity data in videogames with user-centered dashboards},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883958},
doi = {10.1145/2883851.2883958},
abstract = {To promote healthy awareness and activity learning, we gave 12-to 14-year-old youth activity monitors (Fitbits) to track their physical activity, which was then integrated into a videogame we created. The players' real-world steps transform into in-game resources needed for gameplay. In addition to requiring real-world steps for various in-game activities, a dashboard in this game presents visual representations of activity patterns, ostensibly informing students about patterns of their own activity. In this paper and poster, we discuss challenges in initial designs of our dashboard. We present findings and challenges in the process of creating a user-centered dashboard and conclude with our future design goals.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {530–531},
numpages = {2},
keywords = {activity monitors (Fitbit), dashboards, health, quantified self, sociocultural theory},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1145/3361721.3361727,
author = {Kesselbacher, Max and Bollin, Andreas},
title = {Discriminating Programming Strategies in Scratch: Making the Difference between Novice and Experienced Programmers},
year = {2019},
isbn = {9781450377041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361721.3361727},
doi = {10.1145/3361721.3361727},
abstract = {Nowadays, block-based programming environments are often used to offer a gentle introduction to learning a programming language. However, an assessment of students' programming skills based on the results of a programming task is not sufficient to determine all areas students are struggling with. We therefore introduce a learning analytics approach of measuring and evaluating the programming sequences of students that program with Scratch 3. With our measurement framework, it is possible to record, store and analyze programming sequences done on a publicly-available, instrumented Scratch 3 environment. Changes in the programming sequence are categorized regarding the used block types and types of program change. We conducted an exploratory programming trial with lower and upper secondary school students to investigate small-scale programming strategies in the recorded programming sequences. Our goals are to identify students in need of support and to identify recurring patterns used by students successful in the trial. Clustering with k-means makes it possible to identify struggling students based on both interacted block types and types of program changes. Recurring patterns in the programming sequences of successful students show that small-scale programming strategies are very diverse.},
booktitle = {Proceedings of the 14th Workshop in Primary and Secondary Computing Education},
articleno = {20},
numpages = {10},
keywords = {block-based programming, learning analytics, programming patterns},
location = {Glasgow, Scotland, Uk},
series = {WiPSCE '19}
}

@inproceedings{10.1145/2567574.2567577,
author = {Simsek, Duygu and Buckingham Shum, Simon and De Liddo, Anna and Ferguson, Rebecca and S\'{a}ndor, \'{A}gnes},
title = {Visual analytics of academic writing},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567577},
doi = {10.1145/2567574.2567577},
abstract = {This paper describes a novel analytics dashboard which visualises the key features of scholarly documents. The Dashboard aggregates the salient sentences of scholarly papers, their rhetorical types and the key concepts mentioned within these sentences. These features are extracted from papers through a Natural Language Processing (NLP) technology, called Xerox Incremental Parser (XIP). The XIP Dashboard is a set of visual analytics modules based on the XIP output. In this paper, we briefly introduce the XIP technology and demonstrate an example visualisation of the XIP Dashboard.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {265–266},
numpages = {2},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/3027385.3027398,
author = {Kovanovi\'{c}, Vitomir and Joksimovi\'{c}, Sre\'{c}ko and Katerinopoulos, Philip and Michail, Charalampos and Siemens, George and Ga\v{s}evi\'{c}, Dragan},
title = {Developing a MOOC experimentation platform: insights from a user study},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027398},
doi = {10.1145/3027385.3027398},
abstract = {In 2011, the phenomenon of MOOCs had swept the world of education and put online education in the focus of the public discourse around the world. Although researchers were excited with the vast amounts of MOOC data being collected, the benefits of this data did not stand to the expectations due to several challenges. The analyses of MOOC data are very time-consuming and labor-intensive, and require and require a highly advanced set of technical skills, often not available to the education researchers. Because of this MOOC data analyses are rarely done before the courses end, limiting the potential of data to impact the student learning outcomes and experience.In this paper we introduce MOOCito (MOOC intervention tool), a user-friendly software platform for the analysis of MOOC data, that focuses on conducting data-informed instructional interventions and course experimentations. We cover important design principles behind MOOCito and provide an overview of the trends in MOOC research leading to its development. Although a work-in-progress, in this paper, we outline the prototype of MOOCito and the results of a user evaluation study that focused on system's perceived usability and ease-of-use. The results of the study are discussed, as well as their practical implications.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {1–5},
numpages = {5},
keywords = {A/B testing, Coursera, MOOCs, analysis platform, controlled experiments, technology acceptance model, user study},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/2883851.2883943,
author = {Karkalas, Sokratis and Mavrikis, Manolis and Labs, Oliver},
title = {Towards analytics for educational interactive e-books: the case of the reflective designer analytics platform (RDAP)},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883943},
doi = {10.1145/2883851.2883943},
abstract = {This paper presents an analytics dashboard that has been developed for designers of interactive e-books. This is part of the EU-funded MC Squared project that is developing a platform for authoring interactive educational e-books. The primary objective is to develop technologies and resources that enhance creative thinking for both designers (authors) and learners. The learning material is expected to offer learners opportunities to engage creatively with mathematical problems and develop creative mathematical thinking. The analytics dashboard is designed to increase authors' awareness so that they can make informed decisions on how to redesign and improve the e-books. This paper presents architectural and design decisions on key features of the dashboard and discusses future steps with respect to the potential for exploratory data analysis.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {143–147},
numpages = {5},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@article{10.1145/3513140,
author = {Paiva, Jos\'{e} Carlos and Leal, Jos\'{e} Paulo and Figueira, \'{A}lvaro},
title = {Automated Assessment in Computer Science Education: A State-of-the-Art Review},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
url = {https://doi.org/10.1145/3513140},
doi = {10.1145/3513140},
abstract = {Practical programming competencies are critical to the success in computer science (CS) education and go-to-market of fresh graduates. Acquiring the required level of skills is a long journey of discovery, trial and error, and optimization seeking through a broad range of programming activities that learners must perform themselves. It is not reasonable to consider that teachers could evaluate all attempts that the average learner should develop multiplied by the number of students enrolled in a course, much less in a timely, deep, and fair fashion. Unsurprisingly, exploring the formal structure of programs to automate the assessment of certain features has long been a hot topic among CS education practitioners. Assessing a program is considerably more complex than asserting its functional correctness, as the proliferation of tools and techniques in the literature over the past decades indicates. Program efficiency, behavior, and readability, among many other features, assessed either statically or dynamically, are now also relevant for automatic evaluation. The outcome of an evaluation evolved from the primordial Boolean values to information about errors and tips on how to advance, possibly taking into account similar solutions. This work surveys the state of the art in the automated assessment of CS assignments, focusing on the supported types of exercises, security measures adopted, testing techniques used, type of feedback produced, and the information they offer the teacher to understand and optimize learning. A new era of automated assessment, capitalizing on static analysis techniques and containerization, has been identified. Furthermore, this review presents several other findings from the conducted review, discusses the current challenges of the field, and proposes some future research directions.},
journal = {ACM Trans. Comput. Educ.},
month = jun,
articleno = {34},
numpages = {40},
keywords = {Automated assessment, computer science, programming, feedback, learning analytics}
}

@inproceedings{10.1145/3491140.3528312,
author = {Hsu, Shu-Yi and Tutwiler, M. Shane},
title = {How Much and for Whom? A Multi-Wave Study of the Impact of Self-Regulated Learning Scaffolds on MOOC Student Academic Performance},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528312},
doi = {10.1145/3491140.3528312},
abstract = {With an effort to ameliorate the high dropout rates and the low performance in the massive open online courses (MOOCs), this paper presents multi-wave, experimental studies with a longitudinal intervention of self-regulated learning scaffolds on 24 MOOCs for 2650 learners. The self-regulated learning user interface (SRLUI) is designed based on Zimmerman's SRL cyclical model with a learning dashboard, interactive user interface, nudging effect. SRLUI is designed with two goals: 1. manifesting learner self-regulated learning behavior 2. enhancing learning outcomes. In this study, our primary research question is, "What is the marginal effect of SRLUI on learning as evidenced by final course grade?" To answer the research question, we employed a multilevel Bayesian beta regression modeling approach, first to each intervention and then across all three interventions in the aggregate. Our findings were mixed. We found some evidence of enhanced learning for passing and non-passing students across some of the individual interventions. On the whole, we determined that there was no statistical evidence of positive impacts on learning for students who pass a given course, though there is evidence of a small positive impact on learning for students who did not ultimately pass a given course. We discuss potential reasons for this differential impact and its implication for future course design and research.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {350–354},
numpages = {5},
keywords = {bayesian regression, learning analytics, moocs, multilevel modeling, self-regulated learning},
location = {New York City, NY, USA},
series = {L@S '22}
}

@inproceedings{10.1145/3498765.3498777,
author = {Maraza Quispe, Benjamin and Edwar Ninasivincha Apfata, Jhon and Carlos Qusipe Figueroa, Ricardo and Alejandro Valderrama Solis, Manuel},
title = {Design proposal of a personalized Dashboard to optimize teaching-learning in Virtual Learning Environments},
year = {2022},
isbn = {9781450385114},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3498765.3498777},
doi = {10.1145/3498765.3498777},
abstract = {The objective of the research is to develop a methodology to analyze a set of data extracted from a Learning Management System (LMS), in order to implement a Dashboard, which can be used by teachers to make timely and relevant decisions to improve the teaching-learning processes. The methodology used consisted of the analysis of 9,257 records extracted through simple random sampling from a population of 100,000 records. The indicators analyzed were: number of accesses, course grades, time spent, number of courses enrolled and number of activities developed. The results show the data analysis in the KNIME data mining analysis platform, the model was implemented in five phases: Requirements definition, model design, development, implementation and evaluation of results. The results are taken as a recommendation to design and implement a customized Dashboard for teachers to identify observable behavioral patterns that allow them to make decisions to improve the teaching-learning processes of students.},
booktitle = {Proceedings of the 13th International Conference on Education Technology and Computers},
pages = {77–84},
numpages = {8},
keywords = {Dashboard, EVE, LMS, learning, personalized, teaching},
location = {Wuhan, China},
series = {ICETC '21}
}

@inproceedings{10.1145/3027385.3027421,
author = {Kopeinik, Simone and Lex, Elisabeth and Seitlinger, Paul and Albert, Dietrich and Ley, Tobias},
title = {Supporting collaborative learning with tag recommendations: a real-world study in an inquiry-based classroom project},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027421},
doi = {10.1145/3027385.3027421},
abstract = {In online social learning environments, tagging has demonstrated its potential to facilitate search, to improve recommendations and to foster reflection and learning.Studies have shown that shared understanding needs to be established in the group as a prerequisite for learning. We hypothesise that this can be fostered through tag recommendation strategies that contribute to semantic stabilization. In this study, we investigate the application of two tag recommenders that are inspired by models of human memory: (i) the base-level learning equation BLL and (ii) Minerva. BLL models the frequency and recency of tag use while Minerva is based on frequency of tag use and semantic context. We test the impact of both tag recommenders on semantic stabilization in an online study with 56 students completing a group-based inquiry learning project in school. We find that displaying tags from other group members contributes significantly to semantic stabilization in the group, as compared to a strategy where tags from the students' individual vocabularies are used. Testing for the accuracy of the different recommenders revealed that algorithms using frequency counts such as BLL performed better when individual tags were recommended. When group tags were recommended, the Minerva algorithm performed better. We conclude that tag recommenders, exposing learners to each other's tag choices by simulating search processes on learners' semantic memory structures, show potential to support semantic stabilization and thus, inquiry-based learning in groups.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {409–418},
numpages = {10},
keywords = {base-level learning equation, cognitive user models, inquiry-based learning, minerva, personalized tag recommendations, real-world testing, semantic stabilization, technology enhanced learning},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@inproceedings{10.1145/3231644.3231696,
author = {Bektik, Duygu},
title = {XIPIt: updating the XIP dashboard to support educators in essay marking at higher education},
year = {2018},
isbn = {9781450358866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231644.3231696},
doi = {10.1145/3231644.3231696},
abstract = {Effective written communication is an essential skill which promotes educational success for undergraduates. However, undergraduate students, especially those in their first year at university, are unused to this form of writing. After their long experience with the schoolroom essay, for most undergraduates academic writing development is painstakingly slow. Thus, especially those with poor writing abilities, should write more to be better writers. Yet, the biggest impediment to more writing is that overburdened tutors would ask limited number of drafts from their students. Today, there exist powerful computational language technologies that could evaluate student writing, saving time and providing timely, speedy, reliable feedback which can support educators marking process. This paper motivates an updated visual analytics dashboard, XIPIt, to introduce a set of visual and writing analytics features embedded in a marking environment built on XIP output.},
booktitle = {Proceedings of the Fifth Annual ACM Conference on Learning at Scale},
articleno = {38},
numpages = {4},
keywords = {learning analytics, marking interface, undergraduate writing, visual dashboards, writing learning analytics},
location = {London, United Kingdom},
series = {L@S '18}
}

@inproceedings{10.1145/3626252.3630965,
author = {Bogart, Christopher and An, Marshall and Keylor, Eric and Singh, Pawanjeet and Savelka, Jaromir and Sakr, Majd},
title = {What Factors Influence Persistence in Project-based Programming Courses at Community Colleges?},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630965},
doi = {10.1145/3626252.3630965},
abstract = {The rapid adoption of emergent technologies is creating significant shortfall in the CS/IT workforce. With not enough students in the educational pipeline to meet the forthcoming demand over the next decade, community colleges are making the effort to train confident, knowledgeable, and self-driven workers in this field. Project-based learning (PBL) has been shown to be effective for these ends, but it poses distinct challenges in resource-limited community college contexts since it may require more time, preparation, and motivation than other teaching modalities, from both the student and the instructor. We studied fifteen sections of an introductory project-based Python course taught at six community colleges, investigating several features of PBL theorized to be particular barriers to student persistence, particularly among women and other identities traditionally underrepresented in technical fields. We describe successes and challenges faced by students in these areas and suggest implications for project-based learning curriculum and platform design.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {116–122},
numpages = {7},
keywords = {community colleges, computer science education, learning analytics, persistence, project-based learning, retention, self-efficacy},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3491140.3528298,
author = {Tsung, Sean and Wei, Huan and Li, Haotian and Wang, Yong and Xia, Meng and Qu, Huamin},
title = {BlockLens: Visual Analytics of Student Coding Behaviors in Block-Based Programming Environments},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528298},
doi = {10.1145/3491140.3528298},
abstract = {Block-based programming environments have been widely used to introduce K-12 students to coding. To guide students effectively, instructors and platform owners often need to understand behaviors like how students solve certain questions or where they get stuck and why. However, it is challenging for them to effectively analyze students' coding data. To this end, we propose BlockLens, a novel visual analytics system to assist instructors and platform owners in analyzing students' block-based coding behaviors, mistakes, and problem-solving patterns. BlockLens enables the grouping of students by question progress and performance, identification of common problem-solving strategies and pitfalls, and presentation of insights at multiple granularity levels, from a high-level overview of all students to a detailed analysis of one student's behavior and performance. A usage scenario using real-world data demonstrates the usefulness of BlockLens in facilitating the analysis of K-12 students' programming behaviors.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {299–303},
numpages = {5},
keywords = {block-based programming, learning analytics, visual analytics},
location = {New York City, NY, USA},
series = {L@S '22}
}

@inproceedings{10.1145/3012430.3012644,
author = {Balderas, Antonio and Ruiz-Rube, Iv\'{a}n and Mota, Jos\'{e} Miguel and Dodero, Juan M. and Palomo-Duarte, Manuel},
title = {A development environment to customize assessment through students interaction with multimodal applications},
year = {2016},
isbn = {9781450347471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3012430.3012644},
doi = {10.1145/3012430.3012644},
abstract = {Learning experiences based on multimodal interactive applications are becoming common at all educational levels. Designing assessments for learning applications is often addressed through learning analytics. Multimodal interactive applications generate a large amount of data about students' interaction that can provide insights about their profile, behavior and performance. Unfortunately, this information is usually not accessible or difficult to collect from such applications, especially for teachers without computer programming skills. In this work, we present a visual development environment that supports the creation of multimodal interactive applications for learning with non-intrusive monitoring capacities, thus providing teachers the opportunity to create their own learning analytics tools even if they are not skilled in computer programming.},
booktitle = {Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {1043–1048},
numpages = {6},
keywords = {augmented reality, learning analytics, mobile learning, non-intrusive monitoring},
location = {Salamanca, Spain},
series = {TEEM '16}
}

@inproceedings{10.1145/3430895.3460990,
author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
title = {Experimental Design of Learning Analysis Dashboards for Teachers and Learners},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460990},
doi = {10.1145/3430895.3460990},
abstract = {Since learning in higher education is increasingly taking place online, the multiplication of web-based educational content, learning management systems (LMSs) and collaborative communication platforms have generated a large volume of data on learners and their learning activities. In recent years, interest has been growing in analyzing this data to support real-time decision making and improve the learning experience. This paper presents the results of a study conducted in higher education in Morocco, which evaluates a learning analysis dashboards (LADs) for both teachers and learners. The study shows that the dashboard, called TABAT, allowed a synthetic visualization of learning progress in courses and led to improved student engagement and success rates.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {347–350},
numpages = {4},
keywords = {higher education, information visualization, learning analytical dashboard, learning analytics, self-regulated learning},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1145/2971485.2993926,
author = {Derboven, Jan and Vandenberghe, Bert},
title = {NewSchool: Studying the Effects of Design Fiction through Personalized Learning Scenarios},
year = {2016},
isbn = {9781450347631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971485.2993926},
doi = {10.1145/2971485.2993926},
abstract = {We present two design fictions about future online learning environments, inspired by future scenarios presented in the learning analytics literature. The design fictions explore specific aspects of this future technology, its adoption and social consequences. We use Symmetry Theory to analyze the design fictions in terms of the relationship between the readers of the fictions on the one hand, and the fictional characters and technology, on the other. We argue that these relationships determine to what extent a design fiction can stimulate the reader to reflect on the future technology. As such, we present Symmetry Theory as a useful tool to analyze how an existing design fiction can stimulate reflection, and to plan the writing process of design fiction.},
booktitle = {Proceedings of the 9th Nordic Conference on Human-Computer Interaction},
articleno = {81},
numpages = {10},
keywords = {Learning analytics, audience effects, design fiction},
location = {Gothenburg, Sweden},
series = {NordiCHI '16}
}

@inproceedings{10.1145/3139513.3139527,
author = {Sun, Bo and Lai, Song and Xu, Congcong and Xiao, Rong and Wei, Yungang and Xiao, Yongkang},
title = {Differences of online learning behaviors and eye-movement between students having different personality traits},
year = {2017},
isbn = {9781450355575},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139513.3139527},
doi = {10.1145/3139513.3139527},
abstract = {The information technologies are integrated into education so that mass data is available reflecting each action of students in online environments. Numerous studies have exploited these data to do the learning analytics.In this paper, we aim at achieving the show of personalized indicators for students per personality trait on the learning analytics dashboard (LAD) and present the preliminary results. First, we employ learning behavior engagement (LBE) to describe students' learning behaviors, exploited to analyze the significant differences among students having different personality traits. In experiments, fifteen behavioral indicators are tested. The experimental results show that there are significant differences about some behavioral indicators among personality traits. Second, some of these behavioral indicators are presented on the LAD and distributed in each area of interest (AOI). Hence, students can visualize their behavioral data that they care about in AOIs anytime in the learning process. Through the analysis of eye-movement including the fixation duration, fixation count, heat map and track map, we have found that there are significant differences about some visual indicators in AOIs. This is partly consistent with the results of behavioral indicators.},
booktitle = {Proceedings of the 1st ACM SIGCHI International Workshop on Multimodal Interaction for Education},
pages = {71–75},
numpages = {5},
keywords = {Learning analytics, eye-movement, learning behavior engagement, personality traits},
location = {Glasgow, UK},
series = {MIE 2017}
}

@inproceedings{10.1145/2460296.2460341,
author = {Camilleri, Vanessa and de Freitas, Sara and Montebello, Matthew and McDonagh-Smith, Paul},
title = {A case study inside virtual worlds: use of analytics for immersive spaces},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460341},
doi = {10.1145/2460296.2460341},
abstract = {In this paper we describe some case studies of the use of virtual worlds in corporate training as well as Higher Education. In particular for Higher Education we describe how the Virtual World constructed using the platform Avaya Live Engage, is used as an immersive environment with pre-service teachers, who are undergoing a 1-year teacher training program, and how the data analytics collected in-world is being used to monitor and direct content development. We focus our studies on the initial hypothesis that 3D immersive environments are highly engaging and offer an experience that goes beyond the 'traditional' online education. We want to combine different analysis methods to be able to get empirical evidence showing the students' engagement with the 3D space in ways that can help us in the design of the learning experience accompanying the learners in their journey. In this paper we describe the research methods we use for the study, and give an overview of the information we can collect from the in-world analytics. We also propose how these analytics can be used for a predictive model with the intention of refocusing the virtual world experience to match learner needs.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {230–234},
numpages = {5},
keywords = {corporate training, data analytics, higher education, pre-service teachers, virtual worlds},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/2460296.2460331,
author = {Mirriahi, Negin and Dawson, Shane},
title = {The pairing of lecture recording data with assessment scores: a method of discovering pedagogical impact},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460331},
doi = {10.1145/2460296.2460331},
abstract = {Web technologies, such as lecture recordings, have the capacity to capture and store massive amounts of data from individuals' online behavior. Such data can provide insight into student learning processes and the relationship between online trace data and academic performance alerting educators to when intervention may be required or if their learning activities may need to be adjusted. This paper discusses how data captured from students' use of lecture recordings accessed through a Collaborative Lecture Annotation System (CLAS) when aggregated and correlated with assessment data can help educators evaluate the impact of the recordings on their students' learning. Such information can help inform and alert educators to when adjustments may be required to their pedagogical approach.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {180–184},
numpages = {5},
keywords = {data sharing, pedagogical adjustment/intervention},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/3340555.3358662,
author = {Anderson, Khalil J. and Dubiel, Theodore and Tanaka, Kenji and Worsley, Marcelo and Poultney, Cody and Brenneman, Steve},
title = {Chemistry Pods: A Mutlimodal Real Time and Retrospective Tool for the Classroom},
year = {2019},
isbn = {9781450368605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340555.3358662},
doi = {10.1145/3340555.3358662},
abstract = {Instructors are often multitasking in the classroom. This makes it increasingly difficult for them to pay attention to each individual’s engagement especially during activities where students are working in groups. In this paper, we describe a system that aids instructors in supporting group collaboration by utilizing a centralized, easy-to-navigate dashboard connected to multiple pods dispersed among groups of students in a classroom or laboratory. This allows instructors to check multiple qualities of the discussion such as: the usage of instructor specified keywords, relative participation of each individual, the speech acts students are using and different emotional characteristics of group language.},
booktitle = {2019 International Conference on Multimodal Interaction},
pages = {506–507},
numpages = {2},
keywords = {audio processing, collaboration, learning analytics},
location = {Suzhou, China},
series = {ICMI '19}
}

@inproceedings{10.1145/3012430.3012620,
author = {Mercado-Varela, Mart\'{\i}n Alonso and Garc\'{\i}a-Holgado, Alicia and Garc\'{\i}a-Pe\~{n}alvo, Francisco J. and Ram\'{\i}rez-Montoya, Mar\'{\i}a Soledad},
title = {Analyzing navigation logs in MOOC: a case study},
year = {2016},
isbn = {9781450347471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3012430.3012620},
doi = {10.1145/3012430.3012620},
abstract = {Continued use of various technological devices has massively increased the generation of digital data, which are recorded as an opportunity for research. In the educational case, it is common to analyze data generated in Learning Management Systems which allows better understand the learning process of the participants and make informed decisions for better e-learning processes and situations in which develop. This paper analyzes participants' navigation logs in a MOOC hosted on the Coursera platform, for which a visual e-learning analytics process was performed. The results confirm that the videos of experts are an essential educational resource for learning in a MOOC, similarly, the discussion forums are an important resource which are recurrent social spaces in different navigation paths complementing other activities.},
booktitle = {Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {873–880},
numpages = {8},
keywords = {MOOC, coursera, learning analytics, log analysis, statistical analysis},
location = {Salamanca, Spain},
series = {TEEM '16}
}

@inproceedings{10.1145/3407982.3408010,
author = {Dankov, Yavor and Bontchev, Boyan},
title = {Towards a Taxonomy of Instruments for Facilitated Design and Evaluation of Video Games for Education},
year = {2020},
isbn = {9781450377683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407982.3408010},
doi = {10.1145/3407982.3408010},
abstract = {The focus of this paper is on the development of a taxonomy of software instruments that will facilitate the management and evaluation of the design of video games for education. For that reason, we aim to propose such a taxonomy that will be useful to users (especially to designers/creators) in the processes of the creation of educational video games. The proposed taxonomy aims to provide instruments for the facilitated straightforward design of the video games for education; facilitate the processes of creation and evaluation of specific video games for educational purposes; and facilitate non-ICT people such as educators, trainers, teachers in the game-based-learning process. We propose the following taxonomy named Taxonomy of Instruments for Management and Evaluation of the Design of Video Games for Education (TIMED-VGE). The suggested taxonomy includes various software instruments that will be a significant advantage for stakeholders of educational video games. The taxonomy includes two categories of instruments. The first category includes instruments supporting/assisting the processes of design management and its validation, and game generation. The second category presents analytics instruments for game design evaluation, monitoring, processing, analyzing and visualizing all the available data. The proposed taxonomy recommends the appropriate instruments to include in the design, development, and application of video games for education. Therefore, this taxonomy can serve as a starting point or as guidance for professionals (software developers, researchers) in the processes of creation of games and video game platforms for education. In this paper, we describe how the proposed taxonomy is applied in the APOGEE (smArt adaPtive videO GamEs for Education) software platform for the creation and monitoring of educational video games. We use the taxonomy to guide the development of the main platform instruments including both assistive and analytics instruments. The application of the proposed taxonomy in the APOGEE platform will be used to validate it. This will contribute to a better understanding of the game, rapid absorption of educational content, enhanced gaming experience, and for improving the overall game-based learning process. Thus, the taxonomy will be proved as a means for designing future software platforms for game-based learning.},
booktitle = {Proceedings of the 21st International Conference on Computer Systems and Technologies},
pages = {285–292},
numpages = {8},
keywords = {Taxonomy, educational games, gaming analytics, learning analytics},
location = {Ruse, Bulgaria},
series = {CompSysTech '20}
}

@article{10.1145/3381017,
author = {Martinez-Maldonado, Roberto and Mangaroska, Katerina and Schulte, Jurgen and Elliott, Doug and Axisa, Carmen and Shum, Simon Buckingham},
title = {Teacher Tracking with Integrity: What Indoor Positioning Can Reveal About Instructional Proxemics},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3381017},
doi = {10.1145/3381017},
abstract = {Automatic tracking of activity and location in the classroom is becoming increasingly feasible and inexpensive. However, although there is a growing interest in creating classrooms embedded with tracking capabilities using computer vision and wearables, more work is still needed to understand teachers' perceived opportunities and concerns about using indoor positioning data to reflect on their practice. This paper presents results from a qualitative study, conducted across three authentic educational settings, investigating the potential of making positioning traces available to teachers. Positioning data from 28 classes taught by 10 university teachers was captured using sensors in three different collaborative classroom spaces in the disciplines of design, health and science. The contributions of this paper to ubiquitous computing are the documented reflections of teachers from different disciplines provoked by visual representations of their classroom positioning data and that of others. These reflections point to: i) the potential benefit of using these digital traces to support teaching; and ii) concerns to be considered in the design of meaningful analytics systems for instructional proxemics.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {22},
numpages = {27},
keywords = {Learning analytics, indoor positioning, location analytics, proxemics}
}

@article{10.1145/3453165,
author = {Olivares, Daniel and Hundhausen, Christopher and Ray, Namrata},
title = {Designing IDE Interventions to Promote Social Interaction and Improved Programming Outcomes in Early Computing Courses},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
url = {https://doi.org/10.1145/3453165},
doi = {10.1145/3453165},
abstract = {As in other STEM disciplines, early computing courses tend to stress individual assignments and discourage collaboration. This can lead to negative learning experiences that compel some students to give up. According to social learning theory, one way to improve students’ learning experiences is to help them form and participate actively in vibrant social learning communities. Building on social learning theory, we have designed a set of software interventions (scaffolds and prompts) that leverage automatically collected learning process data to promote increased social interactions and better learning outcomes in individual programming assignments, which are a key component of early undergraduate computing courses. In an empirical study, we found that students’ interaction with the interventions was correlated with increased social activity, improved attitudes toward peer learning, more closely coupled social networks, and higher performance on programming assignments. Our work contributes a theoretically motivated technological design for social programming interventions; an understanding of computing students’ willingness to interact with the interventions; and insights into how students’ interactions with the interventions are associated with their social behaviors, attitudes, connectedness with others in the class, and their course outcomes.},
journal = {ACM Trans. Comput. Educ.},
month = oct,
articleno = {2},
numpages = {29},
keywords = {Social programming interventions, software scaffolding, integrated development environment (IDE), learning analytics, social learning theory, computing education, CS1}
}

@inproceedings{10.1145/2872518.2891076,
author = {Carrillo, Rubiela and Lavou\'{e}, Elise and Pri\'{e}, Yannick},
title = {Towards Qualitative Insights for Visualizing Student Engagement in Web-based Learning Environments},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2891076},
doi = {10.1145/2872518.2891076},
abstract = {Learning Sciences argue that student engagement is composed of behavioral, motivational and cognitive dimensions. Many proposals in Learning Analytics have provided teachers with quantitative indicators focusing only on students' behaviors, such as the number and the duration of their actions with the learning environment. In this paper, we propose visual representations of cognitive indicators to add explanatory elements to behavioral indicators. We describe our general architecture for collecting and aggregating data used to build the proposed visualizations. We illustrate the use of these indicators in various pedagogical scenarios oriented towards supporting teachers in students' actions and performances understanding.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {893–898},
numpages = {6},
keywords = {indicators, learning analytics, qualitative clues, student engagement, visual analytics, web-based learning environment},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3430895.3460877,
author = {Ludwig, Sabrina and Rausch, Andreas and Deutscher, Viola and Seifried, J\"{u}rgen},
title = {Problem Solving Analytics (PSA) in the Web-Based Office Simulation LUCA},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460877},
doi = {10.1145/3430895.3460877},
abstract = {Open-ended e-learning environments allow for explorative behaviour in challenging scenarios and hence, foster problem-solving competences. The web-based office simulation LUCA (funded by the German Federal Ministry of Education and Research) addresses the domain-specific competences of students in commercial vocational education and training (VET). The office simulation provides authentic office tools such as a spreadsheet application and an ERP software to solve complex work scenarios. These scenarios are implemented via the "LUCA Editor" and can contain automated assistance based on evidence rules of certain behaviours ("scaffolding"). The real-time analysis of the resulting log files enables the analysis of individual problem-solving behaviour ("Problem Solving Analytics", PSA). Teachers and trainers can monitor their students' problem-solving efforts in the "LUCA Dashboard", where they can also provide individual assistance via a chat tool. In our contribution, the scientific foundations of PSA will be outlined, followed by a demonstration of the latest prototype of LUCA and visitors' interaction with the software. LUCA's alpha version will be released in September of this year and will be available for practitioners in vocational schools and companies.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {363–364},
numpages = {2},
keywords = {automated feedback, computer-based office simulation, learning analytics, log data analysis, open-ended learning environment, vocational education},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1145/3304221.3325547,
author = {Singh, Shaveen},
title = {Exploring the Potential of Social Annotations for Predictive and Descriptive Analytics},
year = {2019},
isbn = {9781450368957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3304221.3325547},
doi = {10.1145/3304221.3325547},
abstract = {In this paper, we illustrate the successful implementation of a social annotation tool within a content authoring platform, that allows students to discuss learning material with their fellow classmates, and to self-report on their cognitive, metacognitive and affective states-by self-coding the annotations as they journey through the learning material. We explore the predictive potential of such self- reports in reading material against the students completion rate and assessment scores, and also examine how visualisation of these annotation classifications can help instructors easily identify issues and adapt their teaching approach and learning material.},
booktitle = {Proceedings of the 2019 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {247–248},
numpages = {2},
keywords = {annotations, e-learning, learning analytics, prediction, self-report},
location = {Aberdeen, Scotland Uk},
series = {ITiCSE '19}
}

@inproceedings{10.1145/3635059.3635094,
author = {Garefalakis, Manos and Panagiotakis, Spyros},
title = {Integration of a Remote Lab with a Learning System for training on Microcontroller programming},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635094},
doi = {10.1145/3635059.3635094},
abstract = {In this paper, there will be presented the design and implementation of the Remote Laboratory (RL) of the Hellenic Mediterranean University (HMU). It will be also presented the hardware which is used and the software running on the RL. Additionally, the paper will present the technologies of the RL used for interconnection with learning platforms and learning analytics, according to the IEEE 1876-2019 standard. The IEEE 1876-2019 standard provides the framework for the design and implementation of RL with learning systems, but not how they can be used in a pedagogical way. So, in this presentation we will address the research question of how the RL can be used in a course of an LMS, which to the best of our knowledge is not presented in other relevant works.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {224–231},
numpages = {8},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3369199.3369216,
author = {Lavoie, Francis B. and Proulx, Pierre},
title = {A Learning Management System for Flipped Courses},
year = {2020},
isbn = {9781450372206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369199.3369216},
doi = {10.1145/3369199.3369216},
abstract = {The "flipped classroom" is gaining around in engineering courses. This teaching method has many advantages, such as helping disabled students. However, we observed that many students are less up-to-date than in traditional courses. To counter this problem, we have developed a learning management system (LMS) with unique features oriented for "flipped courses". The new LMS allows students to watch videos, to interact with Jupyter Notebooks and to complete the exercises directly on the website. The LMS automatically creates progression graphics for each student and pushes automatic messages related to their progression. For instructors, the LMS automatically creates statistics about the overall class progression throughout the lessons and exercises and allows targeting students in difficulty whose can then be individually helped. The LMS was introduced in several engineering courses and helped to lower the failure rate. With machine learning algorithms, the LMS can also demonstrate the importance to keep the students continuously up-to-date in a course.},
booktitle = {Proceedings of the 3rd International Conference on Digital Technology in Education},
pages = {73–76},
numpages = {4},
keywords = {Engineering Teaching, Inclusive Pedagogy, LMS, Learning Analytics, Learning Models},
location = {Yamanashi, Japan},
series = {ICDTE '19}
}

@inproceedings{10.1145/3290605.3300534,
author = {Aslan, Sinem and Alyuz, Nese and Tanriover, Cagri and Mete, Sinem E. and Okur, Eda and D'Mello, Sidney K. and Arslan Esme, Asli},
title = {Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300534},
doi = {10.1145/3290605.3300534},
abstract = {We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {affective computing, dashboards, learning analytics, real-time, student engagement},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3546155.3546708,
author = {Alhamadi, Mohammed and Alghamdi, Omar and Clinch, Sarah and Vigo, Markel},
title = {Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design},
year = {2022},
isbn = {9781450396998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546155.3546708},
doi = {10.1145/3546155.3546708},
abstract = {Interactive information dashboards can help both specialists and the general public understand complex datasets; but interacting with these dashboards often presents users with challenges such as understanding and verifying the presented information. To overcome these challenges, developers first need to acquire a thorough understanding of user perspectives, including strategies that users take when presented with problematic dashboards. We interviewed seventeen dashboard developers to establish (i) their understanding of user problems, (ii) the adaptations introduced as a result, and (iii) whether user-tailored dashboards can cater for users’ individual differences. We find that users’ literacy does not typically align with that required to use dashboards, while dashboard developers struggle with keeping up with changing requirements. We also find that developers are able to propose solutions to most users’ problems but not all. Encouragingly, our findings also highlight that tailoring dashboards to individual user needs is not only desirable, but also feasible. These findings inform future dashboard design recommendations that can mitigate the identified challenges including recommendations for data presentation and visual literacy.},
booktitle = {Nordic Human-Computer Interaction Conference},
articleno = {11},
numpages = {14},
location = {Aarhus, Denmark},
series = {NordiCHI '22}
}

@inproceedings{10.1145/2460296.2460320,
author = {Pardos, Zachary A. and Baker, Ryan S. J. D. and San Pedro, Maria O. C. Z. and Gowda, Sujith M. and Gowda, Supreeth M.},
title = {Affective states and state tests: investigating how affect throughout the school year predicts end of year learning outcomes},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460320},
doi = {10.1145/2460296.2460320},
abstract = {In this paper, we investigate the correspondence between student affect in a web-based tutoring platform throughout the school year and learning outcomes at the end of the year, on a high-stakes mathematics exam. The relationships between affect and learning outcomes have been previously studied, but not in a manner that is both longitudinal and finer-grained. Affect detectors are used to estimate student affective states based on post-hoc analysis of tutor log-data. For every student action in the tutor the detectors give us an estimated probability that the student is in a state of boredom, engaged concentration, confusion, and frustration, and estimates of the probability that they are exhibiting off-task or gaming behaviors. We ran the detectors on two years of log-data from 8th grade student use of the ASSISTments math tutoring system and collected corresponding end of year, high stakes, state math test scores for the 1,393 students in our cohort. By correlating these data sources, we find that boredom during problem solving is negatively correlated with performance, as expected; however, boredom is positively correlated with performance when exhibited during scaffolded tutoring. A similar pattern is unexpectedly seen for confusion. Engaged concentration and frustration are both associated with positive learning outcomes, surprisingly in the case of frustration.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {117–124},
numpages = {8},
keywords = {affect, boredom, confusion, data mining, detectors, high stakes tests, prediction, tutoring},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/3231644.3231706,
author = {Lampietti, Vita and Roy, Anindya and Barnes, Sheryl},
title = {Managing and analyzing student learning data: a python-based solution for edX},
year = {2018},
isbn = {9781450358866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231644.3231706},
doi = {10.1145/3231644.3231706},
abstract = {Online learning platforms, such as edX, generate usage statistics data that can be valuable to educators. However, handling this raw data can prove challenging and time consuming for instructors and course designers. The raw data for the MIT courses running on the edX platform (MITx courses) are pre-processed and stored in a Google BigQuery database. We designed a tool based on Python and additional open-source Python packages such as Jupyter Notebook, to enable instructors to analyze their student data easily and securely. We expect that instructors would be encouraged to adopt more evidence-based teaching practices based on their interaction with the data.},
booktitle = {Proceedings of the Fifth Annual ACM Conference on Learning at Scale},
articleno = {48},
numpages = {2},
keywords = {data analysis, edX, learning analytics, online education, python, science of learning},
location = {London, United Kingdom},
series = {L@S '18}
}

@inproceedings{10.1145/3411763.3451709,
author = {Alzoubi, Dana and Kelley, Jameel and Baran, Evrim and B. Gilbert, Stephen and Karabulut Ilgu, Aliye and Jiang, Shan},
title = {TeachActive Feedback Dashboard: Using Automated Classroom Analytics to Visualize Pedagogical Strategies at a Glance},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451709},
doi = {10.1145/3411763.3451709},
abstract = {TEACHActive is an automated feedback dashboard that provides instructors with visual classroom analytics about the active learning facilitation strategies they use in their classrooms. We describe TEACHActive system's root requirement of improving pedagogical practices through reflection, the system's process of data flow from an automated observation system, EduSense, to the feedback dashboard, and the technical design of the infrastructure. We designed the TEACHActive dashboard to visualize EduSense's automated observation output and give instructors feedback about their active learning facilitation strategies in their classrooms with the goal of improving their pedagogical practices. We present the TEACHActive prototype development process with three illustrative prototypes.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {312},
numpages = {6},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3617733.3617768,
author = {Prayogo, Sendy and Hidayanto, Muhammad Bambang and Lubis, Muharman},
title = {Business Intelligence in e-learning for Higher Education},
year = {2023},
isbn = {9798400707735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617733.3617768},
doi = {10.1145/3617733.3617768},
abstract = {Business intelligence (BI) is a combination of tools and tactics that allow data to be analyzed and information to be provided to aid decision-making. BI characteristics are widely applied in numerous sectors and produce excellent outcomes in the modern digital transformation era. When BI concepts are integrated into academic processes, they can deliver tremendous benefits. In this project, we are interested in assisting university decision-making in supporting academic matters at Telkom University in the Distance Education (PJJ) study program. We use BI to provide analytics that can aid decision-making for various categories of users (students, lecturers, faculty staff, and other decision-makers). Furthermore, BI can monitor and analyze learning behavior and performance in a collegiate setting. BI can also be used to assess the structure of learning materials' content as well as the effectiveness of students in the learning process. The data we use is the data on the e-learning platform. On the one hand, educators cannot guarantee the effectiveness of the learning process due to a lack of instruments for measuring, assessing, and evaluating learners' performance in learning activities. Therefore, providing data that can track and evaluate learners' interactions in e-learning platforms is crucial. This research aims to find relevant data for BI analysis applied to e-learning in higher education from various stakeholder perspectives. The second objective is to visualize student activity data in lectures while using e-learning for study programs that apply asynchronous learning models. Learner activity data in this research will be displayed in the form of a dashboard whose results can be monitored by various stakeholders. For stakeholders such as faculty in higher education, the data collected before, during, and after attending lectures can help in decision-making for multiple parties and the development of learning strategies in the future.},
booktitle = {Proceedings of the 2023 11th International Conference on Computer and Communications Management},
pages = {215–220},
numpages = {6},
keywords = {Business Intelligence (BI), Learning Management System (LMS), asynchronous, dashboard, e-learning, visualization},
location = {Nagoya, Japan},
series = {ICCCM '23}
}

@inproceedings{10.1145/3152771.3152777,
author = {Clayphan, Andrew John and Martinez-Maldonado, Roberto and Kay, Judy},
title = {A student-facing dashboard for supporting sensemaking about the brainstorm process at a multi-surface space},
year = {2017},
isbn = {9781450353793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152771.3152777},
doi = {10.1145/3152771.3152777},
abstract = {We developed a student-facing dashboard tuned to support post-hoc sensemaking in terms of participation and group effects in the context of collocated brainstorming. Grounding on foundations of small-group collaboration, open learner modelling and brainstorming at large interactive displays, we designed a set of models from behavioural data that can be visually presented to students. We validated the effectiveness of our dashboard in provoking group reflection by addressing two questions: (1) What do group members gain from studying measures of egalitarian contribution? and (2) What do group members gain from modelling how they sparked ideas off each other? We report on outcomes from a study with higher education students performing brainstorming. We present evidence from i) descriptive quantitative usage patterns; and ii) qualitative experiential descriptions reported by the students. We conclude the paper with a discussion that can be useful for the community in the design of collective reflection systems.},
booktitle = {Proceedings of the 29th Australian Conference on Computer-Human Interaction},
pages = {49–58},
numpages = {10},
keywords = {brainstorming, collaboration, dashboard, reflection, sensemaking},
location = {Brisbane, Queensland, Australia},
series = {OzCHI '17}
}

@inproceedings{10.1145/3291533.3291563,
author = {Ntourmas, Anastasius and Avouris, Nikolaos and Daskalaki, Sophia and Dimitriadis, Yannis},
title = {Teaching assistants' interventions in online courses: a comparative study of two massive open online courses},
year = {2018},
isbn = {9781450366106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291533.3291563},
doi = {10.1145/3291533.3291563},
abstract = {The purpose of this paper is to explore the characteristics of teaching assistants' interventions in Massive Open Online Courses (MOOCs). The study of interaction patterns in MOOCs can inform the design and development of mechanisms for more effective learning. We performed an analysis of teaching assistants' interactions in two different MOOCs in different subject matters (technology and humanities). The study revealed notable differences in the characteristics of teaching assistants' interventions within the two courses, in terms of language used, length of messages, response time and length of discourse. The findings of this study provide us with useful insights on current human interventions in MOOC forums, driving our effort in designing future modules to support the large number of students of these courses, with the ultimate objective to improve the learning experience for each individual student of future MOOCs.},
booktitle = {Proceedings of the 22nd Pan-Hellenic Conference on Informatics},
pages = {288–293},
numpages = {6},
keywords = {discussion forum, learning analytics, massive open online courses, teaching assistant intervention},
location = {Athens, Greece},
series = {PCI '18}
}

@inproceedings{10.1145/2724660.2724683,
author = {Pardos, Zachary A. and Kao, Kevin},
title = {moocRP: An Open-source Analytics Platform},
year = {2015},
isbn = {9781450334112},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2724660.2724683},
doi = {10.1145/2724660.2724683},
abstract = {In this paper, we address issues of transparency, modularity, and privacy with the introduction of an open source, web-based data repository and analysis tool tailored to the Massive Open Online Course community. The tool integrates data request/authorization and distribution workflows as well as a simple analytics module upload format to enable reuse and replication of analytics results among instructors and researchers. We survey the evolving landscape of competing data models, all of which can be accommodated in the platform. Data model descriptions are provided to analytics authors who choose, much like with smartphone app stores, to write for any number of data models depending on their needs and the proliferation of the particular data model. Two case study examples of analytics and interactive visualizations are described in the paper. The result is a simple but effective approach to learning analytics immediately applicable to X consortium institutions and beyond.},
booktitle = {Proceedings of the Second (2015) ACM Conference on Learning @ Scale},
pages = {103–110},
numpages = {8},
keywords = {dashboards, edx, modularization, mooc, open learning analytics, reproducible research, visualizations},
location = {Vancouver, BC, Canada},
series = {L@S '15}
}

@inproceedings{10.1145/3375258.3375264,
author = {Aldewereld, Huib and van der Stappen, Esther},
title = {Programming, Research and... Coffee? An Analysis of Workplace Activities by Computing Interns},
year = {2020},
isbn = {9781450377171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375258.3375264},
doi = {10.1145/3375258.3375264},
abstract = {To overcome the skills gap between industry demands and learning outcomes achieved by graduates in higher computing education, many Bachelor programs integrate some form of internship in their curriculum; students are assumed to encounter authentic tasks and recent technologies in the workplace. In practice, however, educators often do not know specifically which tasks their students perform and which technologies they use, mainly due to the distance between coach and student during the work placement and the lack of cohort-based overviews of activities performed in internships. In this study, we gathered and analyzed workplace activity data of 54 students over the course of their third-year semester-long internships in the computing industry. We performed descriptive analyses to gain insight into i) which categories of activities students performed most (programming, research and documentation) and ii) which of the activity categories they find most difficult (research, documentation (both academic and IT) and implementation/configuration). Subsequent text analysis gives us insight into students' perceptions of the categories used to label activities (testing, research, meetings, and academic documentation are congruous) and which technologies were used most by these students. Based on the results, we conclude it is feasible to use user-generated data to get insights into workplace activities of computing interns. The quality of this user-generated data does hamper us in drawing certain conclusions. Further research is needed with improved data quality and volume in order to obtain more generalizable results.},
booktitle = {Proceedings of the 8th Computer Science Education Research Conference},
pages = {39–49},
numpages = {11},
keywords = {Computing Internships, Data-Driven Curriculum Development, Workplace Learning Analytics},
location = {Larnaca, Cyprus},
series = {CSERC '19}
}

@inproceedings{10.1145/2876034.2893374,
author = {Roussev, Boris and Simakov, Pavel and Orr, John and Deutsch, Amit and Cox, John and Lenaghan, Michael and Gainer, Mike},
title = {Course Builder Skill Maps},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2893374},
doi = {10.1145/2876034.2893374},
abstract = {In this paper, we present a new set of features introduced in Course Builder that allow instructors to add skill maps to their courses. We show how skill maps can be used to provide up-to-date and actionable information on students' learning behavior and performance.},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {89–92},
numpages = {4},
keywords = {adaptive learning, learning analytics, moocs, skill maps},
location = {Edinburgh, Scotland, UK},
series = {L@S '16}
}

@inproceedings{10.1145/2983468.2983492,
author = {Fonseca, Nuno Gil and Macedo, Lu\'{\i}s and Mendes, Ant\'{o}nio Jos\'{e}},
title = {CodeInsights: Monitoring programming students' progress},
year = {2016},
isbn = {9781450341820},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983468.2983492},
doi = {10.1145/2983468.2983492},
abstract = {Students across the World face the difficulties associated with learning programming languages. Several studies have shown that a permanent monitoring by the teachers highly contributes for increasing the students' performance. We propose the use of a monitoring tool capable of capturing and displaying to the teachers real-time information about the students' performance based on snapshots of the code while they are programming. The teachers can then use that information to identify problems/deviations and act accordingly. To evaluate the developed system, we present some results of a field test involving students from an introductory course on Python programming.},
booktitle = {Proceedings of the 17th International Conference on Computer Systems and Technologies 2016},
pages = {375–382},
numpages = {8},
keywords = {learning analytics, programming learning, progress monitoring},
location = {Palermo, Italy},
series = {CompSysTech '16}
}

@inproceedings{10.1145/3334480.3382871,
author = {Beheshti, Elham and Lyons, Leilah and Mallavarapu, Aditi and Wallingford, Betty and Uzzo, Stephen},
title = {Design Considerations for Data-Driven Dashboards: Supporting Facilitation Tasks for Open-Ended Learning},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382871},
doi = {10.1145/3334480.3382871},
abstract = {Data-driven dashboards have been increasingly integrated into various contexts, particularly in educational settings. There is a growing need to understand how to design learning dashboards to help educators support learning experiences by providing real-time formative feedback. We are studying the design of a learning dashboard that can support educational facilitation tasks in a museum setting. In our approach, we use discrete facilitation tasks as the cornerstone of our design process. Using this task-based approach, we conducted pilot studies and participatory design sessions to better understand the context of design. In this paper, we offer preliminary findings and design considerations for supporting and digitally augmenting facilitation tasks in a highly interactive, open-ended learning environment.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {data-driven dashboards, design, learning analytics dashboards, method, participatory design, socio-technical systems},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3051457.3053980,
author = {Lopez, Glenn and Seaton, Daniel T. and Ang, Andrew and Tingley, Dustin and Chuang, Isaac},
title = {Google BigQuery for Education: Framework for Parsing and Analyzing edX MOOC Data},
year = {2017},
isbn = {9781450344500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3051457.3053980},
doi = {10.1145/3051457.3053980},
abstract = {The size and complexity of MOOC data present overwhelming challenges to many institutions. This paper details the functionality of edx2bigquery -- an open source Python package developed by Harvard and MIT to ingest and report on hundreds of MITx and HarvardX course datasets from edX, making use of Google BigQuery to handle multiple terabytes of learner data. For this application, we find that Google BigQuery provides ease of use in loading the multi-faceted MOOC datasets and near real-time interactive querying of data, including large clickstream datasets; moreover, we are able to provide flexible research and reporting dashboards, visualizing and aggregating data, by interfacing services associated with BigQuery. This framework makes it feasible for edx2bigquery to be open source, following standards which emphasize the importance of data products that transcend a particular data science platform and allow teams with diverse backgrounds to interact with data. edx2bigquery is being adopted by other institutions with an aim toward future collaboration.},
booktitle = {Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale},
pages = {181–184},
numpages = {4},
keywords = {big data, bigquery, educational data mining., learning analytics, mooc},
location = {Cambridge, Massachusetts, USA},
series = {L@S '17}
}

@inproceedings{10.1145/3362789.3362837,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco J. and Ther\'{o}n, Roberto},
title = {Capturing high-level requirements of information dashboards' components through meta-modeling},
year = {2019},
isbn = {9781450371919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3362789.3362837},
doi = {10.1145/3362789.3362837},
abstract = {Information dashboards are increasing their sophistication to match new necessities and adapt to the high quantities of generated data nowadays. These tools support visual analysis, knowledge generation, and thus, are crucial systems to assist decision-making processes. However, the design and development processes are complex, because several perspectives and components can be involved. Tailoring capabilities are focused on providing individualized dashboards without affecting the time-to-market through the decrease of the development processes' time. Among the methods used to configure these tools, the software product lines paradigm and model-driven development can be found. These paradigms benefit from the study of the target domain and the abstraction of features, obtaining high-level models that can be instantiated into concrete models. This paper presents a dashboard meta-model that aims to be applicable to any dashboard. Through domain engineering, different features of these tools are identified and arranged into abstract structures and relationships to gain a better understanding of the domain. The goal of the meta-model is to obtain a framework for instantiating any dashboard to adapt them to different contexts and user profiles. One of the contexts in which dashboards are gaining relevance is Learning Analytics, as learning dashboards are powerful tools for assisting teachers and students in their learning activities. To illustrate the instantiation process of the presented meta-model, a small example within this relevant context (Learning Analytics) is also provided.},
booktitle = {Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {815–821},
numpages = {7},
keywords = {Domain engineering, High-level requirements, Information Dashboards, Meta-modeling},
location = {Le\'{o}n, Spain},
series = {TEEM'19}
}

@inproceedings{10.1145/3472749.3474761,
author = {Gong, Jiangtao and Han, Teng and Guo, Siling and Li, Jiannan and Zha, Siyu and Zhang, Liuxin and Tian, Feng and Wang, Qianying and Rui, Yong},
title = {HoloBoard: a Large-format Immersive Teaching Board based on pseudo HoloGraphics},
year = {2021},
isbn = {9781450386357},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472749.3474761},
doi = {10.1145/3472749.3474761},
abstract = {In this paper, we present HoloBoard, an interactive large-format pseduo-holographic display system for lecture based classes. With its unique properties of immersive visual display and transparent screen, we designed and implemented a rich set of novel interaction techniques like immersive presentation, role-play, and lecturing behind the scene that are potentially valuable for lecturing in class. We conducted a controlled experimental study to compare a HoloBoard class with a normal class through measuring students’ learning outcomes and three dimensions of engagement (i.e., behavioral, emotional, and cognitive engagement). We used pre-/post- knowledge tests and multimodal learning analytics to measure students’ learning outcomes and learning experiences. Results indicated that the lecture-based class utilizing HoloBoard lead to slightly better learning outcomes and a significantly higher level of student engagement. Given the results, we discussed the impact of HoloBoard as an immersive media in the classroom setting and suggest several design implications for deploying HoloBoard in immersive teaching practices.},
booktitle = {The 34th Annual ACM Symposium on User Interface Software and Technology},
pages = {441–456},
numpages = {16},
keywords = {hologram, immersive learning, large-format display, mixed reality, teaching board},
location = {Virtual Event, USA},
series = {UIST '21}
}

@inproceedings{10.1145/3270316.3271529,
author = {Charleer, Sven and Guti\'{e}rrez, Francisco and Gerling, Kathrin and Verbert, Katrien},
title = {Towards an Open Standard for Gameplay Metrics},
year = {2018},
isbn = {9781450359689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3270316.3271529},
doi = {10.1145/3270316.3271529},
abstract = {Gameplay Metrics can help provide insights into player behaviour and performance, supporting game designers and players wishing to better understand their own game, yet such data is often not easily available to the wider public. We take our inspiration from the field of Learning Analytics, which attempts to create awareness and insights for learners by leveraging the gathered activity data and feeding this back to the students in an open way. This paper suggests an open standard for gathering and storing Gameplay Metrics data based on proven standards in Learning Analytics, facilitating easier development of analytical tools across different video games and genres to the benefit of researchers, developers, and players.},
booktitle = {Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts},
pages = {399–406},
numpages = {8},
keywords = {gameplay metrics, open data, standardisation, video games, xapi, xvgm},
location = {Melbourne, VIC, Australia},
series = {CHI PLAY '18 Extended Abstracts}
}

@inproceedings{10.1145/2851581.2892524,
author = {Alphen, Erik van and Bakker, Saskia},
title = {Lernanto: Using an Ambient Display During Differentiated Instruction},
year = {2016},
isbn = {9781450340823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851581.2892524},
doi = {10.1145/2851581.2892524},
abstract = {The emerging field of Learning Analytics (LA) promises to provide teachers with all types of data gathered real-time during lessons. This data could support teachers during differentiated instruction. A potential pitfall of providing teachers with such data on a screen-based dashboard, is information overload: comprehending the overload of information might decrease the valuable time available to attend to students. We present a pilot study in which data from Learning Analytics is provided to two secondary school teachers by means of an ambient display, called Lernanto. Semi-structured interviews, after a ten-week testing period, reveal that immediate access to learning analytics through an ambient display, next to using a LA dashboard, could result in teachers being able to distribute their attention more efficiently during lessons.},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {2334–2340},
numpages = {7},
keywords = {ambient display, classroom orchestration, classroom technology, peripheral interaction},
location = {San Jose, California, USA},
series = {CHI EA '16}
}

@inproceedings{10.1145/3489410.3489423,
author = {Andreou, Panayiotis and Amyrotos, Christos and Pamboris, Andreas and Germanakos, Panagiotis},
title = {RABIT: Reflective Analytics for Business InTelligence},
year = {2021},
isbn = {9781450385787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489410.3489423},
doi = {10.1145/3489410.3489423},
abstract = {Self-tracking enables individuals to monitor things like their behavioral, biological, physical or environmental data, offering the means for reflection and self-growth. Reflective Analytics utilizes educational data mining and learning analytics to further empower the reflection process by unveiling hidden insights regarding one’s productivity. While a number of productivity monitoring systems exist, they focus solely on personal analytics and lack the ability to identify best practices within teams or organizations. We present RABIT (Reflective Analytics for Business InTelligence), a platform that enables the observation, analysis and reflection on analytical work patterns at various levels within an organization. It seamlessly monitors/logs fine-grained information regarding the users’ data exploration process and generates insights for the individual, team and organization. RABIT is evaluated in a real world setting with ten analysts and is shown to hold the promise for detecting problems and planning contingencies, identifying opportunities for change, and adopting best practices.},
booktitle = {CHI Greece 2021: 1st International Conference of the ACM Greek SIGCHI Chapter},
articleno = {13},
numpages = {8},
keywords = {personalized recommendations, reflective analytics, self-tracking},
location = {Online (Athens, Greece), Greece},
series = {CHI Greece 2021}
}

@inproceedings{10.1145/2641580.2641605,
author = {Schneider, Daniel K. and Class, Barbara and Benetos, Kalliopi and Da Costa, Julien and Follonier, Val\'{e}rie},
title = {Learning process analytics for a self-study class in a Semantic Mediawiki},
year = {2014},
isbn = {9781450330169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2641580.2641605},
doi = {10.1145/2641580.2641605},
abstract = {We describe a framework and an implementation of learning process analytics for both learners and teachers to enhance a self-study class on psychological and educational theory. The environment is implemented in a Semantic MediaWiki using Semantic Forms and Semantic Result Formats. The design is in early development, but it is deployed and operational.},
booktitle = {Proceedings of The International Symposium on Open Collaboration},
pages = {1–4},
numpages = {4},
keywords = {Learning analytics, Semantic Forms, Semantic MediaWiki, Semantic Result Formats, learning cockpit, learning dashboard, online learning, self-study course},
location = {Berlin, Germany},
series = {OpenSym '14}
}

@inproceedings{10.1145/3313831.3376277,
author = {An, Pengcheng and Holstein, Kenneth and d'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
title = {The TA Framework: Designing Real-time Teaching Augmentation for K-12 Classrooms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376277},
doi = {10.1145/3313831.3376277},
abstract = {Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {ambient intelligence, augmented intelligence, classroom, dashboards, k-12, orchestration, teacher},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3051457.3053994,
author = {Hossain, Zahid and Bumbacher, Engin and Blikstein, Paulo and Riedel-Kruse, Ingmar},
title = {Authentic Science Inquiry Learning at Scale Enabled by an Interactive Biology Cloud Experimentation Lab},
year = {2017},
isbn = {9781450344500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3051457.3053994},
doi = {10.1145/3051457.3053994},
abstract = {National guidelines advocate for a more sophisticated STEM education that integrates complex and authentic scientific practices, e.g., experimentation, data collection, data analysis, and modeling. How to achieve that is currently unclear for both presential and distance education. We recently developed a scalable cloud lab that enables many online users to perform phototaxis experiment with real, living Euglena cells (opposed to just simulations). Here we iteratively designed and deployed an open course on the edX platform including suitable user interfaces that facilitates inquiry-based learning on this cloud lab: Online students (&gt;300) run real experiments (&gt;2,300), performed data analysis, explored models, and even formulated and experimentally tested their own hypotheses. Platform and course content are now suited for global adaptation in formal K-16 education. We will demo our cloud lab at the conference.},
booktitle = {Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale},
pages = {237–240},
numpages = {4},
keywords = {biology, cloud lab, data analysis, education, edx, euglena, inquiry-based learning, interactive biotechnology, learning analytics, life science, modeling, mooc, phototaxis, remote experimentation, user interface, user studies},
location = {Cambridge, Massachusetts, USA},
series = {L@S '17}
}

@inproceedings{10.1145/3379156.3391838,
author = {Heinemann, Birte and Ehlenz, Matthias and Schroeder, Prof. Dr. Ulrik},
title = {Eye-Tracking in Educational Multi-Touch Games: Design-Based (interaction) research and great visions},
year = {2020},
isbn = {9781450371346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379156.3391838},
doi = {10.1145/3379156.3391838},
abstract = {Collaborative learning with educational games on multi-touch tabletop devices opens chances, challenges and questions which make contemporary approaches in learning analytics meet their boundaries. Multi-modality might help here, and eye-tracking is a promising data source in the effort to a better understanding of the learners’ behaviour. This article describes our previous work regarding serious games on large multi-touch tabletop displays, developed to teach computer science theory topics in a collaborative and entertaining way, our previous research efforts and challenges and obstacles we met on our way. Eye-tracking will improve our understanding of the learners’ behaviour while they are not interacting with the game, enhance the construction of coherent learner models and might even provide a subtle way of control on a medium of public interaction. The benefits of our work can be used to enhance the game mechanics and support shy or students with disabilities. We present our plan of action which follows a design-based research approach and includes the motivation for our work and our short- and long-term goals.},
booktitle = {ACM Symposium on Eye Tracking Research and Applications},
articleno = {58},
numpages = {5},
keywords = {Collaboration, Eye Tracking, Interaction, Large Scale Displays, Learning, Multi-Touch Games, Serious Games},
location = {Stuttgart, Germany},
series = {ETRA '20 Short Papers}
}

@inproceedings{10.1145/2787622.2787710,
author = {Carter, Adam S. and Hundhausen, Christopher D. and Adesope, Olusola},
title = {The Normalized Programming State Model: Predicting Student Performance in Computing Courses Based on Programming Behavior},
year = {2015},
isbn = {9781450336307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2787622.2787710},
doi = {10.1145/2787622.2787710},
abstract = {Educators stand to benefit from advance predictions of their students' course performance based on learning process data collected in their courses. Indeed, such predictions can help educators not only to identify at-risk students, but also to better tailor their instructional methods. In computing education, at least two different measures, the Error Quotient and Watwin Score, have achieved modest success at predicting student course performance based solely on students' compilation attempts. We hypothesize that one can achieve even greater predictive power by considering students' programming activities more holistically. To that end, we derive the Normalized Programming State Model (NPSM), which characterizes students' programming activity in terms of the dynamically-changing syntactic and semantic correctness of their programs. In an empirical study, the NPSM accounted for 41% of the variance in students' programming assignment grades, and 36% of the variance in students' final course grades. We identify the components of the NPSM that contribute to its explanatory power, and derive a formula capable of predicting students' course programming performance with between 36 and 67 percent accuracy, depending on the quantity of programming process data.},
booktitle = {Proceedings of the Eleventh Annual International Conference on International Computing Education Research},
pages = {141–150},
numpages = {10},
keywords = {educational data mining, error quotient, learning analytics, normalized programming state model, predictive measures of student performance and achievement, watwin score},
location = {Omaha, Nebraska, USA},
series = {ICER '15}
}

@inproceedings{10.1145/2993363.2993367,
author = {Simon and Li, Y. K. and Wong, Gary K. W.},
title = {Visualizing the asynchronous discussion forum data with topic detection},
year = {2016},
isbn = {9781450345453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993363.2993367},
doi = {10.1145/2993363.2993367},
abstract = {Visualization is a crucial part in learning analytics, where ordinary teachers could comprehend the depth of textual learning (e.g. discussion forum) through the easy-to-interpret figures (e.g. keygraph). However, the open source tools are often not fully developed with plug-in to common learning management system such as Moodle. In this paper, we are going to present the preliminary results of an ongoing project learning analytics extended based on Li &amp; Wong (2016) and Wong &amp; Li (2016), which sets the direction for the next stage of our experiment to aim for a better educational technology application in helping teacher evaluate the learning process of students through analytics. In this project, contents of discussion forums of students were extracted into text files, which were imported to a software tool called Polaris developed by Oshawa Lab (http://www.panda.sys.t.utokyo.ac.jp/KeyGraph/) to generate keygraphs to visualize the scenarios for mining patterns. However, as keygraphs are difficult to comprehend by humans and therefore, more effective tools are needed. In our latest experiments, we deployed novel text mining algorithms and data visualization tools to improve educational analytics intuitively.},
booktitle = {SIGGRAPH ASIA 2016 Symposium on Education: Talks},
articleno = {17},
numpages = {3},
keywords = {LDA, LDAvis, education data mining},
location = {Macau},
series = {SA '16}
}

@inproceedings{10.1145/3375627.3375856,
author = {Zhou, Tongyu and Sheng, Haoyu and Howley, Iris},
title = {Assessing Post-hoc Explainability of the BKT Algorithm},
year = {2020},
isbn = {9781450371100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375627.3375856},
doi = {10.1145/3375627.3375856},
abstract = {As machine intelligence is increasingly incorporated into educational technologies, it becomes imperative for instructors and students to understand the potential flaws of the algorithms on which their systems rely. This paper describes the design and implementation of an interactive post-hoc explanation of the Bayesian Knowledge Tracing algorithm which is implemented in learning analytics systems used across the United States. After a user-centered design process to smooth out interaction design difficulties, we ran a controlled experiment to evaluate whether the interactive or static version of the explainable led to increased learning. Our results reveal that learning about an algorithm through an explainable depends on users' educational background. For other contexts, designers of post-hoc explainables must consider their users' educational background to best determine how to empower more informed decision-making with AI-enhanced systems.},
booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
pages = {407–413},
numpages = {7},
keywords = {communicating algorithmic systems, evaluation of xai systems, explainable ai, interpretability of algorithms, post-hoc explanations},
location = {New York, NY, USA},
series = {AIES '20}
}

@inproceedings{10.5555/2819009.2819070,
author = {Vivian, Rebecca and Tarmazdi, Hamid and Falkner, Katrina and Falkner, Nickolas and Szabo, Claudia},
title = {The development of a dashboard tool for visualising online teamwork discussions},
year = {2015},
publisher = {IEEE Press},
abstract = {Many software development organisations today adopt global software engineering (GSE) and agile models; requiring software engineers to collaborate and develop software in flexible, distributed, online teams. However, many employers have expressed concern that graduates lack teamwork skills and one of the most commonly occurring problems with GSE models are issues with project management. Team managers and educators often oversee a number of teams and the large corpus of data, in combination with agile models, make it difficult to efficiently assess factors such as team role distribution and emotional climate.Current methods and tools for monitoring software engineering (SE) teamwork in both industry and education settings typically focus on member contributions, reflection, or product outcomes, which are limited in terms of real-time feedback and accurate behavioural analysis. We have created a dashboard that extracts and communicates team role distribution and team emotion information in real-time. Our proof of concept provides a real-time analysis of teamwork discussions and visualises team member emotions, the roles they have adopted and overall team sentiment during the course of a collaborative problem-solving project. We demonstrate and discuss how such a tool could be useful for SE team management and training and the development of teamwork skills in SE university courses.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {380–388},
numpages = {9},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3362789.3362839,
author = {Caeiro-Rodriguez, Manuel},
title = {Making Teaching and Learning Visible: How Can Learning Designs Be Represented?},
year = {2019},
isbn = {9781450371919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3362789.3362839},
doi = {10.1145/3362789.3362839},
abstract = {This work is situated in the context of the Learning Design research area. It reviews different forms in which learning designs can be represented both in textual or in a graphical way. The different forms have been gathered from the options used by teachers in current practice and from proposals of the research community. The following categories have been defined to classify the several representation types into a clear and concise classification: Narrative Text; Forms/Templates; Table Representations/Matrices; Concept Maps, Mind Maps and Tree-based Representations; Flow Diagrams; Sequential Diagrams; and Ad-hoc Diagrams. For each type of representation specific examples and uses are provided, showing the benefits and contexts in which they are used. Text-based representations are common in the real teachers' practice, while graphical representations have been taken from research initiatives. The goal of the paper is to attract attention to the fact that no type of representation for learning designs has been adopted as a mainstream, yet. A common language in this domain would be desirable and could offer great benefits related to the communication and sharing of teaching and learning results. This could be very useful for the representation of learning designs and teaching practices in learning analytics dashboards.},
booktitle = {Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {265–274},
numpages = {10},
keywords = {Representation types, diagrams, learning design, making teaching and learning visible},
location = {Le\'{o}n, Spain},
series = {TEEM'19}
}

@inproceedings{10.1145/2957792.2957808,
author = {Bhandari, Gokul and Gowing, Maureen},
title = {A Framework for Open Assurance of Learning},
year = {2016},
isbn = {9781450344517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2957792.2957808},
doi = {10.1145/2957792.2957808},
abstract = {Assurance of Learning (AOL) refers to the outcomes assessment process which involves the systematic collection, review, and use of information about educational programs undertaken for the purpose of improving student learning and development [8]. While emerging trends such as open education, open learning, learning analytics, academic analytics, and big data in education have recently become mainstream, studies regarding the design and development of open source analytics applications for AOL are non-existent. In this paper, we describe an application called AOL Analyzer that we developed for our business school last year to assist in the analysis of AOL results reported by faculty. To the best of our knowledge, this is a first paper to bridge the existing gap in AOL analytics research.},
booktitle = {Proceedings of the 12th International Symposium on Open Collaboration},
articleno = {12},
numpages = {4},
keywords = {AACSB, Analytics, Assurance of Learning, Open Framework, R, Shiny},
location = {Berlin, Germany},
series = {OpenSym '16}
}

@article{10.1145/3715964,
author = {Susnjak, Teo and Hwang, Peter and Reyes, Napoleon and Barczak, Andre L. C. and McIntosh, Timothy and Ranathunga, Surangika},
title = {Automating Research Synthesis with Domain-Specific Large Language Model Fine-Tuning},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4681},
url = {https://doi.org/10.1145/3715964},
doi = {10.1145/3715964},
abstract = {This research pioneers the use of fine-tuned Large Language Models (LLMs) to automate Systematic Literature Reviews (SLRs), presenting a significant and novel contribution in integrating AI to enhance academic research methodologies. Our study employed advanced fine-tuning methodologies on open sourced LLMs, applying textual data mining techniques to automate the knowledge discovery and synthesis phases of an SLR process, thus demonstrating a practical and efficient approach for extracting and analyzing high-quality information from large academic datasets. The results maintained high fidelity in factual accuracy in LLM responses, and were validated through the replication of an existing PRISMA-conforming SLR. Our research proposed solutions for mitigating LLM hallucination and proposed mechanisms for tracking LLM responses to their sources of information, thus demonstrating how this approach can meet the rigorous demands of scholarly research. The findings ultimately confirmed the potential of fine-tuned LLMs in streamlining various labor-intensive processes of conducting literature reviews. As a scalable proof-of-concept, this study highlights the broad applicability of our approach across multiple research domains. The potential demonstrated here advocates for updates to PRISMA reporting guidelines, incorporating AI-driven processes to ensure methodological transparency and reliability in future SLRs. This study broadens the appeal of AI-enhanced tools across various academic and research fields, demonstrating how to conduct comprehensive and accurate literature reviews with more efficiency in the face of ever-increasing volumes of academic studies while maintaining high standards.},
journal = {ACM Trans. Knowl. Discov. Data},
month = mar,
articleno = {68},
numpages = {39},
keywords = {AI-Assisted Literature Review, Text Mining for Research Synthesis, LLM Fine-tuning, Systematic Literature Review Automation, Retrieval-Augmented Generation for Research, Domain-Specific Model Training, Knowledge Synthesis AI, AI-Driven Research, Literature Review Automation, Generative AI, AI-Enhanced Systematic Reviews, PRISMA and AI, Question and Answering}
}

@inproceedings{10.1145/2899475.2899487,
author = {Buzzi, Maria Claudia and Buzzi, Marina and Perrone, Erico and Rapisarda, Beatrice and Senette, Caterina},
title = {Learning games for the cognitively impaired people},
year = {2016},
isbn = {9781450341387},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2899475.2899487},
doi = {10.1145/2899475.2899487},
abstract = {Learning environments have been profoundly reshaped by pervasive technology. New educational methodologies take full advantage of ICT in a mobile customized user-friendly environment, to support learning and stimulate individuals' potential. Unfortunately, technology-enhanced learning tools are not often designed with accessibility in mind, although they can greatly benefit the personal empowerment and inclusion of special-needs people. To address this gap, a Web platform has been created for delivering accessible games to people with Down syndrome. Since personalization, orderliness and positive reinforcement are crucial to learning in these subjects, the platform offers a personalized safe environment for learning, conforming to behavioral analysis principles. Learning analytics are incorporated in the platform for easy monitoring of student progress via Web interfaces. The participatory design driving the development of the learning platform allowed the customization of the games' discriminative stimuli, difficulty levels and reinforcement, as well as the creation of a game "engine" to easily set up new personalized exercises. These customization features make the game platform usable by a larger audience, including individuals with learning difficulties and autism.},
booktitle = {Proceedings of the 13th International Web for All Conference},
articleno = {30},
numpages = {4},
keywords = {cognitive games, computer-enhanced learning, people with special needs, web applications},
location = {Montreal, Canada},
series = {W4A '16}
}

@inproceedings{10.1145/2702123.2702354,
author = {Hossain, Zahid and Jin, Xiaofan and Bumbacher, Engin W. and Chung, Alice M. and Koo, Stephen and Shapiro, Jordan D. and Truong, Cynthia Y. and Choi, Sean and Orloff, Nathan D. and Blikstein, Paulo and Riedel-Kruse, Ingmar H.},
title = {Interactive Cloud Experimentation for Biology: An Online Education Case Study},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702354},
doi = {10.1145/2702123.2702354},
abstract = {Interacting with biological systems via experiments is important for academia, industry, and education, but access barriers exist due to training, costs, safety, logistics, and spatial separation. High-throughput equipment combined with web streaming could enable interactive biology experiments online, but no such platform currently exists. We present a cloud experimentation architecture (paralleling cloud computation), which is optimized for a class of domain-specific equipments (biotic processing units - BPU) to share and execute many experiments in parallel remotely and interactively at all time. We implemented an instance of this architecture that enables chemotactic experiments with a slime mold Physarum Polycephelum. A user study in the blended teaching and research setting of a graduate-level biophysics class demonstrated that this platform lowers the access barrier for non-biologists, enables discovery, and facilitates learning analytics. This architecture is flexible for integration with various biological specimens and equipments to facilitate scalable interactive online education, collaborations, research, and citizen science.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3681–3690},
numpages = {10},
keywords = {automation, biology, cloud computing, cloud experimentation, cloud lab, education, remote experimentation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3699538.3699539,
author = {Kong, Minji and He, Owen and Louis Mauriello, Matthew and Pollock, Lori},
title = {"Anything That Can Be Streamlined Would Be Great": Validating Elementary School Teachers’ Preferences for a Block-Based Programming Teaching Augmentation System},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699539},
doi = {10.1145/3699538.3699539},
abstract = {Conversations around teaching augmentation (TA) system designs that benefit teachers’ pedagogical capabilities while teaching using block-based programming environments (BBPEs) are up and coming. Despite the growing interest in this area, past findings and design recommendations still need to be validated in additional contexts beyond what is represented in the literature. In addition, there yet exist formal investigations that ground themselves in a theoretical model of student reflection and explore how a TA system design might support students’ reflective learning processes as they program using BBPEs. In this paper, we aim to address such gaps with a concept validation study, where we conducted design activities with a targeted audience of seven teachers who have used Scratch in their teaching for grades three to five. Grounded in dialogues with our teacher participants during the activities, we reveal themes of interest identified via thematic analysis that strengthen past findings on teachers’ preferences for a BBPE TA system and reveal additional factors for future researchers to consider as they explore design opportunities.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {47},
numpages = {9},
keywords = {teaching augmentation tools, block-based programming environments, teaching pedagogy, concept validation},
location = {
},
series = {Koli Calling '24}
}

@proceedings{10.1145/3643479,
title = {AIQAM '24: Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@article{10.1145/3534526,
author = {Jiang, Liuyue and Tran, Nguyen Khoi and Ali Babar, Muhammad},
title = {Mod2Dash: A Framework for Model-Driven Dashboards Generation},
year = {2022},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {EICS},
url = {https://doi.org/10.1145/3534526},
doi = {10.1145/3534526},
abstract = {The construction of an interactive dashboard involves deciding on what information to present and how to display it and implementing those design decisions to create an operational dashboard. Traditionally, a dashboard's design is implied in the deployed dashboard rather captured explicitly as a digital artifact, preventing it from being backed up, version-controlled, and shared. Moreover, practitioners have to implement this implicit design manually by coding or configuring it on a dashboard platform. This paper proposes Mod2Dash, a software framework that enables practitioners to capture their dashboard designs as models and generate operational dashboards automatically from these models. The framework also provides a GUI-driven customization approach for practitioners to fine-tune the auto-generated dashboards and update their models. With these abilities, Mod2Dash enables practitioners to rapidly prototype and deploy dashboards for both operational and research purposes. We evaluated the framework's effectiveness in a case study on cyber security visualization for decision support. A proof-of-concept of Mod2Dash was employed to model and reconstruct 31 diverse real-world cyber security dashboards. A human-assisted comparison between the Mod2Dash-generated dashboards and the baseline dashboards shows a close matching, indicating the framework's effectiveness for real-world scenarios.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {172},
numpages = {28},
keywords = {big data analytics, cyber situational awareness, data visualization, decision making, model-driven dashboard, visual data analytics, visualization specification}
}

@proceedings{10.1145/3617570,
title = {QP4SE 2023: Proceedings of the 2nd International Workshop on Quantum Programming for Software Engineering},
year = {2023},
isbn = {9798400703768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the second edition of the workshop on Quantum Programming for Software Engineering (QP4SE) to be held virtually, December 4th, 2023, co-located with ESEC/FSE 2023, San Francisco.},
location = {San Francisco, CA, USA}
}

@article{10.1145/3589660,
author = {Ogata, Hiroaki and Majumdar, Rwitajit and Flanagan, Brendan},
title = {Learning and Evidence Analytics Framework Bridges Research and Practice for Educational Data Science},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3589660},
doi = {10.1145/3589660},
journal = {Commun. ACM},
month = jun,
pages = {72–74},
numpages = {3}
}

@inproceedings{10.1145/3706598.3713194,
author = {Fung, Ka Yan and Lee, Lik Hang and Yuan, Linping and Fung, Kwong Chiu and Sin, Kuen Fung and Lui, Tze Leung Rick and Qu, Huamin and Song, Shenghui},
title = {DysVis: A User-Centred Data Visualization System for Dyslexia Pre-screening},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713194},
doi = {10.1145/3706598.3713194},
abstract = {Dyslexia is a common neurobiological learning disorder significantly impacting reading, writing, and spelling worldwide. Early identification and intervention are essential, but most pre-screening tools focus on Latin languages, leaving Chinese-speaking students underserved. To address this gap, we conduct semi-structured interviews with special education (special-ed) teachers to gather their needs for dyslexia pre-screening tailored to Chinese contexts. Using their insights, we have developed DysVis, a user-centered data visualization system that combines handwriting analysis, body movement keypoint conversion, and a comprehensive visualization interface. DysVis provides teachers with multi-level visualizations, such as performance overviews, task analyses, handwriting observations, and behavioural insights, enabling them to identify the root causes of learning difficulties. Our evaluations, including case studies, a user study, and expert interviews, demonstrate that DysVis is user-friendly and effective in quickly identifying at-risk students, ultimately enhancing learning outcomes for Chinese-speaking students with dyslexia.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {565},
numpages = {18},
keywords = {Data Visualization System, User-centred Design, Data-driven Technology-enabled Analytics, Dyslexia Pre-screening},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3585088.3589368,
author = {Cosentino, Giulia and Lee-Cultura, Serena and Papavlasopoulou, Sofia and Giannakos, Michail},
title = {Designing Multi Sensory Environments for Children’s Learning: An Analysis of Teachers’ and Researchers’ Perspectives},
year = {2023},
isbn = {9798400701313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585088.3589368},
doi = {10.1145/3585088.3589368},
abstract = {Embodied learning offers new opportunities to enhance learning effectively, and engage children with stimulating educational experiences. Multi Sensory Environments (MSEs) are spaces that allow for several interaction modalities that stimulate users’ senses and allow the collection of multimodal data. In educational contexts, they provide opportunities to support children’s learning in a playful manner. The use of MSEs is usually carried out with the collaboration of teachers; their perspectives and responsibilities are crucial for the children’s experience. The goal of our research is to uncover evidence-based challenges and opportunities, while considering teachers’ experiences. We conducted fourteen semi-structured interviews with teachers (n = 6) and researchers (n = 8) experienced using MSEs’, and analysed the identified challenges and considerations during a workshop with four Child-Computer Interaction (CCI) experts. We offer a series of implications for consideration when designing and/or using MSEs to support children’s learning.},
booktitle = {Proceedings of the 22nd Annual ACM Interaction Design and Children Conference},
pages = {388–396},
numpages = {9},
keywords = {child-computer interaction, education, learning, multisensory environments},
location = {Chicago, IL, USA},
series = {IDC '23}
}

@article{10.1145/3589252,
author = {Adair, Amy},
title = {Teaching and Learning with AI: How Artificial Intelligence is Transforming the Future of Education},
year = {2023},
issue_date = {Spring 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1528-4972},
url = {https://doi.org/10.1145/3589252},
doi = {10.1145/3589252},
journal = {XRDS},
month = apr,
pages = {7–9},
numpages = {3}
}

@proceedings{10.1145/3696230,
title = {ICDTE '24: Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE)},
year = {2024},
isbn = {9798400717574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3581754.3584114,
author = {Brdnik, Sa\v{s}a},
title = {GUI Design Patterns for Improving the HCI in Explainable Artificial Intelligence},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584114},
doi = {10.1145/3581754.3584114},
abstract = {The rising number of artificial intelligence systems has increased the demand for transparency and accountability. This thesis addresses the human-computer interaction (HCI) challenges of explainable artificial intelligence (XAI), focusing on reusable solutions for transparency and fairness challenges. The main objectives we aim to address are 1) Identification of the most common and most significant HCI usability challenges in XAI; 2) Identification of good and reusable solutions for recognised HCI challenges in literature and existing XAI solutions, and 3) Their definition in the form of the design patterns. A catalogue of graphical user interface design patterns (i.e. reusable solutions to commonly occurring problems with a given context) in XAI is proposed. Expected benefits of the thesis include facilitating communication and collaboration between researchers and practitioners by providing shared vocabulary and proven design patterns, enhancing trust and accountability of AI solutions, promoting user-centred design and facilitating the evaluation and accelerating the maturation of XAI.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {240–242},
numpages = {3},
keywords = {XAI, design pattern catalogue, design patterns, explainable artificial intelligence},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3639474.3640051,
author = {van den Aker, Eddy and Rahimi, Ebrahim},
title = {Design principles for generating and presenting automated formative feedback on code quality using software metrics},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640051},
doi = {10.1145/3639474.3640051},
abstract = {Code quality and maintainability are among under-emphasized and often neglected topics in the curriculum of software engineering (SE) in higher education. This neglect tends to overlook research findings that demonstrate SE students' programming submissions most often exhibit severe code quality issues, which are frequently left unaddressed by the students. Furthermore, it can result in the software engineering curriculum becoming indifferent to the essential requirements of the software development industry, where code quality and maintainability play a crucial role in the software's cost throughout its life cycle.Therefore, SE students in higher education should be trained to master the knowledge and skills of writing high-quality code. One possible approach to improving students' understanding of code quality issues is to provide automatically generated formative feedback about the code quality aspects of their programming submissions throughout the code development process. However, while there are tools available for generating automated feedback on the code quality aspects of programming submissions, they often lack a set of theory-driven design principles to underpin the content and presentation of their provided feedback. This lack of theoretical foundation makes it difficult to follow a systematic approach to designing and developing such tools, reasoning about their quality, and evaluating the effectiveness of their generated feedback.To address this lack, this study provides nine contextualized design principles for generating automated formative feedback on code quality. These design principles are rooted in solid educational constructs about feedback and learning dashboards, and empirically validated and contextualized by two focus group sessions consisting of 8 senior SE students and 2 teachers.This approach has resulted in a set of contextualized design principles. These design principles can be used to guide the implementation of tools that provide automated feedback on code quality using software metrics.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {139–150},
numpages = {12},
keywords = {programming education, undergraduate education, design principles, code quality, formative feedback, automated feedback},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3568364.3568375,
author = {Alharbi, Ali},
title = {Re-imagining Computer Laboratories for Teaching Introductory Programming Concepts Using Web-based Integrated Development Environments: Opportunities and Challenges},
year = {2022},
isbn = {9781450396950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568364.3568375},
doi = {10.1145/3568364.3568375},
abstract = {This study reported on students' views and experience during the transition from a traditional computer laboratory into a web-based integrated development environment in an introductory programming concepts course. The aim of this study is twofold. First, to review and evaluate selected web-based integrated development environments (Web IDEs) that can be used to support teaching and learning of programming concepts. Second, to get insight into students' views and experience towards the web-based integrated development environments compared to computer laboratory. Students' understanding of basic programming concepts is part of any computer science and information technology academic program. However, research shows that it is not always easy for students to learn about these concepts, and that is reflected in the high drop rate among students in these subjects. Computer laboratory is an integral part for introductory courses on programming concepts to help students practice what they have learnt. The study is descriptive and exploratory in its nature, and was conducted in two stages. First, a review of some selected web integrated development environments was performed using a rubric for evaluating e-learning tools. Second, the study explored students' views and experience with the web-based integrated development environment using a questionnaire and a focus group. The study demonstrated that students had positive views and experience towards the web-based integrated development environments implying that these tools have the potential to overcome the limitations inherited in computer laboratory. The study suggested some improvements to the web-based integrated development environments to be more educationally effective.},
booktitle = {Proceedings of the 4th World Symposium on Software Engineering},
pages = {67–74},
numpages = {8},
keywords = {Programming education, Virtual labs, Web-based integrated development environments, e-learning},
location = {Xiamen, China},
series = {WSSE '22}
}

@inproceedings{10.1145/3613904.3642643,
author = {Pfau, Johannes and Charan, Manik and Kleinman, Erica and Seif El-Nasr, Magy},
title = {Damage Optimization in Video Games: A Player-Driven Co-Creative Approach},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642643},
doi = {10.1145/3613904.3642643},
abstract = {The concept of dealing damage is established and widespread in video games. With growing complexity and countless interactions in modern games, capturing how damage unfolds becomes an intricate problem - for developers just as for players. Misunderstanding how to optimize damage potentials includes risks of game imbalances, game-breaking exploits, mismatches between player skill and challenge (harming flow), and impaired perceived competence. All of these considerably impact player experience, game reception, success, and retention, yet polishing optimal strategies remains often a player community effort. To accelerate, inform and ease this process, we implemented an interactive tool capable of simulating, visualizing, planning and comparing damage strategies in video games. Following a case study within the Guild Wars 2 community, we contribute a player-driven perspective on the problem of damage optimization, as well as an artifact that resulted in empirical improvements – advancing the fields of game analytics, game evaluation methods and self-regulated learning.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {368},
numpages = {16},
keywords = {Damage Optimization, Game Analytics, Video Game Simulation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3640543.3645142,
author = {Coscia, Adam and Holmes, Langdon and Morris, Wesley and Choi, Joon Suh and Crossley, Scott and Endert, Alex},
title = {iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645142},
doi = {10.1145/3640543.3645142},
abstract = {The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction. To validate our approach, we deployed iScore with three learning engineers over the course of a month. We present a case study where interacting with iScore led a learning engineer to improve their LLM’s score accuracy by three percentage points. Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {787–802},
numpages = {16},
keywords = {Data visualization, educational technology, explainable AI, large language models, visual analytics},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3564721.3564725,
author = {Kong, Minji and Mauriello, Matthew Louis and Pollock, Lori},
title = {Exploring K-8 Teachers’ Preferences in a Teaching Augmentation System for Block-Based Programming Environments},
year = {2022},
isbn = {9781450396165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3564721.3564725},
doi = {10.1145/3564721.3564725},
abstract = {Multiple disciplines have taken interest in investigating and using teaching augmentation (TA) tools that are designed to support teachers’ pedagogical capabilities during classroom activities. TA systems can take various forms (e.g., dashboards, ambient displays). However, research on TA systems that complement K-8 teachers’ in-class when their students are learning to program in block-based programming environments (BBPEs) is nascent. For a TA system to positively impact teaching practices, the system’s design should be informed by a strong understanding of its stakeholders’ preferences. Through 10 semi-structured interviews with and 37 anonymous survey responses from K-8 teachers, we identify respondents’ preferences for potential BBPE TA systems. To put their preferences into context, we also describe how respondents typically teach programming using a BBPE and monitor students’ progress. Our mixed-methods approach reveals how TA systems could best target teachers’ attention level when teaching using BBPEs and assist in interpreting students’ behaviors while learning to code. Using these findings, we identify directions for future TA systems to best assist teachers in making data-driven instructional decisions and meeting students’ learning needs.},
booktitle = {Proceedings of the 22nd Koli Calling International Conference on Computing Education Research},
articleno = {6},
numpages = {12},
keywords = {block-based programming environments, teaching augmentation tools, teaching pedagogy},
location = {Koli, Finland},
series = {Koli Calling '22}
}

@article{10.1145/3711013,
author = {Chen, Si and Situ, Jason and Cheng, Haocong and Su, Suzy and Kirst, Desir\'{e}e and Ming, Lu and Wang, Qi and Angrave, Lawrence and Huang, Yun},
title = {Inclusive Emotion Technologies: Addressing the Needs of d/Deaf and Hard of Hearing Learners in Video-Based Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711013},
doi = {10.1145/3711013},
abstract = {Accessibility efforts for d/Deaf and hard of hearing (DHH) learners in video-based learning have mainly focused on captions and interpreters, with limited attention to learners' emotional awareness--an important yet challenging skill for effective learning. Current emotion technologies are designed to support learners' emotional awareness and social needs; however, little is known about whether and how DHH learners could benefit from these technologies. Our study explores how DHH learners perceive and use emotion data from two collection approaches, self-reported and automatic emotion recognition (AER), in video-based learning. By comparing the use of these technologies between DHH (N=20) and hearing learners (N=20), we identified key differences in their usage and perceptions: 1) DHH learners enhanced their emotional awareness by rewatching the video to self-report their emotions and called for alternative methods for self-reporting emotion, such as using sign language or expressive emoji designs; and 2) while the AER technology could be useful for detecting emotional patterns in learning experiences, DHH learners expressed more concerns about the accuracy and intrusiveness of the AER data. Our findings provide novel design implications for improving the inclusiveness of emotion technologies to support DHH learners, such as leveraging DHH peer learners' emotions to elicit reflections.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW115},
numpages = {27},
keywords = {automatic emotion recognition, d/deaf and hard-of-hearing, self-regulated learning, video-based learning}
}

@article{10.1145/3715710,
author = {Alhamadi, Mohammed and Alsayahani, Hatim and Clinch, Sarah and Vigo, Markel},
title = {Behavioural Indicators of Usability in Visual Analytics Dashboards},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3715710},
doi = {10.1145/3715710},
abstract = {Information presentation problems on interactive dashboards are known to hinder decision-making. Since a traditional user-centred approach to designing usable dashboards cannot fully satisfy user demands, needs and skills, we isolate behavioural indicators of usability when users conduct typical information-seeking and comparison tasks. In a first study (N = 50), we identified strategies derived from 486,435 interaction events logged in a controlled setting with synthetic dashboards. User models consisting of these user strategies and graph literacy produced strong signals indicating that usability was predictable. In a second study (N = 65), we tested the initial insights on real-world dashboards. While most of our hypotheses were confirmed, graph literacy emerged as the best predictor of usability. Usability was better predicted in dashboards with problems, suggesting promising opportunities for automated usability evaluation and real-time support for users struggling with visual analytics dashboards.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = apr,
articleno = {9},
numpages = {35},
keywords = {Dashboards, Interactive Dashboards, Visual Analytics, Information Presentation, User Modelling, User Strategies, Graph Literacy, Usability}
}

@inproceedings{10.1145/3335595.3335628,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e} and Ther\'{o}n, Roberto},
title = {Tailored information dashboards: A systematic mapping of the literature},
year = {2019},
isbn = {9781450371766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3335595.3335628},
doi = {10.1145/3335595.3335628},
abstract = {Information dashboards are extremely useful tools to exploit knowledge. Dashboards enable users to reach insights and to identify patterns within data at-a-glance. However, dashboards present a series of characteristics and configurations that could not be optimal for every user, thus requiring the modification or variation of its features to fulfill specific user requirements. This variation process is usually referred to as customization, personalization or adaptation, depending on how this variation process is achieved. Given the great number of users and the exponential growth of data sources, tailoring an information dashboard is not a trivial task, as several solutions and configurations could arise. To analyze and understand the current state-of-the-art regarding tailored information dashboards, a systematic mapping has been performed. This mapping focus on answering questions regarding how existing dashboard solutions in the literature manage the customization, personalization and/or adaptation of its elements to produce tailored displays.},
booktitle = {Proceedings of the XX International Conference on Human Computer Interaction},
articleno = {26},
numpages = {8},
keywords = {Adaptation, Customization, Dashboards, Information dashboards, Information visualization, Literature review, Personalization, Systematic mapping},
location = {Donostia, Gipuzkoa, Spain},
series = {Interacci\'{o}n '19}
}

@inproceedings{10.1145/3532106.3533500,
author = {Chen, Si and Liu, Yixin and Lu, Risheng and Zhou, Yuqian and Lee, Yi-Chieh and Huang, Yun},
title = {”Mirror, Mirror, on the Wall” - Promoting Self-Regulated Learning using Affective States Recognition via Facial Movements},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533500},
doi = {10.1145/3532106.3533500},
abstract = {Prior research suggests that affective states of self-regulated learning can be used to improve learners’ cognitive processes and their learning outcomes. However, little research explored the effect of using facial movements to detect learners’ affective states on self-regulated learning. In this work, we designed, implemented, and evaluated Mirror: a self-regulated learning tool that applies facial expression recognition to support learners’ reflections in video-based learning. We conducted two studies to identify user needs (with 12 participants) and to evaluate the tool (with 16 participants). The results show that, after watching a video, participants benefited from using Mirror through different reflection processes, e.g., gaining a deeper understanding of their learning experiences through self-observation and attributing causes for their learning affects through self-judgment. Meanwhile, we also identified several ethical concerns, e.g., users’ agency of handling the uncertainty of AI, reactivity towards outcome-based AI, over-reliance on “positive” AI results, and fairness of AI informed decision-making.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {1300–1314},
numpages = {15},
keywords = {Affective Computing, Emotion, Mixed Methods, Video-based Learning},
location = {Virtual Event, Australia},
series = {DIS '22}
}

@inproceedings{10.1145/3544548.3580664,
author = {Kleinman, Erica and Villareale, Jennifer and Shergadwala, Murtuza N. and Teng, Zhaoqing and Bryant, Andy and Zhu, Jichen and El-Nasr, Magy Seif},
title = {"What else can I do?" Examining the Impact of Community Data on Adaptation and Quality of Reflection in an Educational Game},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580664},
doi = {10.1145/3544548.3580664},
abstract = {Adaptation, or ability and willingness to consider an alternative approach, is a critical component of learning through reflection, especially in educational games, where there are often multiple avenues to success. As a domain, educational games have shown increased interest in using retrospective visualizations to promote and support reflection. Such visualizations, which can facilitate comparison with peer data, may also have an impact on adaptation in educational games. This has, however, not been empirically examined within the domain. In this work, we examine how comparison with other players’ data influenced adaptation, a part of reflection, in the context of a game that teaches parallel programming. Our results indicate that comparison with peers does significantly impact willingness to try a different approach, but suggest that there may also be other ways. We discuss what these results mean for future use of retrospective visualizations in educational games and present opportunities for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {682},
numpages = {12},
keywords = {adaptation, community data, educational games, learning, reflection, retrospective visualization, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3627673.3679231,
author = {Afreen, Neda and Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Malloci, Francesca Maridina and Marras, Mirko and Martis, Andrea Giovanni},
title = {EDGE: A Conversational Interface driven by Large Language Models for Educational Knowledge Graphs Exploration},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679231},
doi = {10.1145/3627673.3679231},
abstract = {As education adopts digital platforms, the vast amount of information from various sources, such as learning management systems and learning object repositories, presents challenges in navigation and elaboration. Traditional interfaces involve a steep learning curve, limited user accessibility, and lack flexibility. Language models alone cannot address these issues as they do not have access to structured information specific to the educational organization. In this paper, we propose EDGE (EDucational knowledge Graph Explorer), a natural language interface that uses knowledge graphs to organize educational information. EDGE translates natural language requests into queries and converts the results back into natural language responses. We show EDGE's versatility using knowledge graphs built from public datasets, providing example interactions of different stakeholders. Demo video: https://u.garr.it/eYq63.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5159–5163},
numpages = {5},
keywords = {conversational interface, graph database, information retrieval, knowledge graph, language model, learning management},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3593663,
title = {ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seeon/Bavaria, Germany}
}

@inproceedings{10.1145/3631700.3664865,
author = {Samanta, Abhishek and Kotte, Hitesh and Handwerk, Patrick and Asyraaf Mat Sanusi, Khaleel and Geisen, Mai and Kravcik, Milos and Duong-Trung, Nghia},
title = {IMPECT-POSE: A Complete Front-end and Back-end Architecture for Pose Tracking and Feedback},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3664865},
doi = {10.1145/3631700.3664865},
abstract = {This paper introduces IMPECT-POSE, an innovative front-end and back-end architecture designed to enhance fitness and sports training through precise body posture tracking. This system integrates advanced computer vision and artificial intelligence in pose estimation to provide real-time feedback on exercise execution, which is crucial for maintaining proper technique, reducing injury risks, and optimizing training outcomes. Our evaluations, conducted at two distinct locations with multiple participants, demonstrate the system’s capability to improve exercise performance significantly. The system’s flexibility allows sports professionals to monitor and guide clients remotely, enhancing the accessibility and effectiveness of training regimens. This research highlights the potential of augmented intelligence in transforming sports training, offering a scalable and effective alternative to conventional methods, and paving the way for future advancements in AI-driven personalized training programs. The continued development of this technology aims to refine its accuracy, broaden its applicability to diverse user preferences, and extend its use in practical, real-world settings.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {142–147},
numpages = {6},
keywords = {Dance., Feedback Template, Fitness, Keypoint Estimation, Pose Tracking},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3647444.3647899,
author = {Rawat, Anshika and Singh, Shubham and Singh, Pawan},
title = {Cloud Resource Management: Monitoring},
year = {2024},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647444.3647899},
doi = {10.1145/3647444.3647899},
abstract = {The management and use of computer resources within enterprises has changed as a result of the emergence of cloud computing as a paradigm shift. With its diverse and comprehensive portfolio of cloud services, including AWS CloudWatch for monitoring, Amazon Web Services (AWS) is at the vanguard of this revolution. In order to fully utilize the capabilities of these platforms and achieve cost- effectiveness, scalability, and optimal performance, proper cloud resource management is essential. This, study offers a thorough investigation of AWS's cloud resource management, with a focus on Particle Swarm Optimization (PSO) integration as a cutting-edge optimization technique. The dynamic and ever-changing workloads seen in cloud computing systems present a special set of issues for resource allocation and optimization. However, finding the ideal compromise between performance and cost-efficiency is still a challenging task. This study examines the changing environment of cloud resource management with an eye toward the future. In order to enable even more intelligent resource allocation decisions, we take into account the possible integration of machine learning and predictive analytics into our PSO framework. We also look at the broader implications of PSO-driven resource management.},
booktitle = {Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence},
articleno = {72},
numpages = {4},
keywords = {Amazon Web Services (AWS), CloudWatch, Particle Swarm Algorithm (PSO)},
location = {Jaipur, India},
series = {ICIMMI '23}
}

@inproceedings{10.1145/3641554.3701935,
author = {Savelka, Jaromir and Kultur, Can and Agarwal, Arav and Bogart, Christopher and Burte, Heather and Zhang, Adam and Sakr, Majd},
title = {AI Technicians: Developing Rapid Occupational Training Methods for a Competitive AI Workforce},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701935},
doi = {10.1145/3641554.3701935},
abstract = {The accelerating pace of developments in Artificial Intelligence (AI) and the increasing role that technology plays in society necessitates substantial changes in the structure of the workforce. Besides scientists and engineers, there is a need for a very large workforce of competent AI technicians (i.e., maintainers, integrators) and users (i.e., operators). As traditional 4-year and 2-year degree-based education cannot fill this quickly opening gap, alternative training methods have to be developed. We present the results of the first four years of the AI Technicians program which is a unique collaboration between the U.S. Army's Artificial Intelligence Integration Center (AI2C) and Carnegie Mellon University to design, implement and evaluate novel rapid occupational training methods to create a competitive AI workforce at the technicians level. Through this multi-year effort we have already trained 59 AI Technicians. A key observation is that ongoing frequent updates to the training are necessary as the adoption of AI in the U.S. Army and within the society at large is evolving rapidly. A tight collaboration among the stakeholders from the army and the university is essential for successful development and maintenance of the training for the evolving role. Our findings can be leveraged by large organizations that face the challenge of developing a competent AI workforce as well as educators and researchers engaged in solving the challenge.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1029–1035},
numpages = {7},
keywords = {artificial intelligence, occupational training, technicians, workforce development},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3613904.3642914,
author = {Kwapisz, Monika Blue and Kohli, Avanya and Rajivan, Prashanth},
title = {Privacy Concerns of Student Data Shared with Instructors in an Online Learning Management System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642914},
doi = {10.1145/3613904.3642914},
abstract = {Learning management systems are used for facilitating communication between instructors and students, dissemination of lecture materials, and grading of assignments. They collect large amounts of student data, necessary or otherwise, with or without explicit consent from students. Furthermore, they make the data visible to instructors, which could have significant implications for students’ grades and experience in the classroom. In this study, we interviewed 31 students enrolled in a large public university about their privacy concerns towards different data sharing practices related to the learning management system used at their university – Canvas. Data from the study was analyzed by two researchers using inductive thematic analysis methods. The results show concerns about misrepresentation, the justification for information being visible, and discrimination. We present the implications of this study on instruction, design of learning management systems, and policy.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {661},
numpages = {16},
keywords = {Education technology, Higher education, Misrepresentation, Surveillance},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3641554.3701798,
author = {Neyem, Andres and Carrasco-Aravena, Jose and Fernandez-Blanco, Alison and Sandoval Alcocer, Juan Pablo},
title = {Exploring the Adaptability and Usefulness of Git-Truck for Assessing Software Capstone Project Development},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701798},
doi = {10.1145/3641554.3701798},
abstract = {In software engineering pedagogy, a persistent challenge is the comprehensive assessment of student contributions within software repositories. This study delves into the investigation of the Git-Truck tool, initially designed for professional software engineers, and explores its adaptability and effectiveness within an academic setting. We specifically focus on the tool's potential for educators when assessing Capstone software repositories. Our results emphasize that educators found bubble chart visualization and metrics such as ''Top Contributor'' and ''Number of Commits'' helpful in understanding group dynamics and contribution. We also discuss the tool's limitations among visual techniques and metrics used. As the educational landscape shifts towards increased virtual and remote modalities, tools like Git-Truck are poised to augment the intricacy and depth of software project evaluations. For those considering adopting or adapting such tools in similar contexts, our study offers the challenges and lessons learned from this experience.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {847–853},
numpages = {7},
keywords = {capstone courses, software engineering education, visualizing software projects},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3604571.3604587,
author = {Rizky, Rizky and Zulaikha, Ellya and Purwitasari, Diana},
title = {Educational Game Quality Assessment Based on The User's Persona Profile: A Systematic Literature Review},
year = {2023},
isbn = {9798400707612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604571.3604587},
doi = {10.1145/3604571.3604587},
abstract = {The use of games in the field of education is widespread. Currently, researchers are developing a model to assess the quality of games. The game evaluation model incorporates a multitude of diverse indicators and metrics. Nevertheless, the specific set of indicators and metrics that hold the utmost relevance for evaluating educational video games is yet to be determined. Differences in educational levels will impact learning objectives. The evaluation approach, instruments, and parameters vary significantly depending on the user's age and educational level. A conceptual framework is required to evaluate educational games, considering learning achievements based on user personas. This study proposes a systematic literature review to identify indicators for measuring the quality of educational games according to user personas. After searching the Scopus database, 159 papers were obtained. However, many of these papers solely discussed games and did not specifically address game evaluation. After further, it was found that thirty-two indicators were associated with game evaluation. These indicators are categorised into four variables: game, education, content, and user persona; some cited literature supports this categorisation method. In addition, the choice of indicators made by previous researchers demonstrates that the user persona element is central to measuring the quality of educational games. The existence of overly broad indicators causes numerous studies to diverge substantially; in this paper, we investigate the tools and methods utilised by user personas divided by education level.},
booktitle = {Proceedings of the Asian HCI Symposium 2023},
pages = {89–98},
numpages = {10},
keywords = {Educational Game, Model, Quality},
location = {Online, Indonesia},
series = {Asian CHI '23}
}

@inproceedings{10.1145/3697789.3697797,
author = {Spikol, Daniel and Li, Zaibei and Nolte, Alexander and Ohsaki, Ayano and Rapur, Karl},
title = {Investigating Hackathons with Collaboration Analytics},
year = {2024},
isbn = {9798400717796},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697789.3697797},
doi = {10.1145/3697789.3697797},
abstract = {Hackathons, collaborative events where individuals form teams to address specific problems, have gained significant traction across various domains since the early 2000s. Due to their time-bound nature, these events present unique challenges, necessitating the rapid establishment of collaboration methods and diverse support from hackathon organizers and mentors. Studying these events offers insights into emerging group work patterns, but tracking all teams during a hackathon is challenging. Traditional methods like surveys and log file analysis provide limited insights into team interactions. To address this, the following paper introduces a comprehensive data collection approach, encompassing detailed observations, speech transcripts, and wearable badges. Furthermore, it explores using Multimodal Collaboration Analytics (CA) and Sociometric wearable devices (SWDs) to study human behavior in hackathons. The primary research aim is to understand collaboration in absentia, leading to questions about designing technologies to capture collaboration and visualize group interactions. The paper discusses the iterative design approach for a collaboration analytics platform. The paper presents initial findings, challenges, and questions related to the study of collaboration in hackathons and how such tools can support the events and offer insight into collaboration.},
booktitle = {Proceedings of the 8th International Conference on Game Jams, Hackathons and Game Creation Events},
pages = {1–8},
numpages = {8},
keywords = {Collaboration Analytics, Iterative Design, Sociometric Wearable Devices, Prototyping, Hackathons, CSCW},
location = {
},
series = {ICGJ '24}
}

@inproceedings{10.1145/3573051.3593388,
author = {Zhou, Xiaofei and Kok, Christopher and Quintana, Rebecca M. and Delahay, Anita and Wang, Xu},
title = {How Learning Experience Designers Make Design Decisions: The Role of Data, the Reliance on Subject Matter Expertise, and the Opportunities for Data-Driven Support},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3593388},
doi = {10.1145/3573051.3593388},
abstract = {Learning Experience Designers (LXDs) play an increasingly consequential role in the creation of courses and training materials that meet the needs of diverse learner populations and the growing class scope. Emerging design requests for scalable and effective courseware introduce new challenges in Learning Experience (LX) design practice while providing an opportunity for researchers to understand LX workflows and design new tools to improve them. This paper presents an interview study with 21 LXDs from 18 different organizations with the goal of understanding LXDs' collaborative relationships with subject matter experts (SMEs), data needs, and contextual challenges. We further perform a survey study to validate the challenges and probe into LXDs' attitudes toward a suite of data-driven solutions. We find that LXDs demonstrate a strong desire to collect data to inform their design - including target learners' prior knowledge and relevant design precedents. LXDs want support in better collaborating with SMEs, acquiring and processing diverse learner data, identifying relevant research studies to communicate their design decisions, understanding domain-specific material, and creating quality materials (especially questions). We discuss LXDs' concerns regarding automated solutions such as the lack of contextual understanding, over-reliance on automation, and data privacy before elaborating on the implications for future work.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {132–143},
numpages = {12},
keywords = {data access, instructional design, interview, learning experience design, survey},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@proceedings{10.1145/3612783,
title = {Interacci\'{o}n '23: Proceedings of the XXIII International Conference on Human Computer Interaction},
year = {2023},
isbn = {9798400707902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lleida, Spain}
}

@inproceedings{10.1145/3678726.3678766,
author = {Almonte, Regina Garcia and Montiano, Alvin M. and Salili, Paul Brian C. and Garcia, Leonard M. and Hipolito,Jr., Ramil R.},
title = {Design and Development of Culture-Based Learning Management System for City College of Calamba: A Qualitative Approach},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678766},
doi = {10.1145/3678726.3678766},
abstract = {This paper explores the design and development of e-Guro 1.0, a culture-based learning management system (CLMS) for the City College of Calamba. Using a qualitative approach, research begins with the exploratory analysis that leverages observations and interviews to understand the current state of teaching and learning in CCC as well as its requirements based on the perspective of the management and instructors. The waterfall methodology with focus group discussion. to provide a methodical and sequential foundation for e-Guro development. Integrating the cultural elements into e-Guro 1.0, was refined through the iterative feedback loops that involve 23 instructors from diverse departments of the institution through the use of Focus Group Discussion. Their comments and suggestions provide an improvement to the e-Guro 1.0’s overall efficacy, usefulness, and sensitivity to cultural differences. Findings revealed that e-GURO 1.0 developed were recommended for utilization for instructions.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {184–190},
numpages = {7},
keywords = {culture, culture-based learning management system, e-learning, higher education, learning management system},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3340631.3398678,
author = {Alhamadi, Mohammed},
title = {Challenges, Strategies and Adaptations on Interactive Dashboards},
year = {2020},
isbn = {9781450368612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340631.3398678},
doi = {10.1145/3340631.3398678},
abstract = {Interactive dashboards enable viewing and interacting with complex underlying data using visualisations such as charts, tables, maps, or even text typically on a single display. By bringing the most important information in a single place, dashboards enable performance monitoring and support decision making. Although nowadays dashboards are widely adopted in many domains, they involve challenges that prevent users from utilising them as they were intended. For example, having a dashboard with too much data can negatively affect decision making and lead to misleading interpretation. Through this research, we identify and investigate the challenges associated with dashboards, what users do in response to those challenges, and what adaptations can be applied to mitigate these challenges. Consequently, we aim to examine and evaluate a set of adaptation techniques that can improve the experience of users interacting with dashboards.},
booktitle = {Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {368–371},
numpages = {4},
keywords = {adaptations, adaptive interaction, dashboards, information presentation, interaction challenges, user modelling, user strategies},
location = {Genoa, Italy},
series = {UMAP '20}
}

@inproceedings{10.1145/3411764.3445320,
author = {Mallari, Keri and Williams, Spencer and Hsieh, Gary},
title = {Understanding Analytics Needs of Video Game Streamers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445320},
doi = {10.1145/3411764.3445320},
abstract = {Live streaming is a rapidly growing industry, with millions of content creators using platforms like Twitch to share games, art, and other activities. However, with this rise in popularity, most streamers often fail to attract viewers and grow their platforms. Analytic tools—which have shown success in other business and learning contexts—may be one potential solution, but their use in streaming settings remains unexplored. In this study, we focused on game streaming and interviewed 18 game streamers on Twitch and Mixer about their information needs and current use of tools, supplemented by explorations into their Discord communities. We find that streamers have a range of content, marketing, and community information needs, many of which are not being met by available tools. We conclude with design implications for developing more streamer-centered analytics for video game streamers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {12},
keywords = {analytics, live streaming, streamers, video games},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3613904.3642451,
author = {McConvey, Kelly and Guha, Shion},
title = {"This is not a data problem": Algorithms and Power in Public Higher Education in Canada},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642451},
doi = {10.1145/3613904.3642451},
abstract = {Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college’s processes and relationships support those outcomes and the different stakeholders’ perceptions of the college’s data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {16},
numpages = {14},
keywords = {Artificial Intelligence, Higher Education, Human-Centered Machine Learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3406865.3418326,
author = {Liu, Junhua and Loh, Lionell and Ng, Ernest and Chen, Yijia and Wood, Kristin L. and Lim, Kwan Hui},
title = {Self-Evolving Adaptive Learning for Personalized Education},
year = {2020},
isbn = {9781450380591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406865.3418326},
doi = {10.1145/3406865.3418326},
abstract = {Primary and secondary education is a crucial stage to build a strong foundation before diving deep into specialised subjects in colleges and universities. To excel in the current education system, students are required to have a deep understanding of knowledge according to standardized curriculums and syllabus, and exam-related problem solving skills. In current school settings, this learning normally occurs in large classes of 30-40 students per class. Such a "one size fits all'' approach may not be effective, as different students proceed on their learning in different ways and pace. To address this problem, we propose the Self-Evolving Adaptive Learning (SEAL) system for personalized education at scale.},
booktitle = {Companion Publication of the 2020 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {317–321},
numpages = {5},
keywords = {adaptive learning, artificial intelligence, personalized education},
location = {Virtual Event, USA},
series = {CSCW '20 Companion}
}

@inproceedings{10.1145/3605098.3636055,
author = {Taiye, Mohammed and High, Christopher and Velander, Johanna and Matar, Khaled and Okmanis, Rihards and Milrad, Marcelo},
title = {Generative AI-Enhanced Academic Writing: A Stakeholder-Centric Approach for the Design and Development of CHAT4ISP-AI},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636055},
doi = {10.1145/3605098.3636055},
abstract = {This study examines the impact of Generative AI (GenAI) chatbots on improving students' academic writing and critical thinking skills. It addresses ethical and operational challenges, including concerns about academic integrity within AI in education (AIEd). Our study aims to analyze perspectives from a diverse array of stakeholders to inform the creation of effective GenAI chatbots. The insights gained will guide the development of comprehensive AI literacy and robust regulatory frameworks, ensuring that these advancements are both ethically sound and practically viable. The primary focus of the study is to understand stakeholders' expectations of GenAI in academic writing, leading to the development of CHAT4ISP-AI, a specialized chatbot aimed at improving the academic writing, analytical, and critical reasoning skills of first-year undergraduate social science students. This study promotes a contemporary educational approach by fostering collaboration among teachers, students, and other stakeholders, significantly advancing the integration of AI into the educational system, and thus preparing students for an AI-driven future.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {74–80},
numpages = {7},
keywords = {generative AI (GenAI), AI literacy, academic writing, soft systems methodology (SSM), stakeholder},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3634814.3634822,
author = {Murai, Kiyohiro and Watanobe, Yutaka},
title = {Integrated Coding Environment for Programming Exercise},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634822},
doi = {10.1145/3634814.3634822},
abstract = {Programming education has become important due to the recent development of ICT. However, there are some barriers for beginners to learn programming. The first is a technical problem that construction of an execution environment is not easy. The second is the lack of graders for solving programming and algorithmic problems. The third is that learners cannot receive sufficient reviews. The fourth is that it is not easy to grasp the learning status of learners. This paper proposes an environment called Integrated Coding Environment to solve these problems. So far, the functional and architectural interactions of online learning services have not been sufficiently discussed. In addition, there is not enough discussion on how to systematically interact with online learning services in the learner's workflow. This paper describes the environment designed to support this workflow, focusing on the comprehensive components it contains and their interactions. The environment has been implemented and utilized, and experiences in its operation are also discussed.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {49–57},
numpages = {9},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

@inproceedings{10.1145/3592571.3592973,
author = {Gan, Wenbin and Dao, Minh-Son and Zettsu, Koji},
title = {Procedural Driving Skill Coaching from More Skilled Drivers to Safer Drivers: A Survey},
year = {2023},
isbn = {9798400701863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592571.3592973},
doi = {10.1145/3592571.3592973},
abstract = {Improving driver behaviors through driving education and coaching is well-recognized as being necessary and efficient for driving safely and reducing traffic accidents, as they promise to reduce human factors accounting for most of the crash involvements. Driver education programs are currently widely employed in many countries, ensuring that the necessary procedural driving skills and competencies are imparted during these processes, to make more skilled drivers. However, making people more skilled drivers does not make them safer ones, the effectiveness of driving education is greatly restricted by the limited amount of actual supervised driving involved and the absence of individualized feedback. To this aim, driving coaching emerges as a more practical alternative to develop safely driving by proactively providing coaching feedback to enhance skills and cultivate corrective behaviors, with the recent technological developments in intelligent vehicles and transportation. This paper presents a systematic review of the existing studies for examining the empirical evidences on the various coaching explorations for the development of drivers’ procedural driving skills. In particular, we propose a taxonomy to classify existing driving coaching into four categories, and explore the answers to three questions: what types, when and how the different kinds of driving coaching are provided and delivered. Finally, the challenges and future directions are also presented from three aspects.},
booktitle = {Proceedings of the 4th ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
pages = {10–18},
numpages = {9},
keywords = {Driver Education, Driving Assistance, Driving Coaching, Driving Safety, Intelligent Vehicles, Procedural Driving Skill},
location = {Thessaloniki, Greece},
series = {ICDAR '23}
}

@inproceedings{10.1145/3430895.3460991,
author = {Perez-Sanagustin, Mar and P\'{e}rez-\'{A}lvarez, Ronald and Maldonado-Mahauad, Jorge and Villalobos, Esteban and Hilliger, Isabel and Hern\'{a}ndez, Josefina and Sapunar, Diego and Moreno-Marcos, Pedro Manuel and Mu\~{n}oz-Merino, Pedro J. and Delgado Kloos, Carlos and Imaz, Jon},
title = {Can Feedback based on Predictive Data Improve Learners' Passing Rates in MOOCs? A Preliminary Analysis},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460991},
doi = {10.1145/3430895.3460991},
abstract = {This work in progress paper investigates if timely feedback increases learners' passing rate in a MOOC. An experiment conducted with 2,421 learners in the Coursera platform tests if weekly messages sent to groups of learners with the same probability of dropping out the course can improve retention. These messages can contain information about: (1) the average time spent in the course, or (2) the average time per learning session, or (3) the exercises performed, or (4) the video-lectures completed. Preliminary results show that the completion rate increased 12% with the intervention compared with data from 1,445 learners that participated in the same course in a previous session without the intervention. We discuss the limitations of these preliminary results and the future research derived from them.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {339–342},
numpages = {4},
keywords = {MOOC, feedback, prediction, self-regulated learning},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1145/3430895.3460139,
author = {Yu, Renzhe and Lee, Hansol and Kizilcec, Ren\'{e} F.},
title = {Should College Dropout Prediction Models Include Protected Attributes?},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460139},
doi = {10.1145/3430895.3460139},
abstract = {Early identification of college dropouts can provide tremendous value for improving student success and institutional effectiveness, and predictive analytics are increasingly used for this purpose. However, ethical concerns have emerged about whether including protected attributes in these prediction models discriminates against underrepresented student groups and exacerbates existing inequities. We examine this issue in the context of a large U.S. research university with both residential and fully online degree-seeking students. Based on comprehensive institutional records for the entire student population across multiple years (N = 93,457), we build machine learning models to predict student dropout after one academic year of study and compare the overall performance and fairness of model predictions with or without four protected attributes (gender, URM, first-generation student, and high financial need). We find that including protected attributes does not impact the overall prediction performance and it only marginally improves the algorithmic fairness of predictions. These findings suggest that including protected attributes is preferable. We offer guidance on how to evaluate the impact of including protected attributes in a local context, where institutional stakeholders seek to leverage predictive analytics to support student success.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {91–100},
numpages = {10},
keywords = {algorithmic fairness, dropout prediction, higher education, online learning, predictive analytics},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@proceedings{10.1145/3711403,
title = {ICETM '24: Proceedings of the 2024 7th International Conference on Educational Technology Management},
year = {2024},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3687050,
author = {Lowy, Rachel and Magiawala, Khushi and Mittal, Shravika and Hall, Kaely and Roberts, Jessica and Kim, Jennifer G},
title = {Research-Education Partnerships: A Co-Design Classroom for College Students with Intellectual and Developmental Disabilities},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687050},
doi = {10.1145/3687050},
abstract = {Co-design of technology encourages participation and decision-making input of end-users. In the case of technologies for individuals with Intellectual and Developmental Disabilities (IDD), the end-users are historically left out of the design process. Further deepening the disconnect between this group and technology, they are also excluded from formal technology design knowledge sharing, such as college courses. To address this, our study investigates the efficacy of a formal classroom adaptation of co-design activities to encourage learning and participation. Through collaboration between educators and designers, we adopted user-centered co-design activities to facilitate knowledge and application of technological design methods within a class of 13 students with IDD. Findings uncovered factors contributing to co-teaching collaboration planning and reflection between educators and designers, and ways that activities can provide accessible collaborative learning environments for students with IDD by supporting collaboration, cognitive engagement, and meta-cognition. We discuss how these factors can support successful co-teacher collaborations that promote student empowerment. Finally, we contribute collaborative co-teaching strategies for educational co-design activities for individuals with IDD.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {511},
numpages = {26},
keywords = {co-design, inclusive design education, intellectual disability}
}

@inproceedings{10.1145/3633083.3633085,
author = {Soudi, Marwa and Ali, Esraa and Bali, Maha and Mabrouk, Nihal},
title = {Generative AI-Based Tutoring System for Upper Egypt Community Schools},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633085},
doi = {10.1145/3633083.3633085},
abstract = {This work introduces design for a Generative AI (Gen-AI) based tutoring system customized for Egyptian community schools needs. Community schools are managed by NGOs as an alternative education to unprivileged students who missed the formal government education. Our research involved working with an Egyptian NGO and a community school in upper Egypt from March 2023 to September 2023. Several workshops were conducted with involved stakeholders and end users to collect the requirements for such a system. The proposed design reflects the views of management, teachers and student parents.It also adhere to Haman-Centered AI (HCAI) principles which prioritize human values and experiences. This paper lists the outcomes of this process and surveys potential tools that can be used in this system. The findings emphasize the need for Gen-AI to act as a teacher’s assistant rather than a replacement, it also highlights the need for localization as well as the need for an end-to-end solution rather than developing an isolated AI-based module. The proposed Gen-AI tutoring system integrates Generative AI, a Learning Management System (LMS), and comprehensive reporting dashboards. This design aims to meet the technical and pedagogical requirements of community school environments and produces a trusted tutoring system that empowers teachers and students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {16–21},
numpages = {6},
keywords = {Generative AI, Human Centered AI, Intelligent Tutoring Systems},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3330430.3333618,
author = {Fong, Matthew and Dodson, Samuel and Harandi, Negar Mohaghegh and Seo, Kyoungwon and Yoon, Dongwook and Roll, Ido and Fels, Sidney},
title = {Instructors Desire Student Activity, Literacy, and Video Quality Analytics to Improve Video-based Blended Courses},
year = {2019},
isbn = {9781450368049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330430.3333618},
doi = {10.1145/3330430.3333618},
abstract = {While video becomes increasingly prevalent in educational settings, current research has yet to investigate what feedback instructors need regarding their students' engagement and learning despite video technologies being equipped to provide viewing analytics and collect student feedback. In this paper we investigate instructors' requirements from video analytics. We used a Grounded Theory Approach and interviewed 16 instructors who teach using video to determine the advantages for using video in their teaching and the different requirements for analytics and feedback in their existing practice. Based on our analysis of the interviews, we found three categories of information that instructors want to inform their teaching. Instructors are looking to see if their students have watched their videos, how much they understood in those videos, and how useful the videos are to the students. These categories provide the foundations and design implications for instructor-centric educational video analytics interfaces.},
booktitle = {Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale},
articleno = {7},
numpages = {10},
keywords = {analytics, blended learning, learning, teaching, video},
location = {Chicago, IL, USA},
series = {L@S '19}
}

@inproceedings{10.1145/3501712.3536384,
author = {Wolf, Jacob and Fuhrmann, Tamar and Wagh, Aditi and da Silva Eloy, Adelmo Antonio and Blikstein, Paulo and Wilkerson, Michelle},
title = {After the Study Ends: Developing Heuristics To Design for Sustainable Use of Learning Technologies in Classrooms},
year = {2022},
isbn = {9781450391979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501712.3536384},
doi = {10.1145/3501712.3536384},
abstract = {A central challenge of developing learning technologies for K-12 classrooms is designing for sustainable use – ensuring that the technology has a lifespan in the classroom beyond the term of a research project or implementation period. This half-day workshop aims to bring together designers, researchers, and educators creating K-12 learning technologies to share and reflect on the challenges and opportunities of designing for sustainable use in classrooms. In the workshop, we seek to develop a set of heuristics to guide designers and provide a context for designing for sustainable use. By sharing the outcomes of this workshop we hope to develop a common language, design goals, and examples of successes and challenges in designing for sustainable use.},
booktitle = {Proceedings of the 21st Annual ACM Interaction Design and Children Conference},
pages = {703–705},
numpages = {3},
keywords = {children, learning technology, sustainable use},
location = {Braga, Portugal},
series = {IDC '22}
}

@inproceedings{10.1145/3491102.3517480,
author = {Gauthier, Andrea and Benton, Laura and Bunting, Leona and Herbert, Elisabeth and Sumner, Emma and Mavrikis, Manolis and Revesz, Andrea and Vasalou, Asimina},
title = {I Don't Usually Listen, I Read: How Different Learner Groups Process Game Feedback},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517480},
doi = {10.1145/3491102.3517480},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {88},
numpages = {15},
keywords = {Learning games, children, feedback, game design, reading},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3357236.3395497,
author = {Sellier, Nine and An, Pengcheng},
title = {How Peripheral Interactive Systems Can Support Teachers with Differentiated Instruction: Using FireFlies as a Probe},
year = {2020},
isbn = {9781450369749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357236.3395497},
doi = {10.1145/3357236.3395497},
abstract = {Teachers' response to the real-time needs of diverse learners in the classroom is important for each learner's success. Teachers who give differentiated instruction (DI) provide pertinent support to each student and acknowledge their differences in learning style and pace. However, due to the already complex and intensive routines in classrooms, it is demanding and time-consuming for teachers to implement DI on-the-spot. This study aims to explore how to ease teachers' classroom differentiation by enabling effortless, low-threshold student-teacher communications through a peripheral interactive system. Namely, we present a six-week study, in which we iteratively co-designed and field-tested interaction solutions with eight school teachers, using a set of distributed, interactive LED-objects (the 'FireFlies' platform). By connecting our findings to the theories of DI, we contribute empirical knowledge about the advantages and limitations of a peripheral interactive system in supporting DI. Taken together, we summarize concrete opportunities and recommendations for future design.},
booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
pages = {1117–1129},
numpages = {13},
keywords = {ambient system, classroom, co-design, differentiated instruction, peripheral interaction, teacher},
location = {Eindhoven, Netherlands},
series = {DIS '20}
}

@inproceedings{10.1145/3544548.3581398,
author = {Yang, Kexin Bella and Echeverria, Vanessa and Lu, Zijing and Mao, Hongyu and Holstein, Kenneth and Rummel, Nikol and Aleven, Vincent},
title = {Pair-Up: Prototyping Human-AI Co-orchestration of Dynamic Transitions between Individual and Collaborative Learning in the Classroom},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581398},
doi = {10.1145/3544548.3581398},
abstract = {Enabling students to dynamically transition between individual and collaborative learning activities has great potential to support better learning. We explore how technology can support teachers in orchestrating dynamic transitions during class. Working with five teachers and 199 students over 22 class sessions, we conducted classroom-based prototyping of a co-orchestration technology ecosystem that supports the dynamic pairing of students working with intelligent tutoring systems. Using mixed-methods data analysis, we study the resulting observed classroom dynamics, and how teachers and students perceived and experienced dynamic transitions as supported by our technology. We discover a potential tension between teachers’ and students’ preferred level of control: students prefer a degree of control over the dynamic transitions that teachers are hesitant to grant. Our study reveals design implications and challenges for future human-AI co-orchestration in classroom use, bringing us closer to realizing the vision of highly-personalized smart classrooms that address the unique needs of each student.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {453},
numpages = {17},
keywords = {Classroom Orchestration, Collaborative Learning, Educational Technology, Human-AI Collaboration, Teacher-supported Tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3408877.3432382,
author = {B\"{a}lter, Olle and Glassey, Richard and Wiggberg, Mattias},
title = {Reduced Learning Time with Maintained Learning Outcomes},
year = {2021},
isbn = {9781450380621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3408877.3432382},
doi = {10.1145/3408877.3432382},
abstract = {Many online learning initiatives have failed to reach beyond the environments in which they were first developed. One exception is the Open Learning Initiative (OLI) at Carnegie Mellon University (CMU). In an attempt to validate the question-based learning methodology implemented in OLI, we developed online material for an introductory course in object-oriented programming, and tested it on two course offerings with a total of 70 students. As our course has been given in the same format for several years, we also had comparable assessment data for two classes prior to our intervention in order to determine that we did not introduce any obvious harm with this methodology. Findings show a reduced teaching and learning time by 25%. No statistically significant differences could be found in the results of the assessment quizzes nor confidence surveys completed by the students. The two teachers (the same who handled the classes before the intervention) took different paths to teaching preparations with this new methodology. One teacher increased preparations, whilst the other reduced them, but both teachers were convinced that using online question-based learning was superior to the previous lecture and textbook-based approach, both for the students and themselves in terms of overall satisfaction. We also gathered time logs from the development to estimate return on investment.},
booktitle = {Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
pages = {660–665},
numpages = {6},
keywords = {evaluation, introductory programming, question-based learning},
location = {Virtual Event, USA},
series = {SIGCSE '21}
}

@proceedings{10.1145/3582580,
title = {ICETM '22: Proceedings of the 2022 5th International Conference on Education Technology Management},
year = {2022},
isbn = {9781450398015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lincoln, United Kingdom}
}

@inproceedings{10.1145/3485768.3485803,
author = {Tran, Tich Phuoc and Sidhu, Leesa and Tran, Dat},
title = {A Framework for Navigating and Enhancing the Use of Digital Assessment},
year = {2021},
isbn = {9781450390156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485768.3485803},
doi = {10.1145/3485768.3485803},
abstract = {Digital assessment (DA) has been recognized as one of the most critical elements of modern education due to the ever-growing uptake of information and communication technologies in learning and teaching. This article provides a systemic approach to navigating and enhancing the use of DA in the higher education context. A multi-dimensional framework for DA development is first introduced which not only captures important aspects of DA but also highlights the trade-off between these competing dimensions. We then take a closer look at the online testing landscape and use this framework to analyze the pedagogical and technical dimensions of DA in practice.},
booktitle = {2021 5th International Conference on E-Society, E-Education and E-Technology},
pages = {1–6},
numpages = {6},
keywords = {Assessment analytics, Assessment authenticity, Bring-your-own-device, Digital assessment, Lockdown application},
location = {Taipei, Taiwan},
series = {ICSET 2021}
}

@inproceedings{10.1145/3411564.3411630,
author = {Thalheimer, J\'{e}ferson Miguel and Filho, Aluizio Haendchen and Briks, Fabio Julio Pereira and Ribeiro, Rafael Castaneda and Concatto, Fernando and Viecelli, Ang\'{e}lica Karize},
title = {A Microservice-driven Collaborative Agent in Virtual Learning Environments: A Role Model for a Tracing Agent},
year = {2020},
isbn = {9781450388733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411564.3411630},
doi = {10.1145/3411564.3411630},
abstract = {Currently, distance learning comprises almost half of students enrolled in undergraduate courses in Brazil. However, the dropout rate of this modality is over 50%, and only 22% of students complete the courses [27]. Despite technological advances and good acceptance of this modality, research indicates that the lack of involvement in a virtual community can lead to feelings of loneliness, low self-esteem, isolation and desmotivation. There is evidence that these feelings are among the main factors responsible for the low performance and high evasion rate. Virtual Learning Environments (VLE) handles a large volume of student interaction data. In this context, it is important to create mechanisms to maintain and manage a data structure to facilitate the processes of transforming data into information and knowledge. This paper aims to present a tracing agent responsible for maintaining and managing the data structure in VLE. The agent acts in the context of a microservice-oriented multi-agent system, interacting and collaborating with other agents in order to improve interaction and decision-making processes. This work becomes original and at the same time innovative, presenting an unprecedented combination of technologies and techniques in the context of VLEs.},
booktitle = {Proceedings of the XVI Brazilian Symposium on Information Systems},
articleno = {21},
numpages = {8},
keywords = {Multiagent System, Tracing Agent, Virtual Learning Environment},
location = {S\~{a}o Bernardo do Campo, Brazil},
series = {SBSI '20}
}

@inproceedings{10.1145/3510309.3510318,
author = {Yulianto, Budi and Khosasih, Andyni and Tanuar, Evawaty and Prisca Diyanti Todalani Kalumbang, Yuventia},
title = {Taman Belajar: Learning Management System (LMS) that Provides Free Massive Open Online Course (MOOC) for School Students},
year = {2022},
isbn = {9781450385800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510309.3510318},
doi = {10.1145/3510309.3510318},
booktitle = {Proceedings of the 2021 4th International Conference on Education Technology Management},
pages = {52–58},
numpages = {7},
keywords = {Learning management system, lms, massive open online course, mooc},
location = {Tokyo, Japan},
series = {ICETM '21}
}

@proceedings{10.1145/3628096,
title = {AfriCHI '23: Proceedings of the 4th African Human Computer Interaction Conference},
year = {2023},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {East London, South Africa}
}

@proceedings{10.1145/3629296,
title = {ICETC '23: Proceedings of the 15th International Conference on Education Technology and Computers},
year = {2023},
isbn = {9798400709111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@article{10.1145/3691630,
author = {Ntentos, Evangelos and Lueger, Nicole Elisabeth and Simhandl, Georg and Zdun, Uwe and Schneider, Simon and Scandariato, Riccardo and D\'{\i}az Ferreyra, Nicol\'{a}s E.},
title = {On the Understandability of Design-Level Security Practices in Infrastructure-as-Code Scripts and Deployment Architectures},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3691630},
doi = {10.1145/3691630},
abstract = {Infrastructure as Code (IaC) automates IT infrastructure deployment, which is particularly beneficial for continuous releases, for instance, in the context of microservices and cloud systems. Despite its flexibility in application architecture, neglecting security can lead to vulnerabilities. The lack of comprehensive architectural security guidelines for IaC poses challenges in adhering to best practices. We studied how developers interpret IaC scripts (source code) in two IaC technologies, Ansible and Terraform, compared to semi-formal IaC deployment architecture models and metrics regarding design-level security understanding. In a controlled experiment involving ninety-four participants, we assessed the understandability of IaC-based deployment architectures through source code inspection compared to semi-formal representations in models and metrics.We hypothesized that providing semi-formal IaC deployment architecture models and metrics as supplementary material would significantly improve the comprehension of IaC security-related practices, as measured by task correctness. Our findings suggest that semi-formal IaC deployment architecture models and metrics as supplementary material enhance the understandability of IaC security-related practices without significantly increasing duration. We also observed a significant correlation between task correctness and duration when models and metrics were provided.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {6},
numpages = {37},
keywords = {Infrastructure as code, modeling, best practices, controlled experiment, empirical software engineering}
}

@inproceedings{10.1145/3492323.3495622,
author = {Heredia, Andres and Barros-Gavilanes, Gabriel},
title = {Dealing with multi-step verification processes for certification issuance in universities},
year = {2022},
isbn = {9781450391634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492323.3495622},
doi = {10.1145/3492323.3495622},
abstract = {As in any institution, universities have processes defined in an unique way, involving many verification steps. Issuance of end-of-course certificates require multiple signatures from authorities, instructors and in some cases administrative staff. After an initial work of single signature certificates using blockchain for education purposes, we generate a prototype including more than one signature over the infrastructure generated for the Smart Ecosystem for Learning and Inclusion or SELI project. This prototype records certificates in a private non-monetary blockchain network, and is provided as an open source project. Countries like Ecuador, Turkey, Uruguay, and Finland can share certificates from the SELI platform through local nodes. This article provides relevant details about the implementation of the system, always with the aim of re-use existing software to reduce implementation time.},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
articleno = {12},
numpages = {5},
keywords = {blockchain, education, multi-signature, open source, smart contract},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@proceedings{10.1145/3568739,
title = {ICDTE '22: Proceedings of the 6th International Conference on Digital Technology in Education},
year = {2022},
isbn = {9781450398091},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@inproceedings{10.1145/3287324.3287480,
author = {Dicheva, Darina and Irwin, Keith and Dichev, Christo},
title = {OneUp: Engaging Students in a Gamified Data Structures Course},
year = {2019},
isbn = {9781450358903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287324.3287480},
doi = {10.1145/3287324.3287480},
abstract = {Although many CS courses require extensive practice, a large number of students show low motivation for engaging in non-graded, self-directed learning activities. To address this problem, we developed OneUp - a highly configurable course gamification platform that enables instructors to tailor the gamification features to fit their preferences. This paper presents a case study of using OneUp to gamify a Data Structures course. The focus is on encouraging students' self-study and better engagement with out-of-class online practicing. We describe the utilized game elements - badges, leaderboard, virtual currency, and learning dashboards, and provide a descriptive analysis of their use. The results of our evaluation show that this gamification intervention has been well received by the students, resulting in significantly increased student engagement and out-of-class practicing and in a reduced failing rate.},
booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
pages = {386–392},
numpages = {7},
keywords = {active learning, data structures, gamification, out-of-class study},
location = {Minneapolis, MN, USA},
series = {SIGCSE '19}
}

@inproceedings{10.1145/3051457.3054000,
author = {H\r{a}klev, Stian and Faucon, Louis and Hadzilacos, Thanasis and Dillenbourg, Pierre},
title = {Orchestration Graphs: Enabling Rich Social Pedagogical Scenarios in MOOCs},
year = {2017},
isbn = {9781450344500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3051457.3054000},
doi = {10.1145/3051457.3054000},
abstract = {One of the initial promises of MOOCs was to enable participants from around the world to learn and build knowledge together, however existing MOOC platforms are very limited in their collaborative functionality. Using a recent educational modeling language which can express a broad diversity of educational scenarios, we present a technical infrastructure design and prototype which enables instructors to design and run pedagogically rich and therefore complex scenarios. We present this as a theoretical and technical contribution to support a broad program of research and innovation related to collaborative learning at scale.},
booktitle = {Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale},
pages = {261–264},
numpages = {4},
keywords = {moocs, orchestration., scripting},
location = {Cambridge, Massachusetts, USA},
series = {L@S '17}
}

@inproceedings{10.1145/3291801.3291828,
author = {Hussain, Mushtaq and Hussain, Sadiq and Zhang, Wu and Zhu, Wenhao and Theodorou, Paraskevi and Abidi, Syed Muhammad Raza},
title = {Mining Moodle Data to Detect the Inactive and Low-performance Students during the Moodle Course},
year = {2018},
isbn = {9781450364768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291801.3291828},
doi = {10.1145/3291801.3291828},
abstract = {In web-based learning systems such as massive open online course (MOOC) and modular object-oriented developmental learning environment (Moodle), monitoring the student's activities as well as predict the low-performance students is an important task because it enables the instructors to award the students when their activities level drops from normal activities levels as well as having lower grades. We used several machine learning (ML) classification and clustering techniques to extract the pattern from student data during completing the Moodle course; which enables the instructor to detect the low-performance student in advance before the examination. The experimental result shows that the fuzzy unordered rule induction algorithm (FURIA) classification technique achieves high accuracy in detecting inactive students as well as predicts the different categories of the student during the Moodle course. The K-means clustering is also able to group the inactive and active users and poorly performed users. The result demonstrates that our proposed system will be easily integrated to Moodle system to send alert to inactive and low- performance students while completing the course and build efficient education environment for the students.},
booktitle = {Proceedings of the 2nd International Conference on Big Data Research},
pages = {133–140},
numpages = {8},
keywords = {Machine learning, Moodle data, activities, and classification, clustering, inactive, low performance},
location = {Weihai, China},
series = {ICBDR '18}
}

@proceedings{10.1145/3631700,
title = {UMAP Adjunct '24: Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3292147.3292168,
author = {Prieto-Alvarez, Carlos Gerardo and Martinez-Maldonado, Roberto and Buckingham Shum, Simon},
title = {Mapping learner-data journeys: evolution of a visual co-design tool},
year = {2018},
isbn = {9781450361880},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292147.3292168},
doi = {10.1145/3292147.3292168},
abstract = {In this paper we present a three-phase process for crafting Learner-Data Journey maps and using them as communication tools to involve other stakeholders in the co-design of a data-intensive educational tool. The three phases in this process are i) scaffolding groups of learners to collaboratively co-create a Learner-Data Journey based on their own experience, ii) distilling key insights from these journey maps, and iii) providing the means for multiple stakeholders to integrate and synthesise key insights from these journey maps to suggest design requirements. We illustrate the process and the kind of tools that can support the co-creation of Learner-Data Journeys in two educational scenarios where learners have become partners of their own 'surveillance'.},
booktitle = {Proceedings of the 30th Australian Conference on Computer-Human Interaction},
pages = {205–214},
numpages = {10},
keywords = {co-design, educational technologies, participatory surveillance, user journey},
location = {Melbourne, Australia},
series = {OzCHI '18}
}

@inproceedings{10.1145/3450614.3464480,
author = {Karoui, Aous and Alvarez, Lionel and Goffre, Thierry and Dherbey Chapuis, Nathalie and Rodi, Mireille and Ramalho, Mario},
title = {Adaptive Pathways within the European Platform for Personalized Language Learning PEAPL},
year = {2021},
isbn = {9781450383677},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450614.3464480},
doi = {10.1145/3450614.3464480},
abstract = {The customization of learning pathways based on competency profiles and game-based learning are increasingly being adopted by education stakeholders because of their potential to maximize the effectiveness of instruction. However, actual learning can vary among individuals, particularly according to specific needs (e.g., L2 speakers learners, students with dyslexia, hearing-impaired children, etc.). In this article, we first present GamesHUB, the pedagogical games platform for primary school pupils, integrating the creation of playful and personalized learning paths. Secondly, we address the issue of adaptive learning, according to the different pupils’ profiles, through the integration of pedagogical resources based on adaptive pathways in the framework of the European project PEAPL. We discuss the way these pathways are elaborated to get close to didactic sequences’ frames that are proposed for the ordinary classroom.},
booktitle = {Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {90–94},
numpages = {5},
keywords = {TEL environment, adaptive learning paths, game-based learning},
location = {Utrecht, Netherlands},
series = {UMAP '21}
}

@inproceedings{10.1145/3242587.3242606,
author = {Dziubak, Volodymyr and Lafreniere, Ben and Grossman, Tovi and Bunt, Andrea and Fitzmaurice, George},
title = {Maestro: Designing a System for Real-Time Orchestration of 3D Modeling Workshops},
year = {2018},
isbn = {9781450359481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242587.3242606},
doi = {10.1145/3242587.3242606},
abstract = {Instructors of 3D design workshops for children face many challenges, including maintaining awareness of students' progress, helping students who need additional attention, and creating a fun experience while still achieving learning goals. To help address these challenges, we developed Maestro, a workshop orchestration system that visualizes students' progress, automatically detects and draws attention to common challenges faced by students, and provides mechanisms to address common student challenges as they occur. We present the design of Maestro, and the results of a case-study evaluation with an experienced facilitator and 13 children. The facilitator appreciated Maestro's real-time indications of which students were successfully following her tutorial demonstration, and recognized the system's potential to "extend her reach" while helping struggling students. Participant interaction data from the study provided support for our follow-along detection algorithm, and the capability to remind students to use 3D navigation.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
pages = {287–298},
numpages = {12},
keywords = {analytics, real-time teaching assistance, software learning},
location = {Berlin, Germany},
series = {UIST '18}
}

@inproceedings{10.1145/3322276.3322365,
author = {d'Anjou, Bernice and Bakker, Saskia and An, Pengcheng and Bekker, Tilde},
title = {How Peripheral Data Visualisation Systems Support Secondary School Teachers during VLE-Supported Lessons},
year = {2019},
isbn = {9781450358507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322276.3322365},
doi = {10.1145/3322276.3322365},
abstract = {Through the integration of technology-enhanced learning (TEL) in the classrooms, there is an increase in Virtual Learning Environment-supported classes in secondary schools, which brings unintentional complexities in terms of monitoring for teachers [25]. To support secondary school teachers during VLE-supported lessons, a peripheral data visualisation system was designed and implemented in a three-week field study. Both qualitative and quantitative data were gathered and analysed through methodological triangulation in order to get an in-depth understanding about the use of the system by teachers. The key findings from our study were that the peripheral data visualisation tool, by being a distributed, highly visible system, was well integrated in the teachers' practice. The peripheral visualisation served as a trigger for teacher interventions where the teacher could confront the student's level of concentration and provide support when a student needs it. Furthermore, by offloading the secondary tasks of checking the students' level of concentration and progress to the visualisation, most teachers experienced more peace of mind and space to manage their primary teaching practice. Lastly, approximately 95% of 89 students experienced the data visualisation as neutral or motivating, while 5.7% of the students experienced violation of privacy by this medium.},
booktitle = {Proceedings of the 2019 on Designing Interactive Systems Conference},
pages = {859–870},
numpages = {12},
keywords = {mixed methods study, peripheral data visualisation, teacher interventions, virtual learning environment},
location = {San Diego, CA, USA},
series = {DIS '19}
}

@article{10.1145/2793507,
author = {Vivian, Rebecca and Falkner, Katrina and Falkner, Nickolas and Tarmazdi, Hamid},
title = {A Method to Analyze Computer Science Students’ Teamwork in Online Collaborative Learning Environments},
year = {2016},
issue_date = {March 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
url = {https://doi.org/10.1145/2793507},
doi = {10.1145/2793507},
abstract = {Although teamwork has been identified as an essential skill for Computer Science (CS) graduates, these skills are identified as lacking by industry employers, which suggests a need for more proactive measures to teach and assess teamwork. In one CS course, students worked in teams to create a wiki solution to problem-based questions. Through a case-study approach, we test a developed teamwork framework, using manual content analysis and sentiment analysis, to determine if the framework can provide insight into students’ teamwork behavior and to determine if the wiki task encouraged students to collaborate, share knowledge, and self-adopt teamwork roles. Analysis revealed the identification of both active and cohesive teams, disengaged students, and particular roles and behaviors that were lacking. Furthermore, sentiment analysis revealed that teams moved through positive and negative emotions over the course of developing their solution, toward satisfaction. The findings demonstrate the value of the detailed analysis of online teamwork. However, we propose the need for automated measures that provide real-time feedback to assist educators in the fair and efficient assessment of teamwork. We present a prototype system and recommendations, based on our analysis, for automated teamwork analysis tools.},
journal = {ACM Trans. Comput. Educ.},
month = feb,
articleno = {7},
numpages = {28},
keywords = {Teamwork, problem-based learning}
}

@inproceedings{10.1145/3512353.3512369,
author = {B. Garcia, Manuel and F.Revano Jr., Teodoro},
title = {Pandemic, Higher Education, and a Developing Country: How Teachers and Students Adapt to Emergency Remote Education},
year = {2022},
isbn = {9781450395571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512353.3512369},
doi = {10.1145/3512353.3512369},
booktitle = {Proceedings of the 2022 4th Asia Pacific Information Technology Conference},
pages = {111–115},
numpages = {5},
keywords = {COVID-19, Developing Country, Distance Education, Emergency Remote Education, Higher Education, Online Learning, Pandemic},
location = {Virtual Event, Thailand},
series = {APIT '22}
}

@inproceedings{10.1145/3424953.3426627,
author = {Macedo, Maylon Pires and Paiva, Ranilson Oscar Ara\'{u}jo and Gasparini, Isabela and Zaina, Luciana Aparecida Martinez},
title = {Vis2Learning: a scenario-based guide of recommendations for building educational data visualizations},
year = {2020},
isbn = {9781450381727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424953.3426627},
doi = {10.1145/3424953.3426627},
abstract = {Information Visualization concerns efforts on creating better solutions to represent data in visual formats and consequently support the user interpretation on it. The literature has shown that there is a gap in the development of educational data visualizations which fulfill end-user needs. This paper presents Vis2Learning a guide of recommendations to support the building of visualizations applied to educational data in e-learning context. Vis2Learning provides a set of scenarios from which educational data visualizations can be developed. Each scenario comprises (i) a visual format of visualization and its characteristics; (ii) examples of how to use it; and (iii) overall recommendations to enhance the user's understanding on the data. We carried out an online questionnaire from which 34 end-users (Brazilian teachers) evaluated visualizations which were constructed by using the guide. The results reveal that the recommendations made the visualizations suitable to be applied in the e-learning context. However, our findings showed that the participants who did not have a former contact with visualizations in e-learning context struggled to understand some visual formats which are not well-known by the audience.},
booktitle = {Proceedings of the 19th Brazilian Symposium on Human Factors in Computing Systems},
articleno = {36},
numpages = {10},
keywords = {e-learning, educational data, end-user interaction, information visualization},
location = {Diamantina, Brazil},
series = {IHC '20}
}

@article{10.1145/3358902,
author = {Ogan, Amy},
title = {Reframing classroom sensing: promise and peril},
year = {2019},
issue_date = {November - December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {6},
issn = {1072-5520},
url = {https://doi.org/10.1145/3358902},
doi = {10.1145/3358902},
journal = {Interactions},
month = oct,
pages = {26–32},
numpages = {7}
}

@inproceedings{10.1145/3599640.3599648,
author = {Cheng, Eric C. K. and Wang, Tianchong},
title = {Exploring Pedagogies &amp; Strategies for Integrating Adaptive Learning Platforms: A Case Study of a High School in Hong Kong},
year = {2023},
isbn = {9781450399593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599640.3599648},
doi = {10.1145/3599640.3599648},
abstract = {This paper explores the pedagogical approaches teachers employ and the strategies that school leaders implement to promote the use of an Adaptive Learning Platform (ALP) in a high school in Hong Kong. It assesses how such an AI-powered platform can support teachers in enhancing student engagement and learning outcomes. The study employs a case study methodology to identify the factors influencing the incorporation of ALP. Qualitative data were collected through teacher interviews, and an in-depth analysis was carried out to identify effective pedagogies and strategies for implementing adaptive learning. The findings of this study underscore the significance of supportive school leadership that encourages teachers to embrace ALP as a tool for promoting student learning. Additionally, effective implementation of ALP necessitates a shift in pedagogical practices from traditional teacher-centred approaches to more student-centred strategies. The study concludes that the integration of ALP into teaching practices can boost student engagement and elevate the quality of learning outcomes. In summary, this research contributes to understanding the successful implementation of ALP in high schools, emphasising the critical roles of school leadership support and the adoption of student-centred pedagogies. The findings provide valuable insights for educators, administrators, and policymakers interested in utilising ALP to improve student learning outcomes.},
booktitle = {Proceedings of the 9th International Conference on Education and Training Technologies},
articleno = {8},
numpages = {9},
keywords = {AI in Education, Adaptive learning system, Assessment for learning, Pedagogies},
location = {Macau, China},
series = {ICETT '23}
}

@inproceedings{10.1145/3448018.3459654,
author = {Lu, Wenyi and He, Hao and Urban, Alex and Griffin, Joe},
title = {What the Eyes Can Tell: Analyzing Visual Attention with an Educational Video Game},
year = {2021},
isbn = {9781450383455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448018.3459654},
doi = {10.1145/3448018.3459654},
abstract = {3D video games show potential as educational tools that improve learner engagement. Integrating 3D games into school curricula, however, faces various challenges. One challenge is providing visualizations on learning dashboards for instructors. Such dashboards provide needed information so that instructors may conduct timely and appropriate interventions when students need it. Another challenge is identifying contributive learning predictors for a computational model, which can be the core algorithm used to make games more intelligent for tutoring and assessment purposes. Previous studies have found that students' visual-attention is a vital aspect of engagement during gameplay. However, few studies have examined whether attention visualization patterns can distinguish students from different performance groups. Complicating this research is the relatively nascent investigation into gaze metrics for learning-prediction models. In this exploratory study, we used eye-tracking data from an educational game, Mission HydroSci, to examine visual-attention pattern differences between low and high performers and how their self-reported demographics affect such patterns. Results showed different visual-attention patterns between low and high performers. Additionally, self-reported science, gaming, and navigational expertise levels were significantly correlated to several gaze metric features.},
booktitle = {ACM Symposium on Eye Tracking Research and Applications},
articleno = {36},
numpages = {7},
location = {Virtual Event, Germany},
series = {ETRA '21 Short Papers}
}

@proceedings{10.1145/2993363,
title = {SA '16: SIGGRAPH ASIA 2016 Symposium on Education: Talks},
year = {2016},
isbn = {9781450345453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SIGGRAPH Asia Symposium on Education program will be inviting experts from both academia and the industry to present innovative research, methods and positions about the teaching and integration of computer graphics and interactive techniques in all areas of learning.This year's main conference theme is "Key to the Future." Education is the key to our future, and we view education as a natural part of the lifelong learning process. We wish to support the evolving integration of art and technology embraced by educators.As an international gathering of industry professionals and academics, the Symposium on Education will present perspectives that appeal to a wide spectrum of interests. We will share educational strategies adopted in both industry and academia to make the learning process more satisfying, productive, and meaningful.},
location = {Macau}
}

@inproceedings{10.1145/3369457.3369539,
author = {Johal, Wafa and Tran, Alex and Khodr, Hala and \"{O}zg\"{u}r, Ayberk and Dillenbourg, Pierre},
title = {TIP: Tangible e-Ink Paper Manipulatives for Classroom Orchestration},
year = {2020},
isbn = {9781450376969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369457.3369539},
doi = {10.1145/3369457.3369539},
abstract = {While digital tools are more and more used in classrooms, teachers' common practice remains to use photocopied paper documents to share and collect learning exercises from their students. With the Tangible e-Ink Paper (TIP) system, we aim to explore the use of tangible manipulatives interacting with paper sheets as a bridge between digital and paper traces of learning. Featuring an e-Ink display, a paper-based localisation system and a wireless connection, TIPs are envisioned to be used as a versatile tool across various curriculum activities. In this paper, we present the design principles of TIPs and a first functional prototype. We conclude by presenting future works in the evaluation of TIPs as a distributed sensor for teachers in their classroom, including learning scenario examples to illustrate our statements.},
booktitle = {Proceedings of the 31st Australian Conference on Human-Computer-Interaction},
pages = {595–598},
numpages = {4},
keywords = {classroom orchestration, collaborative learning, education, iot, tangible manipulative},
location = {Fremantle, WA, Australia},
series = {OzCHI '19}
}

@inproceedings{10.1145/3102071.3106354,
author = {Laffey, James M. and Griffin, Joe and Sigoloff, Justin and Lander, Sean and Sadler, Troy and Goggins, Sean and Kim, So Mi and Wulff, Eric and Womack, Andrew J.},
title = {Mission HydroSci: a progress report on a transformational role playing game for science learning},
year = {2017},
isbn = {9781450353199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3102071.3106354},
doi = {10.1145/3102071.3106354},
abstract = {Mission HydroSci is a game-based 3D virtual environment for enacting transformational role-playing for middle school science students. Student-players will be engaged in a narrative about needing to investigate water resources and use scientific argumentation to complete missions critical to the survival and accomplishments of the members of their scientific enterprise. Our poster presents our progress in years 1 and 2 of a funded project to integrate pedagogical and gameplay objectives, and build mechanisms for purposeful player engagement and activity.},
booktitle = {Proceedings of the 12th International Conference on the Foundations of Digital Games},
articleno = {47},
numpages = {4},
keywords = {3D virtual learning environments, games for a purpose, science learning, scientific argumentation, transformational play},
location = {Hyannis, Massachusetts},
series = {FDG '17}
}

@inproceedings{10.1145/3383668.3419937,
author = {Lee-Cultura, Serena and Sharma, Kshitij and Aloizou, Valeria and Retalis, Symeon and Giannakos, Michail},
title = {Children's Interaction with Motion-Based Touchless Games: Kinecting Effectiveness and Efficiency},
year = {2020},
isbn = {9781450375870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383668.3419937},
doi = {10.1145/3383668.3419937},
abstract = {Leveraging movement data to support children's learning is appealing and technically challenging. However, there is limited knowledge about exploiting the complete design potential of bodily interplay in learning games. We conducted an in-the-wild study with 8 children, with special educational needs, playing a language based educational motion-based touchless game. We collected children's interaction data (correctness and reaction time), and data regarding the different design elements (game settings) implemented in 90 game sessions. Our analysis shows that number of items on-screen, selection gestures, and time to select items, impact the effectiveness (correctness) and efficiency (reaction time) of the children. We highlight the value of interaction analytics and quantify the relationship between different game design elements and children?s efficiency and effectiveness. Our findings help shape the future of learning research by emphasising the substantial benefits of collecting movement data during children's interaction with learning games.},
booktitle = {Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play},
pages = {140–145},
numpages = {6},
keywords = {child-computer interaction, educational games, embodied interaction, gesture, motion-based games},
location = {Virtual Event, Canada},
series = {CHI PLAY '20}
}

@inproceedings{10.1145/2541016.2541076,
author = {Martinez-Maldonado, Roberto and Dimitriadis, Yannis and Clayphan, Andrew and Mu\~{n}oz-Crist\'{o}bal, Juan A. and Prieto, Luis P. and Rodr\'{\i}guez-Triana, Mar\'{\i}a Jes\'{u}s and Kay, Judy},
title = {Integrating orchestration of ubiquitous and pervasive learning environments},
year = {2013},
isbn = {9781450325257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541016.2541076},
doi = {10.1145/2541016.2541076},
abstract = {Ubiquitous and pervasive computing devices, such as interactive tabletops, whiteboards, tablets and phones, have the potential to enhance the management and awareness of learning activities in important ways. They provide students with natural ways to interact with collaborators, and can help teachers create and manage learning tasks that can be carried out both in the classroom and at a distance. But how can these emerging technologies be successfully integrated into current teaching practice? This paper proposes an approach to integrate, from the technological perspective, collaborative learning activities using these kinds of devices. Our approach is based on the concept of orchestration, which tackles the critical task for teachers to coordinate student's learning activities within the constraints of authentic educational settings. Our studies within authentic learning settings enabled us to identify three main elements that are important for ubiquitous and pervasive learning settings. These are i) regulation mechanisms, ii) interconnection with existing web-based learning environments, and iii) awareness tools.},
booktitle = {Proceedings of the 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration},
pages = {189–192},
numpages = {4},
keywords = {collaborative learning, design, pervasive, smartphones, tabletops, tablets, ubiquitous computing},
location = {Adelaide, Australia},
series = {OzCHI '13}
}

@inproceedings{10.1145/3314527.3314537,
author = {Cabanban-Casem, Christianne Lynnette},
title = {Analytical Visualization of Higher Education Institutions' Big Data for Decision Making},
year = {2019},
isbn = {9781450366212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314527.3314537},
doi = {10.1145/3314527.3314537},
abstract = {Education is an important element towards learning and human development, thus, it is the key towards identifying competencies and better productivity for the workforce. As part of the Commission on Higher Education's (CHED) thrust for improving efficiency and effectiveness by simplifying the collection process for all the stakeholders, the developed system will drastically improve the availability of data for making informed decisions and efficient generation of reports.This research outlines opportunities and challenges associated with the implementation and governance of Big Data in higher education through development and implementation of data analytics tool.},
booktitle = {Proceedings of the 2019 Asia Pacific Information Technology Conference},
pages = {61–64},
numpages = {4},
keywords = {Data Science, Higher Education Data, Knowledge Management},
location = {Jeju Island, Republic of Korea},
series = {APIT '19}
}

@inproceedings{10.1145/3051457.3053968,
author = {Faucon, Louis and H\r{a}klev, Stian and Hadzilacos, Thanasis and Dillenbourg, Pierre},
title = {Demo of Orchestration Graph Engine: Enabling Rich Social Pedagogical Scenarios in MOOCs},
year = {2017},
isbn = {9781450344500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3051457.3053968},
doi = {10.1145/3051457.3053968},
abstract = {This demo submission is associated with the Work-in-Progress submission "Orchestration Graphs: enabling rich social pedagogical scenarios in MOOCs". We present our implementation of a web application for designing, running and orchestrating social pedagogical scenarios. The application is based on Orchestration Graphs, an educational modeling language. We plan to demonstrate our technology by automatically simulating user activity, and offering visitors the opportunity to interact with the graph editor.},
booktitle = {Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale},
pages = {143–144},
numpages = {2},
keywords = {moocs, orchestration, scripting},
location = {Cambridge, Massachusetts, USA},
series = {L@S '17}
}

@article{10.1145/3610079,
author = {Chen, Si and Situ, Jason and Cheng, Haocong and Kirst, Desir\'{e}e and Huang, Yun},
title = {MirrorUs: Mirroring Peers' Affective Cues to Promote Learner's Meta-Cognition in Video-based Learning},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610079},
doi = {10.1145/3610079},
abstract = {Learners' awareness of their own affective states (emotions) can improve their meta-cognition, which is a critical skill of being aware of and controlling one's cognitive, motivational, and affect, and adjusting their learning strategies and behaviors accordingly. To investigate the effect of peers' affects on learners' meta-cognition, we proposed two types of cues that aggregated peers' affects that were recognized via facial expression recognition:Locative cues (displaying the spikes of peers' emotions along a video timeline) andTemporal cues (showing the positivities of peers' emotions at different segments of a video). We conducted a between-subject experiment with 42 college students through the use of think-aloud protocols, interviews, and surveys. Our results showed that the two types of cues improved participants' meta-cognition differently. For example, interacting with theTemporal cues triggered the participants to compare their own affective responses with their peers and reflect more on why and how they had different emotions with the same video content. While the participants perceived the benefits of using AI-generated peers' cues to improve their awareness of their own learning affects, they also sought more explanations from their peers to understand the AI-generated results. Our findings not only provide novel design implications for promoting learners' meta-cognition with privacy-preserved social cues of peers' learning affects, but also suggest an expanded design framework for Explainable AI (XAI).},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {288},
numpages = {25},
keywords = {facial recognition, meta-cognition, online learning}
}

@inproceedings{10.1145/3491140.3528270,
author = {Chen, Youjie and Fu, Annie and Lee, Jennifer Jia-Ling and Tomasik, Ian Wilkie and Kizilcec, Ren\'{e} F.},
title = {Pathways: Exploring Academic Interests with Historical Course Enrollment Records},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528270},
doi = {10.1145/3491140.3528270},
abstract = {Students are encouraged to explore their interests during college to stimulate intellectual growth and prepare for a dynamic labor market. However, interest exploration is entangled with the fateful process of choosing courses for enrollment, and most institutions offer limited tools to help students choose. We propose Pathways, an interactive course information retrieval tool that facilitates interest exploration and course discovery with a diverse pool of historical course enrollment records. The tool visualizes sequences of course enrollments as "academic pathways" to grant students unprecedented insights into the academic choices of prior students. We share our design process, including a formative study on need analysis, the UX and algorithm design, and an evaluation study. We find that Pathways supports students in finding courses that both match their interests and expose them to new ideas. We discuss directions for future work on how interest exploration can be promoted at scale and on how to utilize historical course enrollment data through visualization.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {222–233},
numpages = {12},
keywords = {course decision, data storytelling, higher education, interest},
location = {New York City, NY, USA},
series = {L@S '22}
}

@inproceedings{10.1145/3018896.3018975,
author = {Hussein, Ashraf S. and Khan, Hamayun A.},
title = {Students' performance tracking in distributed open education using big data analytics},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018975},
doi = {10.1145/3018896.3018975},
abstract = {The field of Big Data Analytics (BDA) is advancing rapidly, and it is finding adoption in diverse areas such as Health, Commerce, Logistics, Retail and Manufacturing to name a few. Adoption of BDA techniques in the field of Higher Education is new, and it is steadily increasing. In this work, BDA techniques have been applied to track the Key Academic Performance Indicators (KAPIs) related to students at the Arab Open University (AOU) and to support the corresponding decisions in this regard. Since the AOU is a Pan Arab multi-campus distributed institution operating in 8 countries and makes extensive use of a wide range of cloud based applications to manage the students' life cycle, hence it is an ideal candidate for adoption of BDA techniques to track students' KAPIs across the AOU multiple country campuses. In order to achieve this objective, we have used IBM Watson Analytics (WA) platform to track the students' KAPIs. As a pilot project, we have focused in this work on the Information Technology and Computing (ITC) academic programme across the AOU. The Exploration and Business Intelligence BDA capabilities of WA have enabled us to analyze and track the academic KAPIs of the ITC students across AOU country campuses while the Predictive Analytics (PA) has led to identifying the dominant factors behind some of our problems such as students drop out rates. One of the most promising outcomes is the decision support dashboards such as the one related to the Student Risk Factor (SRF). By identifying At Risk Students, such dashboard can act as an "Early Alert System" to enable the AOU management to take corrective action to provide needed support to such students.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {75},
numpages = {8},
keywords = {academic key performance indicators, big data analytics, educational data analytics, student information systems, watson analytics},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3287098.3287140,
author = {F\'{e}raud, Genevi\`{e}ve and Holzer, Adrian and Cardia, Isabelle Von\`{e}che and Gillet, Denis},
title = {ICT adoption in executive training for development: blending digital and physical communication and awareness channels},
year = {2019},
isbn = {9781450361224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287098.3287140},
doi = {10.1145/3287098.3287140},
abstract = {Digital capacity building is a key policy for states to meet the Sustainable Development Goals. This paper1 presents one of the actions carried out by the United Nations Conference on Trade and Development (UNCTAD) in collaboration with the Swiss Federal Institute of Technology in Lausanne (EPFL) to tackle the multifaceted digitization challenges in developing and transition economies by introducing blended learning in one of its flagship executive courses. The main outcome is the obvious but generally neglected importance of focusing on the added values, the competence development, and confidence building for all stakeholders to trigger adoption. These objectives are partially tackled by blending digital and physical communication and awareness channels in face-to-face executive training sessions.},
booktitle = {Proceedings of the Tenth International Conference on Information and Communication Technologies and Development},
articleno = {44},
numpages = {4},
keywords = {blended learning, community building, digital education, discussion channels, executive training, knowledge sharing, participation},
location = {Ahmedabad, India},
series = {ICTD '19}
}

@inproceedings{10.1145/3377672.3378054,
author = {Liqiang, Hao and Quan, Liu},
title = {Design of Resource Recommendation Model for Personalized Learning in the Era of Big Data},
year = {2020},
isbn = {9781450362481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377672.3378054},
doi = {10.1145/3377672.3378054},
abstract = {This paper proposes a personalized learning resource recommendation model based on big data. The design of the model consists of data storage, data analysis, resource matching, and the resource recommendation. In order to provide a suitable resource, data analysis is a more critical procedure that involves the analyses of basic information, learning style, learning status, learning behavior, and learning interest, which can be successfully analyzed by means of kafka and flume. Through an experiment, it shows that personalized resource recommendation platform really plays a positive role in improving students learning.},
booktitle = {Proceedings of the 2019 Annual Meeting on Management Engineering},
pages = {181–187},
numpages = {7},
keywords = {big data, personalized learning, recommendation model},
location = {Kuala Lumpur, Malaysia},
series = {AMME 2019}
}

@inproceedings{10.1145/3141151.3141161,
author = {Rei, Andr\'{e} and Figueira, \'{A}lvaro and Oliveira, Luciana},
title = {A System for Visualization and Analysis of Online Pedagogical Interactions},
year = {2017},
isbn = {9781450353311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3141151.3141161},
doi = {10.1145/3141151.3141161},
abstract = {We present a system for a dynamic graphical representation of the interactions captured in educational online environments. The system goes beyond interaction between students and teachers, also addressing resource usage or any other entity for which it is possible to create a relation which binds two entities. By defining these relationships between pairs of entities in an online learning environment (Moodle, in our case) our tool creates a graph, where it is possible to apply techniques of social network analysis. This system brings up new possibilities for e-learning as a tool capable of helping the teacher assorting and illustrating the degree of participation and to find the implicit relations between participants, or participants and resources or events.},
booktitle = {Proceedings of the 2017 1st International Conference on E-Education, E-Business and E-Technology},
pages = {42–46},
numpages = {5},
keywords = {Learning Management System, Social Graph, Social Network Analysis, Virtual Teaching Environment},
location = {Toronto, ON, Canada},
series = {ICEBT '17}
}

@inproceedings{10.1145/3175536.3175552,
author = {Sha, Junhong and Chen, Kaiquan},
title = {Analysis of Technology Enhancing Knowledge Sharing in Learning Communities: from Handbarrow to Social Expansion to Intelligent Tutoring},
year = {2017},
isbn = {9781450354356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3175536.3175552},
doi = {10.1145/3175536.3175552},
abstract = {Since the first computer ENIAC was born in 1946, it has been over half a century and technologies which develop rapidly have changed the way of knowledge sharing notably. By means of technologies, community entities were transported to the Internet in early times and became the prototype of online learning community. With the range expansion of social media, the functions of learning community increase and technology as scaffold supports communication and knowledge sharing widely. Recently, Artificial Intelligence(AI) makes knowledge sharing elaborately through all kinds of agents and intelligent tutoring systems. In this paper, we quote cases to analyze how knowledge sharing benefits from technology development in different stages and list intelligent technology enhancement for learning specifically.},
booktitle = {Proceedings of the 9th International Conference on Education Technology and Computers},
pages = {22–26},
numpages = {5},
keywords = {instructional technology, intelligent tutoring, knowledge sharing, social expansion},
location = {Barcelona, Spain},
series = {ICETC '17}
}

@inproceedings{10.1145/3491140.3528275,
author = {Leite, Walter L. and Kuang, Huan and Shen, Zuchao and Chakraborty, Nilanjana and Michailidis, George and D'Mello, Sidney and Xing, Wanli},
title = {Heterogeneity of Treatment Effects of a Video Recommendation System for Algebra},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3528275},
doi = {10.1145/3491140.3528275},
abstract = {Previous research has shown that providing video recommendations to students in virtual learning environments implemented at scale positively affects student achievement. However, it is also critical to evaluate whether the treatment effects are heterogeneous, and whether they depend on contextual variables such as disadvantaged student status and characteristics of the school settings. The current study extends the evaluation of a novel video recommendation system by performing an exploratory search for sources of heterogeneity of treatment effects. This study's design is a multi-site randomized controlled trial with an assignment at the student level across three large and diverse school districts in the southeast United States. The study occurred in Spring 2021, when some students were in regular classrooms and others in online classrooms. The results of the current study replicate positive effects found in a previous field experiment that occurred in Spring 2020, at the onset of the COVID-19 pandemic. Then, causal forests were used to investigate the heterogeneity of treatment effects. This study contributes to the literature on content sequencing systems and recommendation systems by showing how these systems can disproportionally benefit the groups of students who had higher levels of previous algebra ability, followed more recommendations, learned remotely, were Hispanic, and received free or reduced-price lunch, which has implications for the fairness of implementation of educational technology solutions.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {12–23},
numpages = {12},
keywords = {content sequencing, heterogeneity of treatment effect, randomized controlled trial, video recommendation system},
location = {New York City, NY, USA},
series = {L@S '22}
}

@proceedings{10.1145/3537674,
title = {SIGITE '22: Proceedings of the 23rd Annual Conference on Information Technology Education},
year = {2022},
isbn = {9781450393911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chicago, IL, USA}
}

@inproceedings{10.1145/3144826.3145352,
author = {Dodero, Juan Manuel and Mota, Jos\'{e} Miguel and Ruiz-Rube, Iv\'{a}n},
title = {Bringing computational thinking to teachers' training: a workshop review},
year = {2017},
isbn = {9781450353861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3144826.3145352},
doi = {10.1145/3144826.3145352},
abstract = {In recent years, several visual programming languages and tools are emerging, which allow young students to easily program applications. Particularly, the block-based language used by Scratch has been the standard in most school initiatives to introduce Computational thinking (CT) in courses unrelated to computing. However, CT competences are not specifically included in the curricula of many Higher Education degrees that future teachers of Primary and Secondary Education have to complete. This paper describes a workshop for teachers' training on CT. It is based on the block-based common language of Scratch, but focused on enhancing teachers' skills to develop mobile applications with a tool based on the MIT's AppInventor. This workshop provided some insights on the capabilities of future teachers in the use of programming tools1.},
booktitle = {Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality},
articleno = {4},
numpages = {6},
keywords = {Computational thinking, mobile programming, visual programming languages},
location = {C\'{a}diz, Spain},
series = {TEEM 2017}
}

@inproceedings{10.1145/3472301.3484349,
author = {Monteiro, Ingrid Teixeira and de Lima Brilhante, Marcelo Q. and dos Santos, Jessica M. \'{A}vila and de Mattos Brito Oliveira, Francisco C. and de Oliveira, Ana C. Bernardo},
title = {Mobile game-based learning with Opi app: Lessons learned with a children usability evaluation},
year = {2021},
isbn = {9781450386173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472301.3484349},
doi = {10.1145/3472301.3484349},
abstract = {Smartphones have been an alternative resource in emergency remote learning. In this paper, we introduce the Opi application, an educational game aimed at students from the 1st to the 5th grade of elementary school. The application was developed with the objective of contributing to the engagement and motivation of children in the context of remote classes during the Covid-19 pandemic, in addition to promoting the participation of parents in the process. The main functionalities and characteristics of Opi are described from a mobile game-based learning framework. We report the usability evaluation carried out with children and parents, listing the problems found and the suggestions and feedback. It ends with some lessons learned on the design and evaluation for children in the context of the pandemic and of mobile game-based learning.},
booktitle = {Proceedings of the XX Brazilian Symposium on Human Factors in Computing Systems},
articleno = {39},
numpages = {11},
keywords = {Covid-19, children interaction, learning at home, mobile game-based learning, pandemic, usability},
location = {Virtual Event, Brazil},
series = {IHC '21}
}

@inproceedings{10.1145/3019612.3019861,
author = {Preuveneers, Davy and Joosen, Wouter and Ilie-Zudor, Elisabeth},
title = {Identity management for cyber-physical production workflows and individualized manufacturing in industry 4.0},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019861},
doi = {10.1145/3019612.3019861},
abstract = {Industry 4.0 envisions a digital transformation in the enterprise, entwining the cyber-physical world and real world of manufacturing to deliver networked production with enhanced process transparency. Production systems, smart products, data analytics and business processes in the cloud will interact directly with customers to realize the ambitious goal of single lot individualized manufacturing. An immediate consequence of the paradigm shift is an increased risk for cyber-security breaches. This paper presents and evaluates the performance and scalability of an identity management solution for dataflow-oriented processes to guarantee the authenticity and trustworthy access of users, machines, products and business processes in Industry 4.0 production workflows that operate across the organizational boundaries of the enterprise.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {1452–1455},
numpages = {4},
keywords = {cyber-physical systems, factory of the future, identity management, networked production},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/3430895.3460128,
author = {Reza, Mohi and Kim, Juho and Bhattacharjee, Ananya and Rafferty, Anna N. and Williams, Joseph Jay},
title = {The MOOClet Framework: Unifying Experimentation, Dynamic Improvement, and Personalization in Online Courses},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460128},
doi = {10.1145/3430895.3460128},
abstract = {How can educational platforms be instrumented to accelerate the use of research to improve students' experiences? We show how modular components of any educational interface - e.g. explanations, homework problems, even emails - can be implemented using the novel MOOClet software architecture. Researchers and instructors can use these augmented MOOClet components for: (1) Iterative Cycles of Randomized Experiments that test alternative versions of course content; (2) Data-Driven Improvement using adaptive experiments that rapidly use data to give better versions of content to future students, on the order of days rather than months. A MOOClet supports both manual and automated improvement using reinforcement learning; (3) Personalization by delivering alternative versions as a function of data about a student's characteristics or subgroup, using both expert-authored rules and data mining algorithms. We provide an open-source web service for implementing MOOClets (www.mooclet.org) that has been used with thousands of students. The MOOClet framework provides an ecosystem that transforms online course components into collaborative micro-laboratories, where instructors, experimental researchers, and data mining/machine learning researchers can engage in perpetual cycles of experimentation, improvement, and personalization.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {15–26},
numpages = {12},
keywords = {A/B comparisons, dynamic improvement, education technology, massive open online courses, multi-armed bandits, personalization, randomized experiments},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1145/3430895.3460144,
author = {Cho, Ji Yong and Li, Yue and Armstrong, Anne K. and Russ, Alex and Krasny, Marianne E. and Kizilcec, Ren\'{e} F.},
title = {Using Social Norms to Promote Actions Beyond the Course},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460144},
doi = {10.1145/3430895.3460144},
abstract = {Educators and researchers in online education have grappled with not only how to increase course completion but also how to make a broader impact that goes beyond online courses, such as course participants' real-world applications of the learned knowledge and skills. Research in social psychology and behavioral science suggests that social norms interventions, which convey norms shared in the community that people belong in to promote desirable behaviors, can offer a low-cost and scalable approach to encourage actions beyond the courses (ABCs). We tested three social norm interventions that presented a weekly normative message (descriptive, dynamic, or injunctive norm) with aggregate information about course participants' ABCs in the prior week. Randomized experiments in three online courses found effects on ABCs to be weak and moderated by norm message type and the complexity of the target behavior. Although the interventions did not improve course completion, the dynamic norm message was more effective at promoting ABCs for complex behaviors, such as developing environmental education activities.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {161–172},
numpages = {12},
keywords = {behavior change, field experiments, intervention design, online learning, social norms},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1145/3159450.3159578,
author = {Gil Fonseca, Nuno and Macedo, Lu\'{\i}s and Mendes, Ant\'{o}nio Jos\'{e}},
title = {Supporting Differentiated Instruction in Programming Courses through Permanent Progress Monitoring},
year = {2018},
isbn = {9781450351034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159450.3159578},
doi = {10.1145/3159450.3159578},
abstract = {Several studies showed that teacher's support is essential to the students learning process. Often it is difficult for teachers to follow all their student's evolution and make timely interventions when needed. Often, in the same class, there are students with substantially different performance levels, and many times a teacher intervention is cructial to help lower performing students. To help the teacher identify these students, we propose the use of CodeInsights, a tool able to capture autonomously and unobtrusively real-time information about the students' performance based on snapshots of their code. The information available can be used by the teachers to support the adoption of the necessary measures to address each student needs or difficulties in a more grounded manner. We present the system and some results of a field test involving students from an introductory course on PHP programming.},
booktitle = {Proceedings of the 49th ACM Technical Symposium on Computer Science Education},
pages = {209–214},
numpages = {6},
keywords = {differentiated instruction, performance monitoring, programming, working pace},
location = {Baltimore, Maryland, USA},
series = {SIGCSE '18}
}

@proceedings{10.1145/3657604,
title = {L@S '24: Proceedings of the Eleventh ACM Conference on Learning @ Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the Proceedings of the Eleventh Annual ACM Conference on Learning at Scale, L@S 2024, held July 18-20, 2024 at Georgia Tech in Atlanta, Georgia, USA.The Learning at Scale conference was created by the Association for Computing Machinery (ACM), inspired by the emergence of Massive Open Online Courses (MOOCs) and the accompanying shift in thinking about education. During the last few years, new opportunities for scaling up learning have emerged, like hybrid learning environments combining online and face-to-face, and informal learning enabled by all sorts of platforms (e.g., gamified language learning, citizen science communities, and collaborative programming communities). In the recent two years, the unprecedented development of generative AI has brought profound opportunities to scale the teaching and learning experiences, with the goal of enhancing learning for the increasingly diverse group of learners in both formal and informal contexts. L@S has evolved along with these emergent massive learning scenarios and opportunities and is today one of the most prominent venues for discussion of the highest quality of research on how learning and teaching can be transformed at scale, in diverse learning environments.The theme of L@S 2024 is Scaling Learning in the Age of AI. Rapid advances in AI have created new opportunities but also challenges for the Learning@Scale community. The advances in generative AI show potential to enhance pedagogical practices and the efficacy of learning at scale. This has led to an unprecedented level of interest in employing generative AI for scaling tutoring and feedback. The prevalence of such tools calls for new practices and understanding on how AI-based methods should be designed and developed to enhance the experiences and outcomes of teachers and learners.Learning@Scale 2024 solicits empirical and theoretical papers on, but not limited to, the following topics (in no particular order): 1) Instruction at scale: studies that examine how teachers and educators scale their instructions, what aspects of instruction could be scaled effectively, and which of these instructional strategies are the most effective for learning. 2) Interventions at scale: studies that examine the effects of interventions on student learning and performance when implemented at scale. We welcome studies that use both qualitative and quantitative methods. 3) The use of generative AI to scale learning: studies that investigate stakeholders' experiences with generative AI, students' and teachers' interactions with generative AI, and the potentials and limitations of using generative AI in education. 4) Systems and tools to support learning at scale: research that designs and develops systems and tools to support learning at scale. For example, this involves scaling learning through web-based systems, MOOCs, visualization, intelligent tutoring systems, gamification, immersive techniques (AR/VR/MR), mobile technologies, tangible interfaces, and various other technologies. 5) The evaluation of existing learning at scale systems and online learning environments using but not limited to the above-mentioned technologies. 6) Methods and algorithms that model learner behavior: research that contributes methods, algorithms, and pipelines that process large student data to enhance learning at scale. 7) Scaling learning in informal contexts: studies that explore how people take advantage of online environments to pursue their interests informally. 8) Review and synthesis of existing literature related to learning at scale. 9) Empirical studies and interventions that address equity, trust, algorithmic transparency and explainability, fairness and bias when using AI in education. 10) Research that addresses accessibility in learning at scale contexts. 11) Design and deployment of learning at scale systems for learners from underrepresented groups.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3297662.3365787,
author = {Troiano, Ernesto and Soldatos, John and Polyviou, Ariana and Polyviou, Andreas and Mamelli, Alessandro and Drakoulis, Dimitris},
title = {Big Data Platform for Integrated Cyber and Physical Security of Critical Infrastructures for the Financial Sector: Critical Infrastructures as Cyber-Physical Systems},
year = {2020},
isbn = {9781450362382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297662.3365787},
doi = {10.1145/3297662.3365787},
abstract = {As critical infrastructures become more complex, sophisticated and digitally interconnected they are also more susceptible to cyber and physical security attacks. In order to mitigate the risks of such attacks, there is a need for securing them in an integrated way, which considers the simultaneous protection of their cyber and physical assets. In this paper we introduce a BigData platform that implements an integrated approach to securing and protecting critical infrastructures for the financial sector, by treating them as large scale cyber-physical systems. The main building blocks of the platform include an integrated security model that covers cyber and physical assets, an architecture for security monitoring and control based on appropriate probes, as well as a range of data analytics algorithms for detecting risks, vulnerabilities and threats. These building blocks are outlined in the paper, along with their deployment and use in a number of representative critical infrastructure protection use cases for the financial sector. One of the merits of our work is its reference character i.e. it can serve as a blueprint for developing and deploying systems for integrated cyber/physical security in various application areas.},
booktitle = {Proceedings of the 11th International Conference on Management of Digital EcoSystems},
pages = {262–269},
numpages = {8},
keywords = {Cyber Physical Systems, Cybersecurity, FINSTIX, Finance, Physical Security, STIX},
location = {Limassol, Cyprus},
series = {MEDES '19}
}

@inproceedings{10.1145/3293881.3295779,
author = {Luxton-Reilly, Andrew and Simon and Albluwi, Ibrahim and Becker, Brett A. and Giannakos, Michail and Kumar, Amruth N. and Ott, Linda and Paterson, James and Scott, Michael James and Sheard, Judy and Szabo, Claudia},
title = {Introductory programming: a systematic literature review},
year = {2018},
isbn = {9781450362238},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293881.3295779},
doi = {10.1145/3293881.3295779},
abstract = {As computing becomes a mainstream discipline embedded in the school curriculum and acts as an enabler for an increasing range of academic disciplines in higher education, the literature on introductory programming is growing. Although there have been several reviews that focus on specific aspects of introductory programming, there has been no broad overview of the literature exploring recent trends across the breadth of introductory programming.  This paper is the report of an ITiCSE working group that conducted a systematic review in order to gain an overview of the introductory programming literature. Partitioning the literature into papers addressing the student, teaching, the curriculum, and assessment, we explore trends, highlight advances in knowledge over the past 15 years, and indicate possible directions for future research.},
booktitle = {Proceedings Companion of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education},
pages = {55–106},
numpages = {52},
keywords = {CS1, ITiCSE working group, SLR, introductory programming, literature review, novice programming, overview, review, systematic literature review, systematic review},
location = {Larnaca, Cyprus},
series = {ITiCSE 2018 Companion}
}

@inproceedings{10.1145/3603555.3603561,
author = {Brandenburger, Jessica and M\"{o}tsch, Isabel and Janneck, Monique},
title = {Design Features of a Career Guidance Platform to Promote Intrinsically Motivated Use},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603555.3603561},
doi = {10.1145/3603555.3603561},
abstract = {Many career guidance platforms are information portals that have a strong text-based approach and are used in higher grades later in the career guidance process. As part of a research project (JOLanDA) aimed at improving the career orientation of young people, we are developing a gamified platform to support younger pupils (12 years and older) in career orientation also outside of school. In this paper, we report on a moderated usability test (n = 14) with junior experts (students) to gain initial insights on how to improve the platform, as well as results from school workshops (n = 197, grade 7-9) within three field phases. Due to the playful approach, narrative structure (interactive digital storytelling), and a novel interaction concept (scroll-activated animations), the platform seems to attract great interest and has the potential to foster intrinsic user motivation. Based on the results, we provide design recommendations for online learning environments.},
booktitle = {Proceedings of Mensch Und Computer 2023},
pages = {197–219},
numpages = {23},
keywords = {Career Guidance Platform, Digital Interactive Storytelling, Learning Platform, Motivation, Usability-Test, User Interface Design},
location = {Rapperswil, Switzerland},
series = {MuC '23}
}

@inproceedings{10.1145/3544548.3581211,
author = {Chauvergne, Edwige and Hachet, Martin and Prouzeau, Arnaud},
title = {User Onboarding in Virtual Reality: An Investigation of Current Practices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581211},
doi = {10.1145/3544548.3581211},
abstract = {Explaining to novice users how to interact in immersive VR applications may be challenging. This is in particular due to the fact that the learners are isolated from the real world, and they are asked to manipulate hardware and software objects they are not used to. Consequently, the onboarding phase, which consists in teaching the user how to interact with the application is particularly crucial. In this paper, we aim at giving a better understanding of current VR onboarding methods, their benefits and challenges. We performed 21 VR tutorial ergonomic reviews and 15 interviews with VR experts with experience in VR onboarding. Building on the results, we propose a conceptual framework for VR onboarding and discuss important research directions to explore the design of future efficient onboarding solutions adapted to VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {711},
numpages = {15},
keywords = {computer assisted, human assisted, learning, user onboarding, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@article{10.1145/3161172,
author = {Saquib, Nazmus and Bose, Ayesha and George, Dwyane and Kamvar, Sepandar},
title = {Sensei: Sensing Educational Interaction},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
url = {https://doi.org/10.1145/3161172},
doi = {10.1145/3161172},
abstract = {We present Sensei, the first system designed to understand social interaction and learning in an early-childhood classroom using a distributed sensor network. Our unobtrusive sensors measure proximity between each node in a dynamic range-based mesh network. The sensors can be worn in the shoes, attached to selected landmarks in the classroom, and placed on Montessori materials. This data, accessible to teachers in a web dashboard, enables teachers to derive deeper insights from their classrooms. Sensei is currently deployed in three Montessori schools and we have evaluated the effectiveness of the system with teachers. Our user studies have shown that the system enhances teachers' capabilities and helps discover insights that would have otherwise been lost. From our evaluation interviews, we have established three major use cases of the system. Sensei augments teachers' manual observations, helps them plan individualized curriculum for each student, and identifies their needs for more interaction with some children. Further, the anonymized data can be used in large-scale research in early childhood development.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {161},
numpages = {27},
keywords = {Data visualization, Education, Sensor networks}
}

@inproceedings{10.1145/2896387.2896421,
author = {Azhan, Mohd Hafriz Bin Nural and Saman, Md. Yazid Bin Mohd and Man, Mustafa Bin},
title = {A Framework for Collaborative Multi-Institution MOOC Environment},
year = {2016},
isbn = {9781450340632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896387.2896421},
doi = {10.1145/2896387.2896421},
abstract = {In e-Learning web applications, users interact directly via the web platforms with other users. The learning management system (LMS) is one web platform that has been used to manage the online teaching and learning (T&amp;L). Moodle is an open-sourced LMS that has a widespread adoption in several universities as a virtual learning environment. However, each university does not have any connection with another. Thus, it is difficult for students in one university to enroll in any readily available courses from another. The Malaysian Government has taken the lead to embark on the Massive Open Online Courseware (MOOC) for the Malaysian Public Universities (MPU). This will enable any student from any university to enroll in any courses available in any university. This paper describes a framework called ArmadaNet for a multi-institution collaborative MOOC platform. It covers technical and non-technical issues related to the MOOC implementation. The Moodle LMS has been chosen as the web platform to support this multi-institution MOOC collaboration. The development of ArmadaNet as the model for the collaboration will be given. It is a hub that connects and displays courses hosted in the MOOC. The progress of the implementation is given.},
booktitle = {Proceedings of the International Conference on Internet of Things and Cloud Computing},
articleno = {36},
numpages = {6},
keywords = {MOOC, Moodle Hub, Multi-institution Collaboration, e-Learning},
location = {Cambridge, United Kingdom},
series = {ICC '16}
}

@proceedings{10.1145/3549737,
title = {SETN '22: Proceedings of the 12th Hellenic Conference on Artificial Intelligence},
year = {2022},
isbn = {9781450395977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Corfu, Greece}
}

@inproceedings{10.1145/3242671.3242680,
author = {Charleer, Sven and Gerling, Kathrin and Guti\'{e}rrez, Francisco and Cauwenbergh, Hans and Luycx, Bram and Verbert, Katrien},
title = {Real-Time Dashboards to Support eSports Spectating},
year = {2018},
isbn = {9781450356244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242671.3242680},
doi = {10.1145/3242671.3242680},
abstract = {eSports matches offer fast-paced entertainment for millions of viewers worldwide, but little is known about how to support a positive viewer experience. One of the key challenges related to popular real-time eSports games (e.g., multiplayer online battle arena games or first-person shooters) is empowering viewers to effectively follow rapid gameplay. In our paper, we address this challenge through the design of information dashboards to improve spectator insight and experience in League of Legends, and Counter Strike: Global Offensive. Based on surveys that received a total of 788 responses, we design information dashboards that we evaluate with 18 experienced eSports viewers. Our results show that dashboards contribute to spectator insight and experience, but that careful consideration is necessary to adequately manage in-game complexity and cognitive load of viewers, and establish spectator trust in information dashboards through transparent design. Based on these findings, our paper formulates design goals for spectator dashboards, and outlines key opportunities for future work.},
booktitle = {Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play},
pages = {59–71},
numpages = {13},
keywords = {data visualisation, esports, spectator experience, video games},
location = {Melbourne, VIC, Australia},
series = {CHI PLAY '18}
}

@proceedings{10.1145/3697789,
title = {ICGJ '24: Proceedings of the 8th International Conference on Game Jams, Hackathons and Game Creation Events},
year = {2024},
isbn = {9798400717796},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3373625.3417029,
author = {Wen, Zikai Alex and Silverstein, Erica and Zhao, Yuhang and Amog, Anjelika Lynne and Garnett, Katherine and Azenkot, Shiri},
title = {Teacher Views of Math E-learning Tools for Students with Specific Learning Disabilities},
year = {2020},
isbn = {9781450371032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373625.3417029},
doi = {10.1145/3373625.3417029},
abstract = {Many students with specific learning disabilities (SLDs) have difficulty learning math. To succeed in math, they need to receive personalized support from teachers. Recently, math e-learning tools that provide personalized math skills training have gained popularity. However, we know little about how well these tools help teachers personalize instruction for students with SLDs. To answer this question, we conducted semi-structured interviews with 12 teachers who taught students with SLDs in grades five to eight. We found that participants used math e-learning tools that were not designed specifically for students with SLDs. Participants had difficulty using these tools because of text-intensive user interfaces, insufficient feedback about student performance, inability to adjust difficulty levels, and problems with setup and maintenance. Participants also needed assistive technology for their students, but they had challenges in getting and using it. From our findings, we distilled design implications to help shape the design of more inclusive and effective e-learning tools.},
booktitle = {Proceedings of the 22nd International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {44},
numpages = {13},
keywords = {Assistive Technology, Educational Technology, K-12 Education, Special Education},
location = {Virtual Event, Greece},
series = {ASSETS '20}
}

@article{10.1145/3505245,
author = {Gruetzemacher, Ross and Paradice, David},
title = {Deep Transfer Learning &amp; Beyond: Transformer Language Models in Information Systems Research},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {10s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3505245},
doi = {10.1145/3505245},
abstract = {AI is widely thought to be poised to transform business, yet current perceptions of the scope of this transformation may be myopic. Recent progress in natural language processing involving transformer language models (TLMs) offers a potential avenue for AI-driven business and societal transformation that is beyond the scope of what most currently foresee. We review this recent progress as well as recent literature utilizing text mining in top IS journals to develop an outline for how future IS research can benefit from these new techniques. Our review of existing IS literature reveals that suboptimal text mining techniques are prevalent and that the more advanced TLMs could be applied to enhance and increase IS research involving text data, and to enable new IS research topics, thus creating more value for the research community. This is possible because these techniques make it easier to develop very powerful custom systems and their performance is superior to existing methods for a wide range of tasks and applications. Further, multilingual language models make possible higher quality text analytics for research in multiple languages. We also identify new avenues for IS research, like language user interfaces, that may offer even greater potential for future IS research.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {204},
numpages = {35},
keywords = {Natural language processing, text mining, artificial intelligence, deep learning, transfer learning, language models}
}

@proceedings{10.1145/3592571,
title = {ICDAR '23: Proceedings of the 4th ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
year = {2023},
isbn = {9798400701863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Thessaloniki, Greece}
}

@proceedings{10.1145/3630970,
title = {CLIHC '23: Proceedings of the XI Latin American Conference on Human Computer Interaction},
year = {2023},
isbn = {9798400716577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Puebla, Mexico}
}

@proceedings{10.1145/3536220,
title = {ICMI '22 Companion: Companion Publication of the 2022 International Conference on Multimodal Interaction},
year = {2022},
isbn = {9781450393898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bengaluru, India}
}

@proceedings{10.1145/2993352,
title = {SA '16: SIGGRAPH ASIA 2016 Symposium on Education},
year = {2016},
isbn = {9781450345446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SIGGRAPH Asia Symposium on Education program will be inviting experts from both academia and the industry to present innovative research, methods and positions about the teaching and integration of computer graphics and interactive techniques in all areas of learning.This year's main conference theme is "Key to the Future." Education is the key to our future, and we view education as a natural part of the lifelong learning process. We wish to support the evolving integration of art and technology embraced by educators.As an international gathering of industry professionals and academics, the Symposium on Education will present perspectives that appeal to a wide spectrum of interests. We will share educational strategies adopted in both industry and academia to make the learning process more satisfying, productive, and meaningful.},
location = {Macau}
}

@proceedings{10.1145/3606150,
title = {ICFET '23: Proceedings of the 2023 9th International Conference on Frontiers of Educational Technologies},
year = {2023},
isbn = {9798400707353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bali, Indonesia}
}

@proceedings{10.1145/3724504,
title = {ICIEAI '24: Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
year = {2024},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3716554,
title = {PCI '24: Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
year = {2024},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3578837,
title = {ICEEL '22: Proceedings of the 2022 6th International Conference on Education and E-Learning},
year = {2022},
isbn = {9781450398428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yamanashi, Japan}
}

@inproceedings{10.1145/2538862.2538935,
author = {Zheeng, Guangzhi and Zhang, Chi and Li, Lei},
title = {Bringing business intelligence to healthcare informatics curriculum: a preliminary investigation},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2538935},
doi = {10.1145/2538862.2538935},
abstract = {Business intelligence (BI) and healthcare analytics are emerging technologies that provide analytical capability to help healthcare industry improve service quality, reduce cost, and manage risks. However, such component on analytical healthcare data processing is largely missed from current healthcare information technology (HIT) or health informatics (HI) curricula. This paper conducts a preliminary analysis on how healthcare business intelligence can be incorporated into a HIT program. A general framework and several exemplar implementation strategies are presented. They can be used to guide the development and improvement of HIT curriculum.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {205–210},
numpages = {6},
keywords = {business intelligence, curriculum development, health informatics, health information technology, healthcare business intelligence},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@article{10.1145/3328924,
author = {Lachand, Valentin and Michel, Christine and Tabard, Aur\'{e}lien},
title = {Toccata: Supporting Classroom Orchestration with Activity Based Computing},
year = {2019},
issue_date = {June 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/3328924},
doi = {10.1145/3328924},
abstract = {We present Toccata, a system that facilitates the management of rich multi-device pedagogical activities. Through interviews with high school teachers, we identified a set of barriers to conducting digital activities in schools: set-up time, network problems, difficulties in following and changing plans as activities unfold. We designed and developed Toccata to support the planning of pedagogical activities (scripting), seamless sharing of content and collaboration across people and devices, live management of activities in the classroom, roaming for situations outside classrooms, resumption across sessions, and resilience to unstable network conditions. We deployed Toccata in three classes, over seven teaching sessions, involving a total of 69 students. Together, these deployments show that Toccata is a generic solution for managing multi-device activities in schools. We reflect on how Activity Based Computing principles support Orchestration in Toccata, and discuss the design opportunities it creates such as better awareness of learners' activity, micro-orchestration techniques for enabling teachers to better control devices in classrooms, or supporting reflective practices of teachers.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {53},
numpages = {24}
}

@proceedings{10.1145/3643655,
title = {SESoS '24: Proceedings of the 12th ACM/IEEE International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
year = {2024},
isbn = {9798400705571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SESoS 2024 will provide a forum for researchers and practitioners with a forum to exchange ideas and experiences, analyze research and development issues, discuss promising solutions, and propose theoretical foundations for the development and evolution of complex software-intensive systems.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1109/ICSE-SEET.2017.7,
author = {Zhang, Yang and Zhang, Tingjian and Jia, Yongzheng and Sun, Jiao and Xu, Fangzhou and Xu, Wei},
title = {DataLab: introducing software engineering thinking into data science education at scale},
year = {2017},
isbn = {9781538626719},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET.2017.7},
doi = {10.1109/ICSE-SEET.2017.7},
abstract = {Data science education is a new area in computer science that has attracted increasing attention in recent years. However, currently, data science educators lack good tools and methodologies. In particular, they lack integrated tools through which their students can acquire hands-on software engineering experience. To address these problems, we designed and implemented DataLab, a web-based tool for data science education that integrates code, data and execution management into one system. The goal of DataLab is to provide a hands-on online lab environment to train students to have basic software engineering thinking and habits while maintaining a focus on the core data science contents. In this paper, we present the user-experience design and system-level implementation of DataLab. Further, we evaluate DataLab's performance through an in-classroom use case. Finally, using objective log-based learning behavior analysis and a subjective survey, we demonstrate DataLab's effectiveness.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track},
pages = {47–56},
numpages = {10},
location = {Buenos Aires, Argentina},
series = {ICSE-SEET '17}
}

@proceedings{10.1145/3699538,
title = {Koli Calling '24: Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3568364,
title = {WSSE '22: Proceedings of the 4th World Symposium on Software Engineering},
year = {2022},
isbn = {9781450396950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3661904,
title = {ICETT '24: Proceedings of the 2024 10th International Conference on Education and Training Technologies},
year = {2024},
isbn = {9798400717895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/3635059,
title = {PCI '23: Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
year = {2023},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lamia, Greece}
}

@proceedings{10.1145/3572549,
title = {ICETC '22: Proceedings of the 14th International Conference on Education Technology and Computers},
year = {2022},
isbn = {9781450397766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@proceedings{10.1145/3702163,
title = {ICETC '24: Proceedings of the 2024 16th International Conference on Education Technology and Computers},
year = {2024},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3649217,
title = {ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 29th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2024), hosted by Universit\`{a} degli Studi di Milano in Milan, Italy.ITiCSE 2024 will take place from Friday July 5 to Wednesday July 10. The conference program includes a keynote address, paper sessions, a panel, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet July 5-7 and will submit draft reports before the conference begins on July 8.The submissions to ITiCSE 2024 were reviewed by 446 researchers and practitioners from computing education and related fields, including 44 program committee members and 402 reviewers. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.},
location = {Milan, Italy}
}

@article{10.1145/3218284,
author = {Billingsley, William and Torbay, Rosemary and Fletcher, Peter R. and Thomas, Richard N. and Steel, Jim R. H. and S\"{u}\ss{}, J\"{o}rn Guy},
title = {Taking a Studio Course in Distributed Software Engineering from a Large Local Cohort to a Small Global Cohort},
year = {2019},
issue_date = {June 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
url = {https://doi.org/10.1145/3218284},
doi = {10.1145/3218284},
abstract = {One of the challenges of global software engineering courses is to bring the practices and experience of large geographically distributed teams into the local and time-limited environment of a classroom. Over the last 6 years, an on-campus studio course for software engineering has been developed at the University of Queensland (UQ) that places small teams of students on different features of a common product. This creates two layers of collaboration, as students work within their teams on individual features, and the teams must interoperate with many other teams on the common product. The class uses continuous integration practices and predominantly asynchronous communication channels (Slack and GitHub) to facilitate this collaboration. The original goal of this design was to ensure that students would authentically experience issues associated with realistically sized software projects, and learn to apply appropriate software engineering and collaboration practices to overcome them, in a course without significant extra staffing. Data from the development logs showed that most commits take place outside synchronous class hours, and the project operates as a temporally distributed team even though the students are geographically co-located. Since 2015, a course adapted from this format has also been taught at the University of New England (UNE), an Australian regional university that is also a longstanding provider of distance education. In this course, most students study online, and the class has to be able to work globally, because as well as students taking part from around Australia, there are also typically a small number of students taking part from overseas. Transferring the course to a smaller but predominantly online institution has allowed us to evaluate the distributed nature of the course, by considering what aspects of the course needed to change to support students who are geographically distributed, and comparing how the two cohorts behave. This has produced an overall course design, to teach professional distributed software engineering practices, that is adaptable from large classes to small, and from local to global.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {13},
numpages = {27},
keywords = {Global software engineering, studio pedagogies}
}

@proceedings{10.1145/3702386,
title = {ICAITE '24: Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
year = {2024},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/2556325.2566237,
author = {Kim, Juho and Guo, Philip J. and Seaton, Daniel T. and Mitros, Piotr and Gajos, Krzysztof Z. and Miller, Robert C.},
title = {Understanding in-video dropouts and interaction peaks inonline lecture videos},
year = {2014},
isbn = {9781450326698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556325.2566237},
doi = {10.1145/2556325.2566237},
abstract = {With thousands of learners watching the same online lecture videos, analyzing video watching patterns provides a unique opportunity to understand how students learn with videos. This paper reports a large-scale analysis of in-video dropout and peaks in viewership and student activity, using second-by-second user interaction data from 862 videos in four Massive Open Online Courses (MOOCs) on edX. We find higher dropout rates in longer videos, re-watching sessions (vs first-time), and tutorials (vs lectures). Peaks in re-watching sessions and play events indicate points of interest and confusion. Results show that tutorials (vs lectures) and re-watching sessions (vs first-time) lead to more frequent and sharper peaks. In attempting to reason why peaks occur by sampling 80 videos, we observe that 61% of the peaks accompany visual transitions in the video, e.g., a slide view to a classroom view. Based on this observation, we identify five student activity patterns that can explain peaks: starting from the beginning of a new material, returning to missed content, following a tutorial step, replaying a brief segment, and repeating a non-visual explanation. Our analysis has design implications for video authoring, editing, and interface design, providing a richer understanding of video learning on MOOCs.},
booktitle = {Proceedings of the First ACM Conference on Learning @ Scale Conference},
pages = {31–40},
numpages = {10},
keywords = {in-video dropout, interaction peaks, mooc, online education, peak detection., video analysis},
location = {Atlanta, Georgia, USA},
series = {L@S '14}
}

@inproceedings{10.1145/2379057.2379107,
author = {Schmidt, Benedikt and Doeweling, Sebastian and M\"{u}hlh\"{a}user, Max},
title = {Interaction history visualization},
year = {2012},
isbn = {9781450314978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2379057.2379107},
doi = {10.1145/2379057.2379107},
abstract = {Interaction histories have been identified as a promising direction to support information workers in the execution of their work processes. However, to increase the workers' awareness about the structure of their work and to help them with the execution of their work processes, a suitable visualization is necessary. Up to now, interaction histories have typically been visualized with the classical Gantt, bar or line charts, neglecting the information contained in links between the individual items in an interaction history. Moreover, clear and empirically grounded guidance for the choice of the visualization is currently lacking. We present two graph-based visualizations for interaction histories and evaluate them against the classical visualizations in a controlled experiment. From the results, we derive a set of recommendations for the visualizations best suited for the different tasks within information workers' work processes.},
booktitle = {Proceedings of the 30th ACM International Conference on Design of Communication},
pages = {261–270},
numpages = {10},
keywords = {human-computer interaction, information work support, interaction history, task execution support, visualization},
location = {Seattle, Washington, USA},
series = {SIGDOC '12}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3608218,
title = {ICBDE '23: Proceedings of the 2023 6th International Conference on Big Data and Education},
year = {2023},
isbn = {9798400708220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jinan, China}
}

@proceedings{10.1145/3708394,
title = {AIFE '24: Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
year = {2024},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/2729094,
title = {ITiCSE '15: Proceedings of the 2015 ACM Conference on Innovation and Technology in Computer Science Education},
year = {2015},
isbn = {9781450334402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to ITiCSE 2015 in Vilnius!The ITiCSE conference celebrates its 20th anniversary in Vilnius, the capital of Lithuania and the geographical center of Europe, so declared in 1989 by scientists of the French National Institute of Geography.ITiCSE will be held on July 6--8, starting on Lithuania's Statehood Day (July 6). This is an annual public holiday that commemorates the coronation in 1253 of Mindaugas as the first and only King of Lithuania. The conference venue is the Parliament buildings (Seimas) of the Republic of Lithuania, and the conference dinner is to served in the reconstructed Palace of the Grand Dukes of Lithuania, one of the most famous in Europe in the 15--17th centuries. ITiCSE 2015 is hosted by Vilnius University, one of the oldest and most famous establishments of higher education in Eastern and Central Europe, founded in 1579. The conference organizers represent the Lithuanian research group of Informatics and Informatics Engineering Didactics at the Institute of Mathematics and Informatics of Vilnius University.This conference brings together delegates from all over the world to address pressing issues in computing education. In addition to invited lectures, papers, panels, posters, and tips, techniques &amp; courseware sessions, the conference provides facilities and exposure for working groups and exhibitions.The conference continues to be truly international with a total of 170 submissions from 40 countries on six continents, with authors from Africa (4), Asia (50), Europe (151), North America (119), Oceania (51), and South America (17). These submissions consisted of 124 research papers, 1 panel, 9 working group proposals, and 36 proposals for posters or for tips, techniques &amp; courseware.All research papers were double blind reviewed by at least four reviewers, though most papers received five or six reviews. A meta-review was conducted by the members of the conference committee to ensure the reliability of the reviews and to make recommendations to the chairs. A final selection phase was conducted by the program chairs who reviewed all reviews and meta-review recommendations before making their final decisions. As a result of this process, 54 research papers (43.5%) were selected for presentation and inclusion in the proceedings. The authors of the accepted papers come from 17 different countries on five continents.All poster submissions were blind reviewed by two members of the conference committee, and tips, techniques &amp; courseware submissions were blind reviewed by three members of the conference committee. Submissions in these categories were then reviewed by the conference chair before selection by the program chairs for final inclusion in the conference. Twenty-four were accepted, representing authors from 15 countries.The two keynote speakers address the learning of programming and computational thinking. Professor Mordechai (Moti) Ben-Ari from the Weizmann Institute of Science, Israel, will give a talk titled In Defense of Programming, which defends the (perhaps controversial) position that programming is the fundamental activity of CS. In the other keynote talk Professor Maciej M. Syslo from Nicolaus Copernicus University and University of Wroc\l{}aw, Poland, will address algorithmic nand computational thinking as the way to computing for all students.ITiCSE is famous for its working groups. Participating in a working group provides a unique opportunity to work with people from different countries who are interested and knowledgeable in the area of the working group. It is also one of the best ways to become part of the ITiCSE community. Seven working groups have been accepted over a broad spectrum of topics. The working groups range from general topics, such as computing education terminology, CS education in K-9 and K-12 schools, and designing an IT curriculum framework for graduates in 2025, to more specific topics such as developing a repository for high school CS questions, visual assessment tools and metadata annotations, and how students construct solutions to programming problems. The leaders of the accepted working groups come from over 13 countries.Welcome to Vilnius and enjoy the vicennial ITiCSE conference and Lithuania's Statehood Day!},
location = {Vilnius, Lithuania}
}

@proceedings{10.1145/3604571,
title = {Asian CHI '23: Proceedings of the Asian HCI Symposium 2023},
year = {2023},
isbn = {9798400707612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Online, Indonesia}
}

@proceedings{10.1145/3633083,
title = {HCAIep '23: Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dublin, Ireland}
}

@proceedings{10.1145/3594781,
title = {LDT '23: Proceedings of the 2023 Symposium on Learning, Design and Technology},
year = {2023},
isbn = {9798400707360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Evanston, IL, USA}
}

@proceedings{10.1145/3660043,
title = {ICIEAI '23: Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
year = {2023},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3564721,
title = {Koli Calling '22: Proceedings of the 22nd Koli Calling International Conference on Computing Education Research},
year = {2022},
isbn = {9781450396165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Koli, Finland}
}

@proceedings{10.1145/3513130,
title = {SIGDOC '22: Proceedings of the 40th ACM International Conference on Design of Communication},
year = {2022},
isbn = {9781450392464},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@proceedings{10.1145/3626253,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@inbook{10.1145/3233795.3233809,
author = {Schnelle-Walka, Dirk and Radomski, Stefan},
title = {Automotive multimodal human-machine interface},
year = {2019},
isbn = {9781970001754},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3233795.3233809},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Language Processing, Software, Commercialization, and Emerging Directions},
pages = {477–522},
numpages = {46}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3535735,
title = {ICIEI '22: Proceedings of the 7th International Conference on Information and Education Innovations},
year = {2022},
isbn = {9781450396196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Belgrade, Serbia}
}

@proceedings{10.1145/3654522,
title = {ICIIT '24: Proceedings of the 2024 9th International Conference on Intelligent Information Technology},
year = {2024},
isbn = {9798400716713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ho Chi Minh City, Vietnam}
}

@proceedings{10.1145/3716640,
title = {ACE '25: Proceedings of the 27th Australasian Computing Education Conference},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3617733,
title = {ICCCM '23: Proceedings of the 2023 11th International Conference on Computer and Communications Management},
year = {2023},
isbn = {9798400707735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@proceedings{10.1145/3613905,
title = {CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3678726,
title = {ICEMT '24: Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3585088,
title = {IDC '23: Proceedings of the 22nd Annual ACM Interaction Design and Children Conference},
year = {2023},
isbn = {9798400701313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chicago, IL, USA}
}

@proceedings{10.1145/3663433,
title = {LDT '24: Proceedings of the 2024 Symposium on Learning, Design and Technology},
year = {2024},
isbn = {9798400717222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Delft, Netherlands}
}

@proceedings{10.1145/3524458,
title = {GoodIT '22: Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Limassol, Cyprus}
}

@proceedings{10.1145/3627217,
title = {COMPUTE '23: Proceedings of the 16th Annual ACM India Compute Conference},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hyderabad, India}
}

@proceedings{10.1145/3658549,
title = {I-DO '24: Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Taipei, Taiwan}
}

@proceedings{10.1145/3641555,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@proceedings{10.1145/3654777,
title = {UIST '24: Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Pittsburgh, PA, USA}
}

@proceedings{10.1145/3565472,
title = {UMAP '23: Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization},
year = {2023},
isbn = {9781450399326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Limassol, Cyprus}
}

@proceedings{10.1145/3536221,
title = {ICMI '22: Proceedings of the 2022 International Conference on Multimodal Interaction},
year = {2022},
isbn = {9781450393904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bengaluru, India}
}

@inbook{10.1145/3233795.3233812,
author = {Cohen, Philip R. and Tumuluri, Raj},
title = {Commercialization of multimodal systems},
year = {2019},
isbn = {9781970001754},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3233795.3233812},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Language Processing, Software, Commercialization, and Emerging Directions},
pages = {621–658},
numpages = {38}
}

@proceedings{10.1145/3649902,
title = {ETRA '24: Proceedings of the 2024 Symposium on Eye Tracking Research and Applications},
year = {2024},
isbn = {9798400706073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Glasgow, United Kingdom}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3708359,
title = {IUI '25: Proceedings of the 30th International Conference on Intelligent User Interfaces},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3634814,
title = {ASSE '23: Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
year = {2023},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Aizu-Wakamatsu City, Japan}
}

@proceedings{10.1145/3581754,
title = {IUI '23 Companion: Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3631802,
title = {Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
year = {2023},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Koli, Finland}
}

@proceedings{10.1145/3670653,
title = {MuC '24: Proceedings of Mensch und Computer 2024},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Karlsruhe, Germany}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@proceedings{10.1145/3638067,
title = {IHC '23: Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
year = {2023},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@proceedings{10.1145/3569951,
title = {PEARC '23: Practice and Experience in Advanced Research Computing 2023: Computing for the Common Good},
year = {2023},
isbn = {9781450399852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Portland, OR, USA}
}

@proceedings{10.1145/3638380,
title = {OzCHI '23: Proceedings of the 35th Australian Computer-Human Interaction Conference},
year = {2023},
isbn = {9798400717079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wellington, New Zealand}
}

@proceedings{10.1145/3641554,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@proceedings{10.1145/3625704,
title = {ICEMT '23: Proceedings of the 7th International Conference on Education and Multimedia Technology},
year = {2023},
isbn = {9798400709142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3544793,
title = {UbiComp/ISWC '22 Adjunct: Adjunct Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers},
year = {2022},
isbn = {9781450394239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cambridge, United Kingdom}
}

@proceedings{10.1145/3702038,
title = {IHC '24: Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3649165,
title = {SIGCSE Virtual 2024: Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of SIGCSE Virtual 2024 Steering, Organization, and Program Committees, we would like to welcome you to this wonderful event. SIGCSE Virtual 2024, 1st ACM Virtual Global Computing Education Conference is now a reality after over a year of work by all the committee members. We like to send our special thanks to the SIGCSE Board and ACM for their continued support, encouragement and facilitation.One of the major goals of SIGCSE Virtual is to promote an inclusive and easily accessible conference to all interested in CS education research and practice. The hope is to allow those who are not able to easily travel to SIGCSE conferences to participate virtually from around the world. For this reason, the core of the conference follows all other SIGCSE conferences by providing papers, panels, posters/lightning talks, working groups, and doctoral consortium sessions dedicated to CS education research and practice.The conference has different themes based on the global aspects of CS education while considering regional circumstances. The sessions are offered considering time-zone constraints. The online program adjusts to time zones.Several different activities are provided besides the technical sessions by conference sponsors as well as for social engagements. All these activities are included in the program.},
location = {Virtual Event, NC, USA}
}

@proceedings{10.1145/3572921,
title = {OzCHI '22: Proceedings of the 34th Australian Conference on Human-Computer Interaction},
year = {2022},
isbn = {9798400700248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Canberra, ACT, Australia}
}

@proceedings{10.1145/3546155,
title = {NordiCHI '22: Nordic Human-Computer Interaction Conference},
year = {2022},
isbn = {9781450396998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Aarhus, Denmark}
}

@proceedings{10.1145/3647722,
title = {ICSIM '24: Proceedings of the 2024 7th International Conference on Software Engineering and Information Management},
year = {2024},
isbn = {9798400709197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Suva, Fiji}
}

@proceedings{10.1145/3644523,
title = {ICCSMT '23: Proceedings of the 2023 4th International Conference on Computer Science and Management Technology},
year = {2023},
isbn = {9798400709517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3581641,
title = {IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3640543,
title = {IUI '24: Proceedings of the 29th International Conference on Intelligent User Interfaces},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Greenville, SC, USA}
}

@proceedings{10.1145/3647444,
title = {ICIMMI '23: Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence},
year = {2023},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@proceedings{10.1145/3614321,
title = {ICEGOV '23: Proceedings of the 16th International Conference on Theory and Practice of Electronic Governance},
year = {2023},
isbn = {9798400707421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Belo Horizonte, Brazil}
}

@proceedings{10.1145/3664476,
title = {ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@proceedings{10.1145/3628516,
title = {IDC '24: Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Delft, Netherlands}
}

@proceedings{10.1145/3681716,
title = {Mindtrek '24: Proceedings of the 27th International Academic Mindtrek Conference},
year = {2024},
isbn = {9798400718236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tampere, Finland}
}

@proceedings{10.1145/3656650,
title = {AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.},
location = {Arenzano, Genoa, Italy}
}

@book{10.1145/3233795,
editor = {Oviatt, Sharon and Schuller, Bj\"{o}rn and Cohen, Philip R. and Sonntag, Daniel and Potamianos, Gerasimos and Kr\"{u}ger, Antonio},
title = {The Handbook of Multimodal-Multisensor Interfaces: Language Processing, Software, Commercialization, and Emerging Directions},
year = {2019},
isbn = {9781970001754},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
abstract = {The Handbook of Multimodal-Multisensor Interfaces provides the first authoritative resource on what has become the dominant paradigm for new computer interfaces---user input involving new media (speech, multi-touch, hand and body gestures, facial expressions, writing) embedded in multimodal-multisensor interfaces.This three-volume handbook is written by international experts and pioneers in the field. It provides a textbook, reference, and technology roadmap for professionals working in this and related areas.This third volume focuses on state-of-the-art multimodal language and dialogue processing, including semantic integration of modalities. The development of increasingly expressive embodied agents and robots has become an active test-bed for coordinating multimodal dialogue input and output, including processing of language and nonverbal communication. In addition, major application areas are featured for commercializing multimodal-multisensor systems, including automotive, robotic, manufacturing, machine translation, banking, communications, and others. These systems rely heavily on software tools, data resources, and international standards to facilitate their development. For insights into the future, emerging multimodal-multisensor technology trends are highlighted for medicine, robotics, interaction with smart spaces, and similar topics. Finally, this volume discusses the societal impact of more widespread adoption of these systems, such as privacy risks and how to mitigate them. The handbook chapters provide a number of walk-through examples of system design and processing, information on practical resources for developing and evaluating new systems, and terminology and tutorial support for mastering this emerging field. In the final section of this volume, experts exchange views on a timely and controversial challenge topic, and how they believe multimodal-multisensor interfaces need to be equipped to most effectively advance human performance during the next decade.}
}

@proceedings{10.1145/3671151,
title = {CIBDA '24: Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3671127,
title = {BuildSys '24: Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3583961,
title = {IHM '23: Proceedings of the 34th Conference on l'Interaction Humain-Machine},
year = {2023},
isbn = {9781450398244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {TROYES, France}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3599640,
title = {ICETT '23: Proceedings of the 9th International Conference on Education and Training Technologies},
year = {2023},
isbn = {9781450399593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/3592813,
title = {SBSI '23: Proceedings of the XIX Brazilian Symposium on Information Systems},
year = {2023},
isbn = {9798400707599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@proceedings{10.1145/3626252,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@proceedings{10.1145/3625008,
title = {SVR '23: Proceedings of the 25th Symposium on Virtual and Augmented Reality},
year = {2023},
isbn = {9798400709432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio Grande, Brazil}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3603555,
title = {MuC '23: Proceedings of Mensch und Computer 2023},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rapperswil, Switzerland}
}

@proceedings{10.1145/2993148,
title = {ICMI '16: Proceedings of the 18th ACM International Conference on Multimodal Interaction},
year = {2016},
isbn = {9781450345569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3660853,
title = {AICCONF '24: Proceedings of the Cognitive Models and Artificial Intelligence Conference},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {undefinedstanbul, Turkiye}
}

@proceedings{10.1145/3577190,
title = {ICMI '23: Proceedings of the 25th International Conference on Multimodal Interaction},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Paris, France}
}

@proceedings{10.1145/3630106,
title = {FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio de Janeiro, Brazil}
}

@proceedings{10.1145/3616961,
title = {Mindtrek '23: Proceedings of the 26th International Academic Mindtrek Conference},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tampere, Finland}
}

@proceedings{10.1145/3606094,
title = {ICDEL '23: Proceedings of the 2023 8th International Conference on Distance Education and Learning},
year = {2023},
isbn = {9798400700422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3672758,
title = {CAICE '24: Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi' an, China}
}

@proceedings{10.1145/3590837,
title = {ICIMMI '22: Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
year = {2022},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@proceedings{10.1145/3723936,
title = {ICSTPA '24: Proceedings of the 2024 International Conference on Sports Technology and Performance Analysis},
year = {2024},
isbn = {9798400712234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3411763,
title = {CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3544549,
title = {CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3594739,
title = {UbiComp/ISWC '23 Adjunct: Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing &amp; the 2023 ACM International Symposium on Wearable Computing},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cancun, Quintana Roo, Mexico}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3487553,
title = {WWW '22: Companion Proceedings of the Web Conference 2022},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Lyon, France}
}

@proceedings{10.1145/3542929,
title = {SoCC '22: Proceedings of the 13th Symposium on Cloud Computing},
year = {2022},
isbn = {9781450394147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SoCC 2022 is the thirteenth annual ACMSymposium on Cloud Computing, the premier conference on cloud computing. It brings together researchers, software developers, end-users, and practitioners interested in wide-ranging aspects of cloud computing, and it is the only conference co-sponsored by the ACM Special Interest Groups on Management of Data (SIGMOD) and on Operating Systems (SIGOPS).},
location = {San Francisco, California}
}

@proceedings{10.1145/3677182,
title = {ASENS '24: Proceedings of the International Conference on Algorithms, Software Engineering, and Network Security},
year = {2024},
isbn = {9798400709784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@proceedings{10.1145/3644713,
title = {ICFNDS '23: Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
year = {2023},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dubai, United Arab Emirates}
}

@proceedings{10.1145/3652583,
title = {ICMR '24: Proceedings of the 2024 International Conference on Multimedia Retrieval},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to present the 2024 edition of the ACM International Conference on Multimedia Retrieval, ACM ICMR 2024, that took place from 10-14 June 2024, in Phuket, Thailand.Effectively and efficiently retrieving information from multimedia collections (e.g., text, image, video, audio, sensor data, 3D) based on user needs is one of the most exciting areas in multimedia research. The Annual ACM International Conference on Multimedia Retrieval (ICMR) offers a great opportunity for exchanging leading-edge multimedia retrieval ideas among researchers, practitioners, and other potential users of multimedia retrieval systems. ACM ICMR was created in 2011 in a merger of ACM CIVR (International Conference on Image and Video Retrieval) and ACM MIR (International Conference on Multimedia Information Retrieval). ACM ICMR serves to illuminate the state of the art in multimedia retrieval. ACM ICMR 2024 in Phuket follows the successful previous editions of ICMR in Trento, Italy 2011; Hong Kong, China 2012; Dallas, USA 2013; Glasgow, UK 2014; Shanghai, China 2015; New York, USA 2016; Bucharest, Romania 2017; Yokohama, Japan 2018; Ottawa, Canada 2019; Dublin, Ireland 2020 (online); Taipei, Taiwan 2021 (online); Newark, USA 2022 (hybrid); and Thessaloniki, Greece 2023 (hybrid).},
location = {Phuket, Thailand}
}

@proceedings{10.1145/3593013,
title = {FAccT '23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chicago, IL, USA}
}

@proceedings{10.1145/3573428,
title = {EITCE '22: Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
year = {2022},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3308558,
title = {WWW '19: The World Wide Web Conference},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, CA, USA}
}

