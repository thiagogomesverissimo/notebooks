@INPROCEEDINGS{9853797,
  author={Ong, Shuoh-Chwen and Chua, Fang-Fang},
  booktitle={2022 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={ChemistLab: An Educational Game with Learning Analytics Dashboard}, 
  year={2022},
  volume={},
  number={},
  pages={101-103},
  abstract={Educational games are games explicitly designed with educational purposes and aims to balance learning and playing. These educational games help people to learn and improve as they play. However, there is a lack of gameplay monitoring process whereby the real-time information of game progress is not being reflected. Most of the existing educational games do not consolidate with learning analytics dashboards which leads to no visualization of gameplay information and inadequate gameplay analysis. When players have information on how to improve their performance, they will be encouraged to revisit the game. Hence, an educational game with learning analytics dashboard, ChemistLab, is developed for learners to learn chemistry. The dashboard will visualize the performance and skills changes overtime which reflect the players’ learning patterns and strategies used to improve their performance for better learning. The learning content of the game is extracted from the Malaysia Upper Secondary Education (Form 4) Chemistry syllabus. The expected output of the game is to allow users to observe their gameplay performance through the dashboard and gaining new knowledge through the game with the achievement of learning objectives.},
  keywords={Chemistry;Education;Games;Predictive models;Real-time systems;Data models;Chemical elements;Educational game;Gaming analytics;Learning analytics;Analytics dashboard;Chemistry},
  doi={10.1109/ICALT55010.2022.00038},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9766808,
  author={Kodumuru, Saketh and Lucas, Brendan and Sabanwar, Vivek and Patil, Sachin and Avudiappan, Deepa and Parikh, Parth and Arya, Kavi},
  booktitle={2022 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Towards developing a learning analytics dashboard for a massive online robotics competition}, 
  year={2022},
  volume={},
  number={},
  pages={1020-1025},
  abstract={A Learning Analytics Dashboard is a quick and efficient way for instructors to track the activities of students. In massive online learning scenarios like an international robotics competition, a dashboard is a critical tool for instructors to ensure continuous engagement of participants. Previous research on learning analytics dashboards focused on the effectiveness of dashboards and learning analytics on students along with factors affecting its success. This research discusses a dashboard developed for a massive robotics competition through which each year thousands of students are trained in engineering skills in an online Project Based Learning approach. The dashboard is developed using the dataset for the competition conducted during September 2020 to April 2021 in which more than 10,000 undergraduate students from 572 academic institutions across 7 countries participated. Team characteristics like demographics, feedback, scores, online activity, etc. are considered to cluster teams and develop models to predict the retention of participants. The Machine Learning (ML) model was able to achieve an accuracy of 80.7% and a recall value of 83.9% to identify dropping teams. Clustering provided insights on how these characteristics affected the performance of participants. These predictions along with participant engagement and feedback data was displayed on the dashboard. This visualization helps instructors identify teams requiring guidance or scaffolds to continue participation. Feedback from instructors shows the dashboard to be a promising tool for effectively managing massive online competitions.},
  keywords={Educational robots;Conferences;Data visualization;Machine learning;Predictive models;Task analysis;Usability;Learning Analytics;Learning Analytics Dashboard;Machine Learning in Learning Analytics;Project Based Learning;Engineering Education},
  doi={10.1109/EDUCON52537.2022.9766808},
  ISSN={2165-9567},
  month={March},}@INPROCEEDINGS{9962531,
  author={Eickholt, Jesse and Weible, Jennifer L. and Teasley, Stephanie D.},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Student-facing Learning Analytics Dashboard: Profiles of Student Use}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={Student-facing learning analytics dashboards (LADs) provide visualizations of course-related information to help students understand and personalize their educational practices. As such, they can be viewed as a meta-cognitive tool that enables awareness, self-reflection and sensemaking of academic performance. While student-facing LADs are becoming a standard feature in educational software, questions have been raised about students’ willingness to adopt LADs and their ability to interpret feedback provided by student-facing LADs. The extent to which student-facing LADs can broadly improve educational outcomes depends, in part, on students’ ability to readily incorporate LAD usage in their educational workflows.This study investigates the use of a student-facing LAD, My Learning Analytics (MyLA), over the span of one semester in a university introductory science course. MyLA draws data from the campus learning management system (Canvas) and displays three visualizations designed to provide students with actionable information. Adoption and use of MyLA was voluntary. As an exploratory study of MyLA’s use in an introductory science course, this work addresses three research questions: i) What are the characteristics of students that use MyLA?, ii) How do students make use of MyLA in their coursework?, and iii) What patterns of use are exhibited by more frequent MyLA users? The results indicate that given the opportunity to use a student-facing LAD, 33% of students made repeated use of the tool. Demographic data (e.g., gender, domestic/international student) did not predict MyLA usage but significant differences in mean cumulative GPA were found between non-MyLA users and MyLA users. Broad patterns of MyLA use were aligned with major assessments in the course (e.g., MyLA was used more often around exam dates) and the grade distribution view was the most commonly accessed. Among the most highly active MyLA users, two distinct profiles were identified: aware and sensemakers. Aware users made use of the dashboard on more than 12 distinct days across the course, primarily around exam dates, and stated that they accessed the dashboard to compare their performance with others. Sensemakers made frequent use of all three MyLA views multiple times over the semester to monitor their own progress, compare their grades to others, and check what materials other students had viewed.LADs such as MyLA allow students to leverage what they already know about course assessment in their interpretation of the data presented, easing adoption and deployment of a student-facing LAD in higher education. As MyLA does not require that students have any additional training to interpret the visualizations they provide, LADs can readily be employed by students in introductory computing and engineering courses to provide them with feedback to help them plan for, monitor, and evaluate their academic progress.},
  keywords={Training;Learning management systems;Data visualization;Software;Monitoring;Standards;learning analytics dashboard;student-facing learning analytics dashboard;self-regulated learning;course level micro-learning analytics},
  doi={10.1109/FIE56618.2022.9962531},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9499859,
  author={Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Singh, Shaveen and Chen, Peter and Richardson, Dan and Bartindale, Tom and Olivier, Patrick and Gašević, Dragan},
  booktitle={2021 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Question-driven Learning Analytics: Designing a Teacher Dashboard for Online Breakout Rooms}, 
  year={2021},
  volume={},
  number={},
  pages={176-178},
  abstract={One of the ultimate goals of several learning analytics (LA) initiatives is to close the loop and support students’ and teachers’ reflective practices. Although there has been a proliferation of end-user interfaces (often in the form of dashboards), various limitations have already been identified in the literature such as little account for sensemaking needs. This paper addresses these limitations by proposing a question-driven LA design approach to ensure that end-user LA interfaces explicitly address teachers’ questions. We illustrate this in the context of synchronous online activities orchestrated by pairs of teachers using audio-visual and text-based tools (Zoom and Google Docs). This led to the design of an open-source monitoring tool to be used in real-time by teachers when students work collaboratively in breakout rooms, and across learning spaces.},
  keywords={Tools;Real-time systems;Internet;Open source software;Monitoring;computer aided instruction;learning management systems},
  doi={10.1109/ICALT52272.2021.00060},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9725188,
  author={Cechinel, Cristian and De Freitas Dos Santos, Mateus and Barrozo, Caio and Schardosim, Jesiel Emerim and Vila, Eduardo de and Ramos, Vinicius and Primo, Tiago and Munoz, Roberto and Queiroga, Emanuel Marques},
  booktitle={2021 XVI Latin American Conference on Learning Technologies (LACLO)}, 
  title={A Learning Analytics Dashboard for Moodle: Implementing Machine Learning Techniques to Early Detect Students at Risk of Failure}, 
  year={2021},
  volume={},
  number={},
  pages={130-136},
  abstract={Learning Analytics Dashboards are important tools that help professors to follow and understand students behavior inside Learning Management Systems. Moodle is one of the most popular and used Learning Management Systems available nowadays, and a number of initiatives have been conducted to offer Learning Analytics features inside it. The present paper describes MAD2, a Learning Analytics Dashboard developed for Moodle that offers different visualizations about students interactions inside the environment, and that uses machine learning techniques to early predict students at-risk of failure. The paper describes the predictive approach implemented inside the tool together with the most important visualization features available to the users. The offering of a tool to early predict students at-risk of failure inside Moodle is an important step to help professors and managers to better assist students during their courses.},
  keywords={Learning management systems;Machine learning;Data mining;Machine Learning;Dashboard;Educational Data Mining;Learning Analytics;At-risk students.},
  doi={10.1109/LACLO54177.2021.00019},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10645910,
  author={Wang, Chao and Ng, Jeremy Tzi Dong and López, Nora Patricia Hernández and Hu, Xiao},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Preliminary Evaluation of Learning Analytics Dashboard for College Teachers’ Online Professional Learning}, 
  year={2024},
  volume={},
  number={},
  pages={83-85},
  abstract={Widely accessible online courses provide a feasible platform for teachers' continuous online professional learning. The learning analytics dashboard (LAD) provides fine-grained and actionable feedback that supports learners’ self-regulated learning. However, previous studies on LAD design and evaluation predominantly focused on student-facing LADs, with scarce attention on LADs designed for teacher-learners. This study introduces the LAD in an online learning platform for college teachers and conducts a preliminary evaluation with 18 participants. Results show their largely positive ratings on five criteria (e.g., perceived usefulness, ease of use, and behavioral changes) and offer feedback for further refinements of the LAD. This study will improve our understanding of LA-enabled teacher online professional learning and provide practical implications for designing and evaluating LA tools catered to teacher-learners.},
  keywords={Data collection;learning analytics dashboard;teacher online professional learning;preliminary evaluation},
  doi={10.1109/ICALT61570.2024.00030},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9731917,
  author={Revano, Teodoro F. and Garcia, Manuel B.},
  booktitle={2021 IEEE 13th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)}, 
  title={Designing Human-Centered Learning Analytics Dashboard for Higher Education Using a Participatory Design Approach}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Higher education institutions (HEIs) are looking for new methods to assess and monitor student learning outcomes, as well as objectively determine the circumstances that contribute to their growth in different courses. Advances in new analytics tools that put visualizations and dashboards on top of live student data are making learning analytics more powerful than ever. This study utilized a participatory design (PD) technique to formulate an analytics dashboard intended for higher education. The rationale behind the study lies on the belief that an information system must be designed for users, rather than users having to accommodate a wide range of adjustments just to utilize such application. Students and teachers were recruited for their feedback and observations, respectively. After multiple PD sessions, four main crucial factors were derived: (1) who has access to data, (2) importance of time, (3) learning analytics should help students make the transition to university life, and (4) it should be discipline-specific. This study opens up a discussion on the importance of human-centered design through the use of PD and how learning analytics dashboard can be maximized to its potential when deployed in the academe.},
  keywords={Conferences;Education;Process control;Humanoid robots;Data visualization;Information technology;Nanotechnology;Academic Analytics;Learning Analytics Dashboard;Participatory Design;Higher Education;Human-Centered Design},
  doi={10.1109/HNICEM54116.2021.9731917},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8987229,
  author={Ulfa, Saida and Fattawi, Izzull and Surahman, Ence and Yusuke, Hayashi},
  booktitle={2019 5th International Conference on Education and Technology (ICET)}, 
  title={Investigating Learners' Perception of Learning Analytics Dashboard to Improve Learning Interaction in Online Learning System}, 
  year={2019},
  volume={},
  number={},
  pages={49-54},
  abstract={Big data has changed the approach in designing an e-Learning. When students interact with e-Learning content, automatically generating data, we can collect and trace their learning tracks. The data is processed and analyzed, then used to understand the behavioral characteristics of the user or student to enable a personalized learning experience. In this study, learning analytics dashboard was used to improve learning interaction which impacts the learning successfulness. Tests were conducted on 67 students in the Educational Technology Department of the State University of Malang and distributed questionnaires and then analyzed using descriptive methods. The result is that most of the students who take online learning using the learning analytics dashboard find it helpful to carry out self-evaluations of their interaction hence they can manage their learning. The results of the study showed that most participants agreed that LAD could provide information to them regarding their interactions with learning content (M = 4.15, SD = 0.557), learning environment (M = 4.13, SD = 0.457), as well as the participants could conduct problem identification during their learning process (M = 3.88, SD = 0.477).},
  keywords={learning analytics;learning interaction;learner's perception},
  doi={10.1109/ICET48172.2019.8987229},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9766741,
  author={Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
  booktitle={2022 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Understand the influence of learning analytics dashboards on learner self-regulation and academic success}, 
  year={2022},
  volume={},
  number={},
  pages={1044-1047},
  abstract={Since the beginning of the COVID-19 pandemic, many countries have adopted online education as an alternative to face-to-face courses. This has increased awareness of the importance of analyzing learning data left by students to improve and evaluate the learning process. This article presents a new tool, named TaBAT, created to work with different LMSs in the form of dashboards accessible online and allowing teachers to monitor the progress of their learners and at the same time and allow teachers to track the progress of their learners, while allowing learners to develop self-regulation skills and visualize their learning process. The results of a study conducted show that TaBAT helped learners to increase their progress and spend more time in the online course.},
  keywords={COVID-19;Pandemics;Conferences;Engineering education;Monitoring;Learning analytics;Learning experience;Self-regulated dashboards},
  doi={10.1109/EDUCON52537.2022.9766741},
  ISSN={2165-9567},
  month={March},}@INPROCEEDINGS{10807906,
  author={Shegupta, Ummay Ubaida and Islam, Md Shoriful and Hardt, Wolfram},
  booktitle={2024 International Symposium on Computer Science and Educational Technology (ISCSET)}, 
  title={Predictive Learning Analytics Utilizing Formative Assessments and Recommender System for Study Success}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Learning analytics aims to understand, intervene, optimize, and improve learning. It deploys data produced from students' learning and learning environment. Within this do-main, predictive learning analytics has emerged as a transformative paradigm in education, leveraging data-driven methodologies to forecast student performance. This study represents the technical realization of a predictive learning analytics system using the data from formative assessments and recommendation system. Providing the pedagogical embeddement of the formative assessments along with educational recommender system in a hybrid learning environment, this study shows a prototype of predictive analytics and visualization for students and teachers. Formative assessments is rooted with the theory of scaffolding and recommendation plays vital role as consultation. These concepts combinedly shape early detection of tutoring for study success. Henceforth, the digital learning footprints of the students from online assessment and recommender systems contain the clues which can be detected for predetermining the performance. In this study, a predictive learning analytics (PLA) system is designed and developed that detects students at risk and those performing average and above average, enabling the option of interventions. By analyzing student data through Python and ASP.NET MVC, the system can accurately forecasts academic performance. An interactive dashboard allows educators and students to compare predicted outcomes with actual grades. The findings of this study steer to detect the need and point of tutoring support by combining current performance data with predictive insights to initiate study success.},
  keywords={Manifolds;Data privacy;Protocols;Shape;Scalability;Data visualization;Prototypes;Predictive analytics;Recommender systems;Standards;Data visualization;dashboard;learning analyt-ics;predictive learning analytics;predictive models;study success;tutoring},
  doi={10.1109/ISCSET58624.2024.10807906},
  ISSN={},
  month={July},}@INPROCEEDINGS{7265321,
  author={Ramos-Soto, A. and Lama, M. and Vazquez-Barreiros, B. and Bugarin, A. and Mucientes, M. and Barro, S.},
  booktitle={2015 IEEE 15th International Conference on Advanced Learning Technologies}, 
  title={Towards Textual Reporting in Learning Analytics Dashboards}, 
  year={2015},
  volume={},
  number={},
  pages={260-264},
  abstract={In this paper we present the Soft Learn Activity Reporter (SLAR) service which automatically generates textual short-term reports about learners' behavior in virtual learning environments. Through this approach, we show how textual reporting is a coherent way of providing information that can complement (and even enhance) visual statistics and help teachers to understand in a comprehensible manner the behavior of their students during the course. This solution extracts relevant information from the students' activity and encodes it into intermediate descriptions using linguistic variables and temporal references, which are subsequently translated into texts in natural language. The examples of application on real data from an undergraduate course supported by the Soft Learn platform show that automatic textual reporting is a valuable complementary tool for explaining teachers and learners the information comprised in a Learning Analytics Dashboard.},
  keywords={Pragmatics;Natural languages;Student activities;Portfolios;Blogs;Data mining;Context;Linguistic Descriptions of Data;Learning Analytics Dashboard;Natural Language Generation},
  doi={10.1109/ICALT.2015.96},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9162357,
  author={Ramaswami, Gomathy Suganya and Susnjak, Teo and Mathrani, Anuradha},
  booktitle={2019 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)}, 
  title={Capitalizing on Learning Analytics Dashboard for Maximizing Student Outcomes}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={With ongoing advancements in technology enabled learning, an opportunity has risen for educators to enhance student learning with use of Learning Analytics. Educational institutions are using Learning Analytics Dashboards (LAD) to provide students with timely and personalized feedback in visual format. LAD use advanced analytical capabilities that capitalize on online learner activities that are extracted from log files. They provide data-driven insights on current learning contexts and inform management on any learning intervention strategies that may be needed to support students in achieving their learning outcomes. Besides students, the perspective of instructors too is considered. Using easy-to-read graphical reporting formats (e.g., line graphs, scatter plot, bar charts, etc.), the LAD reveals a consolidated view of how online learning is taking place. In this manner, a snapshot depicting details of student learning patterns can enable instructors to monitor their students' learning strategies. At the same time, the LAD assists students too by providing them with a personalized environment to help them engage better with the learning outcomes. Therefore, LAD is increasingly used as a pedagogical approach to motivate students and help build their self-learning capacity. In this study, we propose to develop a real-time dashboard that pulls online student data from various sources including a learning management system (Moodle), University's library and from the student management system (SMS) that is used by the staff.},
  keywords={Tools;Data visualization;Data mining;Bars;Libraries;History;Learning systems;learning dashboard;feedback;student feedback system;visualization tool;dashboard},
  doi={10.1109/CSDE48274.2019.9162357},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9725187,
  author={Campoberde, Jonnathan and Macías, Miguel Á. and Maldonado-Mahauad, Jorge},
  booktitle={2021 XVI Latin American Conference on Learning Technologies (LACLO)}, 
  title={Proposal for the Design and Implementation of a XBlock in Open edX to Support Learning Analytics}, 
  year={2021},
  volume={},
  number={},
  pages={498-501},
  abstract={Nowadays, when users using information systems, they generate a large amount of data leaving behind a trace as a result of their interaction, e.g., when students access educational materials on Virtual Learning Environments (VLE). This has developed into what we now know as Massive Open Online Courses (MOOCs), which have millions of registered students. Due to the large amount of data that is generated within these MOOCs, Learning Analytics (LA) has emerged as an alternative to improve teaching and learning processes through data analysis. Open edX in an attempt to incorporate Learning Analytics into its Insights development platform, which provides very simple visualizations. Likewise, other projects have been added, which over time have become obsolete or do not provide sufficient support to improve the learning process of students. Therefore, this study proposes the design, development, and evaluation of a learning analytics dashboard for the Open edX platform. The tool will incorporate indicators of student success in its visualizations to improve the learning process within the platform.},
  keywords={Electronic learning;Data analysis;Education;Data visualization;Proposals;Information systems;Learning Analytics;Open edX;dashboard;student success;XBlock},
  doi={10.1109/LACLO54177.2021.00088},
  ISSN={},
  month={Oct},}@ARTICLE{10319391,
  author={Israel-Fishelson, Rotem and Kohen-Vacs, Dan},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Towards Optimization of Learning Analytics Dashboards That are Customized for the Students’ Requirements}, 
  year={2024},
  volume={17},
  number={},
  pages={794-802},
  abstract={Educational dashboards enable students to monitor and reflect on academic performance and administrative aspects of the learning processes. Occasionally, educational institutions integrate dashboards using the information found in their learning management systems or their students' information desks. Learning analytics offers ways to enrich these dashboards and expose students to analyzed information beyond the monitored data provided such as smart recommendations. Despite the large variety of dashboards, the students’ centric perspective and the ability to adapt the dashboard to their personal needs is not a common practice. To identify and support the needs of students who wish to track aspects of their learning routine, it is very important to position the students at the core of the design process of these dashboards. This article presents a new phase in our research to expand our understanding of the students' needs in monitoring their educational routines and preferences while using an advanced form of a learning analytics dashboard. We propose an optimized approach for designing educational dashboards. In this sense, we examine and seek to integrate the components that are prominently required by students. Hence, we address both the type of components as well as their arrangement within the customized dashboard. The outcomes of our efforts reveal findings concerning students’ trends and habits when exploiting these dashboards. It also offers pivotal insights and recommendations for the optimized implementation of learning analytics dashboards that are aligned with the students’ authentic requirements.},
  keywords={Monitoring;Stakeholders;Learning management systems;Layout;Statistics;Sociology;Market research;Dashboard component;design cluster;learning analytics dashboard;learning management systems (LMS);students information desk (SID)},
  doi={10.1109/TLT.2023.3332500},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{9499886,
  author={Ifenthaler, Dirk and Schumacher, Clara and Sahin, Muhittin},
  booktitle={2021 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={System-based or Teacher-based Learning Analytics Feedback – What Works Best?}, 
  year={2021},
  volume={},
  number={},
  pages={184-186},
  abstract={Feedback has been identified as the most powerful moderator for supporting learning. Learning analytics haven been recognized for opportunities for providing timely and informative feedback to learners when they need it. This study seeks to investigate learners’ perceptions and expected benefits of different forms of learning analytics feedback from different sources. In a quasi-experimental study including 230 students, four experimental groups were confronted with five learning scenarios receiving different learning analytics feedback. Findings indicate that perceived benefits from learning analytics feedback varies across different delivery sources and requires informative recommendations. Accordingly, designing and implementing feedback in learning analytics systems is more complex than just providing visualizations of behavioral data.},
  keywords={Data visualization;Reliability;Testing;feedback;learning analytics;dashboard;visualization;pedagogical feature;perceived benefit},
  doi={10.1109/ICALT52272.2021.00062},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{8433501,
  author={Seaton, Jennifer and Graf, Sabine and Chang, Maiga and Farhmand, Arta},
  booktitle={2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Incorporating Learning Analytics in an Educational Game to Provide Players with Information about how to Improve Their Performance}, 
  year={2018},
  volume={},
  number={},
  pages={229-230},
  abstract={Educational games aim to balance learning and playing. However, for people to benefit from an educational game, they must be encouraged to play the game often. Providing players with information about how to improve their performance could help in achieving this goal. This paper examines how a learning analytics dashboard can be incorporated into an educational game to encourage players to play more often and continuously. The proposed dashboard provides players with a variety of information such as how their performance and skills change over time. Such information allows players to see their performance and play habits, and find strategies on how to improve their performance, and therefore their learning, in the game.},
  keywords={Games;Data visualization;Task analysis;Conferences;Cognition;Programming profession;learning analytics;educational game;dashboard;metacognitive skill},
  doi={10.1109/ICALT.2018.00121},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10645811,
  author={Seidel, Niels and Meyer, Valerie and Radović, Slavisa},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Co-Design of an Adaptive Personalized Learner Dashboard}, 
  year={2024},
  volume={},
  number={},
  pages={26-28},
  abstract={Learning Analytics Dashboards (LAD) equip learners with visual insights into their study activities, enabling informed decision-making. This paper introduces a LAD plugin tailored to individual needs to improve distance learners’ skills in metacognition and self-regulation. Through a co-design approach involving focus groups and interviews, students identified desired features like comprehensive resource overviews, deadline tracking, progress highlights, and enhanced interactions with peers and instructors. The final dashboard design allows learners to assess and track their knowledge, progress, and upcoming tasks, with metrics that facilitate comparisons against their goals and provide adaptive feedback. A user study (N=177) confirmed that users are engaged with the dashboard, but the planning and reflection tools were used less than the monitoring tools.},
  keywords={Measurement;Visualization;User centered design;Decision making;Metacognition;Reflection;Planning;Learning Analytics Dashboard;Co-Design;Adaptive Learning},
  doi={10.1109/ICALT61570.2024.00014},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9368340,
  author={Owatari, Takuro and Shimada, Atsushi and Minematsu, Tsubasa and Hori, Maiya and Taniguchi, Rin-ichiro},
  booktitle={2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)}, 
  title={Real-Time Learning Analytics Dashboard for Students in Online Classes}, 
  year={2020},
  volume={},
  number={},
  pages={523-529},
  abstract={In recent years, online classes have been increasingly conducted in various situations. However, in these classes, especially non-face-to-face and large-scale ones, it is more difficult for teachers and students to understand the status of the class during a lecture. To address this issue, we propose a real-time learning analytics dashboard that provides summarized information on teachers' instruction and students' learning activities during lectures. In this article, we introduce the real-time learning analytics dashboard and report its effectiveness through experiments in an online class at our university.},
  keywords={Electronic publishing;Conferences;Education;Real-time systems;Synchronization;real-time analytics;real-time system;online lecture;learning behavior},
  doi={10.1109/TALE48869.2020.9368340},
  ISSN={2470-6698},
  month={Dec},}@ARTICLE{10399863,
  author={Reid, David P. and Drysdale, Timothy D.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Student-Facing Learning Analytics Dashboard for Remote Lab Practical Work}, 
  year={2024},
  volume={17},
  number={},
  pages={1037-1050},
  abstract={The designs of many student-facing learning analytics (SFLA) dashboards are insufficiently informed by educational research and lack rigorous evaluation in authentic learning contexts, including during remote laboratory practical work. In this article, we present and evaluate an SFLA dashboard designed using the principles of formative assessment to provide feedback to students during remote lab activities. Feedback is based upon graphical visualizations of student actions performed during lab tasks and comparison to expected procedures using TaskCompare—our custom, asymmetric graph dissimilarity measure that distinguishes students who miss expected actions from those who perform additional actions, a capability missing in existing graph distance (symmetrical dissimilarity) measures. Using a total of $N = 235$ student graphs collected during authentic learning in two different engineering courses, we describe the validation of TaskCompare and evaluate the impact of the SFLA dashboard on task completion during remote lab activities. In addition, we use components of the motivated strategies for learning questionnaire as covariates for propensity score matching to account for potential bias in self-selection of use of the dashboard. We find that those students who used the SFLA dashboard achieved significantly better task completion rate (nearly double) than those who did not, with a significant difference in TaskCompare score between the two groups (Mann–Whitney $U = 453.5$, $p < 0.01$ and Cliff's $\delta = 0.43$, large effect size). This difference remains after accounting for self-selection. We also report that students' positive rating of the usefulness of the SFLA dashboard for completing lab work is significantly above a neutral response ($S = 21.0$ and $p < 0.01$). These findings provide evidence that our SFLA dashboard is an effective means of providing formative assessment during remote laboratory activities.},
  keywords={Task analysis;Education;Remote laboratories;Particle measurements;Atmospheric measurements;Videos;Standards;Feedback;formative assessment;graphs;learning analytics (LA);online learning;remote learning;self-regulated learning (SRL)},
  doi={10.1109/TLT.2024.3354128},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{8923106,
  author={Clauss, Alexander and Lenk, Florian and Schoop, Eric},
  booktitle={2019 2nd International Conference on new Trends in Computing Sciences (ICTCS)}, 
  title={Enhancing International Virtual Collaborative Learning with Social Learning Analytics}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The ability to work collaboratively in intercultural virtual teams, is constantly gaining importance for the labour market. Virtual Mobility enables students to acquire the necessary intercultural teamwork skills while remaining locally integrated into their regular studies. But still, international virtual collaborative learning scenarios demand much time and effort for planning and coordination which binds resources. The support concepts for such collaborative virtual learning groups are also resource-intensive, because learners should be accompanied by qualified e-tutors to optimise learning results both at individual and group level. Classical summative tests and exams are rather unsuitable for the assessment of collaboration as expected learning outcome. These arrangements also need new formative assessment forms, as participants need active and ongoing feedback. A meaningful assessment of learning processes and outcomes should not only be based on the observation of `soft' factors but should also be complemented by `hard', fixed, automatically measurable, quantitative indicators. To gain these hard indicators the research project ISLA - Indicator-based Social Learning Analytics was launched. This paper presents the procedure for implementation as well as virtual presence, content creation and relationships within the community as first derived indicators and their prototypical visualisation in a Learning Analytics Dashboard.},
  keywords={Teamwork;Social network services;Collaborative work;Databases;Information management;Systematics;Collaborative Learning;Virtual Mobility;Social Learning Analytics;Learning Analytics Dashboard},
  doi={10.1109/ICTCS.2019.8923106},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8705240,
  author={Villarroel, Rodolfo and Villalobos, Cristian and Merino, Erick and Barcelos, Thiago and Munoz, Roberto},
  booktitle={2018 37th International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={Developing a Dashboard to Support the Analysis of Multimodal Educational Data}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Learning analytics consists of gathering and analyzing data from students in order to understand complex aspects of the learning process and promote its improvement. Currently, there is a lack of tools that allow the visualization of multimodal data. In this paper, we present a visualizer that allows analyzing the data provided by a multimodal learning analytics software. The multimodal data visualizer, in addition to allowing to visualize 10 body postures, permits applying clustering techniques, such as k-means. As validation, we analyze the data provided of 43 engineering student presentations.},
  keywords={Software;Data visualization;Silicon compounds;Visualization;Media;Tools;Engineering students;multimodal learning analytics;kinect;oral presentations;dashboard},
  doi={10.1109/SCCC.2018.8705240},
  ISSN={1522-4902},
  month={Nov},}@INPROCEEDINGS{6901481,
  author={Malhotra, Manav and Hsiao, I-Han and Chae, Hui Soo and Natriello, Gary},
  booktitle={2014 IEEE 14th International Conference on Advanced Learning Technologies}, 
  title={Data Depository: Business & Learning Analytics for Educational Web Applications}, 
  year={2014},
  volume={},
  number={},
  pages={363-364},
  abstract={Quantitative methods in education research have long been limited by the ability to collect detailed learner data in a consistent, scalable way. As education continues to move online we are presented with an unprecedented opportunity to study learner interactions within learning systems. However, doing so requires infrastructure to collect and store massive interaction data from which we can learn. In this paper we present Data Depository, a flexible, pluggable, data hub for tracking interaction data from any browser-based application, aiding the measurement of usage and effectiveness.},
  keywords={Educational institutions;Measurement;Cities and towns;Monitoring;Business;Learning systems;learning analytics;tracking;user interaction;measurement;dashboard;depository},
  doi={10.1109/ICALT.2014.237},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10525855,
  author={Oliveira, Pedro Filipe and Matos, Paulo},
  booktitle={2023 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Learning Analytics to Validate Academic Performance Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The learning process is increasingly on the agenda. As well as the mechanisms that can be used to optimize it, both in terms of improving student performance, as well as improving teacher performance. On this subject, there has been continuous research, and increasingly trying to take advantage of technological development, and thus be able to take full advantage of technology and achieve a significant leverage in this field. This work is developed within the scope of the evaluation of school performance. Namely, with the introduction of additional and customized resources, such as thematic courses on the Coursera platform, and the utilization analysis of the e-learning platform used by the teaching institution. With this, it was possible to develop some tools, which are used as dashboards to give the teacher a greater perception of the student's learning process and performance. And if any student is in the prospect of failing, the teacher receives an immediate notification, so that he can carry out the respective follow-up, and thus be able to act proactively to avoid failure.},
  keywords={Analytical models;Machine learning algorithms;Electronic learning;Soft sensors;Education;Data visualization;Real-time systems;learning-analytics;dashboard;academic-performance;coursera},
  doi={10.1109/ICEET60227.2023.10525855},
  ISSN={2831-3682},
  month={Oct},}@INPROCEEDINGS{10306139,
  author={Choi, Heeryung and Borrella, Inma and Ponce-Cueto, Eva},
  booktitle={2023 IEEE Learning with MOOCS (LWMOOCS)}, 
  title={Meta-LAD: Developing a Learning Analytics Dashboard with a Theoretically Grounded and Context-Specific Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The use of Learning Analytics Dashboards (LADs) has gained popularity as a means of supporting the self-regulated learning (SRL) skills of learners in large-scale online courses. Despite many studies proposing LAD designs, LADs are often criticized for their weak theoretical foundations, lack of actionable feedback, and tendency to encourage excessive social comparison. Furthermore, many LAD designs have missed context-specific details. Hence, it is not uncommon for some dashboard designs to have negative effects on learners, such as discouragement or anxiety. In this study, we designed the Meta-LAD, a LAD that supports SRL processes using theoretical and contextual foundations. We used data from a credit-bearing Massive Open Online Course (MOOC) on supply chain management to contextually ground the dashboard. We performed usability testing interviews to evaluate the design and confirmed that the Meta-LAD could fulfill learners' needs for references and actionable feedback. This study contributes to the field of online learning by presenting a theoretically grounded and contextually specific LAD design process. This paper expands the understanding of how to support SRL in MOOCs.},
  keywords={Computer aided instruction;Electronic learning;Supply chain management;Anxiety disorders;Usability;Interviews;Testing;MOOC;Learning Analytics Dashboard;Self-regulated Learning},
  doi={10.1109/LWMOOCS58322.2023.10306139},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6658135,
  author={Aljohani, Naif Radi and Davis, Hugh C.},
  booktitle={2013 Seventh International Conference on Next Generation Mobile Apps, Services and Technologies}, 
  title={Learning Analytics and Formative Assessment to Provide Immediate Detailed Feedback Using a Student Centered Mobile Dashboard}, 
  year={2013},
  volume={},
  number={},
  pages={262-267},
  abstract={The 'immediacy' of feedback on academic performance is a common characteristic shared by both Learning Analytics (LA) and Formative Assessment (FA), and such immediacy could be facilitated by supporting the mobility of learners. However, there is little literature that investigates the significance of combining these two techniques. Therefore, this paper will discuss the analytical application called Quiz My Class Understanding (QMCU) which was purposely developed to investigate the significance of the combination between LA and FA techniques in order to provide students with immediate detailed feedback. Furthermore, it reports on a case study which reflects the role QMCU students' centered mobile dashboard in increasing the students' engagement with the QMCU dashboard.},
  keywords={Mobile communication;Educational institutions;Mobile handsets;Taxonomy;Materials;Performance evaluation;Learning Analytics;Mobile Learning Analytics Formative Assessment;Mobile Formative Assessment;Immediate Feedback},
  doi={10.1109/NGMAST.2013.54},
  ISSN={2161-2897},
  month={Sep.},}@INPROCEEDINGS{10406321,
  author={Munim, Z. H. and Schramm, H. J. and Krabbel, H. and Nyairo, F. and Haavardtun, P. and Kim, T-E. and Bustgaard, M.},
  booktitle={2023 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)}, 
  title={User Requirements for Learning Analytics Dashboard in Maritime Simulator Training}, 
  year={2023},
  volume={},
  number={},
  pages={0406-0410},
  abstract={This study investigates user requirements for the design of a Learning Analytics Dashboard (LAD) tailored for assessment in maritime simulator training. User requirements for LAD components and visualization elements were examined. Further, perceptions towards the integration of LAD in performance assessment was explored using Likert-scale questions. Data was collected from three Nordic maritime institutions. Situational awareness emerged as the most important component of a maritime LAD, with heat maps preferred for visualization. Both teachers and students have positive perceptions towards the utilization of LAD. Disparities in user requirement and perception towards LAD use across universities, study levels, and simulator modality experience were explored. These insights are pivotal for the advancement and tailoring of LADs in maritime simulator training contexts.},
  keywords={Training;Navigation;Engineering management;Industrial engineering;Regulation;Heat maps;Marine vehicles;Maritime Education;Simulator Training;Learning Analytics;Learning Dashboard;User Perception},
  doi={10.1109/IEEM58616.2023.10406321},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9853830,
  author={Wang, Zuo and Tzi Dong Ng, Jeremy and Liu, Ruilun and Hu, Xiao},
  booktitle={2022 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Learning Analytics Enabled Virtual Reality Content Creation Platform: System Design and Preliminary Evaluation}, 
  year={2022},
  volume={},
  number={},
  pages={161-163},
  abstract={Due to the popularity of virtual reality (VR) in education settings and the rise of maker education, this paper presents LAVR, a platform for VR content creation with learning analytics functions. We design the platform where students can easily create VR stories through a web interface. A learning analytics dashboard is implemented to provide students with feedback on their progress and the quality of the textual content in their VR stories. The platform also offers learning management features for helping teachers set up classrooms with assignments. While the platform will be employed in a forthcoming general education course, we have conducted a preliminary usability evaluation with 12 students and one teacher, and gathered feedback for further refinements before its official launch. The platform will contribute to integrating learning analytics with maker activities.},
  keywords={Virtual reality;Educational courses;Usability;System analysis and design;learning analytics;maker education;virtual reality content creation;platform design},
  doi={10.1109/ICALT55010.2022.00055},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{8363102,
  author={van der Stappen, Esther},
  booktitle={2018 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Workplace learning analytics in higher engineering education}, 
  year={2018},
  volume={},
  number={},
  pages={15-20},
  abstract={Learning in the workplace is crucial in higher engineering education, since it allows students to transfer knowledge and skills from university to professional engineering practice. Learning analytics endeavors in higher education have primarily focused on classroom-based learning. Recently, workplace learning analytics has become an emergent research area, with target users being workers, students and trainers. We propose technology for workplace learning analytics that allows program managers of higher engineering education programs to get insight into the workplace learning of their students, while ensuring privacy of students' personal data by design. Using a design-based agile methodology, we designed and developed a customizable workplace learning dashboard. From the evaluation with program managers in the computing domain, we can conclude that such technology is feasible and promising. The proposed technology was designed to be generalizable to other (engineering) domains. A next logical step would be to evaluate and improve the proposed technology within other engineering domains.},
  keywords={Hafnium;Engineering education;Conferences;Workplace Learning;Learning Analytics;Data-Driven Curriculum Improvement},
  doi={10.1109/EDUCON.2018.8363102},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10080832,
  author={Deshpande, K. V. and Asbe, Shubham and Lugade, Akanksha and More, Yash and Bhalerao, Dipali and Partudkar, Anuradha},
  booktitle={2023 International Conference for Advancement in Technology (ICONAT)}, 
  title={Learning Analytics Powered Teacher Facing Dashboard to Visualize, Analyze Students’ Academic Performance and give Key DL(Deep Learning) Supported Key Recommendations for Performance Improvement.}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={COVID-19 has forced the government to close educational institutes to reduce the spread of the virus. As a result of this decision, students lose contact with teachers and a communication gap also arises. This survey attempts to bridge the gap between students and teachers. Through this survey, we sought to understand where the students are lacking and what are the different steps that can be taken by the teacher to improve the performance of the student and whether this concept should be reviewed or not. We found that most of the researchers who have published papers that we have read did the same mistake in their research, therefore we realized that the concept of AI should be studied again, and we should try not to repeat the same mistake in our research.The main aim of our project is to build “Teacher facing dashboard” which can help the teacher to summarize,visualize and analyze the data of the education field(academics) and also understanding the students performance using Machine Learning(ML) and Deep Learning (DL).},
  keywords={Deep learning;COVID-19;Government;Education;Data visualization;teacher facing dashboard;learning analytics;students;teachers;visualize;analyze;education field;machine learning;deep learning.},
  doi={10.1109/ICONAT57137.2023.10080832},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8115555,
  author={Volarić, Tomislav and Ljubić, Hrvoje},
  booktitle={2017 25th International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={Learner and course dashboards for intelligent learning management systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Visualization of data in learning management systems became essential for easier analysis of learner's behavior and interpretation of results on such system. In this paper, we presented design and development process of dashboard for the prototype of program support-CM Tutor. After analysis of various approaches of designing a learning analytics dashboard, we selected most important items for display on the dashboard, and we created our own. We have designed and built a dashboard for intelligent learning management systems. The dashboard is intended for both students and teachers. The teacher has access to all the functionalities of dashboard, while student approach is limited.},
  keywords={Data visualization;Testing;Adaptation models;Tools;Mathematical model;Learning management systems;Dashboard;Learning analytics;Learning Analytics Dashboards;Visualization;Intelligent learning management systems},
  doi={10.23919/SOFTCOM.2017.8115555},
  ISSN={1847-358X},
  month={Sep.},}@ARTICLE{9446995,
  author={Ruipérez-Valiente, José A. and Gomez, Manuel J. and Martínez, Pedro A. and Kim, Yoon Jeon},
  journal={IEEE Access}, 
  title={Ideating and Developing a Visualization Dashboard to Support Teachers Using Educational Games in the Classroom}, 
  year={2021},
  volume={9},
  number={},
  pages={83467-83481},
  abstract={Technology has become an integral part of our everyday life, and its use in educational environments keeps growing. Additionally, video games are one of the most popular mediums across cultures and ages. There is ample evidence that supports the benefits of using games for learning and assessment, and educators are mainly supportive of using games in classrooms. However, we do not usually find educational games within the classroom activities. One of the main problems is that teachers report difficulties to actually know how their students are using the game so that they can analyze properly the effect of the activity and the interaction of students. To support teachers, educational games should incorporate learning analytics to transform data generated by students when playing useful information in a friendly and understandable way. For this work, we build upon Shadowspect, a 3D geometry puzzle game that has been used by teachers in a group of schools in the US. We use learning analytics techniques to generate a set of metrics implemented in a live dashboard that aims to facilitate that teachers can understand students' interaction with Shadowspect. We depict the multidisciplinary design process that we have followed to generate the metrics and the dashboard with great detail. Finally, we also provide uses cases that exemplify how teachers can use the dashboard to understand the global progress of their class and each of their students at an individual level, in order to intervene, adapt their classes and provide personalize feedback when appropriate.},
  keywords={Games;Measurement;Education;Tools;Three-dimensional displays;Rigidity;Learning systems;Educational games;learning analytics;game-based assessment;visualization dashboard;technology-enhanced learning},
  doi={10.1109/ACCESS.2021.3086703},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9647058,
  author={Avila-Pesantez, Diego and Usca, Brandon Alexander Tub&#x00F3;n and Angamarca, Bryan Gag&#x00F1;ay and Avila, L. Miriam},
  booktitle={2021 IEEE URUCON}, 
  title={Improving the Serious Game design using Game Learning Analytics and Eye-tracking: A pilot study}, 
  year={2021},
  volume={},
  number={},
  pages={536-540},
  abstract={It is necessary to consider metrics that integrate Game Learning Analytics (GLA) and technologies that improve user interfaces through the eye tracker to get better the Serious Games design. In this work, the Math4Fun game was developed using the ADDE methodology to support basic math operations for 7-year-old children, which allowed efficient communication to define the game&#x0027;s critical elements. The GLA metrics were implemented with eXperience API (xAPI) standard and visualized through a real-time dashboard, while Eye-tracking technology working with fixation time analysis on the game&#x0027;s interfaces improves gameplay and design. The results established that combining the GLA indicators with the user interface components obtained from the evaluation with eye-tracking allows redefining concepts in the design and programming inside SG in search of constant improvement.},
  keywords={Measurement;Visualization;Standards organizations;Organizations;User interfaces;Programming;User experience;game learning analytics;serious game design;MATH4FUN;Eye-tracking},
  doi={10.1109/URUCON53396.2021.9647058},
  ISSN={},
  month={Nov},}@ARTICLE{8400475,
  author={Molenaar, Inge and Knoop-van Campen, Carolien A. N.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={How Teachers Make Dashboard Information Actionable}, 
  year={2019},
  volume={12},
  number={3},
  pages={347-355},
  abstract={This study investigates how teachers use dashboards in primary school classrooms. While learners practice on a tablet real-time data indicating learner progress and performance is displayed on teacher dashboards. This study examines how teachers use the dashboards, applying Verberts' learning analytics process model. Teacher dashboard consultations and resulting pedagogical actions were observed in 38 mathematics lessons. In stimulated recall interviews, the 38 teachers were asked to elaborate on how they reflect on and make sense of the information on the dashboard. The results showed that teachers consulted the dashboard on average 8.3 times per lesson. Teachers activated existing knowledge about students and the class to interpret dashboard information. Task and process feedback were the pedagogical actions most often used following dashboard consultation. Additionally, teachers who consulted the dashboard more often activated more and more diverse pedagogical knowledge to interpret the data and, consequently, gave more and more diverse feedback. These results indicated that teacher dashboards were indeed influencing teachers' pedagogical actions in their daily classroom activities. This study provided the first evidence that dashboards progressively impact teaching practice and initiate more profound behavioral changes as teachers become more proficient in using them.},
  keywords={Analytical models;Education;Instruments;Reflection;Mathematics;Real-time systems;Task analysis;Adaptive learning technologies;learning analytics;dashboards;technology enhanced learning.},
  doi={10.1109/TLT.2018.2851585},
  ISSN={1939-1382},
  month={July},}@INPROCEEDINGS{10589982,
  author={Kew, Si Na and Koh, Elizabeth and Choo, Zi Luan and Jonathan, Christin Rekha},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={A Systematic Review on Student-Facing Learning Analytics Dashboards: Reference Frames and Indicators}, 
  year={2024},
  volume={},
  number={},
  pages={45-50},
  abstract={As the integration of technology in education undergoes continuous development, Learning Analytics Dashboards (LADs) have become vital tools for both instructors and learners, facilitating the monitoring and optimization of the learning experience. Student-facing LADs have been designed with various reference frames which enable various feedback, comparisons and reflection. However, there has been limited examination of the reference frames and their indicators employed in student-facing LADs as well as its evaluation. This research aims to address this gap by conducting a systematic literature review using PRISMA to synthesize existing literature to identify and offer insights on reference frames and key indicators used in student-facing LADs. We identified 42 articles and analyzed that social reference frames as compared to progress reference frames are commonly employed in LADs. Key indicators include class performance average, class performance mean, average performance of the class, etc. These insights contribute to the ongoing development and best practices of LAD design. The knowledge and findings can help educators, researchers, system designers and policymakers decide how best to incorporate these tools into educational settings.},
  keywords={Computer science;Systematics;Reviews;Bibliographies;Education;Reflection;Optimization;learning analytics dashboard;reference frame;indicators;systematic literature review;PRISMA},
  doi={10.1109/CSTE62025.2024.00015},
  ISSN={},
  month={April},}@INPROCEEDINGS{9853784,
  author={Sahin, Muhittin and Ifenthaler, Dirk},
  booktitle={2022 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Examining of Learners’ Dashboard Interaction in Computer Classification Testing Environment}, 
  year={2022},
  volume={},
  number={},
  pages={152-154},
  abstract={Technology-and analytics-enhanced self-assessments may provide multiple benefits for learners. However, data analytics approaches currently fail to make full use of educational technology and data for self-assessment. This research focuses on the implementation of an environment for self-assessment including a data-driven dashboard in the context of higher education and examines learners’ usage behaviors of N= 100 learners in three experimentally varied conditions. Findings indicate an intensive use of the self-assessments and data-driven dashboards throughout the semester. However, no differences in the interaction of learners with the different dashboard conditions were found. In conclusion, the design of data-driven dashboards for self-assessments requires valid information about learners, assessment processes, and the context of the assessment to better support the current needs of the learner and provide meaningful feedback to foster learning processes and outcomes.},
  keywords={Data analysis;Educational technology;Behavioral sciences;Testing;computer classification testing;dashboard interaction;adaptation;higher education},
  doi={10.1109/ICALT55010.2022.00052},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{8876527,
  author={García-Zubía, Javier and Cuadros, Jordi and Serrano, Vanessa and Hernández-Jayo, Unai and Angulo-Martínez, Ignacio and Villar, Aitor and Orduña, Pablo and Alves, Gustavo},
  booktitle={2019 5th Experiment International Conference (exp.at'19)}, 
  title={Dashboard for the VISIR remote lab}, 
  year={2019},
  volume={},
  number={},
  pages={42-46},
  abstract={The VISIR dashboard (VISIR-DB) is a learning analytics tool connected with the VISIR remote lab. In VISIR, every action performed by a student from the interface over the remote laboratory and back is logged and recorded. VISIR-DB helps visualizing, in a fast and deep way, the recorded logs from this communication. Using this tool, a teacher can analyze and understand better how the students are using the remote lab during their learning process on analog electronics. With this information, the VISIR platform can be improved and the use of remote labs can be better understood.},
  keywords={Task analysis;Current measurement;Voltage measurement;Electrical resistance measurement;Resistors;Tools;Resistance;remote laboratory;learning analytics;dashboard},
  doi={10.1109/EXPAT.2019.8876527},
  ISSN={},
  month={June},}@ARTICLE{9004573,
  author={Pérez-Berenguer, Daniel and Kessler, Mathieu and García-Molina, Jesús},
  journal={IEEE Access}, 
  title={A Customizable and Incremental Processing Approach for Learning Analytics}, 
  year={2020},
  volume={8},
  number={},
  pages={36350-36362},
  abstract={The ability of learning analytics to improve the learning/teaching processes is widely recognized. In this paper, the learning analytics architecture developed at the Digital Content Production Center of the Technical University of Cartagena (Spain) is presented. This architecture contributes to the field of learning analytics in two aspects: it allows for dashboard customization and improves the efficiency of the analysis of learners' interaction data. Events resulting from learners' interaction are captured and stored in Caliper standard format, to be further processed incrementally to allow dashboards to be shown without delay to teachers. Customization is considered a mandatory requirement for learning analytics tools, however, although some proposals have recently been made, a greater research effort in this topic is necessary. In the present work, this requirement is addressed by defining a domain-specific language (DSL) that allows teachers to customize dashboards. This language allows to express indicators (logical expressions) that classify students into different groups depending on their performance level. The paper also shows how our learning analytics approach was evaluated with a course that applies a flipped classroom method, and how it compares to the most relevant related works that have been published.},
  keywords={DSL;Tools;Data visualization;Computer architecture;Proposals;Data analysis;Standards;Learning analytics;DSL;model-driven development;custom dashboard;incremental event processing;R~language;Caliper},
  doi={10.1109/ACCESS.2020.2975384},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8524221,
  author={Hegde, Vinayak},
  booktitle={2017 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)}, 
  title={An Academic Framework for Designing Dashboard and Enhancing the Quality of Higher Education Admission Process Through Java Enterprise Edition}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={It is very critical to define and analyze the rate of admission in higher education at the private university. It is a democratic process that analyzes individual intellect, leadership quality, logical and problem-solving skills, performance in a co-curricular and extracurricular activity. The main objective of this paper is to design the framework for developing the academic dashboard to keep track of the walk-in, a number of prospectuses sold, call follow-up, tracing the admission to the various branches and applicants remarks. The dashboard provides information about how applicant came to know about the organization so that, in future social marketing can be effectively taken up for further improving the rate of admission. The admission data is analyzed through the various SQL queries and reports are generated through JEE for top-level decision. Google API is used for visualization. Dynamically reports can be accessed through the web by all top-level authorities. The implementation of data analytics and ICT skills in admission analysis stands as forefront technology to improve the growth of admission in higher education sector.},
  keywords={Organizations;Education;Java;Google;Software;Conferences;Computational intelligence;Educational Analytic;Admission;Learning;Analytics;Data Science;SQL queries;Dashboard;JEE},
  doi={10.1109/ICCIC.2017.8524221},
  ISSN={2473-943X},
  month={Dec},}@INPROCEEDINGS{9738149,
  author={Ouatiq, Amina and Riyami, Bouchaib and Mansouri, Khalifa and Qbadou, Mohammed and Aoula, Es-Saadia},
  booktitle={2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={Towards the Co-Design of a Teachers' Dashboards in a Hybrid Learning Environment}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Learning Analytic Dashboards support learning, and try to empower stakeholders to make better-informed decisions. While creating dashboards for teachers is common in Learning analytics, designing it with them is not that common, especially in hybrid systems and using data from both the online and face-to-face sessions. This paper will be discussing co-designing a teacher dashboard with teachers through participatory workshop and interview, after getting their goals and expectation for dashboard in hybrid system. To arrive to a dashboard prototype, conform with teachers' needs and expectations.},
  keywords={Conferences;Education;Data visualization;Prototypes;Stakeholders;Iterative methods;Hybrid learning;co-design;Human-centered design;Teacher's dashboard;Learning analytics;visualization},
  doi={10.1109/IRASET52964.2022.9738149},
  ISSN={},
  month={March},}@INPROCEEDINGS{9381148,
  author={Sigua, Edisson and Aguilar, Bryan and Pesántez-Cabrera, Paola and Maldonado-Mahauad, Jorge},
  booktitle={2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje (LACLO)}, 
  title={Proposal for the Design and Evaluation of a Dashboard for the Analysis of Learner Behavior and Dropout Prediction in Moodle}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid development of technology has meant that over the past two decades Information and Communications Technologies (ICT) become increasingly involved in the teaching process and seek to change traditional learning models. With the support of modern technology, virtual platforms that encourage the adoption of a new learning paradigm in which geographical/temporal limitations no longer pose a difficulty have been developed and refined. These virtual learning platforms, also known as Learning Management Systems (LMS), store student and teacher interactions with course resources, and these interactions are stored in database engines. However, all the information generated by LMS has not been processed in a way that is helpful for the use of teachers and students, mainly because in most cases, students' interactions with these systems focus on downloading class material, delivering assignments, and reading announcements, leaving aside indicators that can be presented in the form of visualizations that allow actions to be taken during the development of the learning process. Thus, this study proposes the design, implementation, and evaluation of a dashboard for the analysis of learner behavior and prediction of dropout on the Moodle platform. The proposed tool will help students to manage their learning process, easily and effectively monitor their progress in an online course, and teachers to know what students do before, during and after a virtual class. The latter for the purpose of being able to detect early students at risk of dropping out.},
  keywords={Visualization;Learning management systems;Tools;Information and communication technology;Proposals;Monitoring;Engines;Learning Analytics;Dashboard;Moodle;Dropout;Prediction},
  doi={10.1109/LACLO50806.2020.9381148},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10511389,
  author={Deshpande, K. V. and Asbe, Shubham and Lugade, Akanksha and More, Yash and Bhalerao, Dipali and Partudkar, Anuradha},
  booktitle={2024 3rd International Conference for Innovation in Technology (INOCON)}, 
  title={LTA (Learn to Analyze) - A Teacher-Centric Analytical Dashboard for Illustrating Students Academic Progress, Backed by Machine Learning for Informed Performance Enhancement Recommendations}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Previous research has firmly established that a communication gap between teachers and students can have detrimental effects on the learning process and student behaviors. In our study, we aim to explore how the implementation of a teacher-centric analytical dashboard can serve as a vital tool in visualizing and addressing this gap [1].Our research underscores the critical role of monitoring each student’s academic progress by their teachers for the purpose of enhancing overall performance. This paper will delve into the significance of this practice and how an analytical dashboard tailored to the needs of educators can facilitate this process. Through this exploration, we will highlight the key features and advantages of a teacher-centric analytical dashboard in fostering effective communication and ultimately improving the learning experience for students.},
  keywords={Technological innovation;Education;Collaboration;Machine learning;Real-time systems;Planning;Monitoring;teacher facing dashboard;learning analytics;students;teachers;visualize;analyze;education field;machine learning;deep learning},
  doi={10.1109/INOCON60754.2024.10511389},
  ISSN={},
  month={March},}@INPROCEEDINGS{9251219,
  author={Farahmand, Arta and Dewan, M. Ali Akber and Lin, Fuhua},
  booktitle={2020 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={Student-Facing Educational Dashboard Design for Online Learners}, 
  year={2020},
  volume={},
  number={},
  pages={345-349},
  abstract={The current shift from traditional classrooms to online learning in higher education calls for more attention to self-regulated learning. This research is motivated by the growing interest in potential of using learning analytics dashboard (LAD) to increase individuals' self-regulation by creating visibility into their performance in various applications. This study explores how data visualization can be integrated with online learning to improve learners' performance through enhancing their skills in planning and organization. We are working on the design of a comprehensive LAD, focusing on micro-level of learning analytics to support learning activities of students. The LAD includes the following two features to enhance students' self-regulation in online learning: (1) a function to track students' progress compared to other students' over time; (2) reminders to help students with upcoming deadlines and auto-generating to do lists. The hypothesis is that the LAD will increase students' engagement, motivation, and self-regulation in an online learning environment. This study is significant because it contributes to the body of knowledge by exploring how student-generated data can be used to improve self-regulated learning. The practical contribution of this study is to create a personalized LAD for students based on the learner-generated data to benefit students' organization skill, planning skill, and motivation.},
  keywords={Correlation;Education;Data visualization;Organizations;Tools;Time measurement;Planning;learning analytics dashboard;online learning;learning management system;information visualization;data mining;self-regulated learning},
  doi={10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00067},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6601968,
  author={Vozniuk, Andrii and Govaerts, Sten and Gillet, Denis},
  booktitle={2013 IEEE 13th International Conference on Advanced Learning Technologies}, 
  title={Towards Portable Learning Analytics Dashboards}, 
  year={2013},
  volume={},
  number={},
  pages={412-416},
  abstract={This paper proposes a novel approach to build and deploy learning analytics dashboards in multiple learning environments. Existing learning dashboards are barely portable: once deployed on a learning platform, it requires considerable effort to deploy the dashboard elsewhere. We suggest constructing dashboards from lightweight web applications, namely widgets. Our approach allows to port dashboards with no additional cost between learning environments that implement open specifications (Open Social and Activity Streams) for data access and use widget APIs. We propose to facilitate reuse by sharing the dashboards and widgets via a centralized analytics repository.},
  keywords={Media;Context;Computer aided manufacturing;Software;Standards;Blogs;Google;learning analytics;dashboards;portability;open standards;widget;ActivityStreams;OpenSocial},
  doi={10.1109/ICALT.2013.126},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10345957,
  author={Tsoni, Rozita and Garani, Georgia and Verykios, Vassilios S.},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Incorporating Data Warehouses into Data Pipelines for Deploying Learning Analytics Dashboards}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={From the data loading to the final reporting, a Learning Analytics (LA) cycle should be an articulated yet structured and repeatable process. Data from the online students' activity can be arranged and organized in Data Warehouses (DWs) to facilitate pre-processing tasks. These data can feed an LA cycle for producing the final reporting. In this work, we propose an integrated process of educational data management for creating insightful knowledge. Firstly, an education-oriented DW schema is presented. Additionally, a data pipeline that loads data from the DW and supports all the LA processes is described. The results are presented to the front-end user through an LA dashboard that focuses on students' social interaction in their learning community. The process is tested in educational data from a Distance Learning postgraduate program.},
  keywords={Computer aided instruction;Pipelines;Decision making;Loading;Data warehouses;Stakeholders;Feeds;Learning Analytics;Data warehouses;Data Pipelines;Social Network Analysis;Dashboards},
  doi={10.1109/IISA59645.2023.10345957},
  ISSN={},
  month={July},}@INPROCEEDINGS{9637388,
  author={Costas-Jauregui, Vladimir and Oyelere, Solomon Sunday and Caussin-Torrez, Bernardo and Barros-Gavilanes, Gabriel and Agbo, Friday Joseph and Toivonen, Tapani and Motz, Regina and Tenesaca, Juan Bernardo},
  booktitle={2021 IEEE Frontiers in Education Conference (FIE)}, 
  title={Descriptive Analytics Dashboard for an Inclusive Learning Environment}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={The educational community continuously seeks ways to improve the learner-centered learning process through new approaches like Learning analytics and its dashboard, which is helpful to enhance the teaching and the learning process. It involves a process whose final goal is presenting results to support decision-making about improving the learning process. However, a descriptive Learning analytics interface for analyzing learning data of students, including the disadvantaged, where to view and interpret learners' historical data is -in general- missing in this research domain. Hence, more research is still required to establish the philosophy of learning analytics on inclusion with an interface for the stakeholders to understand learning and teaching in an inclusive learning environment. This paper fills this gap by providing an inclusive educational learning analytics dashboard to support teachers and students. This study aimed to present a learning analytics implementation in the context of a smart ecosystem for learning and inclusion. We gave the inclusive educational needs and discussed the workflow followed during the descriptive learning analytics dashboard development. Therefore, the study improved existing learning analytics dashboards with a descriptive approach and inclusiveness of students with disabilities. Owing to the software development nature of this study, agile methodology based on five stages was applied: requirement elicitation; data gathering; design and prototyping; implementation; and testing and integration. We performed an initial evaluation, which indicated that the dashboard is suitable for understanding teachers' and students' needs and expectations. Besides, the visualization of inclusive learning characteristics improves engagement and attainment of learning goals.},
  keywords={Visualization;Philosophical considerations;Navigation;Conferences;Education;Data visualization;Software;descriptive learning analytics;inclusion;learning environment},
  doi={10.1109/FIE49875.2021.9637388},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9824707,
  author={Amarasinghe, S. N. and Thalakumbura, T. M. D. D. and Wijewardena, M.D.N.K. and Perera, D.H. and Manathunga, Kalpani and Senaweera, Oshada},
  booktitle={2022 IEEE 7th International conference for Convergence in Technology (I2CT)}, 
  title={Remotify: The Emergency Remote Learning Solution using Learning Analytics}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Current pandemic situation has manipulated people to adapt to a new normal forcefully and due to the same reason education system is also evolving but the actual question is how productive the new methodologies utilized are. E-learning is not a novel concept but is becoming a necessity and the proposed platform could be identified as a direct response to the current emergency. This can also be known as an "ERT" situation; a shift of instructional delivery to an alternate delivery method in response to a crisis situation. The main intention in these situations is not to recreate a robust educational system but to provide access to institutions in a manner that is easy to set up and is dependable during an emergency while outperforming both E-learning & traditional classroom methods. To provide a solution to overcome barriers faced in a pandemic situation in a virtual classroom, the implemented system is encapsulated with a dashboard centralizing facts gathered from audio & video analyzing components which are analyzed against student performance utilizing personalized assessing techniques to deliver learning analytics.},
  keywords={Electronic learning;Pandemics;Education;Training data;Streaming media;Feature extraction;Real-time systems;Emergency Remote Teaching;virtual classroom;Dashboard;learning analytics},
  doi={10.1109/I2CT54291.2022.9824707},
  ISSN={},
  month={April},}@INPROCEEDINGS{10837632,
  author={Hirsch, Sunita and Uckelmann, Dieter},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Effective Feedback Systems in Learning Analytics: Didactic and Psychological Foundations, Implementations, and Perspectives}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Learning Analytics (LA) and LA-based feedback systems have made substantial advancements, providing tools and frameworks designed to improve educational outcomes. However, their long-term effectiveness is often constrained by a predominant focus on technical elements, which can overshadow crucial didactic, psychological, and design-related considerations. This paper introduces an integrative framework for designing LA-based feedback systems that mitigates these limitations by incorporating insights from cognitive and motivational theories. The framework aims to support the development of learner-centered environments that address various learning needs. Based on this framework, practical considerations and recommendations are provided to guide the implementation of feedback systems that move beyond technical constraints. An implemen-tation example illustrates how the framework can be applied using real-time data analysis and learner assessments aiming to improve the usability, effectiveness, and acceptance of feedback systems. This approach highlights the importance of integrating multidisciplinary perspectives in LA to achieve meaningful and impactful educational practices across diverse contexts.},
  keywords={Training;Data analysis;Refining;Psychology;Real-time systems;Usability;Information technology;Learning Analytics;Feedback;Dashboard;Learner-Centered Design;Educational Technology},
  doi={10.1109/ITHET61869.2024.10837632},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{7095994,
  author={Guenaga, Mariluz and Longarte, Jon Kepa and Rayon, Alex},
  booktitle={2015 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Standardized enriched rubrics to support competeney-assessment through the SCALA methodology and dashboard}, 
  year={2015},
  volume={},
  number={},
  pages={340-347},
  abstract={Universities have increasingly emphasized competencies as central elements of students' development. However, the assessment of these competencies is not an easy task. The availability of data that learners generate in computer mediated learning offers great potential to study how learning takes place, and thus, to gather evidences for competency-assessment using enriched rubrics. These are the so-called electronic assessment instruments. Among them, the enriched rubrics arises as a tool to improve the assessment process. However, the lack of data interoperability and the decentralization of those educational applications set out a challenge to exploit trace data. To face these problems we have designed and developed SCALA (Supporting Competency-Assessment through a Learning Analytics approach), an analytics system that integrates usage -how the user interacts with resources- and social -how students and teachers interact among them- trace data to support competency assessment. After presenting the components of SCALA (process, model and platform), we evaluate them presenting six scenarios to know whether it is viable in terms of time, sustainability and quality assurance to normalize the heterogeneous data present in technology-rich learning environments. The results show and confirm the viability of the proposed solution and the possibility to offer real-time feedback to the teachers to assess students'.},
  keywords={Decision support systems;Engineering education;Conferences;competency assessment;learning analytics;data workflow;teacher dashboard;knowledge discovery},
  doi={10.1109/EDUCON.2015.7095994},
  ISSN={2165-9567},
  month={March},}@ARTICLE{7959628,
  author={Charleer, Sven and Moere, Andrew Vande and Klerkx, Joris and Verbert, Katrien and De Laet, Tinne},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Learning Analytics Dashboards to Support Adviser-Student Dialogue}, 
  year={2018},
  volume={11},
  number={3},
  pages={389-399},
  abstract={This paper presents LISSA (Learning dashboard for Insights and Support during Study Advice), a learning analytics dashboard designed, developed, and evaluated in collaboration with study advisers. The overall objective is to facilitate communication between study advisers and students by visualizing grade data that is commonly available in any institution. More specifically, the dashboard attempts to support the dialogue between adviser and student through an overview of study progress, peer comparison, and by triggering insights based on facts as a starting point for discussion and argumentation. We report on the iterative design process and evaluation results of a deployment in 97 advising sessions. We have found that the dashboard supports the current adviser-student dialogue, helps them motivate students, triggers conversation, and provides tools to add personalization, depth, and nuance to the advising session. It provides insights at a factual, interpretative, and reflective level and allows both adviser and student to take an active role during the session.},
  keywords={Data visualization;Recommender systems;Context;Electronic mail;Tutorials;Interviews;Employee welfare;Information visualization;learning technologies},
  doi={10.1109/TLT.2017.2720670},
  ISSN={1939-1382},
  month={July},}@INPROCEEDINGS{10122065,
  author={Heredia-Jimenez, Vanessa and Yaguana, Jhony and Jimenez-Macıas, Alberto and Ortiz-Rojas, Margarita},
  booktitle={2023 Ninth International Conference on eDemocracy & eGovernment (ICEDEG)}, 
  title={Using Design-Based Research for an Academic Dropout and Retention Dashboard}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Student dropout and retention are a major concern in Higher Education Institutions(HEIs). HEIs use the benefits of Learning Analytics (LA) dashboards to address this concern by monitoring student's academic progress and identify students at risk. This study adds to the existing body of knowledge, the experience of designing, implementing, and evaluating a dropout and retention dashboard embedded in an academic counseling system. Through the use of a Design-Based Research methodology, we show the process of going from the needs analysis level, through 3 iterations to test and evaluate the dashboard, to end with preliminary design principles. The lessons learned serve as a guide for LA designers in the implementation of such dashboards.},
  keywords={Employee welfare;Visualization;Education;Monitoring;Learning dashboards;Analytical dashboard;Student retention;Data visualization;Academic advising;Design-Based Research},
  doi={10.1109/ICEDEG58167.2023.10122065},
  ISSN={2573-1998},
  month={April},}@INPROCEEDINGS{10072794,
  author={Pal, Neeti and Dahiya, Omdev},
  booktitle={2022 5th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Role of Learning Management System for Evaluating Students’ progress in Learning Environment}, 
  year={2022},
  volume={},
  number={},
  pages={1800-1806},
  abstract={The paper contributes to getting familiar with various tools and platforms incorporated with learning dashboards that provide digital teaching and learning. The article also includes the different components for learning analytics used by various universities in their LMSs dashboards to improve their teaching-learning achievements. Learning analytics dashboards plays a vital role in the virtual learning environment. These tools work by tracking learners’ data, analyzing data, and presenting the results by revealing the patterns of learners’ behavior and attitude. This paper contributes to an analysis of learning dashboards and tools. The article also explains how these tools track, extract and analyze the students’ learning progress and monitor their activities. Various visualization techniques are also discussed in this paper. This study will help determine the impact of using learning tools to evaluate learners’ learning outcomes.},
  keywords={Learning management systems;Electronic learning;Education;Decision making;Virtual environments;Optimized production technology;Data visualization;Learning Analytics;Learning Management System;Educational Data Mining;Learning Analytics Dashboard (LAD);Moodle;Visualization techniques},
  doi={10.1109/IC3I56241.2022.10072794},
  ISSN={},
  month={Dec},}@ARTICLE{10126127,
  author={Lee-Cultura, Serena and Sharma, Kshitij and Giannakos, Michail N.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Multimodal Teacher Dashboards: Challenges and Opportunities of Enhancing Teacher Insights Through a Case Study}, 
  year={2024},
  volume={17},
  number={},
  pages={181-201},
  abstract={Teacher dashboards provide insights on students' progress through visualizations and scores derived from data generated during teaching and learning activities (e.g., response times and task correctness) to improve teaching. Despite the potential usefulness of enhancing teacher dashboards, and the respective teaching practices, with rich information regarding students' cognitive and affective states (e.g., cognitive load), few studies on teacher dashboards have considered such information. In this study, we drew on contemporary developments of multimodal (MM) learning analytics and designed an MM teacher dashboard with a notification system. The proposed system: 1) receives data from various sensors; 2) computes relevant cognitive and affective measurements; 3) visualizes the resulting measurements in a clean customizable interface; and 4) notifies instructors during moments of interest, so they may determine an appropriate method to support struggling students. To evaluate our MM teacher dashboard, we first collected multimodal data (MMD), performance data, and video recordings of students' interactions during an in situ study where 26 students engaged with a motion-based learning task. Then, we used our MM teacher dashboard to present the collected MMD and video recordings to 20 experienced teachers and educational researchers and collected qualitative data regarding respondents' insights on the advantages and challenges of visualizing students' MMD. Results showed that teachers found an MM teacher dashboard enhanced with a notification system, useful to complement their pedagogical practices. We offer empirically founded guidelines for design and integration of an MM teacher dashboard with notification systems, aimed to enhance teachers' understanding of students' learning states (e.g., real-time awareness of students' stress).},
  keywords={Data visualization;Sensors;Task analysis;Real-time systems;Physiology;Education;Tracking;Educational technologies;learning analytics;multimodal;teacher dashboards},
  doi={10.1109/TLT.2023.3276848},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{9225939,
  author={Rohloff, Tobias and Sauer, Dominic and Meinel, Christoph},
  booktitle={2019 IEEE International Conference on Engineering, Technology and Education (TALE)}, 
  title={Student Perception of a Learner Dashboard in MOOCs to Encourage Self-Regulated Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={In online learning environments like Massive Open Online Courses (MOOCs), where teachers cannot provide individual support and guidance for thousands of students, self-regulated learning (SRL) is a critical metacognitive skillset for students' achievement. However, not every student intuitively self-regulates its learning and therefore technical solutions can help to apply SRL strategies. Learner dashboards with visualizations about the learner's progress and behavior are able to create awareness, encourage self-reflection, and perhaps motivate students to plan and adjust their learning behavior to achieve their learning objectives. Hence, such Learning Analytics tools can support the SRL strategies self-evaluation and strategic planning. To examine this potential, a learner dashboard was integrated into the HPI MOOC platform. This work presents the design process, the concept, and an evaluation of the first dashboard iteration. The perceived usefulness and usability are investigated, and in addition, the question will be considered whether the dashboard encourages students to apply self-regulated learning. The positive results pave the way for future research and a next iteration of the learner dashboard.},
  keywords={Electronic learning;Computer aided instruction;Strategic planning;Visualization;Tools;Data visualization;Monitoring;Learning Analytics;Learner Dashboard;MOOCs;Self-Regulated Learning;Technology-Enhanced Learning},
  doi={10.1109/TALE48000.2019.9225939},
  ISSN={2470-6698},
  month={Dec},}@INPROCEEDINGS{6901452,
  author={Manske, Sven and Hecking, Tobias and Bollen, Lars and Göhnert, Tilman and Ramos, Alfredo and Hoppe, H. Ulrich},
  booktitle={2014 IEEE 14th International Conference on Advanced Learning Technologies}, 
  title={A Flexible Framework for the Authoring of Reusable and Portable Learning Analytics Gadgets}, 
  year={2014},
  volume={},
  number={},
  pages={254-258},
  abstract={Technology supported learning is nowadays often based on heterogeneous environments that encompass not only one application and also possibly involve different devices. This creates specific challenges for data analysis and thus for learning analytics. In this paper, we propose a framework to create reusable learning analytics components that are portable to different target platforms. In this approach, the logic of each analysis component is specified in a separate web-based visual environment (or "workbench") from where it is later exported to the target environments form of a gadget-based dashboard. We demonstrate this mechanism in the context of the Go-Lab portal for accessing remote laboratories in STEM learning scenarios. An example shows how such analytics gadgets can be used to support collaboration inside the classroom.},
  keywords={Portals;Conferences;Context;Visualization;Knowledge engineering;Data visualization;Learning Analytics;CSCL;Inquiry Learning},
  doi={10.1109/ICALT.2014.80},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9368432,
  author={Weng, Jian-Xuan and Huang, Anna Y.Q. and Lu, Owen H.T. and Chen, Irene Y.L. and Yang, Stephen J.H.},
  booktitle={2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)}, 
  title={The Implementation of Precision Education for Learning Analytics}, 
  year={2020},
  volume={},
  number={},
  pages={327-332},
  abstract={This study is based on a novel conceptual framework, precision education, and takes a blended Python programming course as an example to explore how to implement precision education that includes diagnosis, prediction, prevention and treatment. Precision education follows the principles of personalized services for precision medicine. Its purpose is to strengthen the learning risk prediction and early intervention mentioned in emerging learning analytics through big data, artificial intelligence and other emerging technologies, thereby improving teacher teaching quality and student learning efficiency. This study is based on the design of the e-book learning dashboard, so that teachers can quickly understand students' learning status, and improve the e-book through students' feedback on the dashboard to achieve precision diagnosis. Next, this study uses machine learning algorithms to predict students' learning performance, and thus determine whether students are at-risk to achieve precision prediction. Finally, through the correspondence between reading strategy and reading sequence, and then clearly distinguish the types of students by grouping, and use it as a treatment target for precision treatment and prevention. It is hoped that this empirical study can be used as a case study for implementing precision education.},
  keywords={Electronic publishing;Education;Learning (artificial intelligence);Machine learning;Predictive models;Programming profession;Python;precision education;learning analytics;diagnosis;prediction;treatment;prevention;SQ3R},
  doi={10.1109/TALE48869.2020.9368432},
  ISSN={2470-6698},
  month={Dec},}@INPROCEEDINGS{6900177,
  author={Tobarra, Llanos and Ros, Salvador and Hernández, Roberto and Robles-Gómez, Antonio and Caminero, Agustín C. and Pastor, Rafael},
  booktitle={2014 XI Tecnologias Aplicadas a la Ensenanza de la Electronica (Technologies Applied to Electronics Teaching) (TAEE)}, 
  title={Integrated Analytic dashboard for virtual evaluation laboratories and collaborative forums}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a new Learning Analytics dashboard which integrates all the information gathered by a virtual evaluation laboratory deployed at our institution and, also, the collaborative evaluation forums used by students in our courses. As an example, a subject focused on the configuration of network services has been chosen to implement our approach. Our proposal will be able to graphically show the students' progress both in an experimental and collaborative way at the same time. Therefore, lecturers can guide each student through the learning process based on his/her particular knowledge-level and grade her/him at the end of the term. Some specific techniques are needed by the system, in our case Learning Analytics techniques are used, in order to observe the students' behavior and their level of proficiency. In particular, a set of evaluation events for each activity, the students' social network, the students' timeline for their activities and some relevant metrics associated to them are given.},
  keywords={Social network services;Collaboration;Laboratories;Context;Educational institutions;Communities;Learning Analytics (LA);Assessment and Evaluation Strategies;Virtual/Remote Laboratories;Collaborative Forums;Distance Education},
  doi={10.1109/TAEE.2014.6900177},
  ISSN={},
  month={June},}@INPROCEEDINGS{9638263,
  author={Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
  booktitle={2021 Swedish Workshop on Data Science (SweDS)}, 
  title={SBGTool: Similarity-Based Grouping Tool for Students’ Learning Outcomes}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={With the help of Visual Learning Analytics (VLA) tools, teachers can construct meaningful groups of students that can, for example, collaborate and be engaged in productive discussions. However, finding similar samples in large educational databases requires effective similarity measures that capture the teacher’s intent. In this paper we propose a web-based VLA tool called Similarity-Based Grouping (SBGTool), to assist teachers in categorizing students into different groups based on their similar learning outcomes and activities. By using SBGTool, teachers may compare individual students by considering the number of answers (correct and incorrect) in different question categories and time ranges, find the most difficult question categories considering the percentage of similarity to the correct answers, determine the degree of similarity and dissimilarity across students, and find the relationship between students’ activity and success. To demonstrate the tool’s efficacy, we used 10,000 random samples from the EdNet dataset, a large-scale hierarchical educational dataset consisting of student-system interactions from multiple platforms, at university level, collected over a period of two years. The results point to the conclusion that the tool is efficient, can be adapted to different learning domains, and has the potential to assist teachers in maximizing the collaborative learning potential in their classrooms.},
  keywords={Visualization;Databases;Conferences;Data visualization;Tools;Data science;Collaborative work;Visual Learning Analytics;Learning Analytics Dashboard;Similarity-Based Grouping;Data Visualization;Educational Data;EdNet},
  doi={10.1109/SweDS53855.2021.9638263},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7751805,
  author={Einhardt, Luan and Tavares, Tatiana Aires and Cechinel, Cristian},
  booktitle={2016 XI Latin American Conference on Learning Objects and Technology (LACLO)}, 
  title={Moodle analytics dashboard: A learning analytics tool to visualize users interactions in moodle}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The present work describes the Moodle Analytics Dashboard (MAD), a tool developed to allow the visualization of students and professors logs in Moodle disciplines. MAD provides an easy way to obtain graphical visualization of several aspects related to students and professors accesses in virtual learning disciplines, thus helping professors to better follow teaching and learning process, as well as to visually identify potential at-risk students, or to better understand how the different educational resources are being used. The paper presents the theoretical foundations and the technologies used to develop MAD, together with the most important features of the tool and the first results obtained during the preliminary stages of validation.},
  keywords={Visualization;Education;Indexes;Bills of materials;Information services;Electronic publishing;Internet;Learning analytics;dashboards;Moodle;logs;visualization;interactions},
  doi={10.1109/LACLO.2016.7751805},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7942988,
  author={Alonso-Fernandez, Cristina and Calvo, Antonio and Freire, Manuel and Martinez-Ortiz, Ivan and Fernandez-Manjon, Baltasar},
  booktitle={2017 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Systematizing game learning analytics for serious games}, 
  year={2017},
  volume={},
  number={},
  pages={1111-1118},
  abstract={Applying games in education provides multiple benefits clearly visible in entertainment games: their engaging, goal-oriented nature encourages students to improve while they play. Educational games, also known as Serious Games (SGs) are video games designed with a main purpose other than pure entertainment; their main purpose may be to teach, to change an attitude or behavior, or to create awareness of a certain issue. As educators and game developers, the validity and effectiveness of these games towards their defined educational purposes needs to be both measurable and measured. Fortunately, the highly interactive nature of games makes the application of Learning Analytics (LA) perfect to capture students' interaction data with the purpose of better understanding or improving the learning process. However, there is a lack of widely adopted standards to communicate information between games and their tracking modules. Game Learning Analytics (GLA) combines the educational goals of LA with technologies that are commonplace in Game Analytics (GA), and also suffers from a lack of standards adoption that would facilitate its use across different SGs. In this paper, we describe two key steps towards the systematization of GLA: 1), the use of a newly-proposed standard tracking model to exchange information between the SG and the analytics platform, allowing reusable tracker components to be developed for each game engine or development platform; and 2), the use of standardized analysis and visualization assets to provide general but useful information for any SG that sends its data in the aforementioned format. These analysis and visualizations can be further customized and adapted for particular games when needed. We examine the use of this complete standard model in the GLA system currently under development for use in two EU H2020 SG projects.},
  keywords={Games;Standards;Education;Entertainment industry;Data visualization;Measurement;Analytical models;game analytics;serious games;e-learning;dashboard;xAPI},
  doi={10.1109/EDUCON.2017.7942988},
  ISSN={2165-9567},
  month={April},}@ARTICLE{7542151,
  author={Schwendimann, Beat A. and Rodríguez-Triana, María Jesús and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Perceiving Learning at a Glance: A Systematic Literature Review of Learning Dashboard Research}, 
  year={2017},
  volume={10},
  number={1},
  pages={30-41},
  abstract={This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining. Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes. Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs). The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis. Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation. As the research field is still relatively young, most studies are exploratory and proof-of-concept. The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards. There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs.},
  keywords={Data mining;Data visualization;Systematics;Proposals;Bibliographies;Databases;Context;Learning analytics;educational data mining;information visualization;dashboards;systematic review},
  doi={10.1109/TLT.2016.2599522},
  ISSN={1939-1382},
  month={Jan},}@INPROCEEDINGS{9155901,
  author={Ada, Mireilla Bikanga and Turinicova, Katarina},
  booktitle={2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Developing a Dual Dashboard Early Detection System}, 
  year={2020},
  volume={},
  number={},
  pages={155-157},
  abstract={This paper describes the development of `StudentsAtRisk', a prototype early detection system. It is based on engagement with course materials and can be used to identify students who are falling behind by automatically flagging them. The system also allows instructors to flag these students manually. On their dashboard, students can flag themselves, as engagement with the material might not reveal all those who struggle.},
  keywords={Alarm systems;Systems architecture;Measurement;Conferences;Prototypes;Education;Monitoring;learning analytics;at-risk student;higher education;early warning systems;early detection systems},
  doi={10.1109/ICALT49669.2020.00052},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10735033,
  author={Abdullah, Aziman and Jieyu, Pang and Majid, Mazlina Abdul},
  booktitle={2024 Arab ICT Conference (AICTC)}, 
  title={Smart Attendance and Engagement Dashboard for Smart Education}, 
  year={2024},
  volume={},
  number={},
  pages={6-10},
  abstract={This study aims to measure student engagement and attendance in blended learning environments with innovative systems based on cloud services. The system goes beyond traditional attendance tracking methods by providing educators with data on students' learning behaviors, including their level of participation and interest in the subject matter. The dashboard is based on cloud technology, which allows educators and policymakers to access and analyze data easily. The system's comprehensive data capture can help educators better understand their students' learning behaviors and make informed decisions about how to support their success. By providing policymakers with accurate and up-to-date information, this system has the potential to inform education policy and allocate resources more effectively to support student success.},
  keywords={Data privacy;Visualization;Accuracy;Data analysis;Atmospheric measurements;Educational technology;Passwords;Particle measurements;Information and communication technology;Hybrid learning;smart attendance;learning analytics},
  doi={10.1109/AICTC58357.2024.10735033},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9576443,
  author={Akintunde, Ruth Okoilu and Limke, Ally and Barnes, Tiffany and Heckman, Sarah and Lynch, Collin},
  booktitle={2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={PEDI - Piazza Explorer Dashboard for Intervention}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={Analytics about how students navigate online learning tools throughout the duration of an assignment is scarce. Knowledge about how students use online tools before a course's end could positively impact students' learning outcomes. We introduce PEDI (Piazza Explorer Dashboard for Intervention), a tool which analyzes and presents visualizations of forum activity on Piazza, a question and answer forum, to instructors. We outline the design principles and data-informed recommendations used to design PEDI. Our prior research revealed two critical periods in students' forum engagement over the duration of an assignment. Early engagement in the first half of an assignment duration positively correlates with class average performance. Whereas, extremely high engagement toward the deadline predicted lower class average performance. PEDI uses these findings to detect and flag troubling engagement levels and informs instructors through clear visualizations to promote data-informed interventions. By providing insights to instructors, PEDI may improve class performance and pave the way for a new generation of online tools.},
  keywords={Visualization;Histograms;Navigation;Tools;Frequency control;learning analytics dashboards;forum activity;real time visualizations},
  doi={10.1109/VL/HCC51201.2021.9576443},
  ISSN={1943-6106},
  month={Oct},}@INPROCEEDINGS{10645943,
  author={Yamada, Masanori and Geng, Xuewang and Goda, Yoshiko and Teasley, Stephanie D.},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Investigating Metacognitive Behaviors with Online Learning Support Tools}, 
  year={2024},
  volume={},
  number={},
  pages={280-284},
  abstract={As information technology advanced, accuracy of technology-driven assessment is being improved. In order to assess learning performance and awareness, assessment of metacognition level with technology can be useful to understand learner’s learning comprehension and awareness. Metacognition is one of the most important elements for successful learning. However, current way to evaluate metacognition level focuses on psychological method such as questionnaire and interview. The recent growth of learning analytics research has demonstrated the relationships between metacognition, learning awareness, and learning behaviors. This study aims to investigate metacognitive learning behaviors using small grain data on eBook and learning analytics dashboard (LAD) over eight weeks in a university course. To do so, we determined high and low metacognitive learner groups using the Metacognitive Awareness Inventory and investigated the differences between the two groups in eBook and LAD. The findings suggest that four learning behaviors eBook and LAD were detected as metacognitive learning behaviors, and contribute to the improvement of technology-driven assessment.},
  keywords={Electronic publishing;Accuracy;Psychology;Metacognition;Interviews;Information technology;Metacognition;Learning behavior;Small-grain data;Learning analytics},
  doi={10.1109/ICALT61570.2024.00088},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10604520,
  author={Navarro, Miriam and Becerra, Álvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
  booktitle={2024 International Symposium on Computers in Education (SIIE)}, 
  title={VAAD: Visual Attention Analysis Dashboard Applied to e-Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we present an approach in the Multimodal Learning Analytics field. Within this approach, we have developed a tool to visualize and analyze eye movement data collected during learning sessions in online courses. The tool is named VAAD -an acronym for Visual Attention Analysis Dashboard-. These eye movement data have been gathered using an eye-tracker and subsequently processed and visualized for interpretation. The purpose of the tool is to conduct a descriptive analysis of the data by facilitating its visualization, enabling the identification of differences and learning patterns among various learner populations. Additionally, it integrates a predictive module capable of anticipating learner activities during a learning session. Consequently, VAAD holds the potential to offer valuable insights into online learning behaviors from both descriptive and predictive perspectives.},
  keywords={Computers;Visualization;Electronic learning;Terminology;Biometrics (access control);Sociology;Education;biometrics;dashboard;eye-tracker;learning analytics;machine learning;multimodal learning;online learning},
  doi={10.1109/SIIE63180.2024.10604520},
  ISSN={2476-2172},
  month={June},}@INPROCEEDINGS{7839503,
  author={Lu, Owen H.T. and Huang, Anna Y.Q. and Huang, Jeff C.H. and Huang, Chester S.J. and Yang, Stephen J.H.},
  booktitle={2016 International Conference on Educational Innovation through Technology (EITT)}, 
  title={Early-Stage Engagement: Applying Big Data Analytics on Collaborative Learning Environment for Measuring Learners' Engagement Rate}, 
  year={2016},
  volume={},
  number={},
  pages={106-110},
  abstract={Computer-supported Collaborative Learning (CSCL) is a pedagogical strategy associated with how learners construct knowledge with a group by computer-based learning system. In recent years, most of the computer-based learning systems record the interaction log of each learner when developing course assignments. However, the recorded data is facing a challenge to expose the learners behaviors during the course and to design a computer-supported collaborative learning activity. To address those challenges in this paper, a novel collaborative programming tool called Software Project Development and Insight Learning Environment (SPDI Learning Environment) is described. The SPDI Learning environment allows learners of computer science to develop course assignments collaboratively. Besides, it allows instructors to investigate the learners behaviors by associating a web-based integrated development environment (IDE) with Big Data analysis pipeline and Visualization Dashboard. In addition to collect real data from courses, we designed learning activities to help teachers to engage the field of CSCL and Learning Analytics.},
  keywords={Programming;Collaboration;Collaborative work;Big data;Software;Algorithm design and analysis;Education;Computer-supported Collaborative Learning;Learning Analytics;Collaborative Programming;Clickstream Data;Big-Data Analysis},
  doi={10.1109/EITT.2016.28},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8001777,
  author={Seanosky, Jeremie and Guillot, Isabelle and Boulanger, David and Guillot, Rébecca and Guillot, Claudia and Kumar, Vivekanandan and Fraser, Shawn N. and Kinshuk and Aljojo, Nahla and Munshi, Asmaa},
  booktitle={2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Real-Time Visual Feedback: A Study in Coding Analytics}, 
  year={2017},
  volume={},
  number={},
  pages={264-266},
  abstract={Higher dropout and failure rates among computer science students in introductory programming courses tend to be a norm for many institutions. Years of evidence indicate that dropouts and failures persist in spite of advancements in pedagogy, technology, and teacher training. Most advancements have relied on summative assessments and of late formative assessments. This research explores assessments computed from real-time measures, based on observational data collected during student engagement with study and remedial activities. An experiment was conducted to measure the impact of real-time code assessment and dashboard-based feedback in the domain of Programming. Results indicate better course grades for a small percentage of students, and the need for task-level and meta-level interactions to guarantee significant and persistent academic performance and programming mastery.},
  keywords={Programming;Tools;Encoding;Real-time systems;Java;Visualization;Correlation;coding analytics;formative;sommative;interactive dashboard;performance;self-regulation},
  doi={10.1109/ICALT.2017.38},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{6826107,
  author={Orduña, Pablo and Almeida, Aitor and López-de-Ipiña, Diego and Garcia-Zubia, Javier},
  booktitle={2014 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Learning Analytics on federated remote laboratories: Tips and techniques}, 
  year={2014},
  volume={},
  number={},
  pages={299-305},
  abstract={A remote laboratory is a software and hardware tool which enables students to use real equipment -located in an educational institution- through the Internet. This way, students can experiment as if they were using the laboratories with their own hands. And, depending on the design, instructors can later see the results of these students. During the last decade, federation protocols to share remote laboratories have emerged. The focus of these protocols is to be make remote laboratories of one institution available in other in an automated manner, through institutional contracts. And these federation protocols usually rely on existing Remote Laboratory Management Systems (RLMS), which usually provide APIs for tracking student usage. At the same time, the interest on Learning Analytics is increasing. Learning Analytics focuses on the measurement and analysis of data about learners in their context. In the particular context of federated remote laboratories, new challenges arise: on the one hand, remote laboratories must be prepared to track insightful information from the student session so as to extract patterns, and on the other hand, the usage of a federated environment requires different degrees of anonymity. This contribution describes the new Learning Analytics dashboard of WebLab-Deusto, detailing what information can be extracted and how the usage of a RLMS simplifies the development of such tools in a federated environment.},
  keywords={Remote laboratories;Educational institutions;Protocols;Engineering education;Internet;Context},
  doi={10.1109/EDUCON.2014.6826107},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{9853790,
  author={Helgert, André and Canbulat, Anil and Lingnau, Andreas and Straßmann, Carolin},
  booktitle={2022 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={A Framework for Analyzing Interactions in a Video-based Collaborative Learning Environment}, 
  year={2022},
  volume={},
  number={},
  pages={125-127},
  abstract={Studying in social isolation is a reality for many students that was further reinforced after the start of the COVID-19 pandemic. Research shows that isolation can lead to decreased learning efficiency and is intensified by the increased asynchronous online teaching during the pandemic. This change is not only challenging for students, but also for teachers, as students do not have a direct communication and feedback channel when learning content is presented in form of pre-recorded videos in a learning management system. In this paper, we present VGather2Learn Analytics, which is an extension to the already existing collaborative learning system VGather2Learn, which makes it possible for teachers to analyse the learning behavior of students in asynchronous video-teaching. The information presented in a dashboard will allow teachers to better understand how students interact while watching learning videos collaboratively and can improve online-teaching.},
  keywords={COVID-19;Learning management systems;Pandemics;Distance learning;Collaboration;Collaborative work;Behavioral sciences;Learning Analytics;Computer-supported Collaborative Learning;Social Learning},
  doi={10.1109/ICALT55010.2022.00045},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9725212,
  author={Maldonado-Mahauad, Jorge and Aguilar, Bryan and Sigua, Edisson},
  booktitle={2021 XVI Latin American Conference on Learning Technologies (LACLO)}, 
  title={FlipMyLearning: A Tool for Monitoring and Predicting Learner Behavior in Moodle}, 
  year={2021},
  volume={},
  number={},
  pages={16-23},
  abstract={The development of technology has meant that in the last two decades Information and Communication Technologies have become more and more involved in the teaching process and have tried to change traditional learning models. With the support of modern technology, platforms have been developed and perfected that encourage the adoption of a new virtual learning paradigm. These platforms store student and teacher interactions with course resources in database engines, information that can be very relevant, but in many cases has not been processed in a way that is useful for use by teachers and students. Therefore, this study aims to implement and evaluate a dashboard for student behavior analysis and dropout prediction in Moodle. The tool will help teachers to know what students do before, during and after a class mediated by virtual platforms. In addition, it will also help students manage their learning process and easily and effectively monitor their progress in the course. Given the analytical nature of the research, exploratory analysis of the Moodle data model, evaluation of existing visualizations and design of the tool based on Moodle architecture were used to develop a dashboard of visualizations and dropout prediction. As a result, FlipMyLearning was implemented, a plugin for the Moodle platform that allows the teacher to monitor the learning process of students for informed decision making. The developed plugin contains visualizations for both the teacher and the student, divided into different sections, each oriented to monitor different aspects of the course. The research conducted shows that the visualizations generated were useful for both teachers and students who participated in the evaluation process. In addition, variables such as time spent, number of sessions and indicators related to cognitive depth and social breadth are useful variables to identify groups of students at risk of dropping out.},
  keywords={Electronic learning;Databases;Education;Decision making;Data visualization;Data models;Information and communication technology;Learning Analytics;Dashboard;Moodle;Dropout;Prediction},
  doi={10.1109/LACLO54177.2021.00010},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8883651,
  author={Sébastien, Véronique and Sébastien, Didier and Timol, Ilias and Gay, Dominique and Cucchi, Alain and Porlier, Christophe},
  booktitle={2019 Conference on Next Generation Computing Applications (NextComp)}, 
  title={Moodleboard: Dynamic and Interactive Indicators for Teachers and Pedagogical Engineers}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={In this article, we present Moodleboard, a dynamic and interactive dashboard which can be used as a decision support tool by pedagogical engineers and Moodle platforms administrators. These users can explore various indicators in an interactive way in order to obtain statistics about online courses with different granularity levels, but also detect remarkable courses and their types, classify courses, detect misuses or innovations implemented by teaching or administrative teams in the organization. This work also aims at proposing models for digital courses in Moodle, in order to facilitate their adaptation to full-online distance learning.},
  keywords={Tools;Education;Data warehouses;Monitoring;Data visualization;Principal component analysis;Organizations;dashboard;learning analytics;decision support;pedagogical platform;clustering},
  doi={10.1109/NEXTCOMP.2019.8883651},
  ISSN={},
  month={Sep.},}@ARTICLE{8789402,
  author={Vázquez-Ingelmo, Andrea and Garcia-Peñalvo, Francísco J. and Therón, Roberto},
  journal={IEEE Access}, 
  title={Information Dashboards and Tailoring Capabilities - A Systematic Literature Review}, 
  year={2019},
  volume={7},
  number={},
  pages={109673-109688},
  abstract={The design and development of information dashboards are not trivial. Several factors must be accounted; from the data to be displayed to the audience that will use the dashboard. However, the increase in popularity of these tools has extended their use in several and very different contexts among very different user profiles. This popularization has increased the necessity of building tailored displays focused on specific requirements, goals, user roles, situations, domains, etc. Requirements are more sophisticated and varying; thus, dashboards need to match them to enhance knowledge generation and support more complex decision-making processes. This sophistication has led to the proposal of new approaches to address personal requirements and foster individualization regarding dashboards without involving high quantities of resources and long development processes. The goal of this work is to present a systematic review of the literature to analyze and classify the existing dashboard solutions that support tailoring capabilities and the methodologies used to achieve them. The methodology follows the guidelines proposed by Kitchenham and other authors in the field of software engineering. As results, 23 papers about tailored dashboards were retrieved. Three main approaches were identified regarding tailored solutions: customization, personalization, and adaptation. However, there is a wide variety of employed paradigms and features to develop tailored dashboards. The present systematic literature review analyzes challenges and issues regarding the existing solutions. It also identifies new research paths to enhance tailoring capabilities and thus, to improve user experience and insight delivery when it comes to visual analysis.},
  keywords={Systematics;Bibliographies;Tools;Visualization;Planning;User experience;Artificial intelligence;SLR;systematic literature review;tailoring;custom;personalized;adaptive;information dashboards},
  doi={10.1109/ACCESS.2019.2933472},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7427189,
  author={Pantazos, Kostas and Vatrapu, Ravi},
  booktitle={2016 49th Hawaii International Conference on System Sciences (HICSS)}, 
  title={Enhancing the Professional Vision of Teachers: A Physiological Study of Teaching Analytics Dashboards of Students' Repertory Grid Exercises in Business Education}, 
  year={2016},
  volume={},
  number={},
  pages={41-50},
  abstract={This paper reports on a study of the design, development and evaluation of two teaching analytics dashboards that visualize students' repertory grid exercise data. The technical objective of the dashboards is to support teachers to investigate and compare personal constructs and element ratings by students for given topics of study at the individual student, group or classroom levels of analysis. The pedagogical objective of the dashboards is to facilitate formative assessment feedback to students and feed-forward refinements to ongoing instructional practices. The teaching analytics dashboards were evaluated with six university teachers in a bio-metric usability study with integrated physiological and performance measures. Eye-tracking data from the two dashboards showed the relative importance of dashboard areas in each case in terms of aggregate gaze allocation. Findings informed the iterative design of the dashboards leading to teachers not being adversely affected by the visual clutter of the less important dashboard areas in their pedagogical decision-making. The results also showed that the dashboards were efficient and effective from a task performance perspective and were rated to be pleasant from a subjective satisfaction perspective. Regarding education technology innovation, teachers reported that such dashboards are lacking in their regular practice and would recommend their use in formal business educational settings.},
  keywords={Education;Visualization;Data visualization;Usability;Physiology;Decision making;Cognition;Teaching analytics;dashboards;repertory grid;bio-metric usability study},
  doi={10.1109/HICSS.2016.14},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{8658596,
  author={Azcona, David and Hsiao, I-Han and Smeaton, Alan F.},
  booktitle={2018 IEEE Frontiers in Education Conference (FIE)}, 
  title={Personalizing Computer Science Education by Leveraging Multimodal Learning Analytics}, 
  year={2018},
  volume={},
  number={},
  pages={1-9},
  abstract={This Research Full Paper implements a framework that harness sources of programming learning analytics on three computer programming courses a Higher Education Institution. The platform, called PredictCS, automatically detects lower-performing or “at-risk” students in programming courses and automatically and adaptively sends them feedback. This system has been progressively adopted at the classroom level to improve personalized learning. A visual analytics dashboard is developed and accessible to Faculty. This contains information about the models deployed and insights extracted from student's data. By leveraging historical student data we built predictive models using student characteristics, prior academic history, logged interactions between students and online resources, and students' progress in programming laboratory work. Predictions were generated every week during the semester's classes. In addition, during the second half of the semester, students who opted-in received pseudo real-time personalised feedback. Notifications were personalised based on students' predicted performance on the course and included a programming suggestion from a top-student in the class if any programs submitted had failed to meet the specified criteria. As a result, this helped students who corrected their programs to learn more and reduced the gap between lower and higher-performing students.},
  keywords={Predictive models;Computational modeling;Programming profession;Education;Data models;Python;Computer Science Education;Learning Analytics;Predictive Modelling;Peer Learning;Machine Learning;Educational Data Mining},
  doi={10.1109/FIE.2018.8658596},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{9217949,
  author={Amarasinghe, Ishari and Hernández-Leo, Davinia and Michos, Konstantinos and Vujovic, Milica},
  journal={IEEE Transactions on Learning Technologies}, 
  title={An Actionable Orchestration Dashboard to Enhance Collaboration in the Classroom}, 
  year={2020},
  volume={13},
  number={4},
  pages={662-675},
  abstract={The orchestration of collaborative learning activities in technology-enhanced classrooms has become a nontrivial endeavor for educators. Depending on the behaviors and needs of students that emerge in real educational situations, educators may need to orchestrate activity adaptations on the fly. These adaptations may range from the provision of additional scaffolding by the educator (e.g., the educator's participation in a group discussion) to a change in the planned pedagogical scenario (e.g., the duration). This article aims to contribute to the orchestration of technology-mediated collaborative learning sessions in a classroom context. We present the design, implementation, and evaluation of a teacher-facing dashboard that supports teachers in orchestrating scripted collaboration. Evaluation studies were conducted in 16 classroom sessions. The findings indicate that teachers found the information on the dashboard to be actionable and help facilitate just in time support to student groups.},
  keywords={Collaboration;Tools;Collaborative work;Real-time systems;Task analysis;Stakeholders;Monitoring;Collaborative learning;dashboards;learning analytics (LA);learning technologies;orchestration;scripts.},
  doi={10.1109/TLT.2020.3028597},
  ISSN={1939-1382},
  month={Oct},}@ARTICLE{7738510,
  author={Mejia, Carolina and Florian, Beatriz and Vatrapu, Ravi and Bull, Susan and Gomez, Sergio and Fabregat, Ramon},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A Novel Web-Based Approach for Visualization and Inspection of Reading Difficulties on University Students}, 
  year={2017},
  volume={10},
  number={1},
  pages={53-67},
  abstract={Existing tools aim to detect university students with early diagnosis of dyslexia or reading difficulties, but there are not developed tools that let those students better understand some aspects of their difficulties. In this paper, a dashboard for visualizing and inspecting early detected reading difficulties and their characteristics, called PADA (acronym for the Spanish name Panel de Analíticas de Aprendizaje de Dislexia en Adultos), is presented. PADA is a web-based tool designed to facilitate the creation of descriptive visualizations required for a better understanding by students about their learner model. Through information visualization techniques, PADA shows students the knowledge in their learner models in order to help them to increase their awareness and to support reflection and self-regulation about their difficulties in reading. PADA provides different learning analytics on reading performance of students, so that they can self-identify their strengths and weaknesses and self-regulate their learning. This paper describes examples that cover a variety of visualizations (bar-charts, line-charts, and pie-charts) to show user model fragments as personal details, reading profiles, learning styles, and cognitive traits of the students. We tested PADA with 26 students (aged 21-53 years) of different academic programs and levels, dyslexic and non-dyslexic. The results show that PADA can assist students in creating awareness, and help them to understand their difficulties associated with the reading tasks, as well as facilitate reflection and self-regulation in the learning process. Implications for the design of learning analytics are discussed and directions for future work are outlined.},
  keywords={Reflection;Electronic mail;Visualization;Analytical models;Inspection;Education;Terminology;Dyslexia;university students;reading difficulties;open learner modeling;learning analytics solutions},
  doi={10.1109/TLT.2016.2626292},
  ISSN={1939-1382},
  month={Jan},}@INPROCEEDINGS{6826111,
  author={Rayon Jerez, Alex and Guenaga, Mariluz and Núñez, Asier},
  booktitle={2014 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A web platform for the assessment of competences in Mobile Learning Contexts}, 
  year={2014},
  volume={},
  number={},
  pages={321-329},
  abstract={Society demands new competences from professionals, who require having specific skills and abilities. Universities, accordingly, have changed from a content-based towards a competency-based educational model. However, the assessment of these competences is not a scalable task, has a subjective nature and must consider data from many different sources. This paper describes the model, architecture and objectives of an on-going research project aimed at developing a web platform called LACAMOLC, to provide teachers and students a dashboard which gathers usage and social data from different Knowledge and Learning Technologies such as Moodle, Google Apps for Education and MediaWiki to provide visual and learning analytics visualizations to support learning and assessment process. We select Pentaho as our analytics specific tool, based on its characteristics in order to effectively scale learning analytics systems and achieve long-term sustainability and scalability, and we design an experiment to carry out for teamwork competence.},
  keywords={Mobile communication;Context;Educational institutions;Mobile handsets;Web services;Google;competence assessment;knowledge and learning technologies;learning analytics;mobile learning},
  doi={10.1109/EDUCON.2014.6826111},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10216270,
  author={Shuhaiber, Ahmed and Alkuwaiti, Aysha and Alremeithi, Mera and Almenhali, Hamda},
  booktitle={2023 International Conference on Smart Applications, Communications and Networking (SmartNets)}, 
  title={The Development of Smart E-Portfolio Generator System for University students: An SDLC Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={E-portfolio is a creative tool for documenting, analysing and monitoring students’ learning achievements and milestones. An e-portfolio is a computerized collection of documents and certifications that reflect a university student, such as demos, resources, and accomplishments. Since earning a university degree is not enough anymore and other soft and technical skills and certification are required, it became hard for students and graduates to collect and display their achievements in one environment, especially ones with imposter syndrome. Therefore, an e-portfolio generator system has been proposed to collect, store and display user’s documents and certifications in a dashboard. The methodology followed to develop this system is System Development Life Cycle (SDLC). The E-portfolio generator system is a user-friendly system. It enables the users to upload user documents, live-chat, dashboard creation and receiving alerts. Furthermore, the system will optimize the process of gathering, displaying, and storing user’s data in one dashboard. The research is concluded with conclusions and suggestions for further improvement.},
  keywords={Generators;Certification;Monitoring;E-Portfolio;Live-chat;Generator;Users;Dashboard},
  doi={10.1109/SmartNets58706.2023.10216270},
  ISSN={},
  month={July},}@INPROCEEDINGS{8725222,
  author={Martínez-Ortiz, Iván and Pérez-Colado, Iván and Rotaru, Dan Cristian and Freire, Manuel and Fernández-Manjón, Baltasar},
  booktitle={2019 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={From Heterogeneous Activities to Unified Analytics Dashboards}, 
  year={2019},
  volume={},
  number={},
  pages={1108-1113},
  abstract={Teachers often wish to integrate activities from disparate sources into their courses. For example, gamified activities, mediated through technology, can promote the type of active learning required to develop higher-level engagement by students. However, unless the activities have been designed to facilitate it, integrating their analytics into a single dashboard can require significant development effort. A general solution to such heterogeneous analytics integration can be of great value, by presenting a single view of student actions throughout the different parts of a course. We describe the problems presented when integrating the analytics of three heterogeneous stand-alone activities, in the context of a EU project to improve software engineering teaching. The idea is to increase student engagement via gamification, and explore the design space of possible solutions for providing integrated analytics over the heterogeneous activities. We then describe the design of a proof-of-concept implementation, based on the use of both xAPI trackers and simple CSV files for information exchange, single sign-on, a minimal class management web application, and updates to the analytics platform to allow dynamic changes in the multi-level analysis. The resulting approach can be readily applied to similar heterogeneous scenarios.},
  keywords={Servers;Authentication;Software;Games;Buildings;Engineering education;learning analytics;serious games;analytics},
  doi={10.1109/EDUCON.2019.8725222},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10499493,
  author={Tretow-Fish, Tobias Alexander Bang and Andersen, Jesper Fink and Khalid, Md. Saifuddin},
  booktitle={2024 International Conference on Advances in Computing, Communication, Electrical, and Smart Systems (iCACCESS)}, 
  title={Prototyping an Adaptive Learning Platform's Learning Analytic Dashboards on Behavioral Data to Support Teachers' Pedagogical Actions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The behavioural data analysis from Adaptive Learning Platforms (ALPs) is used to create Learning Analytical Dashboards (LADs), which can provide teachers with an overview and recommend pedagogical actions as feedback on students' behaviour. Existing research focuses on demonstrating ALP value through retaining student engagement and prediction of performance, designing multi-modal data, applying algorithms, and improving software and learning systems. Still, it lacks methods for evaluating ALP's LADs as they are applied with a pedagogical aim. Our study addresses the empirical research gap of pedagogically grounded ALP LAD prototypes. The pro-totypes analyse student behaviour, aiming at enhancing ALP functionality and assisting teachers in pedagogical reflection. We analysed activity logs from 397 nursing students of Denmark's University College Absalon from Fall 2020 to Fall 2023 using R. Our study explains students' behaviour, content difficulty, meta-cognition, and performance through two LAD prototypes and aligns insights with learning theories. Results show that while ‘Activity Labyrinths' occurrences are infrequent, our first LAD prototype enables teacher awareness of autonomy-related motivational issues. In the second LAD prototype, teachers find the LAD difficult to comprehend. Additionally, the study addresses the black box issue which hinders the design of ALP LADs by utilising behavioural data along with qualitative data in prototyping pedagogically founded LAD prototypes.},
  keywords={Learning systems;Adaptive learning;Data analysis;Software algorithms;Prototypes;Closed box;Metacognition;Learning Analytic Dashboards;Adaptive Learning Platform;Prototyping;Pedagogical Actions},
  doi={10.1109/iCACCESS61735.2024.10499493},
  ISSN={},
  month={March},}@ARTICLE{9609593,
  author={Jin, Sung-Hee},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Educational Effects on the Transparency of Peer Participation Levels in Asynchronous Online Discussion Activities}, 
  year={2021},
  volume={14},
  number={5},
  pages={604-612},
  abstract={Participation dashboards in online discussions are learning support tools that can have a positive effect on learners&#x2019; learning outcomes and satisfaction levels, but their effectiveness differs according to how learners recognize and interpret them. However, there is a lack of research investigating the effectiveness of visualization methods regarding learners&#x2019; participation levels. Accordingly, in this study, two visualization methods are applied to participation dashboards to show peer participation levels and to support online discussion activities. The Transparent Participation Dashboard (TPD) provides the exact participation levels for all learners who participate in an online discussion, whereas the Private Participation Dashboard (PPD) visualizes a learner&#x0027;s relative level of participation in comparison to the average value of a class. This study aimed to compare the effects of these two types of participation dashboards on the behavioral, cognitive, and affective aspects of online discussion activities. Toward this end, we conducted an experimental study. The participants included 62 undergraduate students who were randomly assigned to two groups. Thirty-two students were assigned to the Transparent group, which received the TPD. Thirty students were assigned to the Private group, which received the PPD. Our findings showed no significant difference in usability, quality of discussions, or learning outcomes between the two groups. However, the Transparent group was more active in its online discussions and expressed more negative satisfaction with the dashboard. This study&#x0027;s conclusions suggest that dashboards for promoting learner competitiveness can positively affect learners&#x2019; behavioral aspects but they may negatively impact their emotions.},
  keywords={Visualization;Privacy;Message systems;Discussion forums;Usability;Tools;Market research;Asynchronous online discussion;emotions;learning analytics;learning outcomes;participation dashboard;visual design directions},
  doi={10.1109/TLT.2021.3126388},
  ISSN={1939-1382},
  month={Oct},}@INPROCEEDINGS{10083713,
  author={Sridhar, K. and Shinde, Govind and Chaurasia, Amrita and R, Asha Rani N},
  booktitle={2023 International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering (ICECONF)}, 
  title={Data science: simulating and development of outcome based teaching method}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The educational researcher has a wealth of options to apply analytics to extract meaningful insights to improve teaching and learning due to the growing availability of educational data. Teaching analytics, in contrast to learning analytics, examines the quality of the classroom environment and the efficacy of the instructional methods used to improve student learning. To investigate the potential of analytics in the classroom without jeopardizing students' privacy, we suggest a data science strategy that uses simulated data using pseudocode to build test cases for educational endeavors. Hopefully, this method's findings will contribute to creating a teaching outcome model (TOM) that can be used to motivate and evaluate educator performance. In Splunk, the study's simulated methodology was carried out. Splunk is a real-time Big Data dashboard that can gather and analyze massive amounts of machine-generated data. We provide the findings as a set of visual dashboards depicting recurring themes and developments in classroom effectiveness. Our study's overarching goal is to help bolster a culture of data-informed decision-making at academic institutions by applying a scientific method to educational data.},
  keywords={Visualization;Data privacy;Education;Decision making;Data science;Big Data;Knowledge discovery},
  doi={10.1109/ICECONF57129.2023.10083713},
  ISSN={},
  month={Jan},}@ARTICLE{10319353,
  author={Qiu, Wei and Khong, Andy W. H. and Supraja, S. and Tang, Wenyin},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A Dual-Mode Grade Prediction Architecture for Identifying At-Risk Students}, 
  year={2024},
  volume={17},
  number={},
  pages={803-814},
  abstract={Predicting student performance in an academic institution is important for detecting at-risk students and to administer early intervention strategies. In this article, we develop a new architecture that achieves grade prediction based only on grades achieved over past semesters. Our proposed architecture involves two stages—weighted loss function incorporated to the long short-term memory (LSTM) model in the first stage, followed by a short-term gated LSTM in the second. The weighted loss function in the first stage ensures low prediction error by weighing loss associated with the minority class label (in our case the at-risk label). The short-term gated LSTM in the second stage, on the other hand, models short-term variations in academic performance to suppress any residual false alarms. Experiment results using three datasets obtained from over 20 000 students across 17 undergraduate courses show that the proposed model achieves a 28.8% improvement in F1 score compared to the LSTM model for at-risk detection. Students identified as at-risk have also been presented and validated by counselors via a dashboard.},
  keywords={Predictive models;Logic gates;Computer architecture;Kernel;Microprocessors;Feature extraction;Computational modeling;At-risk detection;dashboard deployment;false alarm suppression;grade prediction;long short-term memory;weighted loss},
  doi={10.1109/TLT.2023.3333029},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10431497,
  author={Khalifa, Ghada Ben and Belkadhi, Lilia Cheniti},
  booktitle={2023 IEEE Afro-Mediterranean Conference on Artificial Intelligence (AMCAI)}, 
  title={Improving Student Grade Prediction with Machine Learning: Addressing Imbalanced Classifications to Gain Accurate Performance Insights}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Machine learning is a branch of artificial intelli-gence(AI) that builds models and algorithms to enable computers to learn from data, and make predictions, and decisions. Machine Learning(ML) has gained increasing recognition in various do-mains, including education. In this article, we explore the concept of ML in education and its potential to transform teaching and learning. We discuss the process of ML, the importance of data analytic, and how machine learning can be applied to predict student performance. Additionally, we delve into the issue of imbalanced classification and its relevance to student grade prediction. To tackle this challenge, we explore various strategies, including data-level, algorithm-level, and hybrid approaches. We also discuss the emergence of data-driven education and how ML can aid in predicting student grades. Finally, we emphasize the need for a balanced prediction model and present a comprehensive research framework that involves data extraction, analytic, and visualization to enhance educational practices.},
  keywords={Analytical models;Machine learning algorithms;Education;Machine learning;Predictive models;Prediction algorithms;Data models;machine learning;Learning analytic;Learning Analytic Dashboard (LAD);Prediction model},
  doi={10.1109/AMCAI59331.2023.10431497},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9657349,
  author={Cuadros, Jordi and Serrano, Vanessa and Lluch, Francesc and Garcia-Zubia, Javier and Hernandez-Jayo, Unai},
  booktitle={2021 World Engineering Education Forum/Global Engineering Deans Council (WEEF/GEDC)}, 
  title={Mapping VISIR Circuits for Computer-assisted Assessment}, 
  year={2021},
  volume={},
  number={},
  pages={524-527},
  abstract={Virtual Instrument Systems in Reality (VISIR) is a remote laboratory for electrical circuits currently used worldwide. Work is in progress to develop a functional learning analytics tool, the VISIR dashboard (VISIR-DB), that may be useful to instructors and researchers. Explaining what a VISIR circuit is and how to map different circuits that share the same experimental goal is therefore key. This paper presents the issue of circuit identification in VISIR and proposes some algorithms to organize the different experiments users can perform.},
  keywords={Remote laboratories;Instruments;Approximation algorithms;Complexity theory;Engineering education;VISIR;learning analytics;assessment;remote lab},
  doi={10.1109/WEEF/GEDC53299.2021.9657349},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10343069,
  author={Seeling, Patrick and McGarry, Michael P. and Johnson, Matthew},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Reveal Online Learning Clickstream Data to Provide Actionable Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper describes our universally applicable approach to the gathering of learning process data to support learning analytics with the ultimate goal of generating actionable intelligence for learners and instructors. This support is needed as increasingly, course content is provided in an online environment (independent of a class delivery modality, e.g., face-to-face, hybrid, hyflex, or online) where learners are operating independently and in absence of timely feedback loops. Providing learners with automatically generated feedback can stimulate their self-regulation toward success. Specifically, we describe an approach that generates learning process analytics dashboard data that are driven by clickstream data. Our approach enables the gathering of learning process data outside the Learning Management System (LMS) confines to support the generation of models that can produce actionable intelligence and enable deeper exploration options for the instructor. Our approach thus enables continuous education improvement and its operationalization (EdOps).},
  keywords={Learning management systems;Feedback loop;Adaptive learning;Adaptation models;Data models;Learning Management Systems;Adaptive Learning;Learning Analytics},
  doi={10.1109/FIE58773.2023.10343069},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10013469,
  author={Battaglin, Ricardo and Munoz, Roberto and Ramos, Vinicius Culmant and Cechinel, Cristian},
  booktitle={2022 XVII Latin American Conference on Learning Technologies (LACLO)}, 
  title={Predicting at-risk students with LMS data: a comparison between Adaboost and LSTM algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={The prediction of students at-risk (dropout and failure) is a largely explored problem on Learning Analytics and Educational Data Mining. The present work compares the results of two different algorithms used to generate predictive models to early detect students at-risk, LSTM and Adaboost. This comparison aims to improve the performances of the models already implemented and integrated on a Moodle dashboard. For the comparison, data from a total of 122 students was collected from Moodle over four semester of an Introductory Programming course offered at Federal University of Santa Catarina (UFSC). Models were generated for each one of the 17 weeks of the semester, and their AUROC measures were then calculated and compared to evaluate the differences between LSTM and Adaboost. The results have shown that even though LSTM models presented a better performance than Adaboost, these differences were not statistically significant.},
  keywords={Media;Computational modeling;Predictive models;Prediction algorithms;Data mining;Analytical models;Visualization;LSTM;Learning Analytics;Educational Data Mining;at-risk students1},
  doi={10.1109/LACLO56648.2022.10013469},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9499804,
  author={Ada, Mireilla Bikanga and Sears, Gareth},
  booktitle={2021 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Using Students' Affective State as a Measure of CS Lab Risk in an Early Detection System}, 
  year={2021},
  volume={},
  number={},
  pages={203-205},
  abstract={This paper presents a dual dashboard early warning system which uses students’ affective state as a measure of risk. Affective state has been shown to influence CS1 performance, and specific states such as frustration have been linked to attrition. The software administers affective surveys to students using a series of 2-dimensional grids. Students then complete a qualitative journal entry. Risk weights are assigned to students based on the journal response’s sentiment analysis and whether student’s 2-dimensional grid responses fall within configurable 'danger zone' bounds. The early warning system automatically flags students as needing support if the responses’ combined risk weights exceed configurable thresholds. Additionally, flags can be assigned manually, either by instructors or by students themselves.},
  keywords={Sentiment analysis;Prototypes;Alarm systems;Software;Monitoring;CS1;student support;sentiment analysis;early warning system;retention;higher education;student emotions},
  doi={10.1109/ICALT52272.2021.00067},
  ISSN={2161-377X},
  month={July},}@ARTICLE{8443395,
  author={Sarikaya, Alper and Correll, Michael and Bartram, Lyn and Tory, Melanie and Fisher, Danyel},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={What Do We Talk About When We Talk About Dashboards?}, 
  year={2019},
  volume={25},
  number={1},
  pages={682-692},
  abstract={Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation, and use.},
  keywords={Visualization;Data visualization;Encoding;Measurement;Decision making;Monitoring;Tools;Dashboards;literature review;survey;design space;open coding},
  doi={10.1109/TVCG.2018.2864903},
  ISSN={1941-0506},
  month={Jan},}@INPROCEEDINGS{10148293,
  author={Hadiprawoto, Triana R. and Ridley, Arran L.},
  booktitle={2023 IEEE 16th Pacific Visualization Symposium (PacificVis)}, 
  title={Transparent Dashboards: Open data practices for promoting competition-as-motivation in business dashboards}, 
  year={2023},
  volume={},
  number={},
  pages={142-146},
  abstract={Dashboards are a common and familiar format of data visualization and are deployed in a number of fields and across domains, such as business, medical and health, learning analytics, and urban analytics, amongst others. In this paper, we conduct interviews with users of business dashboards, in particular, performance dashboards and scorecards, in order to gain an understanding of how they might be used in daily practice. We discuss how dashboards are not only used, as the literature suggests, to gain a quick understanding of the data but are deployed, by making the data available to everyone, as a means of motivating the users through creating a competitive framing of the data. We discuss the implications of this and how our findings can inform and support approaches to dashboard design, implementation, and usage.},
  keywords={Surveys;Image color analysis;Data visualization;Companies;Interviews;Open data;Business;data visualization;dashboards;motivation},
  doi={10.1109/PacificVis56936.2023.00023},
  ISSN={2165-8773},
  month={April},}@INPROCEEDINGS{10747665,
  author={Weagant, Riley and Zhao, Zixin and Bradley, Adam and Collins, Christopher},
  booktitle={2024 IEEE VIS Workshop on Visualization Education, Literacy, and Activities (EduVIS)}, 
  title={AdVizor: Using Visual Explanations to Guide Data-Driven Student Advising}, 
  year={2024},
  volume={},
  number={},
  pages={21-29},
  abstract={Academic advising can positively impact struggling students’ success. We developed AdVizor, a data-driven learning analytics tool for academic risk prediction for advisors. Our system is equipped with a random forest model for grade prediction probabilities uses a visualization dashboard to allows advisors to interpret model predictions. We evaluated our system in mock advising sessions with academic advisors and undergraduate students at our university. Results show that the system can easily integrate into the existing advising workflow, and visualizations of model outputs can be learned through short training sessions. AdVizor supports and complements the existing expertise of the advisor while helping to facilitate advisor-student discussion and analysis. Advisors found the system assisted them in guiding student course selection for the upcoming semester. It allowed them to guide students to prioritize the most critical and impactful courses. Both advisors and students perceived the system positively and were interested in using the system in the future. Our results encourage the development of intelligent advising systems in higher education, catered for advisors.},
  keywords={Training;Visualization;Navigation;Conferences;Data visualization;Predictive models;Human in the loop;Random forests;Information Visualization;Academic Risk Prediction;Academic Advising;Learning Analytics},
  doi={10.1109/EduVIS63909.2024.00008},
  ISSN={},
  month={Oct},}@ARTICLE{7516709,
  author={Avila, Cecilia and Baldiris, Silvia and Fabregat, Ramon and Graf, Sabine},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Cocreation and Evaluation of Inclusive and Accessible Open Educational Resources: A Mapping Toward the IMS Caliper}, 
  year={2016},
  volume={11},
  number={3},
  pages={167-176},
  abstract={The aim of this paper is to introduce a model to cocreate and evaluate inclusive and accessible open educational resources (IA-OERs) toward the perspective of the IMS caliper analytics framework. The model was applied by 72 teachers of primary and secondary schools who cocreated and evaluated IA-OERs in the context of the validation phase of the inclusive learning project. The evaluation of the IA-OERs covered two aspects: Web accessibility and quality. Moreover, an accessibility dashboard was developed to display the graphics of the results obtained from the Web accessibility evaluation.},
  keywords={Open Educational Resources;Context;Analytical models;Guidelines;Collaboration;Electronic mail;Inclusive and accessible open educational resources;co-creation;IMS caliper analytics framework;Web accessibility and quality},
  doi={10.1109/RITA.2016.2589578},
  ISSN={1932-8540},
  month={Aug},}@INPROCEEDINGS{8436249,
  author={Zinke, Christian and Friedrich, Julia and Haefner, Anne},
  booktitle={2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)}, 
  title={Motivation for Corporate Training Through Feedback in Social Serious Games}, 
  year={2018},
  volume={},
  number={},
  pages={1-9},
  abstract={While serious games [1] are commonly used for educational purposes in pedagogical as well as business contexts, social serious games [2], [3] that combine serious games and Enterprise Social Networks (ESNs) are rare. While the benefits of both gamification and ESN in e-learning contexts are mostly well-known, systematic integration of both has been not sufficiently addressed yet. The main benefit of the combination is the seamless integration of learning into business processes. Nevertheless, in context of corporate training like in any other learning context, the motivation of learners is a barrier that needs to be taken into account. Feedback is a well-known mechanism that supports learning by addressing psychological needs and motivation of the learner. To illustrate approaches for motivation of learners in social serious games, we introduce a knowledge quiz and demonstrate potential feedback mechanisms (especially dashboards). The description of these mechanisms leads to a framework which describes different dashboard types and elements as well as their potential impact on motivation.},
  keywords={Training;Games;Electronic learning;Social network services;Companies;Analytical models;e-learning;gamification;serious game;Enterprise Social Network},
  doi={10.1109/ICE.2018.8436249},
  ISSN={},
  month={June},}@INPROCEEDINGS{9207196,
  author={Alshabandar, Raghad and Hussain, Abir and Keight, Robert and Khan, Wasiq},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Students Performance Prediction in Online Courses Using Machine Learning Algorithms}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={Advances in Information and Communications Technology (ICT) have increased the growth of Massive open online courses (MOOCs) applied in distance learning environments. Various tools have been utilized to deliver interactive content including pictures, figures, and videos that can motivate the learners to build new cognitive skills. High ranking universities have adopted MOOCs as an efficient dashboard platform where learners from around the world can participate in such courses. The students learning progress is evaluated by using set computer-marked assessments. In particular, the computer gives immediate feedback to the student once he or she completes the online assessments. The researchers claim that student success rate in an online course can be related to their performance at the previous session in addition to the level of engagement. Insufficient attention has been paid by literature to evaluate whether student performance and engagement in the prior assessments could affect student achievement in the next assessments. In this paper, two predictive models have been designed namely students' assessments grades and final students' performance. The models can be used to detect the factors that influence students' learning achievement in MOOCs. The result shows that both models gain feasible and accurate results. The lowest RSME gain by RF acquire a value of 8.131 for students assessments grades model while GBM yields the highest accuracy in final students' performance, an average value of 0.086 was achieved.},
  keywords={Predictive models;Feature extraction;Videos;Tools;Computer science;Task analysis;Machine learning;Massive Open Online Courses (MOOCs);Open University Learning Analytics Dataset (OULAD );Receiver Operating Characteristic(ROC)},
  doi={10.1109/IJCNN48605.2020.9207196},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10260876,
  author={Majumdar, Rwitajit and Takami, Kyosuke and Ogata, Hiroaki},
  booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Learning with Explainable AI-Recommendations at School: Extracting Patterns of Self-Directed Learning from Learning Logs}, 
  year={2023},
  volume={},
  number={},
  pages={245-249},
  abstract={Educational explainable AI (XAI) applications are gaining research focus and have distinct needs in the domain of Education. This research presents Educational eXplainable AI Tool (EXAIT), a system for math quiz recommendations, along with an explanation. EXAIT was implemented in a Japanese public high school where students received the top 5 math problems based on Bayesian Knowledge Tracing (BKT) algorithm in a learning analytics dashboard. It aimed to help them complete their summer vacation assignments having 240 questions. On click, the students were redirected to an eBook platform to submit their accuracy and confidence level in each problem. We conducted a study with a quasi-experimental design and divided into 3 groups based on compliance of use. RecoExp group received and used explanations regarding why an item was recommended and how it aims to maximize learners' knowledge-gaining path. RecoCon was the control group that received just the recommendations and used it and RecoNone group did not use the system at all during the time period. We provide a framework to analyze learning logs from EXAIT and extract emerging self-directed learning patterns. Analyzing 222 students' EXAIT logs, we found learners who had checked explanations while selecting recommendations had significantly higher performance. Further differential process mining highlighted significant active daily engagement transitions of the RecoExp group in the self-directed activity.},
  keywords={Electronic publishing;Education;Bayes methods;Artificial intelligence;LEAF;SDL;XAI;LA;pattern mining},
  doi={10.1109/ICALT58122.2023.00078},
  ISSN={2161-377X},
  month={July},}
