@inproceedings{20251218095239 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Self-service Teacher-facing Learning Analytics Dashboard with Large Language Models},
journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
author = {Wang, Zuo and Lin, Weiyue and Hu, Xiao},
year = {2025},
pages = {824 - 830},
address = {Dublin, Ireland},
abstract = {<div data-language="eng" data-ev-field="abstract">With the rise of online learning platforms, the need for effective learning analytics (LA) has become critical for teachers. However, the development of traditional LA dashboards often requires technical expertise and a certain level of data literacy, preventing many teachers from integrating LA dashboards effectively and flexibly into their teaching practice. This paper explores the development of a self-service teacher-facing learning analytics dashboard powered by large language models (LLMs), for improving teaching practices. By leveraging LLMs, the self-service system aims to simplify the implementation of data queries and visualizations, allowing teachers to create personalized LA dashboards using natural languages. This study also investigates the capabilities of LLMs in generating charts for LA dashboards and evaluates the effectiveness of the self-service system through usability tests with 15 teachers. Preliminary findings suggest that LLMs demonstrate high capabilities in generating charts for LA dashboards, and the LLM-powered self-service system can effectively address participating teachers' pedagogical needs for LA. This research contributes to the ongoing research on the intersection of LLMs and education, emphasizing the potential of self-service systems to empower teachers in daily teaching practices.<br/></div> © 2025 Copyright held by the owner/author(s).},
key = {Data Analytics},
keywords = {Network security;Query languages;Teaching;Visual languages;},
note = {Language model;Large language model;Learning analytic dashboard;Learning platform;Online learning;Self-service learning analytic;Self-service systems;Service learning;Teachers';Teaching practices;},
URL = {http://dx.doi.org/10.1145/3706468.3706491},
} 


@inproceedings{20242216154016 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Learning Analytics Dashboard for Improved Learning Outcomes and Diversity in Programming Classes},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Groher, Iris and Vierhauser, Michael and Hartl, Erik},
volume = {2},
year = {2024},
pages = {618 - 625},
issn = {21845026},
address = {Angers, France},
abstract = {<div data-language="eng" data-ev-field="abstract">The increased emphasis on competency management and learning objectives in higher education has led to a rise in Learning Analytics (LA) applications. These tools play a vital role in measuring and optimizing learning outcomes by analyzing and interpreting student-related data. LA tools furthermore provide course instructors with insights on how to refine teaching methods and material and address diversity in student performance to tailor instruction to individual needs. This tool demonstration paper introduces our Learning Analytics Dashboard, designed for an introductory Python programming course. With a focus on gender diversity, the dashboard analyzes graded Jupyter Notebooks, to provide insights into student performance across assignments and exams. An initial assessment of the dashboard, applying it to our Python programming course in the previous year, has provided us with interesting insights and information on how to further improve our class and teaching materials. We present the dashboard’s design, features, and outcomes while outlining our plans for its future development and enhancement.<br/></div> Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
key = {Students},
keywords = {Curricula;High level languages;Teaching;},
note = {Assurance of learning;Dashboard;Diversity;Learning analytic;Learning objectives;Learning outcome;Programming course;Python programming;Student performance;Teaching materials;},
URL = {http://dx.doi.org/10.5220/0012735000003693},
} 


@inproceedings{20241916032512 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Learning Analytics Dashboard to Investigate the Influence of Interaction in a VR Learning Application},
journal = {CEUR Workshop Proceedings},
author = {Heinemann, Birte and Gorzen, Sergej and Dragolji, Ana and Meiendresch, Lars Florian and Troll, Marc and Schroeder, Ulrik},
volume = {3667},
year = {2024},
pages = {251 - 259},
issn = {16130073},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning in Virtual Reality offers various ways to make the learning process interactive, but the implementation of such features is complex, time-consuming and expensive. In order to evaluate the efficiency of interactive tasks, a Learning Analytics dashboard, presented in this paper, was created for both teachers/educators and content creators. The dashboard presents data from a study with different interactive/immersive and non-interactive/non-immersive variants of a learning application for the rendering pipeline, a showcase topic from computer graphics. The dashboard has been implemented with transferability in mind by using xAPI as a data format and can thus be easily transferred to other contexts.<br/></div> © 2024 CEUR-WS. All rights reserved.},
key = {Virtual reality},
keywords = {E-learning;Learning systems;Pipelines;Rendering (computer graphics);},
note = {Content creators;Dashboard;Immersive;Learning analytic;Learning process;Multi-modal learning;Multi-modal learning analytic;Rendering pipelines;Teachers';},
} 


@inproceedings{20241816016124 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {EX-LAD: an Explainable Learning Analytics Dashboard in Higher Education},
journal = {EPiC Series in Computing},
author = {Khelifi, Tesnim and Rabah, Nourhene Ben and Le Grand, Benedicte and Daoudi, Ibtissem},
volume = {97},
year = {2024},
pages = {38 - 51},
issn = {23987340},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper introduces an EXplainable Learning Analytic Dashboard (EX-LAD) that presents learning analytics data on student performance, engagement, and perseverance in a clear and easily understandable manner. The main goal of this study is to make this information accessible to both teachers and students, who may not possess extensive knowledge in data analysis, and demonstrate the effectiveness of the relationship between performance, engagement, and perseverance in identifying student difficulties. This dashboard enables teachers to gain valuable information about their student’s progress, identify at-risk learners, and provide targeted support. Similarly, students can use this dashboard to track their own learning journey, identify their strengths and weaknesses, and make informed decisions to improve their academic performance. It integrates visualizations to represent various aspects of student learning, such as performance, engagement, and perseverance. To demonstrate the effectiveness of our dashboard, we conducted a case study using real data collected from ESIEE-IT, an engineering school in France, during the academic year 2021-2022. This case study serves as concrete evidence of the impact and values our dashboard brings to the educational context.<br/></div> © 2024, EasyChair. All rights reserved.},
key = {Students},
keywords = {Visualization;},
note = {Case-studies;Dashboard;Explainability;High educations;Informed decision;Learning analytic;Performance;Student performance;Teachers';Technology enhanced learning;},
URL = {http://dx.doi.org/10.29007/dsxd},
} 


@article{20242916715745 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Co-creating an equality diversity and inclusion learning analytics dashboard for addressing awarding gaps in higher education},
journal = {British Journal of Educational Technology},
author = {Bayer, Vaclav and Mulholland, Paul and Hlosta, Martin and Farrell, Tracie and Herodotou, Christothea and Fernandez, Miriam},
volume = {55},
number = {5},
year = {2024},
pages = {2058 - 2074},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">Educational outcomes from traditionally underrepresented groups are generally worse than for their more advantaged peers. This problem is typically known as the awarding gap (we use the term awarding gap over ‘attainment gap’ as attainment places the responsibility on students to attain at equal levels) and continues to pose a challenge for educational systems across the world. While Learning Analytics (LA) dashboards help identify patterns contributing to the awarding gap, they often lack stakeholder involvement, offering very little support to institutional Equality, Diversity and Inclusion (EDI) leads or educators to pinpoint and address these gaps. This paper introduces an innovative EDI LA dashboard, co-created with diverse stakeholders. Rigorously evaluated, the dashboard provides fine-grained insights and course-level analysis, empowering institutions to effectively address awarding gaps and contribute to a diverse and inclusive higher education landscape. Practitioners notes What is already known about this topic Traditionally underrepresented groups face educational disparities, commonly known as the awarding gap. Underachievement is a complex multi-dimensional problem and cannot be solely attributable to individual student deficiencies. LA dashboards targeting this specific problem are often not public, there is little research about them, and are frequently designed with little involvement of educational stakeholders. What this paper adds Pioneers the introduction of a dashboard specifically designed to address the awarding gap problem. Emphasises the significant data needs of educational stakeholders in tackling awarding gaps. Expands the design dimensions of Learning Analytics (LA) by introducing a specific design approach rooted in established user experience (UX) design methods. Implications for practice and/or policy Insights from this study will guide practitioners, designers, and developers in creating AI-based educational systems to effectively target the awarding gap problem.<br/></div> © 2024 The Author(s). British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
key = {Design},
keywords = {Students;},
note = {Awarding gap;Co-creation;Dashboard design;Educational inequality;Educational systems;Fine grained;High educations;Multidimensional problems;Stakeholder involvement;Under-represented groups;},
URL = {http://dx.doi.org/10.1111/bjet.13509},
} 


@inproceedings{20243016734701 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Learning Analytics Dashboard for K-12 English Teachers - Bridging the Gap between Student Process Data and Teacher Needs},
journal = {UMAP 2024 - Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
author = {Colling, Leona and Kholin, Mareike and Meurers, Detmar},
year = {2024},
pages = {538 - 548},
address = {Cagliari, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">Educational technologies are being used more and more in secondary school settings. This increases the amount of students' learning related data produced and stored. To keep up with this rise and to get most out of the collected data, teachers need digital tools that support and facilitate their pedagogical decision-making process. Learning analytics dashboards can be a good source to provide teachers with necessary insights into their students' learning processes. However, for such tools to be effective and actionable, they have to be aligned with teachers' needs and thus, provide and visualize data in a concise and structured way. We therefore conducted a survey study with 11 English teachers from K-12 secondary schools in Germany who evaluated the assumed usefulness of possible dashboard features. Based on these findings, we developed a teacher dashboard incorporating the most desired functionalities, such as a quickly accessible summary of strengths, weaknesses and support needs, or an overview of current misconceptions and competencies alongside additional metrics in order to support multiple teaching practices. The implementation and the underlying calculations are described, focusing on the importance of learners' process data to provide teachers with a detailed and revealing view on their students' and class learning states. In an evaluation study of the dashboard's prototype with mock data, teachers (n=6) gave high ratings for the dashboard's usability.<br/></div> © 2024 Owner/Author.},
key = {Students},
keywords = {Computer aided instruction;Decision making;Digital devices;E-learning;Learning systems;Linguistics;},
note = {Computer assisted language learning;Intelligent tutoring;Intelligent tutoring system;Learning analytic;Process data;Secondary schools;Student learning;Teacher dashboard;Teachers';Tutoring system;},
URL = {http://dx.doi.org/10.1145/3631700.3665228},
} 


@inproceedings{20241115753415 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Equity-Forward Learning Analytics: Designing a Dashboard to Support Marginalized Student Success},
journal = {ACM International Conference Proceeding Series},
author = {Sloan-Lynch, Jay and Morse, Robert},
year = {2024},
pages = {1 - 11},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Student outcomes in US higher education exhibit deep and persistent inequities. The continued underperformance of historically marginalized students remains a serious concern across higher education, reflected in increasing efforts among institutions to infuse diversity, equity, and inclusion into their academic and social communities. Yet despite widespread recognition of these inequities, few studies in the learning analytics literature engage in practical ways with issues of educational equity or DEI considerations. In this paper, we share our work supporting a large college's strategic DEI goals through the creation of a Course Diversity Dashboard informed by research into how students' study behaviors and performance interact with their gender and ethnic identities to impact course outcomes. The dashboard enables users to explore inequalities in course outcomes and take concrete actions to improve student study strategies, time management, and prior knowledge. Results from our research revealed the existence of previously hidden learner inequities in all courses included in our study as well as critical differences in underrepresented minority students' prior knowledge. And while we did not find evidence of meaningful differences in the study behaviors of student subgroups, our findings further validate the effectiveness of evidence-informed study strategies in an authentic educational setting.<br/></div> © 2024 Owner/Author.},
key = {Students},
note = {DEI;Educational equity;High educations;Learning analytic dashboard;Prior-knowledge;Student outcomes;Student studies;Student success;Study strategy;Underperformance;},
URL = {http://dx.doi.org/10.1145/3636555.3636844},
} 


@inproceedings{20251218095189 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots},
journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie Xiang and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
year = {2025},
pages = {579 - 590},
address = {Dublin, Ireland},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners' varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners' ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners' GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners' GenAI literacy.<br/></div> © 2025 Copyright held by the owner/author(s).},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;Generative adversarial networks;Visual analytics;},
note = {'current;Chatbots;Educational effectiveness;Generative AI chatbot;Generative AI literacy;Interaction with data;Interactive learning;Learner interaction;Learning analytic dashboard;Personalized feedback;},
URL = {http://dx.doi.org/10.1145/3706468.3706545},
} 


@inproceedings{20243817058993 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Preliminary Evaluation of Learning Analytics Dashboard for College Teachers' Online Professional Learning},
journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
author = {Wang, Chao and Ng, Jeremy Tzi Dong and Lopez, Nora Patricia Hernandez and Hu, Xiao},
year = {2024},
pages = {83 - 85},
address = {Hybrid, Nicosia, Cyprus},
abstract = {<div data-language="eng" data-ev-field="abstract">Widely accessible online courses provide a feasible platform for teachers' continuous online professional learning. The learning analytics dashboard (LAD) provides fine-grained and actionable feedback that supports learners' self-regulated learning. However, previous studies on LAD design and evaluation predominantly focused on student-facing LADs, with scarce attention on LADs designed for teacher-learners. This study introduces the LAD in an online learning platform for college teachers and conducts a preliminary evaluation with 18 participants. Results show their largely positive ratings on five criteria (e.g., perceived usefulness, ease of use, and behavioral changes) and offer feedback for further refinements of the LAD. This study will improve our understanding of LA-enabled teacher online professional learning and provide practical implications for designing and evaluating LA tools catered to teacher-learners.<br/></div> © 2024 IEEE.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;Self-supervised learning;},
note = {College teachers;Design and evaluations;Fine grained;Learning analytic dashboard;Online course;Preliminary evaluation;Professional learning;Self-regulated learning;Teacher online professional learning;Teachers';},
URL = {http://dx.doi.org/10.1109/ICALT61570.2024.00030},
} 


@inproceedings{20241115753457 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How do visualizations and automated personalized feedback engage professional learners in a Learning Analytics Dashboard?},
journal = {ACM International Conference Proceeding Series},
author = {Alcock, Sarah and Rienties, Bart and Aristeidou, Maria and Kouadri Mostefaoui, Soraya},
year = {2024},
pages = {316 - 325},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards (LAD) are the subject of research in a multitude of schools and higher education institutions, but a lack of research into learner-facing dashboards in professional learning has been identified. This study took place in an authentic professional learning context and aims to contribute insights into LAD design by using an academic approach in a practice-based environment. An existing storytelling LAD created to support 81 accountants was evaluated using Technology Acceptance Model, finding a learner expectation for clarity, conciseness, understanding and guidance on next steps. High usage levels and a 'take what you need' approach was identified, with all visualizations and automated personalized feedback being considered useful although to varying degrees. Professional learners in this study focus on understanding and acting upon weaknesses rather than celebrating strengths. The lessons for LAD design are to offer choice and create elements which support learners to take action to improve performance at a multitude of time points and levels of success.<br/></div> © 2024 Owner/Author.},
key = {Professional aspects},
keywords = {Learning systems;Visualization;},
note = {Accountancy;Assessment;Data storytelling;Learning analytic dashboard;Personalizations;Personalized feedback;Professional learning;School education;Technology acceptance model;},
URL = {http://dx.doi.org/10.1145/3636555.3636886},
} 


@unpublished{20240512336 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots},
journal = {arXiv},
author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie and Li, Xinyu and Gaevi, Dragan and Martinez-Maldonado, Roberto},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners’ varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners’ ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners’ GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners’ GenAI literacy.<br/></div> © 2024, CC BY.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;Visual analytics;},
note = {'current;Chatbots;Educational effectiveness;Generative AI chatbot;Generative AI literacy;Interaction with data;Interactive learning;Learner interaction;Learning analytic dashboard;Personalized feedback;},
URL = {http://dx.doi.org/10.48550/arXiv.2411.15597},
} 


@inproceedings{20241115753401 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data Storytelling Editor: A Teacher-Centred Tool for Customising Learning Analytics Dashboard Narratives},
journal = {ACM International Conference Proceeding Series},
author = {Fernandez-Nieto, Gloria Milena and Martinez-Maldonado, Roberto and Echeverria, Vanessa and Kitto, Kirsty and Gaevi, Dragan and Buckingham Shum, Simon},
year = {2024},
pages = {678 - 689},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Dashboards are increasingly used in education to provide teachers and students with insights into learning. Yet, existing dashboards are often criticised for their failure to provide the contextual information or explanations necessary to help students interpret these data. Data Storytelling (DS) is emerging as an alternative way to communicate insights providing guidance and context to facilitate students' interpretations. However, while data stories have proven effective in prompting students' reflections, to date, it has been necessary for researchers to craft the stories rather than enabling teachers to do this by themselves. This can make this approach more feasible and scalable while also respecting teachers' agency. Based on the notion of DS, this paper presents a DS editor for teachers. A study was conducted in two universities to examine whether the editor could enable teachers to create stories adapted to their learning designs. Results showed that teachers appreciated how the tool enabled them to contextualise automated feedback to their teaching needs, generating data stories to support student reflection.<br/></div> © 2024 ACM.},
key = {Students},
keywords = {Education computing;},
note = {Automated feedback;Contextual information;Contextualize;Data storytelling;LA dashboard;Learning designs;Teacher-centered tool;Teachers';},
URL = {http://dx.doi.org/10.1145/3636555.3636930},
} 


@article{20224713133812 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Adaptive or adapted to: Sequence and reflexive thematic analysis to understand learners' self-regulated learning in an adaptive learning analytics dashboard},
journal = {British Journal of Educational Technology},
author = {Park, Eunsung and Ifenthaler, Dirk and Clariana, Roy B.},
volume = {54},
number = {1},
year = {2023},
pages = {98 - 125},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">The real-time and granularized learning information and recommendations available from adaptive learning technology can provide learners with feedback that is personalized. However, at an individual level, learners often experience technological and pedagogical conflicts. Learners have more freedom to accept, ignore or reject the feedback while also having the challenges of building learning strategies and utilizing learning information that requires self-regulated learning skills. Given the conflicts, both understanding how learners learn and providing support for learners to be more self-regulated in the learning environment are imperative. This investigation explores how learners processed their learning in an adaptive technology-integrated learning analytics dashboard (ALAD). It employed mixed-methods using a lens of self-regulated learning (SRL). Three groups were identified based on clustering analysis of the learners' usage of warm-up (WU) tests. Sequence analysis revealed the time trends of each group's interactions with course content. Reflexive thematic analysis brought insights on how learners built their learning strategies (eg, ways of using WU tests and submodule assessments) and how they monitored and controlled their learning. It showed their dynamic interactions with core adaptive learning analytics dashboard elements. Challenges such as difficulties in rehearsing and monitoring through segmented course content arose from the new structural changes. We suggest the need of future improvement to individual learning support through the learning analytics dashboard to be more diverse and dynamic (real-time) over the course of learning while reducing potential undesirable consequences. Practitioner notes What is already known about this topic One purpose of learning analytics and adaptive learning is to help learners identify learning goals and take action to achieve their goals. Learning analytics intervention showed support in learners' reflection phase SRL. However, it is not clear how to better support actionable and strategic changes to learning. Learning improvement through learning analytics interventions varies depending on how learners utilize feedback and monitor their learning progress, interacting with their digital learning environments. What this paper adds Learners established certain learning strategies with core adaptive learning analytics dashboard elements (eg, use of assessments, monitoring strategies). Learners' perceptions about learning support from the ALAD were built by interacting with the learners' task and cognitive conditions. Based on the perceptions, individuals' various SRL strategies and the need for diverse support were found. Monitoring and rehearsals can be challenging when course content is broken down for individuals' support. Implications for practice and/or policy Courses with adaptive learning analytics dashboards need to be designed more carefully, considering possible undesirable consequences, and to improve SRL support. Learners need more diverse learning support at an individual level based on how they interact with the learning environment.<br/></div> © 2022 British Educational Research Association.},
key = {Feedback},
keywords = {Computer aided instruction;Curricula;Learning systems;},
note = {Adaptive learning;Clustering analysis;Course contents;Learning analytic dashboard;Learning strategy;Learning support;Reflexive thematic analyse;Self-regulated learning;Sequence analysis;Thematic analysis;},
URL = {http://dx.doi.org/10.1111/bjet.13287},
} 


@article{20221511942204 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CADA: a teacher-facing learning analytics dashboard to foster teachers’ awareness of students’ participation and discourse patterns in online discussions},
journal = {Technology, Knowledge and Learning},
author = {Kaliisa, Rogers and Dolonen, Jan Arild},
volume = {28},
number = {3},
year = {2023},
pages = {937 - 958},
issn = {22111662},
abstract = {<div data-language="eng" data-ev-field="abstract">Despite the potential of learning analytics (LA) to support teachers’ everyday practice, its adoption has not been fully embraced due to the limited involvement of teachers as co-designers of LA systems and interventions. This is the focus of the study described in this paper. Following a design-based research (DBR) approach and guided by concepts from the socio-cultural perspective and human-computer interaction (HCI), we design, test, and evaluate a teacher-facing LA dashboard, the Canvas Discussion Analytics Dashboard (CADA), in real educational settings. The goal of this dashboard is to support teachers’ roles in online environments through insights into students’ participation and discourse patterns. We evaluate CADA through 10 in-depth interviews with university teachers to examine their experiences using CADA in seven blended undergraduate and graduate courses over a one-year period. The findings suggest that engaging teachers throughout the analytics tool design process and giving them control/agency over LA tools can favour their adoption in practice. Additionally, the alignment of dashboard metrics with relevant theoretical constructs allows teachers to monitor the learning designs and make course design changes on the fly. The teachers in this study emphasise the need for LA dashboards to provide actionable insights by moving beyond what things are towards how things should be. This study has several contributions. First, we make an artefact contribution (e.g. CADA), an LA dashboard to support teachers with insights into students’ online discussions. Second, by leveraging theory, and working with the teachers to develop and implement a dashboard in authentic teaching environments, we make an empirical, theoretical and methodological contribution to the field of learning analytics and technology enhanced learning. We synthesise these through practical design and implementation considerations for researchers, dashboard developers, and higher education institutions.<br/></div> © 2022, The Author(s).},
key = {Facings},
keywords = {Curricula;Design;E-learning;Human computer interaction;Learning systems;Social networking (online);Students;Teaching;},
note = {Analytic tools;Asynchronous online discussion;Discourse;Discourse patterns;Learning designs;Online discussions;Participation;Student participation;Teacher facing learning analytic dashboard;Teachers';},
URL = {http://dx.doi.org/10.1007/s10758-022-09598-7},
} 


@inproceedings{20232614327125 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboard for Educators: Proposed Project to Design with Pedagogical Background},
journal = {ACM International Conference Proceeding Series},
author = {Sapsai, Iryna and Valencia Usme, Yeimy Paola and Abke, Joerg},
year = {2023},
pages = {38 - 47},
address = {Seeon/Bavaria, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">In this article, the authors describe a prototype of a Learning Analytics Dashboard (LAD) for educators. It is based on the analysis of pedagogical actions and taking into the process and learning style of students in an online environment based on learning analytics (LA). A description of the Dashboard structure, divided into levels and categories based on available learning analytics, will allow the educator to dive deeper into the online course themselves and explore more. It will also allow them to determine the level of student performance, identify gaps in learning materials, and research student data. The authors have identified further directions for the development of a LAD for a professor, including modeling algorithms for researching student behavior and learning style using Artificial Intelligence and presenting LA in a visualized form. This paper shows the stages of creating a professor's LAD prototype as a functional part of the adaptive learning system in the HASKI-System to analyze visual information obtained from LA and the possibilities to monitor the learning process, learning progress, student activity, and make decisions on careful intervention in the students' learning process.<br/></div> © 2023 ACM.},
key = {Students},
keywords = {Behavioral research;E-learning;Information systems;Information use;Learning systems;},
note = {Adaptive learning systems;Distance education pedagogy;Information visualization;Learning analytic;Learning analytic dashboard;Learningstyles;Online course;Online environments;Pedagogical action;Pedagogical knowledge;},
URL = {http://dx.doi.org/10.1145/3593663.3593686},
} 


@article{20240415430283 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student-Facing Learning Analytics Dashboard for Remote Lab Practical Work},
journal = {IEEE Transactions on Learning Technologies},
author = {Reid, David P. and Drysdale, Timothy D.},
volume = {17},
year = {2024},
pages = {1037 - 1050},
issn = {19391382},
abstract = {<div data-language="eng" data-ev-field="abstract">The designs of many student-facing learning analytics (SFLA) dashboards are insufficiently informed by educational research and lack rigorous evaluation in authentic learning contexts, including during remote laboratory practical work. In this article, we present and evaluate an SFLA dashboard designed using the principles of formative assessment to provide feedback to students during remote lab activities. Feedback is based upon graphical visualizations of student actions performed during lab tasks and comparison to expected procedures using TaskCompare - our custom, asymmetric graph dissimilarity measure that distinguishes students who miss expected actions from those who perform additional actions, a capability missing in existing graph distance (symmetrical dissimilarity) measures. Using a total of $N = 235$ student graphs collected during authentic learning in two different engineering courses, we describe the validation of TaskCompare and evaluate the impact of the SFLA dashboard on task completion during remote lab activities. In addition, we use components of the motivated strategies for learning questionnaire as covariates for propensity score matching to account for potential bias in self-selection of use of the dashboard. We find that those students who used the SFLA dashboard achieved significantly better task completion rate (nearly double) than those who did not, with a significant difference in TaskCompare score between the two groups (Mann-Whitney $U = 453.5$, $p < 0.01$ and Cliff's $\delta = 0.43$, large effect size). This difference remains after accounting for self-selection. We also report that students' positive rating of the usefulness of the SFLA dashboard for completing lab work is significantly above a neutral response ($S = 21.0$ and $p < 0.01$). These findings provide evidence that our SFLA dashboard is an effective means of providing formative assessment during remote laboratory activities.<br/></div> © 2008-2011 IEEE.},
key = {Students},
keywords = {Curricula;E-learning;Facings;Feedback;Industrial research;Job analysis;Laboratories;},
note = {Atmospheric measurement;Formative assessment;Graph;Learning analytic;Online learning;Particle measurement;Remote laboratories;Remote learning;Self-regulated learning;Task analysis;Video;},
URL = {http://dx.doi.org/10.1109/TLT.2024.3354128},
} 


@inproceedings{20234314937197 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student-Centered Design and Evaluation of a Learning Analytics Dashboard},
journal = {Lecture Notes in Business Information Processing},
author = {Rodda, Alena},
volume = {485 LNBIP},
year = {2023},
pages = {67 - 80},
issn = {18651348},
address = {Braga, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">The digitization of teaching at universities has increased significantly in recent years, with online and hybrid courses becoming more popular. These formats allow students a high degree of autonomy, but also require them to work independently and organize themselves. However, students often lack these skills. Learning analytics (LA) evaluations, provided as dashboards, can help students to continuously monitor their learning progress and compare themselves to their peers. Nevertheless, the student perspective has often been underrepresented in LA research. There is also a lack of standardized knowledge and processes for implementing LA and making LA information available to end users. This paper aims to develop and evaluate a LA dashboard for a university course based on the requirements of the students, using data from a university’s learning management and examination system. Three dashboard versions are designed and evaluated quantitatively and qualitatively in a study with 114 participants. The results will be discussed, along with limitations and potential future research directions.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Students},
keywords = {Information management;},
note = {Analytic evaluation;Dashboard;Degree of autonomy;Design and evaluations;Digitisation;Hybrid course;Information design;Learning analytic;Online course;Student-centred;},
URL = {http://dx.doi.org/10.1007/978-3-031-42788-6_5},
} 


@inproceedings{20233914787843 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Student-Centered Learning Analytics Dashboard Towards Course Goal Achievement in STEM Education},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Buvari, Sebastian and Viberg, Olga and Iop, Alessandro and Romero, Mario},
volume = {14200 LNCS},
year = {2023},
pages = {698 - 704},
issn = {03029743},
address = {Aveiro, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">Online learning has become an everyday form of learning for many students across different disciplines, including STEM subjects in the setting of higher education. Studying in these settings requires students to self-regulate their learning to a higher degree as compared to campus-based education. A vital aspect of self-regulated learning is the application of goal-setting strategies. Universities act to support students’ goal-setting through the achievement of course learning outcomes, which work both as a promise and metric of academic achievement. However, a lack of clear integration between course activities and course learning outcomes leaves a dissonance between students’ study efforts and the course progress. This demo study presents a student-centered learning analytics dashboard aimed at assisting students in their achievement of course learning goals in the setting of STEM higher education. The dashboard was designed using a design science methodological approach. Thirty-seven students have contributed to its development and evaluation during different stages of the design process, including the conceptual iterative design and prototyping. The preliminary results show that students found the tool to be easy to use and useful for the achievement of the course goals.<br/></div> © 2023, The Author(s).},
key = {Students},
keywords = {Curricula;Design;Iterative methods;},
note = {Goal-setting;Goals achievement;High educations;Learning analytic dashboard;Learning outcome;Online learning;Participatory design;STEM education;STEM high education;Student centred learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-42682-7_64},
} 


@article{20230913632971 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Mediating Teacher Professional Learning with a Learning Analytics Dashboard and Training Intervention},
journal = {Technology, Knowledge and Learning},
author = {Khulbe, Manisha and Tammets, Kairit},
volume = {28},
number = {3},
year = {2023},
pages = {981 - 998},
issn = {22111662},
abstract = {<div data-language="eng" data-ev-field="abstract">Insights derived from classroom data can help teachers improve their practice and students’ learning. However, a number of obstacles stand in the way of widespread adoption of data use. Teachers are often sceptical about the usefulness of data. Even when willing to work with data, they often do not have the relevant skills. Tools for analysis of learning data can, theoretically, aid teachers in data use, but often fall short of their potential as they are commonly designed without reference to educational theory and rarely consider end-user’s needs. Keeping these challenges in mind, we designed a professional development program that aimed at, among other things, improving teachers’ beliefs regarding data and their data literacy skills. After the training, we found that teachers had more positive attitudes regarding data. However, some data literacy skills proved quite difficult to learn. We present and analyse our intervention here and forward a proposal for improving the effectiveness of data use interventions by leveraging theory-based Learning Analytics (LA) dashboards as mediating tools that scaffold teachers’ acquisition of new knowledge and skills during and beyond the intervention.<br/></div> © 2023, The Author(s), under exclusive licence to Springer Nature B.V.},
key = {Personnel training},
keywords = {Knowledge management;Scaffolds;Students;},
note = {Data use intervention;Engagement;Learning analytic;Learning analytic dashboard;Professional learning;Teacher-facing dashboard;Teachers';Teacher’ data use;Training intervention;},
URL = {http://dx.doi.org/10.1007/s10758-023-09642-0},
} 


@article{20223312566284 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {VisOJ: real-time visual learning analytics dashboard for online programming judge},
journal = {Visual Computer},
author = {Fu, Qian and Bai, Xue and Zheng, Yafeng and Du, Runsheng and Wang, Dongqing and Zhang, Tianyi},
volume = {39},
number = {6},
year = {2023},
pages = {2393 - 2405},
issn = {01782789},
abstract = {<div data-language="eng" data-ev-field="abstract">Online Judge (OJ) is an important aid for programming learning that can help students evaluate learning effects in real-time, while teachers can adjust practice tasks in time according to the records of the tool. With these advantages, OJ shows great value for promoting teaching and learning in programming. The existing OJ system usually only provides information such as problem status list and recent rank list. However, it is unable to provide teachers with more fine-grained analysis information, such as the distribution of students’ incorrect responses and level of knowledge mastery. And it also cannot provide students with effective comparative information on their learning status. This research developed a visual learning analytics dashboard named VisOJ for the OJ system, which includes two types of user interfaces: teacher and student. The teacher interface presents students' learning status and ranking trends, which help teachers monitor and give feedback on their learning activities. The student interface provides views such as error type analysis and evaluation, which promote students' self-reflection and self-regulation. Preliminary case studies and expert interviews prove the usability of the dashboard. In the end, we summarize our main work and suggest future research directions.<br/></div> © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
key = {Students},
keywords = {E-learning;Learning systems;User interfaces;},
note = {Learning analytic dashboard;Learning effects;On-line programming;Online judges;Programming learning;Programming study;Real- time;Teachers';Visual analytics;Visual learning;},
URL = {http://dx.doi.org/10.1007/s00371-022-02586-z},
} 


@inproceedings{20235015196397 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Meta-LAD: Developing a Learning Analytics Dashboard with a Theoretically Grounded and Context-Specific Approach},
journal = {2023 IEEE Learning with MOOCS, LWMOOCS 2023 - Conference Proceedings},
author = {Choi, Heeryung and Borrella, Inma and Ponce-Cueto, Eva},
year = {2023},
pages = {IEEE; IEEE Education Society; MiT | Open Learning - },
address = {Cambridge, MA, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">The use of Learning Analytics Dashboards (LADs) has gained popularity as a means of supporting the self-regulated learning (SRL) skills of learners in large-scale online courses. Despite many studies proposing LAD designs, LADs are often criticized for their weak theoretical foundations, lack of actionable feedback, and tendency to encourage excessive social comparison. Furthermore, many LAD designs have missed context-specific details. Hence, it is not uncommon for some dashboard designs to have negative effects on learners, such as discouragement or anxiety. In this study, we designed the Meta-LAD, a LAD that supports SRL processes using theoretical and contextual foundations. We used data from a credit-bearing Massive Open Online Course (MOOC) on supply chain management to contextually ground the dashboard. We performed usability testing interviews to evaluate the design and confirmed that the Meta-LAD could fulfill learners' needs for references and actionable feedback. This study contributes to the field of online learning by presenting a theoretically grounded and contextually specific LAD design process. This paper expands the understanding of how to support SRL in MOOCs.<br/></div> © 2023 IEEE.},
key = {Supply chain management},
keywords = {Curricula;E-learning;},
note = {Design learning;Large-scales;Learning analytic dashboard;Learning process;Learning skills;Massive open online course;Metalearning;Online course;Self-regulated learning;Theoretical foundations;},
URL = {http://dx.doi.org/10.1109/LWMOOCS58322.2023.10306139},
} 


@article{20232014102790 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Real-Time Learning Analytics Dashboard for Automatic Detection of Online Learners’ Affective States},
journal = {Sensors},
author = {Hasnine, Mohammad Nehal and Nguyen, Ho Tan and Tran, Thuy Thi Thu and Bui, Huyen T. T. and Akcapinar, Gokhan and Ueda, Hiroshi},
volume = {23},
number = {9},
year = {2023},
issn = {14248220},
abstract = {<div data-language="eng" data-ev-field="abstract">Students’ affective states describe their engagement, concentration, attitude, motivation, happiness, sadness, frustration, off-task behavior, and confusion level in learning. In online learning, students’ affective states are determinative of the learning quality. However, measuring various affective states and what influences them is exceedingly challenging for the lecturer without having real interaction with the students. Existing studies primarily use self-reported data to understand students’ affective states, while this paper presents a novel learning analytics system called MOEMO (Motion and Emotion) that could measure online learners’ affective states of engagement and concentration using emotion data. Therefore, the novelty of this research is to visualize online learners’ affective states on lecturers’ screens in real-time using an automated emotion detection process. In real-time and offline, the system extracts emotion data by analyzing facial features from the lecture videos captured by the typical built-in web camera of a laptop computer. The system determines online learners’ five types of engagement ("strong engagement", "high engagement", "medium engagement", "low engagement", and "disengagement") and two types of concentration levels ("focused" and "distracted"). Furthermore, the dashboard is designed to provide insight into students’ emotional states, the clusters of engaged and disengaged students’, assistance with intervention, create an after-class summary report, and configure the automation parameters to adapt to the study environment.<br/></div> © 2023 by the authors.},
key = {Students},
keywords = {E-learning;Laptop computers;Learning systems;},
note = {Affective state;Affective state detection;AI in education;Dashboard;Emotion;Learning analytic framework;Lecture video;Lecture video analyse;Real- time;Video analysis;},
URL = {http://dx.doi.org/10.3390/s23094243},
} 


@unpublished{20240462471 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LLM-Driven Learning Analytics Dashboard for Teachers in EFL Writing Education},
journal = {arXiv},
author = {Kim, Minsun and Kim, SeonGyeom and Lee, Suyoun and Yoon, Yoosang and Myung, Junho and Yoo, Haneul and Lim, Hyunseung and Han, Jieun and Kim, Yoonsu and Ahn, So-Yeon and Kim, Juho and Oh, Alice and Hong, Hwajung and Lee, Tak Yeon},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper presents the development of a dashboard designed specifically for teachers in English as a Foreign Language (EFL) writing education. Leveraging LLMs, the dashboard facilitates the analysis of student interactions with an essay writing system, which integrates ChatGPT for real-time feedback. The dashboard aids teachers in monitoring student behavior, identifying noneducational interaction with ChatGPT, and aligning instructional strategies with learning objectives. By combining insights from NLP and Human-Computer Interaction (HCI), this study demonstrates how a human-centered approach can enhance the effectiveness of teacher dashboards, particularly in ChatGPT-integrated learning.<br/></div> © 2024, CC BY.},
key = {Human computer interaction},
keywords = {Contrastive Learning;Economic and social effects;Students;Teaching;},
note = {Computer interaction;English-as-a-Foreign-Language;Essay writings;Instructional strategy;Learning objectives;Real-time feedback;Student interactions;Students' behaviors;Teachers';Writing systems;},
URL = {http://dx.doi.org/10.48550/arXiv.2410.15025},
} 


@inproceedings{20231714006459 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Powered Teacher Facing Dashboard to Visualize, Analyze Students' Academic Performance and give Key DL(Deep Learning) Supported Key Recommendations for Performance Improvement.},
journal = {2023 International Conference for Advancement in Technology, ICONAT 2023},
author = {Deshpande, K.V. and Asbe, Shubham and Lugade, Akanksha and More, Yash and Bhalerao, Dipali and Partudkar, Anuradha},
year = {2023},
address = {Goa, India},
abstract = {<div data-language="eng" data-ev-field="abstract">COVID-19 has forced the government to close educational institutes to reduce the spread of the virus. As a result of this decision, students lose contact with teachers and a communication gap also arises. This survey attempts to bridge the gap between students and teachers. Through this survey, we sought to understand where the students are lacking and what are the different steps that can be taken by the teacher to improve the performance of the student and whether this concept should be reviewed or not. We found that most of the researchers who have published papers that we have read did the same mistake in their research, therefore we realized that the concept of AI should be studied again, and we should try not to repeat the same mistake in our research.The main aim of our project is to build 'Teacher facing dashboard' which can help the teacher to summarize,visualize and analyze the data of the education field(academics) and also understanding the students performance using Machine Learning(ML) and Deep Learning (DL).<br/></div> © 2023 IEEE.},
key = {Students},
keywords = {Deep learning;Facings;Learning systems;Viruses;},
note = {Analyze;Deep learning;Education field;Learning analytic;Machine-learning;Performance;Teacher facing dashboard;Teachers';Visualize;},
URL = {http://dx.doi.org/10.1109/ICONAT57137.2023.10080832},
} 


@inproceedings{20241115753403 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Needs Analysis of Learning Analytics Dashboard for College Teacher Online Professional Learning in an International Training Initiative for the Global South},
journal = {ACM International Conference Proceeding Series},
author = {Wang, Chao and Hu, Xiao and Hernandez Lopez, Nora Patricia and Ng, Jeremy Tzi Dong},
year = {2024},
pages = {915 - 921},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Online courses enable wide access to educational resources and thus provide a feasible platform for cross-regional teacher professional learning. Learning analytics dashboards (LAD) can support online learners by providing fine-grained feedback generated from learners' interactions with platforms. Nevertheless, most studies on teacher online professional learning focus on resource-rich and technology-advanced regions, with scarce attention to the Global South. Furthermore, existing studies on LAD design mainly target students' learning, rather than teachers' professional learning. Therefore, it is much needed to develop LAD for teacher-learners online professional learning in the Global South. Contextualized in an international online professional training initiative, this study conducted in-depth interviews with 42 teacher-learners from 19 countries in the Global South, aiming to identify their needs for 1) support on their self-regulated learning (SRL), and 2) potential LA components in dashboards. Findings indicated that teacher-learners needed support for self-regulated learning strategies, including motivation maintenance, time management, environment structuring, help-seeking, and self-evaluation. Nine LA features were identified to design the LADs to support SRL preliminarily. This co-designed LAD study with interviewees improved our understanding on the needs of college teachers in the Global South for LA support during their online professional learning, generating practical insights into needs-driven LAD designs.<br/></div> © 2024 ACM.},
key = {E-learning},
keywords = {Learning systems;Personnel training;Professional aspects;},
note = {College teachers;Educational resource;Fine grained;International training;Learner interaction;Need analysis;Online course;Professional learning;Self-regulated learning;Teachers';},
URL = {http://dx.doi.org/10.1145/3636555.3636932},
} 


@inproceedings{20224913217722 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Discovering the effects of learning analytics dashboard on students' behavioral patterns using differential sequence mining},
journal = {Procedia Computer Science},
author = {Akcapinar, Gokhan and Hasnine, Mohammad Nehal},
volume = {207},
year = {2022},
pages = {3812 - 3819},
issn = {18770509},
address = {Verona, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">Interventions based on learning analytics have a very important place in closing the learning analytics loop. However, data-driven studies that test the effects of learning analytics-based interventions on students' online learning behaviors are very limited. In this study, the effect of the student-facing learning analytics dashboard (LAD) on the learning behavior of students in the online learning environment was investigated by using the differential pattern mining method. In a completely remote course, the learning behaviors of the participants before the introduction of the dashboard were compared with the learning behaviors they exhibited after the dashboard was introduced. In this way, it has become possible to analyze the behavior changes after the dashboard intervention. Wilcoxon signed-rank test was used to test whether these behavioral changes were statistically significant or not. According to the Wilcoxon signed-rank test results, while there is no significant difference in terms of students' assignment and quiz interactions, it is seen that there is a statistically significant increase in terms of students' forum-related activities such as reading other students' posts, starting a new discussion, and replying others' posts. Students' SCORM interactions (e.g, launch, complete) were also increased after engaging with the LAD. In addition, it was found that the overall interaction of students in the online learning environment increased by 57% when the LAD was used.<br/></div> © 2022 The Authors. Published by Elsevier B.V.},
key = {Students},
keywords = {Computer aided instruction;Data mining;E-learning;},
note = {Dashboard;Differential sequence mining;Intervention;Learning analytic;Learning behavior;Online learning environment;Sequence mining;Temporal learning;Temporal learning analytic;Wilcoxon signed rank test;},
URL = {http://dx.doi.org/10.1016/j.procs.2022.09.443},
} 


@inproceedings{20223512673276 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {ChemistLab: An Educational Game with Learning Analytics Dashboard},
journal = {Proceedings - 2022 International Conference on Advanced Learning Technologies, ICALT 2022},
author = {Ong, Shuoh-Chwen and Chua, Fang-Fang},
year = {2022},
pages = {101 - 103},
address = {Bucharest, Romania},
abstract = {<div data-language="eng" data-ev-field="abstract">Educational games are games explicitly designed with educational purposes and aims to balance learning and playing. These educational games help people to learn and improve as they play. However, there is a lack of gameplay monitoring process whereby the real-time information of game progress is not being reflected. Most of the existing educational games do not consolidate with learning analytics dashboards which leads to no visualization of gameplay information and inadequate gameplay analysis. When players have information on how to improve their performance, they will be encouraged to revisit the game. Hence, an educational game with learning analytics dashboard, ChemistLab, is developed for learners to learn chemistry. The dashboard will visualize the performance and skills changes overtime which reflect the players' learning patterns and strategies used to improve their performance for better learning. The learning content of the game is extracted from the Malaysia Upper Secondary Education (Form 4) Chemistry syllabus. The expected output of the game is to allow users to observe their gameplay performance through the dashboard and gaining new knowledge through the game with the achievement of learning objectives.<br/></div> © 2022 IEEE.},
note = {Analytic dashboard;Educational game;Gameplay;Gameplay analysis;Gaming analytic;Learn+;Learning analytic;Monitoring process;Performance;Real-time information;},
URL = {http://dx.doi.org/10.1109/ICALT55010.2022.00038},
} 


@inproceedings{20225213287604 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Comparison with Self vs Comparison with Others: The Influence of Learning Analytics Dashboard Design on Learner Dashboard Use},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gallagher, Timothy and Slof, Bert and van der Schaaf, Marieke and Toyoda, Ryo and Tehreem, Yusra and Fracaro, Sofia Garcia and Kester, Liesbeth},
volume = {13647 LNCS},
year = {2022},
pages = {11 - 21},
issn = {03029743},
address = {Tampere, Finland},
abstract = {<div data-language="eng" data-ev-field="abstract">This study uses log-file data to investigates how chemical process plant employees interact and engage with two distinct learning analytics dashboard designs, which are implemented in a virtual reality simulation-based training environment. The learning analytics dashboard designs differ by reference frame: the progress reference frame, offers historical performance data as a point of comparison and the social reference frame offers aggregated average peer group performance data as a point of comparison. Results show that participants who receive a progress reference frame are likely to spend less time reviewing their dashboard than those who receive a social reference. However, those who receive a progress reference frame are more likely to spend more time reviewing detailed task feedback and engaging with the learning analytics dashboard.<br/></div> © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {E-learning},
keywords = {Personnel training;Virtual reality;},
note = {Chemical process plants;Historical performance data;Learning analytic dashboard;Logfile;Peer groups;Reference frame;Simulation-based training;Social comparison;Virtual reality simulation-based training;Virtual reality simulations;},
URL = {http://dx.doi.org/10.1007/978-3-031-22124-8_2},
} 


@inproceedings{20225213287690 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Development and Evaluation of a Learning Analytics Dashboard for Moodle Learning Management System},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Perai, Ivan and Grubii, Ani},
volume = {13517 LNCS},
year = {2022},
pages = {390 - 408},
issn = {03029743},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics provides a potential for adapting learning, teaching and knowledge testing processes to individual needs. One of the ways of using learning analytics is a dashboard for providing feedback to students and teachers. This paper presents the development and evaluation of the learning analytics dashboard for students (LAD-S). The LAD-S displays three views: a look at student success, system activities and prediction based on machine learning algorithms. We have used LAD-S as a part of Moodle online courses, one during the second semester in the 2020/2021, and the other two during the first semester in the 2021/2022. A survey was designed to examine students’ opinion about the LAD-S that included student’s self-awareness, influence of the dashboard on learning effectiveness, satisfaction with the type of data collected, usefulness and ease-of-use, intention to use the learning analytics dashboard. Data from 33 undergraduate and graduate students were collected. The results have shown that students are satisfied with all examined aspects of the LAD-S above the average. Students express the greatest satisfaction for ease of use (M = 3.79), clarity of collected data (M = 3.6), usefulness (M = 3.6), SUS questionnaire (M = 3.6), behavioral intention (M = 3.4) and satisfaction with individual functions of LAD-S (M = 3.4). Lower, yet above-average satisfaction was obtained for the impact of the LAD-S on more effective learning (M = 3.2); intention to use (M = 3.3) and satisfaction with the possibility of behavioral changes (M = 3.1). To verify the reliability of the measures used, the Cronbach’s alpha reliability coefficient was calculated for each scale. Satisfactory reliability of all measures used was obtained, with alpha coefficients ranging from 0.704 for the SUS questionnaire to 0.942 for the ease-of-use measure.<br/></div> © 2022, Springer Nature Switzerland AG.},
key = {Students},
keywords = {E-learning;Learning algorithms;Learning systems;Machine learning;Reliability;Teaching;},
note = {Ease-of-use;Evaluation;Feedback to students;Intention to use;Knowledge testing;Learning analytic;Learning analytic dashboard;Learning management system;Teachers';Testing process;},
URL = {http://dx.doi.org/10.1007/978-3-031-22131-6_30},
} 


@inproceedings{20222112151745 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards developing a learning analytics dashboard for a massive online robotics competition},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Kodumuru, Saketh and Lucas, Brendan and Sabanwar, Vivek and Patil, Sachin and Avudiappan, Deepa and Parikh, Parth and Arya, Kavi},
volume = {2022-March},
year = {2022},
pages = {1020 - 1025},
issn = {21659559},
address = {Tunis, Tunisia},
abstract = {<div data-language="eng" data-ev-field="abstract">A Learning Analytics Dashboard is a quick and efficient way for instructors to track the activities of students. In massive online learning scenarios like an international robotics competition, a dashboard is a critical tool for instructors to ensure continuous engagement of participants. Previous research on learning analytics dashboards focused on the effectiveness of dashboards and learning analytics on students along with factors affecting its success. This research discusses a dashboard developed for a massive robotics competition through which each year thousands of students are trained in engineering skills in an online Project Based Learning approach. The dashboard is developed using the dataset for the competition conducted during September 2020 to April 2021 in which more than 10,000 undergraduate students from 572 academic institutions across 7 countries participated. Team characteristics like demographics, feedback, scores, online activity, etc. are considered to cluster teams and develop models to predict the retention of participants. The Machine Learning (ML) model was able to achieve an accuracy of 80.7% and a recall value of 83.9% to identify dropping teams. Clustering provided insights on how these characteristics affected the performance of participants. These predictions along with participant engagement and feedback data was displayed on the dashboard. This visualization helps instructors identify teams requiring guidance or scaffolds to continue participation. Feedback from instructors shows the dashboard to be a promising tool for effectively managing massive online competitions.<br/></div> © 2022 IEEE.},
key = {Students},
keywords = {Engineering education;Machine learning;E-learning;Education computing;Robotics;Scaffolds;},
note = {Engineering skills;Learning analytic;Learning analytic dashboard;Learning scenarios;Machine learning in learning analytic;Machine-learning;Online learning;Online robotics;Project based learning;Robotics competitions;},
URL = {http://dx.doi.org/10.1109/EDUCON52537.2022.9766808},
} 


@inproceedings{20242016100731 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a Student-Centered Learning Analytics Dashboard: Design, Development and Evaluation},
journal = {29th Annual Americas Conference on Information Systems, AMCIS 2023},
author = {Rodda, Alena and Stahmann, Philip},
year = {2023},
address = {Panama City, Panama},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper explores the development of a student-centered Learning Analytics Dashboard (LAD) to promote self-regulated learning. With increasing digitization, online teaching has become an important feature in higher education. However, online learning leads to new challenges for students such as isolation or high self-management requirements. LADs can support students by providing data and analytics on their learning behavior and progress. Yet, there is limited research on the design of LADs, especially with respect to student needs. In this paper, we use design science research methodology to design, develop and evaluate a LAD in two iterations. We assess the usability, visual aesthetics, and Task Technology Fit of the dashboard against the background of self-regulated learning theory. The results show that our LAD is capable of supporting students in the tasks of self-evaluation and self-assessment.<br/></div> © 2023 29th Annual Americas Conference on Information Systems, AMCIS 2023. All rights reserved.},
} 


@inproceedings{20224413045410 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Designing a Learning Analytics Dashboard to Provide Students with Actionable Feedback and Evaluating Its Impacts},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Duan, Xiaojing and Wang, Chaoli and Rouamba, Guieswende},
volume = {2},
year = {2022},
pages = {117 - 127},
issn = {21845026},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">Various educational settings have begun to increasingly leverage the power of data analytics to optimize the learning environment and enhance the learning experience for students. However, despite this effort, significant research gaps still exist around utilizing educational data mining to provide students with actionable feedback and assess the comprehensive impact of data-informed feedback on students. In this study, a learning analytics dashboard was designed to provide students with actionable feedback to advance their self-regulated learning skills and improve their course performance. A rigorous inquiry using mixed methods was also conducted to study the dashboard’s impacts on students. It found that students’ use of the dashboard was positively correlated with their course performance, and those who viewed the dashboard had higher course ranks. In addition, it showed that students’ use of the dashboard was positively correlated with their homework submission time, and those who viewed the dashboard submitted homework earlier as the course progressed. The inquiry also revealed that students had mixed feelings about the dashboard, including motivation and anxiety.<br/></div> Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
key = {Students},
keywords = {Computer aided instruction;Data Analytics;Data mining;Machine learning;},
note = {Actionable feedback;Course performance;Data analytics;Educational settings;Learning analytic dashboard;Learning environments;Learning experiences;Machine-learning;Power;Self-regulated learning;},
URL = {http://dx.doi.org/10.5220/0011116400003182},
} 


@inproceedings{20225013243722 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student-facing Learning Analytics Dashboard: Profiles of Student Use},
journal = {Proceedings - Frontiers in Education Conference, FIE},
author = {Eickholt, Jesse and Weible, Jennifer L. and Teasley, Stephanie D.},
volume = {2022-October},
year = {2022},
issn = {15394565},
address = {Uppsala, Sweden},
abstract = {<div data-language="eng" data-ev-field="abstract">Student-facing learning analytics dashboards (LADs) provide visualizations of course-related information to help students understand and personalize their educational practices. As such, they can be viewed as a meta-cognitive tool that enables awareness, self-reflection and sensemaking of academic performance. While student-facing LADs are becoming a standard feature in educational software, questions have been raised about students' willingness to adopt LADs and their ability to interpret feedback provided by student-facing LADs. The extent to which student-facing LADs can broadly improve educational outcomes depends, in part, on students' ability to readily incorporate LAD usage in their educational workflows.This study investigates the use of a student-facing LAD, My Learning Analytics (MyLA), over the span of one semester in a university introductory science course. MyLA draws data from the campus learning management system (Canvas) and displays three visualizations designed to provide students with actionable information. Adoption and use of MyLA was voluntary. As an exploratory study of MyLA's use in an introductory science course, this work addresses three research questions: i) What are the characteristics of students that use MyLA?, ii) How do students make use of MyLA in their coursework?, and iii) What patterns of use are exhibited by more frequent MyLA users? The results indicate that given the opportunity to use a student-facing LAD, 33% of students made repeated use of the tool. Demographic data (e.g., gender, domestic/international student) did not predict MyLA usage but significant differences in mean cumulative GPA were found between non-MyLA users and MyLA users. Broad patterns of MyLA use were aligned with major assessments in the course (e.g., MyLA was used more often around exam dates) and the grade distribution view was the most commonly accessed. Among the most highly active MyLA users, two distinct profiles were identified: aware and sensemakers. Aware users made use of the dashboard on more than 12 distinct days across the course, primarily around exam dates, and stated that they accessed the dashboard to compare their performance with others. Sensemakers made frequent use of all three MyLA views multiple times over the semester to monitor their own progress, compare their grades to others, and check what materials other students had viewed.LADs such as MyLA allow students to leverage what they already know about course assessment in their interpretation of the data presented, easing adoption and deployment of a student-facing LAD in higher education. As MyLA does not require that students have any additional training to interpret the visualizations they provide, LADs can readily be employed by students in introductory computing and engineering courses to provide them with feedback to help them plan for, monitor, and evaluate their academic progress.<br/></div> © 2022 IEEE.},
key = {Students},
keywords = {Facings;Information management;Visualization;},
note = {Course level micro-learning analytic;Course related;Introductory science course;Learning analytic dashboard;Meta-cognitive tools;Micro-learning;Self reflection;Self-regulated learning;Sense making;Student-facing learning analytic dashboard;},
URL = {http://dx.doi.org/10.1109/FIE56618.2022.9962531},
} 


@inproceedings{20240915648077 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {User Requirements for Learning Analytics Dashboard in Maritime Simulator Training},
journal = {2023 IEEE International Conference on Industrial Engineering and Engineering Management, IEEM 2023},
author = {Munim, Z.H. and Schramm, H.J. and Krabbel, H. and Nyairo, F. and Haavardtun, P. and Kim, T.-E. and Bustgaard, M.},
year = {2023},
pages = {406 - 410},
address = {Singapore, Singapore},
abstract = {<div data-language="eng" data-ev-field="abstract">This study investigates user requirements for the design of a Learning Analytics Dashboard (LAD) tailored for assessment in maritime simulator training. User requirements for LAD components and visualization elements were examined. Further, perceptions towards the integration of LAD in performance assessment was explored using Likert-scale questions. Data was collected from three Nordic maritime institutions. Situational awareness emerged as the most important component of a maritime LAD, with heat maps preferred for visualization. Both teachers and students have positive perceptions towards the utilization of LAD. Disparities in user requirement and perception towards LAD use across universities, study levels, and simulator modality experience were explored. These insights are pivotal for the advancement and tailoring of LADs in maritime simulator training contexts.<br/></div> © 2023 IEEE.},
URL = {http://dx.doi.org/10.1109/IEEM58616.2023.10406321},
} 


@inproceedings{20221111797041 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Review of Learning Analytics Dashboard Research in Higher Education: Implications for Justice, Equity, Diversity, and Inclusion},
journal = {ACM International Conference Proceeding Series},
author = {Williamson, Kimberly and Kizilcec, Rene},
year = {2022},
pages = {260 - 270},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards (LADs) are becoming more prevalent in higher education to help students, faculty, and staff make data-informed decisions. Despite extensive research on the design and implementation of LADs, few studies have investigated their relation to justice, equity, diversity, and inclusion (JEDI). Excluding these issues in LAD research limits the potential benefits of LADs generally and risks reinforcing long-standing inequities in education. We conducted a critical literature review, identifying 45 relevant papers to answer three research questions: how is LAD research improving JEDI, ii. how might it maintain or exacerbate inequitable outcomes, and iii. what opportunities exist in this space to improve JEDI in higher education. Using thematic analysis, we identified four common themes: (1) participant identities and researcher positionality, (2) surveillance concerns, (3) implicit pedagogies, and (4) software development resources. While we found very few studies directly addressing or mentioning JEDI concepts, we used these themes to explore ways researchers could consider JEDI in their studies. Our investigation highlights several opportunities to intentionally incorporate JEDI into LAD research by sharing software resources and conducting cross-border collaborations, better incorporating user needs, and centering considerations of justice in LAD efforts to improve historical inequities.<br/></div> © 2022 ACM.},
key = {Software design},
keywords = {Computer programming;Inclusions;},
note = {Dashboard;Design and implementations;Diversity;Equity;High educations;Informed decision;Justice;Literature reviews;Potential benefits;Research questions;},
URL = {http://dx.doi.org/10.1145/3506860.3506900},
} 


@inproceedings{20221411924148 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Designing Human-Centered Learning Analytics Dashboard for Higher Education Using a Participatory Design Approach},
journal = {2021 IEEE 13th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2021},
author = {Revano, Teodoro F. and Garcia, Manuel B.},
year = {2021},
address = {Manila, Philippines},
abstract = {<div data-language="eng" data-ev-field="abstract">Higher education institutions (HEIs) are looking for new methods to assess and monitor student learning outcomes, as well as objectively determine the circumstances that contribute to their growth in different courses. Advances in new analytics tools that put visualizations and dashboards on top of live student data are making learning analytics more powerful than ever. This study utilized a participatory design (PD) technique to formulate an analytics dashboard intended for higher education. The rationale behind the study lies on the belief that an information system must be designed for users, rather than users having to accommodate a wide range of adjustments just to utilize such application. Students and teachers were recruited for their feedback and observations, respectively. After multiple PD sessions, four main crucial factors were derived: (1) who has access to data, (2) importance of time, (3) learning analytics should help students make the transition to university life, and (4) it should be discipline-specific. This study opens up a discussion on the importance of human-centered design through the use of PD and how learning analytics dashboard can be maximized to its potential when deployed in the academe.<br/></div> © 2021 IEEE.},
key = {Students},
note = {Academic analytic;Analytic tools;Design approaches;Design technique;High educations;Higher education institutions;Human-centred designs;Learning analytic dashboard;Participatory design;Student learning outcomes;},
URL = {http://dx.doi.org/10.1109/HNICEM54116.2021.9731917},
} 


@inproceedings{20214411101211 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {SAVis: A learning analytics dashboard with interactive visualization and machine learning},
journal = {CEUR Workshop Proceedings},
author = {Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
volume = {2985},
year = {2021},
issn = {16130073},
address = {Stockholm, Sweden},
abstract = {<div data-language="eng" data-ev-field="abstract">A dashboard that provides a central location to monitor and analyze data is an efficient way to track multiple data sources. In the educational community, for example, using dashboards can be a straightforward introduction into the concepts of visual learning analytics. In this paper, the design and implementation of Student Activity Visualization (SAVis), a new Learning Analytics Dashboard (LAD) using interactive visualization and Machine Learning (ML) is presented and discussed. The design of the dashboard was directed towards answering a set of 22 pedagogical questions that teachers might want to investigate in an educational dataset. We evaluate SAVis with an educational dataset containing more than two million samples, including the learning behaviors of 6,423 students who used a web-based learning platform for one year. We show how SAVis can deliver relevant information to teachers and support them to interact with and analyze the students’ data to gain a better overview of students’ activities in terms of, for example, their performance in number of correct/incorrect answers per each topic.<br/></div> © 2021 Copyright for this paper by its authors.},
key = {Students},
keywords = {Computer aided instruction;E-learning;Visualization;Machine learning;},
note = {Central locations;Educational community;Educational dataset;Interactive visualizations;Learning analytic dashboard;Multiple data sources;Student activity visualization;Teachers';Visual learning;Visual learning analytic;},
} 


@inproceedings{20221311866870 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Learning Analytics Dashboard for Moodle: Implementing Machine Learning Techniques to Early Detect Students at Risk of Failure},
journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
author = {Cechinel, Cristian and De Freitas Dos Santos, Mateus and Barrozo, Caio and Schardosim, Jesiel Emerim and Vila, Eduardo De and Ramos, Vinicius and Primo, Tiago and Munoz, Roberto and Queiroga, Emanuel Marques},
year = {2021},
pages = {130 - 136},
address = {Arequipa, Peru},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards are important tools that help professors to follow and understand students behavior inside Learning Management Systems. Moodle is one of the most popular and used Learning Management Systems available nowadays, and a number of initiatives have been conducted to offer Learning Analytics features inside it. The present paper describes MAD2, a Learning Analytics Dashboard developed for Moodle that offers different visualizations about students interactions inside the environment, and that uses machine learning techniques to early predict students at-risk of failure. The paper describes the predictive approach implemented inside the tool together with the most important visualization features available to the users. The offering of a tool to early predict students at-risk of failure inside Moodle is an important step to help professors and managers to better assist students during their courses.<br/></div> © 2021 IEEE.},
key = {Students},
keywords = {Data mining;Learning algorithms;Machine learning;Visualization;},
note = {At-risk student.;Dashboard;Educational data mining;Learning analytic;Learning management system;Machine learning techniques;Machine-learning;Risk of failure;Student interactions;Students' behaviors;},
URL = {http://dx.doi.org/10.1109/LACLO54177.2021.00019},
} 


@inproceedings{20220611599261 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CAN A LEARNING ANALYTICS DASHBOARD PARTICIPATIVE DESIGN APPROACH BE TRANSPOSED TO AN ONLINE-ONLY CONTEXT?},
journal = {18th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2021},
author = {Oliver-Quelennec, Katia and Bouchet, Francois and Carron, Thibault and Pincon, Claire},
year = {2021},
pages = {63 - 70},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">In-person sessions of participative design are commonly used in the field of Learning Analytics, but to reach students not always available on-site (e.g. during a pandemic), they have to be adapted to online-only context. Card-based tools are a common co-design method to collect users' needs, but this tangible format limits data collection and usage. We propose here two steps: first to use an existing co-design card deck-based method for our university context and next to adapt this new method called PADDLE (PArticipative Design of Dashboard for Learning in Education) for an online use. This article presents key factors and points of attention identified in adapting a card-based co-design method into a digital version for designing learning dashboards. This digital adaptation and the associated tool, ePADDLE, were tested with first year university students divided into 18 groups (N = 58). All groups have successfully designed a dashboard, and using the original evaluation scales, users have evaluated ePADDLE as almost as suitable as the original method. Thanks to the traces provided by the online version, we rely on speech acts to identify favorable conditions for successful collaboration.<br/></div> © 2021 Virtual Simulation Innovation Workshop, SIW 2021. All rights reserved.},
key = {Design},
keywords = {E-learning;},
note = {Card;Co-designs;Codesign method;Data collection;Data usage;Design approaches;Learning analytic dashboard;Participative designs;Participatory design;User need;},
} 


@inproceedings{20215211386403 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics based formative assessment: Gaining insights through interactive dashboard components in mathematics teaching},
journal = {CEUR Workshop Proceedings},
author = {Abu-Raya, Kholod and Olsher, Shai},
volume = {3042},
year = {2021},
issn = {16130073},
address = {Bozen-Bolzano, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">Conducting a student centered discussion in a mathematics classroom is not a trivial task. A teacher must follow their students work, and then use the relevant information in order to conduct a meaningful discussion. This challenge is greater when digital environments are involved, or when the students work remotely and only submit their work online. One possible solution for this challenge could be in the form of accessible learning analytics that could assist the teacher to gain insight about their student's work. We report on a formative assessment platform that automatically analyzes student submissions and characterizes them according to preset conditions that are topic specific. These characterizations are then used in several interactive reports that form a teacher's dashboard that is designed to enable multiple levels of analysis by the teachers in planning a classroom discussion. We describe the different components and demonstrate their use in mathematics classrooms in Israel.<br/></div> © 2021 Copyright for this paper by its authors.},
key = {Students},
keywords = {E-learning;},
note = {Digital environment;Formative assessment;Gaining insights;Mathematics teachings;Online formative assessment;Specific learning;Student-centred;Teacher dashboard;Teachers';Topic specific learning analytic;},
} 


@article{20214811253983 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Responsive dashboard as a component of learning analytics system for evaluation in emergency remote teaching situations},
journal = {Sensors},
author = {Corbu, Emilia Corina and Edelhauser, Eduard},
volume = {21},
number = {23},
year = {2021},
issn = {14248220},
abstract = {<div data-language="eng" data-ev-field="abstract">The pandemic crisis has forced the development of teaching and evaluation activities ex-clusively online. In this context, the emergency remote teaching (ERT) process, which raised a mul-titude of problems for institutions, teachers, and students, led the authors to consider it important to design a model for evaluating teaching and evaluation processes. The study objective presented in this paper was to develop a model for the evaluation system called the learning analytics and evaluation model (LAEM). We also validated a software instrument we designed called the Eval-MathI system, which is to be used in the evaluation system and was developed and tested during the pandemic. The optimization of the evaluation process was accomplished by including and integrating the dashboard model in a responsive panel. With the dashboard from EvalMathI, six online courses were monitored in the 2019/2020 and 2020/2021 academic years, and for each of the six monitored courses, the evaluation of the curricula was performed through the analyzed parameters by highlighting the percentage achieved by each course on various components, such as content, adaptability, skills, and involvement. In addition, after collecting the data through interview guides, the authors were able to determine the extent to which online education during the COVID 19 pandemic has influenced the educational process. Through the developed model, the authors also found software tools to solve some of the problems raised by teaching and evaluation in the ERT environment.<br/></div> © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
key = {Teaching},
keywords = {E-learning;Software testing;COVID-19;Education computing;Curricula;Learning systems;},
note = {Analytics systems;Digital transformation;Elearning and digital transformation of education;Emergency remote teaching;IT for education;Learning analytic;On-line education;Remote teaching;Responsive dashboard;Teaching situations;},
URL = {http://dx.doi.org/10.3390/s21237998},
} 


@inproceedings{20221111797036 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Beyond the Learning Analytics Dashboard: Alternative Ways to Communicate Student Data Insights Combining Visualisation, Narrative and Storytelling},
journal = {ACM International Conference Proceeding Series},
author = {Fernandez Nieto, Gloria Milena and Kitto, Kirsty and Buckingham Shum, Simon and Martinez-Maldonado, Roberto},
year = {2022},
pages = {219 - 229},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics (LA) dashboards have become a popular medium for communicating to teachers analytical insights obtained from student data. However, recent research indicates that LA dashboards can be complex to interpret, are often not grounded in educational theory, and frequently provide little or no guidance on how to interpret them. Despite these acknowledged problems, few suggestions have been made as to how we might improve the visual design of LA tools to support richer and alternative ways to communicate student data insights. In this paper, we explore three design alternatives to represent student multimodal data insights by combining data visualisation, narratives and storytelling principles. Based on foundations in data storytelling, three visual-narrative interfaces were designed with teachers: i) visual data slices, ii) a tabular visualisation, and iii) a written report. These were validated as a part of an authentic study where teachers explored activity logs and physiological data from co-located collaborative learning classes in the context of healthcare education. Results suggest that alternatives to LA dashboards can be considered as effective tools to support teachers' reflection, and that LA designers should identify the representation type that best fits teachers' needs.<br/></div> © 2022 ACM.},
key = {Students},
keywords = {Data visualization;Visualization;},
note = {Analytic tools;Educational theory;Multi-modal data;Narrative and storytelling;Qualitative analysis;Recent researches;Teachers';Visual design;Visual learning;Visual learning analytic;},
URL = {http://dx.doi.org/10.1145/3506860.3506895},
} 


@article{20201408375692 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Linking learning behavior analytics and learning science concepts: Designing a learning analytics dashboard for feedback to support learning regulation},
journal = {Computers in Human Behavior},
author = {Sedrakyan, Gayane and Malmberg, Jonna and Verbert, Katrien and Jarvela, Sanna and Kirschner, Paul A.},
volume = {107},
year = {2020},
issn = {07475632},
abstract = {Technological advancements have generated a strong interest in exploring learner behavior data through learning analytics to provide both learner and instructor with process-oriented feedback in the form of dashboards. However, little is known about the typology of dashboard feedback relevant for different learning goals, learners and teachers. While most dashboards and the feedback that they give are based only on learner performance indicators, research shows that effective feedback needs also to be grounded in the regulatory mechanisms underlying learning processes and an awareness of the learner's learning goals. The design artefact presented in this article uses a conceptual model that visualizes the relationships between dashboard design and the learning sciences to provide cognitive and behavioral process-oriented feedback to learners and teachers to support regulation of learning. A practical case example is given that demonstrates how the ideas presented in the paper can be deployed in the context of a learning dashboard. The case example uses several analytics/visualization techniques based on empirical evidence from earlier research that successfully tested these techniques in various learning contexts.<br/> © 2018 Elsevier Ltd},
key = {Learning systems},
keywords = {Behavioral research;},
note = {Behavior analytics;Learning analytics dashboards;Learning process;Process-oriented;Regulation of learning;},
URL = {http://dx.doi.org/10.1016/j.chb.2018.05.004},
} 


@inproceedings{20200308048979 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Impact of a learning analytics dashboard on the practice of students and teachers},
journal = {SEFI 47th Annual Conference: Varietas Delectat... Complexity is the New Normality, Proceedings},
author = {Hardebolle, C. and Jermann, P. and Pinto, F. and Tormey, R.},
year = {2020},
pages = {1622 - 1632},
address = {Budapest, Hungary},
abstract = {This paper reports results of the deployment of a learning analytics dashboard in the context of introductory Maths, Physics and Chemistry courses in the first year of the Engineering bachelor of a Swiss technical university. Informed by research on self-regulated learning, learning analytics dashboards and the social practice of learning in Higher Education, the tool includes a learning diary feature where students report their progress and the difficulties encountered in solving the course exercises. Both students and teachers have access to a dashboard showing an overview of the class progress and difficulties, the student view including personalized feedback. We present usage and survey data, and show how these help to identify key intervention principles to maximize the impact of learning analytics dashboards on the practice of students and teachers.<br/> © 2020 SEFI 47th Annual Conference: Varietas Delectat... Complexity is the New Normality, Proceedings. All rights reserved.},
key = {Students},
note = {Higher education;Learning;Learning analytics dashboards;Learning diaries;Personalized feedback;Self-regulated learning;Social practices;Technical universities;},
} 


@article{20234715087117 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards Optimization of Learning Analytics Dashboards That are Customized for the Students' Requirements},
journal = {IEEE Transactions on Learning Technologies},
author = {Israel-Fishelson, Rotem and Kohen-Vacs, Dan},
volume = {17},
year = {2024},
pages = {794 - 802},
issn = {19391382},
abstract = {<div data-language="eng" data-ev-field="abstract">Educational dashboards enable students to monitor and reflect on academic performance and administrative aspects of the learning processes. Occasionally, educational institutions integrate dashboards using the information found in their learning management systems or their students' information desks. Learning analytics offers ways to enrich these dashboards and expose students to analyzed information beyond the monitored data provided such as smart recommendations. Despite the large variety of dashboards, the students' centric perspective and the ability to adapt the dashboard to their personal needs is not a common practice. To identify and support the needs of students who wish to track aspects of their learning routine, it is very important to position the students at the core of the design process of these dashboards. This article presents a new phase in our research to expand our understanding of the students' needs in monitoring their educational routines and preferences while using an advanced form of a learning analytics dashboard. We propose an optimized approach for designing educational dashboards. In this sense, we examine and seek to integrate the components that are prominently required by students. Hence, we address both the type of components as well as their arrangement within the customized dashboard. The outcomes of our efforts reveal findings concerning students' trends and habits when exploiting these dashboards. It also offers pivotal insights and recommendations for the optimized implementation of learning analytics dashboards that are aligned with the students' authentic requirements.<br/></div> © 2008-2011 IEEE.},
key = {Students},
keywords = {Design;Information management;Learning systems;},
note = {Academic performance;Dashboard component;Design cluster;Educational institutions;Learning analytic dashboard;Learning management system;Learning process;Optimisations;Student information desk;},
URL = {http://dx.doi.org/10.1109/TLT.2023.3332500},
} 


@inproceedings{20200608139223 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Design of learning analytics dashboard supporting metacognition},
journal = {16th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2019},
author = {Chen, Li and Lu, Min and Goda, Yoshiko and Yamada, Masanori},
year = {2019},
pages = {175 - 182},
address = {Cagliari, Italy},
abstract = {Metacognition is an aspect in self-regulated learning and is necessary to achieve such learning in an effective and efficient manner. However, it is not always easy and accurate for learners to monitor or assess their own metacognition. In this study, we designed a learning analytics dashboard to improve self-regulated learning in online environments through the collection and analysis of learning log data. There are two separate dashboards used in our system: a knowledge monitoring dashboard and a strategy use dashboard. The knowledge monitoring dashboard is designed to support the knowledge monitoring skills of learners, allowing them to monitor their prior knowledge, whereas the strategy use dashboard is designed to help learners develop metacognitive skills of planning, monitoring, and regulation.<br/> © 2019 16th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2019. All rights reserved.},
key = {E-learning},
keywords = {Cognitive systems;},
note = {Dashboard;Knowledge monitoring;Learning Analytics;Metacognition;Metacognitive skills;Online environments;Prior knowledge;Self-regulated learning;},
URL = {http://dx.doi.org/10.33965/celda2019_201911l022},
} 


@inproceedings{20214411101217 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CADA: A learning analytics dashboard to support teachers with visualizations about students’ participation and discourse in online discussions},
journal = {CEUR Workshop Proceedings},
author = {Kaliisa, Rogers and Dolonen, Jan Arild},
volume = {2985},
year = {2021},
issn = {16130073},
address = {Stockholm, Sweden},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper introduces a Canvas discussion analytics tool (CADA), designed following a human-computer interaction approach to provide teachers with real-time insights about students’ participation and discourse in online discussions. CADA supports the automatic extraction and analysis of discussion forums posts and interactions from the Canvas LMS and provides visualizations that communicate at a glance and in detail about participation rate, concepts being used and their epistemic connections, contributions per participant, and sentiment scores. The outputs provided by CADA make students’ thinking visible to the teacher, which provides an informed basis to intervene and change the course activities. This work-in-progress paper outlines the functional features included in CADA, preliminary results, and the next steps for evaluating, redesign and research with CADA in authentic teaching environments.<br/></div> © 2020 Copyright for this paper by its authors.},
key = {Visualization},
keywords = {Teaching;Human computer interaction;Students;Social networking (online);},
note = {Analytic tools;Automatic extraction;Design-based research;Learning analytic;Online discussions;Real- time;Student participation;Teacher dashboard;Teachers';Tool support;},
} 


@inproceedings{20203909251066 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a Learning Analytics Dashboard for Collaborative Conversational Agent Activities in MOOCs},
journal = {Advances in Intelligent Systems and Computing},
author = {Tegos, Stergios and Tsiatsos, Thrasyvoulos and Psathas, Georgios and Demetriadis, Stavros},
volume = {1192 AISC},
year = {2021},
pages = {693 - 704},
issn = {21945357},
address = {Thessaloniki, Greece},
abstract = {This paper presents the design of a learning analytics dashboard, utilizing learning traces that emerge from conversational MOOC activities. These chat-based activities encourage students to collaborate in dyads, with the support of a conversational agent, in order to answer open-ended questions, set by the course instructor. Taking into account the dynamic and context-sensitive nature of the agent-based support provided during this kind of online activities, we aspire to share a series of variables, metrics and use cases, which can be valuable for practitioners and researchers looking forward to initiate the development of a learning analytics dashboard that encompasses aspects of both peer-to-peer and human-to-bot conversational interactions.<br/> © 2021, Springer Nature Switzerland AG.},
key = {Curricula},
keywords = {E-learning;},
note = {Agent based;Context sensitive;Conversational agents;Conversational interaction;Online activities;Open-ended questions;Peer to peer;},
URL = {http://dx.doi.org/10.1007/978-3-030-49932-7_65},
} 


@inproceedings{20211510207582 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A teacher-facing learning analytics dashboard for process-oriented feedback in online learning},
journal = {ACM International Conference Proceeding Series},
author = {Dourado, Raphael A. and Rodrigues, Rodrigo Lins and Ferreira, Nivan and Mello, Rafael Ferreira and Gomes, Alex Sandro and Verbert, Katrien},
year = {2021},
pages = {482 - 489},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">In online learning, teachers need constant feedback about their students' progress and regulation needs. Learning Analytics Dashboards for process-oriented feedback can be a valuable tool for this purpose. However, few such dashboards have been proposed in literature, and most of them lack empirical validation or grounding in learning theories. We present a teacher-facing dashboard for process-oriented feedback in online learning, co-designed and evaluated through an iterative design process involving teachers and visualization experts. We also reflect on our design process by discussing the challenges, pitfalls, and successful strategies for building this type of dashboard.<br/></div> © 2021 ACM.},
key = {Visualization},
keywords = {Facings;Learning systems;E-learning;},
note = {Constant feedback;Design process;Empirical validation;Iterative design;Learning Theory;Online learning;Process-oriented;},
URL = {http://dx.doi.org/10.1145/3448139.3448187},
} 


@article{20185106264858 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LADA: A learning analytics dashboard for academic advising},
journal = {Computers in Human Behavior},
author = {Gutierrez, Francisco and Seipp, Karsten and Ochoa, Xavier and Chiluiza, Katherine and De Laet, Tinne and Verbert, Katrien},
volume = {107},
year = {2020},
issn = {07475632},
abstract = {From the perspective of Learning and Educational Technologies, academic advising has been one of the most overlooked aspects of academic support systems, despite being critical for the learning process and final success of students. The majority of higher education institutions provides simple technical support to academic advisers with basic descriptive statistics. This article presents the general design and implementation of a Learning Analytics Dashboard for Advisers (LADA), to support the decision-making process of academic advisers through comparative and predictive analysis. Moreover, this work evaluates the use of this tool to support decision-making of actual advisers in two different higher education institutions (University A, University B), compared with more traditional procedures and tools. Results indicate that LADA enables expert advisers to evaluate significantly more scenarios (Median = 2), especially for high advising difficulty cases with students that failed many courses (Median<inf>A</inf>=3,Median<inf>B</inf>=2.5), in a not-significantly different amount of time. For inexperienced advisers, LADA is perceived as a valuable tool for more accurate and efficient decision-making, as they were able to make informed decisions in a similar amount of time compared to the experts. These results are encouraging for further developments in the field.<br/> © 2018 Elsevier Ltd},
key = {Decision making},
keywords = {Data visualization;Predictive analytics;Learning systems;Students;},
note = {Academic adviser;Academic advising;Data driven decision;Decision making process;Descriptive statistics;Further development;Higher education institutions;Learning analytics;},
URL = {http://dx.doi.org/10.1016/j.chb.2018.12.004},
} 


@article{20204509453543 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Self-regulation and emotion matter: A case study of instructor interactions with a learning analytics dashboard},
journal = {Computers and Education},
author = {Zheng, Juan and Huang, Lingyun and Li, Shan and Lajoie, Susanne P. and Chen, Yuxin and Hmelo-Silver, Cindy E.},
volume = {161},
year = {2021},
issn = {03601315},
abstract = {Learning analytics (LA) is providing new methodologies that are being applied to the design and application of dashboards to support teaching and learning. However, few studies attempt to understand how instructors interact with an LA dashboard and how self-regulated learning (SRL) activities and emotions of instructors occur and co-occur in the interaction. The current study investigates ten instructors’ SRL activities and epistemic emotions by analyzing the screen capture videos and think-aloud data while they interact with an LA dashboard designed to support the online asynchronous collaboration of multiple groups. The results reveal that instructors demonstrated two ways of navigating LA dashboards, and they relied heavily on the conversation explorer feature. Instructors were mostly engaged in elaboration, monitoring, and evaluation activities and they frequently experienced confusion and enjoyment. Expert instructors were more likely to refer to their personal teaching experience and demonstrated more epistemic emotions than novice instructors. This study contributes to the literature on SRL and teacher emotions by revealing the critical role of elaboration, monitoring, evaluation, and epistemic emotions when instructors attempt to understand a LA dashboard by themselves. These findings highlight the importance of providing pedagogical assistance to teachers who are trying to navigate between group dynamics and visualizations viewed using LA dashboards.<br/> © 2020 Elsevier Ltd},
key = {Learning systems},
keywords = {E-learning;},
note = {Asynchronous collaboration;Design and application;Evaluation activity;Screen capture;Self regulation;Self-regulated learning;Teaching and learning;Teaching experience;},
URL = {http://dx.doi.org/10.1016/j.compedu.2020.104061},
} 


@inproceedings{20192707151797 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Learning Analytics Dashboard to Analyse Learning Activities in Interpreter Training Courses},
journal = {Communications in Computer and Information Science},
author = {Taibi, Davide and Bianchi, Francesca and Kemkes, Philipp and Marenzi, Ivana},
volume = {1022},
year = {2019},
pages = {268 - 286},
issn = {18650929},
address = {Funchal, Portugal},
abstract = {Learning analytics dashboards constitute an effective tool for monitoring learning activities that take place in online learning environments. Thanks to dashboards, teachers can promptly detect low levels of student engagement in given tasks, incorrect usage of a system, and other types of pedagogically relevant information, which helps them to better support students in achieving their learning objectives. This study describes the integration of a dashboard in an online learning system. The system includes a tool that guides students in the creation of highly informative bilingual glossaries, a service that traces student searches on the web for reference material, and a service that tracks student interactions with the glossary. The data thus collected are selectively displayed in the newly developed dashboard. The dashboard was specifically designed to allow teachers to monitor the students’ approaches to glossary building and to provide individual remedial feedback, if necessary. It was also intended to spur students to keep on a par with the rest of the class, by seeing their status compared to the rest of the class. The system was tested with two groups of university students specializing in interpreting, and two different teachers. The results of the experiments suggest that this integrated system manages to achieve its goals and provides students and teachers of interpreting with an innovative online tool that concretely fosters and supports vocabulary building.<br/> © 2019, Springer Nature Switzerland AG.},
key = {Students},
keywords = {Learning systems;Glossaries;Search engines;Computer aided instruction;E-learning;Tracking (position);},
note = {Interpreting;Learning analytics dashboard;Learning objectives;On-line learning systems;Online learning environment;Student interactions;Tracking system;Vocabulary building;},
URL = {http://dx.doi.org/10.1007/978-3-030-21151-6_14},
} 


@inproceedings{20221211820455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboard Prototype for Implicit Feedback from Metacognitive Prompt Responses},
journal = {29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings},
author = {Carlon, May Kristine Jonson and Cross, Jeffrey S.},
volume = {1},
year = {2021},
pages = {267 - 272},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">Online learning can be challenging to learners as they need to have autonomous learning skills to succeed, and to instructors as direct observation and real-time communication with learners are limited. Learning analytics dashboards have been used to assist the learners in developing autonomous learning skills and the instructors in keeping track of the learners’ progress. However, there is little information on systems supporting both learners and instructors in online learning environments. This paper builds on our previous work developing learners' metacognitive skills through open response prompts by using the learner inputs to create a dashboard that uncovers implicit feedback such as sentiments, misconceptions, and shallow learning. The instructor can consult the dashboard on-demand, and the input is from metacognitive prompts that only the individual learners see. Hence, the instructor can provide timely interventions based on inputs from learners who otherwise would not voice their concerns in more public channels such as discussion forums.<br/></div> © 2021 29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings. All rights reserved},
key = {Sentiment analysis},
keywords = {Computer aided instruction;E-learning;Online systems;Learning systems;},
note = {Autonomous learning;Implicit feedback;Learning analytic;Learning management system;Learning skills;Metacognitive prompting;Metacognitives;Sentiment analysis;Text similarity;Topic Modeling;},
} 


@inproceedings{20192407052335 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {User centered approach for learning analytics dashboard generation},
journal = {CSEDU 2019 - Proceedings of the 11th International Conference on Computer Supported Education},
author = {Ines, Dabbebi and Jean-Marie, Gilliot and Sebastien, Iksal},
volume = {2},
year = {2019},
pages = {260 - 267},
address = {Heraklion, Crete, Greece},
abstract = {<div data-language="eng" data-ev-field="abstract">The use of learning dashboards with analytics might help users to gain insight into their learning process and then to make decision. However, designing meaningful Learning Analytics dashboard (LAD) is still a complex process that requires an explicit understanding of the user needs. For this reason, we carried out a user-centered design (UCD) approach with the aim to provide users with adapted LADs to support their decision-making. Hence, we develop a UCD process composed of 4 steps: (i) we propose a participatory-based design tool for capturing contextualized needs (ii) these identified needs will be described using an independent formalism and LAD models in order to capitalize on them (iii) to automate these models, we propose a LAD generation process (iv) finally, we carried out an evaluation phase with the aim to review and refine our models. During our process development, an iterative user needs refinement confirmed that decision is considered as a centered element for LAD generations.<br/></div> Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
key = {Decision making},
keywords = {Learning systems;User centered design;E-learning;},
note = {Complex Processes;Dashboard;Evaluation phase;Generation process;Learning analytics;Process development;User Centered Design(UCD);User-centered approach;},
URL = {http://dx.doi.org/10.5220/0007693102600267},
} 


@article{20215011304289 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Development of Learning Analytics Dashboard based on Moodle Learning Management System},
journal = {International Journal of Advanced Computer Science and Applications},
author = {Xin, Ong Kiat and Singh, Dalbir},
volume = {12},
number = {7},
year = {2021},
pages = {838 - 843},
issn = {2158107X},
abstract = {<div data-language="eng" data-ev-field="abstract">Digitalization catalyzes drastic changes to a particular subject or area. Digitalization is an operational structure transformation process, such as in the educational domain. Digitalization in the academic field has brought the classroom to the users’ fingertips with the prevalence of e-learning applications, learning management systems, etc. However, with the increasing number of digital learning platform users, educators find it hard to monitor their students’ progress. Analytics that analyze data generated from the usage pattern of the users contribute to giving the educators an insight regarding the performance of their students. With that, they can apply early intervention and modification of their delivery method to suit the students’ needs and, at the same time, increase the quality of the content. This study illustrates the development of a learning analytics dashboard that can improve learning outcomes for educators and students.<br/></div> © 2021. All Rights Reserved.},
key = {Students},
keywords = {E-learning;Learning systems;},
note = {Academic fields;Catalyse;Digital-learning;e-Learning application;Learning analytic;Learning management system;Moodle;Operational structure;Structure transformations;Transformation process;},
URL = {http://dx.doi.org/10.14569/IJACSA.2021.0120793},
} 


@unpublished{20240071151 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LEARNING ANALYTICS DASHBOARDS FOR ADVISORS - A SYSTEMATIC LITERATURE REVIEW},
journal = {arXiv},
author = {Vemula, Suchith Reddy and Moraes, Marcia},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboard for Advisors is designed to provide data-driven insights and visualizations to support advisors in their decision-making regarding student academic progress, engagement, targeted support, and overall success. This study explores the current state of the art in learning analytics dashboards, focusing on specific requirements for advisors. By examining existing literature and case studies, this research investigates the key features and functionalities essential for an effective learning analytics dashboard tailored to advisor needs. This study also aims to provide a comprehensive understanding of the landscape of learning analytics dashboards for advisors, offering insights into the advancements, opportunities, and challenges in their development by synthesizing the current trends from a total of 21 research papers used for analysis. The findings will contribute to the design and implementation of new features in learning analytics dashboards that empower advisors to provide proactive and individualized support, ultimately fostering student retention and academic success.<br/></div> © 2024, CC BY-NC-ND.},
key = {Decision making},
keywords = {Learning systems;},
note = {'current;Advisor dashboard;And learning management system;Data driven;Decisions makings;Learning analytic;Learning management system;Self-regulated learning;State of the art;Systematic literature review;},
URL = {http://dx.doi.org/10.48550/arXiv.2402.01671},
} 


@article{20242816667813 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboards for Assessing Remote Labs Users' Work: A Case Study with VISIR-DB},
journal = {Technology, Knowledge and Learning},
author = {Serrano, Vanessa and Cuadros, Jordi and Fernandez-Ruano, Laura and Garcia-Zubia, Javier and Hernandez-Jayo, Unai and Lluch, Francesc},
volume = {30},
number = {1},
year = {2025},
pages = {263 - 290},
issn = {22111662},
abstract = {<div data-language="eng" data-ev-field="abstract">In science and engineering education, remote laboratories are designed to bring ubiquity to experimental scenarios, by having real laboratories operated through the Internet. Despite that remote laboratories enable the collection of students' work data, the educational use of these data is still underdeveloped. Learning analytics dashboards are common tools to present and analyze educational data to provide indicators to understand learning processes. This paper presents how data from remote labs, such as Virtual Instruments Systems In Reality (VISIR), can be analyzed through a learning analytics dashboard to help instructors provide better feedback to their pupils. Visualizations to study the use of the VISIR, to assess students’ performance in a particular activity and to facilitate the assisted assessment of students are introduced to the VISIR dashboard (VISIR-DB). These visualizations include a new recodification of circuits that keeps the fragment being measured, in order to better identify student’s intention. VISIR-DB also incorporates functions to check a priori steps in the resolution process and/or potential errors (observation items), and logical combinations of them to grade students' performance according to the expected outcomes (assessment milestones). Both work indicators, observation items and assessment milestones, can be defined in activity-specific text files and allow for checking the circuit as coded by the interface, the conceptual circuit it represents, its components, parameters, and measurement result. Main results in the use of VISIR for learning DC circuits course show that students mainly use VISIR when indicated by instructors and a great variability regarding to time of use and number of experiments performed. For the particular assessment activity, VISIR-DB helps to easily detect that there is a significant number of students that did not achieved any of the expected tasks. Additionally, it helps to identify students that still make a huge number of errors at the end of the course. Appropriate interventions can be taken from here.<br/></div> © The Author(s) 2024.},
key = {Students},
keywords = {Data mining;Electric network analysis;Engineering education;Laboratories;Visualization;},
note = {Case-studies;Educational use;Learning analytic;Learning analytic dashboard;Remote laboratories;Remote labs;Science and engineering;Student performance;Virtual instrument system in reality;Virtual instrument systems;},
URL = {http://dx.doi.org/10.1007/s10758-024-09752-3},
} 


@article{20233714706976 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A human-centred learning analytics approach for developing contextually scalable K-12 teacher dashboards},
journal = {British Journal of Educational Technology},
author = {Wiley, Korah and Dimitriadis, Yannis and Linn, Marcia},
volume = {55},
number = {3},
year = {2024},
pages = {845 - 885},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper describes a Human-Centred Learning Analytics (HCLA) design approach for developing learning analytics (LA) dashboards for K-12 classrooms that maintain both contextual relevance and scalability—two goals that are often in competition. Using mixed methods, we collected observational and interview data from teacher partners and assessment data from their students' engagement with the lesson materials. This DBR-based, human-centred design process resulted in a dashboard that supported teachers in addressing their students' learning needs. To develop the dashboard features that could support teachers, we found that a design refinement process that drew on the insights of teachers with varying teaching experience, philosophies and teaching contexts strengthened the resulting outcome. The versatile nature of the approach, in terms of student learning outcomes, makes it useful for HCLA design efforts across diverse K-12 educational contexts. Practitioner notes What is already known about this topic Learning analytics that are aligned to both a learning theory and learning design support student learning. LA dashboards that support users to understand the associated learning analytics data provide actionable insight. Design-based research is a promising methodology for Human-Centred Learning Analytics design, particularly in the K-12 educational context. What this paper adds Leveraging a longstanding, yet fluid, research-practice partnership is an effective design-based research adaptation for addressing the high variation in instructional practices that characterize K-12 education. Using both quantitative and qualitative data that reflects students' developing knowledge effectively supports teachers' inquiry into student learning. Teachers' use of learning analytics dashboards is heavily influenced by their perspectives on teaching and learning. Implications for practice and/or policy Impact on student learning outcomes, alongside usability and feasibility, should be included as a necessary metric for the effectiveness of LA design. LA dashboard developers should both leverage learning data that reflect students' developing knowledge and position teachers to take responsive pedagogical action to support student learning. LA researchers and developers should utilize a long-term, yet fluid, research-practice partnership to form a multi-stakeholder, multidisciplinary design team for Human-Centred Learning Analytics design.<br/></div> © 2023 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
key = {Students},
keywords = {Design;Knowledge management;Learning systems;Philosophical aspects;},
note = {Analytic design;Design-based research;Human-centered learning analytic;K-12 education;Knowledge integration;Learning outcome;Student learning;Student learning outcomes;Teacher dashboard;Teachers';},
URL = {http://dx.doi.org/10.1111/bjet.13383},
} 


@inproceedings{20211510207516 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating a learning analytics dashboard to visualize student self-reports of time-on-task: A Case Study in a Latin American University},
journal = {ACM International Conference Proceeding Series},
author = {Hilliger, Isabel and Miranda, Constanza and Schuit, Gregory and Duarte, Fernando and Anselmo, Martin and Parra, Denis},
year = {2021},
pages = {592 - 598},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">In recent years, instructional design has become even more challenging for teaching staff members in higher education institutions. If instructional design causes student overload, it could lead to superficial learning and decreased student well-being. A strategy to avoid overload is reflecting upon the effectiveness of teaching practices in terms of time-on-task. This article presents a Work-In-Progress conducted to provide teachers with a dashboard to visualize student self-reports of time-on-task regarding subject activities. A questionnaire was applied to 15 instructors during a set trial period to evaluate the perceived usability and usefulness of the dashboard. Preliminary findings reveal that the dashboard helped instructors became aware about the number of hours spent outside of class time. Furthermore, data visualizations of time-on-task evidence enabled them to redesign subject activities. Currently, the dashboard has been adopted by 106 engineering instructors. Future work involves the development of a framework to incorporate user-based improvements.<br/></div> © 2021 ACM.},
key = {Students},
note = {Engineering instructors;Higher education institutions;Instructional designs;Latin americans;Perceived usability;Teaching practices;Teaching staff;Work in progress;},
URL = {http://dx.doi.org/10.1145/3448139.3448203},
} 


@inproceedings{20213810902204 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Question-driven learning analytics: Designing a teacher dashboard for online breakout rooms},
journal = {Proceedings - IEEE 21st International Conference on Advanced Learning Technologies, ICALT 2021},
author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Singh, Shaveen and Chen, Peter and Richardson, Dan and Bartindale, Tom and Olivier, Patrick and Gasevic, Dragan},
year = {2021},
pages = {176 - 178},
address = {Virtual, Online, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">One of the ultimate goals of several learning analytics (LA) initiatives is to close the loop and support students' and teachers' reflective practices. Although there has been a proliferation of end-user interfaces (often in the form of dashboards), various limitations have already been identified in the literature such as little account for sensemaking needs. This paper addresses these limitations by proposing a question-driven LA design approach to ensure that end-user LA interfaces explicitly address teachers' questions. We illustrate this in the context of synchronous online activities orchestrated by pairs of teachers using audio-visual and text-based tools (Zoom and Google Docs). This led to the design of an open-source monitoring tool to be used in real-time by teachers when students work collaboratively in breakout rooms, and across learning spaces.<br/></div> © 2021 IEEE.},
key = {Computer aided instruction},
keywords = {Online systems;E-learning;User interfaces;},
note = {Design approaches;End-user interfaces;Google docs;Monitoring tools;Online activities;Open sources;Reflective practices;Sensemaking;},
URL = {http://dx.doi.org/10.1109/ICALT52272.2021.00060},
} 


@inproceedings{20251218095187 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Exploring Eye-tracking Features to Understand Students' Sensemaking of Learning Analytics Dashboards},
journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
author = {Ahrar, Arash and Doroodian, Mohammadreza and Hatala, Marek},
year = {2025},
pages = {931 - 937},
address = {Dublin, Ireland},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards (LADs) are widely used in learning analytics as visual tools to present information about learning activities and outcomes. However, only few studies have explored how students make sense from LAD elements and what cognitive processes follow after viewing each element. In this study, we explore how eye-tracking data can help researchers to identify salient LAD elements critical to students' sensemaking process. Our findings reveal that the eye-tracking derived features, including fixation duration and eye movement patterns, are highly indicative of students' social comparison tendencies and offer valuable insights into their sensemaking processes.<br/></div> © 2025 Copyright held by the owner/author(s).},
key = {Students},
keywords = {Contrastive Learning;},
note = {Cognitive process;Derived features;Eye-tracking;Learning Activity;Learning analytic dashboard;Learning outcome;Sense making;Tracking data;Tracking feature;Visual tools;},
URL = {http://dx.doi.org/10.1145/3706468.3706543},
} 


@inproceedings{20241916032500 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Automating Data Narratives in Learning Analytics Dashboards using GenAI},
journal = {CEUR Workshop Proceedings},
author = {Pinargote, Adriano and Calderon, Eddy and Cevallos, Kevin and Carrillo, Gladys and Chiluiza, Katherine and Echeverria, Vanessa},
volume = {3667},
year = {2024},
pages = {150 - 161},
issn = {16130073},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper presents an innovative approach leveraging Generative Artificial Intelligence to automate data narratives within Learning Analytics Dashboards for collaborative learning scenarios. Focusing on the analysis of class meeting transcripts, the study delves into specific collaboration skill metrics, transforming raw data into a cohesive narrative. Validation through inter-rater reliability, utilizing Cohen’s Kappa coefficient, establishes the reliability of both human and AI assessments. The integration of Large Language Models, such as ChatGPT3.5, is explored, shedding light on their potential in educational narrative assessment. The proposed methodology not only enhances understanding of class dynamics but also contributes a practical tool for educators, seamlessly translating raw data into visually compelling narratives. The paper concludes with insights from a pilot test, revealing student perceptions and addressing concerns around AI impact on dashboard utility and fairness. This research advances the intersection of data storytelling and Learning Analytics Dashboards, offering valuable insights into collaborative learning dynamics.<br/></div> © 2024 CEUR-WS. All rights reserved.},
key = {Artificial intelligence},
keywords = {Data visualization;Metadata;},
note = {Collaboration skills;Collaborative learning;Dashboard;GenAI;Innovative approaches;Interrater reliability;Learning scenarios;Meeting transcripts;Narrative storytelling;Skill metric;},
} 


@inproceedings{20250417734866 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Predictive Learning Analytics Utilizing Formative Assessments and Recommender System for Study Success},
journal = {ISCSET 2024 - 13th International Symposium on Computer Science and Educational Technology},
author = {Shegupta, Ummay Ubaida and Islam, Md Shoriful and Hardt, Wolfram},
year = {2024},
address = {Lauta, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics aims to understand, intervene, optimize, and improve learning. It deploys data produced from students' learning and learning environment. Within this do-main, predictive learning analytics has emerged as a transformative paradigm in education, leveraging data-driven methodologies to forecast student performance. This study represents the technical realization of a predictive learning analytics system using the data from formative assessments and recommendation system. Providing the pedagogical embeddement of the formative assessments along with educational recommender system in a hybrid learning environment, this study shows a prototype of predictive analytics and visualization for students and teachers. Formative assessments is rooted with the theory of scaffolding and recommendation plays vital role as consultation. These concepts combinedly shape early detection of tutoring for study success. Henceforth, the digital learning footprints of the students from online assessment and recommender systems contain the clues which can be detected for predetermining the performance. In this study, a predictive learning analytics (PLA) system is designed and developed that detects students at risk and those performing average and above average, enabling the option of interventions. By analyzing student data through Python and ASP.NET MVC, the system can accurately forecasts academic performance. An interactive dashboard allows educators and students to compare predicted outcomes with actual grades. The findings of this study steer to detect the need and point of tutoring support by combining current performance data with predictive insights to initiate study success.<br/></div> © 2024 IEEE.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;Predictive analytics;Students;},
note = {Analytics systems;Dashboard;Formative assessment;Learning analyt-ic;Learning environments;Predictive learning analytic;Predictive models;Student learning;Study success;Tutoring;},
URL = {http://dx.doi.org/10.1109/ISCSET58624.2024.10807906},
} 


@article{20213210730450 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The influence of task-value scaffolding in a predictive learning analytics dashboard on learners' statistics anxiety, motivation, and performance},
journal = {Computers and Education},
author = {Valle, Natercia and Antonenko, Pavlo and Valle, Denis and Dawson, Kara and Huggins-Manley, Anne Corinne and Baiser, Benjamin},
volume = {173},
year = {2021},
issn = {03601315},
abstract = {<div data-language="eng" data-ev-field="abstract">There is an increasing trend of learning analytics dashboards (LADs) being used to provide feedback to learners. However, there is little empirical evidence about the influence of their design features on learners' cognitive and affective outcomes, especially in high-anxiety courses such as statistics. To address this gap, this study employed a two-group experimental design applied to an authentic setting to assess the influence of task-value scaffolding in a LAD on learners' anxiety, motivation, and learning performance in an online statistics course. This semester-long experiment was implemented in two instances of the course offering (Fall/2019 and Spring/2020) and involved a total of 146 students. The results showed that task-value scaffolding had a negative impact on learners’ computation anxiety and attitudes towards statistics in comparison to the control group. On the other hand, the treatment had no significant influence on other aspects of statistics anxiety, motivation, and learning outcomes. Taken jointly, these results suggest that the use of task-value scaffolding embedded in LADs can have detrimental effects on learners. More experimental studies are necessary to understand the positive and negative effects of LADs with motivational scaffolding.<br/></div> © 2021 Elsevier Ltd},
key = {Statistics},
keywords = {Curricula;Motivation;Predictive analytics;Scaffolds;E-learning;},
note = {Cognitive and affective outcomes;Data science application in education;Design features;Distance education and online learning;Human computer interfaces;Learning performance;Motivation and performance;Pedagogical issues;Postsecondary education;Statistics anxiety;},
URL = {http://dx.doi.org/10.1016/j.compedu.2021.104288},
} 


@article{20205009611106 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Associations between learning analytics dashboard exposure and motivation and self-regulated learning},
journal = {Computers and Education},
author = {Aguilar, Stephen J. and Karabenick, Stuart A. and Teasley, Stephanie D. and Baek, Clare},
volume = {162},
year = {2021},
issn = {03601315},
abstract = {Learning analytics dashboards (LADs) are intended to give relevant information to students and other stakeholders to inform potential next steps in the learning process. The current study examines the relationship between information indirectly presented through academic advisors' use of LADs, and college students' academic motivation, self-regulated learning, and academic achievement. We modeled how changes in student motivation and self-regulated learning (SRL) were related to what occurred during 1-on-1 meetings with academic advisors during which students had the potential to view representations of their achievement embedded within an Early Warning System (EWS) that visually represented aspects of their academic performance referenced with course averages. Constructs associated with SRL were moderated by advisor-advisee meetings. Results indicated that advisors' use of EWS while they met with students was negatively associated with the rate of decrease of students' reporting of using memorizing strategies but positively related when students' performance was compared to that of their peers. We discuss the moderating effects of students’ exposure to visualizations of academic performance on their SRL strategies and academic motivation. This study points to the importance of monitoring the effects of information presented via EWS on motivation and SRL.<br/> © 2020},
key = {Motivation},
keywords = {Students;Learning systems;},
note = {Academic achievements;Academic motivations;Academic performance;College students;Early warning systems;Moderating effect;Self-regulated learning;Student motivation;},
URL = {http://dx.doi.org/10.1016/j.compedu.2020.104085},
} 


@unpublished{20250162291 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The ISC Creator: Human-Centered Design of Learning Analytics Interactive Indicator Specification Cards},
journal = {arXiv},
author = {Joarder, Shoeb and Chatti, Mohamed Amine},
year = {2025},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Emerging research on human-centered learning analytics (HCLA) has demonstrated the importance of involving diverse stakeholders in co-designing learning analytics (LA) systems. However, there is still a demand for effective and efficient methods to co-design LA dashboards and indicators. Indicator Specification Cards (ISCs) have been introduced recently to facilitate the systematic co-design of indicators by different LA stakeholders. In this paper, we strive to enhance the user experience and usefulness of the ISC-based indicator design process. Towards this end, we present the systematic design, implementation, and evaluation details of the ISC Creator, an interactive LA tool that allows low-cost and flexible design of LA indicators. Our findings demonstrate the importance of carefully considered interactivity and recommendations for orienting and supporting non-expert LA stakeholders to design custom LA indicators.<br/></div> © 2025, CC BY-NC-SA.},
key = {Data visualization},
keywords = {Design for manufacturability;Integrated circuit layout;Intellectual property core;Printed circuit design;Specifications;User centered design;},
note = {Analytics systems;Co-designing;Co-designs;Dashboard;Design learning;Human-centered learning analytic;Human-centred designs;Information visualization;Learning analytic;Users' experiences;},
URL = {http://dx.doi.org/10.48550/arXiv.2504.07811},
} 


@article{20190606468996 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An integrated framework for course adapted student learning analytics dashboard},
journal = {Computers in Human Behavior},
author = {Aljohani, Naif Radi and Daud, Ali and Abbasi, Rabeeh Ayaz and Alowibdi, Jalal S. and Basheri, Mohammad and Aslam, Muhammad Ahtisham},
volume = {92},
year = {2019},
pages = {679 - 690},
issn = {07475632},
abstract = {The advanced learning analytics research of the last years converges with the industry demand to enhance famous learning management systems with learning analytics capabilities promoting the efficiency of higher education. The exploitation of big volume learning data, is a critical challenge for the design of personalized curricula and learning experiences. The purpose of this research paper is to communicate a framework for Learning Analytics aiming to support the integrated management of end-to-end learning data. We present the research foundations of a research prototype for the integration of a Learning Analytics Dashboard: The AMBA Prototype with famous Learning Management Systems. Finally, we present the main findings of an empirical study that proves the capacity of learning analytics to enhance the learners' ecosystem with value adding learning services. The proposed framework exploits cognitive computing for the enhancement of decision making in education by proving the capacity of Learning Analytics to reveal hidden patterns of learners’ behaviour and attitude.<br/> © 2018},
key = {Decision making},
keywords = {Information management;Learning systems;Cognitive systems;},
note = {Blackboard;Cognitive Computing;Learning analytics;Learning frameworks;Learning management system;},
URL = {http://dx.doi.org/10.1016/j.chb.2018.03.035},
} 


@article{20251818331276 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The effects of generative AI agents and scaffolding on enhancing students’ comprehension of visual learning analytics},
journal = {Computers and Education},
author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Jin, Yueqiao and Echeverria, Vanessa and Milesi, Mikaela and Fan, Jie and Zhao, Linxuan and Alfredo, Riordan and Li, Xinyu and Gaevi, Dragan},
volume = {234},
year = {2025},
issn = {03601315},
abstract = {<div data-language="eng" data-ev-field="abstract">Visual learning analytics (VLA) is becoming increasingly adopted in educational technologies and learning analytics dashboards to convey critical insights to students and educators. Yet many students experienced difficulties in comprehending complex VLA due to their limited data visualisation literacy. While conventional scaffolding approaches like data storytelling have shown effectiveness in enhancing students’ comprehension of VLA, these approaches remain difficult to scale and adapt to individual learning needs. Generative AI (GenAI) technologies, especially conversational agents, offer potential solutions by providing personalised and dynamic support to enhance students’ comprehension of VLA. This controlled lab study investigates the effectiveness of GenAI agents, particularly when integrated with scaffolding techniques, in improving students’ comprehension of VLA. A randomised controlled trial was conducted with 117 higher education students to compare the effects of two types of GenAI agents: passive agents, which respond to student queries, and proactive agents, which utilise scaffolding questions, against standalone scaffolding in a VLA comprehension task. The results show that passive agents yield comparable improvements to standalone scaffolding both during and after the intervention. Notably, proactive GenAI agents significantly enhance students’ VLA comprehension compared to both passive agents and standalone scaffolding, with these benefits persisting beyond the intervention. These findings suggest that integrating GenAI agents with scaffolding can have lasting positive effects on students’ comprehension skills and support genuine learning.<br/></div> © 2025 The Authors},
key = {Students},
keywords = {Data visualization;Educational robots;Scaffolds;Video analysis;Visualization;},
note = {Generative AI;Individual learning;Language model;Large language model;Learning analytic dashboard;Limited data;Scaffolding;Visual learning;Visual learning analytic;Visualization literacy;},
URL = {http://dx.doi.org/10.1016/j.compedu.2025.105322},
} 


@inproceedings{20242216154251 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Adaptation in Learning Analytics Dashboards: A Systematic Review},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Barbe, Remi and Encelle, Benoit and Sehaba, Karim},
volume = {2},
year = {2024},
pages = {75 - 86},
issn = {21845026},
address = {Angers, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Although learning analytics dashboards (LAD) grow in numbers, they often fail to improve learner awareness as they lack adaptation capabilities. This paper presents a systematic review following the PRISMA statement, about the adaptation capabilities of LADs based on new definitions for LADs and learning indicators. A detailed analysis of 23 articles selected among 426 articles retrieved from databases was conducted based on a coding scheme, centered on adaptation and its dimensions, namely: to whom, what, to what, who, and how. The main result of this study is that there is more evidence of adaptable LADs than adaptive LADs. As a result, the road to adaptivity is worth exploring. The analysis of LAD’s common features led us to distinguish mainly 4 adaptable capabilities and 2 adaptive ones. Most of the adaptable capabilities consist of giving exploration power to the user and providing him with data filtering, zooming, or selection functionalities. In contrast, users have limited options when it comes to selecting indicators, their visualizations, and organization on the dashboard. Providing more flexible LADs could enhance their usability and increase learner awareness. Furthermore, the few adaptive features involve adaptations based on "if-then" rules and there are no reports of advanced computing techniques such as machine learning that could empower LAD’s adaptation.<br/></div> Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
key = {E-learning},
note = {Adaptation;Adaptive features;Adaptivity;Coding scheme;Common features;Data filtering;Learning analytic dashboard;Learning indicator;Power;Systematic Review;},
URL = {http://dx.doi.org/10.5220/0012628600003693},
} 


@article{20193407353266 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Applying and evaluating visualization design guidelines for a MOOC dashboard to facilitate self-regulated learning based on learning analytics},
journal = {KSII Transactions on Internet and Information Systems},
author = {Cha, Hyun-Jin and Park, Taejung},
volume = {13},
number = {6},
year = {2019},
pages = {2799 - 2823},
issn = {19767277},
abstract = {With the help of learning analytics, MOOCs have wider potential to succeed in learning through promoting self-regulated learning (SRL). The current study aims to apply and validate visualization design guidelines for a MOOC dashboard to enhance such SRL capabilities based on learning analytics. To achieve the research objective, a MOOC dashboard prototype, LM-Dashboard, was designed and developed, reflecting the visualization design guidelines to promote SRL. Then, both expert and learner participants evaluated LM-Dashboard through iterations to validate the visualization design guidelines and perceived SRL effectiveness. The results of expert and learner evaluations indicated that most of the visualization design guidelines on LM-Dashboard were valid and some perceived SRL aspects such as monitoring a student’s learning progress and assessing their achievements with time management were beneficial. However, some features on LM-Dashboard should be improved to enhance SRL aspects related to achieving their learning goals with persistence. The findings suggest that it is necessary to offer appropriate feedback or tips as well as to visualize learner behaviors and activities in an intuitive and efficient way for the successful cycle of SRL. Consequently, this study contributes to establishing a basis for the visual design of a MOOC dashboard for optimizing each learner’s SRL.<br/> © 2019 KSII.},
key = {Design},
keywords = {Visualization;Learning systems;},
note = {Learning analytics;Learning goals;Learning progress;MOOCs;Research objectives;Self-regulated learning;Time management;Visualization designs;},
URL = {http://dx.doi.org/10.3837/tiis.2019.06.002},
} 


@inproceedings{20243016745819 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Tools to Analyze Progress and Results with Moodle LMS Data},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Alonso-Fernandez, Cristina and Jorro-Aragoneses, Jose L. and Alaiz, Carlos M. and Rodriguez, Pilar},
year = {2024},
pages = {Aegean Airlines; Avance Car Rental; Computer Logic; IEEE; IEEE Education Society; Mathworks - },
issn = {21659559},
address = {Kos Island, Greece},
abstract = {<div data-language="eng" data-ev-field="abstract">Teachers can benefit from the information provided by learning analytics data for multiple purposes. Visual learning analytics dashboards provide near real-time information while more complex offline tools are commonly used to synthesize and transform the data gathered into interpretable information for teachers. The extended use of Learning Management Systems in universities, such as Moodle or Canvas, provides a rich environment to capture learning analytics data from students' interactions while they are progressing in their courses. In this paper, we present two different learning analytics tools aimed at teachers to obtain information about students' progress and results using data from the Moodle LMS at different stages of their learning process: (1) a progress visualization plugin for Moodle, which provides teachers with real-time information about the progress achieved by students in their courses, and the different goals set for their plans; and (2) an analytics Jupyter Notebook tool with a pre-defined set of analysis and visualizations to apply to data gathered from default activities in Moodle. The plugin is in an initial validation stage, while the analysis tool has been tested in a case study in a university course. Combined, both contributions can enrich the information that teachers have during and after the academic year, adapting their classes to better fit students' progress and needs, as well as providing overall results and comparison between groups after the course has finished.<br/></div> © 2024 IEEE.},
key = {Visualization},
keywords = {Data visualization;Information management;Learning systems;Students;Teaching;},
note = {Analytic tools;Dashboard;Learning analytic;LMS;Moodle;Plug-ins;Real-time information;Student progress;Teachers';Visual learning;},
URL = {http://dx.doi.org/10.1109/EDUCON60312.2024.10578707},
} 


@inproceedings{20203109001418 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Liu, Songran and Mouri, Kousuke and Ogata, Hiroaki},
volume = {12203 LNCS},
year = {2020},
pages = {548 - 557},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {In this paper, we describe about a kind of data flow design that between ubiquitous learning log system called SCROLL and learning analytics and visualizing system called Learning Analytics Dashboard (LAD). SCROLL is a ubiquitous learning system what is logging students’ learning behaviors data in database, and SCROLL can provide students suitable learning method and location to learn efficiently. Lots of paper show that it is appreciate to share the learning data in SCROLL to the other learning analytics system like LTI, Bookroll, Moodle and so on. Learning Analytics Dashboard (LAD) is also a learning data analytics and visualizing system. So share students’ learning data from SCROLL to LAD to show and help students to know their students’ learning situation is the proposal of this paper.<br/> © 2020, Springer Nature Switzerland AG.},
key = {Students},
keywords = {Data Analytics;Data transfer;Learning systems;},
note = {Analytics systems;Data-flow design;Learning behavior;Learning data;Learning methods;Learning situation;Ubiquitous learning;Ubiquitous learning logs;},
URL = {http://dx.doi.org/10.1007/978-3-030-50344-4_39},
} 


@inproceedings{20200908246492 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Investigating Learners' Perception of Learning Analytics Dashboard to Improve Learning Interaction in Online Learning System},
journal = {2019 5th International Conference on Education and Technology, ICET 2019},
author = {Ulfa, Saida and Fattawi, Izzull and Surahman, Ence and Yusuke, Hayashi},
year = {2019},
pages = {49 - 54},
address = {Malang, Indonesia},
abstract = {Big data has changed the approach in designing an e-Learning. When students interact with e-Learning content, automatically generating data, we can collect and trace their learning tracks. The data is processed and analyzed, then used to understand the behavioral characteristics of the user or student to enable a personalized learning experience. In this study, learning analytics dashboard was used to improve learning interaction which impacts the learning successfulness. Tests were conducted on 67 students in the Educational Technology Department of the State University of Malang and distributed questionnaires and then analyzed using descriptive methods. The result is that most of the students who take online learning using the learning analytics dashboard find it helpful to carry out self-evaluations of their interaction hence they can manage their learning. The results of the study showed that most participants agreed that LAD could provide information to them regarding their interactions with learning content (M = 4.15, SD = 0.557), learning environment (M = 4.13, SD = 0.457), as well as the participants could conduct problem identification during their learning process (M = 3.88, SD = 0.477).<br/> © 2019 IEEE.},
key = {Students},
keywords = {E-learning;Computer aided instruction;Learning systems;Surveys;},
note = {Behavioral characteristics;Learners' perceptions;learning analytics;Learning environments;Learning interactions;On-line learning systems;Personalized learning;Problem identification;},
URL = {http://dx.doi.org/10.1109/ICET48172.2019.8987229},
} 


@unpublished{20250101194 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {M2LADS Demo: A System for Generating Multimodal Learning Analytics Dashboards},
journal = {arXiv},
author = {Becerra, Alvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
year = {2025},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">We present a demonstration of a web-based system called M2LADS ("System for Generating Multimodal Learning Analytics Dashboards"), designed to integrate, synchronize, visualize, and analyze multimodal data recorded during computer-based learning sessions with biosensors. This system presents a range of biometric and behavioral data on web-based dashboards, providing detailed insights into various physiological and activity-based metrics. The multimodal data visualized include electroencephalogram (EEG) data for assessing attention and brain activity, heart rate metrics, eye-tracking data to measure visual attention, webcam video recordings, and activity logs of the monitored tasks. M2LADS aims to assist data scientists in two key ways: (1) by providing a comprehensive view of participants’ experiences, displaying all data categorized by the activities in which participants are engaged, and (2) by synchronizing all biosignals and videos, facilitating easier data relabeling if any activity information contains errors.<br/></div> Copyright © 2025, The Authors. All rights reserved.},
key = {Electroencephalography},
keywords = {Biometrics;Brain;Data visualization;Electrophysiology;Metadata;Network security;Visual analytics;},
note = {Biometric and behavior;Computer-based learning;Dashboard;Learning sessions;Multi-modal;Multi-modal learning;Multimodal learning analytic;Online learning;Web-based system;Web-based technologies;},
URL = {http://dx.doi.org/10.48550/arXiv.2502.15363},
} 


@inproceedings{20202408823041 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics dashboard for motivation and performance},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Fleur, Damien S. and van den Bos, Wouter and Bredeweg, Bert},
volume = {12149 LNCS},
year = {2020},
pages = {411 - 419},
issn = {03029743},
address = {Athens, Greece},
abstract = {Deploying Learning Analytics that significantly improve learning outcomes remains a challenge. Motivation has been found to be related to academic achievement and is argued to play an essential role in efficient learning. We developed a Learning Analytics dashboard and designed an intervention that relies on goal orientation and social comparison. Subjects can see a prediction of their final grade in a course as well as how they perform in comparison to classmates with similar goal grades. Those with access to the dashboard ended up more motivated than those without access, outperformed their peers as the course progressed and achieved higher final grades. Our results indicate that learner-oriented dashboards are technically feasible and may have tangible benefits for learners.<br/> © Springer Nature Switzerland AG 2020.},
key = {Motivation},
note = {Academic achievements;Efficient learning;Goal orientations;Learning outcome;Motivation and performance;},
URL = {http://dx.doi.org/10.1007/978-3-030-49663-0_51},
} 


@inproceedings{20211310133543 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Real-time learning analytics dashboard for students in online classes},
journal = {Proceedings of 2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2020},
author = {Owatari, Takuro and Shimada, Atsushi and Minematsu, Tsubasa and Hori, Maiya and Taniguchi, Rin-Ichiro},
year = {2020},
pages = {523 - 529},
address = {Virtual, Takamatsu, Japan},
abstract = {In recent years, online classes have been increasingly conducted in various situations. However, in these classes, especially non-face-to-face and large-scale ones, it is more difficult for teachers and students to understand the status of the class during a lecture. To address this issue, we propose a real-time learning analytics dashboard that provides summarized information on teachers' instruction and students' learning activities during lectures. In this article, we introduce the real-time learning analytics dashboard and report its effectiveness through experiments in an online class at our university.<br/> © 2020 IEEE.},
key = {Real time systems},
keywords = {E-learning;Interactive computer systems;Students;},
note = {Face to face;Learning Activity;Online class;Real-time learning;Teachers';},
URL = {http://dx.doi.org/10.1109/TALE48869.2020.9368340},
} 


@inproceedings{20241115753455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
journal = {ACM International Conference Proceeding Series},
author = {Kaliisa, Rogers and Misiejuk, Kamila and Lopez-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
year = {2024},
pages = {295 - 304},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students' learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.<br/></div> © 2024 Owner/Author.},
key = {Motivation},
keywords = {Computer aided instruction;Learning systems;Students;},
note = {Achievement motivations;Impact;Learning analytic dashboard;Learning outcome;Research studies;Student achievement;Student attitudes;Student learning outcomes;Student motivation;Systematic Review;},
URL = {http://dx.doi.org/10.1145/3636555.3636884},
} 


@inproceedings{20244017130871 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Giorgashvili, Tornike and Jivet, Ioana and Artelt, Cordula and Biedermann, Daniel and Bengs, Daniel and Goldhammer, Frank and Hahnel, Carolin and Mendzheritskaya, Julia and Mordel, Julia and Onofrei, Monica and Winter, Marc and Wolter, Ilka and Horz, Holger and Drachsler, Hendrik},
volume = {15159 LNCS},
year = {2024},
pages = {135 - 151},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards (LAD) have been developed as feedback tools to help students self-regulate their learning (SRL), using the large amounts of data generated by online learning platforms. Despite extensive research on LAD design, there remains a gap in understanding how learners make sense of information visualised on LADs and how they self-reflect using these tools. We address this gap through an experimental study where a LAD delivered personalised SRL feedback based on interactions and progress to a treatment group, and minimal feedback based on the average scores of the class to a control group. Following the feedback, students were asked to state in writing how they would change their study behaviour. Using a coding scheme covering learning strategies, metacognitive strategies and learning materials, three human coders coded 1,251 self-reflection texts submitted by 417 students at three time points. Our results show that learners who received personalised feedback intend to focus on different aspects of their learning in comparison to the learners who received minimal feedback and that the content of the dashboard influences how students formulate their self-reflection texts. Based on our findings, we outline areas where support is needed to improve learners’ sense-making of feedback on LADs and self-reflection in the long term.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;Self-supervised learning;Students;},
note = {Authentic learning;Feed-back based;Feedback tool;Formative feedbacks;Learning analytic dashboard;Learning designs;Learning settings;Psychometric;Self reflection;Self-regulated learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-72315-5_10},
} 


@inproceedings{20192607090367 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {It’s my data! Tensions among stakeholders of a learning analytics dashboard},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
author = {Sun, Kaiwen and Mhaidli, Abraham H. and Watel, Sonakshi and Brooks, Christopher A. and Schaub, Florian},
year = {2019},
pages = {ACM SIGCHI - },
address = {Glasgow, United kingdom},
abstract = {Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system’s developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system’s benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings’ implications for the ethical design and deployment of learning analytics applications in higher education.<br/> © 2019 Copyright held by the owner/author(s).},
key = {Students},
keywords = {Ethical technology;},
note = {Early warning;Ethical designs;Higher education;Learning analytics;Multi-stakeholder analysis;Semi structured interviews;Stakeholder groups;University of Michigan;},
URL = {http://dx.doi.org/10.1145/3290605.3300824},
} 


@article{20202308796425 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Adoption and impact of a learning analytics dashboard supporting the advisor—Student dialogue in a higher education institute in Latin America},
journal = {British Journal of Educational Technology},
author = {De Laet, Tinne and Millecamp, Martijn and Ortiz-Rojas, Margarita and Jimenez, Alberto and Maya, Ricardo and Verbert, Katrien},
volume = {51},
number = {4},
year = {2020},
pages = {1002 - 1018},
issn = {00071013},
abstract = {This paper presents a case study on the adoption and the impact of new modules in a learning analytics dashboard supporting the dialogue between student advisors and students when advising on a study plan for the next academic semester in Escuela Superior Politecnica del Litoral, a higher education institute in Ecuador. The impact and the adoption of the new dashboard modules were assessed using a mixed-methods approach. The quantitative approach builds on data of 172 advisors in 34 programs and 4481 advising sessions in 2019 (post) and 4747 advising sessions in 2018 (pre) to assess the adoption and use of the dashboard, the level of support experienced by the advisors, the impact of the new dashboard modules on the difference between the advised study plan and the plan students register for, and students’ academic achievement. The qualitative approach with observations of 14 staged advising dialogues and semi-structured interviews with eight advisors was used to assess how the dashboard was used and to get deeper understanding of the perceived usefulness and impact of the dashboard. The results show that an institution-wide deployment of dashboard modules tailored to the needs of the advisors can be achieved and can increase the level of support perceived by the advisors and significantly decrease the gap between the suggested study plans in advising dialogues and the study plans that students actually register for. On the short-term, however, no significant changes in academic achievement were observed. Practitioner Notes What is already known about this topic? Academic advising can positively impact retention, academic achievement and study completion. Learning analytics dashboards are promising pieces of educational technology for academic advising as they can trigger reflection and sense-making of educational data. Evaluation of learning analytics dashboards is often still immature and not well-connected to the actual goals of the dashboards. Large-scale evaluations looking at impact of dashboards are even scarcer. What this paper adds? This paper adds, to the scarce scientific evidence on academic advising dashboards, a large-scale case study on a dashboard supporting the advisor student dialogue during the composition of well-balanced study plans. The paper presents research evidence of the impact of the dashboard on the support advisors experience, the study plans suggested by the advisors and the ones actually registered by the students and students’ academic achievement. Evidence is based on a quantitative analysis, using data of 172 advisors from 34 programs representing more than 9000 advising dialogues, and a qualitative analysis using observations and interviews. Implications for practice and/or policy Dashboards to support academic advising dialogues can be realized institution-wide at scale. Training of student advisors supports a large scale deployment. Well-designed dashboards that focus on addressing needs of advisors increase the level of support that advisor experience when advising students. Dashboard accommodating the simulation of study plans and the workload associated with them, succeed in decreasing the variance in suggested plans between advisors and reduce the gap between the study plans that advisors suggest to student and the study plans that students actually register for. Short-term impact on academic achievement was not observed.<br/> © 2020 British Educational Research Association},
key = {Students},
keywords = {Well testing;},
note = {Academic achievements;Large-scale deployment;Perceived usefulness;Qualitative analysis;Qualitative approach;Quantitative approach;Scientific evidence;Semi structured interviews;},
URL = {http://dx.doi.org/10.1111/bjet.12962},
} 


@inproceedings{20204509456823 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Block-based learning analytics repository and dashboard: Towards an interface between researcher and educator},
journal = {ACM International Conference Proceeding Series},
author = {Kesselbacher, Max and Wiltschnig, Kevin and Bollin, Andreas},
year = {2020},
address = {Virtual, Online, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">The collection of programming session data is a cornerstone of programming learning analytics research. For text-based programming, there are data collection projects, like BlueJ's Blackbox, which provide access to the data and thereby facilitate additional research as well as verification. For block-based programming, only data sets of finished projects but not of programming sessions are available. We introduce a data repository that is extendable by implementing instrumentation plugins for various IDEs. The currently supported features are: data collection of text-based and block-based programming sessions, curated user self-registration and filtered data download. This then enables us to implement an educator dashboard in the future, making use of live programming session data to incorporate educators and students into learning analytics research.<br/></div> © 2020 Owner/Author.},
key = {Data acquisition},
keywords = {Computer programming;},
note = {Black boxes;Block based;Block-based learning;Data collection;Data repositories;Plug-ins;Programming learning;},
URL = {http://dx.doi.org/10.1145/3421590.3421662},
} 


@inproceedings{20212510527746 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboard Research Has Neglected Diversity, Equity and Inclusion},
journal = {L@S 2021 - Proceedings of the 8th ACM Conference on Learning @ Scale},
author = {Williamson, Kimberly and Kizilcec, Rene F.},
year = {2021},
pages = {287 - 290},
address = {Virtual, Online, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytic dashboards (LADs) have become more prevalent in higher education to help students, faculty, and staff make data-informed decisions. Despite extensive research on the design and usability of LADs, few studies have examined them in relation to issues of diversity, equity, and inclusion. We conducted a critical literature review to address three research questions: How does LAD research contribute to improving diversity, equity, and inclusion? How might LADs contribute to maintaining or exacerbating inequitable outcomes? And what future opportunities exist in this research space? Our review showed little use of LADs to address or improve issues of diversity, equity, and inclusion in the literature thus far. We argue that excluding these issues from LAD research is not an isolated oversight and it risks reinforcing existing inequities within the higher education system. We argue that LADs can be designed, researched, and deployed intentionally to advance equitable outcomes and help dismantle inequities in education. We highlight opportunities for future LAD research to address issues of diversity, equity, and inclusion.<br/></div> © 2021 Owner/Author.},
key = {Inclusions},
note = {Higher education;Higher education system;Informed decision;Literature reviews;Research questions;},
URL = {http://dx.doi.org/10.1145/3430895.3460160},
} 


@article{20193007236083 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A visual dashboard to track learning analytics for educational cloud computing},
journal = {Sensors (Switzerland)},
author = {Naranjo, Diana M. and Prieto, Jose R. and Molto, German and Calatrava, Amanda},
volume = {19},
number = {13},
year = {2019},
issn = {14248220},
abstract = {Cloud providers such as Amazon Web Services (AWS) stand out as useful platforms to teach distributed computing concepts as well as the development of Cloud-native scalable application architectures on real-world infrastructures. Instructors can benefit from high-level tools to track the progress of students during their learning paths on the Cloud, and this information can be disclosed via educational dashboards for students to understand their progress through the practical activities. To this aim, this paper introduces CloudTrail-Tracker, an open-source platform to obtain enhanced usage analytics from a shared AWS account. The tool provides the instructor with a visual dashboard that depicts the aggregated usage of resources by all the students during a certain time frame and the specific use of AWS for a specific student. To facilitate self-regulation of students, the dashboard also depicts the percentage of progress for each lab session and the pending actions by the student. The dashboard has been integrated in four Cloud subjects that use different learning methodologies (from face-to-face to online learning) and the students positively highlight the usefulness of the tool for Cloud instruction in AWS. This automated procurement of evidences of student activity on the Cloud results in close to real-time learning analytics useful both for semi-automated assessment and student self-awareness of their own training progress.<br/> © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
key = {Students},
keywords = {Cloud analytics;Automation;Learning systems;Web services;},
note = {Amazon web services;Application architecture;Automated assessment;Learning analytics;Learning dashboards;Open source platforms;Real-time learning;Visual learning;},
URL = {http://dx.doi.org/10.3390/s19132952},
} 


@unpublished{20240418230 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Effects of Generative AI Agents and Scaffolding on Enhancing Students’ Comprehension of Visual Learning Analytics},
journal = {arXiv},
author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Jin, Yueqiao and Echeverria, Vanessa and Milesi, Mikaela and Fan, Jie and Zhao, Linxuan and Alfredo, Riordan and Li, Xinyu and Gaevi, Dragan},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Visual learning analytics (VLA) is becoming increasingly adopted in educational technologies and learning analytics dashboards to convey critical insights to students and educators. Yet many students experienced difficulties in comprehending complex VLA due to their limited data visualisation literacy. While conventional scaffolding approaches like data storytelling have shown effectiveness in enhancing students’ comprehension of VLA, these approaches remain difficult to scale and adapt to individual learning needs. Generative AI (GenAI) technologies, especially conversational agents, offer potential solutions by providing personalised and dynamic support to enhance students’ comprehension of VLA. This study investigates the effectiveness of GenAI agents, particularly when integrated with scaffolding techniques, in improving students’ comprehension of VLA. A randomised controlled trial was conducted with 117 higher education students to compare the effects of two types of GenAI agents: passive agents, which respond to student queries, and proactive agents, which utilise scaffolding questions, against standalone scaffolding in a VLA comprehension task. The results show that passive agents yield comparable improvements to standalone scaffolding both during and after the intervention. Notably, proactive GenAI agents significantly enhance students’ VLA comprehension compared to both passive agents and standalone scaffolding, with these benefits persisting beyond the intervention. These findings suggest that integrating GenAI agents with scaffolding can have lasting positive effects on students’ comprehension skills and support genuine learning.<br/></div> © 2024, CC BY.},
key = {Visual analytics},
keywords = {Adversarial machine learning;Chatbots;Contrastive Learning;Federated learning;Students;},
note = {Generative AI;Individual learning;Language model;Large language model;Learning analytic dashboard;Limited data;Scaffolding;Visual learning;Visual learning analytic;Visualization literacy;},
URL = {http://dx.doi.org/10.48550/arXiv.2409.11645},
} 


@inproceedings{20204509452609 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboard for Problem-based Learning},
journal = {L@S 2020 - Proceedings of the 7th ACM Conference on Learning @ Scale},
author = {Pan, Zilong and Li, Chenglu and Liu, Min},
year = {2020},
pages = {393 - 396},
address = {Virtual, Online, United states},
abstract = {This study examined two machine learning models for de-signing a learning analytics dashboard to assist teachers in facilitating problem-based learning. Specifically, we used BERT to automatically process a large amount of textual data to understand students' scientific argumentation. We then used Hidden Markov Model (HMM) to find students' cognitive state transition with time-series data. Preliminary results showed the models achieved high accuracy and were coherent with related theories, indicating the models can provide teachers with interpretable information to identify in-need students.<br/> © 2020 ACM.},
key = {Students},
keywords = {Machine learning;Hidden Markov models;Learning systems;},
note = {Cognitive state;High-accuracy;Large amounts;Problem based learning;Textual data;Time-series data;Two machines;},
URL = {http://dx.doi.org/10.1145/3386527.3406751},
} 


@inproceedings{20244017138409 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Beyond Traditional Classrooms: Addressing the Tensions of Cognitive and Meta-Cognitive Goals in Exercise Sessions},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Cai, Zhenyu and Davis, Richard and Tormey, Roland and Dillenbourg, Pierre},
volume = {15160 LNCS},
year = {2024},
pages = {81 - 86},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">A range of learning analytics (LA) tools have been designed and integrated into university classes to facilitate teaching and learning. However, exercise sessions, the educational setting that complements lectures with practical activities, are commonly overlooked by LA researchers and designers. Little work has focused on involving the key stakeholders, teaching assistants (TAs), and incorporating human-centered design approaches in this context. To address this gap, we conducted a qualitative study to understand TAs’ common approaches and challenges of teaching in exercise sessions, and to explore their visions for LA dashboards that could be adapted into their current practices. Our results indicated that TAs in exercise sessions held two sets of goals in supporting students’ cognitive and meta-cognitive activities, and while LA tools were seen as offering numerous potential benefits, they were also seen as introducing tensions threatened to disrupt the delicate balance of both goals.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Contrastive Learning},
keywords = {Active learning;Adversarial machine learning;Federated learning;},
note = {Analytic tools;Educational settings;Exercise session;High educations;Learning analytic;Metacognitives;Teacher dashboard;Teachers';Teaching and learning;Teaching assistants;},
URL = {http://dx.doi.org/10.1007/978-3-031-72312-4_9},
} 


@inproceedings{20250817920744 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Effective Feedback Systems in Learning Analytics: Didactic and Psychological Foundations, Implementations, and Perspectives},
journal = {2024 21st International Conference on Information Technology Based Higher Education and Training, ITHET 2024},
author = {Hirsch, Sunita and Uckelmann, Dieter},
year = {2024},
address = {Paris, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics (LA) and LA-based feedback systems have made substantial advancements, providing tools and frameworks designed to improve educational outcomes. However, their long-term effectiveness is often constrained by a predominant focus on technical elements, which can overshadow crucial didactic, psychological, and design-related considerations. This paper introduces an integrative framework for designing LA-based feedback systems that mitigates these limitations by incorporating insights from cognitive and motivational theories. The framework aims to support the development of learner-centered environments that address various learning needs. Based on this framework, practical considerations and recommendations are provided to guide the implementation of feedback systems that move beyond technical constraints. An implemen-tation example illustrates how the framework can be applied using real-time data analysis and learner assessments aiming to improve the usability, effectiveness, and acceptance of feedback systems. This approach highlights the importance of integrating multidisciplinary perspectives in LA to achieve meaningful and impactful educational practices across diverse contexts.<br/></div> © 2024 IEEE.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;},
note = {Dashboard;Feedback systems;Integrative framework;Learner-centred;Learner-centred design;Learning analytic;Multidisciplinary perspectives;Real time data analysis;Technical constraints;},
URL = {http://dx.doi.org/10.1109/ITHET61869.2024.10837632},
} 


@inproceedings{20210409814493 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Factors of the use of learning analytics dashboard that affect metacognition},
journal = {17th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2020},
author = {Chen, Li and Lu, Min and Goda, Yoshiko and Shimada, Atsushi and Yamada, Masanori},
year = {2020},
pages = {295 - 302},
address = {Lisbon, Virtual, Portugal},
abstract = {In this study, we used a learning analytics dashboard (LAD) in a higher education course to support students' metacognition and evaluated the effects of its use. The LAD displays students' reading path and specific behaviors when viewing digital learning materials. The study was conducted on 53 university students to identify the factors that affected metacognition changes in terms of their awareness and behavior dimensions when using the LAD. In terms of results, first, the students' perception of visual attraction for the LAD, and behaviors related to reflection such as deleting annotations they had previously added, positively affected the changes in the knowledge of cognition dimension of metacognition. Second, students' perception of behavioral changes by using the LAD had positive effects on the regulation of cognition dimension of metacognition. However, the behaviors of using some cognitive tools, negatively affected knowledge of cognition, which indicated the necessity to provide more guidance or feedback to students.<br/> © 2020 17th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2020. All rights reserved.},
key = {Students},
keywords = {Cognitive systems;E-learning;},
} 


@inproceedings{20212510534351 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics dashboard for teaching with twitter},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
author = {Gruzd, Anatoliy and Conroy, Nadia},
volume = {2020-January},
year = {2020},
pages = {2708 - 2717},
issn = {15301605},
address = {Maui, HI, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">As social media takes root in our society, more University instructors are incorporating platforms like Twitter into their classroom. However, few of the current Learning Analytics (LA) systems process social media data for instructional interventions and evaluation. As a result, instructors who are using social media cannot easily assess their students' learning progress or use the data to adjust their lessons in real time. We surveyed 54 university instructors to better understand how they use social media in the classroom; we then used these results to design and evaluate our own Twitter-centric LA dashboard. The overarching goals for this project were to 1) assist instructors in determining whether their particular use of Twitter met their teaching objectives, and 2) help system designers navigate the nuance of designing LA dashboards for social media platforms.<br/></div> © 2020 IEEE Computer Society. All rights reserved.},
note = {'current;Analytics systems;Instructional interventions;Learning progress;Real- time;Social media;Social media datum;Student learning;System process;Teaching objectives;},
URL = {http://dx.doi.org/10.24251/hicss.2020.330},
} 


@inproceedings{20243817059009 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using learning analytics dashboards to monitor student progress: the case of a blended computer science university course},
journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
author = {Balaban, Igor and Zlatovic, Miran and Matus, Marko},
year = {2024},
pages = {72 - 74},
address = {Hybrid, Nicosia, Cyprus},
abstract = {<div data-language="eng" data-ev-field="abstract">The research presented here focuses on students' perceptions of using learning analytics dashboards, specifically for tracking progress indicators within the Moodle Learning Management System. The study aims to uncover the connections between progress tracking, motivation, satisfaction, andfinalgrades. The research involved 126 students in a blended course covering economics and informatics. Progress through course materials was tracked using conditional activities, and students' progress was measured using self-assessment quizzes and badges. Results indicated a positive correlation between progress indicators and motivation, as well as a strong correlation between progress indicators and satisfaction. However, no significant correlation was found between progress indicators and final course scores. In conclusion, the study confirms that tracking progress indicators positively impacts student motivation and satisfaction but does not directly affect final grades. Future research should explore the mediating role of motivation and satisfaction in the relationship betweenprogress tracking andfinal course grades.<br/></div> © 2024 IEEE.},
key = {Federated learning},
keywords = {Students;},
note = {Course material;Education 4.0;High educations;Informatics;Learning analytic dashboard;Learning management system;Self-assessment;Student perceptions;Student progress;University course;},
URL = {http://dx.doi.org/10.1109/ICALT61570.2024.00027},
} 


@inproceedings{20242216154255 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Empowering Students: A Reflective Learning Analytics Approach to Enhance Academic Performance},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Duch, Dynil and May, Madeth and George, Sebastien},
volume = {2},
year = {2024},
pages = {385 - 396},
issn = {21845026},
address = {Angers, France},
abstract = {<div data-language="eng" data-ev-field="abstract">The surge in online education has accentuated the importance of practical Learning Analytics (LA) tools, traditionally designed to support educators. In the meantime, a notable gap exists in empowering students directly through user progress insights and reflective components. This paper presents our research effort in designing a novel approach: a Self-reflective Tool (SRT) with data indicators on student performance designed to actively engage students in their learning journey. Our research explores the landscape of existing LA tools, pinpointing the lack of technological supports for students, and the limitations in empowering students. The methodology involves data extraction, and a comparative analysis of classifiers to predict student performance (SP). Our reflective tool is therefore built, not only to support students in their learning activities, but also to provide them with a more relevant assistance according to their SP. Surveys are made to assess our proposal of SRT. The findings illustrate how students perceive it and how SRT oriented data indicators increase awareness, regulation, and motivation of individual learning patterns. Our qualitative analysis also demonstrates a positive correlation between student engagement with the reflective tool and improvements in academic outcomes. This research contributes to the discourse on LA by emphasizing the importance of reflective tools for students in Metacognition Online Learning Environments (MOLE), providing valuable insights for future developments in student-centric approaches to education.<br/></div> Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
key = {Students},
keywords = {Computer aided instruction;Data visualization;E-learning;Predictive analytics;},
note = {Analytic tools;Data indicator;Educational dashboard;Empowering student;Learning analytic;Learning behavior;Learning patterns;Predictive learning;Reflective tool;Student performance;},
URL = {http://dx.doi.org/10.5220/0012634600003693},
} 


@article{20241816025357 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The impact of an academic counselling learning analytics tool: Evidence from 3 years of use},
journal = {British Journal of Educational Technology},
author = {Henriquez, Valeria and Guerra, Julio and Scheihing, Eliana},
volume = {55},
number = {5},
year = {2024},
pages = {1884 - 1899},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">Despite the importance of academic counselling for student success, providing timely and personalized guidance can be challenging for higher education institutions. In this study, we investigate the impact of counselling instances supported by a learning analytics (LA) tool, called TrAC, which provides specific data about the curriculum and grades of each student. To evaluate the tool, we measured changes in students' performance ranking position over 3 years and compared the performance of students who received counselling with and without the tool. Our results show that using the tool is related to an improvement in cohort ranking. We further investigated the characteristics of counselled students using cluster analyses. The findings highlight the potential beneficial influence on academic outcomes arising from the provision of guidance to students regarding their course load decisions via TrAC-mediated counselling. This study contributes to the field of LA by providing evidence of the impact of counselling supported by an LA tool in a real-world setting over a long period of time. Our results suggest that incorporating LA into academic counselling practices can improve student success. Practitioner notes What is already known about this topic By analysing student performance, teaching strategies and resource impact, learning analytics (LA) empowers institutions to make informed changes in curriculum design, resource allocation and educational policies. Through insights into academic progress, engagement and behaviour, LA counselling tools enable the identification of at-risk students and those needing additional support. In the related literature, there are areas for further exploration such as understanding the scalability and long-term effects of interventions on student success and retention. What this paper adds Through rigorous data analysis, the paper establishes a connection between LA utilization and enhanced student performance, offering concrete evidence of the effectiveness of LA interventions. By examining various factors such as academic stage and course load, the research offers valuable insights into the contextual nuances that optimize the outcomes of LA tool-based support. It adds to the growing body of evidence that supports the efficacy of data-driven interventions in education, fostering a more informed and evidence-based approach to student support and success. Implications for practice and policy Enhanced student support strategies: By tailoring counselling interventions to align with the identified effective conditions, educators can proactively address individual student needs, improving academic outcomes and retention rates. Informed decision making: The demonstrated positive impact highlights the potential of similar data-driven initiatives to foster student success. Policymakers can consider incentivizing the adoption of such interventions at institutional levels. Future directions for research: By identifying contextual factors that influence the efficacy of LA interventions, it encourages further exploration into how other LA interventions can be optimized for specific conditions. This can guide the development of more precise and effective student support strategies in the future.<br/></div> © 2024 British Educational Research Association.},
key = {Students},
keywords = {Cluster analysis;Curricula;Decision making;},
note = {Academic counseling;Analytic tools;Clustering analysis;Condition;Data driven;Learning analytic dashboard;Learning analytic impact;Student performance;Student success;Student supports;},
URL = {http://dx.doi.org/10.1111/bjet.13474},
} 


@inproceedings{20243116794928 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Systematic Review on Student-Facing Learning Analytics Dashboards: Reference Frames and Indicators},
journal = {Proceedings - 2024 6th International Conference on Computer Science and Technologies in Education, CSTE 2024},
author = {Kew, Si Na and Koh, Elizabeth and Choo, Zi Luan and Jonathan, Christin Rekha},
year = {2024},
pages = {45 - 50},
address = {Hybrid, Xi'an, China},
abstract = {<div data-language="eng" data-ev-field="abstract">As the integration of technology in education undergoes continuous development, Learning Analytics Dashboards (LADs) have become vital tools for both instructors and learners, facilitating the monitoring and optimization of the learning experience. Student-facing LADs have been designed with various reference frames which enable various feedback, comparisons and reflection. However, there has been limited examination of the reference frames and their indicators employed in student-facing LADs as well as its evaluation. This research aims to address this gap by conducting a systematic literature review using PRISMA to synthesize existing literature to identify and offer insights on reference frames and key indicators used in student-facing LADs. We identified 42 articles and analyzed that social reference frames as compared to progress reference frames are commonly employed in LADs. Key indicators include class performance average, class performance mean, average performance of the class, etc. These insights contribute to the ongoing development and best practices of LAD design. The knowledge and findings can help educators, researchers, system designers and policymakers decide how best to incorporate these tools into educational settings.<br/></div> © 2024 IEEE.},
key = {Facings},
keywords = {Petroleum reservoir evaluation;Students;},
note = {Continuous development;Development Learning;Key indicator;Learning analytic dashboard;Performance;PRISMA;Reference frame;Systematic literature review;Systematic Review;Technology in educations;},
URL = {http://dx.doi.org/10.1109/CSTE62025.2024.00015},
} 


@inproceedings{20203909216545 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Openlair an open learning analytics indicator repository dashboard},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ahmad, Atezaz and Schneider, Jan and Drachsler, Hendrik},
volume = {12315 LNCS},
year = {2020},
pages = {467 - 471},
issn = {03029743},
address = {Heidelberg, Germany},
abstract = {In this demo paper we present a tool that provides an overview of learning analytics indicators, metrics, and learning design activities in the field of learning analytics over the past decade. The system is based on our literature review from a total of 123 scientific publications, where we fetched 132 indicators and their metrics, 40 learning activities, and eight learning events (i.e., create, explore, practice, imitate, receive, debate, meta-learn, and experiment). Therefore, we proposed a system that will provide indicators and metrics based on learning activities and learning events selected by the stakeholders. The aim is to help the stakeholders in the application of learning analytics.<br/> © Springer Nature Switzerland AG 2020.},
key = {E-learning},
note = {Indicators and metrics;Learning Activity;Learning designs;Literature reviews;Open learning;Scientific publications;},
URL = {http://dx.doi.org/10.1007/978-3-030-57717-9_46},
} 


@inproceedings{20245217574108 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancing Collaboration and Performance Among EMS Students Through Multimodal Learning Analytics},
journal = {ACM International Conference Proceeding Series},
author = {Joshi, Vasundhara},
year = {2024},
pages = {607 - 611},
address = {San Jose, Costa rica},
abstract = {<div data-language="eng" data-ev-field="abstract">Physiological synchrony plays an important role in measuring collaboration and performance within teams. However, there has been little investigation into awareness of physiological synchrony and its impact on the collaboration and performance. In my dissertation, I am proposing a study to investigate the impact of awareness of near real-time physiological synchrony, through multimodal learning analytic dashboard, on Emergency Medical Services (EMS) students’ perceived collaboration and performance. Also, I plan to investigate the best practices for presenting multimodal data to EMS trainees in collaborative learning environment. The research aims to enhance students’ engagement and reflection on their collaborative interactions and performance.<br/></div> © 2024 Copyright held by the owner/author(s).},
key = {Students},
keywords = {Adversarial machine learning;Electrotherapeutics;Physiological models;},
note = {Collaboration;Electrodermal activity;Emergency medical services;Learning analytic dashboard;Multi-modal;Multi-modal learning;Multimodal data visualization;Near-real time;Performance;Physiological synchrony;},
URL = {http://dx.doi.org/10.1145/3678957.3688613},
} 


@inproceedings{20243316873859 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Review of Learning Analytics Dashboards for Students},
journal = {Lecture Notes in Networks and Systems},
author = {Gujju, Krishnavamsi and Bandi, Sahithi and Moraes, Marcia},
volume = {1058 LNNS},
year = {2024},
pages = {300 - 312},
issn = {23673370},
address = {Athens, Greece},
abstract = {<div data-language="eng" data-ev-field="abstract">In our comprehensive literature review, we systematically explored the impact of Learning Analytics Dashboards (LADs) on student engagement, motivation, and academic performance within higher education settings. Utilizing a methodical approach, we selected and analyzed 21 studies that met our inclusion criteria focusing on diverse research designs, sample sizes, and outcome measures. Our methodology involved a rigorous evaluation of studies to understand the depth of LAD’s effects on various student populations and learning environments. The results revealed that LADs could significantly enhance student engagement and motivation, leading to improved academic performance. However, the findings also underscored a pressing need for further research into the design and implementation of these dashboards, highlighting the importance of addressing challenges like information overload and the necessity for dashboards to cater to different student demographics. This literature review offers valuable insights into the effective design and implementation of learning dashboards, proposing that future LAD developments should prioritize user-centric designs to maximize learning outcomes and enrich the educational experience in higher education.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Students},
keywords = {Computer aided instruction;Learning systems;Motivation;},
note = {Academic performance;Design and implementations;High educations;Learning analytic;Learning analytic dashboard for student;Learning management system;Learning management system and development;Literature reviews;Management development;Student engagement;},
URL = {http://dx.doi.org/10.1007/978-3-031-65522-7_27},
} 


@inproceedings{20182405310428 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The design of a learning analytics pedagogical dashboard to enhance instructors’ facilitation in an online asynchronous problem-based learning environment},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Huang, Lingyun and Bodnar, Stephen and Zheng, Juan and Kazemitabar, Maedeh Assadat and Chen, Yuxin and Birk, Gurpreet and Hmelo-Silver, Cindy E. and Lajoie, Susanne P.},
volume = {10858 LNCS},
year = {2018},
pages = {442 - 445},
issn = {03029743},
address = {Montreal, QC, Canada},
abstract = {Problem-based learning (PBL) refers to small group collaborative learning situations where students solve complex problems with the assistance of teachers who serve as facilitators. Scaling PBL using technology requires specific tools since online asynchronous PBL can increase the number of small groups that engage in the curriculum but poses challenges to PBL teachers who must attend to multiple groups. To address the problem, we have been researching how technology can be used to develop specific tools to extend expert teachers’ instructional capacities. Building on previous work, we present the most recent design of a pedagogical dashboard used in an online asynchronous PBL environment. We illustrate how the new pedagogical dashboard visualizations can support PBL instructors observing individual student learning activities, diagnosing group dynamics and intervening when necessary.<br/> © Springer International Publishing AG, part of Springer Nature 2018.},
key = {Visualization},
keywords = {Computer aided instruction;E-learning;Curricula;},
note = {Collaborative learning;Complex problems;Group dynamics;Learning analytics;Multiple-group;Pedagogical dashboard;Problem based learning;Student learning;},
} 


@inproceedings{20251218095255 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Prescriptive analytics motivating distance learning students to take remedial action: A case study of a student-facing dashboard},
journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
author = {Herodotou, Christothea and Carr, Jessica and Shrestha, Sagun and Comfort, Catherine and Bayer, Vaclav and Maguire, Claire and Lee, John and Mulholland, Paul and Fernandez, Miriam},
year = {2025},
pages = {306 - 316},
address = {Dublin, Ireland},
abstract = {<div data-language="eng" data-ev-field="abstract">Student-facing learning analytics dashboards aim to help students to monitor their study progress, achieve learning goals and develop self-regulation skills. Only few of them present personalised data visualisations and aim to develop agentic students who take remedial action to improve their study habits, learning and performance. In this paper, a student-facing dashboard, designed following principles of participatory research, was tested with 30 undergraduate students, who engaged with it over a period of 4 to 15 weeks and while studying an online course. This is one of the few dashboards available that presents all different types of analytics to students: descriptive, predictive and prescriptive. A mixed methods approach was used to assess its usefulness and impact on motivation to study and take remedial action to support learning. Data analysis showcased that such a dashboard can be "a roadmap to success"by motivating students to study more and improve their performance, in addition to helping with monitoring, planning and reflection. While all dashboard features were perceived as being useful, special value was placed on prescriptive elements, in particular material recommendations and contacting tutors and university support teams, emphasizing the significance of making explicit on a dashboard the actions students should take to improve their performance. Implications for future studies are discussed.<br/></div> © 2025 Copyright held by the owner/author(s).},
key = {Students},
keywords = {Adversarial machine learning;Contrastive Learning;},
note = {Case-studies;Distance-learning;Learning analytic dashboard;Learning goals;Performance;Prescriptive analytic;Remedial actions;Self regulation;Student-facing dashboard;Study habits;},
URL = {http://dx.doi.org/10.1145/3706468.3706508},
} 


@article{20202308789109 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Adaptation and evaluation of a learning analytics dashboard to improve academic support at three Latin American universities},
journal = {British Journal of Educational Technology},
author = {Guerra, Julio and Ortiz-Rojas, Margarita and Zuniga-Prieto, Miguel Angel and Scheihing, Eliana and Jimenez, Alberto and Broos, Tom and De Laet, Tinne and Verbert, Katrien},
volume = {51},
number = {4},
year = {2020},
pages = {973 - 1001},
issn = {00071013},
abstract = {Despite the success of academic advising dashboards in several higher educational institutions (HEI), these dashboards are still under-explored in Latin American HEI's. To close this gap, three different Latin American universities adapted an existing advising dashboard, originally deployed at the KU Leuven to their own context. In all three cases, the context was the main ruling factor to these adaptations. In this paper, we describe these adaptions using a framework that focuses on four different elements of the context: Objectives, Stakeholders, Key moment and Interactions. Evaluation of the adapted dashboards in the three different Latin American universities is conducted through pilots. This evaluation shows the value of the dashboard approach in different contexts in terms of satisfaction, usefulness and impact in academic decision-making and advising tasks. The main contribution of this paper is the systematic reporting of the adaptations to an academic advising dashboard and showing the value of an academic advising dashboard on academic decision-making and advising tasks.<br/> © 2020 British Educational Research Association},
key = {Decision making},
keywords = {Educational technology;},
note = {Academic advising;Academic supports;Educational institutions;Latin americans;},
URL = {http://dx.doi.org/10.1111/bjet.12950},
} 


@inproceedings{20232314190332 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Solution for Monitoring and Analyzing the Students’ Behavior in SQL Lab Work},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Ouared, Abdelkader and Amrani, Moussa and Schobbens, Pierre-Yves},
volume = {2},
year = {2023},
pages = {184 - 195},
issn = {21845026},
address = {Prague, Czech republic},
abstract = {<div data-language="eng" data-ev-field="abstract">Computer-assisted learning is widely discussed in the literature to aid the comprehension of SQL queries (Structured Query Language) in higher education. However, it is difficult for educators/instructors to track, monitor and analyze students’ learning situation due to the higher education massification, and institutions with large classes. Consequently, we need to provide for educators a learning dashboard to monitor and analyze the digital traces issued from students during the practice learning in SQL course. We propose a system called LSQL (Learning Analytics for SQL) that is a solution based on the learning analytics’ methodology. To this end, we propose (i) learning environment dedicated to help students understand the syntax and logic of SQL and getting data issued from these students during online SQL lab work, (ii) trace model which is designed to more effectively represent and capture the complex interactions/actions carried by a student during practice learning activities in virtual/remote laboratories, and (iii) learning analytics dashboard for educators to visualize the statistics and metrics that represent the students’ behavior, and control the students progress in SQL skills to enhance the teaching activities. Tool support is fully available.<br/></div> Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)},
key = {Students},
keywords = {Computer aided instruction;E-learning;Education computing;Learning systems;Query languages;Query processing;},
note = {Analytic solution;Computer assisted learning;High educations;Language learning;Learning analytic;Learning analytic dashboard;SQL language learning;SQL languages;SQL query;Students' behaviors;},
URL = {http://dx.doi.org/10.5220/0011848200003470},
} 


@inproceedings{20233914788407 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Single or Multi-page Learning Analytics Dashboards? Relationships Between Teachers’ Cognitive Load and Visualisation Literacy},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Srivastava, Namrata and Liu, Yuchen and Gasevic, Dragan},
volume = {14200 LNCS},
year = {2023},
pages = {339 - 355},
issn = {03029743},
address = {Aveiro, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">There has been a proliferation of learning analytics (LA) interfaces designed to support teachers, such as LA dashboards. However, although teacher dashboards have been extensively studied, there is limited understanding of the relationship between single-page or multi-page dashboard designs and the cognitive demands placed on teachers to use them. Additionally, teachers typically have varying levels of visualisation literacy (VL), which may make it easier or more difficult for them to engage with single-page versus multi-page dashboard designs. In this paper, we explore how teachers, with varying VL, use single-page and multi-page LA dashboards. We conducted a quasi-experimental study with 23 higher education teachers of varied VL inspecting single and multi-page LA dashboards. We used an eye-tracking device to measure cognitive load while teachers inspected the LA dashboards in online group work. We investigated how proxy metrics derived from eye-tracking data related to teachers’ cognitive load varied depending on the type of the dashboard teacher used and the level of VL teachers have. Our findings suggest that the design of the LA dashboard had an impact on the cognitive load experienced by the teachers. Post-hoc analysis revealed that teachers with low VL had a marginally lower cognitive load when using single-page dashboards. We argue that the LA dashboard design for teachers should account for teachers’ levels of VL and provide design recommendations.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Visualization},
keywords = {Eye tracking;},
note = {Cognitive demands;Cognitive loads;Dashboard;Data literacy;Education teachers;Eye tracking devices;Eye-tracking;High educations;Learning analytic;Teachers';},
URL = {http://dx.doi.org/10.1007/978-3-031-42682-7_23},
} 


@inproceedings{20234314941219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Enhanced Online Academic Success and Self-Regulation Through Learning Analytics Dashboards},
journal = {IFIP Advances in Information and Communication Technology},
author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
volume = {685 AICT},
year = {2023},
pages = {332 - 342},
issn = {18684238},
address = {Hiroshima, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">In the wake of the COVID-19 health crisis, governments around the world made educational continuity during school and university closure a priority. Many countries adopted online education as an alternative to face-to-face courses. This situation has led to an awareness of the importance of analyzing learning traces and data left by students to measure, evaluate and improve the learning process. This paper presents an interoperable online learning analytics dashboard that allows teachers to easily track the progress of their learners as well as to predict and remedy dropouts. For learners, the dashboard offers the possibility to visualize their learning process, analyze it and develop better self-regulation skills. The results of the study conducted on a blended learning course, showed that the dashboard led learners to spend more time on their online training, to perform the proposed activities much better and to respect the deadlines better, and finally to improve their academic success.<br/></div> © 2023, IFIP International Federation for Information Processing.},
key = {COVID-19},
keywords = {Deregulation;E-learning;Learning systems;},
note = {Face to face;Health crisis;Learner success;Learning analytic;Learning analytic dashboard;Learning experiences;Learning process;On-line education;Self regulation;Self-regulated learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-43393-1_30},
} 


@inproceedings{20231013675583 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics dashboards: What do students actually ask for?},
journal = {ACM International Conference Proceeding Series},
author = {Divjak, Blazenka and Svetec, Barbi and Horvat, Damir},
year = {2023},
pages = {44 - 56},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics (LA) has been opening new opportunities to support learning in higher education (HE). LA dashboards are an important tool in providing students with insights into their learning progress, and predictions, leading to reflection and adaptation of learning plans and habits. Based on a human-centered approach, we present a perspective of students, as essential stakeholders, on LA dashboards. We describe a longitudinal study, based on survey methodology. The study included two iterations of a survey, conducted with second-year ICT students in 2017 (N = 222) and 2022 (N = 196). The study provided insights into the LA dashboard features the students find the most useful to support their learning. The students highly appreciated features related to short-term planning and organization of learning, while they were cautious about comparison and competition with other students, finding such features possibly demotivating. We compared the 2017 and 2022 results to establish possible changes in the students' perspectives with the COVID-19 pandemic. The students' awareness of the benefits of LA has increased, which may be related to the strong focus on online learning during the pandemic. Finally, a factor analysis yielded a dashboard model with five underlying factors: comparison, planning, predictions, extracurricular, and teachers.<br/></div> © 2023 ACM.},
key = {Students},
keywords = {Education computing;},
note = {Dashboard;High educations;Human-centered;Learning analytic;Learning progress;Longitudinal study;Short term planning;Student perspectives;Support learning;Survey methodology;},
URL = {http://dx.doi.org/10.1145/3576050.3576141},
} 


@article{20182205258372 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The student’s progress snapshot a hybrid text and visual learning analytics dashboard},
journal = {International Journal of Engineering Education},
author = {Amo, Daniel and Alier, Marc and Casan, Maria Jose},
volume = {34},
number = {3},
year = {2018},
pages = {990 - 1000},
issn = {0949149X},
abstract = {In recent years, virtual learning environments, laptops, tablets and mobile devices have been introduced in the classroom. These technologies start a snowball effect: the old tools teachers used to fathom the students’ learning progress, since so much happens online, are not enough. Thus, the need for new tools to analyse the students’ activity on the online learning environments arises. The field of learning analytics can provide some of these tools. In this paper, we introduce the Student’s Progress Snapshot (SPS), a Learning Analytics Dashboard that allows teachers to analyse the activity of their students on Moodle courses. The SPS running as software as a service, includes both charts and automatically generated explanatory texts of these charts. During the academic course 2015–2016 a pilot was conducted to validate the SPS.<br/> © 2018 TEMPUS Publications.},
key = {Students},
keywords = {E-learning;Software as a service (SaaS);Computer aided instruction;},
note = {Learning analytics;Learning management system;Moodle;Student interactions;Virtual learning environments;},
} 


@article{20240415442999 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A shared lens around sensemaking in learning analytics: What activity theory, definition of a situation and affordances can offer},
journal = {British Journal of Educational Technology},
author = {Poquet, Oleksandra},
volume = {55},
number = {4},
year = {2024},
pages = {1811 - 1831},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">The paper argues that learning analytics as a research field can benefit from a theory-informed shared language to describe sensemaking of learning and teaching data. To make the case for such shared language, first, I critically review prominent sensemaking theories to then demonstrate how studies in learning analytics do not use coherent descriptions of sensemaking, eclectically combining the paradigms that have underlying differences. I then propose a conceptualization of sensemaking that overcomes the differences between these theories and explains how the concepts of activity system, the definition of the situation and affordances can be used to capture individual differences in sensemaking. The paper concludes with a preliminary framework and examples demonstrating its utility in raising new theoretical questions, informing design principles and providing shared language for researchers in learning analytics.Practitioner notesWhat is already known about this topic Sensemaking happens when individuals try to explain unknown situations. Learning analytics uses sensemaking as a lens to understand dashboard use. Systematic analysis of sensemaking is essential for learning analytics. What this paper adds The paper notes that noticing and perceiving are commonly examined in learning analytics on dashboard use. The paper suggests a revision of fundamental assumptions in sensemaking. A paper proposes a toy model of sensemaking that includes operationalization of the definition of the situation, activity where sensemaking happens and processes of noticing and perceiving affordances. Implications for practice and/or policy Learning analytics must examine sensemaking of data about teaching and learning in a systematic manner. Internal perceptions of the social environment and activity that are informed by the data need to be considered in evaluating dashboard use.<br/></div> © 2024 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
key = {Activity coefficients},
keywords = {Educational technology;},
note = {Activity Theory;Affordances;Definition of a situation;Ecological perception theory;Information elaboration;Learning analytic;Learning and teachings;Research fields;Sense making;Shared language;},
URL = {http://dx.doi.org/10.1111/bjet.13435},
} 


@inproceedings{20240315376222 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating Data Warehouses into Data Pipelines for Deploying Learning Analytics Dashboards},
journal = {14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023},
author = {Tsoni, Rozita and Garani, Georgia and Verykios, Vassilios S.},
year = {2023},
address = {Volos, Greece},
abstract = {<div data-language="eng" data-ev-field="abstract">From the data loading to the final reporting, a Learning Analytics (LA) cycle should be an articulated yet structured and repeatable process. Data from the online students' activity can be arranged and organized in Data Warehouses (DWs) to facilitate pre-processing tasks. These data can feed an LA cycle for producing the final reporting. In this work, we propose an integrated process of educational data management for creating insightful knowledge. Firstly, an education-oriented DW schema is presented. Additionally, a data pipeline that loads data from the DW and supports all the LA processes is described. The results are presented to the front-end user through an LA dashboard that focuses on students' social interaction in their learning community. The process is tested in educational data from a Distance Learning postgraduate program.<br/></div> © 2023 IEEE.},
key = {Data warehouses},
keywords = {Data handling;Distance education;Information management;Pipelines;Social networking (online);Software testing;Students;},
note = {Dashboard;Data pipelines;End-users;Front end;Learning analytic;Learning community;Load data;Pre-processing;Social interactions;Social Network Analysis;},
URL = {http://dx.doi.org/10.1109/IISA59645.2023.10345957},
} 


@inproceedings{20241115753412 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LAK 2024 Conference Proceedings - 14th International Conference on Learning Analytics and Knowledge},
journal = {ACM International Conference Proceeding Series},
year = {2024},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 95 papers. The topics discussed include: equity-forward learning analytics: designing a dashboard to support marginalized student success; automating human tutor-style programming feedback: leveraging GPT-4 tutor model for hint generation and GPT-3.5 student model for hint validation; novice programmers inaccurately monitor the quality of their work and their peers’ work in an introductory computer science course; improving model fairness with time-augmented Bayesian knowledge tracing; long-term prediction from topic-level knowledge and engagement in mathematics learning; epistemic network analysis for end-users: closing the loop in the context of multimodal analytics for collaborative team learning; and generative artificial intelligence in learning analytics: contextualizing opportunities and challenges through the learning analytics cycle.<br/></div>},
} 


@unpublished{20250047631 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {TeamVision: An AI-powered Learning Analytics System for Supporting Reflection in Team-based Healthcare Simulation},
journal = {arXiv},
author = {Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Jin, Yueqiao and Abel, Sophie and Fan, Jie and Yan, Lixiang and Li, Xinyu and Dix, Samantha and Wotherspoon, Rosie and Jaggard, Hollie and Osborne, Abra and Shum, Simon Buckingham and Gaevi, Dragan and Martinez-Maldonado, Roberto},
year = {2025},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Healthcare simulations help learners develop teamwork and clinical skills in a risk-free setting, promoting reflection on real-world practices through structured debriefs. However, despite video’s potential, it is hard to use, leaving a gap in providing concise, data-driven summaries for supporting effective debriefing. Addressing this, we present TeamVision, an AI-powered multimodal learning analytics (MMLA) system that captures voice presence, automated transcriptions, body rotation, and positioning data, offering educators a dashboard to guide debriefs immediately after simulations. We conducted an in-the-wild study with 56 teams (221 students) and recorded debriefs led by six teachers using TeamVision. Follow-up interviews with 15 students and five teachers explored perceptions of its usefulness, accuracy, and trustworthiness. This paper examines: i) how TeamVision was used in debriefing, ii) what educators found valuable/challenging, and iii) perceptions of its effectiveness. Results suggest TeamVision enables flexible debriefing and highlights the challenges and implications of using AI-powered systems in healthcare simulation.<br/></div> © 2025, CC BY-NC-ND.},
keywords = {Adversarial machine learning;Contrastive Learning;Digital elevation model;Students;Teaching;},
note = {Analytics systems;Clinical skills;Data driven;Follow up;Multi-modal learning;Positioning data;Real-world practice;Risk free;Teachers';Teamwork skills;},
URL = {http://dx.doi.org/10.48550/arXiv.2501.09930},
} 


@article{20183005610506 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Specification and evaluation of an assessment engine for educational games: Empowering educators with an assessment editor and a learning analytics dashboard},
journal = {Entertainment Computing},
author = {Chaudy, Yaelle and Connolly, Thomas},
volume = {27},
year = {2018},
pages = {209 - 224},
issn = {18759521},
abstract = {Assessment is a crucial aspect of any teaching and learning process. Educational games offer promising advantages for assessment; personalised feedback to students and automated assessment process. However, while many teachers agree that educational games increase motivation, learning and retention, few of them are ready to fully trust them as an assessment tool. We believe there are two main reasons for this lack of trust: educators are not given sufficient information about the gameplays, and many educational games are distributed as black-boxes, unmodifiable by teachers. This paper presents an assessment engine designed to separate a game and its assessment. It allows teachers to modify a game's assessment after distribution and visualise gameplay data via a learning analytics dashboard. The engine was evaluated quantitatively by 31 educators. Findings were overall very positive: both the assessment editor and the learning analytics dashboard were rated useful and easy to use. The evaluation also indicates that, having access to EngAGe, educators would be more likely to trust a game's assessment. This paper concludes that EngAGe can be used by educators effectively to modify educational games’ assessment and visualise gameplay data, and that it contributes to increasing their trust in educational games as an assessment tool.<br/> © 2018 Elsevier B.V.},
key = {Engines},
keywords = {Learning systems;},
note = {Assessment;Assessment editor;Assessment tool;Automated assessment;Educational game;Feedback to students;Learning analytics;Teaching and learning;},
URL = {http://dx.doi.org/10.1016/j.entcom.2018.07.003},
} 


@inproceedings{20232614316964 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Learning Analytics System that Improves the Teaching-Learning Experience of MOOC Instructors and Students},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Cobos, Ruth},
volume = {13869 LNCS},
year = {2023},
pages = {29 - 40},
issn = {03029743},
address = {San Cristobal de La Laguna, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">Great learning opportunities are provided through MOOCs. However, MOOCs provide a number of challenges for students. Many students find it difficult to successfully finish MOOCs due to a variety of factors, including feelings of loneliness, a lack of support, and a lack of feedback. Additionally, the instructors of these courses are highly concerned about this situation and want to reduce these difficulties for their students. Due to the large number of students registered in these courses, this is not a simple task. To help both instructors and students, we created edX-LIMS, a learning analytics (LA) system that allows MOOC instructors to monitor the progress of their students and carry out an intervention strategy in their students’ learning thanks to a Web-based Instructor Dashboard. Furthermore, this LA system provides MOOC students with detailed feedback on their course performance as well as advice on how to improve it thanks to Web-based Learner Dashboards. This LA system have been used for more than two year in a MOOC at edX. During this period the Dashboards supported by the system have been improved, and as a result, MOOC students now appreciate the fact that they feel guided, engagement and motivated to complete the course, among other feelings. MOOC instructor have improved their student monitoring tasks and are better able to identify students who need assistance. Moreover thanks to the services that the intervention strategy supported by the LA system offer to them, now students and instructors feel that are connected.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Students},
keywords = {E-learning;Learning systems;Websites;},
note = {Analytics systems;Dashboard;Engagement;Intervention;Intervention strategy;Learning analytic;Learning experiences;Massive open online course;Teaching-learning;Web based;},
URL = {http://dx.doi.org/10.1007/978-3-031-33023-0_3},
} 


@unpublished{20240011636 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
journal = {arXiv},
author = {Kaliisa, Rogers and Misiejuk, Kamila and Lopez-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
year = {2023},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students’ learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.<br/>MSC Codes 97U50, 97D60<br/></div> © 2023, CC BY.},
key = {Motivation},
keywords = {Computer aided instruction;Learning systems;Students;},
note = {Achievement motivations;Impact;Learning analytic dashboard;Learning outcome;Research studies;Student achievement;Student attitudes;Student learning outcomes;Student motivation;Systematic Review;},
URL = {http://dx.doi.org/10.48550/arXiv.2312.15042},
} 


@inproceedings{20184005900791 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Design of a learning analytics dashboard based on digital textbooks and online learning},
journal = {ICCE 2017 - 25th International Conference on Computers in Education: Technology and Innovation: Computer-Based Educational Systems for the 21st Century, Workshop Proceedings},
author = {Park, Yun-Gon and Cho, Yong-Sang and Son, Jeong-Eun},
year = {2017},
pages = {326 - 334},
address = {Christchurch, New zealand},
abstract = {In general, online learning provides functions such as access to video and learning materials, assessments what learners have learned, and participation in community activities. However, it is difficult to provide a learning environment that meets the achievement level or needs for each learner by providing such a function, and it is especially limited to prescribe in a proper situation. Learning analytics, which has received much attention in recent years, provides a tool to collect and analyze learning activity data. Since the process of collecting and analyzing data is generally performed in the system, the information presented by the analysis results is very important as an interface that users meet. Therefore, research on how teachers and students design intuitively to understand results and messages from data analysis bas a great implication on the place of learning analytics. This study introduces the process of designing a dashboard on users' requirements to intuitively express the collected data based on digital textbooks and online learning.<br/> © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.},
key = {Design},
keywords = {Textbooks;E-learning;Computer aided instruction;},
note = {Community activities;Dashboard;Digital textbooks;Learning Activity;Learning analytics;Learning environments;Learning materials;Online learning;},
} 


@inproceedings{20233514656930 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Definition of a Learning Analytics Ecosystem for the ILEDA Project Piloting},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Conde, Miguel a. and Georgiev, Atanas and Lopez-Pernas, Sonsoles and Jovic, Jovana and Crespo-Martinez, Ignacio and Raspopovic Milic, Miroslava and Saqr, Mohammed and Pancheva, Katina},
volume = {14040 LNCS},
year = {2023},
pages = {444 - 453},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {<div data-language="eng" data-ev-field="abstract">Understanding how students progress in their learning is an important step towards achieving the success of the educational process. One way of understanding student progress is by using learning analytics methods on different student data. The ILEDA project aims to improve online and blended learning by using educational data analytics. For this purpose, the project involves four universities from four different countries and develops several activities. One of these activities. That aims to facilitate the analysis of student progress, is the definition of a Learning Analytics Ecosystem. The aim of defining the ecosystem is to generate solutions that will benefit all institutions and that will allow to look for possible patterns and common issues needing addressing. This paper describes the development of such an ecosystem and its future implementations.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Ecosystems},
keywords = {Data Analytics;Students;},
note = {Analytic method;Blended learning;Dashboard;Data analytics;Educational process;Evidence;Learning analytic;Online learning;Student progress;},
URL = {http://dx.doi.org/10.1007/978-3-031-34411-4_30},
} 


@inproceedings{20173003976103 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a dashboard for learning analytics in higher education},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Leitner, Philipp and Ebner, Martin},
volume = {10296 LNCS},
year = {2017},
pages = {293 - 301},
issn = {03029743},
address = {Vancouver, BC, Canada},
abstract = {In this paper, we discuss the design, development, and implementation of a Learning Analytics (LA) dashboard in the area of Higher Education (HE). The dashboard meets the demands of the different stakeholders, maximizes the mainstreaming potential and transferability to other contexts, and is developed in the path of Open Source. The research concentrates on developing an appropriate concept to fulfil its objectives and finding a suitable technology stack. Therefore, we determine the capabilities and functionalities of the dashboard for the different stakeholders. This is of significant importance as it identifies which data can be collected, which feedback can be given, and which functionalities are provided. A key approach in the development of the dashboard is the modularity. This leads us to a design with three modules: the data collection, the search and information processing, and the data presentation. Based on these modules, we present the steps of finding a fitting Open Source technology stack for our concept and discuss pros and cons trough out the process.<br/> © Springer International Publishing AG 2017.},
key = {Computers},
keywords = {Artificial intelligence;},
note = {Data collection;Data presentation;Higher education;Learning analytics;Learning dashboard;Open sources;Open-source technology;Technology enhanced learning;},
URL = {http://dx.doi.org/10.1007/978-3-319-58515-4_23},
} 


@inproceedings{20233514656936 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Prototyping the Learning Analytics Dashboards of an Adaptive Learning Platform: Faculty Perceptions Versus Designers’ Intentions},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin and Leweke, Victor Anton Charles},
volume = {14040 LNCS},
year = {2023},
pages = {531 - 545},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {<div data-language="eng" data-ev-field="abstract">This study contributes with a case study on redesigning three Learning Analytics Dashboards (LADs) of the adaptive learning platform Rhapsode™ with instructions for pedagogical actions. Applying self determination theory’s elements of competence and relatedness and mental models in a design thinking process, the differences among the teachers perceptions and the designers intentions are highlighted through several methods to answer the questions of: How might we improve the learning analytics dashboards by prioritizing course instructors’ perceived competence and relatedness? and How might we redesign learning analytics dashboards by including course instructors’ purpose, insights, and recommending actions? These questions are answered first by developing three Role-based Personas of Alina Action, Niels Novice, and Paul Privacy along with scenarios and user stories. Second, prototypes of interfaces are designed and tested in three iterations showing insights, recommended actions, and explanation of mechanics. Feedback from the tests on the prototypes receives positive feedback from all teacher personas. The teacher persona of Niels Novice also supplies a criticism of the insights and recommended actions on the basis of creating undesired interpretation, potential bias, taking away freedom of interpretation, and authoritative system that "instructs/orders" action. Additionally, the scope of the study cannot meet the persona of Paul Privacy’s reservations on students’ possible experience of surveillance.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Learning systems},
keywords = {Cognitive systems;Curricula;Design;E-learning;Teaching;},
note = {Actionable learning analytic dashboard;Adaptive learning;Adaptive learning platform;Case-studies;Design thinking;Faculty perceptions;Learning platform;Mental model;Motivation theories;Teachers';},
URL = {http://dx.doi.org/10.1007/978-3-031-34411-4_36},
} 


@inproceedings{20204409441830 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Capitalizing on Learning Analytics Dashboard for Maximizing Student Outcomes},
journal = {2019 IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2019},
author = {Ramaswami, Gomathy Suganya and Susnjak, Teo and Mathrani, Anuradha},
year = {2019},
address = {Melbourne, VIC, Australia},
abstract = {With ongoing advancements in technology enabled learning, an opportunity has risen for educators to enhance student learning with use of Learning Analytics. Educational institutions are using Learning Analytics Dashboards (LAD) to provide students with timely and personalized feedback in visual format. LAD use advanced analytical capabilities that capitalize on online learner activities that are extracted from log files. They provide data-driven insights on current learning contexts and inform management on any learning intervention strategies that may be needed to support students in achieving their learning outcomes. Besides students, the perspective of instructors too is considered. Using easy-to-read graphical reporting formats (e.g., line graphs, scatter plot, bar charts, etc.), the LAD reveals a consolidated view of how online learning is taking place. In this manner, a snapshot depicting details of student learning patterns can enable instructors to monitor their students' learning strategies. At the same time, the LAD assists students too by providing them with a personalized environment to help them engage better with the learning outcomes. Therefore, LAD is increasingly used as a pedagogical approach to motivate students and help build their self-learning capacity. In this study, we propose to develop a real-time dashboard that pulls online student data from various sources including a learning management system (Moodle), University's library and from the student management system (SMS) that is used by the staff.<br/> © 2019 IEEE.},
key = {Students},
keywords = {Human resource management;Graph theory;E-learning;Information management;Learning systems;},
note = {Educational institutions;Intervention strategy;Learning management system;Pedagogical approach;Personalized feedback;Real-time dashboards;Student management;Technology-enabled learning;},
URL = {http://dx.doi.org/10.1109/CSDE48274.2019.9162357},
} 


@inproceedings{20241115753428 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {TeamSlides: a Multimodal Teamwork Analytics Dashboard for Teacher-guided Reflection in a Physical Learning Space},
journal = {ACM International Conference Proceeding Series},
author = {Echeverria, Vanessa and Yan, Lixiang and Zhao, Linxuan and Abel, Sophie and Alfredo, Riordan and Dix, Samantha and Jaggard, Hollie and Wotherspoon, Rosie and Osborne, Abra and Buckingham Shum, Simon and Gasevic, Dragan and Martinez-Maldonado, Roberto},
year = {2024},
pages = {112 - 122},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Advancements in Multimodal Learning Analytics (MMLA) have the potential to enhance the development of effective teamwork skills and foster reflection on collaboration dynamics in physical learning environments. Yet, only a few MMLA studies have closed the learning analytics loop by making MMLA solutions immediately accessible to educators to support reflective practices, especially in authentic settings. Moreover, deploying MMLA solutions in authentic settings can bring new challenges beyond logistic and privacy issues. This paper reports the design and use of TeamSlides, a multimodal teamwork analytics dashboard to support teacher-guided reflection. We conducted an in-the-wild classroom study involving 11 teachers and 138 students. Multimodal data were collected from students working in team healthcare simulations. We examined how teachers used the dashboard in 22 debrief sessions to aid their reflective practices. We also interviewed teachers to discuss their perceptions of the dashboard's value and the challenges faced during its use. Our results suggest that the dashboard effectively reinforced discussions and augmented teacher-guided reflection practices. However, teachers encountered interpretation conflicts, sometimes leading to mistrust or misrepresenting the information. We discuss the considerations needed to overcome these challenges in MMLA research.<br/></div> © 2024 ACM.},
key = {Students},
keywords = {Computer aided instruction;},
note = {Analytic solution;Dashboard;Multi-modal;Multi-modal learning;Multimodal learning analytic;Reflective practise;Teachers';Team dynamics;Teamwork analytic;Teamwork skills;},
URL = {http://dx.doi.org/10.1145/3636555.3636857},
} 


@inproceedings{20244017138415 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Tracking Students’ Progress in Educational Escape Rooms Through a Sequence Analysis Inspired Dashboard},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lopez-Pernas, Sonsoles and Gordillo, Aldo and Barra, Enrique and Saqr, Mohammed},
volume = {15160 LNCS},
year = {2024},
pages = {119 - 124},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards are the main vehicle for providing educators with a visual representation of data and insights related to teaching and learning. Recent research has found that the data visualizations provided by dashboards are often very basic and do not take advantage of the latest research advances to analyze and depict the learning process. In this article, we present a success story of how we adapted a visualization used for research purposes for its integration in a dashboard for its use by teachers in daily practice. Specifically, we described the process of transforming and integrating a static sequence analysis visualization into an interactive web visualization in a learning analytics dashboard for monitoring students’ temporal trajectories in educational escape rooms in real time. We interviewed teachers to find out how they made use of the dashboard and present a qualitative content analysis of their responses.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Students},
keywords = {Adversarial machine learning;Contrastive Learning;Data Analytics;Federated learning;Metadata;Teaching;Visual analytics;Visualization;},
note = {Dashboard;Educational escape room;Game-based Learning;Learning analytic;Recent researches;Sequence analysis;Student progress;Teachers';Teaching and learning;Visual representations;},
URL = {http://dx.doi.org/10.1007/978-3-031-72312-4_15},
} 


@inproceedings{20183805824506 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboard Analysing First-Year Engineering Students},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Vaclavek, Jonas and Kuzilek, Jakub and Skocilas, Jan and Zdrahal, Zdenek and Fuglik, Viktor},
volume = {11082 LNCS},
year = {2018},
pages = {575 - 578},
issn = {03029743},
address = {Leeds, United kingdom},
abstract = {Nowadays, the higher education institutions experience the problem of the student drop-out. In response to this problem, universities started employing analytical dashboards and educational data mining methods such as machine learning, to detect students at risk of failing their studies. In this paper, we present interactive web-based Learning Analytics dashboard - Analyst, which has been successfully deployed at Faculty of Mechanical Engineering (FME), Czech Technical University in Prague. The dashboard provides academic teaching staff with the opportunity to analyse student-related data from various sources in multiple ways to identify those, who might have difficulties to complete their degree. For this purpose, multiple analytical dashboard views have been implemented. It includes summary statistic, study progression graph, and credit completion probabilities graph. In addition, users have the option to export all analysis related graphs for the future use. Based on the outcomes provided by the Analyst, the university successfully ran the interventions on the selected at-risk students and significantly increased the retention rate in the first study year.<br/> © 2018, Springer Nature Switzerland AG.},
key = {Students},
keywords = {Computer aided instruction;Data mining;Engineering education;Data visualization;E-learning;},
note = {Analytical dashboard;Completion probability;Educational data mining;Faculty of mechanical engineerings;First-year engineering;Higher education institutions;Student retention;Technical universities;},
URL = {http://dx.doi.org/10.1007/978-3-319-98572-5_48},
} 


@inproceedings{20242616350067 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Designing for Self-Regulated Learning: A Dual-View Intelligent Visualization Dashboard to Support Instructors and Students Using Multimodal Trace Data in Classrooms},
journal = {Communications in Computer and Information Science},
author = {Brown, Michael and Wiedbusch, Megan and Patel, Milouni and Naderi, Evan and Capello, Sophia and Llinas, Andrea and Azevedo, Roger and Margondai, Ancuta},
volume = {2117 CCIS},
year = {2024},
pages = {9 - 19},
issn = {18650929},
address = {Washington, DC, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Effective learning analytics dashboards (LADs) should offer both instructors and students valuable insights into student learning. Information about one’s learning, as both a product and a process, should be provided to the user as actionable data visualizations and aggregated indicators of learning. However, most dashboards often solely focus on the instructor’s perspective, neglecting the impact of providing students with their data in a student view. Furthermore, these dashboards assume instructors are proficient in data analytics and can quickly interpret complicated visualizations in-situ while accounting for context and conditional factors. This challenge is further exacerbated by the lack of theoretically informed learning analytics principles and design choices as many of the dashboards rely primarily on performance-based data, neglecting process and trace data of cognitive, metacognitive, affective, motivational, and social (CAMMS) processes. As such, we are introducing MetaDash, a multimodal self-regulated learning (SRL) dashboard with both an instructor and student view. This dual-view (i.e., instructor and student-facing) dashboard prototype is populated with aggregate and contextualized multimodal trace data grounded within models of SRL, affect dynamics, information processing, cognitive load, and multimodal learning analytics. In this paper, we leverage ideas derived from SRL to identify gaps in current learning analytics dashboards. We then present the design principles and architecture of MetaDash, including how we derived its structure and how it supports our framework. We discuss the affective dynamics and learning analytics on the landing page to understand user engagement and detail how analytics are customized for different phases within the architecture. We highlight the advantages of incorporating real-time data analysis for immediate decision-making. Future research will focus on refining MetaDash through enhancements informed by user and focus group testing, experimental studies, and the integration of user feedback to address challenges and expand the dashboard’s functionality and effectiveness.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Students},
keywords = {Data Analytics;Data visualization;Decision making;Integration testing;Visualization;},
note = {Dashboard;Data analytics;Effective learning;Learning analytic;Metacognition;Multi-modal;Self-regulated learning;Student learning;Students' views;Trace data;},
URL = {http://dx.doi.org/10.1007/978-3-031-61953-3_2},
} 


@inproceedings{20240515471821 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {User experience study using a system for generating multimodal learning analytics dashboards},
journal = {ACM International Conference Proceeding Series},
author = {Becerra, alvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
year = {2023},
address = {Lleida, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">In the article, we present a Web-based System called M2LADS, which supports the integration and visualization of multimodal data recorded in user experiences (UX) in a Learning Analytics (LA) system in the form of Web-based Dashboards. Based on the edBB platform, the multimodal data gathered contains biometric and behavioral signals including electroencephalogram data to measure learners' cognitive attention, heart rate for affective measures and visual attention from the video recordings. Additionally, learners' static background data and their learning performance measures are tracked using LOGGE tool. M2LADS provides opportunities to capture learners' holistic experience during their interactions with the learning analytic system in order to improve the system and the user experience of the learners.<br/></div> © 2023 Owner/Author.},
key = {Biometrics},
keywords = {Behavioral research;Data visualization;E-learning;Learning systems;Video recording;Websites;},
note = {Analytics systems;Biometric and behavior;Dashboard;E - learning;MOOC;Multi-modal data;Multi-modal learning;Multimodal learning analytic;User experience (UX);Users' experiences;},
URL = {http://dx.doi.org/10.1145/3612783.3612813},
} 


@inproceedings{20162202443328 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Open-DLAs: An open dashboard for learning analytics},
journal = {L@S 2016 - Proceedings of the 3rd 2016 ACM Conference on Learning at Scale},
author = {Cobos, Ruth and Gil, Silvia and Lareo, angel and Vargas, Francisco A.},
year = {2016},
pages = {265 - 268},
address = {Edinburgh, United kingdom},
abstract = {In this paper a learning analytics dashboard for MOOCs is proposed. It visualises the progress of learners' activity taking into account navigation, social interactions and interaction with educational resources. This approach was tested with the MOOCs created by the University Autonóma of Madrid (Spain) in the edX platform. Nowadays, the dashboard is being improved taking into account the received feedback from MOOCs instructors and assistants. Finally, a new version is presented to work along with edX and Open edX. Copyright is held by the author/owner(s).<br/>},
note = {Dashboard;Educational resource;Learning analytics;MOOCs;Social interactions;},
URL = {http://dx.doi.org/10.1145/2876034.2893430},
} 


@inproceedings{20243817059044 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Co-Design of an Adaptive Personalized Learner Dashboard},
journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
author = {Seidel, Niels and Meyer, Valerie and Radovi, Slavisa},
year = {2024},
pages = {26 - 28},
address = {Hybrid, Nicosia, Cyprus},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards (LAD) equip learners with visual insights into their study activities, enabling informed decision-making. This paper introduces a LAD plugin tailored to individual needs to improve distance learners’ skills in metacognition and self-regulation. Through a co-design approach involving focus groups and interviews, students identified desired features like comprehensive resource overviews, deadline tracking, progress highlights, and enhanced interactions with peers and instructors. The final dashboard design allows learners to assess and track their knowledge, progress, and upcoming tasks, with metrics that facilitate comparisons against their goals and provide adaptive feedback. A user study (N=177) confirmed that users are engaged with the dashboard, but the planning and reflection tools were used less than the monitoring tools.<br/></div> © 2024 IEEE.},
key = {Adversarial machine learning},
keywords = {Contrastive Learning;Decision making;Economic and social effects;Federated learning;Self-supervised learning;},
note = {Adaptive learning;Co-designs;Decisions makings;Distance learners;Informed decision;Learning analytic dashboard;Metacognition;Plug-ins;Self regulation;Visual insights;},
URL = {http://dx.doi.org/10.1109/ICALT61570.2024.00014},
} 


@article{20223612680726 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Use of Predictive Analytics within Learning Analytics Dashboards: A Review of Case Studies},
journal = {Technology, Knowledge and Learning},
author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha and Umer, Rahila},
volume = {28},
number = {3},
year = {2023},
pages = {959 - 980},
issn = {22111662},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards (LADs) provide educators and students with a comprehensive snapshot of the learning domain. Visualizations showcasing student learning behavioral patterns can help students gain greater self-awareness of their learning progression, and at the same time assist educators in identifying those students who may be facing learning difficulties. While LADs have gained popularity, existing LADs are still far behind when it comes to employing predictive analytics into their designs. Our systematic literature review has revealed limitations in the utilization of predictive analytics tools among existing LADs. We find that studies leveraging predictive analytics only go as far as identifying the at-risk students and do not employ model interpretation or explainability capabilities. This limits the ability of LADs to offer data-driven prescriptive advice to students that can offer them guidance on appropriate learning adjustments. Further, published studies have mostly described LADs that are still at prototype stages; hence, robust evaluations of how LADs affect student outcomes have not yet been conducted. The evaluations until now are limited to LAD functionalities and usability rather than their effectiveness as a pedagogical treatment. We conclude by making recommendations for the design of advanced dashboards that more fully take advantage of machine learning technologies, while using suitable visualizations to project only relevant information. Finally, we stress the importance of developing dashboards that are ultimately evaluated for their effectiveness.<br/></div> © 2022, The Author(s).},
key = {Predictive analytics},
keywords = {Learning systems;Students;Visualization;},
note = {Behavioral patterns;Case-studies;Early Warning System;Feedback systems;Learning analytic dashboard;Self awareness;Student feedback;Student feedback system;Student learning;Systematic Review;},
URL = {http://dx.doi.org/10.1007/s10758-022-09613-x},
} 


@article{20243817047489 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Work Route for the Inclusion of Learning Analytics in the Development of Interactive Multimedia Experiences for Elementary Education},
journal = {Applied Sciences (Switzerland)},
author = {Solano, Andres and Pelaez, Carlos Alberto and Ospina, Johann A. and Luna-Garcia, Huizilopoztli and Parra, Jorge Andrick and Ramirez, Gabriel Mauricio and Moreira, Fernando and Lopez Sotelo, Jesus Alfonso and Villalba-Condori, Klinge Orlando},
volume = {14},
number = {17},
year = {2024},
issn = {20763417},
abstract = {<div data-language="eng" data-ev-field="abstract">Interactive multimedia experiences (IME) can be a pedagogical resource that has a strong potential to enhance learning experiences in early childhood. Learning analytics (LA) has become an important tool that allows us to understand more clearly how these multimedia experiences can contribute to the learning processes of these students. This article proposes a work route that defines a set of activities and techniques, as well as a flow for their application, by taking into consideration the importance of including LA guidelines when designing IMEs for elementary education. The work route’s graphical representation is inspired by the foundations of the Essence standard’s graphical notation language. The guidelines are grouped into five categories, namely (i) a data analytics dashboard, (ii) student data, (iii) teacher data, (iv) learning activity data, and (v) student progress data. The guidelines were validated through two approaches. The first involved a case study, where the guidelines were applied to an IME called Coco Shapes, which was aimed at transition students at the Colegio La Fontaine in Cali (Colombia), and the second involved the judgments of experts who examined the usefulness and clarity of the guidelines. The results from these approaches allowed us to obtain precise and effective feedback regarding the hypothesis under study. Our findings provide promising evidence of the value of our guidelines, which were included in the design of an IME and contributed to the greater personalized monitoring available to teachers to evaluate student learning.<br/></div> © 2024 by the authors.},
keywords = {Adversarial machine learning;Contrastive Learning;Students;},
note = {Elementary education;Enhance learning;Guideline;Interactive multimedia;Interactive multimedium experience;Learning analytic;Learning experiences;Pedagogical resources;Teachers';Work route;},
URL = {http://dx.doi.org/10.3390/app14177645},
} 


@inproceedings{20251218095131 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {15th International Conference on Learning Analytics and Knowledge, LAK 2025},
journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
year = {2025},
address = {Dublin, Ireland},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 100 papers. The topics discussed include: designing visual explanations and learner controls to engage adolescents in AI-supported exercise selection; platform-based adaptive experimental research in education: lessons learned from the digital learning challenge; one size does not fit all: considerations when using webcam-based eye tracking to models of neurodivergent learners’ attention and comprehension; diversity considerations in team formation design, algorithm, and measurement; scaling up collaborative dialogue analysis: an AI-driven approach to understanding dialogue patterns in computational thinking education; TeamTeachingViz: benefits, challenges, and ethical considerations of using a multimodal analytics dashboard to support team teaching reflection; and from complexity to parsimony: integrating latent class analysis to uncover multimodal learning patterns in collaborative learning.<br/></div>},
} 


@article{20201208314483 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A customizable and incremental processing approach for learning analytics},
journal = {IEEE Access},
author = {Perez-Berenguer, Daniel and Kessler, Mathieu and Garcia-Molina, Jesus},
volume = {8},
year = {2020},
pages = {36350 - 36362},
issn = {21693536},
abstract = {The ability of learning analytics to improve the learning/teaching processes is widely recognized. In this paper, the learning analytics architecture developed at the Digital Content Production Center of the Technical University of Cartagena (Spain) is presented. This architecture contributes to the field of learning analytics in two aspects: it allows for dashboard customization and improves the efficiency of the analysis of learners' interaction data. Events resulting from learners' interaction are captured and stored in Caliper standard format, to be further processed incrementally to allow dashboards to be shown without delay to teachers. Customization is considered a mandatory requirement for learning analytics tools, however, although some proposals have recently been made, a greater research effort in this topic is necessary. In the present work, this requirement is addressed by defining a domain-specific language (DSL) that allows teachers to customize dashboards. This language allows to express indicators (logical expressions) that classify students into different groups depending on their performance level. The paper also shows how our learning analytics approach was evaluated with a course that applies a flipped classroom method, and how it compares to the most relevant related works that have been published.<br/> © 2013 IEEE.},
key = {Learning systems},
keywords = {Problem oriented languages;Digital subscriber lines;},
note = {Caliper;Custom dashboard;Event Processing;Learning analytics;Model driven development;R~language;},
URL = {http://dx.doi.org/10.1109/ACCESS.2020.2975384},
} 


@unpublished{20240259600 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {VAAD: Visual Attention Analysis Dashboard applied to e-Learning},
journal = {arXiv},
author = {Navarro, Miriam and Becerra, alvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">In this paper, we present an approach in the Multimodal Learning Analytics field. Within this approach, we have developed a tool to visualize and analyze eye movement data collected during learning sessions in online courses. The tool is named VAAD -an acronym for Visual Attention Analysis Dashboard-. These eye movement data have been gathered using an eye-tracker and subsequently processed and visualized for interpretation. The purpose of the tool is to conduct a descriptive analysis of the data by facilitating its visualization, enabling the identification of differences and learning patterns among various learner populations. Additionally, it integrates a predictive module capable of anticipating learner activities during a learning session. Consequently, VAAD holds the potential to offer valuable insights into online learning behaviors from both descriptive and predictive perspectives.<br/></div> Copyright © 2024, The Authors. All rights reserved.},
keywords = {Adversarial machine learning;Contrastive Learning;Data visualization;Eye movements;Federated learning;Visual analytics;Visualization;},
note = {Dashboard;E - learning;Eye trackers;Learning analytic;Learning sessions;Machine-learning;Multi-modal learning;Online course;Online learning;Visual Attention;},
URL = {http://dx.doi.org/10.48550/arXiv.2405.20091},
} 


@inproceedings{20223812760079 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Adapting Learning Analytics Dashboards by and for University Students},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Oliver-Quelennec, Katia and Bouchet, Francois and Carron, Thibault and Fronton Casalino, Kathy and Pincon, Claire},
volume = {13450 LNCS},
year = {2022},
pages = {299 - 309},
issn = {03029743},
address = {Toulouse, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards (LADs) are becoming a key element in enabling learners to monitor their learning, plan and actually learn. However, LADs are sometimes not completely adapted to students, who are rarely involved in their design. Moreover, even when they are, the implemented LADs are often the same for all students, whereas previous works have shown the value of adapted LADs. Here we investigate which adaptations are requested by students, and attempt to identify which data and visualizations are suitable depending on the student’s profile. More specifically, we consider dynamic profiles as students’ expectations can vary over the course duration. By using LADs co-design sessions both online and on-site, we collected needs from N = 386 university students from different disciplines and degree level, split in 108 groups (2 to 4 students). After a manual annotation, we identified a total of 54 types of data and indicators, divided into 12 thematics. Our first analysis confirmed some previous results, particularly on the use of peer comparisons that do not fulfill every student’s needs. And we noticed other expectations according to the student’s learning context or the academic period. Future work will benefit from these results to define a model of adapted LADs.<br/></div> © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Students},
keywords = {Education computing;},
note = {Co-designs;Dashboard;Key elements;Learn+;Learning analytic dashboard;Learning context;Manual annotation;Student expectations;University students;},
URL = {http://dx.doi.org/10.1007/978-3-031-16290-9_22},
} 


@inproceedings{20193407343886 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics, dashboard for academic trajectory},
title = {Analítica del aprendizaje, visualización de trayectoria académica},
journal = {CEUR Workshop Proceedings},
author = {Pena, M. and Bravo, F. and Illescas-Pena, L.},
volume = {2425},
year = {2019},
issn = {16130073},
address = {Valdivia, Chile},
abstract = {In the context of university academic management, several proposals have been developed for the study of analysis and visualization of learning trajectories. Bearing in mind that the educational trajectory is the trajectory of the student traveled at a given time from entry to the end of the stay, it can be considered that the use of technology could extract or highlight relevant information that is not seen directly with the tools traditional The visualization of data in educational environments has become a challenge due to the large amounts of information available. The responsibilities of educational administrators require a clear visual proposal adapted to queries based on an academic context. Therefore, it was proposed to generate a tool that generates dashboard based on relevant variables of the students. To do this, the proposal began with a review of the literature that helped analyze the different ways of visualizing the data of academic trajectories. Subsequently, a dynamic visualization was formulated to explain the teachers and authorities through the learning analysis panel, based on the use of parallel coordinates that present multidimensional data over time. The sample was constituted by records of 1975 students of an Ecuadorian university, of the cohort that began in March 2013, distributed by faculties and careers. The technique used allowed us to discover trends and relationships between dimensions, improving the understanding of the trajectory patterns of students, the trends of school dropout, either increase or decrease performance, among other relationships. The consultations allowed to filter data by variables such as: faculties, careers, students and intervals of scores. Finally, the validation of the proposal was made based on the relevance of the dashboard, in response to the inquiries of the academic manager.<br/> © 2019 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {Visualization;Data visualization;Trajectories;},
note = {Academic managements;Dynamic visualization;Educational administrators;Educational environment;Learning trajectories;Multidimensional data;Parallel coordinates;Trajectory pattern;},
} 


@article{20233714721469 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging cultural forms in human-centred learning analytics design},
journal = {British Journal of Educational Technology},
author = {Campos, Fabio and Nguyen, Ha and Ahn, June and Jackson, Kara},
volume = {55},
number = {3},
year = {2024},
pages = {769 - 784},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">In this article, we offer theory-grounded narratives of a 4-year participatory design process of a Learning Analytics tool with K-12 educators. We describe how we design-in-partnership by leveraging educators' routines, values and cultural representations into the designs of digital dashboards. We make our long-term reasoning visible by reflecting upon how design decisions were made, discussing key tensions and analysing to what extent the developed tools were taken up in practice. Through thick design narratives, we reflect upon how cultural forms—recognizable cultural constructs that might cue and facilitate specific activities—were identified among educators and informed the design of a dashboard. We then examined the extent to which the designed tool supported coaches and teachers to engage in Generative Uncertainty, an interpretive stance in which educators manifest productive inquiries towards data. Our analysis highlights that attuning to cultural forms is a valuable first step but not enough towards designing LA tools for systems in ways that fit institutionalized practices, challenge instrumental uses and spur productive inquiry. We conclude by offering two key criteria for making culturally-grounded design decisions in the context of long-term partnerships. Practitioner notes What is already known about this topic Participatory design can invite stakeholders to directly inform the creation of LA artefacts that fit their needs, context and cultural markers. What this paper adds Cultural forms can be identified and leveraged in the design of LA tools. HCLA scholars ought to design for systems—the complex body of organizational routines, cultural practices and interactions among multiple stakeholders—and not just for users. Implications for practice and/or policy Leveraging cultural forms in LA needs to be accompanied by a critical view of which practices, behaviours, values and structures are suggested by such forms. Designing features that are easy to use, are associated with concrete tasks, and fit into existing cultural practices are three criteria for embedding cultural forms into LA design.<br/></div> © 2023 British Educational Research Association.},
key = {Design},
note = {Analytic design;Analytic tools;Cultural form;Cultural practices;Design decisions;Design-process;K-12 educators;Learning analytic;Participatory design;Research-practice partnership;},
URL = {http://dx.doi.org/10.1111/bjet.13384},
} 


@inproceedings{20243416888204 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {VAAD: Visual Attention Analysis Dashboard Applied to e-Learning},
journal = {26th International Symposium on Computers in Education, SIIE 2024},
author = {Navarro, Miriam and Becerra, alvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
year = {2024},
address = {A Coruna, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">In this paper, we present an approach in the Multimodal Learning Analytics field. Within this approach, we have developed a tool to visualize and analyze eye movement data collected during learning sessions in online courses. The tool is named VAAD -an acronym for Visual Attention Analysis Dashboard-. These eye movement data have been gathered using an eye-tracker and subsequently processed and visualized for interpretation. The purpose of the tool is to conduct a descriptive analysis of the data by facilitating its visualization, enabling the identification of differences and learning patterns among various learner populations. Additionally, it integrates a predictive module capable of anticipating learner activities during a learning session. Consequently, VAAD holds the potential to offer valuable insights into online learning behaviors from both descriptive and predictive perspectives.<br/></div> © 2024 IEEE.},
key = {Population statistics},
keywords = {Behavioral research;Data visualization;E-learning;Eye movements;Eye tracking;Learning systems;Modal analysis;},
note = {Dashboard;E - learning;Eye movement datum;Eye trackers;Learning analytic;Learning sessions;Machine-learning;Multi-modal learning;Online learning;Visual Attention;},
URL = {http://dx.doi.org/10.1109/SIIE63180.2024.10604520},
} 


@inproceedings{20223312558095 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Remotify: The Emergency Remote Learning Solution using Learning Analytics},
journal = {2022 IEEE 7th International conference for Convergence in Technology, I2CT 2022},
author = {Amarasinghe, S.N. and Thalakumbura, T.M.D.D. and Wijewardena, M.D.N.K. and Perera, D.H. and Manathunga, Kalpani and Senaweera, Oshada},
year = {2022},
pages = {Siddhant College of Engineering - },
address = {Pune, India},
abstract = {<div data-language="eng" data-ev-field="abstract">Current pandemic situation has manipulated people to adapt to a new normal forcefully and due to the same reason education system is also evolving but the actual question is how productive the new methodologies utilized are. E-learning is not a novel concept but is becoming a necessity and the proposed platform could be identified as a direct response to the current emergency. This can also be known as an "ERT"situation; a shift of instructional delivery to an alternate delivery method in response to a crisis situation. The main intention in these situations is not to recreate a robust educational system but to provide access to institutions in a manner that is easy to set up and is dependable during an emergency while outperforming both E-learning & traditional classroom methods. To provide a solution to overcome barriers faced in a pandemic situation in a virtual classroom, the implemented system is encapsulated with a dashboard centralizing facts gathered from audio & video analyzing components which are analyzed against student performance utilizing personalized assessing techniques to deliver learning analytics.<br/></div> © 2022 IEEE.},
key = {E-learning},
keywords = {Computer aided instruction;Learning systems;Students;},
note = {'current;Dashboard;E - learning;Education systems;Emergency remote teaching;Learning analytic;Novel concept;Remote learning;Remote teaching;Virtual Classroom;},
URL = {http://dx.doi.org/10.1109/I2CT54291.2022.9824707},
} 


@inproceedings{20231313819171 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Analysis of the Impact Student‐Facing Learning Analytics Dashboards on Learning Motivation and Behaviors according to the Motivational Type of Learners},
journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
author = {Matsumoto, Tomoka and Ishii, Yuna and Horikoshi, Izumi and Tamura, Yasuhisa},
volume = {2},
year = {2022},
pages = {705 - 708},
address = {Kuala Lumpur, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">The authors developed two types of dashboards according to learners' motivational type and analyzed the effects of differences in dashboard visualization formats on learning behaviors and motivation. The results showed that some subjects prefer the visualization format of the dashboard regardless of their motivational type. In addition, we confirmed that learners with increased motivation also had increased learning behaviors, such as viewing videos.<br/></div> © ICCE 2022.All rights reserved.},
key = {Motivation},
keywords = {Visualization;},
note = {Adaptive learning;Dashboard;Learning analytic;Learning behavior;Learning motivation;},
} 


@article{20172403788373 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Give Me a Customizable Dashboard: Personalized Learning Analytics Dashboards in Higher Education},
journal = {Technology, Knowledge and Learning},
author = {Roberts, Lynne D. and Howell, Joel A. and Seaman, Kristen},
volume = {22},
number = {3},
year = {2017},
pages = {317 - 333},
issn = {22111662},
abstract = {With the increased capability of learning analytics in higher education, more institutions are developing or implementing student dashboards. Despite the emergence of dashboards as an easy way to present data to students, students have had limited involvement in the dashboard development process. As part of a larger program of research examining student and academic perceptions of learning analytics, we report here on work in progress exploring student perceptions of dashboards and student preferences for dashboard features. First, we present findings on higher education students’ attitudes towards learning analytic dashboards resulting from four focus groups (N = 41). Thematic analysis of the focus group transcripts identified five key themes relating to dashboards: ‘provide everyone with the same learning opportunities’, ‘to compare or not to compare’, ‘dashboard privacy’, ‘automate alerts’ and ‘make it meaningful—give me a customizable dashboard’. Next we present findings from a content analysis of students’ drawings of dashboards demonstrating that students are interested in features that support learning opportunities, provide comparisons to peers and are meaningful to the student. Finally, we present preliminary findings from a survey of higher education students, reinforcing students’ desire to choose whether to have a dashboard and to be able to customize their dashboards. These findings highlight the potential for providing students with some level of control over learning analytics as a means to increasing self-regulated learning and academic achievement. Future research directions aimed at better understanding students emotional and behavioral responses to learning analytics feedback on dashboards and alerts are outlined.<br/> © 2017, Springer Science+Business Media B.V.},
key = {Students},
keywords = {Big data;},
note = {Academic achievements;Future research directions;Higher education;Higher education students;Learning analytics;Personalized learning;Self-regulated learning;Student attitudes;},
URL = {http://dx.doi.org/10.1007/s10758-017-9316-1},
} 


@inproceedings{20242216163094 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics to Validate Academic Performance Analysis},
journal = {9th International Conference on Engineering and Emerging Technology, ICEET 2023},
author = {Oliveira, Pedro Filipe and Matos, Paulo},
year = {2023},
address = {Istanbul, Turkey},
abstract = {<div data-language="eng" data-ev-field="abstract">The learning process is increasingly on the agenda. As well as the mechanisms that can be used to optimize it, both in terms of improving student performance, as well as improving teacher performance. On this subject, there has been continuous research, and increasingly trying to take advantage of technological development, and thus be able to take full advantage of technology and achieve a significant leverage in this field. This work is developed within the scope of the evaluation of school performance. Namely, with the introduction of additional and customized resources, such as thematic courses on the Coursera platform, and the utilization analysis of the e-learning platform used by the teaching institution. With this, it was possible to develop some tools, which are used as dashboards to give the teacher a greater perception of the student's learning process and performance. And if any student is in the prospect of failing, the teacher receives an immediate notification, so that he can carry out the respective follow-up, and thus be able to act proactively to avoid failure.<br/></div> © 2023 IEEE.},
key = {Teaching},
keywords = {Engineering education;Learning systems;Students;},
note = {Academic performance;Courserum;Dashboard;Learning process;Learning-analytic;Performance;Performances analysis;Student performance;Teachers';Technological development;},
URL = {http://dx.doi.org/10.1109/ICEET60227.2023.10525855},
} 


@inproceedings{20225013255531 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting self-regulated learning in a blended learning environment using prompts and learning analytics},
journal = {CEUR Workshop Proceedings},
author = {Rako, Sabina and imi, Diana and Rienties, Bart},
volume = {3292},
year = {2022},
pages = {66 - 71},
issn = {16130073},
address = {Toulouse, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Higher education institutions, teachers, and students face new difficulties and opportunities resulting from the introduction of modern technology into the learning process. The widespread of learning environments that integrate online learning and face-to-face learning may pose some opportunities as well as difficulties for some groups of students' self-regulation skills. Providing automated prompts may help to support those students with insufficient self-regulation skills. The use of learning analytics and multiple methods and data sources (data triangulation) may give better insight into the self-regulation process. The objective of the proposed research is to explore the students' evaluation of the usefulness of prompts implemented in a blended learning environment. A secondary objective is to develop and evaluate a real-time dashboard designed to notify teachers of student responses to deployed prompts. The research methodology will be grounded in action research and empirical research. The scientific contribution will be achieved through the development of artefacts and the performance of empirical research to advance understanding of the student's self-regulation in a blended learning environment.<br/></div> © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
key = {Students},
keywords = {Computer aided instruction;Deregulation;Learning systems;},
note = {Blended learning;Blended learning environments;Dashboard;Empirical research;High educations;Higher education students;Learning analytic;Prompt;Self regulation;Self-regulated learning;},
} 


@inproceedings{20232314183875 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using Design-Based Research for an Academic Dropout and Retention Dashboard},
journal = {2023 9th International Conference on eDemocracy and eGovernment, ICEDEG 2023},
author = {Heredia-Jimenez, Vanessa and Yaguana, Jhony and Jimenez-Macias, Alberto and Ortiz-Rojas, Margarita},
year = {2023},
address = {Quito, Ecuador},
abstract = {<div data-language="eng" data-ev-field="abstract">Student dropout and retention are a major concern in Higher Education Institutions(HEIs). HEIs use the benefits of Learning Analytics (LA) dashboards to address this concern by monitoring student's academic progress and identify students at risk. This study adds to the existing body of knowledge, the experience of designing, implementing, and evaluating a dropout and retention dashboard embedded in an academic counseling system. Through the use of a Design-Based Research methodology, we show the process of going from the needs analysis level, through 3 iterations to test and evaluate the dashboard, to end with preliminary design principles. The lessons learned serve as a guide for LA designers in the implementation of such dashboards.<br/></div> © 2023 IEEE.},
key = {Data visualization},
keywords = {Design;Students;},
note = {Academic advising;Analytical dashboard;Body of knowledge;Design-based research;Higher education institutions;Learning dashboard;Need analysis;Preliminary design;Research methodologies;Student retention;},
URL = {http://dx.doi.org/10.1109/ICEDEG58167.2023.10122065},
} 


@inproceedings{20184005884945 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancing students' critical reading fluency, engagement and self-efficacy using self-referenced learning analytics dashboard visualizations},
journal = {Proceedings of the 25th International Conference on Computers in Education, ICCE 2017 - Main Conference Proceedings},
author = {Jonathan, Christin and Tan, Jennifer Pei-Ling and Koh, Elizabeth and Caleon, Imelda and Tay, Siu Hua},
year = {2017},
pages = {457 - 462},
address = {Christchurch, New zealand},
abstract = {Although learning analytics (LA) dashboard visualizations are increasingly being used to provide feedback to students, literature on the effectiveness of LA dashboards has been inconclusive. To address this, a LA student dashboard visualizing students' latest data against their own data from previous weeks (i.e., self-referenced data) was designed - informed by Fredrickson's (2004) broaden-and-build theory, as well as studies highlighting personal best goals (Martin & Elliot, 2016) and the negative effects of peer comparisons (Corrin & de Barba, 2014). The self-referenced LA student dashboard was implemented and evaluated in a Singapore Secondary school as part of a larger study, WiREAD. This paper reports on the quantitative impact of the WiREAD self-referenced LA dashboard visualizations on 15-year-old students' critical reading fluency, cognitive reading engagement, and English language (EL) self-efficacy, as well as students' qualitative feedback on the usefulness and shortcomings of the LA dashboard.<br/> © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.},
key = {Students},
keywords = {Visualization;},
note = {English languages;Feedback to students;Learning Analytics;Qualitative feedback;Reading skills;Secondary schools;Self efficacy;Singapore;},
} 


@article{20221812044914 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Team interactions with learning analytics dashboards},
journal = {Computers and Education},
author = {Zamecnik, Andrew and Kovanovi, Vitomir and Grossmann, Georg and Joksimovi, Sreko and Jolliffe, Gabrielle and Gibson, David and Pardo, Abelardo},
volume = {185},
year = {2022},
issn = {03601315},
abstract = {<div data-language="eng" data-ev-field="abstract">Student-facing visualisations have attracted increased attention with recent developments in data-driven tools to support individual and group work. Learning analytics dashboards (LADs), a data-enhanced feedback tool that allows students to make sense of their learning by providing insights into their learning behaviours represents one of the prominent examples of this trend. While these visualisation tools are increasingly used to study and enhance students' learning in academic contexts, current research is limited regarding the effects of the LADs in K-12 environments. There is a missed opportunity to empower teams and allow instructors and researchers to understand how teams use the LAD to regulate their learning. In this study, we developed a K-12 LAD for supporting students' collaborative work and evaluated with respect to students' perceived usefulness of the proposed LAD and the association between its use and course performance. The study followed a mixed-methods approach, combining quantitative analysis of log data from the dashboard and qualitative analysis of students’ perceptions using surveys and focus groups. Our results show that different roles within teams have distinguished engagement patterns with the LAD and that the tool improves the collaborative learning experience. We postulate that the implications of this study will aid future research work when investigating the behaviours of teams and optimising their learning using LADs.<br/></div> © 2022 Elsevier Ltd},
key = {Students},
keywords = {Visualization;},
note = {Blended learning;Collaboration;Dashboard;Data driven;Feedback tool;Group work;K-12;Learning analytic;Learning behavior;Team interaction;},
URL = {http://dx.doi.org/10.1016/j.compedu.2022.104514},
} 


@inproceedings{20221111797004 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Empowering Teachers with AI: Co-Designing a Learning Analytics Tool for Personalized Instruction in the Science Classroom},
journal = {ACM International Conference Proceeding Series},
author = {Nazaretsky, Tanya and Bar, Carmel and Walter, Michal and Alexandron, Giora},
year = {2022},
pages = {1 - 12},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">AI-powered educational technology that is designed to support teachers in providing personalized instruction can enhance their ability to address the needs of individual students, hopefully leading to better learning gains. This paper presents results from a participatory research aimed at co-designing with science teachers a learning analytics tool that will assist them in implementing a personalized pedagogy in blended learning contexts. The development process included three stages. In the first, we interviewed a group of teachers to identify where and how personalized instruction may be integrated into their teaching practices. This yielded a clustering-based personalization strategy. Next, we designed a mock-up of a learning analytics tool that supports this strategy and worked with another group of teachers to define an 'explainable learning analytics' scheme that explains each cluster in a way that is both pedagogically meaningful and can be generated automatically. Third, we developed an AI algorithm that supports this 'explainable clusters' pedagogy and conducted a controlled experiment that evaluated its contribution to teachers' ability to plan personalized learning sequences. The planned sequences were evaluated in a blinded fashion by an expert, and the results demonstrated that the experimental group - teachers who received the clusters with the explanations - designed sequences that addressed the difficulties exhibited by different groups of students better than those designed by teachers who received the clusters without explanations. The main contribution of this study is twofold. First, it presents an effective personalization approach that fits blended learning in the science classroom, which combines a real-time clustering algorithm with an explainable-AI scheme that can automatically build pedagogically meaningful explanations from item-level meta-data (Q Matrix). Second, it demonstrates how such an end-to-end learning analytics solution can be built with teachers through a co-design process and highlights the types of knowledge that teachers add to system-provided analytics in order to apply them to their local context. As a practical contribution, this process informed the design of a new learning analytics tool that was integrated into a free online learning platform that is being used by more than 1000 science teachers.<br/></div> © 2022 ACM.},
key = {Clustering algorithms},
keywords = {Design;Learning systems;Students;},
note = {Analytic tools;Blended learning;Co-designing;Learning analytic;Participatory design;Personalized instruction;Science classroom;Science teachers;Teacher dashboard;Teachers';},
URL = {http://dx.doi.org/10.1145/3506860.3506861},
} 


@inproceedings{20244017138410 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An Experimental Study into the Effects of an Advisory Dashboard on Students’ Online and Offline Learning},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {de Vetten, Arjen},
volume = {15160 LNCS},
year = {2024},
pages = {87 - 92},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards can provide students with personalized actionable feedback to enhance students’ learning. Previous studies have shown positive effects of such advisory dashboards on course engagement and self-regulatory activities. To date, no studies have investigated the effects of advisory dashboards on students’ offline learning activities, such as taking and reviewing written notes, while previous research suggests that many students also employ offline learning activities. Using a randomized control trial, the current study investigated the effects of an advisory dashboard on students’ online and offline remediation activities. Before the start of a second-year course, 65 Bachelor of Law students completed a prior knowledge test concerning the topics of a preceding first-year course. The experimental group (n = 30) received their test results and personalized feedback to review particular knowledge clips and quizzes to remediate their prior knowledge. The control group (n = 35) received their test results and a generic, non-personalized remediation advice. A combination of digital trace and questionnaire data measured students’ remediation activities, including the review of knowledge clips, online quizzes, readings and written notes. The findings did not reveal significant effects of the personalized actionable feedback on students’ remediation activities. However, overall students showed a strong preference for offline activities to remediate their prior knowledge. This calls for further studies on students’ offline learning activities in response to personalized actionable feedback.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Remediation},
keywords = {Active learning;Contrastive Learning;Curricula;Federated learning;Self-supervised learning;Students;},
note = {Actionable feedback;Advisory dashboard;Learning Activity;Learning analytic;Off-line learning;Offline;Online learning;Personalized learning;Prior-knowledge;Student learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-72312-4_10},
} 


@inproceedings{20231313819179 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Digitally Enhanced Active Reading in a Learning Analytics Enhanced Environment},
journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
author = {Toyokawa, Yuko and Horikoshi, Izumi and Majumdar, Rwitajit and Ogata, Hiroaki},
volume = {2},
year = {2022},
pages = {742 - 745},
address = {Kuala Lumpur, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">Active reading (AR) strategies have learners challenge reading through deep engagement with the content to foster their independence and develop their performance and skills in reading. A number of studies have been conducted to examine the effectiveness of AR, yet there is no research that uses logs obtained from reading activities to scaffold and promote AR learning. Therefore, this study proposes to investigate AR from Learning Analytics (LA) perspectives. An e-book called BookRoll (BR) was used, and the logs obtained from the learning were visualized and shared as feedback. As part of it, we designed and developed Active Reading Dashboard (AR-D). In the framework of our LA-enhanced AR called Digitally Enhanced Active Reading (DEAR), AR experiments in language classes were conducted to reveal its effects. As a result, it was found that the process of AR could be visualized from learning logs, and DEAR could be applied in formal and informal learning contexts. The AR-D was found to influence learners' attitudes or perceptions toward reflecting on their own learning and striving to improve their reading strategies. As future work, continual implementation and verifying its application in different learning contexts are suggested. We shall also consider the importance of stakeholders' engagement in learning environments.<br/></div> © ICCE 2022.All rights reserved.},
key = {Scaffolds},
keywords = {Computer aided instruction;E-learning;Electronic publishing;},
note = {Active reading;E-books;Formal learning;Learning analytic;Learning analytic dashboard;Learning context;Learning log;Performance;Reading activities;Reading strategies;},
} 


@inproceedings{20184405999446 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics dashboard to work the Flipped Classroom methodology through the reuse of MOOCs},
title = {Tablero Learning Analytics para trabajar la metodologia Flipped Classroom mediante la reutilización de MOOCs},
journal = {CEUR Workshop Proceedings},
author = {Collado-Gomez, Cristina and Alario-Hoyos, Carlos and Santin-Cristobal, David and Cruz-Argudo, Francisco and Kloos, Carlos Delgado},
volume = {2224},
year = {2018},
pages = {15 - 24},
issn = {16130073},
address = {Medellin, Colombia},
abstract = {That a student can be aware, in real time, of his/her performance is essential to promote participation in a course and the implementation of flipped classroom strategies. This work presents a preliminary work on the development of a Learning Analytics dashboard for the Open edX platform to support MOOCs (Massive Open Online Courses) and SPOCs (Small Private Online Courses) at Universidad Carlos III de Madrid. The new design tries to motivate students, showing them information about the results and statistics they are obtaining in a course. In addition, the student gets information about his/her progress with respect to the peers. After asking users their opinion on the new Learning Analytics dashboard, the answers received are mostly positive, also receiving suggestions and opinions on possible improvements that the system could have in the future.<br/> © 2018 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {Curricula;E-learning;},
note = {Classroom methodologies;Massive open online course;Online course;Real time;},
} 


@inproceedings{20183405715618 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Designing a learning analytics dashboard for twitter-facilitated teaching},
journal = {Proceedings of the 5th Annual ACM Conference on Learning at Scale, L at S 2018},
author = {Gruzd, Anatoliy and Conroy, Nadia},
year = {2017},
address = {London, United kingdom},
abstract = {Social media sites are increasingly being adopted to support teaching practice in higher education. Learning Analytics (LA) dashboards can be used to reveal how students engage with course material and others in the class. However, research on the best practices of designing, developing, and evaluating such dashboards to support teaching and learning with social media has been limited. Considering the increasing use of Twitter for both formal and informal learning processes, this paper presents our design process and a LA prototype dashboard developed based on a comprehensive literature review and an online survey among 54 higher education instructors who have used Twitter in their teaching.<br/> © 2017 Association for Computing Machinery. All rights reserved.},
key = {Surveys},
keywords = {Social networking (online);Teaching;Design;},
note = {Course material;Dashboards;Higher education;Informal learning;Learning Analytics;Literature reviews;Teaching and learning;Teaching practices;},
URL = {http://dx.doi.org/10.1145/3231644.3231704},
} 


@inproceedings{20214811235219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Scaffolding Teacher Learning During Professional Development with Theory-Driven Learning Analytics},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Khulbe, Manisha and Tammets, Kairit},
volume = {13103 LNCS},
year = {2021},
pages = {14 - 27},
issn = {03029743},
address = {Macau, China},
abstract = {<div data-language="eng" data-ev-field="abstract">It is claimed that the innovative use of educational technology combined with appropriate pedagogical strategies can lead to improved student outcomes. However, teachers face difficulties in adopting educational technology and novel pedagogical methods as this involves acquiring complex new knowledge. Combined with training, Learning Analytics dashboards – artifacts which mediate teachers’ learning in technology-enhanced environments – can aid them in this task. Using student engagement as an example, we present the prototype of a theory-driven dashboard that can help teachers to better understand and implement new instructional methods in technology-enhanced learning environments. We describe here our needs analysis, design, and evaluation process and outcomes, reflecting upon how teachers can benefit from using thoughtfully-designed LA dashboards in professional development scenarios.<br/></div> © 2021, Springer Nature Switzerland AG.},
key = {Educational technology},
keywords = {Personnel training;Professional aspects;Engineering education;Computer aided instruction;Students;Scaffolds;},
note = {Learning analytic dashboard;Pedagogical method;Pedagogical strategies;Professional development;Student outcomes;Teacher learning;Teacher professional development;Teacher-facing dashboard;Teachers';Theory-driven dashboard;},
URL = {http://dx.doi.org/10.1007/978-3-030-90785-3_2},
} 


@inproceedings{20231313819239 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Pedagogical Companions to Support Teachers' Interpretation of Students' Engagement from Multimodal Learning Analytics Dashboards},
journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
author = {Wiedbusch, Megan and Sonnenfeld, Nathan and Henderson, James},
volume = {2},
year = {2022},
pages = {432 - 437},
address = {Kuala Lumpur, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">Teaching demands educators adapt and improvise their instruction for each student's unique needs and capabilities across contexts. This requires teachers to observe their students, evaluate their ongoing learning, and offer individualized scaffolding and feedback and foster sustained growth and development. This challenging practice has been made even more difficult by the recent emphasis on data-driven instructional decision making from dashboards, further requiring teachers to become both pedagogical and data experts. Despite the development of dashboards to alleviate some of the load of collecting and aggregating complex multimodal student data, there is a need to provide support for teachers in analyzing, interpreting, and applying their students' real-time multimodal learning analytical data (e.g., metacognitive accuracy, negative emotions) in the form of pedagogical companions. Before we can begin the design and development of these agents, we must first understand how educators are currently approaching multimodal learning analytics (MMLA) that report on more than just performance-based outcomes. In this on-going work, we begin by briefly reviewing MMLA in teacher dashboards, teacher data literacy, and the role of pedagogical companions in teacher augmentation technologies. We then describe the development of an in-progress study exploring how three teachers currently use fictious MMLA on self-regulated learning (SRL) processes and the emerging trends we see from their data. Finally, we postulate what these results suggest about the needs that embedded intelligent pedagogical companions may fill in future dashboard and agent design.<br/></div> © ICCE 2022.All rights reserved.},
key = {Students},
keywords = {Decision making;Scaffolds;},
note = {Agent design;Data driven;Growth and development;Multi-modal learning;Multimodal learning analytic;Ongoing learning;Pedagogical companion;Student engagement;Teacher dashboard;Teachers';},
} 


@inproceedings{20242316192341 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancing Educational Efficiency: Learning Analytics in the Management of Course Development in Virtual Environments},
journal = {CEUR Workshop Proceedings},
author = {Abad-Troya, Jose and Cadme-Samaniego, Irma E.},
volume = {3691},
year = {2023},
pages = {91 - 101},
issn = {16130073},
address = {Zacatecas, Mexico},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics provide a set of elements for data analysis in the educational field. This analysis is complemented with semantic web tools that allow obtaining a wider benefit, overcoming the interoperability barrier, and the capacity to generate new knowledge. The present work aims to facilitate the management of courses offered in the various online education platforms through learning analytics. The analytics process includes extracting, transforming, and loading data stored in an RDF data repository. It has also required designing and implementing an ontology representing MOOC courses. Finally, the visualization of the obtained indicators will be available in a dashboard with access for end users.<br/></div> © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
key = {Ontology},
keywords = {Curricula;E-learning;Metadata;Resource Description Framework (RDF);},
note = {Course development;Data repositories;Learning analytic;Loading data;MOOC;On-line education;Ontology's;RDF data;Semantic-Web;Web tools;},
} 


@article{20251118050351 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Student’s Progress Snapshot a Hybrid Text and Visual Learning Analytics Dashboard},
journal = {International Journal of Engineering Education},
author = {Amo, Daniel and Alier, Marc and Casan, Maria Jose},
volume = {34},
number = {3},
year = {2018},
pages = {990 - 1000},
issn = {0949149X},
abstract = {<div data-language="eng" data-ev-field="abstract">In recent years, virtual learning environments, laptops, tablets and mobile devices have been introduced in the classroom. These technologies start a snowball effect: the old tools teachers used to fathom the students’ learning progress, since so much happens online, are not enough. Thus, the need for new tools to analyse the students’ activity on the online learning environments arises. The field of learning analytics can provide some of these tools. In this paper, we introduce the Student’s Progress Snapshot (SPS), a Learning Analytics Dashboard that allows teachers to analyse the activity of their students on Moodle courses. The SPS running as software as a service, includes both charts and automatically generated explanatory texts of these charts. During the academic course 2015-2016 a pilot was conducted to validate the SPS.<br/></div> © 2018 Tempus Publications. All rights reserved.},
key = {Contrastive Learning},
keywords = {Active learning;Adversarial machine learning;Collaborative learning;Federated learning;Software as a service (SaaS);Students;Transfer learning;Virtual environments;Visual analytics;},
note = {Learning analytic;Learning management system;Learning progress;Moodle;Online learning environment;Student interactions;Student learning;Teachers';Virtual learning environments;Visual learning;},
} 


@inproceedings{20251218095223 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {TeamTeachingViz: Benefits, Challenges, and Ethical Considerations of Using a Multimodal Analytics Dashboard to Support Team Teaching Reflection},
journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
author = {Alfredo, Riordan and Mejia-Domenzain, Paola and Echeverria, Vanessa and Rahayu, Dwi and Zhao, Linxuan and Alajlan, Haya and Swiecki, Zachari and Kaser, Tanja and Gaevi, Dragan and Martinez-Maldonado, Roberto},
year = {2025},
pages = {58 - 69},
address = {Dublin, Ireland},
abstract = {<div data-language="eng" data-ev-field="abstract">Team teaching in higher education can be challenging, especially for educators managing large classes with limited pedagogical training and few opportunities to reflect on their practices. Emerging sensing technologies and analytics can capture and analyse patterns of collaboration, communication, and movement of team teaching. Yet, few studies have presented these data to educators for reflection. To address this gap, we examine the benefits, challenges, and concerns of presenting multimodal teaching data (positional, audio, and spatial pedagogy observations) to educators via the TeamTeachingViz dashboard. We evaluated TeamTeachingViz in an authentic classroom context where educators explored their own data and team teaching strategies. Multimodal data was collected from 36 in-the-wild classroom sessions involving 12 educators grouped in various combinations over 4 weeks, followed by semi-structured interviews to reflect on their practices. Findings suggest that educators improved their self-awareness by using data-driven insights to understand their movements and interactions, enabling continuous improvement in team teaching. However, they noted the need for additional data, such as student behaviours and speech content, to better contextualise these insights.<br/></div> © 2025 Copyright held by the owner/author(s).},
note = {Co-teaching;In-the-wild;LA dashboard;Multi-modal;Multi-modal learning;Multimodal learning analytic;Spatial pedagogy;Teaching analytics;Teaching reflection;Team teaching;},
URL = {http://dx.doi.org/10.1145/3706468.3706475},
} 


@inproceedings{20223912787246 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Data Pipeline Approach for Building Learning Analytics Dashboards},
journal = {ACM International Conference Proceeding Series},
author = {Tsoni, Rozita and Kalles, Dimitris and Verykios, Vassilios},
year = {2022},
pages = {Hellenic Artificial Intelligence Society; Humanistic and Social Informatics Laboratory (HILab); Ionian University, Department of Informatics - },
address = {Corfu, Greece},
abstract = {<div data-language="eng" data-ev-field="abstract">In the era of data abundance, the ability to leverage data to assess the learning process is of great importance. Learning Analytics has been widely used and different approaches of deployment methods have been proposed, aiming to improve teaching and learning. Learning Analytics Dashboards (LAD), as the most dominant method to communicate results to the educational stakeholders, are found to be very effective. However, building a flexible and informative LAD is a complex procedure that incorporates several consecutive steps. The data pipeline framework which is used as a blueprint for generating LADs in this paper offers an important abstraction that helps the non-technical users to appreciate the effectiveness of the approach, as for every insight and report that is generated by a data scientist, there are most probably large such pipelines that implement the underlying functionality. This paper discusses the utility of data pipelines and presents the implementation of a LAD based on a data pipeline in Distance Learning students' data for summative assessment, along with some preliminary results.<br/></div> © 2022 ACM.},
key = {Distance education},
keywords = {Blueprints;Learning systems;Pipelines;},
note = {Complex procedure;Data pipelines;Deployment methods;Distance-learning;Learning analytic dashboard;Learning process;Non-technical users;Summative assessments;Teaching and learning;},
URL = {http://dx.doi.org/10.1145/3549737.3549774},
} 


@inproceedings{20250217650983 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Share Spell - From Fantasy to Reality: A Collaboration Platform with Learning Analytics for a Dynamic Online Learning Environment System},
journal = {Lecture Notes in Networks and Systems},
author = {Soni, Priyanshi and Prajapat, Shaligram},
volume = {884 LNNS},
year = {2024},
pages = {82 - 110},
issn = {23673370},
address = {London, United kingdom},
abstract = {<div data-language="eng" data-ev-field="abstract">Growth of online learning and the need for interactions has increased globally and in India. The use of social media and online chat in educational environments became the backbone for this learning. Traditional classroom communication lacks freedom due to moderator control and time limitations. To support this, the Share Spell platform aims here as a secure, moderated communication model with a resource-sharing mechanism. It uses role-based access control to enhance information sharing and promote effective discussions in professional learning settings. Share Spell model here is for users to post and manage content within predefined categories, participate in discussions, and report inappropriate content, while administrators manage user access, categories, and reported content through a comprehensive dashboard. This work contributes to the development process of Massive online open courses for self-paced learners. The collaborative nature of MOOCs (Massive Open Online Courses), and ability to simulate professional environments to enhance communication and knowledge sharing among learners. The proposed model enhances learner performance, contributing to their success and growth using discussion forums. The prototype accommodates diverse learning styles, encourages professional behavior, and advanced analytics to continuously improve user experience and the effectiveness of knowledge sharing.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Adversarial machine learning},
keywords = {Collaborative learning;Contrastive Learning;Federated learning;},
note = {Collaboration platforms;Communication platforms;Content moderation;Engagement analysis;Environment systems;Knowledge-sharing;Online learning environment;Role-based Access Control;User engagement;User engagement analyze;},
URL = {http://dx.doi.org/10.1007/978-3-031-74443-3_5},
} 


@article{20241015698595 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics and the Universal Design for Learning (UDL): A clustering approach},
journal = {Computers and Education},
author = {Roski, Marvin and Sebastian, Ratan and Ewerth, Ralph and Hoppe, Anett and Nehring, Andreas},
volume = {214},
year = {2024},
issn = {03601315},
abstract = {<div data-language="eng" data-ev-field="abstract">In the context of inclusive education, Universal Design for Learning (UDL) is a framework used worldwide to create learning opportunities accessible to all learners. While much research focused on the design and students' perceptions of UDL-based learning settings, studies on students’ usage patterns in UDL-guided elements, particularly in digital environments, are still scarce. Therefore, we analyze and cluster the usage patterns of 9th and 10th graders in a web-based learning platform called I<inf>3</inf>Learn. The platform focuses on chemistry learning, and UDL principles guide its design. We collected the temporal usage patterns of UDL-guided elements of 384 learners in detailed log files. The collected data includes the time spent using video and/or text as a source of information, working on learning tasks with or without help and working on self-assessments. We used Exploratory Factor Analysis (EFA) to identify relevant factors in the observed usage behaviors. Based on the factor loadings, we extracted features for k-means clustering and named the resulting groups based on their usage patterns and learner characteristics. The EFA revealed four factors suggesting that learners remain consistent in selecting UDL-guided elements that require a decision (video or text, tasks with or without help). Based on these four factors, the cluster analysis identifies six different groups. We discuss these results as a starting point to provide individualized learning support through further artificial intelligence applications and inform educators about learner activity through a dashboard.<br/></div> © 2024 The Authors},
key = {Factor analysis},
keywords = {Cluster analysis;Computer aided instruction;Design;E-learning;K-means clustering;Students;Websites;},
note = {Clustering approach;Clusterings;Education inclusive education;Factors analysis;Inclusive education;Learning science;Universal Design;Usage patterns;Web-based learning science;Web-based-learning;},
URL = {http://dx.doi.org/10.1016/j.compedu.2024.105028},
} 


@inproceedings{20240215354717 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Methodology for the Participatory Design of a Learner-Facing Analytics Dashboard},
journal = {31st International Conference on Computers in Education, ICCE 2023 - Proceedings},
author = {Bourguet, Marie-Luce},
volume = {2},
year = {2023},
pages = {920 - 922},
address = {Matsue, Shimane, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">In this work-in-progress paper, we describe the participatory design approach we adopted for the inclusive design of a student-facing learning analytics dashboard. The objective is to involve learners throughout the design process to help prevent instructors’ biases ending up in the design. The design participants developed learner personas, use scenarios and storyboards to capture the broad spectrum of students' abilities, skills, objectives, and situations. These guided the decisions made for the essential features, functions, and interactive behaviours of the dashboard and for its initial functional implementation.<br/></div> © 2023 Asia-Pacific Society for Computers in Education.},
key = {Facings},
keywords = {Design;Students;},
note = {Broad spectrum;Dashboard;Design approaches;Design-process;Essential features;Feature function;Inclusive design;Learning analytic;Participatory design;Persona;},
} 


@inproceedings{20233514656937 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Operationalising Transparency as an Integral Value of Learning Analytics Systems – From Ethical and Data Protection to Technical Design Requirements},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Veljanova, Hristina and Barreiros, Carla and Gosch, Nicole and Staudegger, Elisabeth and Ebner, Martin and Lindstaedt, Stefanie},
volume = {14040 LNCS},
year = {2023},
pages = {546 - 562},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {<div data-language="eng" data-ev-field="abstract">With the rising complexity of technology and its introduction into educational settings, the question of trusting and designing trustworthy learning analytics (LA) systems has gained importance. Transparency is one of the values that can contribute to enhancing an LA system’s trustworthiness. It has been included and discussed as a separate core value or principle in many ethical frameworks for LA. Even though these frameworks provide valuable contributions, they are mostly limited to the conceptual level. Defining what transparency entails in the context of LA is an important aspect, nevertheless, the translation and operationalisation of such abstract concepts into technology should be equally considered. In this paper, we focus on the question of how transparency can be translated into concrete design requirements in order to enhance the trustworthiness of LA systems. We present a normative framework in the form of an interdisciplinary Criteria Catalogue for trustworthy LA, which consists of seven core areas, including transparency. Second, we demonstrate how transparency can be translated and operationalised into more specific and low-level elements by using an example of the Learners’ Corner LA dashboard developed within the project "Learning Analytics – Students in Focus". Third, we share the results of a study conducted to better understand students’ information needs in relation to LA tools and evaluate our design choices for the introduction of three quick information buttons within the Learners’ Corner.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Transparency},
keywords = {Ethical technology;Learning systems;Students;},
note = {Abstract concept;Analytics systems;Conceptual levels;Core values;Educational settings;Human-centered learning analytic;Integral values;Learning analytic;Technical design;Trustworthy learning analytic system;},
URL = {http://dx.doi.org/10.1007/978-3-031-34411-4_37},
} 


@inproceedings{20190306392517 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Evidence-based implementation of a learning analytics dashboard into an existing learning management system},
title = {Evidenzbasierte Implementation eines Learning Analytics Dashboards in ein bestehendes Lernmanagementsystem},
journal = {CEUR Workshop Proceedings},
author = {Schumacher, Clara and Klasen, Daniel and Ifenthaler, Dirk},
volume = {2250},
year = {2018},
issn = {16130073},
address = {Frankfurt, Germany},
abstract = {The interaction between learning analytics (LA) systems and students is usually realized via LA-dashboards. The LA-system LeAP is a Plug-In for the learning management platform ILIAS and was designed under consideration of pedagogical, information technological and data privacy perspectives. The featured LA-dashboard offers students an overview about their utilization of the course’s resources, the results of self-assessment tests, the option to decide about the usage of their data and a transparent insight into the stored personal information. A qualitative interview study showed that students particularly perceive the overview about learning objectives and progress, as well as self-assessments as supportive for their learning. The study also showed, that besides transparent data privacy, students request that their progress and behaviour within the learning environment must not influence their final grading. Future research and implementations will be on data analysis, implementing automatic prompts and how students interact with the feedback provided.<br/> © 2018 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {Computer aided instruction;Data privacy;Grading;Information management;},
note = {Evidence-based;Learning environments;Learning management system;Learning managements;Learning objectives;Personal information;Qualitative interviews;Self assessment;},
} 


@inproceedings{20231313819138 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {What do Teachers Want to Know About Game-Based Learning Analytics: Cross-Case Study},
journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
author = {Kim, Yoon Jeon and Scianna, Jennifer},
volume = {1},
year = {2022},
pages = {493 - 498},
address = {Kuala Lumpur, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">Game-based pedagogy requires innovation in learning analytics, so teachers can make sense of the complex data generated in the game in relation to evidence for learning. In this paper, we advocate for co-design as a process to elucidate the types of data that teachers want and need to effectively implement games in the classroom. We examine two cases to discuss affordances of co-design activities and present initial findings that built towards two prototypical dashboards.<br/></div> © 30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings.},
key = {Design},
keywords = {Computer games;Game design;},
note = {Affordances;Co-designs;Complex data;Cross-case studies;Design activity;Game-Based;Game-based Learning;Game-based learning analytic;Teacher dashboard;Teachers';},
} 


@inproceedings{20190406401394 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Implementation and evaluation of a trusted learning analytics dashboard},
journal = {CEUR Workshop Proceedings},
author = {Biedermann, Daniel and Schneider, Jan and Drachsler, Hendrik},
volume = {2294},
year = {2018},
issn = {16130073},
address = {Leeds, United kingdom},
abstract = {The research described in this article covers the user-facing components of a learning analytics environment which is developed with the premise of trust as an essential factor for the adoption of learning analytics. It investigates the influence of privacy settings and personalization on the acceptance and adoption of learning analytics. By ensuring compliance with data protection legislation, and by providing transparency in the means and results of data collection, we aim to reduce doubts and fears in the learning analytics process. By respecting the needs of individuals, we hope to create an environment where learning analytics is perceived as something positive.<br/> © 2018 CEUR-WS. All Rights Reserved.},
key = {Data privacy},
note = {Data collection;Personalizations;Privacy Settings;},
} 


@inproceedings{20250217651020 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Experimental Demonstration for Learning Analytics and Data Mining on e-assessment},
journal = {Lecture Notes in Networks and Systems},
author = {Bhurre, Shraddha and Prajapat, Shaligram and Raikwar, Sunny and Goswami, Prakshep and Kothari, Soham and khanuja, Gurpreet and Yadav, Kartikey and Choure, Purvi},
volume = {884 LNNS},
year = {2024},
pages = {720 - 741},
issn = {23673370},
address = {London, United kingdom},
abstract = {<div data-language="eng" data-ev-field="abstract">Every subject and course has a learning goal that we work towards during the teaching-learning process, whether it be online or offline. Under the current system, assignments, project analysis, semester exams, and internal exams are used to evaluate students’ learning. Several factors, including participation in class, prior knowledge, engagement time, activity logs, forum posts, understanding level, etc., influence how well students learn throughout a course or session. All these factors will be difficult to analyze in offline mode. All of these activities determine whether or not the learning objective is met. This study examines an experiment that provided blended learning data on students’ academic details, learning behaviors, and evaluation modules to determine the success of the two subjects. It discussed the details of each phase involved in the experiment. Students enrolled in integrated courses, MTech(PG-1) and MCA(PG-2) were analyzed in this study procedure through 4 weeks of offline classes. Moodle Gnomio was used for the online processes related to the Registration process, Quizzes, and discussion forums. A total of 6 quizzes for PG-1(M-Tech) and PG-2(MCA) were organized, and learning resources were provided before the exam. This study discusses detailed experiment setup, and Statistical analysis involving difficulty level of quizzes. This study proposed a framework for the dashboard that utilize this dataset and involves analysis related to student performance, grade distribution, inferring learning patterns, and course success.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Contrastive Learning},
keywords = {Active learning;Adversarial machine learning;Federated learning;Students;},
note = {Blended learning;Current system;E assessments;Experimental demonstrations;Learning analytic;Learning goals;Moodle;Offline;Online learning;Teaching-learning process;},
URL = {http://dx.doi.org/10.1007/978-3-031-74443-3_42},
} 


@inproceedings{20234314937199 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How Can Learning Analytics Enhance Online Teaching? A Teacher’s Perspective},
journal = {Lecture Notes in Business Information Processing},
author = {Rodda, Alena},
volume = {485 LNBIP},
year = {2023},
pages = {97 - 110},
issn = {18651348},
address = {Braga, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper examines the perspectives of teachers on the use of Learning Analytics (LA) to enhance online teaching in higher education institutions during the post-Covid era. The increasing shift towards online teaching as a result of the pandemic has presented a number of challenges for teachers. As online teaching is likely to remain a part of the higher education landscape, it is important to understand teachers’ views on the topic. This study explores how LA could support teachers in their online teaching. For this purpose, we conducted 18 interviews with instructors from German and Dutch universities about the changes that online teaching has led to, opportunities and threats of LA, the information teachers require about their students, and the ability of LA to enhance the advantages of online teaching and mitigate its disadvantages. Our results show that teachers’ opinions of LA are generally positive and that they would use LA if it were available in form of an intuitive and interactive dashboard. LA also offers the possibility to alleviate many of the problems in online teaching identified by the instructors.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {E-learning},
note = {E - learning;High educations;Higher education institutions;Learning analytic;Online teaching;Teachers';Teachers' views;},
URL = {http://dx.doi.org/10.1007/978-3-031-42788-6_7},
} 


@inproceedings{20181304937111 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {That dashboard looks nice, but what does it mean? towards making meaning explicit in learning analytics design},
journal = {ACM International Conference Proceeding Series},
author = {Gibson, Andrew and Martinez-Maldonado, Roberto},
year = {2017},
pages = {528 - 532},
address = {Brisbane, QLD, Australia},
abstract = {As learning analytics (LA) systems become more common, teachers and students are often required to not only make sense of the user interface (UI) elements of a system, but also to make meaning that is pedagogically appropriate to the learning context. However, we suggest that the dominant way of thinking about the relationship between representation and meaning results in an overemphasis on the UI, and that re-thinking this relationship is necessary to create systems that can facilitate deeper meaning making. We propose a conceptual view as a basis for discussion among the LA and HCI communities around a different way of thinking about meaning making, specifically that it should be explicit in the design process, provoking greater consideration of system level elements such as algorithms, data structures and information flow. We illustrate the application of the conceptualisation with two cases of LA design in the areas of Writing Analytics and Multi-modal Dashboards.<br/> © 2017 Association for Computing Machinery. All rights reserved.},
key = {User interfaces},
keywords = {Information systems;Design;Learning systems;},
note = {Conceptual views;Design process;Embodied cognition;Information flows;Learning analytics;Learning context;Meaning makings;User interface designs;},
URL = {http://dx.doi.org/10.1145/3152771.3156171},
} 


@inproceedings{20231013675735 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {"That Student Should be a Lion Tamer!" StressViz: Designing a Stress Analytics Dashboard for Teachers},
journal = {ACM International Conference Proceeding Series},
author = {Alfredo, Riordan Dervin and Nie, Lanbing and Kennedy, Paul and Power, Tamara and Hayes, Carolyn and Chen, Hui and McGregor, Carolyn and Swiecki, Zachari and Gaevic, Dragan and Martinez-Maldonado, Roberto},
year = {2023},
pages = {57 - 67},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">In recent years, there has been a growing interest in creating multimodal learning analytics (LA) systems that automatically analyse students' states that are hard to see with the "naked eye", such as cognitive load and stress levels, but that can considerably shape their learning experience. A rich body of research has focused on detecting such aspects by capturing bodily signals from students using wearables and computer vision. Yet, little work has aimed at designing end-user interfaces that visualise physiological data to support tasks deliberately designed for students to learn from stressful situations. This paper addresses this gap by designing a stress analytics dashboard that encodes students' physiological data into stress levels during different phases of an authentic team simulation in the context of nursing education. We conducted a qualitative study with teachers to understand (i) how they made sense of the stress analytics dashboard; (ii) the extent to which they trusted the dashboard in relation to students' cortisol data; and (iii) the potential adoption of this tool to communicate insights and aid teaching practices.<br/></div> © 2023 ACM.},
key = {Students},
keywords = {Cognitive systems;Human engineering;Psychophysiology;User interfaces;},
note = {Affective Computing;Analytics systems;Health care education;Learning analytic dashboard;Multi-modal dataset;Multi-modal learning;Physiological data;Stress detection;Stress levels;Teachers';},
URL = {http://dx.doi.org/10.1145/3576050.3576058},
} 


@inproceedings{20231413824972 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Poster: EduGraph: Dashboard for Personalised Feedback in Massive Open Online Courses},
journal = {Lecture Notes in Networks and Systems},
author = {Haarde, Fredrik and Khalil, Mohammad},
volume = {633 LNNS},
year = {2023},
pages = {790 - 795},
issn = {23673370},
address = {Vienna, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">This poster presents our work on exploring the data generated in an Open edX MOOC to understand how it can be analysed and used to impact learners’ motivation in online courses. The work presents the development of eduGraph, a learning analytics dashboard to disseminate insights about learners’ and their learning processes grounded in the self-regulated learning theory. Evaluations and conclusions are drawn thereafter.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Curricula},
keywords = {E-learning;},
note = {Dashboard;Learner's motivations;Learning analytic;Learning process;Learning Theory;Massive open online course;Online course;Personalized feedback;Self-regulated learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-26876-2_75},
} 


@article{20250517780724 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Task-value motivational prompts in a descriptive dashboard can increase anxiety among anxious learners},
journal = {Computers and Education},
author = {Valle, Natercia and Antonenko, Pavlo and Valle, Denis and Baiser, Benjamin},
volume = {229},
year = {2025},
issn = {03601315},
abstract = {<div data-language="eng" data-ev-field="abstract">Despite the ubiquitous use of learning analytics dashboards in computer-mediated learning environments, there is still a knowledge gap on how these tools can support learners’ academic performance and motivation. This article describes an experimental study that investigated the influence of motivational prompts (task-value scaffolding) in a descriptive learning analytics dashboard on learners’ motivation, statistics anxiety, and learning performance in an authentic semester-long online statistics course. The study was based on a two-group experimental design during two semesters (Fall 2020 and Spring 2021). A total of 122 graduate students completed the study. The results showed that despite learners’ mostly positive perceptions of the dashboard, the use of motivational prompts did not influence learners’ cognitive outcomes. Test anxiety was the only affective outcome influenced by the intervention, with motivational prompts having a negative effect on learners who started the course with a higher level of test anxiety. This study provides needed empirical evidence on how the design of these tools can influence learners’ affective outcomes, with implications for theory and practice. However, additional experimental studies that account for sources of heterogeneity (e.g., intrapersonal characteristics, contextual factors) are necessary to uncover theoretical gaps and opportunities in the design of effective learning analytics dashboards.<br/></div> © 2025 Elsevier Ltd},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;},
note = {Application in education;Computer-mediated learning environments;Data science application in education;Distance education and online learning;Human computer interfaces;Knowledge gaps;Online learning;Pedagogical issues;Postsecondary education;Science applications;},
URL = {http://dx.doi.org/10.1016/j.compedu.2025.105242},
} 


@inproceedings{20221311866869 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Proposal for the Design and Implementation of a XBlock in Open edX to Support Learning Analytics},
journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
author = {Campoberde, Jonnathan and Macias, Miguel A. and Maldonado-Mahauad, Jorge},
year = {2021},
pages = {498 - 501},
address = {Arequipa, Peru},
abstract = {<div data-language="eng" data-ev-field="abstract">Nowadays, when users using information systems, they generate a large amount of data leaving behind a trace as a result of their interaction, e.g., when students access educational materials on Virtual Learning Environments (VLE). This has developed into what we now know as Massive Open Online Courses (MOOCs), which have millions of registered students. Due to the large amount of data that is generated within these MOOCs, Learning Analytics (LA) has emerged as an alternative to improve teaching and learning processes through data analysis. Open edX in an attempt to incorporate Learning Analytics into its Insights development platform, which provides very simple visualizations. Likewise, other projects have been added, which over time have become obsolete or do not provide sufficient support to improve the learning process of students. Therefore, this study proposes the design, development, and evaluation of a learning analytics dashboard for the Open edX platform. The tool will incorporate indicators of student success in its visualizations to improve the learning process within the platform.<br/></div> © 2021 IEEE.},
key = {Students},
keywords = {Information systems;Visualization;Information use;Learning systems;Computer aided instruction;},
note = {Dashboard;Design and implementations;Large amounts of data;Learning analytic;Learning process;Massive open online course;Open edx;Student success;Support learning;Xblock;},
URL = {http://dx.doi.org/10.1109/LACLO54177.2021.00088},
} 


@article{20232714340703 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a Multimodal Classroom Engagement Analysis Dashboard for Higher-Education},
journal = {Proceedings of the ACM on Human-Computer Interaction},
author = {Sabuncuoglu, Alpay and Sezgin, T. Metin},
volume = {7},
number = {EICS},
year = {2023},
issn = {25730142},
abstract = {<div data-language="eng" data-ev-field="abstract">Developing learning analytics dashboards (LADs) is a growing research interest as online learning tools have become more accessible in K-12 and higher education settings. This paper reports our multimodal classroom engagement data analysis and dashboard design process and the resulting engagement dashboard. Our work stems from the importance of monitoring classroom engagement, which refers to students' active physical and cognitive involvement in learning that influences their motivation and success in a given course. To monitor this vital facade of learning, we developed an engagement dashboard using an iterative and user-centered process. We first created a multimodal machine learning model that utilizes face and pose features obtained from recent deep learning models. Then, we created a dashboard where users can view their engagement over time and discover their learning/teaching patterns. Finally, we conducted user studies with undergraduate and graduate-level participants to obtain feedback on our dashboard design. Our paper makes three contributions by (1) presenting a student-centric, open-source dashboard, (2) demonstrating a baseline architecture for engagement analysis using our open-Access data, and (3) presenting user insights and design takeaways to inspire future LADs. We expect our research to guide the development of tools for novice teacher education, student self-evaluation, and engagement evaluation in crowded classrooms.<br/></div> © 2023 ACM.},
key = {Students},
keywords = {Data handling;Deep learning;Education computing;Information analysis;Learning systems;Modal analysis;},
note = {Classroom engagement;Engagement analysis;Interactive learning;Interactive learning analytic dashboard;Learning dataset;Multi-modal;Multi-modal learning;Multimodal data analyse pipeline;Multimodal data analysis;Multimodal learning dataset;},
URL = {http://dx.doi.org/10.1145/3593240},
} 


@inproceedings{20184806167356 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Gamification and learning analytics to improve engagement in university courses},
journal = {Advances in Intelligent Systems and Computing},
author = {Cassano, Fabio and Piccinno, Antonio and Roselli, Teresa and Rossano, Veronica},
volume = {804},
year = {2019},
pages = {156 - 163},
issn = {21945357},
address = {Toledo, Spain},
abstract = {Gamification is one of the most used techniques to improve active participation and engagement in different kinds of contexts. The use of game techniques is effective in pushing subjects to be involved in an activity. Since the early childhood, indeed, the promises of rewards are useful to affect specific behaviors. On the other hands, the learning analytics have been largely implemented in education in order to improve the assessment and the self-assessment of students, above all in e-learning settings. The research presented in this work aims at combining gamification techniques and learning analytics to improve the engagement in University courses. The paper describes a model of gamification and a learning dashboard defined based on data in Moodle e-learning platform. A pilot test of an app android in which both the solutions have been implemented pointed out promising results.<br/> © Springer Nature Switzerland AG 2019.},
key = {E-learning},
keywords = {Education computing;Learning systems;},
note = {E-learning platforms;Early childhoods;Learning analytics;Learning dashboard;Pilot tests;Self assessment;University course;},
URL = {http://dx.doi.org/10.1007/978-3-319-98872-6_19},
} 


@inproceedings{20200208022048 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Beyond just following data: How does visualization strategy facilitate learning analytics design?},
journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
author = {Cao, Jiaxin and Song, Yanjie},
volume = {1},
year = {2019},
pages = {372 - 374},
address = {Kenting, Taiwan},
abstract = {In this poster, we reviewed 38 articles on learning analytics research, focusing on the data visualization interface designs. After examining the original ideas their interface design, a new visualization strategy was proposed to categorize and characterize them premised on their principles and approaches in four types, namely, (1) directly-presented, (2) outcome-oriented, (3) process-oriented, and (4) theory-oriented. Then, how these types of the visualization strategy could help facilitate learning analytics design and make data interpretable by users was presented.<br/> © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
key = {Data visualization},
keywords = {Visualization;},
note = {Design Principles;Interface designs;Learning analytics;Learning dashboard;Process-oriented;},
} 


@inproceedings{20232014107385 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {FLAIEC 2022 - Proceedings of the 1st Finnish Learning Analytics and Artificial Intelligence in Education Conference},
journal = {CEUR Workshop Proceedings},
volume = {3383},
year = {2022},
issn = {16130073},
address = {Joensuu, Finland},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 11 papers. The topics discussed include: what are they telling us? accessible analysis of free text data from a national survey of higher education students; learning analytics in Moroccan higher education: justifications for use and challenges for successful implementation; how social interactions kindle productive online problem based learning: an exploratory study of the temporal dynamics; a chatbot-guided learning experience in the inquiry science classroom; using an automated learning analytics dashboard to capture sentiment in academic asynchronous online discussions; flipped online approach with learning analytics for supporting higher education students’ learning. course feedback results; and implementing learning analytics into teaching in higher education: teachers’ perceptions.<br/></div>},
} 


@inproceedings{20223512673235 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Enabled Virtual Reality Content Creation Platform: System Design and Preliminary Evaluation},
journal = {Proceedings - 2022 International Conference on Advanced Learning Technologies, ICALT 2022},
author = {Wang, Zuo and Tzi Dong Ng, Jeremy and Liu, Ruilun and Hu, Xiao},
year = {2022},
pages = {161 - 163},
address = {Bucharest, Romania},
abstract = {<div data-language="eng" data-ev-field="abstract">Due to the popularity of virtual reality (VR) in education settings and the rise of maker education, this paper presents LAVR, a platform for VR content creation with learning analytics functions. We design the platform where students can easily create VR stories through a web interface. A learning analytics dashboard is implemented to provide students with feedback on their progress and the quality of the textual content in their VR stories. The platform also offers learning management features for helping teachers set up classrooms with assignments. While the platform will be employed in a forthcoming general education course, we have conducted a preliminary usability evaluation with 12 students and one teacher, and gathered feedback for further refinements before its official launch. The platform will contribute to integrating learning analytics with maker activities.<br/></div> © 2022 IEEE.},
key = {Virtual reality},
keywords = {E-learning;Students;},
note = {Analytic functions;Content creation;Learning analytic;Maker education;Platform design;Platform systems;Teachers';Textual content;Virtual reality content creation;Web interface;},
URL = {http://dx.doi.org/10.1109/ICALT55010.2022.00055},
} 


@inproceedings{20224212974750 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {InDash: An Interactions Dashboard to Analyze Moodle Logs},
journal = {CEUR Workshop Proceedings},
author = {Nwachukwu, Uchendu and Hernandez-Garcia, angel and Cuenca-Enrique, Carlos and Del-Rio-Carazo, Laura},
volume = {3238},
year = {2022},
pages = {18 - 25},
issn = {16130073},
address = {Salamanca, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">This study presents InDash, a learning analytics web service and web application dashboard to collect, analyze and visualize Moodle log data in the form of interaction categories. The document provides an overview of learning analytics applications and data collection processes in learning analytics, with an emphasis on log-based learning analytics indicators. To showcase the use and application of InDash, we propose an example categorization of indicators, based on different learning cycle theories, and we detail the main components of the system: a web service that exposes Moodle log for data collection, and the web application for data categorization, analysis and visualization.<br/></div> © 2022 Copyright for this paper by its authors.},
key = {Data visualization},
keywords = {Data acquisition;Learning systems;Visualization;Web services;Websites;},
note = {Dashboard;Data extraction;Descriptive analytic;Learning analytic;Log;Log data;Moodle;WEB application;Web applications;Web service applications;},
} 


@inproceedings{20232414221725 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How Can We Co-design Learning Analytics for Game-Based Assessment: ENA Analysis},
journal = {Communications in Computer and Information Science},
author = {Kim, Yoon Jeon and Scianna, Jennifer and Knowles, Mariah A.},
volume = {1785 CCIS},
year = {2023},
pages = {214 - 226},
issn = {18650929},
address = {Copenhagen, Denmark},
abstract = {<div data-language="eng" data-ev-field="abstract">The broader education research community has adopted co-design, or participatory design, as a method to increase adoption of innovations in classrooms and to support professional learning of teachers. However, it can be challenging, due to co-design’s dynamic nature, to closely investigate how the co-process played out over time, and how it led to changes in teachers’ perceptions, beliefs, and/or practices. Applying Quantitative Ethnography, we investigate how teachers and researchers collaboratively designed assessment metrics and data visualizations for an educational math game; we discuss the interactions among the co-design activities, teachers’ learning, and qualities of the dashboard created as the output of the process.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Data visualization},
keywords = {Design;Game design;Visualization;},
note = {Co-designs;Design learning;Education research;ENA;Game-Based;Game-based assessment;Human-centered learning analytic;Professional learning;Teacher professional learning;Teachers';},
URL = {http://dx.doi.org/10.1007/978-3-031-31726-2_15},
} 


@inproceedings{20183605769545 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating learning analytics in an educational game to provide players with information about how to improve their performance},
journal = {Proceedings - IEEE 18th International Conference on Advanced Learning Technologies, ICALT 2018},
author = {Seaton, Jennifer and Graf, Sabine and Chang, Maiga and Farhmand, Arta},
year = {2018},
pages = {229 - 230},
address = {Bombay, India},
abstract = {Educational games aim to balance learning and playing. However, for people to benefit from an educational game, they must be encouraged to play the game often. Providing players with information about how to improve their performance could help in achieving this goal. This paper examines how a learning analytics dashboard can be incorporated into an educational game to encourage players to play more often and continuously. The proposed dashboard provides players with a variety of information such as how their performance and skills change over time. Such information allows players to see their performance and play habits, and find strategies on how to improve their performance, and therefore their learning, in the game.<br/> © 2018 IEEE.},
note = {Dashboard;Educational game;Learning analytics;Metacognitive skills;},
URL = {http://dx.doi.org/10.1109/ICALT.2018.00121},
} 


@inproceedings{20233914787848 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LA-ReflecT: A Platform Facilitating Micro-learning and Its Multimodal Learning Analytics},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Majumdar, Rwitajit and Prasad, Prajish and Kadam, Kapil and Gatare, Kinnari and Warriem, Jayakrishnan Madathil},
volume = {14200 LNCS},
year = {2023},
pages = {731 - 735},
issn = {03029743},
address = {Aveiro, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">The interactive demo highlights LA-ReflecT, an LTI-enabled platform that facilitates the creation of micro-learning activities with multimedia content, and helps track interactions and artefacts created by students within the platform as xAPI logs. The platform facilitates reflection on action in the form of presenting information on a dashboard as a part of the learning activity. LA-ReflecT also enables an app connecting with Bluetooth sensors that stream time series signals. The sensor data from a user is synchronized with their particular activity and can be linked to their learning log. We are doing multiple pilots with research partners in Japan and India. We are open to discussing adaptors who want to potentially pilot LA-ReflecT for creating microlearning material and investigating the potential of the data logged in the platform.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
note = {Bluetooth sensors;Lareflect;Learning Activity;Micro-learning;Multi-modal learning;Multimedia contents;Multimodal learning analytic;Presenting informations;Stream time series;Time series signals;},
URL = {http://dx.doi.org/10.1007/978-3-031-42682-7_69},
} 


@article{20162902605649 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluation of a Data-To-Text System for Verbalizing a Learning Analytics Dashboard},
journal = {International Journal of Intelligent Systems},
author = {Ramos-Soto, Alejandro and Vazquez-Barreiros, Borja and Bugarin, Alberto and Gewerc, Adriana and Barro, Senen},
volume = {32},
number = {2},
year = {2017},
pages = {177 - 193},
issn = {08848173},
abstract = {The SoftLearn Activity Reporter is a data-to-text service, which automatically generates textual reports about the activity developed by students within the SoftLearn virtual learning environment. In this paper, we describe the conception of the service, its architecture, and its subsequent evaluation by an expert pedagogue, where 20 full reports generated from real data from an undergraduate course supported by the SoftLearn platform were assessed. Results show that the automatically generated reports are a valuable complementary tool for explaining teachers and students the information comprised in a learning analytics dashboard.<br/> © 2016 Wiley Periodicals, Inc.},
key = {Computer aided instruction},
keywords = {Teaching;},
note = {Automatically generated;Complementary tools;ITS architecture;Undergraduate Courses;Virtual learning environments;},
URL = {http://dx.doi.org/10.1002/int.21835},
} 


@inbook{20215011316105 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Machine Learning for Learning Analytics for Meta-cognitive Support},
journal = {Smart Innovation, Systems and Technologies},
author = {Kommers, Piet},
volume = {261},
year = {2022},
pages = {205 - 217},
issn = {21903018},
abstract = {<div data-language="eng" data-ev-field="abstract">The motivation for this chapter is to show the evolutionary nature from earlier student tracking and 'intelligent tutoring systems' until the current stages of advanced learning analytics. This chapter's added value is its illustration of how learning analytics contributes to learners’ meta-cognitive awareness and how indirectly a teachers’ 'dashboard' allows teachers, parents, and remedial teachers to trace the more subtle cognitive entailments in the student’s mind. The sources for the chosen direction rest upon earlier research into media-support for conceptual learning. This chapter may elicit the discussion on how far technology-driven innovations can bypass the existing repertoire of earlier didactic solutions.<br/></div> © 2022, Springer Nature Switzerland AG.},
key = {Big data},
keywords = {Data mining;Deep learning;Learning systems;Computer aided instruction;},
note = {Cognitive support;Conceptual representation;Deep learning and data mining;Didactic paradigm;Learning analytic;Machine-learning;Meta cognitions;Metacognitives;Student tracking;Teachers';},
URL = {http://dx.doi.org/10.1007/978-3-030-86316-6_10},
} 


@inproceedings{20222112152106 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Understand the influence of learning analytics dashboards on learner self-regulation and academic success},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
volume = {2022-March},
year = {2022},
pages = {1044 - 1047},
issn = {21659559},
address = {Tunis, Tunisia},
abstract = {<div data-language="eng" data-ev-field="abstract">Since the beginning of the COVID-19 pandemic, many countries have adopted online education as an alternative to face-to-face courses. This has increased awareness of the importance of analyzing learning data left by students to improve and evaluate the learning process. This article presents a new tool, named TaBAT, created to work with different LMSs in the form of dashboards accessible online and allowing teachers to monitor the progress of their learners and at the same time and allow teachers to track the progress of their learners, while allowing learners to develop self-regulation skills and visualize their learning process. The results of a study conducted show that TaBAT helped learners to increase their progress and spend more time in the online course.<br/></div> © 2022 IEEE.},
key = {Deregulation},
keywords = {E-learning;Learning systems;},
note = {Face to face;Learning analytic;Learning data;Learning experiences;Learning process;On-line education;Online course;Self regulation;Self-regulated dashboard;Teachers';},
URL = {http://dx.doi.org/10.1109/EDUCON52537.2022.9766741},
} 


@inproceedings{20200107970186 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancing international virtual collaborative learning with social learning analytics},
journal = {2019 2nd International Conference on New Trends in Computing Sciences, ICTCS 2019 - Proceedings},
author = {Clauss, Alexander and Lenk, Florian and Schoop, Eric},
year = {2019},
address = {Amman, Jordan},
abstract = {The ability to work collaboratively in intercultural virtual teams, is constantly gaining importance for the labour market. Virtual Mobility enables students to acquire the necessary intercultural teamwork skills while remaining locally integrated into their regular studies. But still, international virtual collaborative learning scenarios demand much time and effort for planning and coordination which binds resources. The support concepts for such collaborative virtual learning groups are also resource-intensive, because learners should be accompanied by qualified e-Tutors to optimise learning results both at individual and group level. Classical summative tests and exams are rather unsuitable for the assessment of collaboration as expected learning outcome. These arrangements also need new formative assessment forms, as participants need active and ongoing feedback. A meaningful assessment of learning processes and outcomes should not only be based on the observation of 'soft' factors but should also be complemented by 'hard', fixed, automatically measurable, quantitative indicators. To gain these hard indicators the research project ISLA-Indicator-based Social Learning Analytics was launched. This paper presents the procedure for implementation as well as virtual presence, content creation and relationships within the community as first derived indicators and their prototypical visualisation in a Learning Analytics Dashboard.<br/> © 2019 IEEE.},
key = {Students},
keywords = {Employment;E-learning;},
note = {Collaborative learning;Collaborative virtual learning;Expected learning outcomes;Learning Analytics Dashboard;Quantitative indicators;Social learning;Virtual collaborative learning;Virtual mobility;},
URL = {http://dx.doi.org/10.1109/ICTCS.2019.8923106},
} 


@inproceedings{20224212974759 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LASI Spain 2022 - Proceedings of the Learning Analytics Summer Institute Spain 2022},
journal = {CEUR Workshop Proceedings},
volume = {3238},
year = {2022},
issn = {16130073},
address = {Salamanca, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 10 papers. The topics discussed include: content-validation questionnaire of a meta-model to ease the learning of data visualization concepts; exploring the synergies between gamification and data collection in higher education; InDash: an interactions dashboard to analyze Moodle logs; a proposal for predicting and intervening on MOOC learners’ performance in real time; data mashups privacy preservation for learning analytics; unplugged institutions: towards a localization of the cloud for learning analytics privacy enhancement; using process mining to determine the relevance and impact of performing optional quizzes before evaluative assessments; human context in sentiment analysis symbolic technique; a proposal to measure the understanding of data visualization elements in visual analytics applications; and analyzing collaborative filtering for UNED freshman enrolment recommendation system.<br/></div>},
} 


@inproceedings{20221311866894 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Systematic Mapping of Moodle Dashboards Focused on Learning Analytics Tasks},
journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
author = {Centenaro, Belisa and Cechinel, Cristian and Ramos, Vinicius and Primo, Tiago and Munoz, Roberto},
year = {2021},
pages = {60 - 66},
address = {Arequipa, Peru},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards are useful tools for presenting data visually. This work presents a systematic mapping study of publications from 2010 to 2020 (May) about Learning Analytics and visualization tools for Moodle. A total of 238 papers were collected from Scopus, Web of Science, and CAPES Portal. From those, 51 were selected to be analyzed according to a seven dimension model involving the following criteria: data sources; goals of analysis; stakeholders; research approach; maturity of the tool; ethical issues; and specificities of the tool. The analysis showed that most of the tools are developed to be used by the teachers, and that the most frequent goal of the tools is to allow the comparison of students' metrics. Moreover, the analysis also showed a huge amount of papers proposing (still not developed) tools focused on prediction and intervention, thus indicating a growing interest in this topic. At last, it was also observed a lack of information available regarding ethical issues over the collection, processing and storage of personal information by the existing LAD.<br/></div> © 2021 IEEE.},
key = {Data visualization},
keywords = {Digital storage;Educational technology;Ethical technology;Mapping;Visualization;},
note = {Analytic tools;Data-source;Ethical issues;Learning analytic dashboard;Moodle plugin;Plug-ins;Systematic mapping;Systematic mapping studies;Visualization tools;Web of Science;},
URL = {http://dx.doi.org/10.1109/LACLO54177.2021.00013},
} 


@inproceedings{20224413041166 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {What Indicators Can I Serve You with? An Evaluation of a Research-Driven Learning Analytics Indicator Repository},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Ahmad, Atezaz and Schneider, Jan and Weidlich, Joshua and Di Mitri, Daniele and Yau, Jane Yin-Kim and Schiffner, Daniel and Drachsler, Hendrik},
volume = {1},
year = {2022},
pages = {58 - 68},
issn = {21845026},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">In recent years, Learning Analytics (LA) has become a very heterogeneous research field due to the diversity in the data generated by the Learning Management Systems (LMS) as well as the researchers in a variety of disciplines, who analyze this data from a range of perspectives. In this paper, we present the evaluation of a LA tool that helps course designers, teachers, students and educational researchers to make informed decisions about the selection of learning activities and LA indicators for their course design or LA dashboard. The aim of this paper is to present Open Learning Analytics Indicator Repository (OpenLAIR) and provide a first evaluation with key stakeholders (N=41). Moreover, it presents the results of the prevalence of indicators that have been used over the past ten years in LA. Our results show that OpenLAIR can support course designers in designing LA-based learning activities and courses. Furthermore, we found a significant difference between the relevance and usage of LA indicators between educators and learners. The top rated LA indicators by researchers and educators were not perceived as equally important from students' perspectives.<br/></div> Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
key = {Curricula},
keywords = {E-learning;Information management;},
note = {Analytic tools;Evidence based researches;Learning Activity;Learning analytic;Learning event;Learning management system;Metric;Open learning;Research fields;Research-driven;},
URL = {http://dx.doi.org/10.5220/0010995800003182},
} 


@inproceedings{20231013675759 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Dashboard to Provide Instructors with Automated Feedback on Students' Peer Review Comments},
journal = {ACM International Conference Proceeding Series},
author = {Dood, Amber and Das, Kapotaksha and Qian, Zhen and Finkenstaedt-Quinn, Solaire and Gere, Anne and Shultz, Ginger},
year = {2023},
pages = {619 - 625},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Writing-to-Learn (WTL) is an evidence-based instructional practice which can help students construct knowledge across many disciplines. Though it is known to be an effective practice, many instructors do not implement WTL in their courses due to time constraints and inability to provide students with personalized feedback. One way to address this is to include peer review, which allows students to receive feedback on their writing and benefits them as they act as reviewers. To further ease the implementation of peer review and provide instructors with feedback on their students' work, we labeled students' peer review comments across courses for type of feedback provided and trained a machine learning model to automatically classify those comments, improving upon models reported in prior work. We then created a dashboard which takes students' comments, labels the comments using the model, and allows instructors to filter through their students' comments based on how the model labels the comments. This dashboard can be used by instructors to monitor the peer review collaborations occurring in their courses. The dashboard will allow them to efficiently use information provided by peers to identify common issues in their students' writing and better evaluate the quality of their students' peer review.<br/></div> © 2023 ACM.},
key = {Students},
keywords = {Machine learning;},
note = {Automated feedback;Effective practices;Evidence-based;Instructional practices;Instructor dashboard;Machine-learning;Peer review;Personalized feedback;Time constraints;Writing to learn;},
URL = {http://dx.doi.org/10.1145/3576050.3576087},
} 


@inproceedings{20230213355199 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Examining the Effectiveness of Self-Referenced and Peer-Referenced Learning Analytics Dashboards in Enhancing Students' Self-efficacy: Taking Individual Differences into Account},
journal = {Proceedings of International Conference of the Learning Sciences, ICLS},
author = {Jonathan, Christin and Koh, Elizabeth and Tan, Jennifer Pei-Ling},
year = {2022},
pages = {250 - 257},
issn = {18149316},
address = {Virtual, Online, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">This study examined the effectiveness of self-referenced and peer-referenced learning analytics (LA) dashboards in enhancing students' self-efficacy in critical reading, taking individual differences into account. A quasi-experiment with an embedded mixed methods approach was used, with 209 Grade 9 students who participated in critical reading online discussions in the English Language (EL) subject during a nine-week trial. Multiple regression analysis revealed that individual differences, namely, learning goals, performance goals, and gender, were significant predictors of critical reading self-efficacy, whereas dashboard type and initial achievement levels were not. Epistemic network analysis highlighted the importance of students' perceptions of how helpful and motivating they found the dashboards to be. Put together, the results highlight the theoretical and methodological importance of taking individual differences into account and have practical implications for designing more purposeful formative LA dashboards for enhancing students' self-efficacy.<br/></div> © ISLS.},
key = {Students},
keywords = {E-learning;Regression analysis;},
note = {English languages;Individual Differences;Learning goals;Mixed method;Multiple regression analysis;Online discussions;Performance;Quasi-experiments;Self efficacy;Student perceptions;},
} 


@inproceedings{20221111797022 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Needs Analysis and Prototype Evaluation of Student-facing la Dashboard for Virtual Reality Content Creation},
journal = {ACM International Conference Proceeding Series},
author = {Tzi-Dong Ng, Jeremy and Wang, Zuo and Hu, Xiao},
year = {2022},
pages = {444 - 450},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Being a promising constructionist pedagogy in recent years, maker education empowers students to take agency of their learning process through constructing both knowledge and real-world physical or digital products and fosters peer interactions for collective innovation. Learning Analytics (LA) excels at generating personalized, fine-grained feedback in near real-time and holds much potential in supporting process-oriented and peer-supported learning activities, including maker activities. In the context of virtual reality (VR) content creation for cultural heritage education, this study qualitatively solicited 27 students' needs on progress monitoring, reflection, and feedback during their making process. Findings have inspired the prototype design of a student-facing LA dashboard (LAVR). Leveraging multimodal learning analytics (MmLA) such as text and audio analytics to fulfill students' needs, the prototype has various features and functions including automatic task reminders, content quality detection, and real-time feedback on quality of audio-visual elements. A preliminary evaluation of the prototype with 10 students confirms its potential in supporting students' self-regulated learning during the making process and for improving the quality of VR content. Implications on LA design for supporting maker education are discussed. Future work is planned to include implementation and evaluation of the dashboard in classrooms.<br/></div> © 2022 ACM.},
key = {Students},
keywords = {Learning systems;Facings;Quality control;User interfaces;Virtual reality;},
note = {Content creation;Dashboard;Digital products;Learning process;Making process;Need analysis;Physical products;Prototype evaluation;Real-world;Virtual reality content creation;},
URL = {http://dx.doi.org/10.1145/3506860.3506880},
} 


@unpublished{20220428438 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Aligning Learners’ Expectations and Performance by Learning Analytics System with a Predictive Model},
journal = {arXiv},
author = {Brdnik, Saa and umak, Bostjan and Podgorelec, Vili},
year = {2022},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics (LA) is data collection, analysis, and representation of data about learners in order to improve their learning and performance. Furthermore, LA opens the door to opportunities for self-regulated learning in higher education, a circular process in which learners activate and sustain behaviors that are systematically oriented toward their personal learning goals. The potentials of LA and self-regulated learning are huge; however, they are not yet widely applied in higher education institutions. Slovenian higher education institutions have lagged behind other European countries in LA adoption. Our research aims to fill this gap by using a qualitatively and quantitatively led workflow for building requirement-oriented LA solution, consisting of empirically gathering the students’ expectations of LA and presenting a dashboard solution. Translated Student Expectations of Learning Analytics Questionnaire (SELAQ) and focus groups were used to gather expectations from learners. Based on this data, a user interface utilizing learning analytics and grade prediction with an artificial intelligence model was implemented for a selected course. The interface includes early grade prediction, peer comparison, and historical data overview. Early grade prediction is based on a machine learning model built on users’ interaction in the virtual learning environment, demographic data and their lab grades. First, classification is used to determine students at risk of failing - its precision is reaching 98% after the first month of the course. Second, the exact grade is predicted with the Decision Tree Regressor, which reaches a mean absolute error of 11.2grade points (on a 100 points scale) after the first month. The proposed system is designed for students - its main benefit is the support for self-regulation of the learning process during the semester, possibly motivating students to adjust their learning strategies to prevent failing the course. Initial student evaluation of the system showed positive results.<br/></div> © 2022, CC BY-NC-SA.},
key = {Students},
keywords = {Artificial intelligence;Computer aided instruction;Decision trees;Education computing;Learning systems;Predictive analytics;User interfaces;},
note = {Academic success prediction;Analytics systems;Explainable artificial intelligence;Grade predictions;Higher education institutions;Learning analytic;Performance;Predictive models;Self-regulated learning;Student expectations;},
URL = {http://dx.doi.org/10.48550/arXiv.2211.07729},
} 


@inproceedings{20225013255523 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics to support teachers in the challenge of overcoming the learning gaps in k-12 students},
journal = {CEUR Workshop Proceedings},
author = {de Sousa, Erverson B.G. and Mello, Rafael Ferreira},
volume = {3292},
year = {2022},
pages = {5 - 11},
issn = {16130073},
address = {Toulouse, France},
abstract = {<div data-language="eng" data-ev-field="abstract">The emergency remote teaching caused by the covid-19 pandemic has potentiated the learning gaps of several students in Brazilian education, especially in the K-12 settings. Amidst the many challenges imposed by the pandemic, the adoption of digital tools in the school context has provided the generation of educational data, which can be collected and analyzed in order to provide evidence-based decision making, taking into account all the stakeholders in the teaching and learning process. Such decisions can provide for the personalization of learning, which aims to provide the student with educational resources that promote the building of weakened skills caused by learning gaps. The present thesis plan aims to present the work plan for the development of a Learning Analytics Dashboard tool for teachers in a basic education school in order to support data-driven pedagogical decision-making and to enable personalized monitoring of learning.<br/></div> © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
key = {Students},
keywords = {Decision making;Digital devices;},
note = {Decisions makings;Digital tools;Evidence- based decisions;K-12 student;Learning analytic;Learning gap;Personalized learning;Remote teaching;School context;Teachers';},
} 


@inproceedings{20165203180456 ,
language = {Portuguese},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Moodle analytics dashboard: A learning analytics tool to visualize users interactions in moodle},
journal = {Proceedings - 2016 11th Latin American Conference on Learning Objects and Technology, LACLO 2016},
author = {Einhardt, Luan and Tavares, Tatiana Aires and Cechinel, Cristian},
year = {2016},
address = {San Carlos, Costa rica},
abstract = {The present work describes the Moodle Analytics Dashboard (MAD), a tool developed to allow the visualization of students and professors logs in Moodle disciplines. MAD provides an easy way to obtain graphical visualization of several aspects related to students and professors accesses in virtual learning disciplines, thus helping professors to better follow teaching and learning process, as well as to visually identify potential at-risk students, or to better understand how the different educational resources are being used. The paper presents the theoretical foundations and the technologies used to develop MAD, together with the most important features of the tool and the first results obtained during the preliminary stages of validation.<br/> © 2016 IEEE.},
key = {Visualization},
keywords = {Students;},
note = {Dashboards;Educational resource;Graphical visualization;Learning analytics;Logs;Moodle;Teaching and learning;Theoretical foundations;},
URL = {http://dx.doi.org/10.1109/LACLO.2016.7751805},
} 


@inproceedings{20223812759980 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Design a Dashboard for Secondary School Learners to Support Mastery Learning in a Gamified Learning Environment},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hou, Xinying and Nagashima, Tomohiro and Aleven, Vincent},
volume = {13450 LNCS},
year = {2022},
pages = {542 - 549},
issn = {03029743},
address = {Toulouse, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Although prior studies have shown the benefits of using learning analytics dashboards (LADs) in non-gamified contexts in higher education, few have focused on pre-college users and gamified learning environments. In this paper, we present the design of Gwynnette Dashboard, an interactive student-facing LAD for secondary school learners that aims at promoting mastery learning in a gamified intelligent tutoring system. It contains three main components: a planet chart with two control buttons, a connected skill progress bar with a skill mastery growth line, and an overall mastery progress bar. We also report two user-centered design changes after validating our design with 18 students iteratively. Our preliminary evaluation of a fully-developed version with 2 students revealed that this dashboard with linked representations of skill mastery status and skill growth was easy for learners to understand and motivated learners to use it to regulate learning. Our future work will focus on broader classroom studies to experimentally investigate the effectiveness of this dashboard to foster mastery learning and growth mindset.<br/></div> © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Students},
keywords = {Computer aided instruction;Education computing;Learning systems;User centered design;},
note = {Control buttons;Gamification;High educations;Intelligent tutoring;Learning analytic dashboard;Learning environments;Mastery learning;Pre-college;Secondary schools;Tutoring system;},
URL = {http://dx.doi.org/10.1007/978-3-031-16290-9_48},
} 


@inproceedings{20190906565220 ,
language = {French},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Participatory design of learning analytics dashboards},
title = {Conception participative de tableaux de bord d'apprentissage},
journal = {IHM 2018 - Actes de la 30ieme Conference Francophone sur l''Interaction Homme-Machine},
author = {Gilliot, Jean-Marie and Iksal, Sebastien and Medou, Daniel Magloire and Dabbebi, Ines},
year = {2018},
pages = {119 - 127},
address = {Brest, France},
abstract = {While the field of Learning Analytics is in full development, potential users are just discovering the opportunities offered by these tools. One of the major difficulties consists in proposing a visual data representation which makes sense to the users. After refining our method to identify user needs in terms of visualization, and to define the main dimensions of a learning dashboard, we propose a tool to support participatory design. This tool is based on a canvas and cards to help dashboards' creation using Learning Analytics. It allows users to support creativity around decision making, characterize their context, and draw a dashboard's mockup using existing content.<br/> © 2018 Copyright held by the owner/author(s).},
key = {Decision making},
note = {Canvas;Dashboard;Learning Analytics;Participatory design;Potential users;User need;Visual data representation;},
URL = {http://dx.doi.org/10.1145/3286689.3286693},
} 


@inproceedings{20234114863064 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Examining the Effectiveness of Self-Referenced and Peer-Referenced Learning Analytics Dashboards in Enhancing Students' Self-efficacy: Taking Individual Differences into Account},
journal = {Computer-Supported Collaborative Learning Conference, CSCL},
author = {Jonathan, Christin and Koh, Elizabeth and Tan, Jennifer Pei-Ling},
volume = {2022-June},
year = {2022},
pages = {250 - 257},
issn = {15734552},
address = {Hiroshima, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">This study examined the effectiveness of self-referenced and peer-referenced learning analytics (LA) dashboards in enhancing students' self-efficacy in critical reading, taking individual differences into account. A quasi-experiment with an embedded mixed methods approach was used, with 209 Grade 9 students who participated in critical reading online discussions in the English Language (EL) subject during a nine-week trial. Multiple regression analysis revealed that individual differences, namely, learning goals, performance goals, and gender, were significant predictors of critical reading self-efficacy, whereas dashboard type and initial achievement levels were not. Epistemic network analysis highlighted the importance of students' perceptions of how helpful and motivating they found the dashboards to be. Put together, the results highlight the theoretical and methodological importance of taking individual differences into account and have practical implications for designing more purposeful formative LA dashboards for enhancing students' self-efficacy.<br/></div> © ISLS.},
key = {Students},
keywords = {E-learning;Regression analysis;},
note = {English languages;Individual Differences;Learning goals;Mixed method;Multiple regression analysis;Online discussions;Performance;Quasi-experiments;Self efficacy;Student perceptions;},
} 


@inproceedings{20222712309235 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Applying Natural Language Processing to Teamwork – A New Dashboard for CTMTC Methodology},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Conde, Miguel a. and Andres-Gomez, Adrian and Rodriguez-Sedano, Francisco J. and Fernandez-Llamas, Camino},
volume = {13329 LNCS},
year = {2022},
pages = {251 - 261},
issn = {03029743},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">In our current society the acquisition of competences such as teamwork is essential. However, the evaluation of how this competence is developed is not easy and requires methodologies and tools to support the assessment process. In this sense several Learning Analytics tools have been developed. They explore students’ interactions in different types of tools such as forums or instant messaging apps. However those tools are especially focused on the quantitative evaluation of the interaction and are not very usable. This work presents a new dashboard that analyzes students’ Telegram interactions while they work as a team to address a project. The innovation of this tool lies in the functionalities included to explore not only numbers about messages, replies, type of messages, characters, etc., but the content of the texts. To do so natural language processing and sentiment analysis libraries were used. The tool has been tested successfully with 4 subject editions in which it is possible to appreciate an evolution in students’ interactions.<br/></div> © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Sentiment analysis},
keywords = {Students;},
note = {'current;Assessment process;Dashboard;Language processing;Learning analytic;Natural language processing;Natural languages;Student interactions;Teamwork;Telegram;},
URL = {http://dx.doi.org/10.1007/978-3-031-05675-8_19},
} 


@article{20205209693848 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics dashboards for adaptive support in face-to-face collaborative argumentation},
journal = {Computers and Education},
author = {Han, Jeongyun and Kim, Kwan Hoon and Rhee, Wonjong and Cho, Young Hoan},
volume = {163},
year = {2021},
issn = {03601315},
abstract = {Despite the potential of learning analytics for personalized learning, it is seldom used to support collaborative learning particularly in face-to-face (F2F) learning contexts. This study uses learning analytics to develop a dashboard system that provides adaptive support for F2F collaborative argumentation (FCA). This study developed two dashboards for students and instructors, which enabled students to monitor their FCA process through adaptive feedback and helped the instructor provide adaptive support at the right time. The effectiveness of the dashboards was examined in a university class with 88 students (56 females, 32 males) for 4 weeks. The dashboards significantly improved the FCA process and outcomes, encouraging students to actively participate in FCA and create high-quality arguments. Students had a positive attitude toward the dashboard and perceived it as useful and easy to use. These findings indicate the usefulness of learning analytics dashboards in improving collaborative learning through adaptive feedback and support. Suggestions are provided on how to design dashboards for adaptive support in F2F learning contexts using learning analytics.<br/> © 2020 The Authors},
key = {Students},
note = {Adaptive feedback;Adaptive support;Collaborative argumentations;Collaborative learning;High quality;Learning context;Personalized learning;Positive attitude;},
URL = {http://dx.doi.org/10.1016/j.compedu.2020.104041},
} 


@article{20211910314414 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Staying on target: A systematic literature review on learner-facing learning analytics dashboards},
journal = {British Journal of Educational Technology},
author = {Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and Huggins-Manley, Anne Corinne},
volume = {52},
number = {4},
year = {2021},
pages = {1724 - 1748},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">The advances in technology to capture and process unprecedented amounts of educational data has boosted the interest in Learning Analytics Dashboard (LAD) applications as a way to provide meaningful visual information to administrators, parents, teachers and learners. Despite the frequent argument that LADs are useful to support target users and their goals to monitor and act upon the information provided, little is known about LADs’ theoretical underpinnings and the alignment (or lack thereof) between LADs intended outcomes and the measures used to evaluate their implementation. However, this knowledge is necessary to illuminate more efficient approaches in the development and implementation of LAD tools. Guided by the self-regulated learning perspective and using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, this systematic literature review addressed this gap by examining whether and how learner-facing LAD’s target outcomes align with the domain measures used to evaluate their implementations. Out of the 1297 papers retrieved from 15 databases, 28 were included in the final quantitative and qualitative analysis. Results suggested an intriguing lack of alignment between LADs’ intended outcomes (mostly cognitive domain) and their evaluation (mostly affective measures). Based on these results and on the premise that LADs are designed to support learners, a critical recommendation from this study is that LADs’ target outcomes should guide the selection of measures used to evaluate the efficacy of these tools. This alignment is critical to enable the construction of more robust guidelines to inform future endeavours in the field. Practitioner notes What is already known about this topic There has been an increased interest and investment in learning analytics dashboards to support learners as end-users. Learner-facing learning analytics dashboards are designed with different purposes, functionalities and types of data in an attempt to influence learners’ behaviour, achievement and skills. What this paper adds This paper reports trends and opportunities regarding the design of learner-facing learning analytics dashboards, contexts of implementation, as well as types and features of learner-facing learning analytics dashboard studies. The paper discusses how affect and motivation have been largely overlooked as target outcomes in learner-facing learning analytics dashboards. Implications for practice and/or policy Based on the evidence gathered through the review, this paper makes recommendations for theory (eg, inclusion of motivation as an important target outcome). The paper makes recommendations related to the design, implementation and evaluation of learning analytics dashboards. The paper also highlights the need for further integration between learner-facing learning analytics dashboards and open learner models.<br/></div> © 2021 British Educational Research Association.},
key = {Facings},
keywords = {Learning systems;Alignment;Motivation;},
note = {Affective measures;Cognitive domain;Open learner models;Quantitative and qualitative analysis;Self-regulated learning;Systematic literature review;Systematic Review;Visual information;},
URL = {http://dx.doi.org/10.1111/bjet.13089},
} 


@inproceedings{20214411101219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {NLASI 2021 - Proceedings of the Nordic Learning Analytics (Summer) Institute},
journal = {CEUR Workshop Proceedings},
volume = {2985},
year = {2021},
issn = {16130073},
address = {Stockholm, Sweden},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 8 papers. The topics discussed include: the development of computational thinking concepts in course participants’ programming solutions; students’ information privacy concerns in learning analytics: towards model development; Finnish education professionals’ thoughts on adaptive learning technologies; gamified learning analytics: an initial outline of design concept synergies from two fields; how deployment processes affect the adoption of learning analytics in higher education institutions: improving potential for impact with better deployment practices; AI driven competency development at the threshold of working life; and CADA: a learning analytics dashboard to support teachers with visualizations about students’ participation and discourse in online discussions.<br/></div>},
} 


@article{20162702554287 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Elusive learning-Using learning analytics to support reflective sensemaking of ill-structured ethical problems: A learner-managed dashboard solution},
journal = {Future Internet},
author = {Vovides, Yianna and Inman, Sarah},
volume = {8},
number = {2},
year = {2016},
issn = {19995903},
abstract = {Since the turn of the 21st century, we have seen a surge of studies on the state of U.S. education addressing issues such as cost, graduation rates, retention, achievement, engagement, and curricular outcomes. There is an expectation that graduates should be able to enter the workplace equipped to take on complex and "messy" or ill-structured problems as part of their professional and everyday life. In the context of online learning, we have identified two key issues that are elusive (hard to capture and make visible): learning with ill-structured problems and the interaction of social and individual learning. We believe that the intersection between learning and analytics has the potential, in the long-term, to minimize the elusiveness of deep learning. A proposed analytics model is described in this article that is meant to capture and also support further development of a learner's reflective sensemaking.<br/> © 2016 By The Authors.},
key = {Deep learning},
keywords = {Learning systems;},
note = {Ethical problems;Graduation rates;Ill-structured problems;Individual learning;Learner-managed dashboard;Online learning;Sensemaking;Social concepts;},
URL = {http://dx.doi.org/10.3390/fi8020026},
} 


@inproceedings{20183105647581 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Gamification driven learning analytics},
journal = {Proceedings of the International Conference on e-Learning, ICEL},
author = {Dichev, Christo and Dicheva, Darina and Irwin, Keith},
volume = {2018-July},
year = {2018},
pages = {70 - 76},
issn = {20488882},
address = {Cape Town, South africa},
abstract = {In this paper we introduce our approach towards learning analytics and associated visualizations implemented in a gamified learning platform. Driven by the goal to better encourage learners to reflect on and monitor their learning activities, we aim at bridging the gap between learning analytics and educational gamification research. We discuss the principles and the learning analytics support incorporated in the form of learning dashboards into the course gamification platform OneUp Learning. The focus of the paper is on leveraging the potential of combining learning analytics and gamification, on the feedback capabilities and mechanisms of OneUp dashboards, and on utilizing their motivational effect in a learning context. The paper presents the design strategy, the visualization approach of the dashboards, and the provided support for learners and teachers.<br/> © Academic Conferences Limited. All rights reserved.},
key = {Visualization},
note = {Dashboard;Design strategies;Feedback capabilities;Learning Activity;Learning analytics;Learning context;Learning platform;Self regulation;},
} 


@inproceedings{20182205262032 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics for interpreting},
journal = {CSEDU 2018 - Proceedings of the 10th International Conference on Computer Supported Education},
author = {Taibi, Davide and Bianchi, Francesca and Kemkes, Philipp and Marenzi, Ivana},
volume = {1},
year = {2018},
pages = {145 - 154},
address = {Funchal, Madeira, Portugal},
abstract = {An important activity in the life of interpreters is terminology work. A primary method for learning technical vocabulary is the creation of personal glossaries. The current paper describes the design and creation of a system that guides the students in autonomous vocabulary work, supports the students' learning progress, and helps the teacher in monitoring the student commitment to and achievements in the creation of personal glossaries. The system includes a tool for the creation of glossaries, a tracking system that records the students' actions and the websites they visit while searching the Web for linguistic and content information, and a learning analytics dashboard. The system was tested on a class of 34 university students training in interpreting and the paper reports some preliminary results.<br/> Copyright © 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Students},
keywords = {Glossaries;Learning systems;Search engines;},
note = {Content information;Learning Analytics Dashboard;Learning progress;Searching the Web;Technical Vocabulary for Interpreting;Tracking system;University students;},
} 


@inproceedings{20220311464238 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Dicrev-Dash: Proposal for the Design, Creation and Evaluation of a Dashboard for Data Visualization},
journal = {CEUR Workshop Proceedings},
author = {Delgado, Maria and Pando, Diego and Maldonado-Mahauad, Jorge},
volume = {3059},
year = {2021},
pages = {100 - 110},
issn = {16130073},
address = {Arequipa, Peru},
abstract = {<div data-language="eng" data-ev-field="abstract">Today there are large amounts of data that are difficult to understand in spreadsheets or textual reports, so data visualizations have become an easy and fast way to convey the ideas or objectives that you want to achieve with that data. The objective of this article is to propose a methodology for creating dashboard data visualizations, taking into account the fundamental steps in the creation of a data methodology. To this end, the following question has been posed: What are the phases that must be considered to create an efficient and effective data visualization? This question will be answered in this article with the elaboration of the proposed methodology. Having said all the above, it is proposed to follow and prove this methodology in the future to create a dashboard of data visualizations for the learning analytics observatory.<br/></div> ©? 2020 Copyright for this paper by its authors.},
key = {Visualization},
keywords = {Data visualization;},
note = {Creation;Dashboard;Data methodology;Evaluation;Large amounts of data;Methodology;Proposal;},
} 


@inproceedings{20220311464240 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LALA 2021 - Proceedings of the 4th Latin American Conference on Learning Analytics},
journal = {CEUR Workshop Proceedings},
volume = {3059},
year = {2021},
issn = {16130073},
address = {Arequipa, Peru},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 10 papers. The topics discussed include: adopting learning analytics in a Brazilian higher education institution: ideal and predicted expectations; proposal for the design and implementation of Miranda: a chatbot-type recommender for supporting self-regulated learning in online environments; applying group formation in practice on a Brazilian postgraduate course; modelling computer engineering student trajectories with process mining; a chatbot to support basic students questions; using relational inference engine to answer questions; learning analytics in computer programming courses; machine learning for learning personalization to enhance student academic performance; and Dicrev-Dash: proposal for the design, creation and evaluation of a dashboard for data visualization.<br/></div>},
} 


@article{20172903952247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Features students really expect from learning analytics},
journal = {Computers in Human Behavior},
author = {Schumacher, Clara and Ifenthaler, Dirk},
volume = {78},
year = {2018},
pages = {397 - 407},
issn = {07475632},
abstract = {More and more learning in higher education settings is being facilitated through online learning environments. Students' ability to self-regulate their learning is considered a key factor for success in higher education. Learning analytics offer a promising approach to better support and understand students' learning processes. The purpose of this study is to investigate students' expectations towards features of learning analytics systems and their willingness to use these features for learning. A total of 20 university students participated in an initial qualitative exploratory study. They were interviewed about their expectations of learning analytics features. The findings of the qualitative study were complemented by a quantitative study with 216 participating students. The findings show that students expect learning analytics features to support their planning and organization of learning processes, provide self-assessments, deliver adaptive recommendations, and produce personalized analyses of their learning activities.<br/> © 2017 Elsevier Ltd},
key = {Students},
keywords = {Computer aided instruction;},
note = {Dashboard;Exploratory studies;Feature;Learning analytics;Online learning environment;Quantitative study;Self-regulated learning;University students;},
URL = {http://dx.doi.org/10.1016/j.chb.2017.06.030},
} 


@inproceedings{20221211820581 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data-informed Teaching Reflection: A Pilot of a Learning Analytics Workflow in Japanese High School},
journal = {29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings},
author = {Nakanishi, Taro and Kuromiya, Hiroyuki and Majumdar, Rwitajit and Ogata, Hiroaki},
volume = {1},
year = {2021},
pages = {675 - 677},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">The use of ICT devices in the classroom for teaching has become more relevant in secondary education. However, the use of data driven technologies for supporting pedagogical practices are still limited in the Japanese school context. Promoting the use of ICT in the classroom is an important part of improving the quality of education. In this paper, we introduce the workflow of using e-book reader and learning analytics dashboard to improve teaching of a junior-high school Mathematics class in Japan. We recruited a teacher and forty students for the research and introduced the simple dashboard for daily teaching and learning in their class. An end of the study period survey results showed that the dashboard prompted a change in the way of teaching in the class and also the teacher became more positive towards using data-driven technologies for reflecting on teaching practices.<br/></div> © 2021 29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings. All rights reserved},
key = {Electronic publishing},
keywords = {Surveys;Teaching;},
note = {Data driven;Ebook reader;Evidence-based;Evidence-based education;Higher School;LEAF;Learning analytic;Secondary education;Teachers';Work-flows;},
} 


@inproceedings{20194507625956 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Dashboard for the VISIR remote lab},
journal = {Proceedings of the 2019 5th Experiment at International Conference, exp.at 2019},
author = {Garcia-Zubia, Javier and Cuadros, Jordi and Serrano, Vanessa and Hernandez-Jayo, Unai and Angulo-Martinez, Ignacio and Villar, Aitor and Orduna, Pablo and Alves, Gustavo},
year = {2019},
pages = {42 - 46},
address = {Funchal, Madeira, Portugal},
abstract = {The VISIR dashboard (VISIR-DB) is a learning analytics tool connected with the VISIR remote lab. In VISIR, every action performed by a student from the interface over the remote laboratory and back is logged and recorded. VISIR-DB helps visualizing, in a fast and deep way, the recorded logs from this communication. Using this tool, a teacher can analyze and understand better how the students are using the remote lab during their learning process on analog electronics. With this information, the VISIR platform can be improved and the use of remote labs can be better understood.<br/> © 2019 IEEE.},
key = {Laboratories},
keywords = {Students;},
note = {Analog electronics;Analytics tools;dashboard;learning analytics;Learning process;Remote laboratories;Remote-labs;},
URL = {http://dx.doi.org/10.1109/EXPAT.2019.8876527},
} 


@inproceedings{20221111797026 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Question-driven Dashboard: How Can We Design Analytics Interfaces Aligned to Teachers' Inquiry?},
journal = {ACM International Conference Proceeding Series},
author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Cukurova, Mutlu and Bartindale, Tom and Chen, Peter and Marshall, Harrison and Richardson, Dan and Gasevic, Dragan},
year = {2022},
pages = {175 - 185},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">One of the ultimate goals of several learning analytics (LA) initiatives is to close the loop and support students' and teachers' reflective practices. Although there has been a proliferation of end-user interfaces (often in the form of dashboards), various limitations have already been identified in the literature such as key stakeholders not being involved in their design, little or no account for sense-making needs, and unclear effects on teaching and learning. There has been a recent call for human-centred design practices to create LA interfaces in close collaboration with educational stakeholders to consider the learning design, and their authentic needs and pedagogical intentions. This paper addresses the call by proposing a question-driven LA design approach to ensure that end-user LA interfaces explicitly address teachers' questions. We illustrate the approach in the context of synchronous online activities, orchestrated by pairs of teachers using audio-visual and text-based tools (namely Zoom and Google Docs). This study led to the design and deployment of an open-source monitoring tool to be used in real-time by teachers when students work collaboratively in breakout rooms, and across learning spaces.<br/></div> © 2022 ACM.},
key = {User interfaces},
keywords = {E-learning;Students;},
note = {CSCL;Dashboard;End-user interfaces;Human-centred designs;Inquiry-driven practice;Learning analytic;Online learning;Reflective practise;Sense making;Teachers';},
URL = {http://dx.doi.org/10.1145/3506860.3506885},
} 


@inproceedings{20220711622087 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Improving the Serious Game design using Game Learning Analytics and Eye-tracking: A pilot study},
journal = {2021 IEEE URUCON, URUCON 2021},
author = {Avila-Pesantez, Diego and Usca, Brandon Alexander Tubon and Angamarca, Bryan Gagnay and Miriam Avila, L.},
year = {2021},
pages = {536 - 540},
address = {Montevideo, Uruguay},
abstract = {<div data-language="eng" data-ev-field="abstract">It is necessary to consider metrics that integrate Game Learning Analytics (GLA) and technologies that improve user interfaces through the eye tracker to get better the Serious Games design. In this work, the Math4Fun game was developed using the ADDE methodology to support basic math operations for 7-year-old children, which allowed efficient communication to define the game's critical elements. The GLA metrics were implemented with eXperience API (xAPI) standard and visualized through a real-time dashboard, while Eye-tracking technology working with fixation time analysis on the game's interfaces improves gameplay and design. The results established that combining the GLA indicators with the user interface components obtained from the evaluation with eye-tracking allows redefining concepts in the design and programming inside SG in search of constant improvement.<br/></div> © 2021 IEEE.},
key = {Eye tracking},
keywords = {Serious games;Application programming interfaces (API);Game design;User interfaces;},
note = {Critical elements;Efficient communications;Eye trackers;Eye tracking technologies;Eye-tracking;Game learning analytic;MATH4FUN;Pilot studies;Real-time dashboards;Serious games designs;},
URL = {http://dx.doi.org/10.1109/URUCON53396.2021.9647058},
} 


@inproceedings{20191306707609 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How learning analytics becomes a bridge for non-expert data miners: Impact on higher education online teaching},
journal = {Communications in Computer and Information Science},
author = {Herbert, Katherine and Holder, Ian},
volume = {996},
year = {2019},
pages = {387 - 395},
issn = {18650929},
address = {Bathurst, NSW, Australia},
abstract = {This paper builds on the current studies on data mining’s potential benefits to online learning environments. Many Teaching Academics who are non-experts in data mining techniques however are not able to take advantage of these potential benefits. The objective of this paper is to illustrate how learning analytics is bridging the gap between data mined from Learning Management Systems and teaching practice development in higher education, specifically for Teaching Academics who recently transitioned into online teaching. The authors suggest that bridging this gap is an essential step in the development of online teaching practices and online courses. A customised Dashboard that curates data mined from a university’s LMS is discussed, showcasing the impact on the practices of Teaching Academics. The results from the preliminary exploration suggest that learning analytics can bridge the gap between expert and non-experts of data mining techniques and can become a valuable tool for teaching practice development.<br/> © Springer Nature Singapore Pte Ltd. 2019.},
key = {Data mining},
keywords = {Online systems;Teaching;Information management;Learning systems;E-learning;Computer aided instruction;},
note = {Higher education;Learning analytics;Learning and teachings;Learning management system;Online learning environment;Potential benefits;Professional learning;Teaching practices;},
URL = {http://dx.doi.org/10.1007/978-981-13-6661-1_30},
} 


@inproceedings{20191106629207 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student centred design of a learning analytics system},
journal = {ACM International Conference Proceeding Series},
author = {De Quincey, Ed and Kyriacou, Theocharis and Briggs, Chris and Waller, Richard},
year = {2019},
pages = {353 - 362},
address = {Tempe, AZ, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Current Learning Analytics (LA) systems are primarily designed with University staff members as the target audience; very few are aimed at students, with almost none being developed with direct student involvement and undertaking a comprehensive evaluation. This paper describes a HEFCE funded project that has employed a variety of methods to engage students in the design, development and evaluation of a student facing LA dashboard. LA was integrated into the delivery of 4 undergraduate modules with 169 student sign-ups. The design of the dashboard uses a novel approach of trying to understand the reasons why students want to study at university and maps their engagement and predicted outcomes to these motivations, with weekly personalised notifications and feedback. Students are also given the choice of how to visualise the data either via a chart-based view or to be represented as themselves. A mixed-methods evaluation has shown that students' feelings of dependability and trust of the underlying analytics and data is variable. However, students were mostly positive about the usability and interface design of the system and almost all students once signed-up did interact with their LA. The majority of students could see how the LA system could support their learning and said that it would influence their behaviour. In some cases, this has had a direct impact on their levels of engagement. The main contribution of this paper is the transparent documentation of a User Centred Design approach that has produced forms of LA representation, recommendation and interaction design that go beyond those used in current similar systems and have been shown to motivate students and impact their learning behaviour.<br/></div> © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
key = {Students},
keywords = {Learning systems;Data visualization;User centered design;},
note = {Analytics systems;Comprehensive evaluation;Interaction design;Interface designs;Laddering;Learning analytics;Student involvements;Usability;},
URL = {http://dx.doi.org/10.1145/3303772.3303793},
} 


@inproceedings{20214411097199 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Representation and Visualization of Students’ Progress Data Through Learning Dashboard},
journal = {Communications in Computer and Information Science},
author = {Vaidya, Anagha and Sharma, Sarika},
volume = {1441},
year = {2021},
pages = {125 - 135},
issn = {18650929},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning process of students is very important, it motivates the students for acquiring skills of critical thinking and gives a learning experience. Hence, a systematic feedback is required by the students for measuring their learning processes. This measurement is performed through different educational techniques namely learning analytics (LA), Education Data Mining (EDM) and Learning Dashboard (LD). Students’ learning measurement can be performed by measuring their log activity, content they read, by tracking assignment solving method etc., however in a traditional learning system, students’ learning is measured through the marks they score in the different evaluations. Therefore, these evaluations must be well structured and carefully planned in advanced. Hence the systematic management tool is required which assists the teacher as well as students for their learning progress at any time. In this paper we propose and demonstrate the Learning Dashboard in traditional learning environment which measures the different skills of students through a systematic assessment plan and the results of these assessments are displayed through an analytical report which will be helpful for all stakeholders.<br/></div> © 2021, Springer Nature Switzerland AG.},
key = {Data mining},
keywords = {Data visualization;Computer aided instruction;Information management;Learning systems;Students;Visualization;},
note = {Critical thinking;Educational data mining;Learning analytic;Learning dashboard;Learning experiences;Learning management system;Learning process;Student learning;Student progress;Traditional learning;},
URL = {http://dx.doi.org/10.1007/978-3-030-88244-0_13},
} 


@inproceedings{20183805824487 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Low-Investment, Realistic-Return Business Cases for Learning Analytics Dashboards: Leveraging Usage Data and Microinteractions},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Broos, Tom and Verbert, Katrien and Langie, Greet and Van Soom, Carolien and De Laet, Tinne},
volume = {11082 LNCS},
year = {2018},
pages = {399 - 405},
issn = {03029743},
address = {Leeds, United kingdom},
abstract = {In recent years, Learning Analytics (LA) is finding more and more practical adoption, alongside of continued research interest. However, questions about the impact of LA applications and their underpinning in educational science are still being raised, impeding viability of some LA projects at larger scale. Within this paper we describe two examples using student-facing LA dashboards (LAD) deployed at scale at a relatively low cost. Leveraging data collected by the dashboards themselves, usage data (N = 4070 students) and in-dashboard microinteractions (N = 367 students), we try to put the impact question in perspective. We suggest that when investment is kept limited, a business case with modest but realistic expatiations of returns may be feasible.<br/> © 2018, Springer Nature Switzerland AG.},
key = {Students},
keywords = {Artificial intelligence;},
note = {Business case;Learning analytics;Learning analytics dashboards;Microinteractions;Realistics expectations;Usage data;},
URL = {http://dx.doi.org/10.1007/978-3-319-98572-5_30},
} 


@inproceedings{20171403522600 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Real-time learning analytics for C programming language courses},
journal = {ACM International Conference Proceeding Series},
author = {Fu, Xinyu and Shimada, Atsushi and Ogata, Hiroaki and Taniguchi, Yuta and Suehiro, Daiki},
year = {2017},
pages = {280 - 288},
address = {Vancouver, BC, Canada},
abstract = {Many universities choose the C programming language (C) as the first one they teach their students, early on in their program. However, students often consider programming courses difficult, and these courses often have among the highest dropout rates of computer science courses offered. It is therefore critical to provide more effective instruction to help students understand the syntax of C and prevent them losing interest in programming. In addition, homework and paper-based exams are still the main assessment methods in the majority of classrooms. It is difficult for teachers to grasp students' learning situation due to the large amount of evaluation work. To facilitate teaching and learning of C, in this article we propose a system-LAPLE (Learning Analytics in Programming Language Education)-that provides a learning dashboard to capture the behavior of students in the classroom and identify the different difficulties faced by different students looking at different knowledge. With LAPLE, teachers may better grasp students' learning situation in real time and better improve educational materials using analysis results. For their part, novice undergraduate programmers may use LAPLE to locate syntax errors in C and get recommendations from educational materials on how to fix them.<br/> © 2017 ACM.},
key = {Students},
keywords = {C (programming language);Syntactics;Information systems;Teaching;},
note = {C programming;Information visualization;Learning Analytics;Learning dashboard;Programming education;},
URL = {http://dx.doi.org/10.1145/3027385.3027407},
} 


@inproceedings{20213910941596 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Interactive and Explainable Advising Dashboard Opens the Black Box of Student Success Prediction},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Scheers, Hanne and De Laet, Tinne},
volume = {12884 LNCS},
year = {2021},
pages = {52 - 66},
issn = {03029743},
address = {Bolzano, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper presents exploratory research regarding the design and evaluation of a dashboard supporting the advising of aspiring university students incorporating a black-box predictive model for student success. While black-box predictive models can provide accurate predictions, incorporating them in dashboards is challenging as the black-box nature can threaten the interpretability and negatively impact trust of end-users. Explainable Learning Analytics aims to provide insights to black-box predictions by for instance explaining how the input features impact the prediction made. Two dashboards were designed to visualize the prediction and the outcome of the explainer. The dashboards supplemented the explainer with an interactive visualisation allowing to simulate how changes in the student’s features impact the prediction. Both dashboards were evaluated in user tests with 13 participants. The results show the potential of explainable AI techniques to bring predictive models to advising practice. We found that the combination of the explainer with the simulation helped users to compare the predictive model with their mental models of student success, challenging understanding of users and influencing trust in the predictive model.<br/></div> © 2021, Springer Nature Switzerland AG.},
key = {Forecasting},
keywords = {Information systems;Students;Visualization;},
note = {Accurate prediction;Black boxes;Design and evaluations;Exploratory research;Information visualization;Learning dashboard;Predictive models;Student advising;Student success;University students;},
URL = {http://dx.doi.org/10.1007/978-3-030-86436-1_5},
} 


@inproceedings{20190406401397 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics dashboards for professional training - Challenges and proposal},
journal = {CEUR Workshop Proceedings},
author = {Mouaici, Mohamed and Vignollet, Laurence and Galez, Christine and Etienne, Mael},
volume = {2294},
year = {2018},
issn = {16130073},
address = {Leeds, United kingdom},
abstract = {Exploiting the large quantities of traces left by learners in Virtual Learning Environments (VLE) allows educators, learners and administrators to gain new insights into the learning process. Learning Analytics (LA) aims to leverage data collection, measurement, analysis and reporting data which can help users to improve the learning process. This paper presents the first results of the work we are conducting in a professional learning context to design an effective learning analytics dashboard. We show the particularities and explain the different challenges of our context that have led us to propose models to tackle it. We discuss how these models meet the requirements of our domain, and we finally give an example of indicators, measures and visualization built with educators to help them better understand the learner’s behavior.<br/> © 2018 CEUR-WS. All Rights Reserved.},
key = {Visualization},
keywords = {Information systems;Information use;Learning systems;Computer aided instruction;Professional aspects;},
note = {Challenges;Information visualization;Learning Analytics;Measures;Professional training;},
} 


@inproceedings{20181705111639 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {License to evaluate: Preparing learning analytics dashboards for educational practice},
journal = {ACM International Conference Proceeding Series},
author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
year = {2018},
pages = {31 - 40},
address = {Sydney, NSW, Australia},
abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners.<br/> © 2018 Copyright held by the owner/author(s).},
key = {Data Analytics},
keywords = {Computer aided instruction;Learning systems;},
note = {Evaluation;Learning analytics;Learning dashboards;Learning science;Learning Theory;Social comparison;Systematic Review;},
URL = {http://dx.doi.org/10.1145/3170358.3170421},
} 


@article{20230513527520 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {FIRST: Finding Interesting StoRies about STudents - An Interactive Narrative Approach to Explainable Learning Analytics},
journal = {ProQuest Dissertations and Theses Global},
author = {Al-Doulat, Ahmad},
year = {2021},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics (LA) has had a growing interest by academics, researchers, and administrators motivated by the use of data to identify and intervene with students at risk of underperformance or discontinuation. Typically, faculty leadership and advisors use data sources hosted on different institutional databases to advise their students for better performance in their academic life. Although academic advising has been critical for the learning process and the success of students, it is one of the most overlooked aspects of academic support systems. Most LA systems provide technical support to academic advisors with descriptive statistics and aggregate analytics about students' groups. Therefore, one of the demanding tasks in academic support systems is facilitating the advisors' awareness and sensemaking of students at the individual level. This enables them to make rational, informed decisions and advise their students. To facilitate the advisors' sensemaking of individual students, large volumes of student data need to be presented effectively and efficiently. Effective presentation of data and analytic results for sensemaking and decision-making has been a major issue when dealing with large volumes of data in LA. Typically, the students' data is presented in dashboard interfaces using various kinds of visualizations like scientific charts and graphs. From a human-centered computing perspective, the user's interpretation of such visualizations is a critical challenge to design for, with empirical evidence already showing that 'usable' visualizations are not necessarily effective and efficient from a learning perspective. Since an advisor's interpretation of the visualized data is fundamentally the construction of a narrative about student progress, this dissertation draws on the growing body of work in LA sensemaking, data storytelling, creative storytelling, and explainable artificial intelligence as the inspiration for the development of FIRST, Finding Interesting stoRies about STudents, that supports advisors in understanding the context of each student when making recommendations in an advising session. FIRST is an intelligible interactive interface built to promote the advisors' sensemaking of students' data at the individual level. It combines interactive storytelling and aggregate analytics of student data. It presents the student's data through natural language stories that are automatically generated and updated in coordination with the results of the aggregate analytics. In contrast to many LA systems designed to support student awareness of their performance or support teachers in understanding the students' performance in their courses, FIRST is designed to support advisors and higher education leadership in making sense of students' success and risk in their degree programs. The approach to interactive sensemaking has five main stages: (i) Student temporal data Model, (ii) Domain experts' questions and queries, (iii) Student data reasoning, (iv) Student storytelling model, and (v) Domain experts' reflection. The student storytelling stage is the main component of the sensemaking model and it composes four tasks: (i) Data sources, (ii) Story synthesis, (iii) Story analysis, and (iv) User interaction. The contributions of this dissertation are: (i) A novel student storytelling model to facilitate the sensemaking of complex, diverse, and heterogeneous student data, (ii) An anomaly detection model to enrich student stories with interesting, yet, insightful information for the domain experts and (iii) An explainable and interpretable interactive LA model to inspire advisors' trust and confidence with the student stories. This study reports on four ethnographic studies to show the potential of the proposed LA sensemaking model and how it affects the advisor's sensemaking of students at the individual level. The user studies considered for this dissertation were focus group discussions, in-depth interviews, and diary study- in-situ and snippet technique. These studies investigate if FIRST can improve and facilitate the advisor's sensemaking of students' success or risk by presenting individual student's heterogeneous data as a complete and comprehensive story. ProQuest Subject Headings: Information science, Computer science, Artificial intelligence, Education, Educational administration, Communication, Language.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Students},
keywords = {Aggregates;Artificial intelligence;Curricula;Decision making;Education computing;Engineering education;Teaching;Visualization;},
note = {Academic supports;Analytics systems;Data-source;Domain experts;Educational administration;Individual levels;Language;Performance;Sense making;Support systems;},
} 


@inproceedings{20204509452674 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Role of Self-Regulated Learning in the Design, Implementation, and Evaluation of Learning Analytics Dashboards},
journal = {L@S 2020 - Proceedings of the 7th ACM Conference on Learning @ Scale},
author = {Haynes, Carl C.},
year = {2020},
pages = {297 - 300},
address = {Virtual, Online, United states},
abstract = {Learning technologies are generating a vast quantity of data every day. This data is often presented to students through learning analytics dashboards (LADs) with a goal of improving learners' self-regulated learning. However, are students actually using these dashboards, and do they perceive that using dashboards lead to any changes in their behavior? In this paper we report on the development and implementation of several dashboard views, which we call My Learning Analytics (MyLA). This study found that students thought using the dashboard would have more of an effect on the way they planned their course activity at pre-use (after a demo) than post use. Low self-regulated learners believed so significantly less post-use and used the grade distribution view the least. Students made several suggestions for ways to improve the grade distribution view and rated MyLA's usability more positively at pre-than post-use. Given the low use and low perceived impact of the current dashboard, we suggest that researchers use participatory design to illicit students' needs and better incorporate student suggestions.<br/> © 2020 ACM.},
key = {Students},
note = {Learning technology;Participatory design;Self-regulated learning;},
URL = {http://dx.doi.org/10.1145/3386527.3406732},
} 


@inproceedings{20212510534100 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics in the flipped classroom - Learning dashboards from the students' perspective},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
author = {Droit, Alena and Rieger, Bodo},
volume = {2020-January},
year = {2020},
pages = {100 - 107},
issn = {15301605},
address = {Maui, HI, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Blended learning courses offer the opportunity to collect large amounts of learning data that can help students to improve their performance. The presentation of learning data often takes place in the form of Learning Analytics dashboards, which are already in use at some universities. Students, who are the primary data providers and at the same time the main users, should be involved in the process of developing Learning Analytics dashboards from the beginning. Since there are only a few guidelines for designing these dashboards in literature, we conducted a study with 139 business and information systems students who, in addition to answering a questionnaire, also designed their dashboards with the help of a case study. The dashboard analysis provides detailed insights into the design of the functional and information scope, as well as the presentation of the data for Learning Analytics dashboards.<br/></div> © 2020 IEEE Computer Society. All rights reserved.},
key = {Students},
note = {Blended learning;Case-studies;Classroom learning;Large amounts;Learning course;Learning data;Performance;Primary data;Student perspectives;},
URL = {http://dx.doi.org/10.24251/hicss.2020.013},
} 


@inproceedings{20184706114452 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A model to forecast learning outcomes for students in blended learning courses based on learning analytics},
journal = {ACM International Conference Proceeding Series},
author = {Nguyen, Viet Anh and Nguyen, Quang Bach and Nguyen, Vuong Thinh},
year = {2018},
pages = {35 - 41},
address = {Taipei, China},
abstract = {One of the difficulties experienced by online learners is the lack of regular supervision as well as the need to provide instructions to support the learning process more effectively. The analysis of the learning data in the online courses is not only becoming increasingly important in forecasting learning outcomes but also providing effective instructional strategies for learners to help them get the best results. In this paper, we propose a forecast learning outcomes model based on learners' interaction with online learning systems by providing learning analytics dashboard for both learners and teachers to monitor and orient online learners. This approach is mainly based on some machine learning and data mining techniques. This research aims to answer two research questions: (1) Is it possible to accurately predict learners' learning outcomes based on their interactive activities? (2) How to monitor and guide learners in an effective online learning environment? To answer these two questions, our model has been developed and tested by learners participating in the Moodle LMS system. The results show that 75% of students have outcomes close to the predicted results with an accuracy of over 50%. These positive results, though done on a small scale, can also be considered as suggestions for studies of using learning analytics in predicting learning outcomes of learners through learning activities.<br/> © 2018 Association for Computing Machinery.},
key = {Online systems},
keywords = {Computer aided instruction;Data mining;Learning systems;Students;E-learning;Education computing;Predictive analytics;},
note = {FORECAST model;Learning Activity;Learning analytics;Learning outcome;Predictive modeling;},
URL = {http://dx.doi.org/10.1145/3268808.3268827},
} 


@unpublished{20200309910 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics made in France: The METALproject},
journal = {arXiv},
author = {Brun, Armelle and Bonnin, Geoffray and Castagnos, Sylvain and Roussanaly, Azim and Boyer, Anne},
year = {2019},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper presents the METAL project, an ongoing French open Learning Analytics (LA) project for secondary school, that aims at improving the quality of the learning process. The originality of METAL is that it relies on research through exploratory activities and focuses on all the aspects of a Learning Analytics implementation. This large-scale project includes many concerns, divided into 4 main actions. (1) data management: multi-source data identification, collection and storage, selection and promotion of standards, and design and development of an open-source Learning Record Store (LRS); (2) data visualization: learner and teacher dashboards, with a design that relies on the co-conception with final users, including trust and usability concerns; (3) data exploitation: study of the link between gaze and memory of learners, design of explainable multi-source data-mining algorithms, including ethics and privacy concerns. An additional key of originality lies in the global dissemination of LA at an institution level or at a broader level such as a territory, at the opposite on many projects that focus on a specific school or a school curriculum. Each of these aspects is a hot topic in the literature. Taking into account all of them in a holistic view of education is an additional added value of the project.<br/></div> Copyright © 2019, The Authors. All rights reserved.},
key = {Data mining},
keywords = {Curricula;Data acquisition;Data visualization;Digital storage;Information management;Learning systems;},
note = {Data collection;Data storage;Educational data;Large-scale projects;Learning process;Multisource data;Open learning;Secondary schools;Teacher and learner dashboard;Teachers';},
} 


@article{20202108691414 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A learning analytics journey: Bridging the gap between technology services and the academic need},
journal = {Internet and Higher Education},
author = {Munguia, Pablo and Brennan, Amelia and Taylor, Sarah and Lee, David},
volume = {46},
year = {2020},
issn = {10967516},
abstract = {Developing data visualisation tools to support academics in the classroom is a challenging process due to the key requirements of usefulness and scalability, and the constraints of a university ecosystem. Here we describe the evolution of an enterprise-level, teacher-facing dashboard, designed to display data about students' enrolments and use of the Learning Management System in a meaningful way, and summarise the challenges and lessons we encountered along the way. This large university has a maturing learning analytics unit, a new, data-friendly LMS system, and data-savvy and data-hungry executive leadership. Yet the experienced pathway and evolutionary steps evidence the points that need be resolved to successfully deliver and transition to learning analytics solutions that have previously been conceptually proposed or tested at small scales in other studies. The key findings through the process highlight the level of uplift (in tech, capacity and capability) that universities need to meet contemporary demands and future possibilities.<br/> © 2020},
key = {Information management},
keywords = {Data visualization;Learning systems;},
note = {Learning management system;Small scale;Technology service;},
URL = {http://dx.doi.org/10.1016/j.iheduc.2020.100744},
} 


@inproceedings{20204109316086 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Conceptual framework for process-oriented feedback through learning analytics dashboards},
journal = {CEUR Workshop Proceedings},
author = {Olalde, Inigo Arriaran and Larranaga, Nagore Ipina},
volume = {2671},
year = {2020},
pages = {73 - 80},
issn = {16130073},
address = {Valladolid, Spain},
abstract = {The number of students enrolled in online higher education courses is increasing, and as a result, more data on their learning process is being generated. By exploring this student behavior data through learning analytics, both student and teacher can be provided with process-oriented feedback in the form of dashboards. However, little is known about the typology of relevant feedback in the dashboard to different learning objectives, students and teachers. Although most dashboards and the feedback they provide are based solely on student performance indicators, research shows that such feedback is not sufficient. This article attempts to define a conceptual model that visualizes the relationships between the design of a Learning Analytics Dashboard (LAD) and the concepts of learning science in order to provide process-oriented feedback that supports the regulation of learning. The aim of the work is not to propose a specific design of the LAD to provide feedback, but rather a conceptual framework for the choice of concepts for that design, and therefore to help understand future data needs as a basis for the educational feedback of the dashboards. As a conclusion of our research, we can say that having LADs adapted to any profile (student, teacher, etc.) can improve decision-making processes by showing each user the information that interests them most in the way that best enables them to understand it.<br/> Copyright © 2020 for this paper by its authors.},
key = {Students},
keywords = {Decision making;User profile;Education computing;Learning systems;},
note = {Conceptual frameworks;Decision making process;Higher education;Learning objectives;Learning science;Relevant feedback;Student behavior;Student performance;},
} 


@inproceedings{20211310133576 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The implementation of precision education for learning analytics},
journal = {Proceedings of 2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2020},
author = {Weng, Jian-Xuan and Huang, Anna Y.Q. and Lu, Owen H.T. and Chen, Irene Y.L. and Yang, Stephen J.H.},
year = {2020},
pages = {327 - 332},
address = {Virtual, Takamatsu, Japan},
abstract = {This study is based on a novel conceptual framework, precision education, and takes a blended Python programming course as an example to explore how to implement precision education that includes diagnosis, prediction, prevention and treatment. Precision education follows the principles of personalized services for precision medicine. Its purpose is to strengthen the learning risk prediction and early intervention mentioned in emerging learning analytics through big data, artificial intelligence and other emerging technologies, thereby improving teacher teaching quality and student learning efficiency. This study is based on the design of the e-book learning dashboard, so that teachers can quickly understand students' learning status, and improve the e-book through students' feedback on the dashboard to achieve precision diagnosis. Next, this study uses machine learning algorithms to predict students' learning performance, and thus determine whether students are at-risk to achieve precision prediction. Finally, through the correspondence between reading strategy and reading sequence, and then clearly distinguish the types of students by grouping, and use it as a treatment target for precision treatment and prevention. It is hoped that this empirical study can be used as a case study for implementing precision education.<br/> © 2020 IEEE.},
key = {Forecasting},
keywords = {Machine learning;Learning algorithms;Students;Diagnosis;},
note = {Conceptual frameworks;Early intervention;Emerging technologies;Learning performance;Personalized service;Precision prediction;Python programming;Reading strategies;},
URL = {http://dx.doi.org/10.1109/TALE48869.2020.9368432},
} 


@article{20210609876324 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Applying learning analytics to detect sequences of actions and common errors in a geometry game},
journal = {Sensors (Switzerland)},
author = {Gomez, Manuel J. and Ruiperez-Valiente, Jose A. and Martinez, Pedro A. and Kim, Yoon Jeon},
volume = {21},
number = {4},
year = {2021},
pages = {1 - 16},
issn = {14248220},
abstract = {Games have become one of the most popular activities across cultures and ages. There is ample evidence that supports the benefits of using games for learning and assessment. However, incorporating game activities as part of the curriculum in schools remains limited. Some of the barriers for broader adoption in classrooms is the lack of actionable assessment data, the fact that teachers often do not have a clear sense of how students are interacting with the game, and it is unclear if the gameplay is leading to productive learning. To address this gap, we seek to provide sequence and process mining metrics to teachers that are easily interpretable and actionable. More specifically, we build our work on top of Shadowspect, a three-dimensional geometry game that has been developed to measure geometry skills as well other cognitive and noncognitive skills. We use data from its implementation across schools in the U.S. to implement two sequence and process mining metrics in an interactive dashboard for teachers. The final objective is to facilitate that teachers can understand the sequence of actions and common errors of students using Shadowspect so they can better understand the process, make proper assessment, and conduct personalized interventions when appropriate.<br/> © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
key = {Students},
keywords = {Data mining;Curricula;Geometry;},
note = {Final objective;Gameplay;Games for learning;Process mining;Productive learning;Sequence of actions;Three dimensional geometry;},
URL = {http://dx.doi.org/10.3390/s21041025},
} 


@inproceedings{20191306705488 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Personalizing computer science education by leveraging multimodal learning analytics},
journal = {Proceedings - Frontiers in Education Conference, FIE},
author = {Azcona, David and Hsiao, I-Han and Smeaton, Alan F.},
volume = {2018-October},
year = {2018},
pages = {American Society for Engineering Education (ASEE), Educational Research Methods (ERM) Division; IEEE Computer Society; IEEE Education Society; SJSU Charles W. Davidson College of Engineering - },
issn = {15394565},
address = {San Jose, CA, United states},
abstract = {This Research Full Paper implements a framework that harness sources of programming learning analytics on three computer programming courses a Higher Education Institution. The platform, called PredictCS, automatically detects lower-performing or 'at-risk' students in programming courses and automatically and adaptively sends them feedback. This system has been progressively adopted at the classroom level to improve personalized learning. A visual analytics dashboard is developed and accessible to Faculty. This contains information about the models deployed and insights extracted from student's data. By leveraging historical student data we built predictive models using student characteristics, prior academic history, logged interactions between students and online resources, and students' progress in programming laboratory work. Predictions were generated every week during the semester's classes. In addition, during the second half of the semester, students who opted-in received pseudo real-time personalised feedback. Notifications were personalised based on students' predicted performance on the course and included a programming suggestion from a top-student in the class if any programs submitted had failed to meet the specified criteria. As a result, this helped students who corrected their programs to learn more and reduced the gap between lower and higher-performing students.<br/> © 2018 IEEE.},
key = {Students},
keywords = {Machine learning;Education computing;Learning systems;Data mining;Computer programming;Predictive analytics;},
note = {Computer Science Education;Educational data mining;Learning Analytics;Peer learning;Predictive modelling;},
URL = {http://dx.doi.org/10.1109/FIE.2018.8658596},
} 


@article{20230513486468 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Developing Learning Analytics to Promote Knowledge Integration in a Technology-Enhanced Learning Environment},
journal = {ProQuest Dissertations and Theses Global},
author = {Wiley, Korah J.},
year = {2020},
abstract = {<div data-language="eng" data-ev-field="abstract">In a context where classrooms are becoming increasingly enhanced with technology, a research priority is to develop learning analytics and teacher dashboards that support pedagogical actions that leverage students’ ideas as learning resources. While the field of learning analytics has made remarkable advances in developing and applying cutting edge technologies to support teaching and learning (e.g. machine learning-based predictive analytics), more progress is needed to connect these advances to the complex task of providing teachers with insight into student thinking (Baker et al., 2020). Additionally, the widespread adoption of the Next Generation Science Standards (NGSS) and the increased use of data-generating technologies in K-12 science classrooms makes the need for learning analytics that align with research- and theory-based pedagogy especially important. Taken together, this situation calls for the development of learning analytics and pedagogical supports that align with the current education reform efforts and leverage the unique perspectives and practices of teachers and students. My dissertation project addresses this situation by investigating the research question of how to develop and evaluate learning analytics and pedagogical supports that assist diverse teachers in supporting their students to build on their developing ideas towards integrated science knowledge. Specifically, this design-based dissertation project uses mixed methods to develop learning analytics that support teachers in investigating their students’ developing understanding of complex ideas about energy and matter transformation in photosynthesis. Using the knowledge integration (KI) pedagogical framework, I: (a) developed an online inquiry science unit on photosynthesis; (b) developed analytics to reveal student thinking by analyzing system-logged data associated with student-generated artifacts using natural language processing and machine learning techniques; and (c) developed and refined a teacher dashboard, called the Teacher Action Planner. While this dissertation project primarily focuses on a middle school science classroom using a technology-enhanced learning environment, the resulting development strategy and products have broad application across disciplinary domains, instructional contexts, and teacher and student populations. ProQuest Subject Headings: Science education, Middle school education, Pedagogy, Teacher education, Educational administration, Educational leadership, Educational technology, Education policy, Curriculum development, Artificial intelligence.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Students},
keywords = {Artificial intelligence;C (programming language);Computer aided instruction;Curricula;E-learning;Educational technology;Engineering education;Knowledge management;Learning algorithms;Learning systems;Natural language processing systems;Teaching;},
note = {Curriculum development;Education policies;Educational administration;Educational leadership;Knowledge integration;Middle school educations;Pedagogy;Science education;Teacher education;Teachers';},
} 


@article{20202908941245 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {From students with love: An empirical study on learner goals, self-regulated learning and sense-making of learning analytics in higher education},
journal = {Internet and Higher Education},
author = {Jivet, Ioana and Scheffel, Maren and Schmitz, Marcel and Robbers, Stefan and Specht, Marcus and Drachsler, Hendrik},
volume = {47},
year = {2020},
issn = {10967516},
abstract = {Unequal stakeholder engagement is a common pitfall of adoption approaches of learning analytics in higher education leading to lower buy-in and flawed tools that fail to meet the needs of their target groups. With each design decision, we make assumptions on how learners will make sense of the visualisations, but we know very little about how students make sense of dashboard and which aspects influence their sense-making. We investigated how learner goals and self-regulated learning (SRL) skills influence dashboard sense-making following a mixed-methods research methodology: a qualitative pre-study followed-up with an extensive quantitative study with 247 university students. We uncovered three latent variables for sense-making: transparency of design, reference frames and support for action. SRL skills are predictors for how relevant students find these constructs. Learner goals have a significant effect only on the perceived relevance of reference frames. Knowing which factors influence students' sense-making will lead to more inclusive and flexible designs that will cater to the needs of both novice and expert learners.<br/> © 2020 The Authors},
key = {Students},
note = {Empirical studies;Flexible designs;Mixed-methods research;Perceived relevances;Quantitative study;Self-regulated learning;Stakeholder engagement;University students;},
URL = {http://dx.doi.org/10.1016/j.iheduc.2020.100758},
} 


@inproceedings{20182405294381 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Workplace learning analytics in higher engineering education},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Van Der Stappen, Esther},
volume = {2018-April},
year = {2018},
pages = {15 - 20},
issn = {21659559},
address = {Santa Cruz de Tenerife, Canary Islands, Spain},
abstract = {Learning in the workplace is crucial in higher engineering education, since it allows students to transfer knowledge and skills from university to professional engineering practice. Learning analytics endeavors in higher education have primarily focused on classroom-based learning. Recently, workplace learning analytics has become an emergent research area, with target users being workers, students and trainers. We propose technology for workplace learning analytics that allows program managers of higher engineering education programs to get insight into the workplace learning of their students, while ensuring privacy of students' personal data by design. Using a design-based agile methodology, we designed and developed a customizable workplace learning dashboard. From the evaluation with program managers in the computing domain, we can conclude that such technology is feasible and promising. The proposed technology was designed to be generalizable to other (engineering) domains. A next logical step would be to evaluate and improve the proposed technology within other engineering domains.<br/> © 2018 IEEE.},
key = {Students},
keywords = {Data privacy;Engineering education;Managers;},
note = {Agile Methodologies;Classroom based learning;Curriculum improvement;Engineering domains;Higher engineering educations;Learning Analytics;Professional engineerings;Workplace learning;},
URL = {http://dx.doi.org/10.1109/EDUCON.2018.8363102},
} 


@inproceedings{20182405310439 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {iMoodle: An intelligent moodle based on learning analytics},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Tlili, Ahmed and Essalmi, Fathi and Jemni, Mohamed and Chang, Maiga and Kinshuk},
volume = {10858 LNCS},
year = {2018},
pages = {476 - 479},
issn = {03029743},
address = {Montreal, QC, Canada},
abstract = {Online learning is gaining an increasing attention by researchers and educators, since it makes students learn without being limited in time or space like traditional classrooms. However, this type of learning faces several challenges include the difficulties for teachers to control the learning process and keep track of their students’ learning progress. Therefore, this paper presents an ongoing project which is an intelligent Moodle (iMoodle) that uses learning analytics to provide dashboard for teachers to control the learning process and make decisions. It also aims to increase the students’ success rate with an early warning system for identifying at-risk students as well as providing real time interventions of supportive learning content as notifications.<br/> © Springer International Publishing AG, part of Springer Nature 2018.},
key = {Students},
keywords = {Learning systems;Computer aided instruction;Online systems;Education computing;Process control;E-learning;},
note = {Early Warning System;Intelligent tutoring system;Learning analytics;Learning contents;Learning process;Learning progress;Moodle;Online learning;},
} 


@inproceedings{20240115302412 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Three Level Design Study Approach to Develop a Student-Centered Learner Dashboard},
journal = {Communications in Computer and Information Science},
author = {Drzyzga, Gilbert and Harder, Thorleif},
volume = {1996 CCIS},
year = {2023},
pages = {262 - 281},
issn = {18650929},
address = {Rome, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">Online programs risk higher student dropout rates. Supporting learning tools such as learning analytics dashboards (LADs) can promote self-regulated learning and positively impact student outcomes. In this paper, a three-level design study is presented that demonstrates the reduction of cognitive load at multiple levels when students are involved in the LAD design process. Through a user-centered design process (including requirements analysis and expert interviews), a wireframe was developed using participatory methods and evaluated by 24 university students using the laws of Gestalt psychology, resulting in a clickable, low-fidelity prototype (LFD). This was then evaluated by 24 university students using the interaction principles of EN ISO 9241-110:2020. The refined LFD was further evaluated with university students in an eye-tracking study using the thinking-aloud technique (n = 10). The feedback emphasized the importance of participatory design and provided critical insights into the most effective use of the LAD and its elements, taking into account cognitive aspects. The results showed significant optimization in the small details and the big picture in the use of content elements, e.g., it is a crucial part to create a navigation structure adapted to the needs of an LAD and it is beneficial to present a reduced level of information during the initial access, with the option to add or access additional elements as needed.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
URL = {http://dx.doi.org/10.1007/978-3-031-49425-3_16},
} 


@article{20211910325136 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Do Teachers Find Dashboards Trustworthy, Actionable and Useful? A Vignette Study Using a Logs and Audio Dashboard},
journal = {Technology, Knowledge and Learning},
author = {Kasepalu, Reet and Chejara, Pankaj and Prieto, Luis P. and Ley, Tobias},
volume = {27},
number = {3},
year = {2022},
pages = {971 - 989},
issn = {22111662},
abstract = {<div data-language="eng" data-ev-field="abstract">Monitoring and guiding multiple groups of students in face-to-face collaborative work is a demanding task which could possibly be alleviated with the use of a technological assistant in the form of learning analytics. However, it is still unclear whether teachers would indeed trust, understand, and use such analytics in their classroom practice and how they would interact with such an assistant. The present research aimed to find out what the perception of in-service secondary school teachers is when provided with a dashboard based on audio and digital trace data when monitoring a collaborative learning activity. In a vignette study, we presented twenty-one in-service teachers with videos from an authentic collaborative activity, together with visualizations of simple collaboration analytics of those activities. The teachers perceived the dashboards as providers of useful information for their everyday work. In addition to assisting in monitoring collaboration, the involved teachers imagined using it for picking out students in need, getting information about the individual contribution of each collaborator, or even as a basis for assessment. Our results highlight the need for guiding dashboards as only providing new information to teachers did not compel them to intervene and additionally, a guiding dashboard could possibly help less experienced teachers with data-informed assessment.<br/></div> © 2021, The Author(s).},
key = {Students},
keywords = {Teaching;},
note = {Classroom practices;Collaborative activities;Collaborative learning activities;Collaborative Work;Face to face;Multiple-group;Secondary schools;Trace data;},
URL = {http://dx.doi.org/10.1007/s10758-021-09522-5},
} 


@inproceedings{20220511580523 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Descriptive Analytics Dashboard for an Inclusive Learning Environment},
journal = {Proceedings - Frontiers in Education Conference, FIE},
author = {Costas-Jauregui, Vladimir and Oyelere, Solomon Sunday and Caussin-Torrez, Bernardo and Barros-Gavilanes, Gabriel and Agbo, Friday Joseph and Toivonen, Tapani and Motz, Regina and Tenesaca, Juan Bernardo},
volume = {2021-October},
year = {2021},
pages = {American Society for Engineering Education (ASEE) Educational Research and Methods Division (ERM); IEEE Computer Society; IEEE Education Society - },
issn = {15394565},
address = {Lincoln, NE, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">The educational community continuously seeks ways to improve the learner-centered learning process through new approaches like Learning analytics and its dashboard, which is helpful to enhance the teaching and the learning process. It involves a process whose final goal is presenting results to support decision-making about improving the learning process. However, a descriptive Learning analytics interface for analyzing learning data of students, including the disadvantaged, where to view and interpret learners' historical data is -in general- missing in this research domain. Hence, more research is still required to establish the philosophy of learning analytics on inclusion with an interface for the stakeholders to understand learning and teaching in an inclusive learning environment. This paper fills this gap by providing an inclusive educational learning analytics dashboard to support teachers and students. This study aimed to present a learning analytics implementation in the context of a smart ecosystem for learning and inclusion. We gave the inclusive educational needs and discussed the workflow followed during the descriptive learning analytics dashboard development. Therefore, the study improved existing learning analytics dashboards with a descriptive approach and inclusiveness of students with disabilities. Owing to the software development nature of this study, agile methodology based on five stages was applied: requirement elicitation; data gathering; design and prototyping; implementation; and testing and integration. We performed an initial evaluation, which indicated that the dashboard is suitable for understanding teachers' and students' needs and expectations. Besides, the visualization of inclusive learning characteristics improves engagement and attainment of learning goals.<br/></div> © 2021 IEEE.},
key = {Students},
keywords = {Learning systems;Integration testing;Software design;Software prototyping;Computer aided instruction;Decision making;},
note = {Decisions makings;Descriptive learning analytic;Educational community;Historical data;Learner-centred;Learning data;Learning environments;Learning process;New approaches;Teachers';},
URL = {http://dx.doi.org/10.1109/FIE49875.2021.9637388},
} 


@inproceedings{20140517239923 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics and formative assessment to provide immediate detailed feedback using a student centered mobile dashboard},
journal = {International Conference on Next Generation Mobile Applications, Services, and Technologies},
author = {Aljohani, Naif Radi and Davis, Hugh C.},
year = {2013},
pages = {262 - 267},
issn = {21612889},
address = {Prague, Czech republic},
abstract = {The 'immediacy' of feedback on academic performance is a common characteristic shared by both Learning Analytics (LA) and Formative Assessment (FA), and such immediacy could be facilitated by supporting the mobility of learners. However, there is little literature that investigates the significance of combining these two techniques. Therefore, this paper will discuss the analytical application called Quiz My Class Understanding (QMCU) which was purposely developed to investigate the significance of the combination between LA and FA techniques in order to provide students with immediate detailed feedback. Furthermore, it reports on a case study which reflects the role QMCU students' centered mobile dashboard in increasing the students' engagement with the QMCU dashboard. © 2013 IEEE.<br/>},
key = {Students},
keywords = {E-learning;},
note = {Academic performance;Analytical applications;Detailed feedbacks;Formative assessment;Immediate feedbacks;Learning Analytics;Students' engagements;},
URL = {http://dx.doi.org/10.1109/NGMAST.2013.54},
} 


@inproceedings{20221511943072 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An Analytics Dashboard for Personalised E-learning: A Preliminary Study},
journal = {Lecture Notes in Electrical Engineering},
author = {Azmi Murad, M.A. and Shah Jahan, A.F. and Mohd Sharef, N. and Ab Jalil, H. and Ismail, I.A. and Mohd Noor, M.Z.},
volume = {835},
year = {2022},
pages = {855 - 866},
issn = {18761100},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">Over the last few decades, information and communication technologies (ICT) have changed our lives to enhance the process of teaching and learning. E-learning is powerful and influential in the classroom or elsewhere, as long as there is computer and internet access. The vast majority of institutions utilized a Learning Management System (LMS) to administer online courses to create, deliver, moderate and facilitate academic content and activities. While LMSs are mainly being used as a repository for course materials and platforms for assessing learning, recent developments require e-learning to be more responsive to students’ needs for a more customized learning experience. This requires functional characteristics like personalization analytics, self-monitoring, and intervention. Besides being a primary learning source nowadays, e-learning has been useful to monitor students’ performance and retention levels. However, the current e-learning system does not allow the user to empower the learning experience and the research on the suitability of the learning content is still lacking. We proposed a general design and implementation of a learning analytics dashboard for students comprising a predictive analytic component that is useful to help monitor or predict their academic performance based on learning activities. The results show that the system, known as DashLearn, allows students to stay alert of their current academic performance compared to their peers, monitor attendance and assignment submission status, and predict their grade ahead of time for an early intervention leading to more optimized learning.<br/></div> © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
key = {Students},
keywords = {E-learning;Predictive analytics;Learning systems;Teaching;Curricula;},
note = {'current;Academic performance;Computer access;E - learning;Information and Communication Technologies;Internet access;Learning analytic;Learning experiences;Learning management system;Teaching and learning;},
URL = {http://dx.doi.org/10.1007/978-981-16-8515-6_65},
} 


@article{20182705408957 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How Teachers Make Dashboard Information Actionable},
journal = {IEEE Transactions on Learning Technologies},
author = {Molenaar, I. and Knoop-Van Campen, C.A.N.},
volume = {12},
number = {3},
year = {2019},
pages = {347 - 355},
issn = {19391382},
abstract = {This study investigates how teachers use dashboards in primary school classrooms. While learners practice on a tablet real-time data indicating learner progress and performance is displayed on teacher dashboards. This study examines how teachers use the dashboards, applying Verberts' learning analytics process model. Teacher dashboard consultations and resulting pedagogical actions were observed in 38 mathematics lessons. In stimulated recall interviews, the 38 teachers were asked to elaborate on how they reflect on and make sense of the information on the dashboard. The results showed that teachers consulted the dashboard on average 8.3 times per lesson. Teachers activated existing knowledge about students and the class to interpret dashboard information. Task and process feedback were the pedagogical actions most often used following dashboard consultation. Additionally, teachers who consulted the dashboard more often activated more and more diverse pedagogical knowledge to interpret the data and, consequently, gave more and more diverse feedback. These results indicated that teacher dashboards were indeed influencing teachers' pedagogical actions in their daily classroom activities. This study provided the first evidence that dashboards progressively impact teaching practice and initiate more profound behavioral changes as teachers become more proficient in using them.<br/> © 2008-2011 IEEE.},
key = {Engineering education},
keywords = {Learning systems;Education computing;},
note = {Adaptive learning;Behavioral changes;Classroom activity;dashboards;learning analytics;Pedagogical knowledge;Teaching practices;Technology enhanced learning;},
URL = {http://dx.doi.org/10.1109/TLT.2018.2851585},
} 


@inproceedings{20173804194987 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Awareness is not enough: Pitfalls of learning analytics dashboards in the educational practice},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus},
volume = {10474 LNCS},
year = {2017},
pages = {82 - 96},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {It has been long argued that learning analytics has the potential to act as a "middle space" between the learning sciences and data analytics, creating technical possibilities for exploring the vast amount of data generated in online learning environments. One common learning analytics intervention is the learning dashboard, a support tool for teachers and learners alike that allows them to gain insight into the learning process. Although several related works have scrutinised the state-of-the-art in the field of learning dashboards, none have addressed the theoretical foundation that should inform the design of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our critical examination reveals the most common educational concepts and the context in which they have been applied. We find evidence that current designs foster competition between learners rather than knowledge mastery, offering misguided frames of reference for comparison.<br/> © Springer International Publishing AG 2017.},
key = {Computer aided instruction},
keywords = {Learning systems;Teaching;},
note = {Learning analytics;Learning dashboards;Learning science;Learning Theory;Social comparison;Systematic Review;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_7},
} 


@inproceedings{20211310128984 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting collaboration: From learning analytics to teacher dashboards},
journal = {Computer-Supported Collaborative Learning Conference, CSCL},
author = {Chen, Yuxin and Saleh, Asmalina and Hmelo-Silver, Cindy E. and Glazewski, Krista and Mott, Bradford W. and Lester, James C.},
volume = {3},
year = {2020},
pages = {1689 - 1692},
issn = {15734552},
address = {Nashville, TN, United states},
abstract = {Designing embedded teacher-support structures within computer-supported collaborative learning environments is key to successful facilitation of group collaboration. Previous work has designed and examined various orchestration tools for teachers facilitating groups of learners, including the integration of a data visualization dashboard for teachers to simultaneously monitor multiple classroom groups. However, few studies have investigated to what extent and which supports are needed to monitor groups while students engage in a game-based collaborative learning environment. This paper proposes a theory-driven design framework for building teacher dashboards and examines the specific functions and design features needed.<br/> © ISLS.},
key = {Data visualization},
keywords = {Computer aided instruction;E-learning;},
note = {Computer supported collaborative learning environments;Design features;Design frameworks;Game-based collaborative learning;Group collaboration;Support structures;},
} 


@inproceedings{20153201117840 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a learning analytics dashboard for undergraduate engineering using participatory design},
journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
author = {Knight, David B. and Brozina, Cory and Stauffer, Eric M. and Frisina, Chris and Abel, Troy D.},
volume = {122nd ASEE Annual Conference and Exposition: Making Value for Society},
number = {122nd ASEE Annual Conference and Exposition: Making Value for Society},
year = {2015},
issn = {21535965},
address = {Seattle, WA, United states},
} 


@unpublished{20200219954 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Development of learning analytics-moodle extension for Easy JavaScript Simulation (EjsS) virtual laboratories},
journal = {arXiv},
author = {Garcia Clemente, Felix J. and Wee, Loo Kang and Esquembre, Francisco and Leong, Tze Kwang and Tan, Darren},
year = {2019},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Easy JavaScript Simulations (EjsS) is a popular and powerful authoring toolkit for the creation of open source HTML5-compliant JavaScript simulations. This paper focuses on developing a Learning Analytics extension in Moodle for EjsS, capable of monitoring interactions with the simulation (e.g. mouse clicks, states of buttons and sliders, variable assignments). This extension was piloted with educational physics simulations. Data on learners can be visualised in real-time on the instructor dashboard, allowing instructors to better understand the learning process and modify classroom instruction accordingly.<br/></div> Copyright © 2019, The Authors. All rights reserved.},
key = {High level languages},
keywords = {E-learning;Mammals;},
note = {Analytic extension;Classroom instruction;Javascript;Learning process;Mouse clicks;Open-source;Physics simulation;Real- time;Variable assignment;Virtual laboratories;},
} 


@inproceedings{20173804195047 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The proof of the pudding: Examining validity and reliability of the evaluation framework for learning analytics},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Scheffel, Maren and Drachsler, Hendrik and Toisoul, Christian and Ternier, Stefaan and Specht, Marcus},
volume = {10474 LNCS},
year = {2017},
pages = {194 - 208},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {While learning analytics (LA) is maturing from being a trend to being part of the institutional toolbox, the need for more empirical evidences about the effects for LA on the actual stakeholders, i.e. learners and teachers, is increasing. Within this paper we report about a further evaluation iteration of the Evaluation Framework for Learning Analytics (EFLA) that provides an efficient and effective measure to get insights into the application of LA in educational institutes. For this empirical study we have thus developed and implemented several LA widgets into a MOOC platform’s dashboard and evaluated these widgets using the EFLA as well as the framework itself using principal component and reliability analysis. The results show that the EFLA is able to measure differences between widget versions. Furthermore, they indicate that the framework is highly reliable after slightly adapting its dimensions.<br/> © Springer International Publishing AG 2017.},
key = {Reliability analysis},
keywords = {Computer aided instruction;Principal component analysis;Teaching;},
note = {Educational Institutes;Effective measures;Empirical studies;Evaluation;Evaluation framework;Learning analytics;Principal Components;Validity;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_15},
} 


@inproceedings{20172803936734 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Effects of a dashboard for an intelligent tutoring system on teacher knowledge, lesson plans and class sessions},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Xhakaj, Franceska and Aleven, Vincent and McLaren, Bruce M.},
volume = {10331 LNAI},
year = {2017},
pages = {582 - 585},
issn = {03029743},
address = {Wuhan, China},
abstract = {Even though Intelligent Tutoring Systems (ITS) have been shown to help students learn, little research has investigated how a dashboard could help teachers help their students. In this paper, we explore how a dashboard prototype designed for an ITS affects teachers’ knowledge about their students, their classroom lesson plans and class sessions. We conducted a quasi-experimental classroom study with 5 middle school teachers and 8 classes. We found that the dashboard influences what teachers know about their students, which in turn influences the lesson plans they prepare, which then guides what teachers cover in a class session. We believe this is the first study that explores how a dashboard for an ITS affects teacher’s knowledge, decision-making and actions in the classroom.<br/> © Springer International Publishing AG 2017.},
key = {Students},
keywords = {Planning;Teaching;Computer aided instruction;Decision making;Education computing;Intelligent vehicle highway systems;},
note = {Dashboard;Data driven;Intelligent tutoring system;Learning analytics;Teachers';},
URL = {http://dx.doi.org/10.1007/978-3-319-61425-0_69},
} 


@article{20212310473188 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Ideating and Developing a Visualization Dashboard to Support Teachers Using Educational Games in the Classroom},
journal = {IEEE Access},
author = {Ruiperez-Valiente, Jose A. and Gomez, Manuel J. and Martinez, Pedro A. and Kim, Yoon Jeon},
volume = {9},
year = {2021},
pages = {83467 - 83481},
issn = {21693536},
abstract = {<div data-language="eng" data-ev-field="abstract">Technology has become an integral part of our everyday life, and its use in educational environments keeps growing. Additionally, video games are one of the most popular mediums across cultures and ages. There is ample evidence that supports the benefits of using games for learning and assessment, and educators are mainly supportive of using games in classrooms. However, we do not usually find educational games within the classroom activities. One of the main problems is that teachers report difficulties to actually know how their students are using the game so that they can analyze properly the effect of the activity and the interaction of students. To support teachers, educational games should incorporate learning analytics to transform data generated by students when playing useful information in a friendly and understandable way. For this work, we build upon Shadowspect, a 3D geometry puzzle game that has been used by teachers in a group of schools in the US. We use learning analytics techniques to generate a set of metrics implemented in a live dashboard that aims to facilitate that teachers can understand students' interaction with Shadowspect. We depict the multidisciplinary design process that we have followed to generate the metrics and the dashboard with great detail. Finally, we also provide uses cases that exemplify how teachers can use the dashboard to understand the global progress of their class and each of their students at an individual level, in order to intervene, adapt their classes and provide personalize feedback when appropriate.<br/></div> © 2013 IEEE.},
key = {Students},
keywords = {Technology transfer;Human computer interaction;Visualization;},
note = {Classroom activity;Educational environment;Educational game;Games for learning;Individual levels;Integral part;Multi-disciplinary designs;Puzzle games;},
URL = {http://dx.doi.org/10.1109/ACCESS.2021.3086703},
} 


@inproceedings{20173804195048 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Opportunities and challenges in using learning analytics in learning design},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Schmitz, Marcel and van Limbeek, Evelien and Greller, Wolfgang and Sloep, Peter and Drachsler, Hendrik},
volume = {10474 LNCS},
year = {2017},
pages = {209 - 223},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {Educational institutions are designing, creating and evaluating courses to optimize learning outcomes for highly diverse student populations. Yet, most of the delivery is still monitored retrospectively with summative evaluation forms. Therefore, improvements to the course design are only implemented at the very end of a course, thus missing to benefit the current cohort. Teachers find it difficult to interpret and plan interventions just-in-time. In this context, Learning Analytics (LA) data streams gathered from ‘authentic’ student learning activities, may provide new opportunities to receive valuable information on the students’ learning behaviors and could be utilized to adjust the learning design already "on the fly" during runtime. We presume that Learning Analytics applied within Learning Design (LD) and presented in a learning dashboard provide opportunities that can lead to more personalized learning experiences, if implemented thoughtfully. In this paper, we describe opportunities and challenges for using LA in LD. We identify three key opportunities for using LA in LD: (O1) using on demand indicators for evidence based decisions on learning design; (O2) intervening during the run-time of a course; and, (O3) increasing student learning outcomes and satisfaction. In order to benefit from these opportunities, several challenges have to be overcome. Following a thorough literature review, we mapped the identified opportunities and challenges in a conceptual model that considers the interaction of LA in LD.<br/> © Springer International Publishing AG 2017.},
key = {Students},
keywords = {Teaching;Curricula;Data mining;},
note = {Educational institutions;Evidence- based decisions;Learning analytics;Learning dashboards;Learning designs;Metacognitives;Personalized learning;Student learning outcomes;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_16},
} 


@inproceedings{20161002065201 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Exploring learning analytics for computing education},
journal = {ICER 2015 - Proceedings of the 2015 ACM Conference on International Computing Education Research},
author = {Olivares, Daniel},
year = {2015},
pages = {271 - 272},
address = {Omaha, NE, United states},
abstract = {Student retention in STEM disciplines is a growing problem. The number of students receiving undergraduate STEM degrees will need to increase by about 34% annually in order to meet projected needs [6]. One way to address this problem is by leveraging the emerging field of learning analytics, a data-driven approach to designing learning interventions based on continuously-updated data on learning processes and outcomes. Through an iterative, user-centered, design approach, we propose to develop a learning dashboard tailored for computing courses. The dashboard will collect, analyze, and present learning process and outcome data to instructors and students, thus providing an empirical basis for automated, teacher-initiated, and learner-initiated interventions to positively influence learning outcomes and retention. Through a series of mixed-method empirical studies, we will determine what data should be made available to instructors, how that data can be best displayed, how effective teaching interventions can be fashioned from the data, and how such interventions affect student grades and persistence in introductory computing science courses.<br/>},
key = {Students},
keywords = {Computation theory;Learning systems;Curricula;Teaching;Iterative methods;},
note = {Computing education;Learning analytics;Learning dashboard;Social learning theory;Social programming;},
URL = {http://dx.doi.org/10.1145/2787622.2787746},
} 


@article{20230513489270 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards Building a Dashboard for Faculty in Higher Education: Faculty Perceptions of Information That Informs Their Practice},
journal = {ProQuest Dissertations and Theses Global},
author = {Powell, Leigh},
year = {2021},
abstract = {<div data-language="eng" data-ev-field="abstract">Sources of information are growing as a result of the changing technology landscape in our learning environments. This presents an opportunity to leverage information in new ways to benefit students and faculty by illuminating different aspects of the practice of teaching. For this information to have an impact, it is first necessary to understand what information is most relevant to faculty in their teaching practice and how to go about providing this information. In this study, a thorough review of the literature was first conducted to understand the kinds of information that faculty use to guide their practice and the ways that information is typically provided to faculty. This included a review of the growing field of learning analytics and the use of dashboards, which seek to display educational data in a visual way to promote insight and action. A qualitative approach was then used to explore the teaching practice of eleven faculty participants at a university of medicine and health sciences in the UAE. Data were collected through semi-structured interviews that focused on understanding the kinds of information relevant to participants’ practice, the kinds of technology they use, and the factors they believed would be useful to consider if a dashboard were to be built for their needs.Findings from this study show how participants care deeply about graduating successful and competent medical professionals but have little ongoing information to help them know that their teaching strategies are working. Additionally, the findings show that there is a gap in faculty development efforts that promote practices that generate evidence of learning. A discussion of the results in the context of the literature serves to highlight similarities not just in the kinds of information faculty find useful in their teaching but also their expressed uses and desires for a dashboard. The implications of this study suggest the creation of a faculty development cycle that places information at the center of practice and inquiry, using a dashboard as a conduit for faculty development; motivating teaching strategies that promote evidence-based practices and information-driven reflection. ProQuest Subject Headings: Educational technology, Information technology, Higher education.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Educational technology},
keywords = {Computer aided instruction;Engineering education;Information use;Medicine;},
note = {Faculty development;Faculty perceptions;Faculty use;High educations;Learning environments;Practice of teachings;Sources of informations;Teaching practices;Teaching strategy;Technology landscapes;},
} 


@inproceedings{20165103148262 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizing online (social) learning processes - Designing a Dashboard to support reflection},
journal = {CEUR Workshop Proceedings},
author = {Hayit, Darya and Holterhof, Tobias and Rehm, Martin and Carl, Oskar and Kerres, Michael},
volume = {1736},
year = {2016},
pages = {35 - 40},
issn = {16130073},
address = {Lyon, France},
abstract = {Learning analytics, as a means to visualize learning, has been repeatedly suggested to enhance learners' and teachers' self-reflection in online learning processes. Departing from this notion, we propose a combination of this visual approach to learning analytics with the concept of social presence, thereby acknowledging social aspects of online learning processes that are often overlooked. More specifically, we present the considerations and design of a dedicated dashboard that supports self-reflection by visualizing (social) online learning processes. The approach is based on our belief that visualizing learning by itself does not automatically lead to self-reflection and awareness among students and teachers. Instead, organizers and instructors of learning activities need to be conscious about the social aspects of learning.<br/>},
key = {Social aspects},
keywords = {Teaching;E-learning;Visualization;},
note = {Awareness;Dashboard;Learning analytics;Online learning;Social learning;Social presence;},
} 


@inproceedings{20193207285642 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Gathering researchers’ requirements to develop a learning technologies dashboard},
journal = {Proceedings of the 12th IADIS International Conference Information Systems 2019, IS 2019},
author = {Mena, Miguel Alonso Canizares and Isaias, Pedro Teixeira},
year = {2019},
pages = {51 - 59},
address = {Utrecht, Netherlands},
abstract = {<div data-language="eng" data-ev-field="abstract">The learning technologies area has expanded incredibly fast due to the growing and acceptance of technology in the classrooms. As a result, the data produced by students is vast and is growing in each of the learning technologies used, leading to a possibility of discovering patterns that can help to enhance the student experience. However, a clear research regarding the adoption of learning technologies and how to spread this research is limited and almost inexistent. Most of the research revolves around students or teachers disregarding the researcher’s standpoint. All the tools and artefacts such as dashboards that have helped to improve both students and teachers’ knowledge are absent for researchers. Hence, this paper is aimed on finding and defining the most common learning technologies platforms and tools as well as the user requirements to build a dashboard to display this information considering the researchers’ objectives. In this regard, an online survey was created and sent to both researchers interested in the learning technology area and learning technologies designers. The responses were analysed with quantitative tools such as exploratory factor analysis, analysis of variance, t-tests and graphical means. The results led to the user requirements for developing a dashboard.<br/></div> © 2019 IADIS Press. All rights reserved.},
key = {Students},
keywords = {Factor analysis;Engineering education;E-learning;},
note = {Acceptance of technologies;Exploratory factor analysis;Learning Analytics;Learning technology;Quantitative research;Quantitative tool;Student experiences;User requirements;},
URL = {http://dx.doi.org/10.33965/is2019_201905l007},
} 


@inproceedings{20201308362480 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How patterns of students dashboard use are related to their achievement and self-regulatory engagement},
journal = {ACM International Conference Proceeding Series},
author = {Kia, Fatemeh Salehian and Teasley, Stephanie D. and Hatala, Marek and Karabenick, Stuart A. and Kay, Matthew},
year = {2020},
pages = {340 - 349},
address = {Frankfurt, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">The aim of student-facing dashboards is to support learning by providing students with actionable information and promoting selfregulated learning. We created a new dashboard design aligned with SRL theory, called MyLA, to better understand how students use a learning analytics tool. We conducted sequence analysis on students' interactions with three different visualizations in the dashboard, implemented in a LMS, for a large number of students (860) in ten courses representing different disciplines. To evaluate different students' experiences with the dashboard, we computed chi-squared tests of independence on dashboard users (52%) to find frequent patterns that discriminate students by their differences in academic achievement and self-regulated learning behaviors. The results revealed discriminating patterns in dashboard use among different levels of academic achievement and self-regulated learning, particularly for low achieving students and high self-regulated learners. Our findings highlight the importance of differences in students' experience with a student-facing dashboard, and emphasize that one size does not fit all in the design of learning analytics tools.<br/></div> © 2020 Copyright held by the owner/author(s).},
key = {Students},
keywords = {Facings;},
note = {Academic achievements;Chi-Squared test;Low-achieving students;Self-regulated learning;Self-regulated learning behaviors;Sequence analysis;Sequential-pattern mining;Support learning;},
URL = {http://dx.doi.org/10.1145/3375462.3375472},
} 


@inproceedings{20172903950794 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Systematizing game learning analytics for serious games},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Alonso-Fernandez, Cristina and Calvo, Antonio and Freire, Manuel and Martinez-Ortiz, Ivan and Fernandez-Manjon, Baltasar},
volume = {0},
year = {2017},
pages = {1111 - 1118},
issn = {21659559},
address = {Athens, Greece},
abstract = {Applying games in education provides multiple benefits clearly visible in entertainment games: their engaging, goal-oriented nature encourages students to improve while they play. Educational games, also known as Serious Games (SGs) are video games designed with a main purpose other than pure entertainment; their main purpose may be to teach, to change an attitude or behavior, or to create awareness of a certain issue. As educators and game developers, the validity and effectiveness of these games towards their defined educational purposes needs to be both measurable and measured. Fortunately, the highly interactive nature of games makes the application of Learning Analytics (LA) perfect to capture students' interaction data with the purpose of better understanding or improving the learning process. However, there is a lack of widely adopted standards to communicate information between games and their tracking modules. Game Learning Analytics (GLA) combines the educational goals of LA with technologies that are commonplace in Game Analytics (GA), and also suffers from a lack of standards adoption that would facilitate its use across different SGs. In this paper, we describe two key steps towards the systematization of GLA: 1), the use of a newly-proposed standard tracking model to exchange information between the SG and the analytics platform, allowing reusable tracker components to be developed for each game engine or development platform; and 2), the use of standardized analysis and visualization assets to provide general but useful information for any SG that sends its data in the aforementioned format. These analysis and visualizations can be further customized and adapted for particular games when needed. We examine the use of this complete standard model in the GLA system currently under development for use in two EU H2020 SG projects.<br/> © 2017 IEEE.},
key = {Serious games},
keywords = {Learning systems;Human computer interaction;Students;Visualization;Information use;Interactive computer graphics;Computer software reusability;Education computing;},
note = {Dashboard;Development platform;Educational game;Educational goals;Game analytics;Learning process;Standards adoptions;XAPI;},
URL = {http://dx.doi.org/10.1109/EDUCON.2017.7942988},
} 


@article{20172903957386 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics Dashboards to Support Adviser-Student Dialogue},
journal = {IEEE Transactions on Learning Technologies},
author = {Charleer, Sven and Moere, Andrew Vande and Klerkx, Joris and Verbert, Katrien and De Laet, Tinne},
volume = {11},
number = {3},
year = {2018},
pages = {389 - 399},
issn = {19391382},
abstract = {This paper presents LISSA ("Learning dashboard for Insights and Support during Study Advice"), a learning analytics dashboard designed, developed, and evaluated in collaboration with study advisers. The overall objective is to facilitate communication between study advisers and students by visualizing grade data that is commonly available in any institution. More specifically, the dashboard attempts to support the dialogue between adviser and student through an overview of study progress, peer comparison, and by triggering insights based on facts as a starting point for discussion and argumentation. We report on the iterative design process and evaluation results of a deployment in 97 advising sessions. We have found that the dashboard supports the current adviser-student dialogue, helps them motivate students, triggers conversation, and provides tools to add personalization, depth, and nuance to the advising session. It provides insights at a factual, interpretative, and reflective level and allows both adviser and student to take an active role during the session.<br/> © 2018 IEEE.},
key = {Students},
keywords = {Information systems;},
note = {Evaluation results;Information visualization;Iterative design;Learning technology;Personalizations;},
URL = {http://dx.doi.org/10.1109/TLT.2017.2720670},
} 


@inproceedings{20173804195056 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Effects of a teacher dashboard for an intelligent tutoring system on teacher knowledge, lesson planning, lessons and student learning},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Xhakaj, Franceska and Aleven, Vincent and McLaren, Bruce M.},
volume = {10474 LNCS},
year = {2017},
pages = {315 - 329},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {Intelligent Tutoring Systems (ITSs) help students learn but often are not designed to support teachers and their practices. A dashboard with analytics about students’ learning processes might help in this regard. However, little research has investigated how dashboards influence teacher practices in the classroom and whether they can help improve student learning. In this paper, we explore how Luna, a dashboard prototype designed for an ITS and used with real data, affects teachers and students. Results from a quasi-experimental classroom study with 5 middle school teachers and 17 classes show that Luna influences what teachers know about their students’ learning in the ITS and that the teachers’ updated knowledge affects the lesson plan they prepare, which in turn guides what they cover in a class session. Results did not confirm that Luna increased student learning. In summary, even though teachers generally know their classes well, a dashboard with analytics from an ITS can still enhance their knowledge about their students and support their classroom practices. The teachers tended to focus primarily on dashboard information about the challenges their students were experiencing. To the best of our knowledge, this is the first study that demonstrates that a dashboard for an ITS can affect teacher knowledge, decision-making and actions in the classroom.<br/> © Springer International Publishing AG 2017.},
key = {Students},
keywords = {Computer aided instruction;Intelligent vehicle highway systems;Education computing;Decision making;Planning;Teaching;},
note = {Classroom practices;Dashboard;Data driven;Intelligent tutoring system;Intelligent tutoring system (ITSs);Learning analytics;Learning process;Teacher practices;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_23},
} 


@inproceedings{20180704787111 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A demonstration of evidence-based action research using information dashboard in introductory programming education},
journal = {IFIP Advances in Information and Communication Technology},
author = {Matsuzawa, Yoshiaki and Tanaka, Yoshiki and Kitani, Tomoya and Sakai, Sanshiro},
volume = {515},
year = {2017},
pages = {619 - 629},
issn = {18684238},
address = {Dublin, Ireland},
abstract = {In this paper, we demonstrated an evidence-based action research in an introductory programming class with the use of an information dashboard which provides coding metrics to visualize students’ engagement of their assignments. The information dashboard was designed for teachers to improve their classroom teaching using the same coding metrics which was verified in our previous research [9]. The system was equipped with a cross-filter functionality for exploring the entire classroom metrics. Accordingly, teachers can easily conduct a temporal analysis, an across-year comparison, and a cross metrics analysis. We examined the system for the improvement of the 5th year course using a dataset from the past four years from a non-CS introductory programming course at a university. Qualitative analysis was conducted using the discourse between teachers and teaching assistants with the proposed dashboard. The results showed that the system succeeded in promoting discourse, which included a clearer understanding of the class and its improvement, such as teaching method, assignments, or of students’ behavior.<br/> © 2017, IFIP International Federation for Information Processing.},
key = {Teaching},
keywords = {Information use;Students;},
note = {Action research;Information dashboard;Introductory programming;Introductory programming course;Learning analytics;Programming education;Qualitative analysis;Teaching assistants;},
URL = {http://dx.doi.org/10.1007/978-3-319-74310-3_62},
} 


@inproceedings{20161402179367 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards textual reporting in learning analytics dashboards},
journal = {Proceedings - IEEE 15th International Conference on Advanced Learning Technologies: Advanced Technologies for Supporting Open Access to Formal and Informal Learning, ICALT 2015},
author = {Ramos-Soto, A. and Lama, M. and Vazquez-Barreiros, B. and Bugarin, A. and Mucientes, M. and Barro, S.},
year = {2015},
pages = {260 - 264},
address = {Hualien, Taiwan},
abstract = {In this paper we present the Soft Learn Activity Reporter (SLAR) service which automatically generates textual short-term reports about learners' behavior in virtual learning environments. Through this approach, we show how textual reporting is a coherent way of providing information that can complement (and even enhance) visual statistics and help teachers to understand in a comprehensible manner the behavior of their students during the course. This solution extracts relevant information from the students' activity and encodes it into intermediate descriptions using linguistic variables and temporal references, which are subsequently translated into texts in natural language. The examples of application on real data from an undergraduate course supported by the Soft Learn platform show that automatic textual reporting is a valuable complementary tool for explaining teachers and learners the information comprised in a Learning Analytics Dashboard.<br/> © 2015 IEEE.},
key = {Linguistics},
keywords = {Computer aided instruction;Teaching;Learning systems;Natural language processing systems;},
note = {Complementary tools;Learning Analytics Dashboard;Linguistic descriptions;Linguistic variable;Natural language generation;Natural languages;Undergraduate Courses;Virtual learning environments;},
URL = {http://dx.doi.org/10.1109/ICALT.2015.96},
} 


@inproceedings{20203209028830 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {On the Design of a Teachers’ Dashboard: Requirements and Insights},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Isaias, Pedro and Backx Noronha Viana, Adriana},
volume = {12205 LNCS},
year = {2020},
pages = {255 - 269},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {The value that data has in the information society is undeniable. However data per se has limited significance, as it requires structure and it needs to be adequately conveyed to the user. Education is no exception to all the sectors currently harnessing the power of the data that stems from the interaction with their various stakeholders. Learning analytics can assist educators to understand how their students are learning, how successful they are at the accomplishment of certain tasks and to identify if they are at risk of failing. A fundamental part of learning analytics is visualisation, which is responsible for the communication of the data that is collected and becomes central in determining the teacher intervention in the learning process. In this paper the authors will present the results of semi-structured interviews that were conducted with lecturers at UNIV faculties and schools, in order to collect their insights regarding what aspects should be considered when design a teachers dashboard. Main requirements as well as major concerns are compiled and discussed. This is specifically useful to guide the future design of a teacher dashboard at UNIV and other universities.<br/> © 2020, Springer Nature Switzerland AG.},
note = {Future designs;Information society;Learning process;Semi structured interviews;},
URL = {http://dx.doi.org/10.1007/978-3-030-50513-4_19},
} 


@inproceedings{20162702561728 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Fostering 21st century literacies through a collaborative critical reading and learning analytics environment: Userperceived benefits and problematic},
journal = {ACM International Conference Proceeding Series},
author = {Tan, Jennifer Pei-Ling and Yang, Simon and Koh, Elizabeth and Jonathan, Christin},
volume = {25-29-April-2016},
year = {2016},
pages = {430 - 434},
address = {Edinburgh, United kingdom},
abstract = {The affordances of learning analytics (LA) are being increasingly harnessed to enhance 21st century (21C) pedagogy and learning. Relatively rare, however, are use cases and empirically based understandings of students' actual experiences with LA tools and environments at fostering 21C literacies, especially in secondary schooling and Asian education contexts. This paper addresses this knowledge gap by 1) presenting a first iteration design of a computer-supported collaborative critical reading and LA environment and its 16-week implementation in a Singapore high school; and 2) foregrounding students' quantitative and qualitative accounts of the benefits and problematics associated with this learning innovation. We focus the analytic lens on the LA dashboard components that provided visualizations of students' reading achievement, 21C learning dispositions, critical literacy competencies and social learning network positioning within the class. The paper aims to provide insights into the potentialities, paradoxes and pathways forward for designing LA that take into consideration the voices of learners as critical stakeholders.<br/> © 2016 Copyright held by the owner/author(s).},
key = {Students},
note = {21st century skills;Affordances;Critical literacy;CSCL;High school;Knowledge gaps;Learning analytics;Social learning;},
URL = {http://dx.doi.org/10.1145/2883851.2883965},
} 


@inproceedings{20174904514025 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Dashboard for actionable feedback on learning skills: How learner profile affects use},
journal = {CEUR Workshop Proceedings},
author = {Broos, Tom and Peeters, Laurie and Verbert, Katrien and Van Soom, Carolien and Langie, Greet and De Laet, Tinne},
volume = {1997},
year = {2017},
issn = {16130073},
address = {Tallinn, Estonia},
abstract = {Learning Analytics Dashboards (LAD) provide a means to leverage data to support learners, teachers, and counselors. This paper reports on an in-depth analysis of how learners interact with a LAD. N=1,406 first-year students in 12 different study programs were invited to use a LAD to support them in their transition from secondary to higher education. The LAD provides actionable feedback about five of the learning skills assessed by the Learning and Study Strategies Inventory (LASSI): concentration, anxiety, motivation, test strategies, and time management. We logged access to and behavior within the LAD and analyzed their relationship with these learning skills. While eight out of ten students accessed the LAD, students with lower time management scores tend to have a lower click-trough rate. Once within the LAD, students with lower scores for specific learning skills are accessing the corresponding information and remediation possibilities more often. Regardless of their scores for any of the other learning skills, learners with higher motivation scores are reading the remediation possibilities for the other four learning skills more often. Gender and study program have an influence on how learners use the LAD. Our findings may help both researchers and practitioners by creating awareness about how LAD use in itself may depend on the context and profile of the learner.<br/>},
key = {Students},
keywords = {Learning systems;Teaching;Motivation;},
note = {First year;First year students;Higher education;In-depth analysis;Learner profiles;Learning analytics dashboard;Learning skills;Specific learning;},
} 


@inproceedings{20184005884921 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using learning analytics to support computer-assisted language learning},
journal = {Proceedings of the 25th International Conference on Computers in Education, ICCE 2017 - Main Conference Proceedings},
author = {Li, Huiyong and Ogata, Hiroaki and Tsuchiya, Tomoyuki and Suzuki, Yubun and Uchida, Satoru and Ohashi, Hiroshi and Konomi, Shin'ichi},
year = {2017},
pages = {908 - 913},
address = {Christchurch, New zealand},
abstract = {Computer-assisted language learning (CALL) is often used as an approach to foreign language teaching and learning in higher education. The CALL course is offered at a national university in Japan to allow freshman students to perform self-regulated learning with e-learning materials for the purpose of developing language skills. However, as novice self-regulated learners, freshman students have low self-regulation skills and they are more likely to obtain lower achievement. In addition, it is difficult for instructors to grasp students' learning situation due to the large amount of evaluation work. Therefore, in this research, a total of 7,413,397 learning logs were analyzed, which were collected from 2,499 students' learning interactions in the CALL course. After that, a learning support system for freshman students is proposed. The system is provided for students and instructors through the learning dashboard. On the one hand, students can conduct self-monitoring and reflect their behaviors in a visual way. On the other hand, instructors can identify learning behavioral patterns and grasp individual learning situation to provide one-on-one instructions.<br/> © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.},
key = {Students},
keywords = {Linguistics;Teaching;Computer aided instruction;Curricula;E-learning;Learning systems;},
note = {Computer assisted language learning;E-learning materials;Foreign language teaching;Individual learning;Learning analytics;Learning interactions;Learning support systems;Self-regulated learning;},
} 


@article{20230513508812 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Drill-Down Dashboard for Coordination of Master Programmes in Engineering},
journal = {ProQuest Dissertations and Theses Global},
author = {e Silva, Anabela Costa},
year = {2020},
abstract = {<div data-language="eng" data-ev-field="abstract">Online masters program coordinators need information promptly to monitor efficiently and effectively all the courses in the program they are responsible for.Learning Management Systems (LMS) supporting the operation of the online programme collect vast amounts of data about the learning process. These systems are geared to support teachers and students, and not to support master program’s coordinators in their monitor role.Thus, it is proposed to create a dashboard that provides master program’s coordinators with information relevant to their tasks. This information is aggregated (from all courses), contributing to improving decision making.This dissertation begins by presenting the bibliographic review of the related works in the areas of "Learning Dashboards" and "Learning Analytics". It describes the design and development of a dashboard to support the coordinators of master programs. It includes requirements gathering, through interviews, to determine the relevant tasks of the master program coordinators and the information to be used. It also includes an analysis of the data currently available in the LMS that can provide this information and a description of the prototyping process. ProQuest Subject Headings: Pedagogy, Information science, Engineering, Educational technology, Science education.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Educational technology},
keywords = {Curricula;Decision making;E-learning;Engineering education;Information management;Online systems;Teaching;},
note = {Distance-learning;Drill-down;Learning management system;Master programs;Online instructions;Online projects;Pedagogy;Program coordinators;Science;Science education;},
} 


@inproceedings{20163902850218 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics pilot with coach2 - Searching for effective mirroring},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Brouwer, Natasa and Bredeweg, Bert and Latour, Sander and Berg, Alan and van der Huizen, Gerben},
volume = {9891 LNCS},
year = {2016},
pages = {363 - 369},
issn = {03029743},
address = {Lyon, France},
abstract = {Coach2 project investigated usability and effectiveness of Learning Analytics in a group of Bachelor courses in the area of Computer Science. An advanced architecture was developed and implemented, including a standalone Learning Record Store for data storage and easy access to miscellaneous data, Machine Learning techniques for determining relevant predictors, and a dashboard for informing learners. The overall approach was based on mirroring, the idea that learners see themselves operating in the context of their peers. The results were informative in terms of pro’s and con’s regarding the design and approach. The treatment showed tendencies, but finding statistical significant results turned out difficult. This paper reports on the Coach2 project.<br/> © Springer International Publishing Switzerland 2016.},
key = {Learning systems},
keywords = {Digital storage;},
note = {Advanced architecture;Data storage;Higher education;Learning analytics;Learning record;Machine learning techniques;Mirroring;Usability and effectiveness;},
URL = {http://dx.doi.org/10.1007/978-3-319-45153-4_28},
} 


@inproceedings{20181705111641 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Multi-Institutional positioning test feedback dashboard for aspiring students lessons learnt from a case study in flanders},
journal = {ACM International Conference Proceeding Series},
author = {Broos, Tom and Verbert, Katrien and Langie, Greet and Van Soom, Carolien and De Laet, Tinne},
year = {2018},
pages = {51 - 55},
address = {Sydney, NSW, Australia},
abstract = {Our work focuses on a multi-institutional implementation and evaluation of a Learning Analytics Dashboards (LAD) at scale, providing feedback to N=337 aspiring STEM (science, technology, engineering and mathematics) students participating in a region-wide positioning test before entering the study program. Study advisors were closely involved in the design and evaluation of the dashboard. The multi-institutional context of our case study requires careful consideration of external stakeholders and data ownership and portability issues, which gives shape to the technical design of the LAD. Our approach confirms students as active agents with data ownership, using an anonymous feedback code to access the LAD and to enable students to share their data with institutions at their discretion. Other distinguishing features of the LAD are the support for active content contribution by study advisors and LAT<inf>E</inf>X typesetting of question item feedback to enhance visual recognizability. We present our lessons learnt from a first iteration in production.<br/> © 2018 Association for Computing Machinery.},
key = {Students},
keywords = {Engineering education;Software testing;},
note = {Active content;Design and evaluations;External stakeholders;Higher education;Institutional contexts;Learning analytics;Science , Technology , Engineering and Mathematics;Technical design;},
URL = {http://dx.doi.org/10.1145/3170358.3170419},
} 


@inproceedings{20203909216527 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Human-centered design of a dashboard on students’ revisions during writing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Conijn, Rianne and Van Waes, Luuk and van Zaanen, Menno},
volume = {12315 LNCS},
year = {2020},
pages = {30 - 44},
issn = {03029743},
address = {Heidelberg, Germany},
abstract = {Learning dashboards are often used to provide teachers with insight into students’ learning processes. However, simply providing teachers with data on students’ learning processes is not necessarily beneficial for improving learning and teaching; the data need to be actionable. Recently, human-centered learning analytics has been suggested as a solution to realize more effective and actionable dashboards. Accordingly, this study aims to identify how these human-centered approaches could be used to design an interpretable and actionable learning dashboard on students’ writing processes. The design consists of three iterative steps. First, visualizations on students’ revision process, created from keystroke data, were evaluated with writing researchers. Second, the updated visualizations were used to co-design a paper prototype of the dashboard within a focus group session with writing teachers. Finally, the paper prototype was transformed into a digital prototype and evaluated by teachers in individual user test interviews. The results showed that this approach was useful for designing an interpretable dashboard with envisioned actions, which could be further tested in classroom settings.<br/> © Springer Nature Switzerland AG 2020.},
key = {Students},
keywords = {Design;Visualization;Digital devices;},
note = {Classroom settings;Digital prototype;Focus groups;Human-centered designs;Improving learning;Learning process;Paper prototypes;Writing process;},
URL = {http://dx.doi.org/10.1007/978-3-030-57717-9_3},
} 


@inproceedings{20203109001415 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lu, Min and Chen, Li and Goda, Yoshiko and Shimada, Atsushi and Yamada, Masanori},
volume = {12203 LNCS},
year = {2020},
pages = {569 - 580},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {The existing researches and developments of dashboard visualizing results from learning analytics mainly serve the instructors instead of learners in a direct manner. Effective visualizations extracted from learning log data can help the students to reflect and compare studying activities and access their metacognition to improve their self-regulated learning. For such purposes, we designed a reading path graph for visualizing the studying activities on slide pages used as teaching materials in classes intuitively, as one of the key functions of the learning dashboard. By providing the comparisons between the user’s own situation and the class overview, the visualization is expected to motivate the further actions of using other tools of the learning dashboard and reflecting studies. This paper introduces our exploration of the data process flows of extracting necessary data from a large number of operational logs for the visualization, and the techniques and strategies applied for rendering the graphics effectively. We implemented the data processing module with Python3 and the web-based visualization module of the reading path graph with JavaScript based on D3.js considering the extensibilities. The issues engaged in the development of prototypes are discussed, which will lead to the improvement of future prototypes and better designs of user experiments for formative evaluations as the next step of this research.<br/> © 2020, Springer Nature Switzerland AG.},
key = {Visualization},
keywords = {Data visualization;Students;Data mining;Data handling;Flow graphs;Learning systems;},
note = {Formative evaluation;Meta cognitions;Metacognition;Processing modules;Self-regulated learning;Teaching materials;User experiments;Web-based visualization;},
URL = {http://dx.doi.org/10.1007/978-3-030-50344-4_41},
} 


@inproceedings{20205109649469 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student-Facing Educational Dashboard Design for Online Learners},
journal = {Proceedings - IEEE 18th International Conference on Dependable, Autonomic and Secure Computing, IEEE 18th International Conference on Pervasive Intelligence and Computing, IEEE 6th International Conference on Cloud and Big Data Computing and IEEE 5th Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2020},
author = {Farahmand, Arta and Dewan, M. Ali Akber and Lin, Fuhua},
year = {2020},
pages = {345 - 349},
address = {Virtual, Calgary, AB, Canada},
abstract = {The current shift from traditional classrooms to online learning in higher education calls for more attention to self-regulated learning. This research is motivated by the growing interest in potential of using learning analytics dashboard (LAD) to increase individuals' self-regulation by creating visibility into their performance in various applications. This study explores how data visualization can be integrated with online learning to improve learners' performance through enhancing their skills in planning and organization. We are working on the design of a comprehensive LAD, focusing on micro-level of learning analytics to support learning activities of students. The LAD includes the following two features to enhance students' self-regulation in online learning: (1) a function to track students' progress compared to other students' over time; (2) reminders to help students with upcoming deadlines and auto-generating to do lists. The hypothesis is that the LAD will increase students' engagement, motivation, and self-regulation in an online learning environment. This study is significant because it contributes to the body of knowledge by exploring how student-generated data can be used to improve self-regulated learning. The practical contribution of this study is to create a personalized LAD for students based on the learner-generated data to benefit students' organization skill, planning skill, and motivation.<br/> © 2020 IEEE.},
key = {Students},
keywords = {Deregulation;Data mining;E-learning;Information systems;Learning systems;Computer aided instruction;Data visualization;Visualization;Information management;},
note = {Body of knowledge;Higher education;Online learning;Online learning environment;Self regulation;Self-regulated learning;Students' engagements;Support learning;},
URL = {http://dx.doi.org/10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00067},
} 


@inproceedings{20173003976097 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Dashboard for actionable feedback on learning skills: Scalability and usefulness},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Broos, Tom and Peeters, Laurie and Verbert, Katrien and Van Soom, Carolien and Langie, Greet and De Laet, Tinne},
volume = {10296 LNCS},
year = {2017},
pages = {229 - 241},
issn = {03029743},
address = {Vancouver, BC, Canada},
abstract = {In the transition from secondary to higher education, students are expected to develop a set of learning skills. This paper reports on a dashboard implemented and designed to support this development, hereby bridging the gap between Learning Analytics research and the daily practice of supporting students. To demonstrate the scalability and usefulness of the dashboard, this paper reports on an intervention with 1406 first-year students in 12 different programs. The results show that the dashboard is perceived as clear and useful.While students not accessing the dashboard have lower learning skills, they make more use of the extra remediation possibilities in the dashboard.<br/> © Springer International Publishing AG 2017.},
key = {Scalability},
keywords = {Students;},
note = {First year students;Higher education;Learning analytics;Learning skills;Scalable;},
URL = {http://dx.doi.org/10.1007/978-3-319-58515-4_18},
} 


@inproceedings{20181705111642 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A qualitative evaluation of a learning dashboard to support advisor-Student dialogues},
journal = {ACM International Conference Proceeding Series},
author = {Millecamp, Martijn and Gutierrez, Francisco and Charleer, Sven and Verbert, Katrien and De Laet, Tinne},
year = {2018},
pages = {56 - 60},
address = {Sydney, NSW, Australia},
abstract = {This paper presents an evaluation of a learning dashboard that supports the dialogue between a student and a study advisor. The dashboard was designed, developed, and evaluated in collaboration with study advisers. To ensure scalability to other contexts, the dashboard uses data that is commonly available at any higher education institute. It visualizes the grades of the student, an overview of the progress through the year, his/her position in comparison with peers, sliders to plan the next years and a prediction of the length of the bachelor program for this student in years based on historic data. The dashboard was deployed at KU Leuven, Belgium and used in September 2017 to support 224 sessions between students and study advisers. We observed twenty of these conversations. We also collected feedback from 101 students with questionnaires. Results of our observations indicate that the dashboard primarily triggers insights at the beginning of a conversation. The number of insights and the level of these insights (factual, interpretative and reflective) depends on the context of the conversation. Most insights were triggered in conversations with students doubting to continue the program, indicating that our dashboard is useful to support difficult decision-making processes.<br/> © 2018 Association for Computing Machinery.},
key = {Students},
keywords = {Decision making;Information systems;Surveys;},
note = {Bachelor programs;Decision making process;Higher education;Information visualization;Insights;Learning analytics dashboards;Learning technology;Qualitative evaluations;},
URL = {http://dx.doi.org/10.1145/3170358.3170417},
} 


@inproceedings{20181605011842 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics in MOOCs: EMMA case},
journal = {Studies in Classification, Data Analysis, and Knowledge Organization},
author = {Eradze, Maka and Tammets, Kairit},
volume = {2},
year = {2017},
pages = {193 - 204},
issn = {14318814},
address = {Naples, Italy},
abstract = {The paper overviews the project—European Multiple MOOC Aggre-gator, EMMA for short, and its learning analytics system with the initial results. xAPI statements are used for designing learning analytics dashboards in order to provide instant feedback for learners and instructors. The paper presents dashboard visualizations and discusses the possibilities of use of EMMA learning analytics dashboard views for sensemaking and reflection of the MOOCs and MOOC experience. It investigates some of the MOOCs in EMMA platform as cases and analyzes the learning designs of those MOOCs. Recommendations of changes to learning designs based on learning analytics data are provided.<br/> © Springer International Publishing AG 2017.},
key = {Computers},
note = {Analytics systems;Learning designs;Sensemaking;},
URL = {http://dx.doi.org/10.1007/978-3-319-55477-8_18},
} 


@inproceedings{20192106941663 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a Dashboard to Support the Analysis of Multimodal Educational Data},
journal = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
author = {Villarroel, Rodolfo and Villalobos, Cristian and Merino, Erick and Barcelos, Thiago and Munoz, Roberto},
volume = {2018-November},
year = {2018},
issn = {15224902},
address = {Santiago, Chile},
abstract = {Learning analytics consists of gathering and analyzing data from students in order to understand complex aspects of the learning process and promote its improvement. Currently, there is a lack of tools that allow the visualization of multimodal data. In this paper, we present a visualizer that allows analyzing the data provided by a multimodal learning analytics software. The multimodal data visualizer, in addition to allowing to visualize 10 body postures, permits applying clustering techniques, such as k-means. As validation, we analyze the data provided of 43 engineering student presentations.<br/> © 2018 IEEE.},
key = {Data visualization},
keywords = {Students;K-means clustering;},
note = {Body postures;Clustering techniques;dashboard;kinect;Learning process;Multi-modal data;Multi-modal learning;Oral presentations;},
URL = {http://dx.doi.org/10.1109/SCCC.2018.8705240},
} 


@inproceedings{20162702561838 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Interactive surfaces and learning analytics: Data, orchestration aspects, pedagogical uses and challenges},
journal = {ACM International Conference Proceeding Series},
author = {Roberto, Martinez-Maldonado and Schneider, Bertrand and Charleer, Sven and Shum, Simon Buckingham and Klerkx, Joris and Duval, Erik},
volume = {25-29-April-2016},
year = {2016},
pages = {124 - 133},
address = {Edinburgh, United kingdom},
abstract = {The proliferation of varied types of multi-user interactive surfaces (such as digital whiteboards, tabletops and tangible interfaces) is opening a new range of applications in face-to-face (f2f) contexts. They offer unique opportunities for Learning Analytics (LA) by facilitating multi-user sensemaking of automatically captured digital footprints of students' f2f interactions. This paper presents an analysis of current research exploring learning analytics associated with the use of surface devices. We use a framework to analyse our first-hand experiences, and the small number of related deployments according to four dimensions: The orchestration aspects involved; the phases of the pedagogical practice that are supported; the target actors; and the levels of iteration of the LA process. The contribution of the paper is twofold: 1) a synthesis of conclusions that identify the degree of maturity, challenges and pedagogical opportunities of the existing applications of learning analytics and interactive surfaces; and 2) an analysis framework that can be used to characterise the design space of similar areas and LA applications.<br/> © 2016 ACM.},
key = {Groupware},
note = {Analysis frameworks;Awareness;Dashboard;Face to face;Interactive surfaces;Pedagogical practices;Studies in the wild;Tangible interfaces;},
URL = {http://dx.doi.org/10.1145/2883851.2883873},
} 


@inproceedings{20171003414257 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {VisCa: A dashboard system to visualize learning activities from e-learning platforms},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lin, Chan-Hsien and Hu, Shih-Shin and Lai, Horng-Yih and Chiang, Chieh-Feng and Tseng, Hsiao-Chien and Cheng, Yuan-Che},
volume = {10108 LNCS},
year = {2017},
pages = {422 - 427},
issn = {03029743},
address = {Rome, Italy},
abstract = {With the advance of ICT technology, the e-learning platform from higher education to K12 becomes increasingly prevalent in recent years. Furthermore, as the emerging trend of data science, several educational platforms have introduced learning analytics and data-driven learning in their system, leading to more adaptive and personalized learning services. Therefore, it is crucial time to develop a mechanism to manage and visualize the data of learning experience. To achieve this goal, we created a web-based dashboard system called VisCa to track, store, and show learning experience from e-learning platforms. The data model is based on the standard of Experience API (xAPI) to communicate with third-party platforms. The whole system brings a general framework for the data flow of learning experience, as well as supports the students and teachers to understand their leaning status. The development of this study will provide an infrastructure to collect the data of learning activities, which can be used for further learning analytics or data-driven learning in the future.<br/> © Springer International Publishing AG 2017.},
key = {Data visualization},
keywords = {Teaching;Data acquisition;E-learning;Education computing;},
note = {E-learning platforms;Educational platforms;Experience API;Learning Activity;Learning analytics;Learning experiences;Learning record;Personalized learning;},
URL = {http://dx.doi.org/10.1007/978-3-319-52836-6_44},
} 


@article{20171603588045 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Perceiving learning at a glance: A systematic literature review of learning dashboard research},
journal = {IEEE Transactions on Learning Technologies},
author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
volume = {10},
number = {1},
year = {2017},
pages = {30 - 41},
issn = {19391382},
abstract = {This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining. Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes. Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs). The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis. Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation. As the research field is still relatively young, most studies are exploratory and proof-of-concept. The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards. There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs.<br/> © 2008-2011 IEEE.},
key = {Data mining},
keywords = {Online systems;Data visualization;Information systems;},
note = {dashboards;Educational data mining;Information visualization;Learning analytics;Systematic Review;},
URL = {http://dx.doi.org/10.1109/TLT.2016.2599522},
} 


@inproceedings{20154701570306 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Exploring student interactions: Learning analytics tools for student tracking},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Conde, Miguel angel and Hernandez-Garcia, angel and Garcia-Penalvo, Francisco J. and Sein-Echaluce, Maria Luisa},
volume = {9192},
year = {2015},
pages = {50 - 61},
issn = {03029743},
address = {Los Angeles, CA, United states},
abstract = {This paper presents four categories of learning analytics tools: dashboards, ad hoc tools, tools for analysis of specific issues, and learning analytics frameworks, and details the characteristics of a selection of tools within each category: (1) Moodle Dashboard and Moodle default reporting tool; (2) Interactions and Teamwork Assessment Tool; (3) SNAPP, GraphFES and Moodle Engagement Analytics; and (4) VeLA and GISMO. The study investigates how these tools can be applied to the analysis of courses by using real data from a course that made intensive use of forums, wikis, web resources, videos, quizzes and assignments. The discussion that follows points out how the different tools complement each other, and suggests the implementation of basic dashboards in learning platforms and the use of external frameworks for learning analytics.<br/> © Springer International Publishing Switzerland 2015.},
key = {Students},
keywords = {Artificial intelligence;},
note = {Learning analytics;Learning platform;Moodle;Reporting tools;Student interactions;Student tracking;Teamwork assessments;User interaction;},
URL = {http://dx.doi.org/10.1007/978-3-319-20609-7_6},
} 


@inproceedings{20193707423991 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating student-facing learning analytics into pedagogical practice},
journal = {ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
author = {Kitto, Kirsty and Lupton, Mandy and Davis, Kate and Waters, Zak},
year = {2016},
pages = {338 - 347},
address = {Adelaide, SA, Australia},
abstract = {<div data-language="eng" data-ev-field="abstract">Despite a narrative that sees Learning Analytics (LA) as a field that enhances student learning, few student-facing solutions have been developed. A lack of tools enables a sophisticated student focus, and it is difficult for educators to imagine how data can be used in authentic practice. This is unfortunate, as LA has the potential to be a powerful tool for encouraging metacognition and reflection. We propose a series of learning design patterns that will help people to incorporate LA into their teaching protocols: do-analyse-change-reflect, active learning squared, and group contribution. We discuss these learning design patterns with reference to a case study provided by the Connected Learning Analytics (CLA) toolkit, demonstrating that student-facing learning analytics is not just a future possibility, but an area that is ripe for further development.<br/></div> © 2016 Deakin University. All Rights Reserved.},
key = {Students},
keywords = {Educational technology;Facings;},
note = {Connected learning analytic toolkit;Dashboard;Design Patterns;Learning analytic;Learning design pattern;Learning designs;Metacognition;Pedagogical practices;Pedagogy;Student learning;},
URL = {http://dx.doi.org/10.14742/apubs.2016.810},
} 


@inproceedings{20171403522328 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An outcome-based dashboard for Moodle and Open edX},
journal = {ACM International Conference Proceeding Series},
author = {Hu, Xiao and Hou, Xiangyu and Lei, Chi-Un and Yang, Chengrui and Ng, Jeremy},
year = {2017},
pages = {604 - 605},
address = {Vancouver, BC, Canada},
abstract = {This poster presents a cross-platform learning analytics dashboard on Moodle and Open edX for monitoring outcome-based learning progress. The dashboard visualizes students' interactions with the platforms in near real-time, aiming to help teachers and students monitor students' learning progress. The dashboard has been used in four large-size general education courses in a comprehensive university in Hong Kong, undergoing evaluation and improvement.<br/> © 2017 ACM.},
key = {Students},
keywords = {Teaching;},
note = {Cross-platform;Dashboard;Evaluation and improvement;General education;Learning progress;Moodle;Near-real time;Open edX, outcome-based learning;},
URL = {http://dx.doi.org/10.1145/3027385.3029483},
} 


@article{20162502527760 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Dashboard for analyzing ubiquitous learning log},
journal = {International Journal of Distance Education Technologies},
author = {Lkhagvasuren, Erdenesaikhan and Matsuura, Kenji and Mouri, Kousuke and Ogata, Hiroaki},
volume = {14},
number = {3},
year = {2016},
pages = {1 - 20},
issn = {15393100},
abstract = {Mobile and ubiquitous technologies have been applied to a wide range of learning fields such as science, social science, history and language learning. Many researchers have been investigating the development of ubiquitous learning environments; nevertheless, to date, there have not been enough research works related to the reflection, analysis and traces of learners' activities in the history of ubiquitous learning environment. Therefore this paper presents a research on the design and development of a dashboard function which proposes new opportunity for ubiquitous learning. The dashboard captures, analyzes and visualizes traces of learning activities in order to promote awareness and enables learners to reflect on their own activity and helps to recall what they have learned. An initial evaluation has been conducted with 14 international students. Results indicate that the dashboard is a useful tool for self-reflection on activities and recall what learners have learned by repeated quizzes.<br/> Copyright © 2016, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.},
key = {Social sciences computing},
keywords = {Learning systems;Computer aided instruction;},
note = {Dashboard;Design and Development;International students;Language learning;Learning analytics;Ubiquitous learning;Ubiquitous learning environment;Ubiquitous learning logs;},
URL = {http://dx.doi.org/10.4018/IJDET.2016070101},
} 


@inproceedings{20171103436090 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting competency-assessment through a learning analytics approach using enriched rubrics},
journal = {ACM International Conference Proceeding Series},
author = {Rayon, Alex and Guenaga, Mariluz and Nunez, Asier},
year = {2014},
pages = {291 - 298},
address = {Salamanca, Spain},
abstract = {Universities have increasingly emphasized competencies as central elements of students' development. However, the assessment of these competencies is not an easy task. The availability of data that learners generate in computer mediated learning offers great potential to study how learning takes place, and thus, to gather evidences for competency-assessment using enriched rubrics. The lack of data interoperability and the decentralization of those educational applications set out a challenge to exploit trace data. To face these problems we have designed and developed SCALA (Scalable Competence Assessment through a Learning Analytics approach), an analytics system that integrates usage-how the user interacts with resources-and social-how students and teachers interact among them-trace data to support competency assessment. The case study of SCALA presents teachers a dashboard with enriched rubrics of blended datasets obtained from six assessment learning activities, performed with a group of 28 students working teamwork competency. In terms of knowledge discovery, we obtain results applying clustering and association rule mining algorithms. Thus, we provide a visual analytics tool ready to support competency-assessment.<br/>},
key = {Interoperability},
keywords = {Students;Data integration;Data mining;Teaching;},
note = {Competence assessments;Competency assessment;Computer-mediated learning;Data interoperability;Educational Applications;Learning analytics;Learning dashboard;Rule mining algorithms;},
URL = {http://dx.doi.org/10.1145/2669711.2669913},
} 


@inproceedings{20161202131582 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Exploring inquiry-based learning analytics through interactive surfaces},
journal = {CEUR Workshop Proceedings},
author = {Charleer, Sven and Klerkx, Joris and Duval, Erik},
volume = {1518},
year = {2015},
pages = {32 - 35},
issn = {16130073},
address = {Poughkeepsie, NY, United states},
abstract = {Learning Analytics is about collecting traces that learners leave behind and using those traces to improve learning. Dashboard applications can visualize these traces to present learners and teachers with useful information. The work in this paper is based on traces from an inquiry-based learning (IBL) environment, where learners create hypotheses, discuss findings and collect data in the field using mobile devices. We present a work-in-progress that enables teachers and learners to gather around an interactive tabletop to explore the abundance of learning traces an IBL environment generates, and help collaboratively make sense of them, so as to facilitate insights.<br/>},
key = {Teaching},
keywords = {Learning systems;Information systems;},
note = {Awareness;Collaboration;Information visualization;Inquiry-based learning;Interactive surfaces;Learning analytics;Learning dashboards;Reection;Sense making;},
} 


@inproceedings{20160101749341 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using learning analytics to visualise computer science teamwork},
journal = {Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
author = {Tarmazdi, Harmid and Vivian, Rebecca and Szabo, Claudia and Falkner, Katrina and Falkner, Nickolas},
volume = {2015-June},
year = {2015},
pages = {165 - 170},
issn = {1942647X},
address = {Vilnius, Lithuania},
abstract = {Industry has called upon academia to better prepare Computer Science graduates for teamwork, especially in developing the soft skills necessary for collaborative work. However, the teaching and assessment of teamwork is not easy, with instructors being pressed for time and a lack of tools available to efficiently analyse student teamwork, where large cohorts are involved. We have developed a teamwork dashboard, founded on learning analytics, learning theory and teamwork models that analyses students' online teamwork discussion data and visualises the team mood, role distribution and emotional climate. This tool allows educators to easily monitor teams in real-time. Educators may use the tool to provide students with feedback about team interactions as well as to identify problematic teams. We present a case study, trialing the dashboard on one university Computer Science course and include reflections from the course lecturer to determine its utility in monitoring online student teamwork.<br/> Copyright 2015 ACM.},
key = {Students},
keywords = {Climate models;Curricula;Teaching;Education computing;},
note = {Collaboration;Collaborative Work;Computer Science course;Computer Science Education;Learning analytics;Monitoring on line;Teaching and assessments;Teamwork discussions;},
URL = {http://dx.doi.org/10.1145/2729094.2742613},
} 


@inproceedings{20204809538964 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student Perception of a Learner Dashboard in MOOCs to Encourage Self-Regulated Learning},
journal = {TALE 2019 - 2019 IEEE International Conference on Engineering, Technology and Education},
author = {Rohloff, Tobias and Sauer, Dominic and Meinel, Christoph},
year = {2019},
address = {Yogyakarta, Indonesia},
abstract = {In online learning environments like Massive Open Online Courses (MOOCs), where teachers cannot provide individual support and guidance for thousands of students, self-regulated learning (SRL) is a critical metacognitive skillset for students' achievement. However, not every student intuitively self-regulates its learning and therefore technical solutions can help to apply SRL strategies. Learner dashboards with visualizations about the learner's progress and behavior are able to create awareness, encourage self-reflection, and perhaps motivate students to plan and adjust their learning behavior to achieve their learning objectives. Hence, such Learning Analytics tools can support the SRL strategies self-evaluation and strategic planning. To examine this potential, a learner dashboard was integrated into the HPI MOOC platform. This work presents the design process, the concept, and an evaluation of the first dashboard iteration. The perceived usefulness and usability are investigated, and in addition, the question will be considered whether the dashboard encourages students to apply self-regulated learning. The positive results pave the way for future research and a next iteration of the learner dashboard.<br/> © 2019 IEEE.},
key = {Students},
keywords = {Curricula;E-learning;Computer aided instruction;},
note = {Learning behavior;Learning objectives;Massive open online course;Online learning environment;Perceived usefulness;Self-regulated learning;Student perceptions;Technical solutions;},
URL = {http://dx.doi.org/10.1109/TALE48000.2019.9225939},
} 


@inproceedings{20193507381526 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Extending a dashboard meta-model to account for users’ characteristics and goals for enhancing personalization},
journal = {CEUR Workshop Proceedings},
author = {Vazquez-Ingelmo, Andrea and Garcia-Penalvo, Francisco Jose and Theron, Roberto and Conde, Miguel angel},
volume = {2415},
year = {2019},
pages = {35 - 42},
issn = {16130073},
address = {Vigo, Spain},
abstract = {Information dashboards are useful tools for exploiting datasets and support decision-making processes. However, these tools are not trivial to design and build. Information dashboards not only involve a set of visualizations and handlers to manage the presented data, but also a set of users that will potentially benefit from the knowledge generated by interacting with the data. It is important to know and understand the requirements of the final users of a dashboard because they will influence the design processes. But several user profiles can be involved, making these processes even more complicated. This paper identifies and discusses why it is essential to include the final users when modeling a dashboard. Through meta-modeling, different characteristics of potential users are structured, thus obtaining a meta-model that dissects not only technical and functional features of a dashboard (from an abstract point of view) but also the different aspects of the final users that will make use of it. By identifying these user characteristics and by arranging them into a meta-model, software engineering paradigms such as model-driven development or software product lines can employ it as an input for generating concrete dashboard products. This approach could be useful for generating Learning Analytics dashboards that take into account the users' motivations, beliefs, and knowledge.<br/> Copyright © 2019 for the individual papers by the papers' authors.},
key = {Visualization},
keywords = {Information use;Information systems;Software architecture;Decision making;User profile;},
note = {Decision making process;Information dashboards;Information visualization;Meta model;Model driven development;Software engineering paradigm;Technical and functional features;User Modeling;},
} 


@inproceedings{20203909216553 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {For learners, with learners: Identifying indicators for an academic advising dashboard for students},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hilliger, Isabel and De Laet, Tinne and Henriquez, Valeria and Guerra, Julio and Ortiz-Rojas, Margarita and Zuniga, Miguel angel and Baier, Jorge and Perez-Sanagustin, Mar},
volume = {12315 LNCS},
year = {2020},
pages = {117 - 130},
issn = {03029743},
address = {Heidelberg, Germany},
abstract = {Learning Analytics (LA) dashboards aggregate indicators about student performance and demographics to support academic advising. The majority of existing dashboards are targeted at advisors and professors, but not much attention has been put into students’ need for information for their own academic decision-making. In this study, we identify relevant indicators from a student perspective using a mixed methods approach. Qualitative data was obtained from an open-ended online questionnaire answered by 31 student representatives, and quantitative data was collected from a closed-ended online questionnaire answered by 652 students from different cohorts. Findings point out relevant indicators to help students choose what courses to take in an upcoming academic period. Since this study is part of a large research project that has motivated the adoption of academic advising dashboards in different Latin American universities, these findings were also contrasted with indicators of these advising dashboards, informing future developments targeting students.<br/> © Springer Nature Switzerland AG 2020.},
key = {Students},
keywords = {Decision making;Surveys;},
note = {Academic advising;Latin americans;Mixed method;Online questionnaire;Qualitative data;Quantitative data;Student performance;Student perspectives;},
URL = {http://dx.doi.org/10.1007/978-3-030-57717-9_9},
} 


@inproceedings{20171403522599 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An instructor dashboard for real-time analytics in interactive programming assignments},
journal = {ACM International Conference Proceeding Series},
author = {Diana, Nicholas and Grover, Shuchi and Eagle, Michael and Bienkowski, Marie and Stamper, John and Basu, Satabdi},
year = {2017},
pages = {272 - 279},
address = {Vancouver, BC, Canada},
abstract = {Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well.<br/> © 2017 ACM.},
key = {Students},
keywords = {Education computing;Predictive analytics;Learning systems;Teaching;},
note = {Dashboards;Introductory programming;Learning analytics;Peer tutors;Predictive models;Programming assignments;Real-time analytics;Student outcomes;},
URL = {http://dx.doi.org/10.1145/3027385.3027441},
} 


@inproceedings{20144600197862 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data depository: Business & learning analytics for educational web applications},
journal = {Proceedings - IEEE 14th International Conference on Advanced Learning Technologies, ICALT 2014},
author = {Malhotra, Manav and Hsiao, I-Han and Chae, Hui Soo and Natriello, Gary},
year = {2014},
pages = {363 - 364},
address = {Athens, Greece},
abstract = {Quantitative methods in education research have long been limited by the ability to collect detailed learner data in a consistent, scalable way. As education continues to move online we are presented with an unprecedented opportunity to study learner interactions within learning systems. However, doing so requires infrastructure to collect and store massive interaction data from which we can learn. In this paper we present Data Depository, a flexible, pluggable, data hub for tracking interaction data from any browser-based application, aiding the measurement of usage and effectiveness.<br/> © 2014 IEEE.},
key = {Learning systems},
keywords = {Online systems;},
note = {Browser-based application;dashboard;depository;Education research;Learner interaction;learning analytics;Quantitative method;User interaction;},
URL = {http://dx.doi.org/10.1109/ICALT.2014.237},
} 


@inproceedings{20174804462098 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The university of Southampton MOOC observatory dashboard},
journal = {CEUR Workshop Proceedings},
author = {Leon-Urrutia, Manuel and Tang, Darron},
volume = {1967},
year = {2017},
pages = {8 - 19},
issn = {16130073},
address = {Vancouver, BC, Canada},
abstract = {The University of Southampton MOOC Observatory Dashboard (UoSMOD) is an application that visualises near-to-real time data from Future-Learn courses. The intended end users of this tool are those who are involved in MOOC development and delivery such as mentors, educators, learning designers, researchers, programme leaders, and marketing officers. These different stakeholders (mentors, educators, learning designers, etc) are beneficiaries of different features of UoSMOD, who use them for different purposes. The tool downloads the data dumps that FutureLearn provides to their partners every 24 hours, and scrapes the courses metadata from the administration site of the platform. The data is managed in a MySQL database, and an R based environment called Shiny is used for its analysis and visualisation. These visualisations have been presented to mentors and learning designers. New features have been being added as a response to the feedback provided by its first users. Further iterations are in the pipeline, in this process of optimising a tool that exploits the data available in the most usable way as possible.<br/> Copyright © 2017 for the individual papers by the papers' authors.},
key = {Observatories},
keywords = {Curricula;Visualization;},
note = {Dashboards;End users;Learning analytics;MOOCs;MySQL database;Real-time data;University of Southampton;},
} 


@inproceedings{20183405715610 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {XIPIt: Updating the XIP dashboard to support educators in essay marking at higher education},
journal = {Proceedings of the 5th Annual ACM Conference on Learning at Scale, L at S 2018},
author = {Bektik, Duygu},
year = {2017},
address = {London, United kingdom},
abstract = {Effective written communication is an essential skill which promotes educational success for undergraduates. However, undergraduate students, especially those in their first year at university, are unused to this form of writing. After their long experience with the schoolroom essay, for most undergraduates academic writing development is painstakingly slow. Thus, especially those with poor writing abilities, should write more to be better writers. Yet, the biggest impediment to more writing is that overburdened tutors would ask limited number of drafts from their students. Today, there exist powerful computational language technologies that could evaluate student writing, saving time and providing timely, speedy, reliable feedback which can support educators marking process. This paper motivates an updated visual analytics dashboard, XIPIt, to introduce a set of visual and writing analytics features embedded in a marking environment built on XIP output.<br/> © 2017 Association for Computing Machinery. All rights reserved.},
key = {Students},
keywords = {Visualization;},
note = {Academic writings;Computational languages;Learning Analytics;Undergraduate students;Visual analytics;Visual Dashboards;Writing abilities;Written communications;},
URL = {http://dx.doi.org/10.1145/3231644.3231696},
} 


@inproceedings{20144800257944 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {LARAe: Learning analytics reflection & awareness environment},
journal = {CEUR Workshop Proceedings},
author = {Charleer, Sven and Santos, Jose Luis and Klerkx, Joris and Duval, Erik},
volume = {1238},
year = {2014},
pages = {85 - 87},
issn = {16130073},
address = {Graz, Austria},
abstract = {Exploring and managing the abundance of data that Learning Analytics generate is a challenge for both teachers and students. This paper introduces a Learning Dashboard that provides an overview, context and content of learner traces to help students with awareness of feedback and progress, and assist teachers with monitoring student effort and outcomes to intervene where needed.<br/>},
key = {Students},
keywords = {Teaching;Information systems;},
note = {Awareness;Effort;Information visualization;Inquiry-based learning;Intervention;Learning analytics;Learning dashboards;},
} 


@inproceedings{20162702561764 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning analytics in practice The effects of adaptive educational technology Snappet on students' arithmetic skills},
journal = {ACM International Conference Proceeding Series},
author = {Molenaar, Inge and Campen, Carolien Knoop-Van},
volume = {25-29-April-2016},
year = {2016},
pages = {538 - 539},
address = {Edinburgh, United kingdom},
abstract = {Even though the recent influx of tablets in primary education goes together with the vision that educational technology empowered with learning analytics will revolutionize education, empirical results supporting this claim are scares. Adaptive educational technology Snappet combines extracted and embedded learning analytics daily in classrooms. While students make exercises on the tablet this technology displays real-time data of learner performance in a teacher dashboard (extracted analytics). At the same time, learner performance is used to adaptively adjust exercises to students' progress (embedded analytics). This quasiexperimental study compares the development of students' arithmetic skills over one schoolyear (grade 2 and 4) in a traditional paper based setting to learning with the adaptive educational technology Snappet. The results indicate that students in the Snappet condition make significantly more progress on arithmetic skills in grade 4. Moreover, in this grade students with a high ability level, benefit the most from working with this adaptive educational technology. Overall the development pattern of students with different abilities was more divergent in the AET condition compared to the control condition. These results indicate that adaptive educational technologies combining extracted and embedded learning analytics are indeed creating new education scenarios that contribute to personalized learning in primary education.<br/> © 2016 Copyright held by the owner/author(s).},
key = {Educational technology},
keywords = {Learning systems;Students;Teaching;Engineering education;},
note = {Ability levels;Development patterns;Embedded learning;Personalized learning;Primary education;Real-time data;},
URL = {http://dx.doi.org/10.1145/2883851.2883892},
} 


@inproceedings{20171403522432 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {EMODA: A tutor oriented multimodal and contextual emotional dashboard},
journal = {ACM International Conference Proceeding Series},
author = {Ez-Zaouia, Mohamed and Lavoue, Elise},
year = {2017},
pages = {429 - 438},
address = {Vancouver, BC, Canada},
abstract = {Learners' emotional state has proven to be a key factor for successful learning. Visualizing learners' emotions during synchronous on-line learning activities can help tutors in creating and maintaining socio-affective relationships with their learners. However, few dashboards offer emotional information on the learning activity. The current study focuses on synchronous interactions via a videoconferencing tool dedicated to foreign language training. We collected data on learners' emotions in real conditions during ten sessions (five sessions for two learners). We propose to adopt and combine different models of emotions (discrete and dimensional) and to use heterogeneous APIs for measuring learners' emotions from different data sources (audio, video, self-reporting and interaction traces). Based on a thorough data analysis, we propose an approach to combine different cues to infer information on learners' emotional states. We finally present the EMODA dashboard, an affective multimodal and contextual visual analytics dashboard, which allows the tutor to monitor learners' emotions and better understand their evolution during the synchronous learning activity.<br/> © 2017 ACM.},
key = {Visualization},
keywords = {Learning systems;Video conferencing;},
note = {Emotional information;Emotions;Interactive visualizations;Learning Activity;Multi-modal data;Synchronous interactions;Synchronous learning;Tutor dashboard;},
URL = {http://dx.doi.org/10.1145/3027385.3027434},
} 


@inproceedings{20154501510814 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Standardized enriched rubrics to support competeney-assessment through the SCALA methodology and dashboard},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Guenaga, Mariluz and Longarte, Jon Kepa and Rayon, Alex},
volume = {2015-April},
year = {2015},
pages = {340 - 347},
issn = {21659559},
address = {Tallinn, Estonia},
abstract = {Universities have increasingly emphasized competencies as central elements of students' development. However, the assessment of these competencies is not an easy task. The availability of data that learners generate in computer mediated learning offers great potential to study how learning takes place, and thus, to gather evidences for competency-assessment using enriched rubrics. These are the so-called electronic assessment instruments. Among them, the enriched rubrics arises as a tool to improve the assessment process. However, the lack of data interoperability and the decentralization of those educational applications set out a challenge to exploit trace data. To face these problems we have designed and developed SCALA (Supporting Competency-Assessment through a Learning Analytics approach), an analytics system that integrates usage -how the user interacts with resources- and social -how students and teachers interact among them- trace data to support competency assessment. After presenting the components of SCALA (process, model and platform), we evaluate them presenting six scenarios to know whether it is viable in terms of time, sustainability and quality assurance to normalize the heterogeneous data present in technology-rich learning environments. The results show and confirm the viability of the proposed solution and the possibility to offer real-time feedback to the teachers to assess students'.<br/> © 2015 IEEE.},
key = {Students},
keywords = {Computer aided instruction;Quality assurance;Education computing;Teaching;},
note = {Assessment instruments;Competency assessment;Computer-mediated learning;Data interoperability;data workflow;Educational Applications;learning analytics;teacher dashboard;},
URL = {http://dx.doi.org/10.1109/EDUCON.2015.7095994},
} 


@inproceedings{20174804462099 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic dashboard for educators and students in FutureLearn MOOCs: Experiences and insights},
journal = {CEUR Workshop Proceedings},
author = {Vigentini, Lorenzo and Clayphan, Andrew and Chitsaz, Mahsa},
volume = {1967},
year = {2017},
pages = {20 - 35},
issn = {16130073},
address = {Vancouver, BC, Canada},
abstract = {One of the differentiating aspects of the FutureLearn platform, compared with other MOOC providers such as Coursera and EdX, is the approach to data sharing with partners. This is grounded on the release of a small set of relatively simple source files, which can be downloaded and used as required by end users (e.g. educators, researchers and so on). This approach has both advantages and disadvantages. The major advantage is the simplicity; the most important drawback is the lack of an 'out-of-the-box' set of analytical representations which the end-user can use and digest to obtain immediate insights regarding their online course. In this paper, we discuss these aspects in more detail and document the approach adopted at UNSW Sydney, to use the data as released, and how we produced a set of analytical dashboards for educators and students. The architecture underpinning the dashboards built is explained with a link to a GitHub repository with more detailed information.<br/> Copyright © 2017 for the individual papers by the papers' authors.},
note = {End users;FutureLearn;Learning analytics;MOOCs;Online course;Source files;},
} 


@inproceedings{20144600197937 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A flexible framework for the authoring of reusable and portable learning analytics gadgets},
journal = {Proceedings - IEEE 14th International Conference on Advanced Learning Technologies, ICALT 2014},
author = {Manske, Sven and Hecking, Tobias and Bollen, Lars and Gohnert, Tilman and Ramos, Alfredo and Hoppe, H. Ulrich},
year = {2014},
pages = {254 - 258},
address = {Athens, Greece},
abstract = {Technology supported learning is nowadays often based on heterogeneous environments that encompass not only one application and also possibly involve different devices. This creates specific challenges for data analysis and thus for learning analytics. In this paper, we propose a framework to create reusable learning analytics components that are portable to different target platforms. In this approach, the logic of each analysis component is specified in a separate web-based visual environment (or 'workbench') from where it is later exported to the target environments form of a gadget-based dashboard. We demonstrate this mechanism in the context of the Go-Lab portal for accessing remote laboratories in STEM learning scenarios. An example shows how such analytics gadgets can be used to support collaboration inside the classroom.<br/> © 2014 IEEE.},
key = {Computer software reusability},
note = {CSCL;Heterogeneous environments;Inquiry learning;learning analytics;Learning scenarios;Remote laboratories;Supported learning;Visual environments;},
URL = {http://dx.doi.org/10.1109/ICALT.2014.80},
} 


@inproceedings{20165103153791 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a teacher dashboard for use with intelligent tutoring systems},
journal = {CEUR Workshop Proceedings},
author = {Aleven, Vincent and Xhakaj, Franceska and Holstein, Kenneth and McLaren, Bruce M.},
volume = {1738},
year = {2016},
pages = {15 - 23},
issn = {16130073},
address = {Lyon, France},
abstract = {Many dashboards display analytics generated by educational technologies, but few of them work with intelligent tutoring systems (ITSs). We are creating a teacher dashboard for use with ITSs built and used within our CTAT/Tutorshop infrastructure: an environment for authoring and deploying ITSs. The dashboard will take advantage of the fine-grained interaction data and derived analytics that CTAT-built ITSs produce. We are taking a user-centered design approach in which we target two usage scenarios for the dashboard. In one scenario, a teacher uses the dashboard while helping a class of students working with the tutoring software in the school's computer lab. In the other, the teacher uses the dashboard to prepare for an upcoming class session. So far, we have completed a Contextual Inquiry, ideation, Speed Dating sessions in which teachers evaluated story boards, usability testing, and a classroom study with a mocked up version of the dashboard with real data from the teacher's current classes and students. We are currently analyzing the data produced in these activities, iterating on the design of the dashboard, and implementing a full version of the dashboard. Unique characteristics of this dashboard may be that it leverages finegrained interaction data produced by an ITS and that it will be fully integrated with an ITS development and deployment environment, and therefore available for use with many ITSs.<br/>},
key = {Students},
keywords = {Education computing;User centered design;Intelligent vehicle highway systems;Computer aided instruction;Teaching;},
note = {Blended learning;Dashboards;Intelligent tutoring system;Learning analytics;Student Modeling;},
} 


@inproceedings{20193707424058 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Toward the development of a dynamic dashboard for FutureLearn MOOCs: Insights and directions},
journal = {ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
author = {Chitsaz, Mahsa and Vigentini, Lorenzo and Clayphan, Andrew},
year = {2016},
pages = {116 - 121},
address = {Adelaide, SA, Australia},
abstract = {In recent years, many higher education institutions have invested in the development of Massive Open Online Courses (MOOCs). With the increase of available MOOC data, there is an opportunity to provide insights to educators and developers into learners’ behaviors through learning analytics. Focusing on the FutureLearn platform (FL), standardized data files are offered to partner institutions. Additionally, a report is offered to stakeholders, but it is limited in a number of ways: it is static, it is limited in presenting relevant information and, most importantly, it does not provide ‘real-time’ access to data. This paper provides an overview of the rationale and the development process of a dynamic and near real-time dashboard. It explores the viability of different types of visualizations with the available data, lessons learned, comparisons with similar efforts, and future directions are discussed.<br/> © 2016 Deakin University. All Rights Reserved.},
key = {Visualization},
keywords = {Educational technology;},
note = {Dashboards;Development process;FutureLearn MOOCs;Higher education institutions;Learning analytics;Massive open online course;Partner institutions;Sense making;},
} 


@inproceedings{20165103153790 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Luna: A dashboard for teachers using Intelligent Tutoring Systems},
journal = {CEUR Workshop Proceedings},
author = {Holstein, Kenneth and Xhakaj, Franceska and Aleven, Vincent and McLaren, Bruce},
volume = {1738},
year = {2016},
pages = {14 - 18},
issn = {16130073},
address = {Lyon, France},
abstract = {Intelligent Tutoring Systems (ITS) generate a wealth of finegrained student interaction data. Although it seems likely that teachers could benefit from access to advanced analytics generated from these data, ITSs do not typically come with dashboards designed for teachers' needs. In this project, we follow a user-centered design approach to create a dashboard for teachers using ITSs.<br/>},
key = {User centered design},
keywords = {Intelligent vehicle highway systems;Computer aided instruction;Teaching;Education computing;},
note = {Blended learning;Dashboards;Intelligent tutoring system;Learning analytics;Student Modeling;},
} 


@inproceedings{20162702561761 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Understanding learning at a glance: An overview of learning dashboard studies},
journal = {ACM International Conference Proceeding Series},
author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
volume = {25-29-April-2016},
year = {2016},
pages = {532 - 533},
address = {Edinburgh, United kingdom},
abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the fnal analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dash-board design options.<br/> © 2016 Copyright held by the owner/author(s).},
key = {Data mining},
note = {Dashboards;Educational data mining;Information VI- sualization;Learning analytics;Systematic Review;},
URL = {http://dx.doi.org/10.1145/2883851.2883930},
} 


@inproceedings{20134216854716 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards portable learning analytics dashboards},
journal = {Proceedings - 2013 IEEE 13th International Conference on Advanced Learning Technologies, ICALT 2013},
author = {Vozniuk, Andrii and Govaerts, Sten and Gillet, Denis},
year = {2013},
pages = {412 - 416},
address = {Beijing, China},
abstract = {This paper proposes a novel approach to build and deploy learning analytics dashboards in multiple learning environments. Existing learning dashboards are barely portable: once deployed on a learning platform, it requires considerable effort to deploy the dashboard elsewhere. We suggest constructing dashboards from lightweight web applications, namely widgets. Our approach allows to port dashboards with no additional cost between learning environments that implement open specifications (Open Social and Activity Streams) for data access and use widget APIs. We propose to facilitate reuse by sharing the dashboards and widgets via a centralized analytics repository. © 2013 IEEE.<br/>},
note = {ActivityStreams;dashboards;learning analytics;Open Standards;OpenSocial;widget;},
URL = {http://dx.doi.org/10.1109/ICALT.2013.126},
} 


@inproceedings{20142817919552 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Empowering L&D managers through customisation of inline learning analytics},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Kapros, Evangelos and Peirce, Neil},
volume = {8523 LNCS},
number = {PART 1},
year = {2014},
pages = {282 - 291},
issn = {03029743},
address = {Heraklion, Crete, Greece},
abstract = {Popular learning management systems (LMS) often feature dashboards displaying various analytics. This dashboard display might be suboptimal for some learning and development managers (L&D). Moreover, the analytics presented are often based on standardised quizzes or semesters, which might be unsuitable (e.g., informal learning, corporate education, etc.). Finally, each LMS has its bespoke reporting solution, thus making it difficult for L&D managers to monitor the situation across various LMSs. We propose an interactive system where an L&D manager can customise the data source, queries, filters, and visualisations of their LMSs, and display them inline. To this end, we have built EVADE, a system that allows L&D managers to capture data from various LMSs, analyse them, and embed related visualisations in each LMS. In this instance, we have integrated EVADE with a Moodle instance for corporate education, and Almanac, a tablet application for informal learning. In this paper we present EVADE and discuss how it can improve the L&D manager-LMS interaction. © 2014 Springer International Publishing.<br/>},
key = {Managers},
keywords = {Visualization;},
note = {Corporate Learning;Customisation;Data-source;Informal learning;Interactive system;Learning Analytics;Learning management system;Tablet applications;},
URL = {http://dx.doi.org/10.1007/978-3-319-07482-5_27},
} 


@inproceedings{20163902833229 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating and visualizing learner and social data to elicit higher-order indicators in SCALA dashboard},
journal = {ACM International Conference Proceeding Series},
author = {Rayon, Alex and Guenaga, Mariluz and Nunez, Asier},
volume = {16-19-September-2014},
year = {2014},
address = {Graz, Austria},
abstract = {The assessment of competencies is a difficult task; on one hand due to its subjective nature, and, on the other one, because of the difficulties to make it scalable and simple. Since ICT are becoming increasingly important learning mediating tools, data stored in learning tools could yield a wealth of information that could serve as an indicator to measure students' progress and the development of competencies. However, the lack of data interoperability among different educational applications imposes a challenge to data mining and analytics that rely on diverse and distributed data. Besides, these educational technologies do neither usually provide a statistics module in which the teacher can obtain specific reports about students' performance, nor visualization tools to summarize student usage data. In response to this weakness, and based on the limitations encountered in existing tools, we have developed an integrated and extensible web tool called SCALA (Scalable Competency Assessment through a Learning Analytics approach) that not only shows but also mines using analytics techniques for the discovery of student patterns and metric relations in web-based educational systems.<br/> © Copyright 2014 ACM.},
key = {Interoperability},
keywords = {Teaching;Data integration;Data visualization;Students;Data mining;Visualization;},
note = {Competency assessment;Dashboard;Data interoperability;Educational Applications;Learning analytics;Visual analytics;Wealth of information;Web-based educational systems;},
URL = {http://dx.doi.org/10.1145/2637748.2638435},
} 


@inproceedings{20152500962929 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Integrated Analytic dashboard for virtual evaluation laboratories and collaborative forums},
journal = {Proceedings of XI Tecnologias Aplicadas a la Ensenanza de la Electronica (Technologies Applied to Electronics Teaching), TAEE 2014},
author = {Tobarra, Llanos and Ros, Salvador and Hernandez, Roberto and Robles-Gomez, Antonio and Caminero, Agustin C. and Pastor, Rafael},
year = {2014},
pages = {BizkaiLab; Eusko Jaurlaritza - Gobierno Vasco - },
address = {Bilbao, Spain},
abstract = {This paper presents a new Learning Analytics dashboard which integrates all the information gathered by a virtual evaluation laboratory deployed at our institution and, also, the collaborative evaluation forums used by students in our courses. As an example, a subject focused on the configuration of network services has been chosen to implement our approach. Our proposal will be able to graphically show the students' progress both in an experimental and collaborative way at the same time. Therefore, lecturers can guide each student through the learning process based on his/her particular knowledge-level and grade her/him at the end of the term. Some specific techniques are needed by the system, in our case Learning Analytics techniques are used, in order to observe the students' behavior and their level of proficiency. In particular, a set of evaluation events for each activity, the students' social network, the students' timeline for their activities and some relevant metrics associated to them are given.<br/> © 2014 IEEE.},
key = {Students},
keywords = {Laboratories;Teaching;E-learning;},
note = {Collaborative evaluation;Collaborative Forums;Evaluation strategies;Knowledge level;Learning Analytics (LA);Learning process;Network services;Students' behaviors;},
URL = {http://dx.doi.org/10.1109/TAEE.2014.6900177},
} 


@inproceedings{20162802591787 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizing workplace learning data with the SSS dashboard},
journal = {CEUR Workshop Proceedings},
author = {Ruiz-Calleja, Adolfo and Dennerlein, Sebastian and Ley, Tobias and Lex, Elisabeth},
volume = {1601},
year = {2016},
pages = {79 - 86},
issn = {16130073},
address = {Edinburgh, Scotland, United kingdom},
abstract = {This paper reports the design and development of a visual Dashboard, called the SSS Dashboard, which visualizes data from informal workplace learning processes from different viewpoints. The SSS Dashboard retrieves its data from the Social Semantic Server (SSS), an infrastructure that integrates data from several workplace learning applications into a semantically-enriched Artifact-Actor Network. A first evaluation with end users in a course for professional teachers gave promising results. Both a trainer and a learner could understand the learning process from different perspectives using the SSS Dashboard. The results obtained will pave the way for the development of future Learning Analytics applications that exploit the data collected by the SSS.<br/> © Copyright 2016 for this paper by its authors.},
key = {Data visualization},
keywords = {Learning systems;Semantics;Teaching;},
note = {Actor-network;Design and Development;End users;ITS data;Learning process;Social semantics;Workplace learning;},
} 


@inproceedings{20142717899820 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning Analytics on federated remote laboratories: Tips and techniques},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Orduna, Pablo and Almeida, Aitor and Lopez-De-Ipina, Diego and Garcia-Zubia, Javier},
year = {2014},
pages = {299 - 305},
issn = {21659559},
address = {Istanbul, Turkey},
abstract = {A remote laboratory is a software and hardware tool which enables students to use real equipment -located in an educational institution- through the Internet. This way, students can experiment as if they were using the laboratories with their own hands. And, depending on the design, instructors can later see the results of these students. During the last decade, federation protocols to share remote laboratories have emerged. The focus of these protocols is to be make remote laboratories of one institution available in other in an automated manner, through institutional contracts. And these federation protocols usually rely on existing Remote Laboratory Management Systems (RLMS), which usually provide APIs for tracking student usage. At the same time, the interest on Learning Analytics is increasing. Learning Analytics focuses on the measurement and analysis of data about learners in their context. In the particular context of federated remote laboratories, new challenges arise: on the one hand, remote laboratories must be prepared to track insightful information from the student session so as to extract patterns, and on the other hand, the usage of a federated environment requires different degrees of anonymity. This contribution describes the new Learning Analytics dashboard of WebLab-Deusto, detailing what information can be extracted and how the usage of a RLMS simplifies the development of such tools in a federated environment. © 2014 IEEE.<br/>},
key = {Students},
keywords = {Distance education;Laboratories;},
note = {Educational institutions;Measurement and analysis;Remote laboratories;Software and hardwares;},
URL = {http://dx.doi.org/10.1109/EDUCON.2014.6826107},
} 


@inproceedings{20181705111645 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The classroom as a dashboard: Co-designing wearable cognitive augmentation for K-12 teachers},
journal = {ACM International Conference Proceeding Series},
author = {Holstein, Kenneth and Hong, Gena and Tegene, Mera and McLaren, Bruce M. and Aleven, Vincent},
year = {2018},
pages = {79 - 88},
address = {Sydney, NSW, Australia},
abstract = {When used in classrooms, personalized learning software allows students to work at their own pace, while freeing up the teacher to spend more time working one-on-one with students. Yet such personalized classrooms also pose unique challenges for teachers, who are tasked with monitoring classes working on divergent activities, and prioritizing help-giving in the face of limited time. This paper reports on the co-design, implementation, and evaluation of a wearable classroom orchestration tool for K-12 teachers: mixed-reality smart glasses that augment teachers’ real-time perceptions of their students’ learning, metacognition, and behavior, while students work with personalized learning software. The main contributions are: (1) the first exploration of the use of smart glasses to support orchestration of personalized classrooms, yielding design findings that May inform future work on real-time orchestration tools; (2) Replay Enactments: a new prototyping method for real-time orchestration tools; and (3) an in-lab evaluation and classroom pilot using a prototype of teacher smart glasses (Lumilo), with early findings suggesting that Lumilo can direct teachers’ time to students who May need it most.<br/> © 2018 Copyright is held by the owner/author(s).},
key = {Students},
keywords = {Wearable computers;Glass;Mixed reality;},
note = {Awareness;Co-designs;Orchestration;Personalized classrooms;Real-time analytics;},
URL = {http://dx.doi.org/10.1145/3170358.3170377},
} 


@inproceedings{20120514733959 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Attention please! Learning analytics for visualization and recommendation},
journal = {ACM International Conference Proceeding Series},
author = {Duval, Erik},
year = {2011},
pages = {9 - 17},
address = {Banff, AB, Canada},
abstract = {This paper will present the general goal of and inspiration for our work on learning analytics, that relies on attention metadata for visualization and recommendation. Through information visualization techniques, we can provide a dashboard for learners and teachers, so that they no longer need to "drive blind". Moreover, recommendation can help to deal with the "paradox of choice" and turn abundance from a problem into an asset for learning. © 2011 ACM.<br/>},
key = {Visualization},
keywords = {Teaching;Information systems;},
note = {Information visualization;Learning analytics;Recommendation;},
URL = {http://dx.doi.org/10.1145/2090116.2090118},
} 


@inproceedings{20194707700357 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Moodleboard: Dynamic and Interactive Indicators for Teachers and Pedagogical Engineers},
journal = {2nd International Conference on Next Generation Computing Applications 2019, NextComp 2019 - Proceedings},
author = {Sebastien, Veronique and Sebastien, Didier and Timol, Ilias and Gay, Dominique and Cucchi, Alain and Porlier, Christophe},
year = {2019},
pages = {Ceridian; Infomil; SBM - },
address = {Mauritius, Mauritius},
abstract = {In this article, we present Moodleboard, a dynamic and interactive dashboard which can be used as a decision support tool by pedagogical engineers and Moodle platforms administrators. These users can explore various indicators in an interactive way in order to obtain statistics about online courses with different granularity levels, but also detect remarkable courses and their types, classify courses, detect misuses or innovations implemented by teaching or administrative teams in the organization. This work also aims at proposing models for digital courses in Moodle, in order to facilitate their adaptation to full-online distance learning.<br/> © 2019 IEEE.},
key = {E-learning},
keywords = {Decision support systems;Teaching;},
note = {clustering;dashboard;Decision supports;learning analytics;pedagogical platform;},
URL = {http://dx.doi.org/10.1109/NEXTCOMP.2019.8883651},
} 


@inproceedings{20231013675778 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How Students' Emotion and Motivation Changes after Viewing Dashboards with Varied Social Comparison Group: A Qualitative Study},
journal = {ACM International Conference Proceeding Series},
author = {Aghaei, Kimia and Hatala, Marek and Mogharrab, Alireza},
year = {2023},
pages = {663 - 669},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">The need to personalize learning analytics dashboards (LADs) is getting more recognized in learning analytics research community. In order to study the impact of these dashboards on learners, various types of prototypes have been designed and deployed in different settings. Applying Weiner's attribution theory, our goal in this study was to understand the effect of dashboard information content on learners. We wanted to understand how elements of assignment grade, time spent on an assignment, assignment view, and proficiency in the dashboard affect students' attribution of achievement and motivation for future work. We designed a qualitative study in which we analyzed participants' responses and indicated behavioural changes after viewing the dashboard. Through in-depth interviews, we aimed to understand students' interpretations of the designed dashboard, and to what extent social comparison impacts their judgments of learning. Students used multiple dimensions to attribute their success or failure to their ability and effort. Our results indicate that to maximize the benefits of dashboards as a vehicle for motivating change in students learning, the dashboard should promote effort in both personal and social comparison capacities.<br/></div> © 2023 ACM.},
key = {Students},
keywords = {Economic and social effects;Motivation;},
note = {Attribution theory;Comparison group;Information contents;Learning analytic dashboard;Qualitative analysis;Qualitative study;Research communities;Social comparison;Student emotions;Student motivation;},
URL = {http://dx.doi.org/10.1145/3576050.3576107},
} 


@inproceedings{20200208022114 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Simulatable open learner models of core competencies for setting goals for course performance},
journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
author = {Chou, Chih-Yueh and Chih, Wen-Chieh and Tseng, Shu-Fen and Chen, Zhi-Hong},
volume = {1},
year = {2019},
pages = {93 - 95},
address = {Kenting, Taiwan},
abstract = {A competency-based curriculum involves courses for cultivating core competencies required for specific professions to enable students to take courses to cultivate their core competencies. This paper presents a curriculum level and competency-based learning analytics dashboard system with simulatable open learner models (OLMs) of core competencies for assisting students in setting goals for course performance. At first, the system provides students with their OLMs of core competencies based on their taken courses and grades. After that, students are asked to set their goals for course grades of all their courses during the current semester. The system displays the simulation of students’ future OLMs if they achieve their goals for course grades this semester. Students can re-set their goals and conduct the simulation of OLMs again until they satisfy the simulation results. The system also enables students to set detailed goals for attendance, assignment hand-in rate, midterm exam, and final exam in order to achieve their goals for course grade. A preliminary evaluation was conducted. Most students agreed that the simulatable OLMs assisted them in understanding the influence of their goals for course grades on core competencies and in setting goals for course grades. Most students also stated that setting detailed course goals prompted them to achieve the goal for course grade.<br/> © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
key = {Curricula},
keywords = {Education computing;Learning systems;Students;},
note = {Core competencies;Course performance;Goal setting;Learning analytics dashboard system;Open learner models;System displays;},
} 


@inproceedings{20232614322113 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Transparent Dashboards: Open data practices for promoting competition-As-motivation in business dashboards},
journal = {IEEE Pacific Visualization Symposium},
author = {Hadiprawoto, Triana R. and Ridley, Arran L.},
volume = {2023-April},
year = {2023},
pages = {142 - 146},
issn = {21658765},
address = {Seoul, Korea, Republic of},
abstract = {<div data-language="eng" data-ev-field="abstract">Dashboards are a common and familiar format of data visualization and are deployed in a number of fields and across domains, such as business, medical and health, learning analytics, and urban analytics, amongst others. In this paper, we conduct interviews with users of business dashboards, in particular, performance dashboards and scorecards, in order to gain an understanding of how they might be used in daily practice. We discuss how dashboards are not only used, as the literature suggests, to gain a quick understanding of the data but are deployed, by making the data available to everyone, as a means of motivating the users through creating a competitive framing of the data. We discuss the implications of this and how our findings can inform and support approaches to dashboard design, implementation, and usage.<br/></div> © 2023 IEEE.},
key = {Data visualization},
keywords = {Competition;Motivation;Open Data;Visualization;},
note = {Dashboard;Data practices;Design implementation;Open datum;Performance;Promoting competition;},
URL = {http://dx.doi.org/10.1109/PacificVis56936.2023.00023},
} 


@article{20232614309204 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Multimodal Teacher Dashboards: Challenges and Opportunities of Enhancing Teacher Insights Through a Case Study},
journal = {IEEE Transactions on Learning Technologies},
author = {Lee-Cultura, Serena and Sharma, Kshitij and Giannakos, Michail N.},
volume = {17},
year = {2024},
pages = {181 - 201},
issn = {19391382},
abstract = {<div data-language="eng" data-ev-field="abstract">Teacher dashboards provide insights on students' progress through visualizations and scores derived from data generated during teaching and learning activities (e.g., response times and task correctness) to improve teaching. Despite the potential usefulness of enhancing teacher dashboards, and the respective teaching practices, with rich information regarding students' cognitive and affective states (e.g., cognitive load), few studies on teacher dashboards have considered such information. In this study, we drew on contemporary developments of multimodal (MM) learning analytics and designed an MM teacher dashboard with a notification system. The proposed system: 1) receives data from various sensors; 2) computes relevant cognitive and affective measurements; 3) visualizes the resulting measurements in a clean customizable interface; and 4) notifies instructors during moments of interest, so they may determine an appropriate method to support struggling students. To evaluate our MM teacher dashboard, we first collected multimodal data (MMD), performance data, and video recordings of students' interactions during an in situ study where 26 students engaged with a motion-based learning task. Then, we used our MM teacher dashboard to present the collected MMD and video recordings to 20 experienced teachers and educational researchers and collected qualitative data regarding respondents' insights on the advantages and challenges of visualizing students' MMD. Results showed that teachers found an MM teacher dashboard enhanced with a notification system, useful to complement their pedagogical practices. We offer empirically founded guidelines for design and integration of an MM teacher dashboard with notification systems, aimed to enhance teachers' understanding of students' learning states (e.g., real-time awareness of students' stress).<br/></div> © 2008-2011 IEEE.},
key = {Real time systems},
keywords = {Data visualization;Interactive computer systems;Job analysis;Students;Teaching;Video recording;Visualization;},
note = {Educational tech- nologies;Learning analytic;Multi-modal;Multi-modal data;Notification systems;Real - Time system;Task analysis;Teacher dashboard;Teachers';Tracking;},
URL = {http://dx.doi.org/10.1109/TLT.2023.3276848},
} 


@inproceedings{20180604754297 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learner and course dashboards for intelligent learning management systems},
journal = {2017 25th International Conference on Software, Telecommunications and Computer Networks, SoftCOM 2017},
author = {Volaric, Tomislav and Ljubic, Hrvoje},
year = {2017},
address = {Split, Croatia},
abstract = {Visualization of data in learning management systems became essential for easier analysis of learner's behavior and interpretation of results on such system. In this paper, we presented design and development process of dashboard for the prototype of program support-CM Tutor. After analysis of various approaches of designing a learning analytics dashboard, we selected most important items for display on the dashboard, and we created our own. We have designed and built a dashboard for intelligent learning management systems. The dashboard is intended for both students and teachers. The teacher has access to all the functionalities of dashboard, while student approach is limited.<br/> © 2017 University of Split, FESB.},
key = {Visualization},
keywords = {Data visualization;Learning systems;Information management;},
note = {Analysis of various;Dashboard;Design and development process;Intelligent learning management systems;Learning analytics;Learning Analytics Dashboards;Learning management system;Program support;},
URL = {http://dx.doi.org/10.23919/SOFTCOM.2017.8115555},
} 


@inproceedings{20231013675739 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How Do Teachers Use Dashboards Enhanced with Data Storytelling Elements According to their Data Visualisation Literacy Skills?},
journal = {ACM International Conference Proceeding Series},
author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Echeverria, Vanessa and Srivastava, Namrata and Gasevic, Dragan},
year = {2023},
pages = {89 - 99},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">There is a proliferation of learning analytics (LA) dashboards aimed at supporting teachers. Yet, teachers still find it challenging to make sense of LA dashboards, thereby making informed decisions. Two main strategies to address this are emerging: i) upskilling teachers' data literacy; ii) improving the explanatory design features of current dashboards (e.g., adding visual cues or text) to minimise the skills required by teachers to effectively use dashboards. While each approach has its own trade-offs, no previous work has explored the interplay between the dashboard design and such "data skills". In this paper, we explore how teachers with varying visualisation literacy (VL) skills use LA dashboards enhanced with (explanatory) data storytelling elements. We conducted a quasi-experimental study with 23 teachers of varied VL inspecting two versions of an authentic multichannel dashboard enhanced with data storytelling elements. We used an eye-tracking device while teachers inspected the students' data captured from Zoom and Google Docs, followed by interviews. Results suggest that high VL teachers adopted complex exploratory strategies and were more sensitive to subtle inconsistencies in the design; while low VL teachers benefited the most from more explicit data storytelling guidance such as accompanying complex graphs with narrative and semantic colour encoding.<br/></div> © 2023 ACM.},
key = {Semantics},
keywords = {Data visualization;Economic and social effects;Eye tracking;Visualization;},
note = {'current;Dashboard;Data literacy;Data storytelling;Design features;Human-centred designs;Informed decision;Learning analytic;Teachers';Visual cues;},
URL = {http://dx.doi.org/10.1145/3576050.3576063},
} 


@inproceedings{20232314188455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Generating LADs that Make Sense},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Sadallah, Madjid and Gilliot, Jean-Marie},
volume = {1},
year = {2023},
pages = {35 - 46},
issn = {21845026},
address = {Prague, Czech republic},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards (LADs) deliver rich and actionable representations of learning data to support meaningful and insightful decisions that ultimately leverage the learning process. Yet, because of their limited adoption and the complex nature of learning data, their design is still a major area of inquiry. In this paper, we propose to expand LAD codesign approaches. We first investigate how the user makes sense of the data delivered by LADs and how to support this sensemaking process at design. Second, we propose a generative tool, supporting sensemaking and decision making process, that extends end-users participation during the prototyping phase and empowers LAD designers. We also present an evaluation of the tool, including usability and user experience, demonstrating its effectiveness in supporting the design and prototyping of LADs.<br/></div> Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda.},
key = {Decision making},
keywords = {Computer vision;Design;E-learning;},
note = {Co-design approach;Co-designs;Complex nature;Dashboard generation;Generative design;Generative tools;Learning analytic dashboard;Learning data;Learning process;Sense making;},
URL = {http://dx.doi.org/10.5220/0011839800003470},
} 


@inproceedings{20244017130865 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barthakur, Abhinava and Marrone, Rebecca and Esnaashari, Shadi and Kovanovic, Vitomir and Dawson, Shane},
volume = {15159 LNCS},
year = {2024},
pages = {49 - 63},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Within the education sector, there is growing recognition of the importance of diverse data sets in aiding strategic decisions and supporting personalized learning. To date, this call for increased and more nuanced data has been translated into institutional use of data dashboards or learning analytics dashboards. While these dashboards have been extensively developed and adopted in higher education, there is limited research investigating the use of dashboards in K-12 education. To address this gap, this study presents a systematic literature review examining dashboards as a decision-making system in K-12 settings. Our analysis indicates significant underuse of data in these dashboards, with a concerning scarcity of implementations and evaluations in real-world classroom environments. To counteract these shortcomings, we propose a set of recommendations designed to enhance dashboard development by promoting the use of Learner Profiles (LPs). These guidelines aim to support educational outcomes and student success by informing the design and deployment of fine-grained dashboards aligned with the specific needs of K-12 education. By highlighting the current gaps and offering forward-looking recommendations, our study clarifies the present landscape and serves as a foundation for future research, with significant implications for educators, policymakers, and scholars interested in using LPs to improve student learning outcomes.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Decision making;Federated learning;Students;Teaching;},
note = {Dashboard;Decision-making systems;Decisions makings;Education sectors;K-12;K-12 education;Learner profiles;Systematic literature review;Systematic Review;Teaching and learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-72315-5_4},
} 


@inproceedings{20221611964982 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards the Co-Design of a Teachers' Dashboards in a Hybrid Learning Environment},
journal = {2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology, IRASET 2022},
author = {Ouatiq, Amina and Riyami, Bouchaib and Mansouri, Khalifa and Qbadou, Mohammed and Aoula, Es-Saadia},
year = {2022},
address = {Meknes, Morocco},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytic Dashboards support learning, and try to empower stakeholders to make better-informed decisions. While creating dashboards for teachers is common in Learning analytics, designing it with them is not that common, especially in hybrid systems and using data from both the online and face-to-face sessions. This paper will be discussing co-designing a teacher dashboard with teachers through participatory workshop and interview, after getting their goals and expectation for dashboard in hybrid system. To arrive to a dashboard prototype, conform with teachers' needs and expectations.<br/></div> © 2022 IEEE.},
key = {Hybrid systems},
keywords = {Computer aided instruction;Online systems;},
note = {Co-designs;Face to face;Human-centred designs;Hybrid learning;Informed decision;Learning analytic;Learning environments;Support learning;Teacher dashboard;Teachers';},
URL = {http://dx.doi.org/10.1109/IRASET52964.2022.9738149},
} 


@inproceedings{20241916032485 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Classroom Monitoring using Emotional Data},
journal = {CEUR Workshop Proceedings},
author = {Hasnine, Mohammad Nehal and Nguyen, Ho Tan and Akcapinar, Gokhan and Morita, Ryugo and Ueda, Hiroshi},
volume = {3667},
year = {2024},
pages = {83 - 88},
issn = {16130073},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Emotions are an integrated part of learning. Emotions can reveal many hidden factors about learning and have the potential to provide actionable insights to teachers to increase the quality of teaching. This study uses multimodal learning analytics methodologies to introduce a classroom monitoring system for teachers teaching online courses. The system is an integrated component of the MOEMO (Motion and Emotion) learning analytics framework that visualizes students' affective and emotional states while taking online classes. Using this classroom monitoring system, a teacher could understand the moments when students were disengaged so that the teacher could intervene to make those disengaged students engaged. The system reports actionable insights on students' engagements and concentrations to the teacher.<br/></div> © 2024 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {E-learning;Learning systems;Teaching;},
note = {Affective state;Classroom monitoring;Emotion analysis;Engagement;MMLA;Monitoring system;Multi-modal learning;Quality of teaching;Teacher-facing dashboard;Teachers';},
} 


@inproceedings{20223812760099 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Designing LADs That Promote Sensemaking: A Participatory Tool},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sadallah, Madjid and Gilliot, Jean-Marie and Iksal, Sebastien and Quelennec, Katia and Vermeulen, Mathieu and Neyssensas, Laurent and Aubert, Olivier and Venant, Remi},
volume = {13450 LNCS},
year = {2022},
pages = {587 - 593},
issn = {03029743},
address = {Toulouse, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboards (LADs) are data visualization tools built to empower teachers and learners to make purposeful decisions that impact the learning process. Due to their relatively recent emergence and the scarcity of studies on their design principles, dashboard design remains a major area of investigation in learning analytics research, and large scale diffusion to their stakeholders remains limited. We promote human-centered approaches for LADs design since their success in terms of acceptance and adoption greatly depends on the level of stakeholder involvement in their design. In this paper, we present a tool to support the participatory design of LADs. First experiments during a pilot study with teachers demonstrate that the proposed tool encourages group work, and in-depth exploration of LADs use.<br/></div> © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Data visualization},
keywords = {Learning systems;},
note = {Dashboard;Data visualization tools;Design Principles;Large-scales;Learning analytic;Learning process;Participatory design;Sense making;Stakeholder involvement;Teachers';},
URL = {http://dx.doi.org/10.1007/978-3-031-16290-9_54},
} 


@inproceedings{20232314201969 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Know the Knowledge of Your Students: A Flexible Analytics Tool for Student Exercises},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Aguirre Reid, Soren and Kammer, Frank and Schuller, Daria and Siepermann, Markus and Wolfer, Jonas},
volume = {13873 LNCS},
year = {2023},
pages = {329 - 344},
issn = {03029743},
address = {Pretoria, South africa},
abstract = {<div data-language="eng" data-ev-field="abstract">Intelligent tutoring systems (ITS) have the power to influence lecturers’ practices in the classroom and to improve students’ learning. Many ITS provide standardized analytical methods to evaluate classroom performance or the results of the exercises. But they lack more sophisticated, flexible and individual analyses. This paper presents an e-learning Analytics Tool (EAT) for an ITS that provides a dashboard with key figures and a flexible analytics board (FAB). This enables lecturers to analyze students’ performance in detail and identify misconceptions. For instance, the FAB allows us to classify student solutions, reveal conceptual errors in exercises, and analyze each part of an exercise. By this, common mistakes can be identified, and tailored feedback can be given to the students. Following the design science approach, the platform is designed in a general way so that it can be used for different types of exercises (e.g., Math, Excel, SQL). To assess the artifact, we conducted group interviews with German University lecturers from various courses. The results show that lecturers require a good overview of the submitted student solutions to provide timely feedback. They also appreciate the flexible analytics tool for detailed analyses of student solutions to understand student mistakes better. The employed architecture allows general analyses of exercises and the content of students’ solutions. In addition, the EAT is not bound to a specific kind of exercise, but can cope with different kinds like SQL and Excel.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Students},
keywords = {Computer aided instruction;Education computing;Intelligent vehicle highway systems;Learning systems;},
note = {Analytic tools;Dashboard;Flexible analyse;Intelligent tutoring;Intelligent tutoring system;Learning analytic and evaluation;Tutoring system;},
URL = {http://dx.doi.org/10.1007/978-3-031-32808-4_21},
} 


@article{20194607696838 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Effects of learner interaction with learning dashboards on academic performance in an e-learning environment},
journal = {Behaviour and Information Technology},
author = {Kokoc, Mehmet and Altun, Arif},
volume = {40},
number = {2},
year = {2021},
pages = {161 - 175},
issn = {0144929X},
abstract = {This study aims to investigate learners’ interaction with the learning dashboards as a predictor outcome of an online learning experience and, to what extent this interaction data could be used to predict and/or provide guidance through their academic performance. For this purpose, a prescriptive learning dashboard integrated into an e-learning environment was developed as a learning analytics tool. The participants consisted of 126 higher education students enrolled in the 12-week Computer Networks and Communication course. Data gathered through logs and academic performances of learners were analysed with data mining techniques. The result of cluster analysis, based on interaction with the prescriptive learning dashboard, showed that learners were separated into four groups according to their behavioural patterns. A similar pattern appears when the related clusters are profiled based on the academic performances. At predictive analysis, the study indicates that the interaction with prescriptive learning dashboard had certain effects on academic performance of learners significantly and artificial neural networks algorithm yielded the best performance for predicting academic performance. The results support that the usage prescriptive learning dashboards can be applied in online courses as an instructional aid to improve performance of learners and learning design in e-learning environments.<br/> © 2019 Informa UK Limited, trading as Taylor & Francis Group.},
key = {Data mining},
keywords = {Cluster analysis;E-learning;Neural networks;Curricula;Data visualization;Computer aided instruction;},
note = {Communication course;E-learning environment;Educational data mining;Higher education students;Learning analytics;learning dashboards;On-line interactions;Predicting academic performance;},
URL = {http://dx.doi.org/10.1080/0144929X.2019.1680731},
} 


@inproceedings{20244017130864 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Investigating Learning Dashboards Adaptation},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barbe, Remi and Encelle, Benoit and Sehaba, Karim},
volume = {15159 LNCS},
year = {2024},
pages = {34 - 48},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Although there is a growing number of learning analytics dashboards (LADs), they often fail to improve learning and learners’ awareness due to their lack of adaptation capabilities. This paper presents a systematic review that follows the PRISMA statement and analyzes the adaptation features of LADs and their potential effects on learning. 24 of the 462 articles retrieved were scrutinized using an analysis framework centered on adaptation. The main finding is that there is more evidence of adaptable LADs than adaptive LADs, suggesting that adaptivity is worth exploring. The results mainly highlight 3 common LADs adaptable capabilities - most of which offer data exploration features - and 2 adaptive ones that change or refresh indicators on dashboards. Only a few articles investigate the adaptation of indicator visualizations or organization on dashboards. Currently, there is no work on the use of advanced computing techniques such as machine learning for LADs adaptation. Additionally, only 5 articles provide some evidence of dashboards adaptation features evaluation. As a result, a preliminary research agenda on LADs adaptation is suggested for enhancing LADs adoption and utility.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Adversarial machine learning},
keywords = {Contrastive Learning;Federated learning;},
note = {Adaptation;Adaptive learning;Adaptivity;Analysis frameworks;Computing techniques;Data exploration;Learning analytic dashboard;Learning indicator;Potential effects;Systematic Review;},
URL = {http://dx.doi.org/10.1007/978-3-031-72315-5_3},
} 


@inproceedings{20162702561854 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data2U: Scalable real time student feedback in active learning environments},
journal = {ACM International Conference Proceeding Series},
author = {Khan, Imran and Pardo, Abelardo},
volume = {25-29-April-2016},
year = {2016},
pages = {249 - 253},
address = {Edinburgh, United kingdom},
abstract = {The majority of applications and products that use learning analytics to understand and improve learning experiences assume the creation of actionable items that will affect students through an intermediary. Much less focus is devoted to exploring how to provide insight directly to students. Furthermore, student engagement has always been a relevant aspect to increase the quality of a learning experience. Learning analytics techniques can be used to provide real-time insight tightly integrated with the learning outcomes directly to the students. This paper describes a case study deployed in a first year engineering course using a flipped learning strategy to explore the behavior of students interacting with a dashboard updated in real time providing indicators of their engagement with the course activities. The results show different patterns of use and their evolution throughout the experience and shed some light on how students perceived this resource.<br/> © 2016 ACM.},
key = {Students},
keywords = {Engineering education;Computer aided instruction;},
note = {Active learning environment;Dashboard;First year engineering course;Learning analytics;Learning experiences;Learning outcome;Learning strategy;Student engagement;},
URL = {http://dx.doi.org/10.1145/2883851.2883911},
} 


@inproceedings{20231013675772 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using Teacher Dashboards to Customize Lesson Plans for a Problem-Based, Middle School STEM Curriculum},
journal = {ACM International Conference Proceeding Series},
author = {Hutchins, Nicole and Biswas, Gautam},
year = {2023},
pages = {324 - 332},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Keeping K-12 teachers engaged during students' learning and problem solving in technology-enhanced, integrated problem-based learning (PBL) has been shown to support deeper student involvement, and, therefore, better success learning difficult science, computing, and engineering concepts and practices. However, students' learning processes and corresponding difficulties are not easily noticed by teachers as students learn from these environments as processes are captured through mouse clicks, drag and drop actions, and other low-level activities. As such, teachers find it difficult to set up meaningful interactions with students while also maintaining the focus on student-centered learning. Little research has examined dashboard-supported responsive teaching practices for K-12 PBL. This study examined 8 teachers as they used a co-designed teacher dashboard to assess and respond to students' learning and strategies during an integrated, PBL STEM curriculum. Teachers completed a series of 5 "planning period simulations"leveraging the dashboard and think-aloud protocols were implemented, supported by semi-structured interview questions, to enable the teachers to verbalize their thought and evaluation processes. Content analysis and epistemic network analysis were conducted to analyze the simulations. Understanding how teachers use dashboards to support evidence-based teaching practices during technology-enhanced curricula is critical for improving teacher support and preparation.<br/></div> © 2023 ACM.},
key = {Curricula},
keywords = {Education computing;Engineering education;Mammals;Students;},
note = {Co-designs;Computational modelling;Lesson plans;Problem based learning;Problem-based;Responsive teaching;Student learning;Teacher dashboard;Teachers';Teaching practices;},
URL = {http://dx.doi.org/10.1145/3576050.3576100},
} 


@inproceedings{20162902608169 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Promoting instructor and department action via simple, actionable tools and analyses},
journal = {CEUR Workshop Proceedings},
author = {Molinaro, Marco and Li, Qiwei and Steinwachs, Matthew and Guzman-Alvarez, Alberto},
volume = {1590},
year = {2016},
pages = {36 - 40},
issn = {16130073},
address = {Edinburgh, United kingdom},
abstract = {In this paper, we present some of our ongoing, as well as more recent work designing, implementing, and improving three tools to help university instructors and department leaders make evidence-based improvements to instruction. The first tool, Know Your Students, is a very early prototype that helps instructors tailor their instruction based on characteristics of the students they would not otherwise be aware of in their courses. The other two tools, the Departmental Diagnostic Dashboard and Ribbon Tool, help department chairs, curricular chairs, and/or advisors identify and make sense of student patterns they may be trying to minimize or enhance within individual courses, course series, and/or throughout their entire program. This paper illustrates examples of these tools and some of the actions they have inspired as a means of improving student outcomes.<br/>},
note = {Departmental instructional dashboard;Evidence-based;Learning analytics;Programmatic changes;Student outcomes;},
} 


@unpublished{20230271134 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Estudio de la Experiencia de Usuario mediante un Sistema de Dashboards de Análisis de Aprendizaje Multimodal},
journal = {arXiv},
author = {Becerra, alvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
year = {2023},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">In the article, we present a Web-based System called M2LADS, which supportsthe integration and visualization of multimodal data recorded in userexperiences (UX) in a Learning Analytics (LA) system in the form of Web-basedDashboards. Based on the edBB platform, the multimodal data gathered containsbiometric and behavioral signals including electroencephalogram data to measurelearners\' cognitive attention, heart rate for affective measures and visualattention from the video recordings. Additionally, learners\' static backgrounddata and their learning performance measures are tracked using LOGGE tool.M2LADS provides opportunities to capture learners\' holistic experience duringtheir interactions with the learning analytic system in order to improve thesystem and the user experience of the learners. - En este art\\\'iculo, presentamos M2LADS, un sistema que permite laintegraci\\\'on y visualizaci\\\'on de datos multimodales en forma de DashboardsWeb. Estos datos provienen de sesiones de experiencia de usuario en un sistemade Learning Analytics (LA) llevadas a cabo por estudiantes de MOOCs. Los datosmultimodales incluyen se\\~nales biom\\\'etricas y de comportamiento monitorizadospor la plataforma edBB, como electroencefalogramas (EEG) de 5 canales,frecuencia card\\\'iaca, atenci\\\'on visual, videos en el espectro visible y NIR,entre otros. Adem\\\'as, se incluyen datos de interacci\\\'on de los estudiantescon el sistema de LA a trav\\\'es de la herramienta LOGGE. Toda estainformaci\\\'on proporciona una comprensi\\\'on completa de la experiencia delusuario al utilizar el sistema de LA, lo que ha permitido tanto mejorar elsistema LA como la experiencia de aprendizaje de los estudiantes de MOOCs.<br/></div> Copyright © 2023, The Authors. All rights reserved.},
key = {Video recording},
keywords = {Biometrics;Data visualization;E-learning;Electroencephalography;Learning systems;Websites;},
note = {Analytics systems;Biometric and behavior;Dashboard;E - learning;MOOC;Multi-modal data;Multi-modal learning;Multimodal learning analytic;User experience (userexperience);Users' experiences;},
} 


@inproceedings{20194107514803 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Mature ELLs’ Perceptions Towards Automated and Peer Writing Feedback},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Liaqat, Amna and Akcayir, Gokce and Demmans Epp, Carrie and Munteanu, Cosmin},
volume = {11722 LNCS},
year = {2019},
pages = {266 - 279},
issn = {03029743},
address = {Delft, Netherlands},
abstract = {Mature English Language Learners (ELLs) learning to write in informal environments have little access to instructor feedback and must rely on other sources to support their writing development. While it is known that mature ELLs trust instructor feedback, their perceptions towards feedback from non-expert sources may be mixed. We report on mature ELLs’ perceptions and interpretations of peer and automated feedback when using dashboard visualizations of their writing skills derived from several metrics and sources of feedback. These perceptions and interpretations were collected through a short-term deployment of the dashboard within a writing app with 16 mature ELLs, followed by interviews with the learners. From analyses of these interviews, we suggest three design guidelines (DG) related to learning analytics dashboard design for mature ELLs in informal learning contexts. First, analytics-based feedback should contextualize ELLs’ learning progress by providing temporal information about learner performance. Second, justifications should accompany feedback to avoid criticism arising from ELLs’ prior beliefs. Third, learner autonomy should be fostered by offering explicit mechanisms for reflecting on feedback that is inconsistent with learner beliefs since learners are willing to question automated feedback. We discuss how these three guidelines can be used to benefit learners when an instructor is not present.<br/> © 2019, Springer Nature Switzerland AG.},
key = {Automation},
keywords = {Artificial intelligence;Computer aided instruction;},
note = {Adult learners;Automated feedback;Dashboards;Learner autonomies;Learning analytics;Migrants;Temporal information;Writing feedbacks;},
URL = {http://dx.doi.org/10.1007/978-3-030-29736-7_20},
} 


@inproceedings{20183805824475 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Tools to Support Self-Regulated Learning in Online Environments: Literature Review},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Perez-alvarez, Ronald and Maldonado-Mahauad, Jorge and Perez-Sanagustin, Mar},
volume = {11082 LNCS},
year = {2018},
pages = {16 - 30},
issn = {03029743},
address = {Leeds, United kingdom},
abstract = {Self-regulated learning (SRL) skills are especially important in Massive Open Online Courses (MOOCs), where teacher guidance is scarce, and learners must engage in their learning process trying to succeed and achieve their learning goals. However, developing SRL strategies is difficult for learners given the autonomy that is required in this kind of courses. In order to support learners on this process, researchers have proposed a variety of tools designed to support certain aspects of self-regulation in online learning environments. Nevertheless, there is a lack of study to understand what the commonalities and differences in terms of design are, what the results in terms of the effect on learners’ self-regulation are and which of them could be applied in MOOCs. Those are the questions that should be further explored. In this paper we present a systematic literature review where 22 tools designed to support SRL in online environments were analyzed. Our findings indicate that: (1) most of the studies do not evaluate the effect on learners’ SRL strategies; (2) the use of interactive visualizations has a positive effect on learners’ motivation; (3) the use of the social comparison component has a positive effect on engagement and time management; and (4) there is a lack of models to match learners’ activity with the tools with SRL strategies. Finally, we present the lessons learned for guiding the community in the implementation of tools to support SRL strategies in MOOCs.<br/> © 2018, Springer Nature Switzerland AG.},
key = {Computer aided instruction},
keywords = {Curricula;E-learning;Deregulation;Learning systems;Visualization;},
note = {Dashboard;Learning analytics;Literature reviews;Massive open online course;MOOC;Online;Self-regulated learning;System;},
URL = {http://dx.doi.org/10.1007/978-3-319-98572-5_2},
} 


@inproceedings{20194207556286 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizations to support facilitation: The instructors’ view},
journal = {Computer-Supported Collaborative Learning Conference, CSCL},
author = {Chen, Yuxin and Birk, Gurpreet and Hmelo-Silver, Cindy E. and Kazemitabar, Maedeh and Bodnar, Stephen and Lajoie, Susanne P.},
volume = {2},
year = {2017},
pages = {857 - 858},
issn = {15734552},
address = {Philadelphia, PA, United states},
abstract = {Dashboards with visualization techniques have the potential to support instructors in facilitating multiple asynchronous small groups by tracing learning activities and making interventions with the use of synthesized real-time information. However, few studies address how instructors use these visualizations in an online problem-based learning environment. This poster presents the results of a study that examined instructors’ use of a teacher dashboard in an online PBL environment using a think-aloud protocol.<br/> © ISLS.},
key = {Visualization},
keywords = {E-learning;Computer aided instruction;},
note = {Dashboard;Learning Activity;Learning analytics;Online learning;Problem based learning;Real-time information;Think-aloud protocol;Visualization technique;},
} 


@inproceedings{20171003417808 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizing student engagement in e-learning environment},
journal = {Proceedings - DMS 2016: 22nd International Conference on Distributed Multimedia Systems},
author = {Pesare, Enrica and Roselli, Teresa and Rossano, Veronica},
year = {2016},
pages = {26 - 33},
address = {Salerno, Italy},
abstract = {The learning assessment in e-learning contexts is one of the latest challenges for educational technology researchers. One of the main issues to be addressed is the definition of dimensions that should be used to measure the learning effectiveness. In this perspective, the research work aims at defining the engagement indicators useful to assess the active participation of students in social learning environments. Moreover, the paper presents the design and implementation of Learning Dashboards aimed at visualizing the student engagement in online communities where the engagement and involvement of students are the key factors for successful learning.<br/>},
key = {Students},
keywords = {E-learning;Computer aided instruction;},
note = {Assessment;Engagement;Learning analytics;Learning Dashboard;Social learning;},
URL = {http://dx.doi.org/10.18293/DMS2016-028},
} 


@article{20234715088714 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Dual-Mode Grade Prediction Architecture for Identifying At-Risk Students},
journal = {IEEE Transactions on Learning Technologies},
author = {Qiu, Wei and Khong, Andy W. H. and Supraja, S. and Tang, Wenyin},
volume = {17},
year = {2024},
pages = {803 - 814},
issn = {19391382},
abstract = {<div data-language="eng" data-ev-field="abstract">Predicting student performance in an academic institution is important for detecting at-risk students and to administer early intervention strategies. In this article, we develop a new architecture that achieves grade prediction based only on grades achieved over past semesters. Our proposed architecture involves two stages - weighted loss function incorporated to the long short-term memory (LSTM) model in the first stage, followed by a short-term gated LSTM in the second. The weighted loss function in the first stage ensures low prediction error by weighing loss associated with the minority class label (in our case the at-risk label). The short-term gated LSTM in the second stage, on the other hand, models short-term variations in academic performance to suppress any residual false alarms. Experiment results using three datasets obtained from over 20 000 students across 17 undergraduate courses show that the proposed model achieves a 28.8% improvement in F1 score compared to the LSTM model for at-risk detection. Students identified as at-risk have also been presented and validated by counselors via a dashboard.<br/></div> © 2008-2011 IEEE.},
key = {Long short-term memory},
keywords = {Brain;Errors;Forecasting;Memory architecture;Students;},
note = {At-risk detection;Dashboard deployment;Dual modes;False alarm suppression;Falsealarms;Grade predictions;Memory modeling;Risk detections;Weighted loss;Weighted loss function;},
URL = {http://dx.doi.org/10.1109/TLT.2023.3333029},
} 


@inproceedings{20231513874420 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Role of Learning Management System for Evaluating Students' progress in Learning Environment},
journal = {Proceedings of 5th International Conference on Contemporary Computing and Informatics, IC3I 2022},
author = {Pal, Neeti and Dahiya, Omdev},
year = {2022},
pages = {1800 - 1806},
address = {Uttar Pradesh, India},
abstract = {<div data-language="eng" data-ev-field="abstract">The paper contributes to getting familiar with various tools and platforms incorporated with learning dashboards that provide digital teaching and learning. The article also includes the different components for learning analytics used by various universities in their LMSs dashboards to improve their teaching-learning achievements. Learning analytics dashboards plays a vital role in the virtual learning environment. These tools work by tracking learners' data, analyzing data, and presenting the results by revealing the patterns of learners' behavior and attitude. This paper contributes to an analysis of learning dashboards and tools. The article also explains how these tools track, extract and analyze the students' learning progress and monitor their activities. Various visualization techniques are also discussed in this paper. This study will help determine the impact of using learning tools to evaluate learners' learning outcomes.<br/></div> © 2022 IEEE.},
key = {Computer aided instruction},
keywords = {Data mining;E-learning;Information management;Learning systems;Students;Visualization;},
note = {Digital teachings;Digital-learning;Educational data mining;Learning analytic;Learning analytic dashboard;Learning environments;Learning management system;Moodle;Student progress;Visualization technique;},
URL = {http://dx.doi.org/10.1109/IC3I56241.2022.10072794},
} 


@inproceedings{20200208022000 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting teachers in group work formation and analytics for in-class group activities},
journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
author = {Changhao, Liang and Botiki, Ivica and Ogata, Hiroaki},
volume = {1},
year = {2019},
pages = {744 - 749},
address = {Kenting, Taiwan},
abstract = {This paper introduces a system for collaborative learning which is designed to assist teachers in forming and grading groups for in-class group activities. The system is implemented as an extension of a learning analytics dashboard system and uses log data from a learning management system for operation. It consists of a group formation parameter console and the results console where formed groups are visualized and can be graded. The system supports teachers by using algorithms based on reliable learning evidence thereby simplifying the group formation process. All the group formation and grading data is logged thereby cyclically providing an infrastructure for subsequent collaborative learning activities.<br/> © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
key = {Grading},
keywords = {Information management;Learning systems;},
note = {Class group;Collaborative learning;Collaborative learning activities;CSCL;Group formations;Learning Analytics;Learning management system;System supports;},
} 


@article{20224413045832 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {SBGTool v2.0: An Empirical Study on a Similarity-Based Grouping Tool for Students’ Learning Outcomes †},
journal = {Data},
author = {Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
volume = {7},
number = {7},
year = {2022},
issn = {23065729},
abstract = {<div data-language="eng" data-ev-field="abstract">Visual learning analytics (VLA) tools and technologies enable the meaningful exchange of information between educational data and teachers. This allows teachers to create meaningful groups of students based on possible collaboration and productive discussions. VLA tools also allow a better understanding of students’ educational demands. Finding similar samples in huge educational datasets, however, involves the use of effective similarity measures that represent the teacher’s purpose. In this study, we conducted a user study and improved our web-based similarity-based grouping VLA tool, (SBGTool) to help teachers categorize students into groups based on their similar learning outcomes and activities. SBGTool v2.0 differs from SBGTool due to design changes made in response to teacher suggestions, the addition of sorting options to the dashboard table, the addition of a dropdown component to group the students into classrooms, and improvement in some visualizations. To counteract color blindness, we have also considered a number of color palettes. By applying SBGTool v2.0, teachers may compare the outcomes of individual students inside a classroom, determine which subjects are the most and least difficult over the period of a week or an academic year, identify the numbers of correct and incorrect responses for the most difficult and easiest subjects, categorize students into various groups based on their learning outcomes, discover the week with the most interactions for examining students’ engagement, and find the relationship between students’ activity and study success. We used 10,000 random samples from the EdNet dataset, a large-scale hierarchical educational dataset consisting of student–system interactions from multiple platforms at the university level, collected over a two-year period, to illustrate the tool’s efficacy. Finally, we provide the outcomes of the user study that evaluated the tool’s effectiveness. The results revealed that even with limited training, the participants were able to complete the required analysis tasks. Additionally, the participants’ feedback showed that the SBGTool v2.0 gained a good level of support for the given tasks, and it had the potential to assist teachers in enhancing collaborative learning in their classrooms.<br/></div> © 2022 by the authors.},
key = {Data visualization},
keywords = {Eye protection;Large dataset;Students;Visualization;},
note = {Analytic tools;Ednet;Educational data;Learning analytic dashboard;Similarity-based grouping;Similarity-based grouping VLA tool,;Teachers';User study;Visual learning;Visual learning analytic;},
URL = {http://dx.doi.org/10.3390/data7070098},
} 


@article{20243917084332 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A multimodal approach to support teacher, researcher and AI collaboration in STEM+C learning environments},
journal = {British Journal of Educational Technology},
author = {Cohn, Clayton and Snyder, Caitlin and Fonteles, Joyce Horn and Ashwin, T.S. and Montenegro, Justin and Biswas, Gautam},
volume = {56},
number = {2},
year = {2025},
pages = {595 - 620},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">Abstract: Recent advances in generative artificial intelligence (AI) and multimodal learning analytics (MMLA) have allowed for new and creative ways of leveraging AI to support K12 students' collaborative learning in STEM+C domains. To date, there is little evidence of AI methods supporting students' collaboration in complex, open-ended environments. AI systems are known to underperform humans in (1) interpreting students' emotions in learning contexts, (2) grasping the nuances of social interactions and (3) understanding domain-specific information that was not well-represented in the training data. As such, combined human and AI (ie, hybrid) approaches are needed to overcome the current limitations of AI systems. In this paper, we take a first step towards investigating how a human-AI collaboration between teachers and researchers using an AI-generated multimodal timeline can guide and support teachers' feedback while addressing students' STEM+C difficulties as they work collaboratively to build computational models and solve problems. In doing so, we present a framework characterizing the human component of our human-AI partnership as a collaboration between teachers and researchers. To evaluate our approach, we present our timeline to a high school teacher and discuss the key insights gleaned from our discussions. Our case study analysis reveals the effectiveness of an iterative approach to using human-AI collaboration to address students' STEM+C challenges: the teacher can use the AI-generated timeline to guide formative feedback for students, and the researchers can leverage the teacher's feedback to help improve the multimodal timeline. Additionally, we characterize our findings with respect to two events of interest to the teacher: (1) when the students cross a difficulty threshold, and (2) the point of intervention, that is, when the teacher (or system) should intervene to provide effective feedback. It is important to note that the teacher explained that there should be a lag between (1) and (2) to give students a chance to resolve their own difficulties. Typically, such a lag is not implemented in computer-based learning environments that provide feedback. Practitioner notes What is already known about this topic Collaborative, open-ended learning environments enhance students' STEM+C conceptual understanding and practice, but they introduce additional complexities when students learn concepts spanning multiple domains. Recent advances in generative AI and MMLA allow for integrating multiple datastreams to derive holistic views of students' states, which can support more informed feedback mechanisms to address students' difficulties in complex STEM+C environments. Hybrid human-AI approaches can help address collaborating students' STEM+C difficulties by combining the domain knowledge, emotional intelligence and social awareness of human experts with the general knowledge and efficiency of AI. What this paper adds We extend a previous human-AI collaboration framework using a hybrid intelligence approach to characterize the human component of the partnership as a researcher-teacher partnership and present our approach as a teacher-researcher-AI collaboration. We adapt an AI-generated multimodal timeline to actualize our human-AI collaboration by pairing the timeline with videos of students encountering difficulties, engaging in active discussions with a high school teacher while watching the videos to discern the timeline's utility in the classroom. From our discussions with the teacher, we define two types of inflection points to address students' STEM+C difficulties—the difficulty threshold and the intervention point—and discuss how the feedback latency interval separating them can inform educator interventions. We discuss two ways in which our teacher-researcher-AI collaboration can help teachers support students encountering STEM+C difficulties: (1) teachers using the multimodal timeline to guide feedback for students, and (2) researchers using teachers' input to iteratively refine the multimodal timeline. Implications for practice and/or policy Our case study suggests that timeline gaps (ie, disengaged behaviour identified by off-screen students, pauses in discourse and lulls in environment actions) are particularly important for identifying inflection points and formulating formative feedback. Human-AI collaboration exists on a dynamic spectrum and requires varying degrees of human control and AI automation depending on the context of the learning task and students' work in the environment. Our analysis of this human-AI collaboration using a multimodal timeline can be extended in the future to support students and teachers in additional ways, for example, designing pedagogical agents that interact directly with students, developing intervention and reflection tools for teachers, helping teachers craft daily lesson plans and aiding teachers and administrators in designing curricula.<br/></div> © 2024 The Author(s). British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
key = {Students},
keywords = {Adversarial machine learning;C (programming language);Collaborative learning;Contrastive Learning;Economic and social effects;Educational technology;Personnel training;Teaching;},
note = {Human-artificial intelligence collaboration;K-12 education;Multi-modal learning;Multimodal learning analytic;STEM+C learning;Teachers';Teachers' support;Timeline dashboard;},
URL = {http://dx.doi.org/10.1111/bjet.13518},
} 


@inproceedings{20234715087371 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Triggers of Teacher-Perceived Stressful Moments When Orchestrating Collaborative Learning with Technology},
journal = {CEUR Workshop Proceedings},
author = {Hakami, Eyad and Hakami, Lubna and Hernandez-Leo, Davinia and Amarasinghe, Ishari},
volume = {3542},
year = {2023},
issn = {16130073},
address = {Madrid, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">Teachers' well-being may be negatively impacted by the widespread adoption of educational technologies. The stress linked with teachers' use of digital technologies is an emerging area of research. To promote teachers' well-being through the design of CSCL tools, it is crucial to gain a deeper understanding of the stressful moments experienced by teachers when orchestrating collaborative learning activities facilitated by technology. Following a mixed method approach, this paper sheds light on the triggers of teachers perceived stressful moments when using a CSCL tool in F2F and online classes. In the scenarios studied, teachers report feeling less stressful moments during online sessions. However, more stress-related triggers and orchestrated actions happened during F2F sessions. It was found that technological difficulties, students behavior, and time constraints all contributed to the highlighted stressful moments. In addition, the dashboard interventions were found more related to stressful moments than other actions such as teacher-class interaction. This work provides an initial understanding of what makes teachers stressed when orchestrating CSCL activities from their perceptions. Collecting objective data about stress and orchestration load is needed to assert the findings of this work.<br/></div> © 2023 CEUR-WS. All rights reserved.},
key = {E-learning},
keywords = {Educational technology;Learning systems;},
note = {Collaborative learning;Computer Supported Collaborative Learning;Dashboard;Orchestration;Stressful moment;Support tool;Teacher support tool;Teachers';Teachers' support;Well being;},
} 


@inproceedings{20224212974751 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A proposal for predicting and intervening on MOOC learners' performance in real time},
journal = {CEUR Workshop Proceedings},
author = {Pascual, Ivan and Cobos, Ruth},
volume = {3238},
year = {2022},
pages = {26 - 38},
issn = {16130073},
address = {Salamanca, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">There is a lot of data from MOOCs, but their instructors cannot process that much information. While many learners end up dropping out of the course in which they enrolled in, a substantial problem in this context, their engagement data reveals their lack of interest even before they drop out. In order to make use of this information, we propose a Machine Learning approach to predict in real-time whether a learner would drop out or pass the MOOC, and a web-based dashboard approach to support this information and provide interventions over these learners. Using it in an asynchronous MOOC for 4 months, we predicted, with 0.93 F1-Score, the dropouts and passes from that period.<br/></div> © 2022 Copyright for this paper by its authors.},
key = {Forecasting},
keywords = {Drops;E-learning;Machine learning;},
note = {Dashboard;Drop-out;Engagement;Intervention;Learning analytic;Machine-learning;Massive open online course;Performance;Prescription;Real- time;},
} 


@inproceedings{20221111797046 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Unpacking Instructors' Analytics Use: Two Distinct Profiles for Informing Teaching},
journal = {ACM International Conference Proceeding Series},
author = {Li, Qiujie and Jung, Yeonji and D'Anjou, Bernice and Wise, Alyssa Friend},
year = {2022},
pages = {528 - 534},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">This study addresses the gap in knowledge about differences in how instructors use analytics to inform teaching by examining the ways that thirteen college instructors engaged with a set of university-provided analytics. Using multiple walk-through interviews with the instructors and qualitative inductive coding, two profiles of instructor analytics use were identified that were distinct from each other in terms of the goals of analytics use, how instructors made sense of and took actions upon the analytics, and the ways that ethical concerns were conceived. Specifically, one group of instructors used analytics to help students get aligned to and engaged in the course, whereas the other group used analytics to align the course to meet students' needs. Instructors in both profiles saw ethical questions as central to their learning analytics use, with instructors in one profile focusing on transparency and the other on student privacy and agency. These findings suggest the need to view analytics use as an integrated component of instructor teaching practices and envision complementary sets of technical and pedagogical support that can best facilitate the distinct activities aligned with each profile.<br/></div> © 2022 ACM.},
key = {Students},
keywords = {Ethical technology;Teaching;},
note = {Complementary sets;Data-informed teaching;Ethical concerns;Ethical question;Instructional dashboard;Pedagogical supports;Teacher inquiry;Teachers';Teaching practices;Technical support;},
URL = {http://dx.doi.org/10.1145/3506860.3506905},
} 


@inproceedings{20221311833260 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of Automatic Data-Driven Feedback to Students Using Explainable Machine Learning},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Afzaal, Muhammad and Nouri, Jalal and Zia, Aayesha and Papapetrou, Panagiotis and Fors, Uno and Wu, Yongchao and Li, Xiu and Weegar, Rebecka},
volume = {12749 LNAI},
year = {2021},
pages = {37 - 42},
issn = {03029743},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper proposes a novel approach that employs learning analytics techniques combined with explainable machine learning to provide automatic and intelligent actionable feedback that supports students self-regulation of learning in a data-driven manner. Prior studies within the field of learning analytics predict students’ performance and use the prediction status as feedback without explaining the reasons behind the prediction. Our proposed method, which has been developed based on LMS data from a university course, extends this approach by explaining the root causes of the predictions and automatically provides data-driven recommendations for action. The underlying predictive model effectiveness of the proposed approach is evaluated, with the results demonstrating 90 per cent accuracy.<br/></div> © 2021, Springer Nature Switzerland AG.},
key = {Forecasting},
keywords = {Students;Machine learning;},
note = {Analytic technique;Dashboard;Data driven;Explainable machine learning;Feedback provision;Feedback to students;Learning analytic;Machine-learning;Recommendation generation;Self regulation;},
URL = {http://dx.doi.org/10.1007/978-3-030-78270-2_6},
} 


@inproceedings{20162202436124 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Digitally enhanced assessment in virtual learning environments},
journal = {Proceedings - DMS 2015: 21st International Conference on Distributed Multimedia Systems},
author = {Di Bitonto, Pierpaolo and Pesare, Enrica and Roselli, Teresa and Rossano, Veronica},
year = {2015},
pages = {148 - 154},
address = {Vancouver, BC, Canada},
abstract = {One of the main challenges in teaching and learning activities is the assessment: it allows teachers and learners to improve the future activities on the basis of the previous ones. It allows a deep analysis and understanding of the whole learning process. This is particularly difficult in virtual learning environments where a general overview is not always available. In the latest years, Learning Analytics are becoming the most popular methods to analyze the data collected in the learning environments in order to support teachers and learners in the complex process of learning. If they are properly integrated in learning activities, indeed, they can supply useful information to adapt the activities on the basis of student's needs. In this context, the paper presents a solution for the digitally enhanced assessment. Two different Learning Dashboards have been designed in order to represent the most interesting Learning Analytics aiming at providing teachers and learners with easy understandable view of learning data in virtual learning environments.<br/>},
key = {Teaching},
keywords = {E-learning;Computer aided instruction;Learning systems;},
note = {Assessment;Complex Processes;Learning Activity;Learning Analytics;Learning Dashboard;Learning environments;Teaching and learning;Virtual learning environments;},
URL = {http://dx.doi.org/10.18293/DMS2015-34},
} 


@article{20174804477775 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Facilitating Student Success in Introductory Chemistry with Feedback in an Online Platform},
journal = {Technology, Knowledge and Learning},
author = {Van Horne, Sam and Curran, Maura and Smith, Anna and VanBuren, John and Zahrieh, David and Larsen, Russell and Miller, Ross},
volume = {23},
number = {1},
year = {2018},
pages = {21 - 40},
issn = {22111662},
abstract = {Instructional technologists and faculty in post-secondary institutions have increasingly adopted learning analytics interventions such as dashboards that provide real-time feedback to students to support student’ ability to regulate their learning. But analyses of the effectiveness of such interventions can be confounded by measures of students’ prior learning as well as their baseline level of self-regulated learning. For this research study, we sought to examine whether the frequency of accessing a dashboard was associated with learning outcomes after matching subjects on confounding variables. And because prior research has suggested that measures of prior learning are associated with students’ likelihood to use learning analytics interventions, we sought to adequately control for learners’ likelihood to access the feedback by using a propensity score matching with a non-binary treatment variable. We administered the Motivated Strategies for Learning Questionnaire and also collected demographic information for a propensity score matching process. Users’ frequency of accessing the intervention was categorized as High, Moderate, or Low/No usage. After matching users on characteristics associated with dashboard usage (gender, high school GPA, and the "Test Anxiety" and "Self Efficacy" factors) we found that both the "High" and "Moderate" users achieved significantly higher course grades than the "Low/No" users. The results suggest learners benefited from regularly accessing the feedback, but extreme amounts of usage were not necessary to achieve a positive effect. We discuss the implications for recommending how students use learning analytics interventions without excessively accessing feedback.<br/> © 2017, Springer Science+Business Media B.V., part of Springer Nature.},
key = {Feedback},
keywords = {Learning systems;E-learning;Teaching;Students;},
note = {Demographic information;Introductory chemistry;Learning analytics;Post-secondary institutions;Propensity score matching;Real-time feedback;Self-regulated learners;Self-regulated learning;},
URL = {http://dx.doi.org/10.1007/s10758-017-9341-0},
} 


@inproceedings{20143518106822 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Heterogeneous educational data integration and knowledge discovery to supporting competency assessment in SCALA web tool},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Rayon, Alex and Guenaga, Mariluz and Nunez, Asier},
volume = {8719 LNCS},
year = {2014},
pages = {584 - 585},
issn = {03029743},
address = {Graz, Austria},
abstract = {The lack of data interoperability among different educational systems imposes a challenge to data analytics. To face these problems, we have developed SCALA (Scalable Competency Assessment web platform through a Learning Analytics approach), an integrated analytics system that employs Learning Analytics techniques to visualize in a single interface enriched indicators to teachers and learners, gaining insights into their habits and the impact of their learning activities. © 2014 Springer International Publishing Switzerland.<br/>},
key = {Data integration},
keywords = {Interoperability;Teaching;},
note = {Analytics systems;Competency assessment;dashboard;Data interoperability;Educational systems;Learning Activity;learning analytics;Learning metrics;},
URL = {http://dx.doi.org/10.1007/978-3-319-11200-8_81},
} 


@inproceedings{20184406015936 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Analytics for everyday learning from two perspectives: Knowledge workers and teachers},
journal = {CEUR Workshop Proceedings},
author = {Fessl, Angela and Kowald, Dominik and Sola, Susana Lopez and Moreno, Ana and Maturana, Ricardo Alonso and Thalmann, Stefan},
volume = {2209},
year = {2018},
issn = {16130073},
address = {Leeds, United kingdom},
abstract = {Learning analytics deals with tools and methods for analyzing and detecting patterns in order to support learners while learning in formal as well as informal learning settings. In this work, we present the results of two focus groups in which the effects of a learning resource recommender system and a dashboard based on analytics for everyday learning were discussed from two perspectives: (1) knowledge workers as self-regulated everyday learners (i.e., informal learning) and (2) teachers who serve as instructors for learners (i.e., formal learning). Our findings show that the advantages of analytics for everyday learning are three-fold: (1) it can enhance the motivation to learn, (2) it can make learning easier and broadens the scope of learning, and (3) it helps to organize and to systematize everyday learning.<br/> © 2018 CEUR-WS. All rights reserved.},
key = {Recommender systems},
keywords = {Knowledge management;Learning systems;},
note = {Focus groups;Formal learning;Informal learning;Knowledge workers;Learning analytics;Learning resource;Three folds;Tools and methods;},
} 


@unpublished{20200341572 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The TA framework: Designing real-time teaching augmentation for K-12 classrooms},
journal = {arXiv},
author = {An, Pengcheng and Holstein, Kenneth and D'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
year = {2020},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design.<br/></div> Copyright © 2020, The Authors. All rights reserved.},
key = {Economic and social effects},
keywords = {Ambient intelligence;},
note = {Ambient intelligence;Ambients;Augmentation systems;Augmented intelligence;Classroom;Dashboard;K-12;Orchestration;Real- time;Teachers';},
} 


@inproceedings{20184406003050 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Designing dashboards for students and instructors in a Sakai supported face-To-face learning environment},
journal = {CEUR Workshop Proceedings},
author = {Haro-Valle, Valeria and Benlloch-Dualde, Jose-V. and Lemus-Zuniga, Lenin Y Maldonado-Mahauad and Jorge, J.},
volume = {2231},
year = {2018},
issn = {16130073},
address = {Guayaquil, Ecuador},
abstract = {A very recent review of the literature in the field of Visual Learning Analytics states that the use of these techniques is quite frequent in blended learning or online learning environments, including MOOCs. However, this is not the case in classroom learning environments. In this context, the paper aims at studying how using Visual Learning Analytics can contribute to a better understanding of the educational processes in face-To-face educational contexts, supported by a Sakai-based Virtual Learning Environment. Considering that the institutional platform reports are only available for teachers, the main objective is the design and implementation of a learning dashboard that could help students in their learning process. To accomplish that, it should integrate data from different sources, generating easy to understand visual representations. Additionally, the same data sources will be used to develop a dashboard for instructors that could help them to provide formative feedback to their students, or to improve the teaching materials they use. In order to create the dashboards, visualization tools such as Tableau and QlikSense have been initially employed. However, it was decided to use the Java script library D3.js, as it allows us to create any imaginable visualization and because of the interactivity it offers. To conclude, some preliminary results are discussed, and further research is outlined.<br/> © 2018 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {Computer aided instruction;E-learning;Visualization;},
note = {Design and implementations;Face-to-face learning;Learning Dashboard;Online learning environment;Sakai;Virtual learning environments;Visual learning;Visual representations;},
} 


@inproceedings{20194607694374 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Chemistry pods: A mutlimodal real time and retrospective tool for the classroom},
journal = {ICMI 2019 - Proceedings of the 2019 International Conference on Multimodal Interaction},
author = {Anderson, Khalil and Dubiel, Theodore and Tanaka, Kenji and Worsley, Marcelo},
year = {2019},
pages = {506 - 507},
address = {Suzhou, China},
abstract = {Instructors are often multitasking in the classroom. This makes it increasingly difficult for them to pay attention to each individual's engagement especially during activities where students are working in groups. In this paper, we describe a system that aids instructors in supporting group collaboration by utilizing a centralized, easy-to-navigate dashboard connected to multiple pods dispersed among groups of students in a classroom or laboratory. This allows instructors to check multiple qualities of the discussion such as: the usage of instructor specified keywords, relative participation of each individual, the speech acts students are using and different emotional characteristics of group language.<br/> © 2019 Copyright held by the owner/author(s).},
key = {Students},
note = {Audio processing;Collaboration;Group collaboration;Learning analytics;Multiple quality;Real time;Speech acts;},
URL = {http://dx.doi.org/10.1145/3340555.3358662},
} 


@inproceedings{20181905173244 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Differences of online learning behaviors and eye-movement between students having different personality traits},
journal = {MIE 2017 - Proceedings of the 1st ACM SIGCHI International Workshop on Multimodal Interaction for Education, Co-located with ICMI 2017},
author = {Sun, Bo and Lai, Song and Xu, Congcong and Xiao, Rong and Wei, Yungang and Xiao, Yongkang},
volume = {2017-November},
year = {2017},
pages = {71 - 75},
address = {Glasgow, United kingdom},
abstract = {The information technologies are integrated into education so that mass data is available reflecting each action of students in online environments. Numerous studies have exploited these data to do the learning analytics. In this paper, we aim at achieving the show of personalized indicators for students per personality trait on the learning analytics dashboard (LAD) and present the preliminary results. First, we employ learning behavior engagement (LBE) to describe students' learning behaviors, exploited to analyze the significant differences among students having different personality traits. In experiments, fifteen behavioral indicators are tested. The experimental results show that there are significant differences about some behavioral indicators among personality traits. Second, some of these behavioral indicators are presented on the LAD and distributed in each area of interest (AOI). Hence, students can visualize their behavioral data that they care about in AOIs anytime in the learning process. Through the analysis of eye-movement including the fixation duration, fixation count, heat map and track map, we have found that there are significant differences about some visual indicators in AOIs. This is partly consistent with the results of behavioral indicators.<br/> © 2017 Association for Computing Machinery.},
key = {Eye movements},
keywords = {E-learning;Students;},
note = {Area of interest;Behavioral indicators;Fixation duration;Learning analytics;Learning behavior;Online environments;Personality traits;Visual indicators;},
URL = {http://dx.doi.org/10.1145/3139513.3139527},
} 


@inproceedings{20220511578764 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {SBGTool: Similarity-Based Grouping Tool for Students' Learning Outcomes},
journal = {Proceedings of the 2021 Swedish Workshop on Data Science, SweDS 2021},
author = {Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
year = {2021},
pages = {Fortnox AB; IEEE Sweden Section; Linnaeus University; MDPI Data - },
address = {Virtual, Vaxjo, Sweden},
abstract = {<div data-language="eng" data-ev-field="abstract">With the help of Visual Learning Analytics (VLA) tools, teachers can construct meaningful groups of students that can, for example, collaborate and be engaged in productive discussions. However, finding similar samples in large educational databases requires effective similarity measures that capture the teacher's intent. In this paper we propose a web-based VLA tool called Similarity-Based Grouping (SBGTool), to assist teachers in categorizing students into different groups based on their similar learning outcomes and activities. By using SBGTool, teachers may compare individual students by considering the number of answers (correct and incorrect) in different question categories and time ranges, find the most difficult question categories considering the percentage of similarity to the correct answers, determine the degree of similarity and dissimilarity across students, and find the relationship between students' activity and success. To demonstrate the tool's efficacy, we used 10,000 random samples from the EdNet dataset, a large-scale hierarchical educational dataset consisting of student-system interactions from multiple platforms, at university level, collected over a period of two years. The results point to the conclusion that the tool is efficient, can be adapted to different learning domains, and has the potential to assist teachers in maximizing the collaborative learning potential in their classrooms.<br/></div> © 2021 IEEE.},
key = {Data visualization},
keywords = {Students;Large dataset;},
note = {Analytic tools;Ednet;Educational data;Learning analytic dashboard;Question categories;Similarity-based grouping;Student learning outcomes;Teachers';Visual learning;Visual learning analytic;},
URL = {http://dx.doi.org/10.1109/SweDS53855.2021.9638263},
} 


@inproceedings{20182705519610 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Communication at scale in a MOOC using predictive engagement analytics},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Le, Christopher V. and Pardos, Zachary A. and Meyer, Samuel D. and Thorp, Rachel},
volume = {10947 LNAI},
year = {2018},
pages = {239 - 252},
issn = {03029743},
address = {London, United kingdom},
abstract = {When teaching at scale in the physical classroom or online classroom of a MOOC, the scarce resource of personal instructor communication becomes a differentiating factor between the quality of learning experience available in smaller classrooms. In this paper, through real-time predictive modeling of engagement analytics, we augment a MOOC platform with personalized communication affordances, allowing the instructional staff to direct communication to learners based on individual predictions of three engagement analytics. The three model analytics are the current probability of earning a certificate, of submitting enough materials to pass the class, and of leaving the class and not returning. We engineer an interactive analytics interface in edX which is populated with real-time predictive analytics from a backend API service. The instructor can target messages to, for example, all learners who are predicted to complete all materials but not pass the class. Our approach utilizes the state-of-the-art in recurrent neural network classification, evaluated on a MOOC dataset of 20 courses and deployed in one. We provide evaluation of these courses, comparing a manual feature engineering approach to an automatic feature learning approach using neural networks. Our provided code for the front-end and back-end allows any instructional team to add this personalized communication dashboard to their edX course granted they have access to the historical clickstream data from a previous offering of the course, their course’s daily provided log data, and an external machine to run the model service API.<br/> © Springer International Publishing AG, part of Springer Nature 2018.},
key = {User interfaces},
keywords = {Recurrent neural networks;Application programming interfaces (API);Predictive analytics;Classification (of information);Learning systems;},
note = {Drop-out;Engagement;Learning analytics;MOOCs;Representation learning;},
URL = {http://dx.doi.org/10.1007/978-3-319-93843-1_18},
} 


@inproceedings{20192707151736 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Detection of collaboration: Relationship between log and speech-based classification},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Viswanathan, Sree Aurovindh and Vanlehn, Kurt},
volume = {11626 LNAI},
year = {2019},
pages = {327 - 331},
issn = {03029743},
address = {Chicago, IL, United states},
abstract = {Research in the field of collaboration shows that students do not spontaneously collaborate with each other. A system that can measure collaboration in real time could be useful by, for example, helping the teacher locate a group requiring guidance. To address this challenge, my research focuses on building and comparing collaboration detectors for different types of classroom problem solving activities, such as card sorting and hand writing. I am also studying transfer: how collaboration detectors for one task can be used with a new task. Finally, we attempt to build a teachers dashboard that can describe reasoning behind the triggered alerts thereby helping the teachers with insights to aid the collaborative activity. Data for building such detectors were collected in the form of verbal interaction and user action logs from students’ tablets. Three qualitative levels of interactivity was distinguished: Collaboration, Cooperation and Asymmetric Contribution. Machine learning was used to induce a classifier that can assign a code for every episode based on the set of features. Our preliminary results indicate that machine learned classifiers were reliable.<br/> © Springer Nature Switzerland AG 2019.},
key = {Machine learning},
note = {Card-sorting;Collaborative activities;Collaborative learning;Hand writing;Interactivity;Learning analytics;Research focus;Verbal interaction;},
URL = {http://dx.doi.org/10.1007/978-3-030-23207-8_60},
} 


@inproceedings{20144600188555 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning process analytics for a self-study class in a semantic mediawiki},
journal = {Proceedings of the 10th International Symposium on Open Collaboration, OpenSym 2014},
author = {Schneider, Daniel K. and Class, Barbara and Benetos, Kalliopi and Da Costa, Julien and Follonier, Valerie},
year = {2014},
pages = {D3 - },
address = {Berlin, Germany},
abstract = {We describe a framework and an implementation of learning process analytics for both learners and teachers to enhance a self-study class on psychological and educational theory. The environment is implemented in a Semantic MediaWiki using Semantic Forms and Semantic Result Formats. The design is in early development, but it is deployed and operational.<br/>},
key = {Semantics},
keywords = {E-learning;Semantic Web;Teaching;Computer software;Learning systems;},
note = {Learning analytics;Learning dashboard;Online learning;Self-study course;Semantic mediawiki;},
URL = {http://dx.doi.org/10.1145/2641580.2641605},
} 


@inproceedings{20154101369551 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student focused dashboards: An analysis of current student dashboards and what students really want},
journal = {CSEDU 2015 - 7th International Conference on Computer Supported Education, Proceedings},
author = {Reimers, Gabriel and Neovesky, Anna},
volume = {1},
year = {2015},
pages = {399 - 404},
address = {Lisbon, Portugal},
abstract = {Online learning analytics dashboards are already available in various online learning platforms and are in use at schools and universities. In this paper we give an overview about several existing dashboard applications. Most of these dashboards are either targeted at teachers and tutors or focus on the presentation of research relevant learning analytics concepts. We present two surveys among school and university students asking them about their requirements on a learning dashboard. The results show that basic requirements of students are not addressed in current learning platforms and dashboards. We formulate several research questions that need to be answered to create dashboards that put students in the center of dashboard design processes and give an outline of our own efforts in that direction.<br/>},
key = {Students},
keywords = {Visualization;E-learning;Teaching;},
note = {Dashboards;Design process;Learning analytics;Learning platform;Online learning;Research questions;Self reflection;University students;},
URL = {http://dx.doi.org/10.5220/0005475103990404},
} 


@inproceedings{20231313819170 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Teaching Analytics Across Multiple Systems: A Case Study at a Junior High School in Japan},
journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
author = {Nakamura, Kohei and Horikoshi, Izumi and Ogata, Hiroaki},
volume = {2},
year = {2022},
pages = {702 - 704},
address = {Kuala Lumpur, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">This study analyzed and visualized the daily behaviors of teachers on multiple systems using Experience API (xAPI). The results revealed that the learning management system was routinely used, while the learning analytics dashboard was not. Further, we examined how the teacher used the dashboard during the experimental classes with a learning analytics researcher. The results showed that the use of e-book readers and dashboards was encouraged on the day when the researcher attended class together. Additionally, the timings when the teacher checked the dashboard were getting earlier in each class. These results imply that the repeated use of a dashboard and the help of an expert foster the literacy of teachers in using educational data in their classes.<br/></div> © ICCE 2022.All rights reserved.},
key = {Learning systems},
note = {Case-studies;Daily behaviors;Data literacy;E-books;Junior high schools;Learning management system;Multiple systems;Teachers';Teaching analytics;XAPI;},
} 


@inproceedings{20192507077909 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {From heterogeneous activities to unified analytics dashboards},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Martinez-Ortiz, Ivan and Perez-Colado, Ivan and Rotaru, Dan Cristian and Freire, Manuel and Fernandez-Manjon, Baltasar},
volume = {April-2019},
year = {2019},
pages = {1108 - 1113},
issn = {21659559},
address = {Dubai, United arab emirates},
abstract = {Teachers often wish to integrate activities from disparate sources into their courses. For example, gamified activities, mediated through technology, can promote the type of active learning required to develop higher-level engagement by students. However, unless the activities have been designed to facilitate it, integrating their analytics into a single dashboard can require significant development effort. A general solution to such heterogeneous analytics integration can be of great value, by presenting a single view of student actions throughout the different parts of a course. We describe the problems presented when integrating the analytics of three heterogeneous stand-alone activities, in the context of a EU project to improve software engineering teaching. The idea is to increase student engagement via gamification, and explore the design space of possible solutions for providing integrated analytics over the heterogeneous activities. We then describe the design of a proof-of-concept implementation, based on the use of both xAPI trackers and simple CSV files for information exchange, single sign-on, a minimal class management web application, and updates to the analytics platform to allow dynamic changes in the multi-level analysis. The resulting approach can be readily applied to similar heterogeneous scenarios.<br/> © 2019 IEEE.},
key = {Serious games},
keywords = {Curricula;Students;Teaching;Software engineering;},
note = {Analytics;Dynamic changes;General solutions;Information exchanges;Learning analytics;Multi-level analysis;Proof of concept;Student engagement;},
URL = {http://dx.doi.org/10.1109/EDUCON.2019.8725222},
} 


@article{20233014446017 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Co-designing teacher support technology for problem-based learning in middle school science},
journal = {British Journal of Educational Technology},
author = {Hutchins, Nicole M. and Biswas, Gautam},
volume = {55},
number = {3},
year = {2024},
pages = {802 - 822},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper provides an experience report on a co-design approach with teachers to co-create learning analytics-based technology to support problem-based learning in middle school science classrooms. We have mapped out a workflow for such applications and developed design narratives to investigate the implementation, modifications and temporal roles of the participants in the design process. Our results provide precedent knowledge on co-designing with experienced and novice teachers and co-constructing actionable insight that can help teachers engage more effectively with their students' learning and problem-solving processes during classroom PBL implementations. Practitioner notes What is already known about this topic Success of educational technology depends in large part on the technology's alignment with teachers' goals for their students, teaching strategies and classroom context. Teacher and researcher co-design of educational technology and supporting curricula has proven to be an effective way for integrating teacher insight and supporting their implementation needs. Co-designing learning analytics and support technologies with teachers is difficult due to differences in design and development goals, workplace norms, and AI-literacy and learning analytics background of teachers. What this paper adds We provide a co-design workflow for middle school teachers that centres on co-designing and developing actionable insights to support problem-based learning (PBL) by systematic development of responsive teaching practices using AI-generated learning analytics. We adapt established human-computer interaction (HCI) methods to tackle the complex task of classroom PBL implementation, working with experienced and novice teachers to create a learning analytics dashboard for a PBL curriculum. We demonstrate researcher and teacher roles and needs in ensuring co-design collaboration and the co-construction of actionable insight to support middle school PBL. Implications for practice and/or policy Learning analytics researchers will be able to use the workflow as a tool to support their PBL co-design processes. Learning analytics researchers will be able to apply adapted HCI methods for effective co-design processes. Co-design teams will be able to pre-emptively prepare for the difficulties and needs of teachers when integrating middle school teacher feedback during the co-design process in support of PBL technologies.<br/></div> © 2023 British Educational Research Association.},
key = {Educational technology},
keywords = {Curricula;Design;Engineering education;Human computer interaction;Students;},
note = {Co-designing;Co-designs;Design-process;HLCA;Middle school;Problem based learning;School teachers;Support technology;Teachers';Work-flows;},
URL = {http://dx.doi.org/10.1111/bjet.13363},
} 


@inproceedings{20162702561831 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Investigating collaborative learning success with physiological coupling indices based on electrodermal activity},
journal = {ACM International Conference Proceeding Series},
author = {Hector, J. Pijeira-Diaz and Drachsler, Hendrik and Jarvela, Sanna and Kirschner, Paul A.},
volume = {25-29-April-2016},
year = {2016},
pages = {64 - 73},
address = {Edinburgh, United kingdom},
abstract = {Collaborative learning is considered a critical 21st century skill. Much is known about its contribution to learning, but still investigating a process of collaboration remains a challenge. This paper approaches the investigation on collaborative learning from a psychophysiological perspective. An experiment was set up to explore whether biosensors can play a role in analysing collaborative learning. On the one hand, we identified five physiological coupling indices (PCIs) found in the literature: 1) Signal Matching (SM), 2) Instantaneous Derivative Matching (IDM), 3) Directional Agreement (DA), 4) Pearson's correlation coeficient (PCC) and the 5) Fisher's z-transform (FZT) of the PCC. On the other hand, three collaborative learning measurements were used: 1) collaborative will (CW), 2) collaborative learning product (CLP) and 3) dual learning gain (DLG). Regression analyses showed that out of the five PCIs, IDM related the most to CW and was the best predictor of the CLP. Meanwhile, DA predicted DLG the best. These results play a role in determining informative collaboration measures for designing a learning analytics, biofeedback dashboard.<br/>},
key = {Biofeedback},
keywords = {Correlation methods;Electrodes;Regression analysis;Z transforms;Frequency response;Physiology;},
note = {Collaborative learning;Correlation coeficient;Coupling indices;Electrodermal activity;Learning analytics;Learning gain;Signal matching;},
URL = {http://dx.doi.org/10.1145/2883851.2883897},
} 


@inproceedings{20243817059010 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Investigating Metacognitive Behaviors with Online Learning Support Tools},
journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
author = {Yamada, Masanori and Geng, Xuewang and Goda, Yoshiko and Teasley, Stephanie D.},
year = {2024},
pages = {280 - 284},
address = {Hybrid, Nicosia, Cyprus},
abstract = {<div data-language="eng" data-ev-field="abstract">As information technology advanced, accuracy of technology-driven assessment is being improved. In order to assess learning performance and awareness, assessment of metacognition level with technology can be useful to understand learner's learning comprehension and awareness. Metacognition is one of the most important elements for successful learning. However, current way to evaluate metacognition level focuses on psychological method such as questionnaire and interview. The recent growth of learning analytics research has demonstrated the relationships between metacognition, learning awareness, and learning behaviors. This study aims to investigate metacognitive learning behaviors using small grain data on eBook and learning analytics dashboard (LAD) over eight weeks in a university course. To do so, we determined high and low metacognitive learner groups using the Metacognitive Awareness Inventory and investigated the differences between the two groups in eBook and LAD. The findings suggest that four learning behaviors eBook and LAD were detected as metacognitive learning behaviors, and contribute to the improvement of technology-driven assessment.<br/></div> © 2024 IEEE.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;},
note = {E-books;Learning analytic;Learning behavior;Learning support tool;Meta-cognitive behavior;Meta-cognitive learning;Metacognition;Online learning;Small grains;Small-grain data;},
URL = {http://dx.doi.org/10.1109/ICALT61570.2024.00088},
} 


@inproceedings{20171403522587 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {ATCE - An analytics tool to trace the creation and evaluation of inclusive and accessible open educational resources},
journal = {ACM International Conference Proceeding Series},
author = {Avila, Cecilia and Fabregat, Ramon and Baldiris, Silvia and Graf, Sabine},
year = {2017},
pages = {183 - 187},
address = {Vancouver, BC, Canada},
abstract = {The creation of Inclusive and Accessible Open Educational Resources (IA-OERs) is a challenge for teachers because they have to invest time and effort to create learning contents considering students' learning needs and preferences. An IA-OER is characterized by its alignment with the Universal Design Learning (UDL) principles, the quality on its contents and the web accessibility as a way to address the diversity of students. Creating an IA-OER with these characteristics is not a straightforward task, especially when teachers do not have enough information/feedback to make decisions on how to improve the learning contents. In this paper we introduce ATCE - an Analytics Tool to Trace the Creation and Evaluation of IA-OERs. This tool focuses in particular on the accessibility and quality of the IA-OERs. ATCE was developed as a module within the ATutor Learning Management System (LMS). An analytics dashboard with visualizations related to the teachers' competences in the creation and evaluation of IA-OERs was included as part of the tool. This paper also presents a use case of the visualizations obtained from the creation and evaluation of one IA-OER after using our analytics tool.<br/> © 2017 ACM.},
key = {Visualization},
keywords = {Students;Teaching;Quality control;Websites;},
note = {Competences;Learning analytics;Open educational resources;Teachers;Web accessibility;},
URL = {http://dx.doi.org/10.1145/3027385.3027413},
} 


@inproceedings{20182805541624 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Utilization measures in a learning management system},
journal = {Communications in Computer and Information Science},
author = {Meluso, Floriana and Avogadro, Paolo and Calegari, Silvia and Dominoni, Matteo},
volume = {814},
year = {2018},
pages = {176 - 196},
issn = {18650929},
address = {Madrid, Spain},
abstract = {Learning Management Systems (LMSs) are becoming more and more popular and incorporate many different functionalities. For this reason, an evaluation of the quantitative utilization of all the parts of a LMS is essential. In this research we propose indicators and techniques which allow to understand in detail how a functionality is accessed by the users. These analytic tools are useful in particular for the administrators of the LMS which are in charge of allocating resources according to the workload and importance of the functionalities. We tested the proposed indicators with the data obtained from the LMS of Università degli Studi di Milano-Bicocca (Milan, Italy) about the messaging functionality. Although the students’ messages can potentially be a source of big data, in the present case it is observed that the utilization is limited. With this analysis it has been possible to notice a similarity between the utilization of the message system and the empirical Zipf law. We also introduced the description of the structure of a dashboard which allows to access to the indicators and goes towards the definition of a global tool for students, teachers and administrators.<br/> © Springer International Publishing AG, part of Springer Nature 2018.},
key = {Computational linguistics},
keywords = {Learning systems;},
note = {Analytic tools;Learning analytics;Learning management system;Message systems;Milan , Italy;Zipf;Zipf Law;},
URL = {http://dx.doi.org/10.1007/978-3-319-94809-6_9},
} 


@inproceedings{20190306392511 ,
language = {German},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Facing the general data privacy regulation: What data is being collected about me and how can I get access?},
title = {Der EU-Datenschutz-Grundverordnung begegnen: Welche Daten sind über mich erhoben und wie komme ich da ran?},
journal = {CEUR Workshop Proceedings},
author = {Kiy, Alexander and Sass, Kristin and Lucke, Ulrike},
volume = {2250},
year = {2018},
issn = {16130073},
address = {Frankfurt, Germany},
abstract = {With the General Data Privacy Regulation (GDPR) coming into force, users get new and advanced privileges in dealing with their personal data. Especially in virtual learning environments, where manifold data is aggregated and processed, the transparency about which data is gathered, and saved is lost quickly. When the number of applications increases, it gets even more confusing for the users to keep track of their data. In addition, at worst case it entails several manual steps by the service providers to exercise the data subject rights. This article presents a self-information dashboard, by which the users achieve an overview about their personal data. The implementation of the use cases is based on the GDPR fundamental data subject rights and is automated as far possible. Therefore, users can exercise most of their rights without manual intervention of service providers. The article closes with a discussion about current limitations and future challenges.<br/> © 2018 CEUR-WS. All rights reserved.},
key = {Data privacy},
keywords = {Computer aided instruction;},
note = {Current limitation;DSGVO;GDPR;Learning Analytics;Manual intervention;Privacy regulation;Self Service;Virtual learning environments;},
} 


@inproceedings{20224212974756 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A proposal to measure the understanding of data visualization elements in visual analytics applications},
journal = {CEUR Workshop Proceedings},
author = {Vazquez-Ingelmo, Andrea and Garcia-Penalvo, Francisco Jose and Theron, Roberto and Byrd, Vetria and Camba, Jorge D.},
volume = {3238},
year = {2022},
pages = {70 - 76},
issn = {16130073},
address = {Salamanca, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">Data visualizations and information dashboards are useful but complex tools. They must be fully understood to draw proper insights and to avoid misleading conclusions. However, several elements and factors are involved in this domain, which makes it difficult to learn. In previous works, we proposed a meta-model to capture the primitive elements that compose visualizations and dashboards. This meta-model has served as a framework for conducting data visualization research, but also to develop a graphical tool for generating data visualizations and dashboards. This tool (namely MetaViz) enables users to create data visualizations through fine-grained components based on the entities represented in the meta-model. The main goal of the system is to provide a learning experience in which users can freely add and configure elements to understand how they influence the final display. This work describes work in progress to validate the pedagogical value of MetaViz in terms of the understanding of data visualization concepts.<br/></div> © 2022 Copyright for this paper by its authors.},
key = {Data visualization},
keywords = {Visualization;},
note = {Fine-grained components;Graphical tools;Information dashboard;Learn+;Meta model;Metamodeling;Primitive element;Understandability;Visual analytics;Visualization research;},
} 


@inproceedings{20241816016119 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {36th International Conference on Computer Applications in Industry and Engineering, CAINE 2023},
journal = {EPiC Series in Computing},
volume = {97},
year = {2024},
issn = {23987340},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 11 papers. The special focus in this conference is on Computer Applications in Industry and Engineering. The topics include: KWDOA: Adapted dataset for detection of the direction of arrival of the keyword; EX-LAD: an Explainable Learning Analytics Dashboard in Higher Education; a Workflow Model Based on Three Pillars: Processes, Technology and People within an Organization; Accelerating the execution of the Partition Problem on PYNQ FPGA platform; Peer-to-Peer Data Transfer Evaluation in SmartSSD-based Multi-devices System; an Evaluation of Strategies for Dimensionality Reduction; establishing Trust using Zero Knowledge Succinct Proof in Peer-to-peer Data Transfer; tensor decompositions in cancer study; A comprehensive review.<br/></div>},
} 


@inproceedings{20145100339095 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Improving teacher awareness through activity, Badge and content visualizations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Charleer, Sven and Santos, Jose Luis and Klerkx, Joris and Duval, Erik},
volume = {8699},
year = {2014},
pages = {143 - 152},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {This paper introduces LARAe (Learning Analytics Reflection & Awareness environment), a teacher-oriented dashboard that visualizes learning traces from students, badges and course content. We also present an evaluation of the dashboard in a course on Human-Computer Interaction. The LARAe teacher dashboard provides a detailed overview of group and individual activities, achievements and course outcomes. To help visualize the abundance of traces, badges are used to abstract essential aspects of the course such as course goals and social activity. This paper reports our work on LARAe, presents the course in which we evaluated our approach with students and teachers, and analyses our first results that indicate that such an environment can help with teacher awareness.<br/> © Springer International Publishing Switzerland 2014.},
key = {Teaching},
keywords = {Curricula;Computer aided instruction;Visualization;Human computer interaction;Information systems;},
note = {Awareness;Collaboration;Information visualization;Learning analytics;Learning dashboards;Open badges;},
URL = {http://dx.doi.org/10.1007/978-3-319-13296-9_16},
} 


@inproceedings{20220711637787 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An Investigation into the Design of Learning Analytic Dashboards (LAD) for the Enhancement of Motivation, Engagement and Achievements in an E-Learning Environment},
journal = {Proceedings of the 33rd International BCS Human Computer Interaction Conference, BCS HCI 2020},
author = {Thiruppugal, Mithila},
year = {2020},
pages = {48 - 50},
address = {Keele, United kingdom},
abstract = {<div data-language="eng" data-ev-field="abstract">The current scenario of higher education reflects an increased permeation of digital technology, with this integration has influenced both learning and teaching practices. One of the main impacts has been in the advancement of Learning Management Systems (LMS). By facilitating synchronous and asynchronous communication and interactions linked to a virtual environment, LMSs have become integral to higher education. Learning Analytic Dashboards (LAD) are the digital platforms used by educational institutions for collecting, measuring, analysing and reporting data concerning learners and their activities and achievements. Related to that, as an area of research and development, learning Analytics is a rapidly growing field of LMS and of particular significance to LAD design. Many universities are utilising LADs, but guidelines to support effective design underpinned by research are limited. This study aims to assess the role of LAD design in optimising learning by influencing factors such as student motivation, engagement and achievement. The significance of this study is that it will offer novel insights on principles that should be adopted while designing LADs capable of leading students towards better learning experience and performance. Based on implications from previous studies as well as an empirical investigation on the need for such tools, this study will develop a prototype of a LAD that befits with student-facing demands.<br/></div> © Thiruppugal. Published by BCS Learning and Development Ltd.},
key = {Students},
keywords = {Computer aided instruction;E-learning;Information management;Learning systems;Motivation;Virtual reality;},
note = {'current;Digital technologies;E-learning environment;High educations;Information visualization;Learning analytic dashboard;Learning and teachings;Learning management system;Synchronous and asynchronous communications;Teaching practices;},
URL = {http://dx.doi.org/10.14236/ewic/HCI20DC.11},
} 


@inproceedings{20232614327136 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 5th European Conference on Software Engineering Education, ECSEE 2023},
journal = {ACM International Conference Proceeding Series},
year = {2023},
address = {Seeon/Bavaria, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 32 papers. The topics discussed include: reflections on training next-gen industry workforce on secure software development; the gap between higher education and the software industry – a case study on technology differences; using automatic program assessment in a software development project course; using learning analytics to identify student learning profiles for software development courses; learning analytics dashboard for educators: proposed project to design with pedagogical background; towards learning style prediction based on personality; adaptive learning path sequencing based on learning styles within n-dimensional spaces; learning style classification by using Bayesian networks based on the index of learning style; systematic literature review for the use of AI based techniques in adaptive learning management systems; and flipped teaching in software engineering education: results of a long-term study.<br/></div>},
} 


@inproceedings{20243817059026 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
year = {2024},
address = {Hybrid, Nicosia, Cyprus},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 87 papers. The topics discussed include: unlocking access: can audio replace Odia Braille in rural India’s post-pandemic shift to online learning?; technical acceptance, issues, and recommendations of novice Chinese teachers towards 360-degree videos; perspective of AI Chatbots in K-12 education; towards lesson planning interfaces for integration of students’ out-of-classroom experiences; evaluating personality impact on engagement and confusion detection in learning environments; co-design of an adaptive personalized learner dashboard; auto-scoring of math self-explanations by combining visual and language analysis; and game learning analytics in educational digital games: preliminary results of a systematic mapping of analysis techniques and visualization strategies.<br/></div>},
} 


@article{20223912815843 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data science approach for simulating educational data: Towards the development of teaching outcome model (TOM)},
journal = {Big Data and Cognitive Computing},
author = {Ndukwe, Ifeanyi G. and Daniel, Ben K. and Butson, Russell J.},
volume = {2},
number = {3},
year = {2018},
pages = {1 - 18},
issn = {25042289},
abstract = {<div data-language="eng" data-ev-field="abstract">The increasing availability of educational data provides the educational researcher with numerous opportunities to use analytics to extract useful knowledge to enhance teaching and learning. While learning analytics focuses on the collection and analysis of data about students and their learning contexts, teaching analytics focuses on the analysis of the design of the teaching environment and the quality of learning activities provided to students. In this article, we propose a data science approach that incorporates the analysis and delivery of data-driven solution to explore the role of teaching analytics, without compromising issues of privacy, by creating pseudocode that simulates data to help develop test cases of teaching activities. The outcome of this approach is intended to inform the development of a teaching outcome model (TOM), that can be used to inspire and inspect quality of teaching. The simulated approach reported in the research was accomplished through Splunk. Splunk is a Big Data platform designed to collect and analyse high volumes of machine-generated data and render results on a dashboard in real-time. We present the results as a series of visual dashboards illustrating patterns, trends and results in teaching performance. Our research aims to contribute to the development of an educational data science approach to support the culture of data-informed decision making in higher education.<br/></div> © 2018 by the authors. Licensee MDPI, Basel, Switzerland.},
key = {Big data},
keywords = {Data Science;Decision making;Education computing;Quality control;Students;},
note = {Analysis of data;Big data education;Dashboard;Learning context;Student evaluation of teaching;Students' evaluations;Teaching analytics;Teaching and learning;Teaching output model;Teaching practices;},
URL = {http://dx.doi.org/10.3390/bdcc2030024},
} 


@inproceedings{20224212974748 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Content-validation questionnaire of a meta-model to ease the learning of data visualization concepts},
journal = {CEUR Workshop Proceedings},
author = {Vazquez-Ingelmo, Andrea and Garcia-Holgado, Alicia and Garcia-Penalvo, Francisco Jose and Colomo-Palacios, Ricardo},
volume = {3238},
year = {2022},
pages = {6 - 11},
issn = {16130073},
address = {Salamanca, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">Data visualizations and dashboards are powerful means to convey information to large audiences. However, the design and understanding of these tools are not straightforward because several factors are involved. It is essential to rely on theoretical frameworks to design and implement data visualizations for these reasons. In this context, we propose a meta-model to identify and arrange the main characteristics and elements of data visualizations and dashboards. The proposed meta-model provides a powerful artifact to generate information visualizations and dashboards automatically, but also a learning resource to understand how data visualizations elements interact and influence each other. However, it is necessary to validate this artifact to ensure its quality and usefulness. In this paper, we present a work-in-progress or a quality assessment and content validation of the me-ta-model to seek weaknesses and tackle them in subsequent iterations.<br/></div> © 2022 Copyright for this paper by its authors.},
key = {Data visualization},
keywords = {Information analysis;Information systems;Learning systems;Visualization;},
note = {Content validation;Design and implements;Information dashboard;Information visualization;Learning resource;Meta model;Metamodeling;Quality assessment;Quality content;Theoretical framework;},
} 


@article{20192106943129 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Forecasting students' performance through self-regulated learning behavioral analysis},
journal = {International Journal of Distance Education Technologies},
author = {Rodrigues, Rodrigo Lins and Ramos, Jorge Luis Cavalcanti and Silva, Joao Carlos Sedraz and Dourado, Raphael A. and Gomes, Alex Sandro},
volume = {17},
number = {3},
year = {2019},
pages = {52 - 74},
issn = {15393100},
abstract = {The increasing use of the Learning Management Systems (LMSs) is making available an ever-growing, volume of data from interactions between teachers and students. This study aimed to develop a model capable of predicting students' academic performance based on indicators of their self-regulated behavior in LMSs. To accomplish this goal, the authors analyzed behavioral data from an LMS platform used in a public University for distance learning courses, collected during a period of seven years. With this data, they developed, evaluated, and compared predictive models using four algorithms: Decision Tree (CART), Logistic Regression, SVM, and Naïve Bayes. The Logistic Regression model yielded the best results in predicting students' academic performance, being able to do so with an accuracy rate of 0.893 and an area under the ROC curve of 0.9574. Finally, they conceived and implemented a dashboard-like interface intended to present the predictions in a user-friendly way to tutors and teachers, so they could use it as a tool to help monitor their students' learning process.<br/> Copyright © 2019, IGI Global.},
key = {Students},
keywords = {Data mining;Decision trees;Regression analysis;Information management;Distance education;Forecasting;Learning systems;},
note = {Academic performance;Area under the ROC curve;Distance learning course;Educational data mining;Learning Analytics;Learning management system;Logistic Regression modeling;Self-regulated learning;},
URL = {http://dx.doi.org/10.4018/IJDET.2019070104},
} 


@inproceedings{20172903956329 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Knowledge tracking variables in intelligent tutoring systems},
journal = {CSEDU 2017 - Proceedings of the 9th International Conference on Computer Supported Education},
author = {Grubii, Ani and Stankov, Slavomir and itko, Branko and ari, Ines and Toma, Suzana and Brajkovi, Emil and Volari, Tomislav and Vasi, Daniel and Dodaj, Arta},
volume = {1},
year = {2017},
pages = {513 - 518},
address = {Porto, Portugal},
abstract = {In this research we propose a comprehensive set of knowledge indicators aimed to enhance learners' selfreflection and awareness in the learning and testing process. Since examined intelligent tutoring systems do not include additional messaging features, the introduction of common set of knowledge indicators differentiates our approach from the previous studies. In order to investigate the relation between proposed knowledge indicators and learner performance, the correlation and regression analysis were performed for 3 different courses and each examined intelligent tutoring system. The results of correlation and regression analysis, as well as learners' feedback, guided us in discussion about the introduction of knowledge indicators in dashboard-like visualizations of integrated intelligent tutoring system.<br/> Copyright © 2017 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.},
key = {Regression analysis},
keywords = {Education computing;Learning systems;E-learning;Computer aided instruction;},
note = {Correlation and regression analysis;Intelligent tutoring system;Learning analytics;Self reflection;Testing process;},
URL = {http://dx.doi.org/10.5220/0006366905130518},
} 


@inproceedings{20171203482418 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Early-Stage Engagement: Applying Big Data Analytics on Collaborative Learning Environment for Measuring Learners' Engagement Rate},
journal = {Proceedings - 5th International Conference on Educational Innovation through Technology, EITT 2016},
author = {Lu, Owen H.T. and Huang, Anna Y.Q. and Huang, Jeff C.H. and Huang, Chester S.J. and Yang, Stephen J.H.},
year = {2016},
pages = {106 - 110},
address = {Tainan, Taiwan},
abstract = {Computer-supported Collaborative Learning (CSCL) is a pedagogical strategy associated with how learners construct knowledge with a group by computer-based learning system. In recent years, most of the computer-based learning systems record the interaction log of each learner when developing course assignments. However, the recorded data is facing a challenge to expose the learners behaviors during the course and to design a computer-supported collaborative learning activity. To address those challenges in this paper, a novel collaborative programming tool called Software Project Development and Insight Learning Environment (SPDI Learning Environment) is described. The SPDI Learning environment allows learners of computer science to develop course assignments collaboratively. Besides, it allows instructors to investigate the learners behaviors by associating a web-based integrated development environment (IDE) with Big Data analysis pipeline and Visualization Dashboard. In addition to collect real data from courses, we designed learning activities to help teachers to engage the field of CSCL and Learning Analytics.<br/> © 2016 IEEE.},
key = {Big data},
keywords = {Curricula;E-learning;Information analysis;Teaching;Computer aided instruction;Learning systems;Computer programming;Data handling;Data visualization;},
note = {Clickstream data;Collaborative learning environment;Collaborative programming;Computer Supported Collaborative Learning;Computer-based learning systems;Integrated development environment;Learning Analytics;Pedagogical strategies;},
URL = {http://dx.doi.org/10.1109/EITT.2016.28},
} 


@unpublished{20250008971 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {User-Centered Course Reengineering An Analytical Approach to Enhancing Reading Comprehension in Educational Content},
journal = {arXiv},
author = {Sadallah, Madjid},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Delivering high-quality content is crucial for effective reading comprehension and successful learning. Ensuring educational materials are interpreted as intended by their authors is a persistent challenge, especially with the added complexity of multimedia and interactivity in the digital age. Authors must continuously revise their materials to meet learners’ evolving needs. Detecting comprehension barriers and identifying actionable improvements within documents is complex, particularly in education where reading is fundamental. This study presents an analytical framework to help course designers enhance educational content to better support learning outcomes. Grounded in a robust theoretical foundation integrating learning analytics, reading comprehension, and content revision, our approach introduces usage-based document reengineering. This methodology adapts document content and structure based on insights from analyzing digital reading traces-interactions between readers and content. We define reading sessions to capture these interactions and develop indicators to detect comprehension challenges. Our framework enables authors to receive tailored content revision recommendations through an interactive dashboard, presenting actionable insights from reading activity. The proposed approach was implemented and evaluated using data from a European e-learning platform. Evaluations validate the framework’s effectiveness, demonstrating its capacity to empower authors with data-driven insights for targeted revisions. The findings highlight the framework’s ability to enhance educational content quality, making it more responsive to learners’ needs. This research significantly contributes to learning analytics and content optimization, offering practical tools to improve educational outcomes and inform future developments in e-learning.<br/></div> © 2024, CC BY-NC-ND.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Federated learning;},
note = {Analytical approach;Digital age;Educational contents;Educational materials;High quality;Interactivity;Quality content;Reading comprehension;Support learning;User-centred;},
URL = {http://dx.doi.org/10.48550/arXiv.2412.11944},
} 


@inproceedings{20193807453908 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Topic-wise classification of MOOC discussions: A visual analytics approach},
journal = {Proceedings of the 9th International Conference on Educational Data Mining, EDM 2016},
author = {Atapattu, Thushari and Falkner, Katrina and Tarmazdi, Hamid},
year = {2016},
pages = {276 - 281},
address = {Raleigh, NC, United states},
abstract = {With a goal of better understanding the online discourse within the Massive Open Online Course (MOOC) context, this paper presents an open source visualisation dashboard developed to identify and classify emergent discussion topics (or themes). As an extension to the authors’ previous work in identifying key topics from MOOC discussion contents, this work visualises lecture-related discussions as a graph of relationships between topics and threads. We demonstrate the visualisation using three popular MOOCs offered during 2013. This work facilitates the course staff to locate and navigate the most influential topic clusters as well as the discussions that require intervention by connecting the topics with the corresponding weekly lectures. Further, we demonstrate how our interactive visualisation can be used to explore correlation between discussion topics and other variables such as views, posts, votes, and instructor intervention.<br/> © 2016 International Educational Data Mining Society. All rights reserved.},
key = {Visualization},
keywords = {Data mining;E-learning;},
note = {Discussion forum;Learning analytics;MOOC;Online discourse;Topic Modeling;},
} 


@inproceedings{20250917976447 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Fading of F(AI)th: Tracing the Technological Promises of a Wellbeing App in K-12 Education},
journal = {Lecture Notes in Networks and Systems},
author = {Sperling, Katarina},
volume = {1171 LNNS},
year = {2024},
pages = {103 - 115},
issn = {23673370},
address = {Salamanca, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper explores the implementation of a wellbeing app in a Swedish Upper Secondary School. The aim is to understand how ideas of data driven school improvement underpinned by promises of artificial intelligence (AI) and learning analytics (LA) change the work of teachers. The study draws on video-ethnography from 17 meetings between five teachers/form tutors. The produced data is analysed using actor-network theory to focus on the various stages of the implementation process and the interactions between the learning analytics dashboard (LAD) and the teachers. To capture the complexity of the data, the empirical material is presented through cartoon-inspired illustrations grounded in a Thinking through Cartoons methodology. Findings show how teachers took on new roles and responsibilities in relation to the wellbeing app, most notably the role of collecting data from students. Teachers came to act as data analysts which imposed constant negotiations and uncertainties. To address the declining engagement of students over time, a student-facing LAD was introduced. The teachers shifted their focus to motivate students to engage with their own data in different ways. Despite no improvements in students’ response rates teachers remained committed to the app, trusting that new AI and LA functionalities would compensate unsatisfactory outcomes. In conclusion, instead of improving teachers’ capacity to identify at-risk students, the wellbeing app increased teachers’ workload and led to different dilemmas related to teacher-student relations and teachers’ professional judgement.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Students},
keywords = {Artificial intelligence;Contrastive Learning;Economic and social effects;Teaching;},
note = {Actor-network;Actor-network theory;Data driven;Data-driven schooling;Edtech;Learning analytic;PERMA-model;Socio materialities;Teachers';Wellbeing;},
URL = {http://dx.doi.org/10.1007/978-3-031-73538-7_10},
} 


@inproceedings{20241916032497 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data Storytelling for Feedback Analytics},
journal = {CEUR Workshop Proceedings},
author = {Maheshi, Bhagya and Milesi, Mikaela Elizabeth and Palihena, Hiruni and Zheng, Aaron and Martinez-Maldonado, Roberto and Tsai, Yi-Shan},
volume = {3667},
year = {2024},
pages = {118 - 123},
issn = {16130073},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Feedback is an essential process of learning in higher education. Yet, capturing students’ interactions with feedback is challenging, which makes it difficult to evaluate its impact. Learning Analytics (LA) is a potential solution to address this issue as it is capable of capturing and analysing learners’ activities in a technology-enabled learning environment. LA often use dashboards to deliver insights derived from educational data, yet questions remain on how to most effectively communicate key insights to students. Data Storytelling (DS) is a promising technique to address this challenge by combining data, visuals and narrative to convey key insights. Co-design can facilitate the crafting of visualisations and data stories that best aligns with goals of the students. This study presents the preliminary findings from a design sprint conducted with students to co-design a prototype for a dashboard of an LA solution – PolyFeed – that captures and analyses students’ interactions with feedback. In developing the dashboards, students used DS principles – Explanatory titles, Annotations, Highlighting important data points, and Decluttering – to improve the selected visualisations. The results show that the student groups perceived visualising strengths and weaknesses identified in feedback, action plans based on feedback, and trends in their performance as key aspects to include in FA dashboard. However, they primarily used two DS principles: explanatory titles and highlighting key data points to improve visualisations because the dataset was pre-dominantly qualitative. Therefore, the effective use of DS to support qualitative data should be further explored.<br/></div> © 2024 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {Computer aided instruction;Visualization;},
note = {Co-designs;Data storytelling;Datapoints;Feedback analytic;Feedback traceability;High educations;Information visualization;Learning analytic;Process of learning;Student interactions;},
} 


@inproceedings{20150700530283 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Improving awareness and reflection through collaborative, interactive visualizations of badges},
journal = {CEUR Workshop Proceedings},
author = {Charleer, Sven and Klerkx, Joris and Santos, Jose Luis and Duval, Erik},
volume = {1103},
year = {2013},
pages = {69 - 81},
issn = {16130073},
address = {Paphos, Cyprus},
abstract = {This paper introduces novel ways of improving awareness and reflection through visualizations of badges as an abstraction of learning analytics data. We report initial findings with both a personal dashboard approach, Navi Badgeboard, that provides details on student and class progress, and a collaborative, interactive tabletop visualization, Navi Surface, to promote group reflection. We evaluate both approaches to find improvements among students regarding awareness and reflec- tion on course activities. Our results indicate that Navi Badgeboard helps with awareness of personal activity while Navi Surface improves collaboration resulting in better reflection.<br/>},
key = {Visualization},
keywords = {Students;},
note = {Awareness;Badges;Collaboration;Learning analytics;Learning dashboards;},
} 


@inproceedings{20160501872142 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {How do students interpret feedback delivered via dashboards?},
journal = {ACM International Conference Proceeding Series},
author = {Corrin, Linda and De Barba, Paula},
volume = {16-20-March-2015},
year = {2015},
pages = {430 - 431},
address = {Poughkeepsie, NY, United states},
abstract = {Providing feedback directly to students on their engagement and performance in educational activities is important to supporting students' learning. However, questions have been raised whether such data representations are adequate to inform reflection, planning and monitoring of students' learning strategies. In this poster we present an investigation of how students interpret feedback delivered via learning analytics dashboards. The findings indicated that most students were able to articulate an interpretation of the feedback presented through the dashboard to identify gaps between their expected and actual performance to inform changes to their study strategies. However, there was also evidence of uncertain interpretation both in terms of the format of the visualization of the feedback and their inability to understand the connection between the feedback and their current strategies. The findings have been used to inform recommendations for ways to enhance the effectiveness of the delivery of feedback through dashboards to provide value to students in developing effective learning strategies to meet their educational goals.<br/> © Copyright 2015 ACM.},
key = {Students},
keywords = {Learning systems;},
note = {Dashboards;Data representations;Educational activities;Effective learning;Learning Analytics;Learning strategy;Planning and monitoring;Self-regulated learning;},
URL = {http://dx.doi.org/10.1145/2723576.2723662},
} 


@inproceedings{20242216154448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Unified Teaching Platform for (No)SQL Databases},
journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
author = {Meyer, Vanessa and Wiese, Lena and Al-Ghezi, Ahmed},
volume = {1},
year = {2024},
pages = {374 - 381},
issn = {21844992},
address = {Angers, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Databases form the basic backend for information systems. This paper describes the development of a digital learning tool to promote learning of (No)SQL databases like PostgreSQL, Cassandra, Neo4J and MongoDB and the underlying data models using the React library. The learning tool will be uniformly connected to each of the mentioned databases. Thus, students can enter and execute their database queries, which are needed to solve tasks for a given example scenario, directly in our learning tool. This allows students to fully concentrate on learning the respective query languages. In this study, we present the web application’s architecture and front-end design, which will be continuously extended with additional components, such as a learning analytics dashboard. With this approach we want to contribute to the improvement of teaching methods in the field of databases and create a basis for the further development of interactive learning tools.<br/></div> Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
key = {Query languages},
keywords = {E-learning;Education computing;Learning systems;Query processing;Students;},
note = {Cassandras;Database queries;Digital-learning;Learning analytic;Learning tool;MongoDB;no-SQL database;NoSQL;PostgreSQL;Teaching platform;},
URL = {http://dx.doi.org/10.5220/0012724300003690},
} 


@inproceedings{20162802580476 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student data: Data is knowledge: Putting the knowledge back in the students' hands},
journal = {Proceedings of the European Conference on e-Learning, ECEL},
author = {Corrigan, Owen and Glynn, Mark and McKenna, Aisling and Smeaton, Alan and Smyth, Sinead},
volume = {0},
year = {2015},
pages = {165 - 172},
issn = {20488637},
address = {Hatfield, United kingdom},
abstract = {Learning Management Systems are integral technologies within higher education institutions. These tools automatically amass large amounts of log data relating to student activities. The field of learning analytics uses data from learning management systems (LMSs) and student information systems to track student progress and predict future performance in order to enhance learning environments (Siemens, 2011). The aim of this paper is to describe a project where we utilized a system developed in Dublin City University to use information about student engagement with our LMS, Moodle, to create a model predicting pass or failure in certain modules. The project is divided into three distinct phases. An initial investigation was completed analyzing Moodle activity for the last six years. The purpose of this exercise was to determine automatically if "trends" could be identified linking Moodle engagement with student attainment. This was done by training a machine learning classifier to map student online behaviour, against outcomes. Once the classifier was trained, several modules were identified as suitable for building a predictor of student exam success.Ten modules were identified for semester 1 with a further seven identified for semester 2. The second phase involved analyzing current students' engagement with these modules and sending students information about the predictions of their attainment for the module, based on their Moodle engagement. At this stage concerns were raised within the university that the data that we share with the students could actually have the opposite effect to what we are after, i.e. the student may look at the data and think that there is no point in putting in more effort as 'I'm too far behind already'. Dietz-Uhler and Hurn refer to this as "instead of being a constructive tool, feedback becomes a prophet of failure" (Dietz-Uhler, 2013). This contention was addressed by conducting an online survey with students in an effort to explore their experiences of being provided with feedback regarding their engagement with the LMS. The third and final phase of this project was the development of a dashboard for lecturers to enable monitoring of their students' engagement with their module on Moodle. This enables lecturers to have an overview of how students are engaging with their course on Moodle and quickly identify students who are not engaging with the LMS and who are potentially at risk of failure or non-completion. There are numerous examples of the use of learning analytics in higher education. This study focuses on the provision of data obtained through learning analytics to the student and qualitative analysis that was conducted in relation to this data. This research adds to the existing research into learning analytics being used for student retention.<br/>},
key = {Students},
keywords = {Information management;Data mining;Education computing;Teaching;Learning systems;Computer aided instruction;Forecasting;Information use;},
note = {Dublin City University;Higher education institutions;Integral technologies;Learner;Learning analytics;Learning management system;Student retention;Students' engagements;},
} 


@inproceedings{20243216808747 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {From Learning Actions to Dynamics: Characterizing Students’ Individual Temporal Behavior with Sequence Analysis},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Villalobos, Esteban and Perez-Sanagustin, Mar and Broisin, Julien},
volume = {14829 LNAI},
year = {2024},
pages = {3 - 17},
issn = {03029743},
address = {Recife, Brazil},
abstract = {<div data-language="eng" data-ev-field="abstract">Researchers recognize the pivotal role of temporal analysis in unraveling learning processes from learners’ trace data. However, most temporal analysis methods focus on clustering similar trajectories, and very few offer metrics to characterize the learners’ temporal learning behavior. This study draws upon a set of sequence indicators that characterize students’ temporal behavior dynamics. These metrics, focusing on sequence length, diversity, and complexity, provide insights into students’ learning engagement with the course. Applied to a dataset of 91 students collected from a Blended Learning course, we studied these metrics in relation to the learners’ final grades and their self-regulatory profiles. Additionally, we assessed the causal effects of introducing a Learning Analytics Dashboard, an intervention aimed at fostering self-regulated learning, on students’ temporal behavior and final grades by applying Inverse Probability Weighting (IPW). The results show that these metrics serve (1) to characterize individual students’ dynamics through the course and (2) to provide information about the effects of the intervention. In particular, we show that students who interacted with the dashboard had significantly more complex behavior, but no difference in their final course grades. We also revealed that engagement measured as consistent activity might be a stronger predictor than specific learning strategies in an order. This research contributes with a methodological approach for extracting metrics that enrich traditional methods, emphasizing the unique dynamics of individual students, and paving the way for future interventions.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Students},
keywords = {Dynamics;Inverse problems;Learning systems;Phase sequence indicators;},
note = {Analysis method;Inverse probability weighting;Learning actions;Learning analytic;Learning process;Probability weighting;Sequence analysis;Temporal analysis;Temporal behavior;Trace data;},
URL = {http://dx.doi.org/10.1007/978-3-031-64302-6_1},
} 


@article{20143118005434 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning dashboards: An overview and future research opportunities},
journal = {Personal and Ubiquitous Computing},
author = {Verbert, Katrien and Govaerts, Sten and Duval, Erik and Santos, Jose Luis and Van Assche, Frans and Parra, Gonzalo and Klerkx, Joris},
volume = {18},
number = {6},
year = {2014},
pages = {1499 - 1514},
issn = {16174909},
abstract = {In this paper, we present work on learning analytics that aims to support learners and teachers through dashboard applications, ranging from small mobile applications to learnscapes on large public displays. Dashboards typically capture and visualize traces of learning activities, in order to promote awareness, reflection, and sense-making, and to enable learners to define goals and track progress toward these goals. Based on an analysis of our own work and a broad range of similar learning dashboards, we identify HCI issues for this exciting research area. © 2013 Springer-Verlag London.<br/>},
key = {Teaching},
keywords = {Information systems;Learning systems;Human computer interaction;},
note = {Dashboards;Information visualization;Learning Activity;Learning analytics;Mobile applications;Public display;Research opportunities;Track progress;},
URL = {http://dx.doi.org/10.1007/s00779-013-0751-2},
} 


@article{20251218097384 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Predictive Performance Assessment in Simulation Training using Machine Learning},
journal = {International Journal of Artificial Intelligence in Education},
author = {Munim, Ziaul Haque and Kjeldsberg, Fabian and Bustgaard, Morten and Bhagat, Sahil and Haavardtun, Per and Kim, Tae-Eun and Lindroos, Emilia and Thorvaldsen, Haakon and Nyairo, Franklin and Lampiola, Jani},
year = {2025},
issn = {15604292},
abstract = {<div data-language="eng" data-ev-field="abstract">Maritime simulators are a central tool for the education and training of navigators, allowing them to develop and improve their skills in a controlled and replicable environment. Despite efforts to enhance the simulation training performance assessment, there are few reliable approaches to take advantage of readily available data from simulator logs to inform performance evaluation and training adjustments. Harnessing this data more effectively could enhance the way we assess simulation training and provide a more transparent understanding of learning progress and areas for improvement. To develop a learning analytics dashboard (LAD) for performance assessment in maritime simulation training, we analyse simulator log data with 27 potential input features to predict student performance as the target feature. After filtering down to 13 potential input features using data visualization and expert validation, a cloud artificial intelligence platform is used for predicting student performance. A total of 58 algorithms were trained, of which the eXtreme Gradient Boosted Trees Classifier algorithm is adopted for prediction. The results demonstrate the potential for utilizing machine learning algorithms in analysing maritime navigation training data paving the way for a new direction in simulation training assessment.<br/></div> © The Author(s) 2025.},
key = {Adversarial machine learning},
keywords = {Contrastive Learning;Marine navigation;Predictive analytics;},
note = {Input features;Learning analytic;Machine-learning;Maritime simulators;Performance assessment;Predictive performance;Simulation training;Simulator training;Student performance;Training and assessment;},
URL = {http://dx.doi.org/10.1007/s40593-025-00464-y},
} 


@inproceedings{20245217583430 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {AdVizor: Using Visual Explanations to Guide Data-Driven Student Advising},
journal = {Proceedings - 2024 IEEE VIS Workshop on Visualization Education, Literacy, and Activities, EduVIS 2024},
author = {Weagant, Riley and Zhao, Zixin and Bradley, Adam and Collins, Christopher},
year = {2024},
pages = {21 - 29},
address = {St. Pete Beach, FL, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Academic advising can positively impact struggling students' success. We developed AdVizor, a data-driven learning analytics tool for academic risk prediction for advisors. Our system is equipped with a random forest model for grade prediction probabilities uses a visualization dashboard to allows advisors to interpret model predictions. We evaluated our system in mock advising sessions with academic advisors and undergraduate students at our university. Results show that the system can easily integrate into the existing advising workflow, and visualizations of model outputs can be learned through short training sessions. AdVizor supports and complements the existing expertise of the advisor while helping to facilitate advisor-student discussion and analysis. Advisors found the system assisted them in guiding student course selection for the upcoming semester. It allowed them to guide students to prioritize the most critical and impactful courses. Both advisors and students perceived the system positively and were interested in using the system in the future. Our results encourage the development of intelligent advising systems in higher education, catered for advisors.<br/></div> © 2024 IEEE.},
key = {Prediction models},
keywords = {Adversarial machine learning;Contrastive Learning;Data visualization;Decision trees;Intelligent systems;Students;Visual analytics;Visualization;},
note = {Academic advising;Academic risk prediction;Analytic tools;Data driven;Grade predictions;Information visualization;Learning analytic;Random forest modeling;Risk predictions;Student success;},
URL = {http://dx.doi.org/10.1109/EduVIS63909.2024.00008},
} 


@inproceedings{20142717899824 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A web platform for the assessment of competences in Mobile Learning Contexts},
journal = {IEEE Global Engineering Education Conference, EDUCON},
author = {Rayon Jerez, Alex and Guenaga, Mariluz and Nunez, Asier},
year = {2014},
pages = {321 - 329},
issn = {21659559},
address = {Istanbul, Turkey},
abstract = {Society demands new competences from professionals, who require having specific skills and abilities. Universities, accordingly, have changed from a content-based towards a competency-based educational model. However, the assessment of these competences is not a scalable task, has a subjective nature and must consider data from many different sources. This paper describes the model, architecture and objectives of an on-going research project aimed at developing a web platform called LACAMOLC, to provide teachers and students a dashboard which gathers usage and social data from different Knowledge and Learning Technologies such as Moodle, Google Apps for Education and MediaWiki to provide visual and learning analytics visualizations to support learning and assessment process. We select Pentaho as our analytics specific tool, based on its characteristics in order to effectively scale learning analytics systems and achieve long-term sustainability and scalability, and we design an experiment to carry out for teamwork competence. © 2014 IEEE.<br/>},
key = {Teaching},
keywords = {E-learning;Education computing;Visualization;},
note = {Assessment of competences;Assessment process;Competence assessments;Educational models;learning analytics;Learning technology;Long-term sustainability;Mobile Learning;},
URL = {http://dx.doi.org/10.1109/EDUCON.2014.6826111},
} 


@inproceedings{20170603328649 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Analyzing social learning management systems for educational environments},
journal = {Communications in Computer and Information Science},
author = {Avogadro, Paolo and Calegari, Silvia and Dominoni, Matteo},
volume = {631},
year = {2016},
pages = {470 - 491},
issn = {18650929},
address = {Lisbon, Portugal},
abstract = {A Social Learning Management System (Social LMS) is an instantiation of an LMS where there is an inclusion and strong emphasis of the social aspects mediated via the ICT. The amount of data produced within the social educational network (since all the students are potential creators of material) outnumbers the information of a normal LMS and calls for novel analysis methods. At the beginning, we introduce the architecture of the social learning analytics required to manage the knowledge of a Social LMS. At this point, we adapt the Kirkpatrcik-Phillips model for scholastic environments in order to provide assessment and control tools for a Social LMS. This requires the definition of new metrics which clarify aspects related to the single student but also provide global views of the network as a whole. In order to manage and visualize these metrics we suggest to use modular dashboards which accommodate for the different roles present in a learning institution.<br/> © Springer International Publishing AG 2016.},
key = {Students},
keywords = {Benchmarking;E-learning;Social aspects;},
note = {Dashboard;E-learning platforms;Key performance indicators;Phillips;Social learning;},
URL = {http://dx.doi.org/10.1007/978-3-319-52758-1_25},
} 


@inproceedings{20211310129001 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {What do distance learning students need from student analytics?},
journal = {Computer-Supported Collaborative Learning Conference, CSCL},
author = {Herodotou, Christothea and Boroowa, Avinash and Hlosta, Martin and Rienties, Bart},
volume = {3},
year = {2020},
pages = {1737 - 1738},
issn = {15734552},
address = {Nashville, TN, United states},
abstract = {This study explores the perspectives of distance learners about student-facing learning analytics. Nineteen middle-aged, white, online students answered eight forum questions about a hypothetical scenario of a student who struggles to balance work and study and who was given access to a learning analytics dashboard. The dashboard presented comparative performance and engagement information and personalised study recommendations. Findings showed that study recommendations were highly favoured by students whereas peer comparisons were mostly viewed as not useful and demotivating.<br/> © ISLS.},
key = {Students},
keywords = {E-learning;},
note = {Comparative performance;Distance learners;},
} 


@inproceedings{20131716245739 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Addressing learner issues with StepUp!: An evaluation},
journal = {ACM International Conference Proceeding Series},
author = {Santos, Jose Luis and Verbert, Katrien and Govaerts, Sten and Duval, Erik},
year = {2013},
pages = {14 - 22},
address = {Leuven, Belgium},
abstract = {This paper reports on our research on the use of learning analytics dashboards to support awareness, self-reflection, sensemaking and impact for learners. So far, little research has been done to evaluate such dashboards with students and to assess their impact on learning. In this paper, we present the results of an evaluation study of our dashboard, called StepUp!, and the extent to which it addresses issues and needs of our students. Through brainstorming sessions with our students, we identified and prioritized learning issues and needs. In a second step, we deployed StepUp! during one month and we evaluated to which extent our dashboard addresses the issues and needs identified earlier in different courses. The results show that our tool has potentially higher impact for students working in groups and sharing a topic than students working individually on different topics. © 2013 ACM.<br/>},
key = {Students},
keywords = {Learning systems;},
note = {Brainstorming sessions;Design-based research;evaluation;Evaluation study;learning analytics;Self reflection;Sensemaking;},
URL = {http://dx.doi.org/10.1145/2460296.2460301},
} 


@inproceedings{20241115753368 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study Quasi-Experimental Investigation},
journal = {ACM International Conference Proceeding Series},
author = {Thomas, Danielle R and Lin, Jionghao and Gatz, Erin and Gurung, Ashish and Gupta, Shivang and Norberg, Kole and Fancsali, Stephen E and Aleven, Vincent and Branstetter, Lee and Brunskill, Emma and Koedinger, Kenneth R},
year = {2024},
pages = {404 - 415},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">Artificial intelligence (AI) applications to support human tutoring have potential to significantly improve learning outcomes, but engagement issues persist, especially among students from low-income backgrounds. We introduce an AI-assisted tutoring model that combines human and AI tutoring and hypothesize this synergy will have positive impacts on learning processes. To investigate this hypothesis, we conduct a three-study quasi-experiment across three urban and low-income middle schools: 1) 125 students in a Pennsylvania school; 2) 385 students (50% Latinx) in a California school, and 3) 75 students (100% Black) in a Pennsylvania charter school, all implementing analogous tutoring models. We compare learning analytics of students engaged in human-AI tutoring compared to students using math software only. We find human-AI tutoring has positive effects, particularly in student's proficiency and usage, with evidence suggesting lower achieving students may benefit more compared to higher achieving students. We illustrate the use of quasi-experimental methods adapted to the particulars of different schools and data-availability contexts so as to achieve the rapid data-driven iteration needed to guide an inspired creation into effective innovation. Future work focuses on improving the tutor dashboard and optimizing tutor-student ratios, while maintaining annual costs per student of approximately $700 annually.<br/></div> © 2024 Owner/Author.},
key = {Students},
keywords = {Education computing;Iterative methods;Learning systems;},
note = {Artificial intelligence-assisted tutoring;Design-based research;Experimental investigations;Human-artificial intelligence tutoring;Learning outcome;Learning process;Low incomes;Pennsylvania;Student learning;Tutoring;},
URL = {http://dx.doi.org/10.1145/3636555.3636896},
} 


@inproceedings{20173804195049 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating student-facing learning dashboards of affective states},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sedrakyan, Gayane and Leony, Derick and Munoz-Merino, Pedro J. and Kloos, Carlos Delgado and Verbert, Katrien},
volume = {10474 LNCS},
year = {2017},
pages = {224 - 237},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {Detection and visualizations of affective states of students in computer based learning environments have been proposed to support student awareness and improve learning. However, the evaluation of such visualizations with students in real life settings is an open issue. This research reports on our experiences from the use of four different types of dashboard visualizations in two user studies (n = 115). Students who participated in the studies were bachelor and master level students from two different study programs at two universities. The results indicate that usability, measured by interpretability, perceived usefulness and insight, is overall acceptable. However, the findings also suggest that interpretability of some visualizations, in terms of the capability to support emotion awareness, still needs to be improved. The level of students awareness about their emotions during learning activities based on the visualization interpretation varied depending on previous knowledge on visualization techniques. Furthermore, simpler visualizations resulted in better outcomes than more complex techniques.<br/> © Springer International Publishing AG 2017.},
key = {Visualization},
keywords = {E-learning;Students;Interface states;Human computer interaction;Computer aided instruction;},
note = {Computer-based learning environments;Human computer interfaces;Interactive learning environment;Learning analytics;Learning dashboards;Perceived usefulness;Students awareness;Visualization technique;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_17},
} 


@article{20250917969374 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Gamification bolsters self-regulated learning, learning performance and reduces strategy decline in flipped classrooms: A longitudinal quasi-experiment},
journal = {Computers and Education},
author = {Maimaiti, Gulipari and Hew, Khe Foon},
volume = {230},
year = {2025},
issn = {03601315},
abstract = {<div data-language="eng" data-ev-field="abstract">Flipped classrooms, which foster active learning, are becoming more prevalent in higher education. Yet, many students struggle with self-regulated learning (SRL) skills and prefer traditional learning methods. The use of SRL relies on both students' motivation and skills but it is unclear how these skills evolve over time since many previous studies often overlook the temporal effects of interventions. To address these challenges, we introduced a gamified self-regulated flipped learning (GSRFL) approach. This approach integrates gamification elements and self-regulation supports, such as a learning analytics dashboard, to motivate and aid students' behaviors across three main SRL stages: planning, execution, and self-evaluation. We conducted a longitudinal quasi-experimental study with first-year university students to examine the impact on their SRL behaviors. The longitudinal study offers a considerable methodological advantage by providing detailed information about an intervention's impact over time. The experimental group (N = 76) utilized the GSRFL approach, while the control group (N = 75) employed the same self-regulated flipped learning approach but without gamification. Results showed that gamification significantly improved students' English learning achievement and overall SRL behaviors. Longitudinal observations revealed a positive main intervention effect on metacognitive monitoring behaviors, despite a natural decline in SRL behaviors over time. Gamification effectively moderated the decline of underutilized SRL strategies like goal setting and time management. These results underscore gamification's potential to enhance academic performance and promote SRL skills.<br/></div> © 2025 Elsevier Ltd},
key = {Self-supervised learning},
keywords = {Active learning;Adversarial machine learning;Contrastive Learning;Federated learning;},
note = {Active Learning;Flipped classroom;Gamification;Learning approach;Learning performance;Learning skills;Longitudinal study;Quasi-experiments;Self-regulated learning;Self-regulated learning behaviors;},
URL = {http://dx.doi.org/10.1016/j.compedu.2025.105278},
} 


@inproceedings{20240415446942 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Reveal Online Learning Clickstream Data to Provide Actionable Intelligence},
journal = {Proceedings - Frontiers in Education Conference, FIE},
author = {Seeling, Patrick and McGarry, Michael P. and Johnson, Matthew},
year = {2023},
pages = {American Society for Engineering Education (ASEE)/Educational Research and Methods Divison (ERM); IEEE; IEEE Computer Society; IEEE Education Society - },
issn = {15394565},
address = {College Station, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">This paper describes our universally applicable approach to the gathering of learning process data to support learning analytics with the ultimate goal of generating actionable intelligence for learners and instructors. This support is needed as increasingly, course content is provided in an online environment (independent of a class delivery modality, e.g., face-to-face, hybrid, hyflex, or online) where learners are operating independently and in absence of timely feedback loops. Providing learners with automatically generated feedback can stimulate their self-regulation toward success. Specifically, we describe an approach that generates learning process analytics dashboard data that are driven by clickstream data. Our approach enables the gathering of learning process data outside the Learning Management System (LMS) confines to support the generation of models that can produce actionable intelligence and enable deeper exploration options for the instructor. Our approach thus enables continuous education improvement and its operationalization (EdOps).<br/></div> © 2023 IEEE.},
URL = {http://dx.doi.org/10.1109/FIE58773.2023.10343069},
} 


@inproceedings{20162702561829 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Semantic visual analytics for today's programming courses},
journal = {ACM International Conference Proceeding Series},
author = {Hsiao, I-Han and Govindarajan, Sesha Kumar Pandhalkudi and Lin, Yi-Ling},
volume = {25-29-April-2016},
year = {2016},
pages = {48 - 53},
address = {Edinburgh, United kingdom},
abstract = {We designed and studied an innovative semantic visual learning analytics for orchestrating today's programming classes. The visual analytics integrates sources of learning activities by their content semantics. It automatically processs paper-based exams by associating sets of concepts to the exam questions. Results indicated the automatic concept extraction from exams were promising and could be a potential technological solution to address a real world issue. We also discovered that indexing effectiveness was especially prevalent for complex content by covering more comprehensive semantics. Subjective evaluation revealed that the dynamic concept indexing provided teachers with immediate feedback on producing more balanced exams.<br/> © 2016 ACM.},
key = {Grading},
keywords = {Indexing (of information);Teaching;Semantics;Visualization;},
note = {Automatic concept extractions;Dashboard;Immediate feedbacks;Intelligent authoring;Semantic-analytics;Subjective evaluations;Technological solution;Visual analytics;},
URL = {http://dx.doi.org/10.1145/2883851.2883915},
} 


@inproceedings{20203609146065 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Design is (A)live: An environment integrating ideation and assessment},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
author = {Britain, Gabriel and Jain, Ajit and Lupfer, Nic and Kerne, Andruid and Perrine, Aaron and Seo, Jinsil and Sungkajun, Annie},
year = {2020},
pages = {ACM SIGCHI - },
address = {Honolulu, HI, United states},
abstract = {Design coursework is iterative and continuously-evolving. Separation of digital tools used in design courses disaffects instructors' and students' iterative process experiences. We present a system that integrates support for design ideation with a learning analytics dashboard. A preliminary study deployed the system in two courses, each with ∼15 students and 1 instructor, for three months. We conducted semi-structured interviews to understand user experiences. Findings indicate benefits when systems contextualize creative work with assessment by integrating support for ideation with a learning analytics dashboard. Instructors are better able to track students and their work. Students are supported in reflecting on relationships among deliverables. We derive implications for contextualizing design with feedback to support creativity, learning, and teaching.<br/> © 2020 Owner/Author.},
key = {Students},
keywords = {Curricula;Digital devices;},
note = {Contextualize;Creative work;Design course;Design ideation;Digital tools;Iterative process;Semi structured interviews;},
URL = {http://dx.doi.org/10.1145/3334480.3382947},
} 


@inproceedings{20160501872296 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The LATUX workflow: Designing and deploying awareness tools in technology-enabled learning settings},
journal = {ACM International Conference Proceeding Series},
author = {Martinez-Maldonado, Roberto and Pardo, Abelardo and Mirriahi, Negin and Yacef, Kalina and Kay, Judy and Clayphan, Andrew},
volume = {16-20-March-2015},
year = {2015},
pages = {1 - 10},
address = {Poughkeepsie, NY, United states},
abstract = {Designing, deploying and validating learning analytics tools for instructors or students is a challenge requiring techniques and methods from different disciplines, such as software engineering, human-computer interaction, educational design and psychology. Whilst each of these disciplines has consolidated design methodologies, there is a need for more specific methodological frameworks within the cross-disciplinary space defined by learning analytics. In particular there is no systematic workflow for producing learning analytics tools that are both technologically feasible and truly underpin the learning experience. In this paper, we present the LATUX workflow, a five-stage workflow to design, deploy and validate awareness tools in technology-enabled learning environments. LATUX is grounded on a well-established design process for creating, testing and re-designing user interfaces. We extend this process by integrating the pedagogical requirements to generate visual analytics to inform instructors' pedagogical decisions or intervention strategies. The workflow is illustrated with a case study in which collaborative activities were deployed in a real classroom.<br/>},
key = {Visualization},
keywords = {Groupware;Computer aided instruction;Human computer interaction;Design;User interfaces;Engineering education;Teaching;},
note = {Awareness;Collaborative activities;Cross-disciplinary;Dashboard;Intervention strategy;Learning experiences;Methodological frameworks;Technology-enabled learning;},
URL = {http://dx.doi.org/10.1145/2723576.2723583},
} 


@inproceedings{20132816495719 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Monitoring learning activities in PLE using semantic modelling of learner behaviour},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Softic, Selver and Taraghi, Benham and Ebner, Martin and De Vocht, Laurens and Mannens, Erik and Van De Walle, Rik},
volume = {7946 LNCS},
year = {2013},
pages = {74 - 90},
issn = {03029743},
address = {Maribor, Slovenia},
abstract = {We report on the reflection of learning activities and revealing hidden information based on tracked user behaviour in our widget based PLE (Personal Learning Environment) at Graz University of Technology. Our reference data set includes information of more then 4000 active learners for a period of around two years. We have modelled activity and usage traces using domain specific ontologies like Activity Ontology and Learning Context Ontology from the IntelLEO EU project. Generally we distinguish three different metrics: user centric, learning object (widget) centric and activity centric. We have used Semantic Web query languages like SPARQL and representation formats like RDF to implement a human and machine readable web service along with a learning analytics dashboard for metrics visualization. The results offer a quick overview of learning habits, preferred set-ups of learning objects (widgets) and overall reflection of usages and activity dynamics in the PLE platform over time. The architecture delivers insights for intervening and recommending as closure of a learning analytics cycle[1] to optimize confidence in the PLE. © 2013 Springer-Verlag.<br/>},
key = {Web services},
keywords = {Ontology;Computer aided instruction;Query processing;Resource Description Framework (RDF);Behavioral research;Learning systems;Query languages;},
note = {Activity ontologies;Domain-specific ontologies;Hidden information;Learning Activity;Learning Analytics;Personal learning environment;Semantic modelling;SPARQL;},
URL = {http://dx.doi.org/10.1007/978-3-642-39062-3_5},
} 


@inproceedings{20162802591776 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Toward the integration of monitoring in the orchestration of across-spaces learning situations},
journal = {CEUR Workshop Proceedings},
author = {Munoz-Cristobal, Juan A. and Rodriguez-Triana, Maria Jesus and Gallego-Lema, Vanesa and Arribas-Cubero, Higinio F. and Martinez-Mones, Alejandra and Asensio-Perez, Juan I.},
volume = {1601},
year = {2016},
pages = {15 - 21},
issn = {16130073},
address = {Edinburgh, Scotland, United kingdom},
abstract = {Technologies such as augmented Reality (AR), 3D Virtual Worlds (3DVWs) and mobile phones are extending education to other spaces beyond the classroom or the Virtual Learning Environments (VLEs). However, the richness of across-spaces learning situations that could be conducted in all these spaces is hampered by the difficulties (encompassed under the "orchestration" metaphor) that teachers face to carry them out. Monitoring can help in such orchestration, and it has been highly explored in face-to-face and blended learning. Nevertheless, in ubiquitous environments it is usually limited to activities taking place in a specific type of space (e.g., outdoors). In this paper we propose an orchestration system which supports the monitoring of learning situations that may involve web, AR-enabled physical and 3DVW spaces. The proposal was evaluated in three authentic studies, in which a prototype of the system provided monitoring through a web dashboard, an AR app, and a Virtual Globe.<br/> © Copyright 2016 for this paper by its authors.},
key = {Monitoring},
keywords = {Augmented reality;Teaching;Interactive computer graphics;E-learning;Computer aided instruction;Virtual reality;},
note = {3d virtual worlds;Across-spaces;Blended learning;Learning analytics;Learning situation;Ubiquitous environments;Virtual learning environments (VLEs);Virtual worlds;},
} 


@inproceedings{20231713953371 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Data science: simulating and development of outcome based teaching method},
journal = {Proceedings of the International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering, ICECONF 2023},
author = {Sridhar, K. and Shinde, Govind and Chaurasia, Amrita and Rani, N.R. Asha},
year = {2023},
address = {Audio Visual Hall-1 Administrative Block, Chennai, India},
abstract = {<div data-language="eng" data-ev-field="abstract">The educational researcher has a wealth of options to apply analytics to extract meaningful insights to improve teaching and learning due to the growing availability of educational data. Teaching analytics, in contrast to learning analytics, examines the quality of the classroom environment and the efficacy of the instructional methods used to improve student learning. To investigate the potential of analytics in the classroom without jeopardizing students' privacy, we suggest a data science strategy that uses simulated data using pseudocode to build test cases for educational endeavors. Hopefully, this method's findings will contribute to creating a teaching outcome model (TOM) that can be used to motivate and evaluate educator performance. In Splunk, the study's simulated methodology was carried out. Splunk is a real-time Big Data dashboard that can gather and analyze massive amounts of machine-generated data. We provide the findings as a set of visual dashboards depicting recurring themes and developments in classroom effectiveness. Our study's overarching goal is to help bolster a culture of data-informed decision-making at academic institutions by applying a scientific method to educational data.<br/></div> © 2023 IEEE.},
key = {Decision making},
keywords = {Data Science;Education computing;Learning systems;Students;Teaching;},
note = {Classroom environment;Instructional methods;Performance;Pseudo codes;Science strategies;Student learning;Teaching analytics;Teaching and learning;Teaching methods;Test case;},
URL = {http://dx.doi.org/10.1109/ICECONF57129.2023.10083713},
} 


@inproceedings{20215211386409 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {AIBL 2021 - AI for Blended-Learning: Empowering Teachers in Real Classrooms, co-located with 16th European Conference on Technology Enhanced Learning, ECTEL 2021},
journal = {CEUR Workshop Proceedings},
volume = {3042},
year = {2021},
issn = {16130073},
address = {Bozen-Bolzano, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 5 papers. The topics discussed include: learning analytics based formative assessment: gaining insights through interactive dashboard components in mathematics teaching; classification in math class: using convolutional neural networks to categorize student cognitive demand; participatory design of feedback mechanism in a physics blended-learning environment; confirmation bias and trust: human factors that influence teachers' adoption of AI-based educational technology; and towards continuity of personalization in a large blended cours.<br/></div>},
} 


@inproceedings{20221111796067 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Experimental Evidence of Performance Feedback vs. Mastery Feedback on Students' Academic Motivation},
journal = {ACM International Conference Proceeding Series},
author = {Aguilar, Stephen J},
year = {2022},
pages = {556 - 562},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Work throughout the learning analytics community has examined associations between Learning Analytics Dashboard (LAD) features and a number of important student outcomes, including academic motivation and self-regulated learning strategies. While there are many potential implications of visualized academic information within a LAD on student outcomes, there remains an unanswered question: are there causal differences between showing performance information (e.g., comparing students' progress to the class average) vs. mastery information (e.g., their individual score) on students' motivation? Grounded in Achievement Goal Theory, this study answers this question experimentally by analyzing the difference between college students' (n=445) reported achievement goal orientations as well as their motivated information seeking orientations after being presented with performance or mastery feedback. Results indicate that students in a performance condition which displayed "above average"achievement on an academic measure reported lower performance-avoidance goals (e.g., not wanting to do worse than everyone else), and performance-avoidance information-seeking goals (e.g., not wanting to seek out information showing that one does worse than peers) when compared to students in the mastery control condition. This study contributes to our understanding of the motivational implications of academic feedback presented to students, and suggests that comparative information has direct effects on student motivation. Results thus uncover a potential tension between what might seem intuitive feedback to give students versus what might be more motivationally appropriate. The implications of this work point to the need to understand LADs not simply as feedback mechanisms, but as embedded features of a learning environment that influence how students engage with course content.<br/></div> © 2022 Owner/Author.},
key = {Motivation},
keywords = {Students;Curricula;Computer aided instruction;Information use;Learning systems;Feedback;},
note = {Academic motivations;Cognitive factors;Condition;Experimental evidence;High educations;Information seeking;Non-cognitive factor;Performance;Student motivation;Student outcomes;},
URL = {http://dx.doi.org/10.1145/3506860.3506916},
} 


@inproceedings{20150800536362 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizing the LAK/EDM literature using combined concept and rhetorical sentence extraction},
journal = {CEUR Workshop Proceedings},
author = {Taibi, Davide and Sandor, agnes and Simsek, Duygu and Shum, Simon Buckingham and Deliddo, Anna and Ferguson, Rebecca},
volume = {974},
year = {2013},
issn = {16130073},
address = {Leuven, Belgium},
abstract = {Scientific communication demands more than the mere listing of empirical findings or assertion of beliefs. Arguments must be constructed to motivate problems, expose weaknesses, justify higher-order concepts, and support claims to be advancing the field. Researchers learn to signal clearly in their writing when they are making such moves, and the progress of natural language processing technology has made it possible to combine conventional concept extraction with rhetorical analysis that detects these moves. To demonstrate the potential of this technology, this short paper documents preliminary analyses of the dataset published by the Society for Learning Analytics, comprising the full texts from primary conferences and journals in Learning Analytics and Knowledge (LAK) and Educational Data Mining (EDM). We document the steps taken to analyse the papers thematically using Edge Betweenness Clustering, combined with sentence extraction using the Xerox Incremental Parser's rhetorical analysis, which detects the linguistic forms used by authors to signal argumentative discourse moves. Initial results indicate that the refined subset derived from more complex concept extraction and rhetorically significant sentences, yields additional relevant clusters. Finally, we illustrate how the results of this analysis can be rendered as a visual analytics dashboard.<br/>},
key = {Visualization},
keywords = {Extraction;Data mining;Syntactics;Natural language processing systems;},
note = {Corpus analysis;Educational data minings (EDM);Learning analytics;NAtural language processing;Preliminary analysis;Scientific communication;Scientific rhetoric;Sentence extraction;},
} 


@inproceedings{20141717632583 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Competency map: Visualizing student learning to promote student success},
journal = {ACM International Conference Proceeding Series},
author = {Grann, Jeff and Bushway, Deborah},
year = {2014},
pages = {168 - 172},
address = {Indianapolis, IN, United states},
abstract = {Adult students often struggle to appreciate the relevance of their higher educational experiences to their careers. Capella University's competency map is a dashboard that visually indicates each student's status relative to specific assessed competencies. MBA students who utilize their competency map demonstrate competencies at slightly higher levels and persist in their program at greater rates, even after statistically controlling for powerful covariates, such as course engagement. Copyright © 2014 by the Association for Computing Machinery, Inc.<br/>},
key = {Students},
note = {Competency;Covariates;Educational experiences;Evaluation;Learning analytics;Student learning;Student success;},
URL = {http://dx.doi.org/10.1145/2567574.2567622},
} 


@inproceedings{20220811682448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Mapping VISIR Circuits for Computer-assisted Assessment},
journal = {Proceedings of 2021 World Engineering Education Forum/Global Engineering Deans Council, WEEF/GEDC 2021},
author = {Cuadros, Jordi and Serrano, Vanessa and Lluch, Francesc and Garcia-Zubia, Javier and Hernandez-Jayo, Unai},
year = {2021},
pages = {524 - 527},
address = {Madrid, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">Virtual Instrument Systems in Reality (VISIR) is a remote laboratory for electrical circuits currently used worldwide. Work is in progress to develop a functional learning analytics tool, the VISIR dashboard (VISIR-DB), that may be useful to instructors and researchers. Explaining what a VISIR circuit is and how to map different circuits that share the same experimental goal is therefore key. This paper presents the issue of circuit identification in VISIR and proposes some algorithms to organize the different experiments users can perform.<br/></div> © 2021 IEEE.},
key = {Timing circuits},
keywords = {Computer aided instruction;E-learning;Laboratories;},
note = {Analytic tools;Assessment;Circuit identification;Computer-assisted assessments;Electrical circuit;Learning analytic;Remote laboratories;Remote labs;Virtual instrument system in reality;Virtual instrument systems;},
URL = {http://dx.doi.org/10.1109/WEEF/GEDC53299.2021.9657349},
} 


@inproceedings{20123315330551 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Goal-oriented visualizations of activity tracking: A case study with engineering students},
journal = {ACM International Conference Proceeding Series},
author = {Santos, Jose Luis and Govaerts, Sten and Verbert, Katrien and Duval, Erik},
year = {2012},
pages = {143 - 152},
address = {Vancouver, BC, Canada},
abstract = {Increasing motivation of students and helping them to reflect on their learning processes is an important driver for learning analytics research. This paper presents our research on the development of a dashboard that enables self-reflection on activities and comparison with peers. We describe evaluation results of four iterations of a design based research methodology that assess the usability, use and usefulness of different visualizations. Lessons learned from the different evaluations performed during each iteration are described. In addition, these evaluations illustrate that the dashboard is a useful tool for students. However, further research is needed to assess the impact on the learning process. © 2012 ACM.<br/>},
key = {Visualization},
keywords = {Iterative methods;Students;},
note = {Activity tracking;Design-based research;Evaluation results;Goal-oriented;learning analytics;Learning process;Self reflection;},
URL = {http://dx.doi.org/10.1145/2330601.2330639},
} 


@inproceedings{20230713578032 ,
language = {Portuguese},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Predicting at-risk students with LMS data: a comparison between Adaboost and LSTM algorithms},
journal = {2022 17th Latin American Conference on Learning Technologies, LACLO 2022},
author = {Battaglin, Ricardo and Munoz, Roberto and Ramos, Vinicius Culmant and Cechinel, Cristian},
year = {2022},
address = {Armenia, Colombia},
abstract = {<div data-language="eng" data-ev-field="abstract">The prediction of students at-risk (dropout and failure) is a largely explored problem on Learning Analytics and Educational Data Mining. The present work compares the results of two different algorithms used to generate predictive models to early detect students at-risk, LSTM and Adaboost. This comparison aims to improve the performances of the models already implemented and integrated on a Moodle dashboard. For the comparison, data from a total of 122 students was collected from Moodle over four semester of an Introductory Programming course offered at Federal University of Santa Catarina (UFSC). Models were generated for each one of the 17 weeks of the semester, and their AUROC measures were then calculated and compared to evaluate the differences between LSTM and Adaboost. The results have shown that even though LSTM models presented a better performance than Adaboost, these differences were not statistically significant.<br/></div> © 2022 IEEE.},
key = {Adaptive boosting},
keywords = {Data mining;Education computing;Long short-term memory;Predictive analytics;Students;},
note = {At-risk student1;Educational data mining;Introductory programming course;Learning analytic;LSTM;Performance;Predictive models;},
URL = {http://dx.doi.org/10.1109/LACLO56648.2022.10013469},
} 


@inproceedings{20203909215826 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {15th European Conference on Technology Enhanced Learning, EC-TEL 2020},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {12315 LNCS},
year = {2020},
issn = {03029743},
address = {Heidelberg, Germany},
abstract = {The proceedings contain 49 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Knowledge-driven wikipedia article recommendation for electronic textbooks; infobits: A mobile application to foster digital competencies of senior citizens; human-centered design of a dashboard on students’ revisions during writing; student awareness and privacy perception of learning analytics in higher education; user assistance for serious games using hidden markov model; guiding socio-technical reflection of ethical principles in tel software development: The srep framework; git4school: A dashboard for supporting teacher interventions in software engineering courses; exploring the design and impact of online exercises for teacher training about dynamic models in mathematics; interactive concept cartoons: Exploring an instrument for developing scientific literacy; quality evaluation of open educational resources; designing digital activities to screen locomotor skills in developing children; towards adaptive social comparison for education; simulation based assessment of epistemological beliefs about science; an operational framework for evaluating the performance of learning record stores; an approach to support interactive activities in live stream lectures; educational escape games for mixed reality; measuring learning progress for serving immediate feedback needs: Learning process quantification framework (lpqf); data-driven game design: The case of difficulty in educational games; extracting topics from open educational resources; supporting gamification with an interactive gamification analytics tool (igat); openlair an open learning analytics indicator repository dashboard; casuallearn: A smart application to learn history of art; applying instructional design principles on augmented reality cards for computer science education; what teachers need for orchestrating robotic classrooms; preface.<br/>},
} 


@inproceedings{20250617806542 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {WOLFRAM in Action: Teaching and Learning (Pseudo)Random Generation with Cellular Automata in Higher Education Settings},
journal = {CEUR Workshop Proceedings},
author = {Anthis, Zach and Zacharioudakis, Lefteris},
volume = {3902},
year = {2024},
pages = {43 - 53},
issn = {16130073},
address = {Bozen-Bolzano, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">This article presents ongoing work on WOLFRAM, an interactive EdTech tool designed to teach random generation by visualizing unidimensional Cellular Automata (CA). The web-based prototype integrates a series of gamified tasks with a Learning Analytics (LA) dashboard, to provide students with hands-on experience in elementary CA mechanics whilst delivering detailed insights to instructors in real time. The backend tracks user progress through key performance metrics, including response times, task accuracy, and engagement levels. Preliminary results from a quasi-experimental study demonstrate substantial learning gains across two distinct cohorts: BSc Computer Science (CS) students in a Cybersecurity module and BSc Artificial Intelligence (AI) students in a Machine Learning module. Both cohorts reported high usability and motivation via quantitative Likert scale assessments, with ANOVA showing no significant differences in these areas. Yet, AI students exhibited notably higher improvements in learning clarity, likely due to stronger curricular alignment with CA concepts. In fact, regression analysis confirmed that being in the AI group significantly predicted greater clarity in general, even after controlling for other factors. Next steps involve the integration of adaptive learning features to dynamically adjust content difficulty based on recorded student performance, alongside additional predictive and prescriptive components to provide for automated feedback (in the form of AI-driven hints) on a need-to basis. Future research will focus on expanding the tool’s scalability across various (adjoining) academic disciplines and investigating its impact on long-term retention of more advanced concepts such as fractal geometry, entropy estimation, algorithmic complexity, pattern formation, or self-organization.<br/></div> © 2023 Copyright for this paper by its authors.},
key = {Students},
keywords = {Adversarial machine learning;Automata theory;Contrastive Learning;Dictating machines;Federated learning;Fractals;Teaching;},
note = {Artificial intelligence;Cellular automaton;Cellular automatons;Computer science;High educations;Learning analytic;Pseudo-random;Random generation;Teaching and learning;Web-based prototype;},
} 


@unpublished{20240004347 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study Quasi-Experimental Investigation},
journal = {arXiv},
author = {Thomas, Danielle R. and Lin, Jionghao and Gatz, Erin and Gurung, Ashish and Gupta, Shivang and Norberg, Kole and Fancsali, Stephen E. and Aleven, Vincent and Branstetter, Lee and Brunskill, Emma and Koedinger, Kenneth R.},
year = {2023},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Artificial intelligence (AI) applications to support human tutoring have potential to significantly improve learning outcomes, but engagement issues persist, especially among students from low-income backgrounds. We introduce an AI-assisted tutoring model that combines human and AI tutoring and hypothesize this synergy will have positive impacts on learning processes. To investigate this hypothesis, we conduct a three-study quasi-experiment across three urban and low-income middle schools: 1) 125 students in a Pennsylvania school; 2) 385 students (50% Latinx) in a California school, and 3) 75 students (100% Black) in a Pennsylvania charter school, all implementing analogous tutoring models. We compare learning analytics of students engaged in human-AI tutoring compared to students using math software only. We find human-AI tutoring has positive effects, particularly in student's proficiency and usage, with evidence suggesting lower achieving students may benefit more compared to higher achieving students. We illustrate the use of quasi-experimental methods adapted to the particulars of different schools and data-availability contexts so as to achieve the rapid data-driven iteration needed to guide an inspired creation into effective innovation. Future work focuses on improving the tutor dashboard and optimizing tutor-student ratios, while maintaining annual costs per student of approximately $700 annually.<br/></div> © 2023, CC BY.},
key = {Students},
keywords = {Artificial intelligence;Iterative methods;Learning systems;},
note = {Artificial intelligence-assisted tutoring;Design-based research;Experimental investigations;Human-artificial intelligence tutoring;Learning outcome;Learning process;Low incomes;Pennsylvania;Student learning;Tutoring;},
URL = {http://dx.doi.org/10.48550/arXiv.2312.11274},
} 


@inproceedings{20244017130860 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {15159 LNCS},
year = {2024},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.<br/></div>},
} 


@inproceedings{20244017138399 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {15160 LNCS},
year = {2024},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.<br/></div>},
} 


@inproceedings{20234314950417 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning with Explainable AI-Recommendations at School: Extracting Patterns of Self-Directed Learning from Learning Logs},
journal = {Proceedings - 2023 IEEE International Conference on Advanced Learning Technologies, ICALT 2023},
author = {Majumdar, Rwitajit and Takami, Kyosuke and Ogata, Hiroaki},
year = {2023},
pages = {245 - 249},
address = {Hybrid, Orem, UT, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Educational explainable AI (XAI) applications are gaining research focus and have distinct needs in the domain of Education. This research presents Educational eXplainable AI Tool (EXAIT), a system for math quiz recommendations, along with an explanation. EXAIT was implemented in a Japanese public high school where students received the top 5 math problems based on Bayesian Knowledge Tracing (BKT) algorithm in a learning analytics dashboard. It aimed to help them complete their summer vacation assignments having 240 questions. On click, the students were redirected to an eBook platform to submit their accuracy and confidence level in each problem. We conducted a study with a quasi-experimental design and divided into 3 groups based on compliance of use. RecoExp group received and used explanations regarding why an item was recommended and how it aims to maximize learners' knowledge-gaining path. RecoCon was the control group that received just the recommendations and used it and RecoNone group did not use the system at all during the time period. We provide a framework to analyze learning logs from EXAIT and extract emerging self-directed learning patterns. Analyzing 222 students' EXAIT logs, we found learners who had checked explanations while selecting recommendations had significantly higher performance. Further differential process mining highlighted significant active daily engagement transitions of the RecoExp group in the self-directed activity.<br/></div> © 2023 IEEE.},
key = {Students},
keywords = {Learning systems;},
note = {Bayesian knowledge tracings;Higher School;LA;LEAF;Pattern mining;Problem-based;Research focus;SDL;Self-directed learning;XAI;},
URL = {http://dx.doi.org/10.1109/ICALT58122.2023.00078},
} 


@inproceedings{20233914787838 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Promise of Physiological Data in Collaborative Learning: A Systematic Literature Review},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Febriantoro, Wicaksono and Gauthier, Andrea and Cukurova, Mutlu},
volume = {14200 LNCS},
year = {2023},
pages = {75 - 88},
issn = {03029743},
address = {Aveiro, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">Collaborative learning is an important approach in education. Researchers are increasingly interested in using physiological data, such as Electrodermal Activity (EDA), as an objective tool to measure bodily reactions during collaborative activities. However, it remains unclear how physiological data can contribute to our understanding, monitoring and support of the collaborative learning process. To address this gap, a Systematic Literature Review (SLR) was conducted, focusing on the contribution of physiological data to collaborative learning, the features of physiological data that correlate with effective outcomes, and interventions designed to support collaboration based on physiological data. The review identified 13 relevant publications that revealed physiological data can indeed be useful for detecting certain aspects of collaboration including students’ cognitive, behavioral, and affective (emotion and motivation) states. Physiological arousal in the form of EDA peaks and physiological synchrony (interdependence or associated activity between individuals’ physiological signals) were the most commonly used features. Surprisingly, only one publication presented a prototype of a learning analytics dashboard that used physiological data to guide student reflections. Furthermore, the review highlights the potential for integrating physiological measures with other data sources, such as speech, eye gaze, and facial expression, to uncover psychophysiological reactions and accompanying social and contextual processes related to collaborative learning. Future research should consider embedding methods for the physiological detection and modeling of learning constructs within explicit, feedback-driven interventions for collaborative learning.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Learning systems},
keywords = {Psychophysiology;},
note = {Collaborative activities;Collaborative learning;Collaborative learning process;Data-source;Electrodermal activity;Eye-gaze;Physiological data;Physiological measures;Physiological signals;Systematic literature review;},
URL = {http://dx.doi.org/10.1007/978-3-031-42682-7_6},
} 


@inproceedings{20220811673593 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of 2021 13th International Conference on Education Technology and Computers, ICETC 2021},
journal = {ACM International Conference Proceeding Series},
year = {2021},
address = {Virtual, Online, China},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 77 papers. The topics discussed include: the development of learning outcomes and prerequisite knowledge recommendation system; learning path recommendation using lesson sequence and learning object based on course graph; predictive model of student academic performance from LMS data based on learning analytics; graph learning based sentiment analysis system for Chinese course evaluation; automatic classroom question classification based on bloom’s taxonomy; from motivation components to academic achievement prediction; a method of speech separation between teachers and students in smart classrooms based on speaker diarization; design proposal of a personalized dashboard to optimize teaching-learning in virtual learning environments; and an experimental study of the efficacy of augmented reality in Chinese kindergarten-level students’ learning of English vocabulary.<br/></div>},
} 


@inproceedings{20231313819294 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Automated Test Set Quiz Maker Optimizing Solving Time and Parameters of Bayesian Knowledge Tracing Model Extracted from Learning Log},
journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
author = {Takami, Kyosuke and Miyabe, Gou and Flanagan, Brendan and Ogata, Hiroaki},
volume = {2},
year = {2022},
pages = {91 - 95},
address = {Kuala Lumpur, Malaysia},
abstract = {<div data-language="eng" data-ev-field="abstract">Creating a set of quizzes for the students' test is almost an irreplaceable task to teachers. In practice, a teacher could use a learning analytics dashboard while creating a test to control the quiz difficulty and the amount of time it takes to solve. This paper draws inspiration from this practical example, and we propose an automated test set quiz maker by optimizing the time and learning parameters that have been estimated from the analysis of learning logs. First, we estimate the Bayesian Knowledge Tracing (BKT) model parameters: in particular the guess and slip probability from the quiz answer log history. The system automatically generates a test set of quizzes if the user inputs the desired amount of time it should take to solve the test by optimizing the selection of quizzes based on BKT parameters and estimated solving time. This function is expected to reduce the burden of preparing examination questions for teachers, and it can be used as a trial test before the exam for students.<br/></div> © ICCE 2022.All rights reserved.},
key = {Combinatorial optimization},
keywords = {Automation;Learning systems;Parameter estimation;Statistical tests;},
note = {Automated test;Automated test set quiz generation;Bayesian knowledge tracings;Knapsack problems;Mathematical optimizations;Student - tests;Teachers';Test sets;Time parameter;Tracing model;},
} 


@inproceedings{20225213287592 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {11th International Conference on Games and Learning Alliance, GALA 2022},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {13647 LNCS},
year = {2022},
issn = {03029743},
address = {Tampere, Finland},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 36 papers. The special focus in this conference is on Games and Learning Alliance. The topics include: More Than Meets the Eye - An Anti-Phishing Learning Game with a Focus on Phishing Emails; promoting Adaptive Number Knowledge Through Deliberate Practice in the Number Navigation Game; effects of a Game-Based Fraction Estimation Task on Math Anxiety; motivation and Emotions in a Health Literacy Game: Insights from Co-occurrence Network Analysis; swarming as a Bird/Fish: Investigating the Effect of First-Person Perspective Simulation on Players’ Connectedness with Nature; design of a Novel Serious Game for the Detection and Measurement of Obsessive-Compulsive Disorder; the Role of Games in Overcoming the Barriers to Paediatric Speech Therapy Training; ludic Didactics: For an Inspired, Motivating and Playful Education; comparison with Self vs Comparison with Others: The Influence of Learning Analytics Dashboard Design on Learner Dashboard Use; out of the Maze: Investigating Fluid Intelligence and Numeracy as Predictive Factors of Planning Skills Using Video Games; a Virtual Ship Evacuation Serious Game: Assessment of Data and Passenger Training; high-Level Decision-Making Non-player Vehicles; influence of a Mixed Reality Game on Students’ Personal Epistemology. An Empirical Study; experts’ Evaluation of a Proposed Taxonomy for Immersive Learning Systems; a Design Space of Educational Authoring Tools for Augmented Reality; the Effectiveness of Adaptive Digital Games for Learning: Calling for a Broader View on Assessment; gamification in Work Teams: A Q Study on How Team Members Experience Gamification; flow in a Game-Based Learning Platform Design for K-12; gamification for Spatial Digital Learning Environments in Higher Education: A Rapid Literature Review; constructing Gamified Learning Experiences.<br/></div>},
} 


@inproceedings{20193507381532 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {2415},
year = {2019},
issn = {16130073},
address = {Vigo, Spain},
abstract = {The proceedings contain 9 papers. The topics discussed include: application of learning analytics techniques on blended learning environments for university students; using Simva to evaluate serious games and collect game learning analytics data; extending a dashboard metamodel to account for users' characteristics and goals for enhancing personalization; predicting student performance over time. a case study for a blended-learning engineering course; analyzing students’ persistence using an event-based model; a data value chain to support the processing of multimodal evidence in authentic learning scenarios; and predictors and early warning systems in higher education a systematic literature review.<br/>},
} 


@inproceedings{20203108999623 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {12203 LNCS},
year = {2020},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {The proceedings contain 50 papers. The special focus in this conference is on Distributed, Ambient and Pervasive Interactions. The topics include: Designing an Interactive Platform for Intangible Cultural Heritage Knowledge of Taoyuan Woodcarving Craft; circuit Game: A Craft-Based Electronic Building Practice; going Beyond Computer-Assisted Vocabulary Learning: Research Synthesis and Frameworks; Returning to Nature: VR Mediated States of Enhanced Wellness; visualization and Analysis for Supporting Teachers Using Clickstream Data and Eye Movement Data; visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students; applying Deep Learning in Creative Re-creation of Changsha Kiln Cultural Relics; rethinking User Interaction with Smart Environments—A Comparative Study of Four Interaction Modalities; Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard; smart Learning in the Community: Supporting Citizen Digital Skills and Literacies; tele Echo Tube for Historic House Tojo-Tei in Matsudo International Science Art Festival 2018; motivating Physical Exercise in the Elderly with Mixed Reality Experiences; computer Vision on Wheelchairs: Detecting Sleeping Behavior of People with Intellectual Disabilities; factors Influencing the Acceptance and Usage of Smart City Services: A Systematic Review and Meta-analysis; civic Crowdsensing Through Location-Aware Virtual Monsters; participatory Governance in Smart Cities: Future Scenarios and Opportunities; Adaptability and Attuning in Smart Cities: Exploring the HCI Grand Challenge of Learning and Creativity; investigating Users Attitudes and Perceptions Towards the Usage of Smart City Apps; accessibility in Pervasive Systems: An Exploratory Study; digitally Enhancing Society Through Structuralism: Virtualizing Collective Human Eyesight and Hearing Capabilities as a Case Study; foreword.<br/>},
} 


@inproceedings{20221211820392 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Mining Students’ Engagement Pattern in Summer Vacation Assignment},
journal = {29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings},
author = {Kuromiya, Hiroyuki and Majumdar, Rwitajit and Ogata, Hiroaki},
volume = {1},
year = {2021},
pages = {559 - 568},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics (LA) is an emergent field which aims at a better understanding of students and providing intelligence to learners, teachers, and administrators using learning log data. Although the use of technology in class is increasing in the K-12 sector as well as territory education, cases of effective implementation of LA in secondary schools were rarely reported, especially in Japan. In this paper, we offer an example where LA is implemented at a junior-high Math class in Japan. We introduce our LA platform, LEAF - LMS and e-book integrated learning analytics dashboard - and its usage during summer vacation period in the target class. We analyzed 121 students’ question answering logs and their exam performance after the vacation by K-means clustering method. As a result, we found that students’ progress patterns were able to be categorized as four types: early engagement, late engagement, high engagement, and low engagement and the early and high engagement group got significantly higher scores than the low engagement group. It implies the importance of the engagement at the beginning of the vacation. Moreover, by comparing the previous studies in MOOCs, we concluded that self-regulation skills are an important factor for student success in a long vacation period, too. Finally, we introduce a monitoring tool which aims to detect and send messages to at-risk students at an early stage in the next summer vacation period. Our case will become the first model case of how to implement LA in secondary school in Japan.<br/></div> © 2021 29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings. All rights reserved},
key = {Students},
keywords = {K-means clustering;Education computing;},
note = {Learning analytic;Log data;Long vacation period;Pattern mining;Secondary education;Secondary schools;Student engagement;Summer vacations;Teachers';Vacation period;},
} 


@inproceedings{20181705111632 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {ACM International Conference Proceeding Series},
journal = {ACM International Conference Proceeding Series},
year = {2018},
address = {Sydney, NSW, Australia},
abstract = {The proceedings contain 60 papers. The topics discussed include: the half-life of MOOC knowledge: a randomized trial evaluating knowledge retention and retrieval practice in MOOCs; graph-based visual topic dependency models: supporting assessment design and delivery at scale; data-driven generation of rubric criteria from an educational programming environment; supporting teacher's intervention in students' virtual collaboration using a network based model; correlating affect and behavior in reasoning mind with state test achievement; license to evaluate: preparing learning analytics dashboards for educational practice; open learner models and learning analytics dashboards: a systematic review; multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in Flanders; a qualitative evaluation of a learning dashboard to support advisor-student dialogues; the classrooom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers; an application of participatory action research in advising-focused learning analytics; profiling students from their questions in a blended learning environment; recurrence quantification analysis as a method for studying text comprehension dynamics; towards a writing analytics framework for adult English language learners; epistemic network analysis of students' longer written assignments as formative/summative evaluation; and the influence of student's cognitive and motivational characteristics on student's use of a 4C/ID-based online learning environment and their learning gain.<br/>},
} 


@inproceedings{20194807744765 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Capturing high-level requirements of information dashboards' components through meta-modeling},
journal = {ACM International Conference Proceeding Series},
author = {Vazquez-Ingelmo, Andrea and Garcia-Palvo, Francisco J. and Theron, Roberto},
year = {2019},
pages = {815 - 821},
address = {Leon, Spain},
abstract = {<div data-language="eng" data-ev-field="abstract">Information dashboards are increasing their sophistication to match new necessities and adapt to the high quantities of generated data nowadays. These tools support visual analysis, knowledge generation, and thus, are crucial systems to assist decision-making processes. However, the design and development processes are complex, because several perspectives and components can be involved. Tailoring capabilities are focused on providing individualized dashboards without affecting the time-to-market through the decrease of the development processes' time. Among the methods used to configure these tools, the software product lines paradigm and model-driven development can be found. These paradigms benefit from the study of the target domain and the abstraction of features, obtaining high-level models that can be instantiated into concrete models. This paper presents a dashboard meta-model that aims to be applicable to any dashboard. Through domain engineering, different features of these tools are identified and arranged into abstract structures and relationships to gain a better understanding of the domain. The goal of the meta-model is to obtain a framework for instantiating any dashboard to adapt them to different contexts and user profiles. One of the contexts in which dashboards are gaining relevance is Learning Analytics, as learning dashboards are powerful tools for assisting teachers and students in their learning activities. To illustrate the instantiation process of the presented meta-model, a small example within this relevant context (Learning Analytics) is also provided.<br/></div> © 2019 ACM.},
key = {Decision making},
keywords = {Learning systems;Software design;User profile;},
note = {Decision making process;Design and development process;Domain engineering;High-level requirements;Information Dashboards;Meta model;Model driven development;Software Product Line;},
URL = {http://dx.doi.org/10.1145/3362789.3362837},
} 


@inproceedings{20203209028818 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {7th International Conference on Learning and Collaboration Technologies, LCT 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {12205 LNCS},
year = {2020},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {The proceedings contain 86 papers. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Reflective Journaling: A Theoretical Model and Digital Prototype for Developing Resilience and Creativity; prototyping a Touch-Optimized Modeling Tool for Co-located and Inverted Classroom Group Modeling Scenarios; evaluating Portable Touch Projectors in the Context of Digital Education; STEAM-X: An Exploratory Study Adding Interactive Physical Activity to the STEAM Model; usability Testing of a Digital Competence Assessment and Certification System; designing ‘Embodied’ Science Learning Experiences for Young Children; impact of Constant Work on the Students’ Academic Performance; Learning Analytics and MOOCs; on the Design of a Teachers’ Dashboard: Requirements and Insights; evaluation of the Virtual Mobility Learning Hub; mudpoint: Evaluating Instructor Perception on a Continuous and Non-specific Feedback System; characterization of Learners from Their Learning Activities on a Smart Learning Platform; AI-Driven Assessment of Students: Current Uses and Research Trends; generating Dashboards Using Fine-Grained Components: A Case Study for a PhD Programme; learning Analytics and Spelling Acquisition in German – The Path to Individualization in Learning; Building Student Interactions Outside the Classroom: Utilizing a Web-Based Application in a University Flipped Learning Course for EFL Learners; the Impact of Corpus Linguistics on Language Teaching in Russia’s Educational Context: Systematic Literature Review; framework of Manga Application for Teaching Japanese Language; Individualized Differentiated Spelling with Blogs - Implementing and Individualizing (IDeRBlog ii): An Example of a Learning Analytics Platform for the Text-Based Acquisition of Spelling Skills of Students in German.<br/>},
} 


@inproceedings{20190406401404 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {2294},
year = {2018},
issn = {16130073},
address = {Leeds, United kingdom},
abstract = {The proceedings contain 11 papers. The topics discussed include: a data mining framework for analyzing students' feedback of assessment; MULTIFOCUS: multimodal learning analytics for co-located collaboration understanding and support; implementation and evaluation of a trusted learning analytics dashboard; learning analytics dashboards for professional training - challenges and proposal; identification of role models in online communities of practice; application of participatory design in designing infrastructures for learning in resource limiting environments; inferring knowledge acquisition through web navigation behaviors; and contextualized instruction in data science and its effect on transfer of learning.<br/>},
} 


@article{20242816691153 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Advancing equity and inclusion in educational practices with AI-powered educational decision support systems (AI-EDSS)},
journal = {British Journal of Educational Technology},
author = {Viberg, Olga and Kizilcec, Rene F. and Wise, Alyssa Friend and Jivet, Ioana and Nixon, Nia},
volume = {55},
number = {5},
year = {2024},
pages = {1974 - 1981},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">A key goal of educational institutions around the world is to provide inclusive, equitable quality education and lifelong learning opportunities for all learners. Achieving this requires contextualized approaches to accommodate diverse global values and promote learning opportunities that best meet the needs and goals of all learners as individuals and members of different communities. Advances in learning analytics (LA), natural language processes (NLP), and artificial intelligence (AI), especially generative AI technologies, offer potential to aid educational decision making by supporting analytic insights and personalized recommendations. However, these technologies also raise serious risks for reinforcing or exacerbating existing inequalities; these dangers arise from multiple factors including biases represented in training datasets, the technologies' abilities to take autonomous decisions, and processes for tool development that do not centre the needs and concerns of historically marginalized groups. To ensure that Educational Decision Support Systems (EDSS), particularly AI-powered ones, are equipped to promote equity, they must be created and evaluated holistically, considering their potential for both targeted and systemic impacts on all learners, especially members of historically marginalized groups. Adopting a socio-technical and cultural perspective is crucial for designing, deploying, and evaluating AI-EDSS that truly advance educational equity and inclusion. This editorial introduces the contributions of five papers for the special section on advancing equity and inclusion in educational practices with AI-EDSS. These papers focus on (i) a review of biases in large language models (LLMs) applications offers practical guidelines for their evaluation to promote educational equity, (ii) techniques to mitigate disparities across countries and languages in LLMs representation of educationally relevant knowledge, (iii) implementing equitable and intersectionality-aware machine learning applications in education, (iv) introducing a LA dashboard that aims to promote institutional equality, diversity, and inclusion, and (v) vulnerable student digital well-being in AI-EDSS. Together, these contributions underscore the importance of an interdisciplinary approach in developing and utilizing AI-EDSS to not only foster a more inclusive and equitable educational landscape worldwide but also reveal a critical need for a broader contextualization of equity that incorporates the socio-technical questions of what kinds of decisions AI is being used to support, for what purposes, and whose goals are prioritized in this process.<br/></div> © 2024 British Educational Research Association.},
URL = {http://dx.doi.org/10.1111/bjet.13507},
} 


@inproceedings{20220611599782 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using epistemic information to improve learning gains in a computer-supported collaborative learning context},
journal = {CEUR Workshop Proceedings},
author = {Dieckmann, Max and Hernandez-Leo, Davinia},
volume = {3076},
year = {2021},
pages = {113 - 121},
issn = {16130073},
address = {Virtual, Bolzano, Italy},
abstract = {<div data-language="eng" data-ev-field="abstract">Computer-supported collaborative learning (CSCL) is a method in education where the students work together on a task while the teacher takes on the role of a coach who - aided by information technology - scaffolds their progress and allows them to discover a solution on their own. CSCL exercises are often run following a script, which breaks the activity in a set number of steps to facilitate productive collaboration. This makes it easier for the teacher to orchestrate the exercise - controlling the flow of the activity and attending to the students' needs as they arise. Teacher-facing dashboards are often used to enable orchestration by providing information about and controls to manipulate the state of the activity. Our research is centered on analyzing whether teachers and students can benefit from visualizing epistemic information, i.e. learning analytics data derived from examining the content of students' input. We expect that giving teachers access to epistemic information will facilitate orchestration, reduce the cognitive load required to oversee a CSCL activity, and create the opportunity for teacher-led debriefing - a technique used by educators to make students reflect on the activity they engaged in and thus help them get a deeper understanding of the content that was covered. We also expect that this will ultimately have a positive impact on students' learning gains. We will extend the dashboard of "PyramidApp" - a software tool that implements the CSCL "Pyramid" script - with epistemic information to test our hypothesis. Subsequently, we will analyze how our findings transfer to other CSCL scripts and tools. We thus hope to contribute to the existing knowledge of how learning analytics data can successfully be employed in a CSCL context. We will follow the design-based research method which emphasizes cooperation with teachers and aims to test and apply interventions in realistic scenarios.<br/></div> © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
key = {Students},
keywords = {E-learning;Software testing;Scaffolds;},
note = {Cognitive loads;Collaborative learning activities;Computer Supported Collaborative Learning;Design-based research;Epistemic information;Learning context;Learning gain;Orchestration;Teacher-lead debriefing;Teachers';},
} 


@inproceedings{20194207553138 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Intelligent cognitive assistants to support orchestration in cscl},
journal = {Computer-Supported Collaborative Learning Conference, CSCL},
author = {Bae, Haesol and Glazewski, Krista and Hmelo-Silver, Cindy E. and Lester, James and Mott, Bradford W. and Rowe, Jonathan},
volume = {2},
year = {2019},
pages = {947 - 948},
issn = {15734552},
address = {Lyon, France},
abstract = {This design paper proposes an intelligent cognitive assistant framework that utilizes AI-based multimodal learning analytics for developing a teacher dashboard. Using six data streams, we suggest this design can extend teacher’s instructional capacity in technology-rich collaborative inquiry-focused science classrooms. We discuss how this tool can support teacher’s orchestration in relation to relevant learning practices in complex problem-solving activities in a CSCL environment.<br/> © ISLS.},
key = {E-learning},
note = {Complex problem solving;Multi-modal learning;Science classroom;},
} 


@inproceedings{20190306392536 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {2250},
year = {2018},
issn = {16130073},
address = {Frankfurt, Germany},
abstract = {The proceedings contain 29 papers. The topics discussed include: design patterns for digital competency credentials based on open badges in the context of virtual mobility; facing the general data privacy regulation: what data is being collected about me and how can i get access?; heart rate, electrodermal activity and skin conductance as new sources for learning analytics; detecting academic emotions from learners’ skin conductance and heart rate: data-driven approach using fuzzy logic; branched learning paths for the recommendation of personalized sequences of course items; on the emergence of typical behaviors in LMS; education 4.0 for tall thin engineer competencies blended learning 4.0 process with learning analytics cockpit; and evidence-based implementation of a learning analytics dashboard into an existing learning management system.<br/>},
} 


@inproceedings{20245217591473 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Serious Games for Vocational Training},
journal = {Proceedings of the European Conference on Games-based Learning},
author = {Gobel, Stefan and Rotter, Elisabeth and Brabander, Wolfgang and Maier, Angelika and Ziegler, Birgit},
volume = {18},
number = {1},
year = {2024},
pages = {297 - 303},
issn = {20490992},
address = {Aarhus, Denmark},
abstract = {<div data-language="eng" data-ev-field="abstract">The research project ‘SG4BB’ (Serious Games for Vocational Education and Training; abbr.: VET) has developed an integrated platform for the description, search, retrieval, integration, and utilization of educational games. This paper summarizes project outcomes, including platform concepts, software components, and – as focus – practical insights derived from a case study involving the educational game ‘Corrugated’ as simulation and training environment for service technicians. SG4BB has followed a user-centered design in an interdisciplinary project team: Two learning providers specified their requirements for VET in their specific application domains. Based on those requirements, game developers, learning solution providers and researchers for VET have conceptualized and prototypically implemented both an integrated learning platform (SG4BB platform) and two case studies of Serious Games for VET: ‘Corrugated’ for service technicians and an IT security game. The platform follows a process pipeline: For search and retrieval of educational games for VET, an application profile for VET based on the standardized ‘Serious Games Metadata Format’ (DIN/SPEC 91380) has been elaborated. This format builds the semantic basis for the metadata-based catalog system ‘Serious Games Information Center’ (SG-IC) with filter functionality for VET. Learning providers and developers can use the SG-IC portal to describe and promote their educational games, enabling users to identify suitable games for their learning needs and integrate them via learning infrastructure. Educational games can interact with the backend (Learning Management System and Learning Record Store) through a middleware based on the xAPI standard, allowing for personalized gameplay and data collection for game-based learning analytics. The final evaluation of the SG4BB project focused on the utilization of the educational game ‘Corrugated’, targeting problem-solving skills for service technicians in the corrugated cardboard industry. Data from 26 participants playing the game for 60 minutes, along with problem-solving tests and user experience feedback, were analyzed to validate game-based assessment and to assess learning impact. Initial results reveal insights into specific game missions, playtimes, and success rates, indicating that participant behavior during gameplay influenced perceived learning progress, leading to varied learning paths. This paper provides valuable insights and technical information for VET practitioners on using educational games for training. Game interactions and learning outcomes can be monitored via a dashboard within the learning infrastructure, offering visualizations for user behavior (during play) and (learning) progress.<br/></div> © 2024 Dechema e.V.. All rights reserved.},
key = {Middleware},
keywords = {Apprentices;Cardboard;Costs;Decision making;Enterprise resource planning;Financial markets;Human resource management;Information management;Intellectual property core;Personnel training;Project management;Records management;},
note = {Case-studies;Educational game;Evaluation;Gameplay;Integrated platform;Learning progress;Platform concept;Project outcomes;Vocational education and training;Vocational training;},
URL = {http://dx.doi.org/10.34190/ecgbl.18.1.2710},
} 


@inproceedings{20200208022041 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Learning evidence Analytics Framework (LEAF) in practice: A2I2 based Teacher Adoption Approach},
journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
author = {Majumdar, Rwitajit and Warriem, Jayakrishnan M. and Kuromiya, Hiroyuki and Akc Apinar, Gokhan and Flanagan, Brendan and Ogata, Hiroaki},
volume = {1},
year = {2019},
pages = {351 - 353},
address = {Kenting, Taiwan},
abstract = {Learning Analytics (LA) platforms can gather data from the teaching-learning interactions during a course. While there have been previous discussions regarding the individual tools, limited scholarship describes the utility of a LA framework for supporting evidence-based teaching-learning practices. We have proposed LEAF, a framework to bridge that gap. We implement the framework in a platform by integrating LMS, learning behaviour sensors such as an ebook reader, learning analytics dashboard and an evidence portal through Learning Tools Interoperability (LTI). The platform was then made available to teachers from different colleges in India to orchestrate their course offering for one semester. This paper describes the design of the teacher training module for the adoption of the platform based on the A2I2 model as its theoretical basis. The A2I2 model explicitly focuses on encouraging scholarship of learning and teaching among participating teachers and thus is an ideal candidate for utilizing an evidence-based framework.<br/> © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
key = {Personnel training},
keywords = {Teaching;Interoperability;},
note = {A2I2;Evidence-based;LEAF;Learning and teachings;Learning tool;Teacher training;Teaching-learning;TEEL;},
} 


@inproceedings{20204109316089 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Self and peer monitoring during peer feedback: The instructor perspective},
journal = {CEUR Workshop Proceedings},
author = {Er, Erkan},
volume = {2671},
year = {2020},
pages = {113 - 120},
issn = {16130073},
address = {Valladolid, Spain},
abstract = {Monitoring is a crucial skill that can trigger regulation of learning for achieving better learning outcomes. While monitoring the self can enhance selfregulation, monitoring peers in collaborative activities can support co-regulation. Student-facing dashboards have been often used to support monitoring. These dashboards intend to provide students with timely feedback on how well they are doing, which then is expected to be used by the students to evaluate their progress and update their learning strategies as needed. This study investigates instructors' perspective about self and peer monitoring enabled via a student-facing dashboard in the specific context of peer reviews, which is an underexplored area of research. The findings suggest that although instructors consider that the proposed approach to monitoring can hold potential to enhance students' (both self- and co-) regulation of learning, they acknowledge that the activation of regulation in real-world practice might be a challenge. Implications for the activity design and learning analytics support are discussed.<br/> Copyright © 2020 for this paper by its authors.},
key = {Students},
keywords = {Monitoring;Learning systems;Facings;},
note = {Co-regulation;Collaborative activities;Learning outcome;Learning strategy;Peer feedback;Peer monitoring;Real-world practice;Timely feedback;},
} 


@inproceedings{20202508840997 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {UserFlow: A Tool for Visualizing Fine-grained Contextual Analytics in Teaching Documents},
journal = {Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
author = {Singh, Shaveen and Meyer, Bernd and Wybrow, Michael},
year = {2020},
pages = {384 - 390},
issn = {1942647X},
address = {Trondheim, Norway},
abstract = {The adoption of innovative online teaching tools in Computer Science (CS) courses provides opportunities for data-informed instruction as a regular teaching practice in CS classrooms. In this paper, we present a design study for an interactive visual analytics dashboard, called UserFlow, that supports feedback collection from teaching documents and assists instructors in interpreting feedback and acting on it in a timely manner. The design study is conducted with eight domain experts comprising of four teaching instructors, two learning analytics (LA) experts and two instructional designers. UserFlow offers a set of novel visualization designs for presenting the four interleaving aspects of document engagement (i.e., annotations, document traversal path, reading/focus time and student information). We evaluated UserFlow in an undergraduate computer science course with over 700 students. Our results demonstrate the usefulness and need for such a tool for CS educators to inform teaching approaches and courseware improvement.<br/> © 2020 ACM.},
key = {Teaching},
keywords = {Visualization;E-learning;Education computing;Students;},
note = {Domain experts;Instructional designer;Novel visualizations;Online teaching;Teaching approaches;Teaching practices;Undergraduate computer science course;Visual analytics;},
URL = {http://dx.doi.org/10.1145/3341525.3387410},
} 


@inproceedings{20173003976086 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {4th International Conference on HCI in Business, Government and Organizations, HCIBGO 2017, held as part of the 19th International Conference on Human-Computer Interaction , HCI 2017},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {10296 LNCS},
year = {2017},
pages = {1 - 498},
issn = {03029743},
address = {Vancouver, BC, Canada},
abstract = {The proceedings contain 75 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Using augmented reality interactive system to support digital electronics learning; an AI system for coaching novice programmers; affective walkthroughs and heuristics; a creative engineering experience; manipulation of mathematical expressions in collaborative environments; designing tools that allows children in the early childhood to program robots; decision making for interactive systems; preschool learning with a fingertip; augmentative and alternative communication in the literacy teaching for deaf children; a model for collaboration in virtual worlds bringing together cultures in conflict; challenges of integrating non-traditional students in higher education and how electronic learning can support inclusion; training socially responsible engineers by developing accessible video games; the use of a new visual language as a supporting resource for people with intellectual disabilities; dashboard for actionable feedback on learning skills; learning analytics and spelling acquisition in German; data analysis of coaching and advising in undergraduate students; learning analytics and its paternalistic influences; development of a dashboard for learning analytics in higher education; mixing and matching learning design and learning analytics; a guidance and evaluation approach for mhealth  education applications; collaborative hybrid agent provision of learner needs using ontology based semantic technology and designing a peer feedback mobile application as a professional development tool.},
} 


@inproceedings{20212710585151 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Studies Suspension Prevention System of Distance University using Analysis of Learning Activity and Learner's Big Data},
journal = {Journal of Physics: Conference Series},
author = {Chung, Kwang Sik and Kuo, Tony Chiu-Tien},
volume = {1944},
number = {1},
year = {2021},
issn = {17426588},
address = {Hangzhou, China},
abstract = {<div data-language="eng" data-ev-field="abstract">Due to the increase in withdrawals and temporary absences of students from changes in the external environment, distance learning universities are trying to establish various policies and increase the number of enrolled students, and at the same time, are trying to establish various policies and efforts to increase the enrollment. However, it is difficult to systematically diagnose the main cause of the interruption of students, and prior research efforts related to the problem of student suspension in distance learning universities have accumulated, since there are various reasons for the student suspensions. In the proposed distance university Studies Suspension Prevention System (SSPS), distance university students can use two types of learning analytics services. In order to analyze learning activities, we propose the asynchronous learning activity analysis module, and the synchronous learning activity analysis module. In the asynchronous analysis module and symchronous analysis module, quiz, LINE group chatting & discussion forum communication, and online lecture has a learning state score according to the lecturer's directions. Learning activities in the learning management system have three kinds of learning states, passive activity state, negative activity state, and medium activity state. Learning activity states are used to predict the student learning state. In the proposed Student Support System, there are two types of learning support services connected to the smart learning portal server. One is the intelligent distance university chatbot service for personalized chatting and caring services. The other is push message services for alarm, warning, notices, and alerts, such as dashboard service.<br/></div> © Published under licence by IOP Publishing Ltd.},
key = {Students},
keywords = {Learning systems;Distance education;Big data;Suspensions (components);Information analysis;},
note = {Asynchronous learning;External environments;Learning Activity;Learning management system;Learning support services;Prevention systems;Synchronous learning;University students;},
URL = {http://dx.doi.org/10.1088/1742-6596/1944/1/012001},
} 


@inproceedings{20171003428652 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Lernanto: Using an ambient display during differentiated instruction},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
author = {Van Alphen, Erik and Bakker, Saskia},
volume = {07-12-May-2016},
year = {2016},
pages = {2334 - 2340},
address = {San Jose, CA, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">The emerging field of Learning Analytics (LA) promises to provide teachers with all types of data gathered realtime during lessons. This data could support teachers during differentiated instruction. A potential pitfall of providing teachers with such data on a screen-based dashboard, is information overload: comprehending the overload of information might decrease the valuable time available to attend to students. We present a pilot study in which data from Learning Analytics is provided to two secondary school teachers by means of an ambient display, called Lernanto. Semi-structured interviews, after a ten-week testing period, reveal that immediate access to learning analytics through an ambient display, next to using a LA dashboard, could result in teachers being able to distribute their attention more efficiently during lessons.<br/></div> © 2016 Authors.},
key = {Teaching},
keywords = {Display devices;Human computer interaction;Human engineering;},
note = {Ambient displays;Classroom orchestration;Classroom technology;Information overloads;Peripheral interactions;Pilot studies;Real- time;School teachers;Secondary schools;Teachers';},
URL = {http://dx.doi.org/10.1145/2851581.2892524},
} 


@article{20204309382930 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Student Modeling for Individuals and Groups: the BioWorld and HOWARD Platforms},
journal = {International Journal of Artificial Intelligence in Education},
author = {Lajoie, Susanne P.},
volume = {31},
number = {3},
year = {2021},
pages = {460 - 475},
issn = {15604292},
abstract = {<div data-language="eng" data-ev-field="abstract">I first met Jim Greer at the NATO Advanced Study Institute on Syntheses of Instructional Sciences and Computing Science for Effective Instructional Computing Systems in 1990 in Calgary, Canada. It was during this meeting that I came to realize that Jim was one of those rare individuals that could help "translate" computer science principles to non-computer scientists. Through this translation process new knowledge could be developed through interdisciplinary partnerships with psychology and education. In this paper, I describe the manner in which Jim influenced my own journey in the field of Artificial Intelligence and Education. In particular, he has influenced two directions in my research, one direction is the manner in which technology can influence teaching and learning for individuals working solo. The second direction is how technology can influence teaching and learning through collaboration. In both situations I will discuss Jim Greer’s influence on my research with respect to learner modelling, educational data mining, and visualization. In the context of solo learning, I will discuss BioWorld, a system that fosters clinical reasoning in medical students, emphasizing the role of student modeling and educational data mining for fostering and identifying performance differences in clinical reasoning. In the context of collaborative learning, I will discuss HOWARD, an online platform for supporting small group problem-based learning in medical students. In particular, I will discuss the role of learning analytics used in a pedagogical dashboard to foster teachers’ interpretation of group learning.<br/></div> © 2020, International Artificial Intelligence in Education Society.},
key = {Data mining},
keywords = {Data visualization;Medical education;Visualization;Learning systems;Medical problems;Students;},
note = {Collaborative learning;Computer scientists;Educational data mining;Instructional computing;Instructional science;Problem based learning;Teaching and learning;Translation process;},
URL = {http://dx.doi.org/10.1007/s40593-020-00219-x},
} 


@inproceedings{20221211808780 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {22nd International Conference on Artificial Intelligence in Education, AIED 2021},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {12748 LNAI},
year = {2021},
issn = {03029743},
address = {Virtual, Online},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 125 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: Protecting Student Privacy with Synthetic Data from Generative Adversarial Networks; learning Analytics and Fairness: Do Existing Algorithms Serve Everyone Equally?; exploiting Structured Error to Improve Automated Scoring of Oral Reading Fluency; data Augmentation for Enlarging Student Feature Space and Improving Random Forest Success Prediction; The School Path Guide: A Practical Introduction to Representation and Reasoning in AI for High School Students; Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses; early Prediction of Children’s Disengagement in a Tablet Tutor Using Visual Features; an Educational System for Personalized Teacher Recommendation in K-12 Online Classrooms; designing Intelligent Systems to Support Medical Diagnostic Reasoning Using Process Data; open Learner Models for Multi-activity Educational Systems; incorporating Item Response Theory into Knowledge Tracing; automated Model of Comprehension V2.0; pre-course Prediction of At-Risk Calculus Students; examining Learners’ Reflections over Time During Game-Based Learning; examining the Use of a Teacher Alerting Dashboard During Remote Learning; capturing Fairness and Uncertainty in Student Dropout Prediction – A Comparison Study; Dr. Proctor: A Multi-modal AI-Based Platform for Remote Proctoring in Education; multimodal Trajectory Analysis of Visitor Engagement with Interactive Science Museum Exhibits; analytics of Emerging and Scripted Roles in Online Discussions: An Epistemic Network Analysis Approach; towards Automatic Content Analysis of Rhetorical Structure in Brazilian College Entrance Essays; personal Vocabulary Recommendation to Support Real Life Needs; contrasting Automatic and Manual Group Formation: A Case Study in a Software Engineering Postgraduate Course.<br/></div>},
} 


@inproceedings{20174804462109 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {1967},
year = {2017},
issn = {16130073},
address = {Vancouver, BC, Canada},
abstract = {The proceedings contain 11 papers. The topics discussed include: FutureLearn data: what we currently have, what we are learning and how it is demonstrating learning in MOOCs; the University of Southampton MOOC observatory dashboard; dynamic dashboard for educators and students in FutureLearn MOOCs: experiences and insights; discussion analytics: identifying conversations and social learners in FutureLearn MOOCs; data analytics informing MOOC continuous improvement; predicting attrition from massive open online courses in FutureLearn and edX; workshop on integrated learning analytics of MOOC post-course development; behavioral predictors of MOOC post-course development; habits of highly successful professional learners and the corresponding online curriculum; public participation in environmental stewardship after MOOCs; and engaging MOOC learners as lifelong collaborators.<br/>},
} 


@inproceedings{20194107514832 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {What Do Educational Data, Generated by an Online Platform, Tell Us About Reciprocal Web-Based Peer Assessment?},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Tsivitanidou, Olia and Ioannou, Andri},
volume = {11722 LNCS},
year = {2019},
pages = {600 - 603},
issn = {03029743},
address = {Delft, Netherlands},
abstract = {Peer Assessment (PA) is a promising evaluation strategy in the educational context, not only due to its effectiveness to reduce instructor’s evaluation loading, but mainly due to its benefit towards student development e.g., teamwork, in-depth thinking. In this exploratory study we sought to explore how do educational data, as generated by an online platform (i.e., Peergrade) and displayed in teacher’s and students’ Learning Analytics Dashboard (LAD), can potentially inform us of the PA process and the peer interactions, as they take place. Participants in the study were 21 undergraduate teacher-students who attended a science course (electrical circuits topic) following the inquiry-based approach. Students were asked to reciprocally and individually assess the responses of a peer in a given task. The findings of this study have implications towards the establishment of new theoretical frameworks and developments for bridging educational theory, design process and data science, in the field of assessment.<br/> © 2019, Springer Nature Switzerland AG.},
key = {Students},
keywords = {E-learning;Websites;},
note = {Educational context;Evaluation strategies;Exploratory studies;Peer assessment;Peer feedback;Science education;Science learning;Theoretical framework;},
URL = {http://dx.doi.org/10.1007/978-3-030-29736-7_48},
} 


@inproceedings{20173804195039 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {12th European Conference on Technology Enhanced Learning, EC-TEL 2017},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {10474 LNCS},
year = {2017},
pages = {1 - 617},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {The proceedings contain 75 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Machine and human observable differences in groups’ collaborative problem-solving behaviours; equality and intra-individual variability of physical interactivity; towards automatic assessment of argumentation in theses justifications; contextualizing the co-creation of artefacts within the nested social structure of a collaborative MOOC; pitfalls of learning analytics dashboards in the educational practice; examining interaction modality effects toward engagement in an interactive learning environment; using embodied learning technology to advance motor performance of children with special educational needs and motor impairments; usage and impact; a multi-aspect generic adaptation model for learning environments; automatic assessment of programming assignments using image recognition; learning analytics for professional and workplace learning; examining validity and reliability of the evaluation framework for learning analytics; opportunities and challenges in using learning analytics in learning design; evaluating student-facing learning dashboards of affective states; a strong concept in technology enhanced learning; a new theoretical framework for curiosity for learning in social contexts; studying multimodal behavioral dynamics to design social scaffolding of curiosity; using sequential pattern mining to explore learners’ behaviors and evaluate their correlation with performance in inquiry-based learning; a multi-system classifier; effects of a teacher dashboard for an intelligent tutoring system on teacher knowledge, lesson planning, lessons and student learning; identifying game elements suitable for MOOCs and an approach for the analysis of perceptual and gestural performance during critical situations.},
} 


@inproceedings{20184405999457 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {2224},
year = {2018},
issn = {16130073},
address = {Medellin, Colombia},
abstract = {The proceedings contain 12 papers. The topics discussed include: MOOC-maker: three years building MOOC management capacities in Latin America; learning analytics dashboard to work the flipped classroom methodology through the reuse of MOOCs; how to map learning activities through URLs? the case of coursera platform; LOAC: a new model in the post-MOOC era; the effectiveness of the use of simulators for knowledge building in a MOOC context; proposal for the inclusion of gamification elements in object-oriented programming through the use of MOOCs; proposal for a code book to evaluate the moderators of the MOOC videos provided by Latin American universities; experiences from the MOOC: flipped learning for teacher education; and learning with MOOCs in face-to-face classes. Pilot study in a programming course.<br/>},
} 


@inproceedings{20173804195042 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Teacher dashboards in practice: Usage and impact},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Molenaar, Inge and Knoop-van Campen, Carolien},
volume = {10474 LNCS},
year = {2017},
pages = {125 - 138},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {Even though the recent influx of tablets in primary education goes together with the vision that educational technologies will revolutionize education, empirical results supporting this claim are scarce. The adaptive educational technology in this research is used daily in primary classrooms and includes teacher dashboards. While students practice on the tablet, the technology displays real-time data of learner progress and performance in teacher dashboards. This study examines how teachers use the dashboards during lessons applying the Verberts’ learning analytic process model. Teacher dashboard consultations and resulting pedagogical actions were observed in mathematics lessons. In a following stimulated recall interview, a teacher was asked to elaborate on the knowledge he/she activated and his/her reasoning in interpreting the dashboard. The results indicate that teachers consult the dashboard on average 8,3 times per lesson, but great variation among teachers was found. Teachers activate existing knowledge about the class and students to interpret dashboard data. The pedagogical actions teachers take after dashboard consultation are mainly providing individual feedback and additional instruction. The results show that pedagogical actions preformed at teachers’ own initiative are mostly directed to low ability students, whereas actions after consulting the dashboard are more directed at middle and high ability students. These results indicate that extracted learning analytics, in the form of teacher dashboards are indeed influencing teachers’ pedagogical actions in daily classroom activities and may initiate behavior changes in teaching practices.<br/> © Springer International Publishing AG 2017.},
key = {Educational technology},
keywords = {Teaching;Students;Education computing;},
note = {Ability levels;Behavior change;Classroom activity;Dashboards;Primary education;Process Modeling;Real-time data;Teaching practices;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_10},
} 


@inproceedings{20165103153797 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {1738},
year = {2016},
issn = {16130073},
address = {Lyon, France},
abstract = {The proceedings contain 8 papers. The topics discussed include: towards understanding the potential of teaching analytics within educational communities; analysis of human-to-human tutorial dialogues: insights for teaching analytics; Luna: a dashboard for teachers using intelligent tutoring systems; developing a teacher dashboard for use with intelligent tutoring systems; an open learner model used by teachers to monitor speed reading learners; modelling the relationship between learner autonomy and cognitive abilities worth the effort?; support teachers' predictions of learning success by structural competence modelling; and improving personalized feedback at the workplace with a learning analytics enhanced e-portfolio.},
} 


@inproceedings{20192707151790 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {10th International Conference on Computer Supported Education, CSEDU 2018},
journal = {Communications in Computer and Information Science},
volume = {1022},
year = {2019},
issn = {18650929},
address = {Funchal, Portugal},
abstract = {The proceedings contain 27 papers. The special focus in this conference is on Computer Supported Education. The topics include: Improving STEM Learning Experience in Primary School by Using NEWTON Project Innovative Technologies; Pathways to Successful Online Testing: eExams with the “Secure Exam Environment” (SEE); A Space-Efficient Technique of Policy Trees for an Intelligent Tutoring System on POMDP; a Learning Analytics Dashboard to Analyse Learning Activities in Interpreter Training Courses; how to Apply Problem-Based Learning in a Managed Way? A Case in Computing Education; practical Software Engineering Capstone Course – Framework for Large, Open-Ended Projects to Graduate Student Teams; a Systematic Mapping Study on Game Elements and Serious Games for Learning Programming; algorithms and Logic as Programming Primers; an Evaluation of the Reliability, Validity and Sensitivity of Three Human Mental Workload Measures Under Different Instructional Conditions in Third-Level Education; Using Spinoza Log Data to Enhance CS1 Pedagogy; an Exercise in Reverse Engineering for Safety-Critical Systems: An Experience for the Classroom; digital Media and Informal Learning: Alteration Mechanism and Captured Episodes; as One Size Doesn’t Fit All, Personalized Massive Open Online Courses Are Required; intermediaries in eHealth Education; detecting and Addressing Design Smells in Novice Processing Programs; investigating Embodied Music Expression Through the Leap Motion: Experimentations in Educational and Clinical Contexts; intuitive Reasoning in Formalized Mathematics with Elfe; automatic Evaluation of Students’ Discussion Skill Based on their Heart Rate; improving Student Learning Experience by the Full Integration of Classroom Response Systems into Lectures; a Layered Approach to Automatic Essay Evaluation Using Word-Embedding.<br/>},
} 


@article{20171603586992 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A novel web-based approach for visualization and inspection of reading difficulties on university students},
journal = {IEEE Transactions on Learning Technologies},
author = {Mejia, Carolina and Florian, Beatriz and Vatrapu, Ravi and Bull, Susan and Gomez, Sergio and Fabregat, Ramon},
volume = {10},
number = {1},
year = {2017},
pages = {53 - 67},
issn = {19391382},
abstract = {Existing tools aim to detect university students with early diagnosis of dyslexia or reading difficulties, but there are not developed tools that let those students better understand some aspects of their difficulties. In this paper, a dashboard for visualizing and inspecting early detected reading difficulties and their characteristics, called PADA (acronym for the Spanish name Panel de Analíticas de Aprendizaje de Dislexia en Adultos), is presented. PADA is a web-based tool designed to facilitate the creation of descriptive visualizations required for a better understanding by students about their learner model. Through information visualization techniques, PADA shows students the knowledge in their learner models in order to help them to increase their awareness and to support reflection and self-regulation about their difficulties in reading. PADA provides different learning analytics on reading performance of students, so that they can self-identify their strengths and weaknesses and self-regulate their learning. This paper describes examples that cover a variety of visualizations (bar-charts, line-charts, and pie-charts) to show user model fragments as personal details, reading profiles, learning styles, and cognitive traits of the students. We tested PADA with 26 students (aged 21-53 years) of different academic programs and levels, dyslexic and non-dyslexic. The results show that PADA can assist students in creating awareness, and help them to understand their difficulties associated with the reading tasks, as well as facilitate reflection and self-regulation in the learning process. Implications for the design of learning analytics are discussed and directions for future work are outlined.<br/> © 2008-2011 IEEE.},
key = {Students},
keywords = {Deregulation;Diagnosis;Information systems;Visualization;Websites;Learning systems;},
note = {Dyslexia;Information visualization;Learning process;Open learner modeling;reading difficulties;Reading performance;University students;Web-based approach;},
URL = {http://dx.doi.org/10.1109/TLT.2016.2626292},
} 


@inproceedings{20201308362479 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Comparing teachers' use of mirroring and advising dashboards},
journal = {ACM International Conference Proceeding Series},
author = {Van Leeuwen, Anouschka and Rummel, Nikol},
year = {2020},
pages = {26 - 34},
address = {Frankfurt, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">Teachers play an essential role during collaborative learning. To provide effective support, teachers have to be constantly aware of students' activities and make fast decisions about which group to offer support, without disrupting students' collaborative process. Teacher dashboards are visual displays that provide analytics about learners to help teachers increase their awareness of the situation. However, if teachers are not able to efficiently and effectively distill information from the dashboard, the dashboard can become an obstacle instead of an aid. In the present study, we compared dashboards that provide information (mirroring) to dashboards that provide information and alert the teacher to groups that are in need of support (advising). Teachers were shown standardized, fictitious collaborative situations on one of the types of dashboards and were asked to detect the group that was in need of support. Te results showed that teachers in the advising condition more often detected the problematic group, needed less effort to do so, and were more confident of their decisions. Te teacher-dashboard interaction paterns showed that teachers in the advising condition generally started by checking the given alert, but also that they tried to look at as much information about other groups as they could. In the mirroring condition, teachers generally started by examining information from class overviews, but did not always have time to check information for individual groups. Tese findings are discussed in light of the role of a teacher dashboard in teachers' decision making in the context of student collaboration.<br/></div> © 2020 Association for Computing Machinery.},
key = {Students},
keywords = {Decision making;},
note = {Cooperative/collaborative learning;Elementary education;Human computer interfaces;Improving classroom teaching;Teaching/learning strategy;},
URL = {http://dx.doi.org/10.1145/3375462.3375471},
} 


@inproceedings{20204109316085 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A proposal for monitoring the intervention strategy on the learning of MOOC learners},
journal = {CEUR Workshop Proceedings},
author = {Cobos, Ruth and Soberon, Juan},
volume = {2671},
year = {2020},
pages = {61 - 72},
issn = {16130073},
address = {Valladolid, Spain},
abstract = {Insufficient feedback and lack of interaction among instructors and learners affect negatively learner retention and engagement in MOOCs. These factors, paired with the feeling of isolation, have a high influence on learners who do not complete the course in which they have enrolled. To overcome this situation, we propose a system to provide periodically MOOC learners with visual information on a Web-based Learner Dashboard, showing them their progress and engagement in the MOOC. This provided information is part of an Intervention Strategy on the learning of these learners. The system offers MOOC instructors to access to a Web-based Instructor Dashboard that shows the interest in this service by the learners and, therefore, facilitates evaluating the success or failure of the Intervention Strategy.<br/> Copyright © 2020 for this paper by its authors.},
key = {Websites},
keywords = {Learning systems;E-learning;},
note = {Intervention strategy;Visual information;Web based;},
} 


@inproceedings{20233314564268 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling Feedback for Self-Direction Skills in K-12 Educational Settings with Learning and Physical Activity Data},
journal = {CEUR Workshop Proceedings},
author = {Li, Huiyong and Majumdar, Rwitajit and Yang, Yuanyuan and Ogata, Hiroaki},
volume = {3439},
year = {2023},
pages = {12 - 22},
issn = {16130073},
address = {Arlington, TX, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">This work aims to propose a learner model-based feedback model for self-direction skills (SDS) acquisition to address the challenge of providing learning services with multimodal data in K-12 settings. The feedback model leverages students' daily life activity data from learning systems and wearable devices, creates a learner model of SDS, and provides multi-dimensional feedback to K-12 students: (1) feedback on contextual activity; (2) feedback on self-direction management and (3) feedback on skill assessment. We also implement the feedback model with two learning dashboards in English learning and physical activity contexts for illustration and show the potential effects of the feedback model on student engagement and skill improvement with two case studies in K-12 settings. The results of the case studies indicate that K-12 students can continuously engage in both learning and physical activities, and take the feedback regularly with the learning dashboard support. The implications and challenges of SDS development with multimodal data in K-12 settings are also discussed.<br/></div> © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
key = {Students},
keywords = {Information management;Learning systems;},
note = {Case-studies;Educational settings;Feedback model;Learner modeling;Learning Activity;Learning analytic;Model feedback;Multi-modal data;Physical activity;Self-direction skill;},
} 


@inproceedings{20221111796070 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards Collaborative Convergence: Quantifying Collaboration Quality with Automated Co-located Collaboration Analytics},
journal = {ACM International Conference Proceeding Series},
author = {Praharaj, Sambit and Scheffel, Maren and Schmitz, Marcel and Specht, Marcus and Drachsler, Hendrik},
year = {2022},
pages = {358 - 369},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Collaboration is one of the four important 21st-century skills. With the pervasive use of sensors, interest on co-located collaboration (CC) has increased lately. Most related literature used the audio modality to detect indicators of collaboration (such as total speaking time and turn taking). CC takes place in physical spaces where group members share their social (i.e., non-verbal audio indicators like speaking time, gestures) and epistemic space (i.e., verbal audio indicators like the content of the conversation). Past literature has mostly focused on the social space to detect the quality of collaboration. In this study, we focus on both social and epistemic space with an emphasis on the epistemic space to understand different evolving collaboration patterns and collaborative convergence and quantify collaboration quality. We conduct field trials by collecting audio recordings in 14 different sessions in a university setting while the university staff and students collaborate over playing a board game to design a learning activity. This collaboration task consists of different phases with each collaborating member having been assigned a pre-fixed role. We analyze the collected group speech data to do role-based profiling and visualize it with the help of a dashboard.<br/></div> © 2022 ACM.},
note = {Co-located collaboration;Collaboration;Collaboration analytic;Collaboration patterns;Field trial;Group members;Multi-modal learning;Multimodal learning analytic;Social spaces;Turn-taking;},
URL = {http://dx.doi.org/10.1145/3506860.3506922},
} 


@inproceedings{20211510207507 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Facilitators first: Building a tool with facilitators to foster a more collaborative makerspace community through movement traces},
journal = {ACM International Conference Proceeding Series},
author = {Guillain, Leonore V. and Schneider, Bertrand},
year = {2021},
pages = {533 - 539},
address = {Virtual, Online, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Research indicates that makerspaces equip students with the practical skills needed to build their own projects and thrive in the twenty-first-century workforce. While the appeal of makerspaces lies in their spirit of tinkering and community-driven ethos, these same attributes make it difficult to monitor and facilitate learning. Makerspaces also attract students from diverse backgrounds and skills, further challenging facilitators to accommodate the needs of each student and their self-directed projects. We propose a dashboard interface that visualizes Kinect sensor data to aid facilitators in monitoring student collaboration. The tool was designed with an iterative and participatory approach. Five facilitators were involved at each phase of the design process, from need-finding to prototyping to implementation and evaluation. Insights derived from interviews were used to inform the design decisions of the final interface. The final evaluation suggests that the use of normalized summary scores and an interactive network graph can successfully support facilitators in tasks related to improving collaboration. Moreover, the use of a red-green color scheme and the inclusion of student photos improved the usability for facilitators, but issues of trustworthiness need to be further examined.<br/></div> © 2021 ACM.},
key = {Students},
keywords = {Image enhancement;Human computer interaction;},
note = {Design decisions;Design process;Kinect sensors;Need findings;Participatory approach;Practical skill;Self-directed;Student collaboration;},
URL = {http://dx.doi.org/10.1145/3448139.3448194},
} 


@inproceedings{20150900586144 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An assessment engine: Educators as editors of their serious games' assessment},
journal = {Proceedings of the European Conference on Games-based Learning},
author = {Chaudy, Yaelle and Connolly, Thomas and Hainey, Thomas},
volume = {1},
year = {2014},
pages = {58 - 67},
issn = {20490992},
abstract = {Serious Games (SG) are increasingly used by educators to assist the teaching and learning process and offer many advantages over traditional education. They are highly engaging, motivating and they have the potential to adapt to each student quickly becoming an ideal supplementary tool for education. However, if the majority of teachers agree that using SGs increases the motivation, learning and retention of their students, very few of them are ready to trust their assessment to verify that the learning goals have been met. They would rather adopt a more conventional method such as a paperbased test. We believe two main reasons explain this attitude: a lack of ownership over the games used and the rigidness of the games, making them unmodifiable by the teacher. To overcome these issues, we have developed an assessment engine to be used by both SG developers and educators. The engine's design results in a separation of a game and its assessment, and the resulting modularity allows the teachers to modify the assessment of a game even after distribution. This paper focuses on the teacher interface of the assessment engine. After reviewing the literature associated with ingame assessment and learning analytics, the paper will provide a summary of the engine and its functionalities, present the Learning Analytics (LA) dashboard. We will then describe the visual language that allows teachers to edit a game's assessment system based on the LA reports. Thereafter, the authorisation and versioning mechanics of the engine will be detailed, showing how the system regulates the access to the games and stressing the fact that every teacher will have, after modification, a unique game customised to their students' needs. Finally, we will provide conclusions and state the remaining work to be undertaken.<br/> © The Authors, 2014.},
key = {Engines},
keywords = {Visual languages;Serious games;Motivation;Students;Teaching;},
note = {Assessment;Assessment system;Authoring tool;Conventional methods;Paper-based test;Teaching and learning;Traditional educations;Visual editors;},
} 


@inproceedings{20162702561760 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating physical activity data in videogames with user-centered dashboards},
journal = {ACM International Conference Proceeding Series},
author = {Hagood, Danielle and Ching, Cynthia Carter and Schaefer, Sara},
volume = {25-29-April-2016},
year = {2016},
pages = {530 - 531},
address = {Edinburgh, United kingdom},
abstract = {To promote healthy awareness and activity learning, we gave 12- To 14-year-old youth activity monitors (Fitbits) to track their physical activity, which was then integrated into a videogame we created. The players' real-world steps transform into in-game resources needed for gameplay. In addition to requiring real-world steps for various in-game activities, a dashboard in this game presents visual representations of activity patterns, ostensibly informing students about patterns of their own activity. In this paper and poster, we discuss challenges in initial designs of our dashboard. We present findings and challenges in the process of creating a user-centered dashboard and conclude with our future design goals.<br/> © 2016 Copyright held by the owner/author(s).},
key = {Human computer interaction},
note = {Activity learning;Activity monitors;Activity patterns;Dashboards;Physical activity;Quantified self;Socio-cultural theories;Visual representations;},
URL = {http://dx.doi.org/10.1145/2883851.2883958},
} 


@inproceedings{20162702561840 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards analytics for educational interactive e-Books: The case of the reflective designer analytics platform (RDAP)},
journal = {ACM International Conference Proceeding Series},
author = {Karkalas, Sokratis and Mavrikis, Manolis and Labs, Oliver},
volume = {25-29-April-2016},
year = {2016},
pages = {143 - 147},
address = {Edinburgh, United kingdom},
abstract = {This paper presents an analytics dashboard that has been developed for designers of interactive e-books. This is part of the EU-funded MC Squared project that is developing a platform for authoring interactive educational e-books. The primary objective is to develop technologies and resources that enhance creative thinking for both designers (authors) and learners. The learning material is expected to offer learners opportunities to engage creatively with mathematical problems and develop creative mathematical thinking. The analytics dashboard is designed to increase authors' awareness so that they can make informed decisions on how to redesign and improve the e-books. This paper presents architectural and design decisions on key features of the dashboard and discusses future steps with respect to the potential for exploratory data analysis.<br/> © 2016 ACM.},
key = {Electronic publishing},
keywords = {Electronic document exchange;},
note = {Creative thinking;Design decisions;Exploratory data analysis;Informed decision;Learning materials;Mathematical problems;Mathematical thinking;Primary objective;},
URL = {http://dx.doi.org/10.1145/2883851.2883943},
} 


@inproceedings{20171403522597 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Intelligent tutors as teachers' aides: Exploring teacher needs for real-time analytics in blended classrooms},
journal = {ACM International Conference Proceeding Series},
author = {Holstein, Kenneth and McLaren, Bruce M. and Aleven, Vincent},
year = {2017},
pages = {257 - 266},
address = {Vancouver, BC, Canada},
abstract = {Intelligent tutoring systems (ITSs) are commonly designed to enhance student learning. However, they are not typically designed to meet the needs of teachers who use them in their classrooms. ITSs generate a wealth of analytics about student learning and behavior, opening a rich design space for real-time teacher support tools such as dashboards. Whereas real-time dashboards for teachers have become popular with many learning technologies, we are not aware of projects that have designed dashboards for ITSs based on a broad investigation of teachers' needs. We conducted design interviews with ten middle school math teachers to explore their needs for on-the-spot support during blended class sessions, as a first step in a user-centered design process of a real-time dashboard. Based on multi-methods analyses of this interview data, we identify several opportunities for ITSs to better support teachers' needs, noting that the analytics commonly generated by existing teacher support tools do not strongly align with the analytics teachers expect to be most useful. We highlight key tensions and tradeoffs in the design of such realtime supports for teachers, as revealed by "Speed Dating" possible futures with teachers. This paper has implications for our ongoing co-design of a real-time dashboard for ITSs, as well as broader implications for the design of ITSs that can effectively collaborate with teachers in classroom settings.<br/> © 2017 ACM.},
key = {Decision making},
keywords = {Computer aided instruction;Interactive computer systems;Teaching;Real time systems;Behavioral research;Students;Scaffolds;User centered design;},
note = {Adoption;Blended learning;Classrooms;Intelligent tutoring system;Real-time analytics;Teachers;},
URL = {http://dx.doi.org/10.1145/3027385.3027451},
} 


@inproceedings{20141717632600 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Visual analytics of academic writing},
journal = {ACM International Conference Proceeding Series},
author = {Simsek, Duygu and Shum, Simon Buckingham and De Liddo, Anna and Ferguson, Rebecca and Sandor, Agnes},
year = {2014},
pages = {265 - 266},
address = {Indianapolis, IN, United states},
abstract = {This paper describes a novel analytics dashboard which visualises the key features of scholarly documents. The Dashboard aggregates the salient sentences of scholarly papers, their rhetorical types and the key concepts mentioned within these sentences. These features are extracted from papers through a Natural Language Processing (NLP) technology, called Xerox Incremental Parser (XIP). The XIP Dashboard is a set of visual analytics modules based on the XIP output. In this paper, we briefly introduce the XIP technology and demonstrate an example visualisation of the XIP Dashboard. Copyright © 2014 by the Association for Computing Machinery, Inc.<br/>},
key = {Visualization},
keywords = {Natural language processing systems;Syntactics;},
note = {Academic writings;Key feature;NAtural language processing;Visual analytics;},
URL = {http://dx.doi.org/10.1145/2567574.2567577},
} 


@inproceedings{20171403522475 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Business intelligence (BI) for personalized student dashboards},
journal = {ACM International Conference Proceeding Series},
author = {Sluijter, J. and Otten, M.},
year = {2017},
pages = {562 - 563},
address = {Vancouver, BC, Canada},
abstract = {At Stenden University students from all over the world study together; all these different nationalities and cultures result in different ideas concerning academic success. The basis of this project was to develop a personalized dashboard for students via Microsoft Office 365 Power BI in which students can set their own personal KPI's. The raw data from the Student Information System (SIS) was transformed into clear visualizations that will help students gain better insight into their academic performance. This information can be used either independently or in consultation with their student advisor.<br/> © 2017 ACM.},
key = {Students},
keywords = {Information analysis;},
note = {Academic performance;Excel;Microsoft Office;Personalized dashboards;Power query;University students;},
URL = {http://dx.doi.org/10.1145/3027385.3029458},
} 


@inproceedings{20184406003049 ,
language = {Spanish; Castilian},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Integration of open source tools in IoT education: Case study of personal response systems in a basic mathematics course in university},
journal = {CEUR Workshop Proceedings},
author = {Flores, Monica and Garzon, Andrea and Arce, Victor and Plaza, Douglas},
volume = {2231},
year = {2018},
issn = {16130073},
address = {Guayaquil, Ecuador},
abstract = {The objective of this research is to compare the knowledge and learning of students through traditional formative tests and with an IoT device. For that, the IoTlicker is developed, it is a device that uses an Arduino that allows the students to answer by a keypad to questions entered by the teacher shown on the LED screen and sends them via Wi-Fi to the database connected with a router. A platform is created with Google Dashboard in which the answers can be shown in real time in order to give the students an instant feedback that helps the teacher to know the results as soon as possible to improve the learning and knowledge. As a result, it is obtained that the IoTlicker helps math students improve their knowledge and learning, with an average of answers with traditional tests is 5.6% and with the IoTlicker it is 7.3%, which has a difference of 1.7%.<br/> © 2018 CEUR-WS. All rights reserved.},
key = {Students},
keywords = {Open systems;Internet of things;},
note = {Basic mathematics;IoT device;Led screens;Open source tools;Personal response systems;Real time;},
} 


@inproceedings{20162702561855 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting learning by considering emotions: Tracking and visualization. A case study},
journal = {ACM International Conference Proceeding Series},
author = {Ruiz, Samara and Charleer, Sven and Urretavizcaya, Maite and Klerkx, Joris and Isabel, Fernandez-Castro and Duval, Erik},
volume = {25-29-April-2016},
year = {2016},
pages = {254 - 263},
address = {Edinburgh, United kingdom},
abstract = {The adequate emotional state of students has proved to be essential for favoring learning. This paper explores the possibility of obtaining students' feedback about the emotions they feel in class in order to discover potential emotion patterns that might indicate learning fails. This paper presents a visual dashboard that allows students to track their emotions and follow up on their evolution during the course. We have compiled the principal classroom related emotions and developed a two-phase inquiry process to: verify the possibility to measure students' emotions in classroom; discover how emotions can be displayed to promote self-reflection; and confirm the impact of emotions on learning performance. Our results suggest that students' emotions in class are related to evaluation marks. This shows that early information about students' emotions can be useful for teachers and students to improve classroom results and learning outcomes.<br/> © 2016 ACM.},
key = {Students},
keywords = {Teaching;},
note = {Emotional state;Face to face;Follow up;Learning outcome;Learning performance;Quantified-self;Self reflection;Two phase;},
URL = {http://dx.doi.org/10.1145/2883851.2883888},
} 


@article{20230513530129 ,
language = {Turkish},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Acik ve Uzaktan Ogrenmede Ogrenme Analitikleri Kontrol Panelinin Gelistirilmesi: Ogrenme Bulutu =},
journal = {ProQuest Dissertations and Theses Global},
author = {Kayabas, Ilker},
year = {2017},
abstract = {<div data-language="tur" data-ev-field="abstract">Acik ve uzaktan ogrenme baglamindaki ogrenme analitikleri uygulamalarina yeni bir bakis acisi sunmayi amaclayan bu calisma kapsaminda, Ogrenme Bulutu olarak adlandirilan yeni bir ogrenme analitikleri sistemi gelistirilerek kullanilabilirligine iliskin arastirmalar yapilmistir. Calismanin ogrenme analitiklerine iliskin alanyazin arastirmasi, atif verilerine dayali iki asamali sistematik bir yaklasim cercevesinde desenlenmistir. Birinci asamada; ogrenme analitiklerine iliskin Web of Science veri tabaninda yer alan akademik yayinlarin analizi yapilmistir. Ikinci asamada ise; ogrenme analitikleri tum detaylari ile tanimlanarak tarihsel gelisimi ortaya konulmustur. Ogrenme analitiklerine iliskin surecler, teknikler, araclar, baglantili calisma alanlari ve uygulama ornekleri incelenmistir. Son olarak ogrenme analitiklerine iliskin etik tartismalar vurgulanmistir. Arastirma sureci; gelistirme, uygulama ve degerlendirme olmak uzere uc bolumden olusmaktadir. Gelistirme surecinde Ogrenme Bulutu’nun teknik altyapisi kurularak, ogrenen etkinlikleri takip mekanizmalari ve kullanici kontrol panelleri gelistirilmistir. Arastirmanin uygulama sureci, Avrupa’daki egitim-is uyusmazliginin azaltilmasi amaciyla hayata gecirilen EMLT acik ve uzaktan ogrenme sistemi kapsaminda gerceklestirilmistir. Bu surecte, Avrupa Birligi Erasmus+ Programi tarafindan desteklenen EMLT Projesine katilan ogrenenlerin ogrenme etkinliklerinin takip edilmesi, depolanmasi ve analiz edilmesi amaciyla Ogrenme Bulutu kullanilmistir. Son asama olan degerlendirme surecinde ise nicel arastirmalar altinda siniflandirilan betimsel tarama modeli cercevesince Ogrenme Bulutu’nun kullanilabilirligini belirlemeye yonelik analizler yapilmistir. Ayrica ogrencilerin Ogrenme Bulutu’nun iv kullanilabilirligine iliskin memnuniyet duzeylerinin ders basarisi, motivasyon, bilgisayar ve internet kullanim duzeyi, veri paylasim tercihleri ve kitlesel acik cevrimici ders deneyimi bakimindan farklilik gosterip gostermedigi istatistiksel olarak aciklanmaya calisilmistir. Calismanin son bolumunde, arastirma sorularina iliskin elde edilen bulgulara, bulgular dogrultusunda ulasilan sonuclara ve sonuclara bagli olarak gelistirilen onerilere yer verilmistir. ProQuest Subject Headings: Management, Computer science.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {E-learning},
keywords = {Application programs;Computer systems programming;Learning systems;Uranium compounds;},
note = {Applications programming interfaces;Distance-learning;Learning clouds;Learning management system;Open learning;Web 2.0;Web of Science;},
} 



