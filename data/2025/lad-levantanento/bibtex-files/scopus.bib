Scopus
EXPORT DATE: 28 May 2025

@CONFERENCE{Kaliisa2024295,
	author = {Kaliisa, Rogers and Misiejuk, Kamila and López-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
	title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {295 – 304},
	doi = {10.1145/3636555.3636884},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187557446&doi=10.1145%2f3636555.3636884&partnerID=40&md5=2955f134832b3876d0d55b1d416c61b2},
	affiliations = {Department of Education, University of Oslo, Norway; Centre for the Science of Learning and Technology (SLATE), University of Bergen, Norway; School of Computing, University of Eastern Finland, Finland},
	abstract = {While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students' learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike. © 2024 Owner/Author.},
	author_keywords = {impact; Learning analytics dashboards (LADs); learning outcomes; systematic review},
	keywords = {Computer aided instruction; Learning systems; Students; Achievement motivations; Impact; Learning analytic dashboard; Learning outcome; Research studies; Student achievement; Student attitudes; Student learning outcomes; Student motivation; Systematic Review; Motivation},
	correspondence_address = {R. Kaliisa; Department of Education, University of Oslo, Norway; email: rogers.kaliisa@iped.uio.no},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{Osman2024240,
	author = {Osman, Shahinaz Abdelrahman and Ahmed, Zeinab E.},
	title = {Navigating AI integration: Case studies and best practices in educational transformation},
	year = {2024},
	journal = {AI-Enhanced Teaching Methods},
	pages = {240 – 267},
	doi = {10.4018/979-8-3693-2728-9.ch011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193636705&doi=10.4018%2f979-8-3693-2728-9.ch011&partnerID=40&md5=a82281274d7c48fc80a5e8419e8fdb4d},
	affiliations = {City University Ajman, United Arab Emirates; Department of Computer Engineering, University of Gezira, Sudan; Department of Electrical and Computer Engineering, International Islamic University Malaysia, Malaysia},
	abstract = {This chapter explores the practical applications and effective methods of integrating artificial intelligence (AI) into various educational settings. It examines how educational institutions, ranging from K-12 to higher education, have successfully utilized AI to enhance teaching methods, strategies, and learning outcomes through the presentation of compelling case studies. In addition to theoretical frameworks, the chapter offers practical insights into the challenges faced, strategies employed, and lessons learned during the implementation of AI-enhanced teaching approaches. The adoption of AI in education can facilitate personalized learning journeys by tailoring instruction, materials, pacing, and resources to individual learners' needs and preferences. It also enables adaptive assessments and feedback systems that provide real-time feedback, identify areas for improvement, and contribute to more nuanced grading systems. The chapter highlights examples of AI-powered platforms, such as adaptive learning platforms, intelligent tutoring systems, smart content recommendation systems, and gamified learning paths, illustrating their effectiveness in meeting the unique requirements of students and promoting engagement and mastery. Furthermore, it discusses the importance of immediate and targeted feedback and individualized content structuring in adaptive learning environments. The chapter also explores AI-assessment tools, real-time feedback systems, learning analytics dashboards, and peer learning facilitation platforms as valuable resources for educators. By leveraging AI technologies, educational institutions can transform teaching and learning practices, promote personalized and adaptive learning, and ensure the alignment of AI-based systems with human values. © 2024, IGI Global. All rights reserved.},
	publisher = {IGI Global},
	isbn = {979-836932729-6; 979-836932728-9},
	language = {English},
	abbrev_source_title = {AI-Enhanc. Teach. Methods},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Cai2025172,
	author = {Cai, Zhenyu and Davis, Richard Lee and Mariétan, Raphaël and Tormey, Roland and Dillenbourg, Pierre},
	title = {Jupyter Analytics: A Toolkit for Collecting, Analyzing, and Visualizing Distributed Student Activity in Jupyter Notebooks},
	year = {2025},
	journal = {SIGCSE TS 2025 - Proceedings of the 56th ACM Technical Symposium on Computer Science Education},
	volume = {1},
	pages = {172 – 178},
	doi = {10.1145/3641554.3701971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000220969&doi=10.1145%2f3641554.3701971&partnerID=40&md5=ee01ef0485873339d5a387d37e62e727},
	affiliations = {EPFL, Lausanne, Switzerland; KTH Royal Institute of Technology, Stockholm, Sweden; Swisscom, Lausanne, Switzerland},
	abstract = {Jupyter is a web-based, interactive computing environment that supports many commonly-used programming languages. It has been widely adopted in the CS education community and is now rapidly expanding to other STEM disciplines due to the growing integration of programming in STEM education. However, unlike other educational platforms, there is currently no integrated way to capture, analyze, and visualize student interaction data in Jupyter notebooks. This means that teachers have limited to no visibility into student activity, preventing them from drawing insights from these data and providing timely interventions on the fly. In this paper, we present Jupyter Analytics, an end-to-end solution for teachers to collect, analyze, and visualize both synchronous and asynchronous learning activities in Jupyter. The Jupyter Analytics system consists of two JupyterLab extensions connected via a cloud-based backend. On the student side, we introduce the Jupyter Analytics Telemetry extension to anonymously capture students’ interaction activity with more structure and higher granularity than log data. On the teacher side, we introduce the Jupyter Analytics Dashboard extension, which visualizes real-time student data directly in the notebook interface. The Jupyter Analytics system was developed through an iterative co-design process with university instructors and teaching assistants, and has been implemented and tested in several university STEM courses. We report two use cases where Jupyter Analytics impacted teaching and learning in the context of exercise sessions, and discuss the potential value of our tools for CS education. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {Educational Dashboards; Jupyter; Learning Analytics; Programming; STEM education},
	keywords = {Curricula; Teaching; Textbooks; Analytics systems; CS education; Educational dashboard; Jupyter; Learning analytic; Programming; STEM education; Student interactions; Teachers'; Web based; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070531-1},
	language = {English},
	abbrev_source_title = {SIGCSE TS - Proc. ACM Tech. Symp. Comput. Sci. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Srivastava2024116,
	author = {Srivastava, Namrata and Nawaz, Sadia and Tsai, Yi-Shan and Gašević, Dragan},
	title = {Curriculum Analytics of Course Choices: Links with Academic Performance},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {1},
	pages = {116 – 131},
	doi = {10.18608/jla.2024.8095},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190235394&doi=10.18608%2fjla.2024.8095&partnerID=40&md5=fa5ffdab8d5f4a4be95a7b96e6827acc},
	affiliations = {Centre for Learning Analytics, Monash University, Clayton, 3168, VIC, Australia; Penn Center for Learning Analytics, University of Pennsylvania, Philadelphia, 19104, PA, United States; School of Computing and Information Systems, The University of Melbourne, Parkville, 3010, VIC, Australia; Melbourne Assessment, Melbourne Graduate School of Education, The University of Melbourne, Parkville, 3010, VIC, Australia},
	abstract = {In a higher education context, students are expected to take charge of their learning by deciding “what” to learn and “how” to learn. While the learning analytics (LA) community has seen increasing research on the “how” to learn part (i.e., researching methods for supporting students in their learning journey), the “what” to learn part is still underinvestigated. We present a case study of curriculum analytics and its application to a dataset of 243 students of the bachelor’s program in the broad discipline of health sciences to explore the effects of course choices on students’ academic performance. Using curriculum metrics such as grading stringency, course temporal position, and duration, we investigated how course choices differed between high-and low-performing students using both temporal and sequential analysis methods. We found that high-performing students were likely to pick an elective course of low difficulty. It appeared that these students were more strategic in terms of their course choices than their low-performing peers. Generally, low-performing students seemed to have made suboptimal choices when selecting elective courses; e.g., when they picked an elective course of high difficulty, they were less likely to pick a following course of low difficulty. The findings of this study have design implications for researchers, program directors, and coordinators, because they can use the results to (i) update the course sequencing, (ii) guide students about course choices based on their current GPA (such as through course recommendation dashboards), (iii) identify bottleneck courses, and (iv) assist higher education institutions in planning a more balanced course roadmap to help students manage their workload effectively. • Analyzing students’ choice of courses is a complex and challenging task. It is important that students be offered some assistance in course selection that can help them with their decision-making processes. • Our study provides empirical evidence about the value of analytics that can be used for supporting program-level decision-making in higher education.• The results can augment and support the roles of academic advisors and instructors and lead to students’ success as well as institutional productivity. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {course choices; course difficult; Curriculum analytics; learning analytics},
	correspondence_address = {N. Srivastava; Centre for Learning Analytics, Monash University, Clayton, 3168, Australia; email: namrata.srivastava@monash.edu; S. Nawaz; Centre for Learning Analytics, Monash University, Clayton, 3168, Australia; email: sadia.nawaz@monash.edu},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Roski2024,
	author = {Roski, Marvin and Sebastian, Ratan and Ewerth, Ralph and Hoppe, Anett and Nehring, Andreas},
	title = {Learning analytics and the Universal Design for Learning (UDL): A clustering approach},
	year = {2024},
	journal = {Computers and Education},
	volume = {214},
	doi = {10.1016/j.compedu.2024.105028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186653675&doi=10.1016%2fj.compedu.2024.105028&partnerID=40&md5=d0c271da54624059372a6f8e5c626720},
	affiliations = {Leibniz University Hannover, Am Kleinen Felde 30, Lower Saxony, Hannover, 30167, Germany; TIB – Leibniz Information Centre for Science and Technology, Lange Laube 28, Lower Saxony, Hannover, 30159, Germany; L3S Research Center, Appelstr. 9a, Lower Saxony, Hannover, 30167, Germany},
	abstract = {In the context of inclusive education, Universal Design for Learning (UDL) is a framework used worldwide to create learning opportunities accessible to all learners. While much research focused on the design and students' perceptions of UDL-based learning settings, studies on students’ usage patterns in UDL-guided elements, particularly in digital environments, are still scarce. Therefore, we analyze and cluster the usage patterns of 9th and 10th graders in a web-based learning platform called I3Learn. The platform focuses on chemistry learning, and UDL principles guide its design. We collected the temporal usage patterns of UDL-guided elements of 384 learners in detailed log files. The collected data includes the time spent using video and/or text as a source of information, working on learning tasks with or without help and working on self-assessments. We used Exploratory Factor Analysis (EFA) to identify relevant factors in the observed usage behaviors. Based on the factor loadings, we extracted features for k-means clustering and named the resulting groups based on their usage patterns and learner characteristics. The EFA revealed four factors suggesting that learners remain consistent in selecting UDL-guided elements that require a decision (video or text, tasks with or without help). Based on these four factors, the cluster analysis identifies six different groups. We discuss these results as a starting point to provide individualized learning support through further artificial intelligence applications and inform educators about learner activity through a dashboard. © 2024 The Authors},
	author_keywords = {Clustering; Education inclusive education; Web-based learning science},
	keywords = {Cluster analysis; Computer aided instruction; Design; E-learning; K-means clustering; Students; Websites; Clustering approach; Clusterings; Education inclusive education; Factors analysis; Inclusive education; Learning science; Universal Design; Usage patterns; Web-based learning science; Web-based-learning; Factor analysis},
	correspondence_address = {M. Roski; Leibniz University Hannover, Institute of Science Education, Hannover, Am Kleinen Felde 30, Lower Saxony, 30167, Germany; email: roski@idn.uni-hannover.de},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Khelifi202483,
	author = {Khelifi, Tesnim and Le Grand, Bénédicte and Ben Rabah, Nourhène},
	title = {Explainable Learning Analytics Dashboard: Enhancing Understanding of Insights derived from Educational Data},
	year = {2024},
	journal = {International Journal of Computers and their Applications},
	volume = {31},
	number = {2},
	pages = {83 – 94},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202035456&partnerID=40&md5=5262e8f55c1b2d01fa8b8f2d461b4394},
	affiliations = {Universite Paris 1 Pantheon Sorbonne, 90 rue de Tolbiac, Paris, France},
	abstract = {The integration of Learning Analytics into educational environments can improve the learning process. However, to be used effectively, these tools need to be both explainable and comprehensible. This article introduces a novel dashboard known as the Explainable Learning Analytics Dashboard (EX-LAD), designed to present learning analytics data relating to student performance, engagement, and perseverance in a clear and accessible way. The main aim of this study is to make this information easily understandable for both teachers and students, even for those without in-depth knowledge of data analysis. The EX-LAD primarily empowers students to self-assess by tracking their progress. This enables them to better target their weaknesses and try to remedy them quickly and effectively, thus avoiding any risk of failure. Teachers, meanwhile, can identify students’ specific needs, and detect any learning difficulties. By emphasizing explicability, we aim to boost user confidence in the analyses generated by the system and encourage their engagement in the process of continuous improvement of the educational experience. To showcase the effectiveness of our dashboard, we conducted a case study using real data collected from ESIEE-IT, an engineering school in France, during the 2021-2022 academic year. © 2024 ISCA.},
	author_keywords = {Dash-board; Explainable Learning Analytics; Higher Education},
	publisher = {International Society for Computers and Their Applications},
	issn = {10765204},
	language = {English},
	abbrev_source_title = {Int. J. Comp. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Karimov20254757,
	author = {Karimov, Ayaz and Saarela, Mirka and Aliyev, Samir and Baker, Ryan S.},
	title = {Ethical Considerations and Student Perceptions of Engagement Data in Learning Analytics},
	year = {2025},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	pages = {4757 – 4766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005139643&partnerID=40&md5=7a07a71241a15571aeca5a2986f2fc6c},
	affiliations = {University of Jyväskylä, Finland; University of Pennsylvania, United States},
	abstract = {The ethical use of engagement data in online education is a growing concern as institutions increasingly rely on learning analytics. This study explores students' perceptions of engagement data collection and usage by focusing on their attitudes towards privacy and data management. We conducted a survey among students (n=108) who participated in online education to understand their views on data collection practices, privacy concerns, and preferences for data handling. The results demonstrate that while many students are comfortable with their engagement data being used for personal and instructor dashboards, significant concerns remain about privacy, particularly with the collection of facial expressions and chat participation data. Students emphasized the importance of transparency and control over their data and they highlighted the need for clear communication and consent processes. These findings illustrate the necessity for ethical data practices that ensure students feel secure and informed about how their engagement data is utilized. © 2025 IEEE Computer Society. All rights reserved.},
	author_keywords = {data ethics; engagement data; ethical concerns; online education; student engagement},
	keywords = {Access control; Data acquisition; Data Analytics; Data collection; Data privacy; Data reduction; Electronic data interchange; Ethical technology; Sorting; Teaching; Data collection; Data ethic; Data usage; Engagement data; Ethical concerns; Ethical considerations; On-line education; Privacy preferences; Student engagement; Student perceptions; Students},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813318-8},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kotorov202421,
	author = {Kotorov, Iouri and Krasylnykova, Yuliya and Pérez-Sanagustín, Mar and Mansilla, Fernanda and Broisin, Julien},
	title = {Supporting Decision-Making for Promoting Teaching and Learning Innovation: A Multiple Case Study},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {1},
	pages = {21 – 36},
	doi = {10.18608/jla.2024.8131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188282311&doi=10.18608%2fjla.2024.8131&partnerID=40&md5=d650957e07bad81882f515b6212094d4},
	affiliations = {Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, Cr Rose Dieng-Kuntz, Toulouse, 31400, France; Department of International Business, Karelia University of Applied Sciences, Karjalankatu 3, Joensuu, 80200, Finland; Computer Science Department, Pontificia Universidad Católica de Chile, Av. Vicuña Mackenna 4860, Región Metropolitana, Santiago, Chile},
	abstract = {The quality of the data and the amount of correct information available is key to informed decision-making. Higher education institutions (HEIs) often employ various decision support systems (DSSs) to make better choices. However, there is a lack of systems to assist with decision-making to promote innovation in teaching and learning. In this study, we evaluate an analytic tool called PROF-XXI that supports strategic decision-making of teaching and learning centres (TLCs) by identifying their competencies in teaching and learning innovation. Through a multiple case study conducted with three Latin American universities and supported by quantitative and qualitative data, we observed how this tool is used and how it facilitates strategic decision-making. Our findings indicate that the tool is accessible, user-friendly, and effective in 1) initiating identification and systematic reflection of institutional competency levels in teaching and learning innovation, 2) enhancing understanding of strengths and weaknesses as well as identifying opportunities for innovation, 3) supporting TLCs with short-and long-term decision-making, and 4) continuously evaluating their strategies, programs, and initiatives. This research can benefit policymakers in higher education who are involved in measuring institutional competencies to improve teaching quality or in making strategic decisions related to teaching and learning innovation. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {analytics tools; dashboards; data-driven decisions; Decision-making in higher education; learning analytics; teaching and learning centres},
	correspondence_address = {I. Kotorov; Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, Toulouse, Cr Rose Dieng-Kuntz, 31400, France; email: iouri.kotorov@karelia.fi},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{de Vreugd2025,
	author = {de Vreugd, Lars and van Leeuwen, Anouschka and van der Schaaf, Marieke},
	title = {Students' Use of a Learning Analytics Dashboard and Influence of Reference Frames: Goal Setting, Motivation, and Performance},
	year = {2025},
	journal = {Journal of Computer Assisted Learning},
	volume = {41},
	number = {2},
	doi = {10.1111/jcal.70015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000377073&doi=10.1111%2fjcal.70015&partnerID=40&md5=d4a566449e872d2b6dc2f599e78d4585},
	affiliations = {Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Utrecht, Netherlands; Department of Education, Utrecht University, Utrecht, Netherlands},
	abstract = {Background: University students need to self-regulate but are sometimes incapable of doing so. Learning Analytics Dashboards (LADs) can support students' appraisal of study behaviour, from which goals can be set and performed. However, it is unclear how goal-setting and self-motivation within self-regulated learning elicits behaviour when using an LAD. Objectives: This study's purpose is exploring reference frames’ influence on goal setting, LAD elements’ influence on student motivation, and the predictive value of goal setting and motivation on behaviour, adding to our understanding of the factors predicting task attainment and the role of reference frames. Methods: In an experimental survey design, university students (n = 88) used an LAD with a peer reference frame (Condition 1) or without one (Condition 2), set a goal, determined goal difficulty, self-assessed motivation and LAD elements' influence on motivation. Researchers coded goal specificity. Four weeks later, students self-assessed task attainment, task satisfaction, time on task, and task frequency. T-tests and MANOVA explored effects of the reference frame. Regression analyses determined predictive potential of goal difficulty, goal specificity, and motivation on goal attainment. Results and Conclusions: Results showed no difference between conditions on goal specificity, difficulty, or motivation. The peer reference frame's perceived influence on motivation was small. LAD elements’ influence on motivation varied but were mainly positive. Regression models were not predictive, except the task satisfaction exploratory model. Most participants (77%) attained their goals. Reference frame integration should be carefully considered, given potential negative effects. Students may require educators’ support when setting goals, but the support should balance students’ autonomy. © 2025 The Author(s). Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	correspondence_address = {L. de Vreugd; Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Utrecht, Netherlands; email: l.b.devreugd-2@umcutrecht.nl},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Wang2024915,
	author = {Wang, Chao and Hu, Xiao and Hernández López, Nora Patricia and Ng, Jeremy Tzi Dong},
	title = {Needs Analysis of Learning Analytics Dashboard for College Teacher Online Professional Learning in an International Training Initiative for the Global South},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {915 – 921},
	doi = {10.1145/3636555.3636932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187557333&doi=10.1145%2f3636555.3636932&partnerID=40&md5=ff1dfa9f8241f99b2b292ec8ef3423cb},
	affiliations = {The University of Hong Kong, Southern University of Science and Technology, Hong Kong; Faculty of Education, The University of Hong Kong, Hong Kong},
	abstract = {Online courses enable wide access to educational resources and thus provide a feasible platform for cross-regional teacher professional learning. Learning analytics dashboards (LAD) can support online learners by providing fine-grained feedback generated from learners' interactions with platforms. Nevertheless, most studies on teacher online professional learning focus on resource-rich and technology-advanced regions, with scarce attention to the Global South. Furthermore, existing studies on LAD design mainly target students' learning, rather than teachers' professional learning. Therefore, it is much needed to develop LAD for teacher-learners online professional learning in the Global South. Contextualized in an international online professional training initiative, this study conducted in-depth interviews with 42 teacher-learners from 19 countries in the Global South, aiming to identify their needs for 1) support on their self-regulated learning (SRL), and 2) potential LA components in dashboards. Findings indicated that teacher-learners needed support for self-regulated learning strategies, including motivation maintenance, time management, environment structuring, help-seeking, and self-evaluation. Nine LA features were identified to design the LADs to support SRL preliminarily. This co-designed LAD study with interviewees improved our understanding on the needs of college teachers in the Global South for LA support during their online professional learning, generating practical insights into needs-driven LAD designs. © 2024 ACM.},
	keywords = {Learning systems; Personnel training; Professional aspects; College teachers; Educational resource; Fine grained; International training; Learner interaction; Need analysis; Online course; Professional learning; Self-regulated learning; Teachers'; E-learning},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bayer20242058,
	author = {Bayer, Vaclav and Mulholland, Paul and Hlosta, Martin and Farrell, Tracie and Herodotou, Christothea and Fernandez, Miriam},
	title = {Co-creating an equality diversity and inclusion learning analytics dashboard for addressing awarding gaps in higher education},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {5},
	pages = {2058 – 2074},
	doi = {10.1111/bjet.13509},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198503108&doi=10.1111%2fbjet.13509&partnerID=40&md5=702c3997e2c029eb960bde57e129fe7c},
	affiliations = {The Open University, Milton Keynes, United Kingdom; Swiss Distance University of Applied Sciences, Brig, Switzerland},
	abstract = {Educational outcomes from traditionally underrepresented groups are generally worse than for their more advantaged peers. This problem is typically known as the awarding gap (we use the term awarding gap over ‘attainment gap’ as attainment places the responsibility on students to attain at equal levels) and continues to pose a challenge for educational systems across the world. While Learning Analytics (LA) dashboards help identify patterns contributing to the awarding gap, they often lack stakeholder involvement, offering very little support to institutional Equality, Diversity and Inclusion (EDI) leads or educators to pinpoint and address these gaps. This paper introduces an innovative EDI LA dashboard, co-created with diverse stakeholders. Rigorously evaluated, the dashboard provides fine-grained insights and course-level analysis, empowering institutions to effectively address awarding gaps and contribute to a diverse and inclusive higher education landscape. Practitioners notes What is already known about this topic Traditionally underrepresented groups face educational disparities, commonly known as the awarding gap. Underachievement is a complex multi-dimensional problem and cannot be solely attributable to individual student deficiencies. LA dashboards targeting this specific problem are often not public, there is little research about them, and are frequently designed with little involvement of educational stakeholders. What this paper adds Pioneers the introduction of a dashboard specifically designed to address the awarding gap problem. Emphasises the significant data needs of educational stakeholders in tackling awarding gaps. Expands the design dimensions of Learning Analytics (LA) by introducing a specific design approach rooted in established user experience (UX) design methods. Implications for practice and/or policy Insights from this study will guide practitioners, designers, and developers in creating AI-based educational systems to effectively target the awarding gap problem. © 2024 The Author(s). British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
	author_keywords = {awarding gaps; co-creation; dashboard design; educational inequality; higher education},
	keywords = {Students; Awarding gap; Co-creation; Dashboard design; Educational inequality; Educational systems; Fine grained; High educations; Multidimensional problems; Stakeholder involvement; Under-represented groups; Design},
	correspondence_address = {V. Bayer; The Open University, Milton Keynes, United Kingdom; email: vaclav.bayer@open.ac.uk},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Yan2025,
	author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Jin, Yueqiao and Echeverria, Vanessa and Milesi, Mikaela and Fan, Jie and Zhao, Linxuan and Alfredo, Riordan and Li, Xinyu and Gašević, Dragan},
	title = {The effects of generative AI agents and scaffolding on enhancing students’ comprehension of visual learning analytics},
	year = {2025},
	journal = {Computers and Education},
	volume = {234},
	doi = {10.1016/j.compedu.2025.105322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003712612&doi=10.1016%2fj.compedu.2025.105322&partnerID=40&md5=398abd52c07854e4115f3f06034e1f79},
	affiliations = {Centre for Learning Analytics at Monash, Faculty of Information Technology, Monash University, Clayton, Victoria, 3168, Australia; Escuela Superior Politécnica del Litoral, Guayaquil, Ecuador},
	abstract = {Visual learning analytics (VLA) is becoming increasingly adopted in educational technologies and learning analytics dashboards to convey critical insights to students and educators. Yet many students experienced difficulties in comprehending complex VLA due to their limited data visualisation literacy. While conventional scaffolding approaches like data storytelling have shown effectiveness in enhancing students’ comprehension of VLA, these approaches remain difficult to scale and adapt to individual learning needs. Generative AI (GenAI) technologies, especially conversational agents, offer potential solutions by providing personalised and dynamic support to enhance students’ comprehension of VLA. This controlled lab study investigates the effectiveness of GenAI agents, particularly when integrated with scaffolding techniques, in improving students’ comprehension of VLA. A randomised controlled trial was conducted with 117 higher education students to compare the effects of two types of GenAI agents: passive agents, which respond to student queries, and proactive agents, which utilise scaffolding questions, against standalone scaffolding in a VLA comprehension task. The results show that passive agents yield comparable improvements to standalone scaffolding both during and after the intervention. Notably, proactive GenAI agents significantly enhance students’ VLA comprehension compared to both passive agents and standalone scaffolding, with these benefits persisting beyond the intervention. These findings suggest that integrating GenAI agents with scaffolding can have lasting positive effects on students’ comprehension skills and support genuine learning. © 2025 The Authors},
	author_keywords = {Artificial intelligence; Generative AI; Large language model; Learning analytics dashboard; Scaffolding; Visual learning analytics; Visualisation literacy},
	keywords = {Data visualization; Educational robots; Scaffolds; Video analysis; Visualization; Generative AI; Individual learning; Language model; Large language model; Learning analytic dashboard; Limited data; Scaffolding; Visual learning; Visual learning analytic; Visualization literacy; Students},
	correspondence_address = {L. Yan; Victoria, 25 Exhibition Walk, Clayton, 3168, Australia; email: Lixiang.Yan@monash.edu},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Valle2025,
	author = {Valle, Natercia and Antonenko, Pavlo and Valle, Denis and Baiser, Benjamin},
	title = {Task-value motivational prompts in a descriptive dashboard can increase anxiety among anxious learners},
	year = {2025},
	journal = {Computers and Education},
	volume = {229},
	doi = {10.1016/j.compedu.2025.105242},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216219807&doi=10.1016%2fj.compedu.2025.105242&partnerID=40&md5=bd323d5c70ab6139756052c7ce4fad0d},
	affiliations = {Assistant University Librarian (STEM Instruction Librarian) at Marston Science Library (George A. Smathers Libraries) at the University of Florida, 444 Newell Drive/, PO Box 117011, Gainesville, 32611-7011, FL, United States; Educational Technology in the School of Teaching and Learning, College of Education, University of Florida, Gainesville, FL, United States; School of Forest, Fisheries, and Geomatics Sciences, University of Florida, Gainesville, FL, United States; Department of Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, United States},
	abstract = {Despite the ubiquitous use of learning analytics dashboards in computer-mediated learning environments, there is still a knowledge gap on how these tools can support learners’ academic performance and motivation. This article describes an experimental study that investigated the influence of motivational prompts (task-value scaffolding) in a descriptive learning analytics dashboard on learners’ motivation, statistics anxiety, and learning performance in an authentic semester-long online statistics course. The study was based on a two-group experimental design during two semesters (Fall 2020 and Spring 2021). A total of 122 graduate students completed the study. The results showed that despite learners’ mostly positive perceptions of the dashboard, the use of motivational prompts did not influence learners’ cognitive outcomes. Test anxiety was the only affective outcome influenced by the intervention, with motivational prompts having a negative effect on learners who started the course with a higher level of test anxiety. This study provides needed empirical evidence on how the design of these tools can influence learners’ affective outcomes, with implications for theory and practice. However, additional experimental studies that account for sources of heterogeneity (e.g., intrapersonal characteristics, contextual factors) are necessary to uncover theoretical gaps and opportunities in the design of effective learning analytics dashboards. © 2025 Elsevier Ltd},
	author_keywords = {Data science applications in education; Distance education and online learning; Human-computer interface; Pedagogical issues; Post-secondary education},
	keywords = {Adversarial machine learning; Federated learning; Application in education; Computer-mediated learning environments; Data science application in education; Distance education and online learning; Human computer interfaces; Knowledge gaps; Online learning; Pedagogical issues; Postsecondary education; Science applications; Contrastive Learning},
	correspondence_address = {N. Valle; Gainesville, 444 Newell Drive/ PO Box 117011, 32611-7011, United States; email: nvalle@ufl.edu},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Şahin20241869,
	author = {Şahin, Muhittin},
	title = {Advances in Video Analytics},
	year = {2024},
	journal = {Technology, Knowledge and Learning},
	volume = {29},
	number = {4},
	pages = {1869 – 1875},
	doi = {10.1007/s10758-024-09768-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200376338&doi=10.1007%2fs10758-024-09768-9&partnerID=40&md5=a1f0c82dab3a1c6ed9c8172f1636f5fb},
	affiliations = {University of Mannheim, Mannheim, Germany},
	abstract = {Learners interact with content, assessments, peers, and instructors in digital learning environments. Videos, which are popular due to internet technologies, capture learners’ attention, boost motivation, and enhance learning. Learning analytics broadly optimize educational environments by analyzing data, with video analytics focusing specifically on video interactions to enhance learning outcomes. Video-player interactions (e.g., play, pause) and video content interactions (e.g., true-false questions) provide insights into learner behaviors. Lack of interaction is a major reason for high dropout rates in video platforms and MOOCs. Video analytics can help address this issue by analyzing and improving engagement with video content. This special issue has a specific focus on video analytics and impact of this field to the learning experience. Four articles were included in this special issue. The findings reveal that I) the type, length, and purpose of the video are important for student engagement, ii) important tips on video-based learning design are presented, iii) when interacting with the video player, pause, play, rewind and fast forward are the most commonly used interaction types., iv) providing more information about video interaction processes with dashboards would provide much more insight, and v) dividing the videos into more than one section both creates the perception of better structuring of the process and the segmentation of the videos contributes more to learning. © The Author(s) 2024.},
	author_keywords = {Learning analytics; Learning experience; Video analytics; Video interaction; Video player interaction},
	correspondence_address = {M. Şahin; University of Mannheim, Mannheim, Germany; email: sahinmuhittin@gmail.com},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Wang2025824,
	author = {Wang, Zuo and Lin, Weiyue and Hu, Xiao},
	title = {Self-service Teacher-facing Learning Analytics Dashboard with Large Language Models},
	year = {2025},
	journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
	pages = {824 – 830},
	doi = {10.1145/3706468.3706491},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000279706&doi=10.1145%2f3706468.3706491&partnerID=40&md5=4e80f0de1f6bbeba7c21911e15f5eb4d},
	affiliations = {The University of Hong Kong, Hong Kong, Hong Kong; The University of Arizona, Tucson, United States},
	abstract = {With the rise of online learning platforms, the need for effective learning analytics (LA) has become critical for teachers. However, the development of traditional LA dashboards often requires technical expertise and a certain level of data literacy, preventing many teachers from integrating LA dashboards effectively and flexibly into their teaching practice. This paper explores the development of a self-service teacher-facing learning analytics dashboard powered by large language models (LLMs), for improving teaching practices. By leveraging LLMs, the self-service system aims to simplify the implementation of data queries and visualizations, allowing teachers to create personalized LA dashboards using natural languages. This study also investigates the capabilities of LLMs in generating charts for LA dashboards and evaluates the effectiveness of the self-service system through usability tests with 15 teachers. Preliminary findings suggest that LLMs demonstrate high capabilities in generating charts for LA dashboards, and the LLM-powered self-service system can effectively address participating teachers' pedagogical needs for LA. This research contributes to the ongoing research on the intersection of LLMs and education, emphasizing the potential of self-service systems to empower teachers in daily teaching practices. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {data visualization; large language models; learning analytics dashboard; self-service learning analytics},
	keywords = {Network security; Query languages; Teaching; Visual languages; Language model; Large language model; Learning analytic dashboard; Learning platform; Online learning; Self-service learning analytic; Self-service systems; Service learning; Teachers'; Teaching practices; Data Analytics},
	correspondence_address = {X. Hu; The University of Arizona, Tucson, United States; email: xiaohu@arizona.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070701-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Anal. Knowl., LAK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Demartini2024,
	author = {Demartini, Claudio Giovanni and Sciascia, Luciano and Bosso, Andrea and Manuri, Federico},
	title = {Artificial Intelligence Bringing Improvements to Adaptive Learning in Education: A Case Study},
	year = {2024},
	journal = {Sustainability (Switzerland)},
	volume = {16},
	number = {3},
	doi = {10.3390/su16031347},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184468234&doi=10.3390%2fsu16031347&partnerID=40&md5=a9f66dc88330d73b76b1f6327aea0fb9},
	affiliations = {Department of Control and Computer Engineering, Politecnico di Torino, Corso Duca Degli Abruzzi, 24, Torino, 10129, Italy; Fondazione per la Scuola della Compagnia di San Paolo, Piazza Bernini, 5, Torino, 10138, Italy; Links Foundation, Via Pier Carlo Boggio, 61, Torino, 10138, Italy},
	abstract = {Despite promising outcomes in higher education, the widespread adoption of learning analytics remains elusive in various educational settings, with primary and secondary schools displaying considerable reluctance to embrace these tools. This hesitancy poses a significant obstacle, particularly given the prevalence of educational technology and the abundance of data generated in these environments. In contrast to higher education institutions that readily integrate learning analytics tools into their educational governance, high schools often harbor skepticism regarding the tools’ impact and returns. To overcome these challenges, this work aims to harness learning analytics to address critical areas, such as school dropout rates, the need to foster student collaboration, improving argumentation and writing skills, and the need to enhance computational thinking across all age groups. The goal is to empower teachers and decision makers with learning analytics tools that will equip them to identify learners in vulnerable or exceptional situations, enabling educational authorities to take suitable actions that are aligned with students’ needs; this could potentially involve adapting learning processes and organizational structures to meet the needs of students. This work also seeks to evaluate the impact of such analytics tools on education within a multi-dimensional and scalable domain, ranging from individual learners to teachers and principals, and extending to broader governing bodies. The primary objective is articulated through the development of a user-friendly AI-based dashboard for learning. This prototype aims to provide robust support for teachers and principals who are dedicated to enhancing the education they provide within the intricate and multifaceted social domain of the school. © 2024 by the authors.},
	author_keywords = {adaptive learning; artificial intelligence; dashboard; education; learning analytics; machine learning},
	keywords = {adaptive management; artificial intelligence; governance approach; higher education; learning; machine learning; student},
	correspondence_address = {C.G. Demartini; Department of Control and Computer Engineering, Politecnico di Torino, Torino, Corso Duca Degli Abruzzi, 24, 10129, Italy; email: claudio.demartini@polito.it},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access}
}

@ARTICLE{Campos2024769,
	author = {Campos, Fabio and Nguyen, Ha and Ahn, June and Jackson, Kara},
	title = {Leveraging cultural forms in human-centred learning analytics design},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {3},
	pages = {769 – 784},
	doi = {10.1111/bjet.13384},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170574946&doi=10.1111%2fbjet.13384&partnerID=40&md5=5855e4a8cfb39c7088e68330558a7547},
	affiliations = {Steinhardt School of Culture, Education, and Human Development Administration, Leadership and Technology, NY, United States; Utah State University College of Education, Instructional Technology & Learning Sciences, Logan, United States; University of California-Irvine, School of Education, Irvine, United States; Teaching, Learning, and Curriculum Department, University of Washington, College of Education, Seattle, United States},
	abstract = {In this article, we offer theory-grounded narratives of a 4-year participatory design process of a Learning Analytics tool with K-12 educators. We describe how we design-in-partnership by leveraging educators' routines, values and cultural representations into the designs of digital dashboards. We make our long-term reasoning visible by reflecting upon how design decisions were made, discussing key tensions and analysing to what extent the developed tools were taken up in practice. Through thick design narratives, we reflect upon how cultural forms—recognizable cultural constructs that might cue and facilitate specific activities—were identified among educators and informed the design of a dashboard. We then examined the extent to which the designed tool supported coaches and teachers to engage in Generative Uncertainty, an interpretive stance in which educators manifest productive inquiries towards data. Our analysis highlights that attuning to cultural forms is a valuable first step but not enough towards designing LA tools for systems in ways that fit institutionalized practices, challenge instrumental uses and spur productive inquiry. We conclude by offering two key criteria for making culturally-grounded design decisions in the context of long-term partnerships. Practitioner notes What is already known about this topic Participatory design can invite stakeholders to directly inform the creation of LA artefacts that fit their needs, context and cultural markers. What this paper adds Cultural forms can be identified and leveraged in the design of LA tools. HCLA scholars ought to design for systems—the complex body of organizational routines, cultural practices and interactions among multiple stakeholders—and not just for users. Implications for practice and/or policy Leveraging cultural forms in LA needs to be accompanied by a critical view of which practices, behaviours, values and structures are suggested by such forms. Designing features that are easy to use, are associated with concrete tasks, and fit into existing cultural practices are three criteria for embedding cultural forms into LA design. © 2023 British Educational Research Association.},
	author_keywords = {cultural forms; learning analytics; participatory design; research-practice partnerships},
	keywords = {Analytic design; Analytic tools; Cultural form; Cultural practices; Design decisions; Design-process; K-12 educators; Learning analytic; Participatory design; Research-practice partnership; Design},
	correspondence_address = {F. Campos; New York University, Brooklyn, 370 Jay St, 5th Floor, 11201, United States; email: fabioc@nyu.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Tlili2025995,
	author = {Tlili, Ahmed and Chikhi, Salim},
	title = {Computer science and educational games to enhancing students’ Islamic content learning},
	year = {2025},
	journal = {International Journal of Evaluation and Research in Education},
	volume = {14},
	number = {2},
	pages = {995 – 1003},
	doi = {10.11591/ijere.v14i2.29459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219660437&doi=10.11591%2fijere.v14i2.29459&partnerID=40&md5=2fbd40c41d0f97c34c20f9c07828aefa},
	affiliations = {Department of Communication, Religion Foundation Faculty, Emir Abd ElKader University of Islamic Sciences, Constantine, Algeria; MISC Laboratory, New Technology and Communication Faculty, Abdelhamid Mahri University, Constantine, Algeria},
	abstract = {Learning in all humanities content branch such as Islamic sciences is declared to be boring, tiring and very dry plain content because the educational level of learners becomes low and worrying. This statement is justified by the result of our statistical study which reveals that learning of Islamic content is not attractive and needs to be revolutionized in order to make it more attractive and interesting for the new generation called digital generation. In this paper, we have used the gamification concept with learning analytics (LA) approach to design an educational game to improve Islamic content learning. However, and due to the lake of works and the knowledge about teaching Islamic contents using education games look insufficient and at their begins. The obtained results, in this study, with proposed approach, shows that the students had remarkably higher motivation and performance to learn than before. The main objective of this investigation is, firstly, allows managers and teachers easily incorporate LA approaches to help student improves their learning; and secondly, future work benefits from these results to define an appropriate dashboard for the Islamic content learning and teaching. © 2025, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Computer sciences; Dashboard teaching; Educational games; Islamic contents; Learning analytics},
	correspondence_address = {A. Tlili; Department of Communication, Religion Foundation Faculty, Emir Abd ElKader University of Islamic Sciences, Constantine, Algeria; email: a.tlili@univ-emir.dz},
	publisher = {Institute of Advanced Engineering and Science},
	issn = {22528822},
	language = {English},
	abbrev_source_title = {Int. J. Eval. Res. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Alowayr2025297,
	author = {Alowayr, Ali},
	title = {LEARNING ANALYTICS SYSTEMS TO IMPROVE THE QUALITY OF STUDENTS’ OUTCOMES},
	year = {2025},
	journal = {International Journal for Quality Research},
	volume = {19},
	number = {1},
	pages = {297 – 312},
	doi = {10.24874/IJQR19.01-19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217919414&doi=10.24874%2fIJQR19.01-19&partnerID=40&md5=c0e825470818854121d04d81a42dd5db},
	affiliations = {Technology; Faculty of Computing and Information; Albaha University; Saudi Arabia, Saudi Arabia},
	abstract = {Learning analytics (LA) is a rapidly growing area of research that focuses on using data from learning technologies to improve the quality of students’ outcomes. This paper aims to provide a comprehensive understanding of the current state of research on learning analytics technologies and how they can positively impact student outcomes. To achieve this, a systematic review using a PRISMA methodology was conducted. Inclusion and exclusion criteria were applied to select relevant papers, resulting in a final set of 31 papers for analysis. The identified papers were then organised and analysed. The findings show that the use of learning analytics has many benefits for both learners and instructors. However, its adoption by higher educational institutions has been slow and limited due to a lack of resources, funding, and skills. Four systematic reviews on the topic have been conducted, but they do not reveal any significant changes in the status of research and practice over the years. The analysed papers highlight the use of learning analytics for predicting student learning behaviours and identifying at-risk students who may benefit from targeted interventions. These interventions have been shown to improve students’ academic performance and retention rates. Furthermore, learning analytics has also been used for technology enhanced learning and to improve overall academic outcomes for students. Moving forward, it is crucial to focus on overcoming the barriers to adoption that hinder the widespread use of learning analytics in higher education. Additionally, exploring alternative options beyond the traditional dashboard-based approach could offer new insights and improve the overall effectiveness of learning analytics systems. This research has implications for universities, learning staff and students. © (2025), (Centar for Quality). All rights reserved.},
	author_keywords = {Learning analytics; Moodle Learning Management System; online learning; student outcomes; student performance; technology enhanced learning},
	correspondence_address = {A. Alowayr; Technology; Faculty of Computing and Information; Albaha University; Saudi Arabia, Saudi Arabia; email: aalowayr@bu.edu.sa},
	publisher = {Centar for Quality},
	issn = {18006450},
	language = {English},
	abbrev_source_title = {Int. J. Qual. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Fernandez-Nieto2024678,
	author = {Fernandez-Nieto, Gloria Milena and Martinez-Maldonado, Roberto and Echeverria, Vanessa and Kitto, Kirsty and Gašević, Dragan and Buckingham Shum, Simon},
	title = {Data Storytelling Editor: A Teacher-Centred Tool for Customising Learning Analytics Dashboard Narratives},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {678 – 689},
	doi = {10.1145/3636555.3636930},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180801572&doi=10.1145%2f3636555.3636930&partnerID=40&md5=fefa0d4432282e8de4a6352e64495d6c},
	affiliations = {Monash University, Melbourne, VIC, Australia; Escuela Superior Politécnica Del Litoral, Guayaquil, Ecuador; University of Technology Sydney, Sydney, NSW, Australia},
	abstract = {Dashboards are increasingly used in education to provide teachers and students with insights into learning. Yet, existing dashboards are often criticised for their failure to provide the contextual information or explanations necessary to help students interpret these data. Data Storytelling (DS) is emerging as an alternative way to communicate insights providing guidance and context to facilitate students' interpretations. However, while data stories have proven effective in prompting students' reflections, to date, it has been necessary for researchers to craft the stories rather than enabling teachers to do this by themselves. This can make this approach more feasible and scalable while also respecting teachers' agency. Based on the notion of DS, this paper presents a DS editor for teachers. A study was conducted in two universities to examine whether the editor could enable teachers to create stories adapted to their learning designs. Results showed that teachers appreciated how the tool enabled them to contextualise automated feedback to their teaching needs, generating data stories to support student reflection. © 2024 ACM.},
	author_keywords = {data storytelling; LA Dashboards; teacher-centered tool},
	keywords = {Education computing; Automated feedback; Contextual information; Contextualize; Data storytelling; LA dashboard; Learning designs; Teacher-centered tool; Teachers'; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Salmen2024267,
	author = {Salmen, Frederic and Breuer, Martin and Görzen, Sergej and Persike, Malte and Schroeder, Ulrik},
	title = {FAIR Learning Technologies with Web Components and Packages},
	year = {2024},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {P-356},
	pages = {267 – 274},
	doi = {10.18420/delfi2024_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217820989&doi=10.18420%2fdelfi2024_23&partnerID=40&md5=25d30afa12023ac012115061c7c8d736},
	affiliations = {RWTH Aachen University, Aachen, Germany},
	abstract = {Making the diverse software artifacts of the learning technologies community findable, accessible, interoperable, and reusable (FAIR) can be a technical challenge. We introduce a concept informed by our research involving packages and components to achieve FAIRness for web-based artifacts. This result is presented as a guideline to make FAIR technology choices when creating web-based learning technologies. The guideline compares classic choices with new paths afforded by technological innovation of the web platform. Supported by practical examples (learning analytics dashboards, e-assessment, and explorables) we discuss practical applications of our result. © 2024 Gesellschaft fur Informatik (GI). All rights reserved.},
	author_keywords = {FAIR principles; Packages; Reusable Software; Web Components},
	keywords = {Computer software reusability; Findable, accessible, interoperable, and reusable principle; Interoperable technologies; Learning technology; Package; Reusable softwares; Reusable technology; Software artefacts; Technical challenges; Web based; Web components; Software packages},
	editor = {Schulz S. and Universitat Hamburg, Mittelweg 177, Hamburg and Kiesler N. and Technische Hochschule Nurnberg Georg Simon Ohm, Kesserplatz 12, Nurnberg},
	publisher = {Gesellschaft fur Informatik (GI)},
	issn = {16175468},
	isbn = {978-388579255-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Informatics (LNI), Proc. - Series Ges. Inform. (GI)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Buseyne20241465,
	author = {Buseyne, Siem and Rajagopal, Kamakshi and Danquigny, Thierry and Depaepe, Fien and Heutte, Jean and Raes, Annelies},
	title = {Assessing verbal interaction of adult learners in computer-supported collaborative problem solving},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {4},
	pages = {1465 – 1485},
	doi = {10.1111/bjet.13391},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173547013&doi=10.1111%2fbjet.13391&partnerID=40&md5=c75a458997d27219b69ccab6f3bde0ab},
	affiliations = {Centre for Instructional Psychology and Technology, Faculty of Psychology and Educational Sciences, KU Leuven, Leuven, Belgium; Itec, imec research group at KU Leuven, Imec, Leuven, Belgium; CIREL, Centre Interuniversitaire de Recherche en Education de Lille (ULR 4354), Villeneuve-d'Ascq, France},
	abstract = {The objective of this study is to explore new ways of assessing collaborative problem solving (CPS) processes based on different modalities of audio data and their combination. The data collection took place in an educational lab setting during an experiment with adult teams from professional contexts who collaboratively solved multiple problems as part of a CPS training. From audio data, both verbal (ie, speech) and non-verbal (ie, pitch) aspects were extracted. Four analysis methods were used, including (a) content analysis; (b) linguistic inquiry and word count; (c) verbal entrainment analysis; and (d) acoustic–prosodic entrainment based on pitch data. Insights are given into the CPS processes of the participating groups using these measures and relevant relationships between some of these measures are further investigated. Based on content analysis, it was found that most of the interactions during the CPS process are task oriented, whereas team-oriented interactions are less present. Second, three measures of proportion of contribution in CPS were investigated and clear differences in participation patterns between and within teams were found. We suggest that a combination of utterance count and words per sentence could provide valuable insights for quantity and equality of participation. Third, the study explored pronoun use and found that the most frequently used personal pronouns were first-person singular. Next, the results indicated a relationship between pronoun use and the relative frequency of interactions. Fourth, a rather weak relationship between lexical entrainment measures and the acoustic–prosodic measures were found, suggesting that these measures are indicative of separate communicative aspects in CPS. This study contributes to a better understanding of which type of audio-based data is most informative to teachers and students as a feedback or assessment tool. This study complements previous research as it focuses on spoken human-to-human communication collected in an authentic context. Practitioner notes What is already known about this topic Support and guidance systems for learning coaches, teachers and learners are needed to foster the educational quality of collaborative problem solving (CPS) activities. CPS is a complex process and measuring the quality of CPS processes remains challenging. Multimodal learning analytics, focusing on verbal and non-verbal data sources and using content analysis, linguistic inquiry and word count and verbal and acoustic entrainment measures could be valuable to measure the quality of CPS. What this paper adds The majority of interactions during CPS processes are task oriented or cognitive of nature, whereas team-oriented interactions are less present. Utterance count and words per sentence should be used in combination, as they are indicative of different aspects. Pronoun use in learners' discourse is related to the types of CPS interactions. Lexical entrainment measures and acoustic–prosodic are indicative of distinctive communicative aspects in CPS. Implications for practice and/or policy Quality indicators of CPS processes should include both verbal and non-verbal measures of students' interactions. Educational researchers and the (Edtech) industry should further leverage their forces to foster the development of (semi-)automated systems for measuring the quality of CPS processes. It should be further investigated how quality indicators of CPS processes can be most meaningful to trainers, teachers and learners, for example, through the use of dashboards. © 2023 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
	author_keywords = {audio data; collaborative problem solving; content analysis; linguistic inquiry; linguistic style matching},
	keywords = {Learning systems; Quality control; Audio data; Collaborative problem solving; Content analysis; Linguistic inquiry; Linguistic style matching; Linguistic styles; Matchings; Problem solving process; Prosodics; Teachers'; Linguistics},
	correspondence_address = {S. Buseyne; Centre for Instructional Psychology and Technology, Faculty of Psychology and Educational Sciences, KU Leuven, Leuven, Belgium; email: siem.buseyne@kuleuven.be},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Anthis202443,
	author = {Anthis, Zach and Zacharioudakis, Lefteris},
	title = {WOLFRAM in Action: Teaching and Learning (Pseudo)Random Generation with Cellular Automata in Higher Education Settings},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3902},
	pages = {43 – 53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216624996&partnerID=40&md5=85ef1cd026dab7ccabd6c05bf4293fff},
	affiliations = {UCL Knowledge Lab., University College London, Gower Street, London, WC1E 6BT, United Kingdom; Department of Computer Science, Neapolis University Pafos, Danaes Avenue, Pafos, 8042, Cyprus; Igor Sikorsky Kyiv Polytechnic Institute, National Technical University of Ukraine, Kyiv, 03056, Ukraine},
	abstract = {This article presents ongoing work on WOLFRAM, an interactive EdTech tool designed to teach random generation by visualizing unidimensional Cellular Automata (CA). The web-based prototype integrates a series of gamified tasks with a Learning Analytics (LA) dashboard, to provide students with hands-on experience in elementary CA mechanics whilst delivering detailed insights to instructors in real time. The backend tracks user progress through key performance metrics, including response times, task accuracy, and engagement levels. Preliminary results from a quasi-experimental study demonstrate substantial learning gains across two distinct cohorts: BSc Computer Science (CS) students in a Cybersecurity module and BSc Artificial Intelligence (AI) students in a Machine Learning module. Both cohorts reported high usability and motivation via quantitative Likert scale assessments, with ANOVA showing no significant differences in these areas. Yet, AI students exhibited notably higher improvements in learning clarity, likely due to stronger curricular alignment with CA concepts. In fact, regression analysis confirmed that being in the AI group significantly predicted greater clarity in general, even after controlling for other factors. Next steps involve the integration of adaptive learning features to dynamically adjust content difficulty based on recorded student performance, alongside additional predictive and prescriptive components to provide for automated feedback (in the form of AI-driven hints) on a need-to basis. Future research will focus on expanding the tool’s scalability across various (adjoining) academic disciplines and investigating its impact on long-term retention of more advanced concepts such as fractal geometry, entropy estimation, algorithmic complexity, pattern formation, or self-organization. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Artificial Intelligence (AI); Cellular Automata (CA); Computer Science (CS); Learning Analytics (LA)},
	keywords = {Adversarial machine learning; Automata theory; Contrastive Learning; Dictating machines; Federated learning; Fractals; Teaching; Artificial intelligence; Cellular automaton; Cellular automatons; Computer science; High educations; Learning analytic; Pseudo-random; Random generation; Teaching and learning; Web-based prototype; Students},
	correspondence_address = {Z. Anthis; UCL Knowledge Lab., University College London, London, Gower Street, WC1E 6BT, United Kingdom; email: qtnvzan@ucl.ac.uk},
	editor = {Marengo E. and Ponticorvo M. and Striani M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mohseni202491,
	author = {Mohseni, Zeynab Artemis and Masiello, Italo and Martins, Rafael M. and Nordmark, Susanna},
	title = {Visual Learning Analytics for Educational Interventions in Primary and Secondary Schools: A Scoping Review},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {2},
	pages = {91 – 111},
	doi = {10.18608/jla.2024.8309},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202576381&doi=10.18608%2fjla.2024.8309&partnerID=40&md5=8ed220c07ea21fe182936061be6bfeda},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden},
	abstract = {Visual Learning Analytics (VLA) uses analytics to monitor and assess educational data by combining visual and automated analysis to provide educational explanations. Such tools could aid teachers in primary and secondary schools in making pedagogical decisions, however, the evidence of their effectiveness and benefits is still limited. With this scoping review, we provide a comprehensive overview of related research on proposed VLA methods, as well as identifying any gaps in the literature that could assist in describing new and helpful directions to the field. This review searched all relevant articles in five accessible databases — Scopus, Web of Science, ERIC, ACM, and IEEE Xplore — using 40 keywords. These studies were mapped, categorized, and summarized based on their objectives, the collected data, the intervention approaches employed, and the results obtained. The results determined what affordances the VLA tools allowed, what kind of visualizations were used to inform teachers and students, and, more importantly, positive evidence of educational interventions. We conclude that there are moderate-to-clear learning improvements within the limit of the studies’ interventions to support the use of VLA tools. More systematic research is needed to determine whether any learning gains are translated into long-term improvements. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {educational interventions; learning analytics dashboard; primary school; scoping review; secondary school; systematic review; Visual learning analytics},
	correspondence_address = {Z.A. Mohseni; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; email: zeynab.mohseni@lnu.se},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Toyokawa2024495,
	author = {Toyokawa, Yuko and Majumdar, Rwitajit and Kondo, Taisho and Horikoshi, Izumi and Ogata, Hiroaki},
	title = {Active reading dashboard in a learning analytics enhanced language-learning environment: effects on learning behavior and performance},
	year = {2024},
	journal = {Journal of Computers in Education},
	volume = {11},
	number = {2},
	pages = {495 – 522},
	doi = {10.1007/s40692-023-00267-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150697805&doi=10.1007%2fs40692-023-00267-x&partnerID=40&md5=a77ed339817884cd703c01933dfc092c},
	affiliations = {Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto, 606-8501, Japan; Academic Center for Computing and Media Studies, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto, 606-8501, Japan},
	abstract = {Various efforts to scaffold improving reading performance and skills have been investigated, yet there have been no efforts to visualize the active reading (AR) process using logs, verify the effects on learning behavior and performance, and further deepen reading comprehension in a data-driven manner. To this end, an Active Reading Dashboard (AR-D) was specifically designed to visualize students’ reading behavior, such as annotations and artifacts created during AR. The dashboard provides individual feedback, allowing students to reflect on the information from the whole class. Such approaches are difficult when conducting AR with paper-based materials. A quasi-experimental study was conducted in high school English classes to examine the differences in the effects of including AR-D reflections (experimental group: AR-D) and only following the AR process (control group: AR). The results indicated that AR-D promoted participants’ learning behaviors during AR. However, regarding students’ vocabulary acquisition and reading comprehension performance, both groups increased in the post-test without any significant difference from the AR-D group. Our findings suggest that using the dashboard during the English AR activity promoted desired student behaviors in attempting answers in English. The visualized data in AR-D can be a scaffold to decide on the next step toward improvement, which is one of the main objectives of integrating Learning Analytics (LA) in practice. We discuss how the LA dashboard can be used in a learning environment as effective means for learners and teachers. © Beijing Normal University 2023.},
	author_keywords = {Active reading; Active reading dashboard; Learning analytics; Technology-enhanced language learning},
	correspondence_address = {Y. Toyokawa; Graduate School of Informatics, Kyoto University, Kyoto, Yoshida-honmachi, Sakyo-ku, 606-8501, Japan; email: toyokawa.yuko.59t@st.kyoto-u.ac.jp},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21979987},
	language = {English},
	abbrev_source_title = {J. Comp. Edu.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Milesi2024167,
	author = {Milesi, Mikaela Elizabeth and Martinez-Maldonado, Roberto},
	title = {Data Storytelling in Learning Analytics? A Qualitative Investigation into Educators' Perceptions of Benefits and Risks},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {167 – 177},
	doi = {10.1145/3636555.3636865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187551685&doi=10.1145%2f3636555.3636865&partnerID=40&md5=e51683d651767140de69a1dbd6995388},
	affiliations = {Monash University, Australia},
	abstract = {Emerging research has begun to explore the incorporation of data storytelling (DS) elements to enhance the design of learning analytics (LA) dashboards. This involves using visual features, such as text annotations and visual highlights, to help educators and learners focus their attention on key insights derived from data and act upon them. Previous studies have often overlooked the perspectives of educators and other stakeholders on the potential value and risks associated with implementing DS in LA to guide attention. We address this gap by presenting a case study examining how educators perceive the: i) potential value of DS features for teaching and learning design; ii) role of the visualisation designer in delivering a contextually appropriate data story; and iii) ethical implications of utilising DS to communicate insights. We asked educators from a first-year undergraduate program to explore and discuss DS and the visualisation designer by reviewing sample data stories using their students' data and crafting their own data stories. Our findings suggest that educators were receptive to DS features, especially meaningful use of annotations and highlighting important data points to easily identify critical information. Every participant acknowledged the potential for DS features to be exploited for harmful or self-serving purposes. © 2024 ACM.},
	author_keywords = {data storytelling; information visualisation; learning analytics},
	keywords = {Risk perception; Visualization; Case-studies; Data storytelling; Information visualization; Learning analytic; Potential risks; Potential values; Teaching and learning; Teaching designs; Text annotations; Visual feature; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Shaikh202519,
	author = {Shaikh, Mohammad Shahnawaz and Ali, Syed Ibad},
	title = {An integrated analysis of the effects of learning analytics dashboards on learner perspective, inspiration, engagement, and accomplishment},
	year = {2025},
	journal = {Revolutionizing Education With Remote Experimentation and Learning Analytics},
	pages = {19 – 36},
	doi = {10.4018/979-8-3693-8593-7.ch002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002675167&doi=10.4018%2f979-8-3693-8593-7.ch002&partnerID=40&md5=74af4a143c8b573d67f1f715a8fc3e4b},
	affiliations = {Parul Institute of Engineering and Technology, Parul University, India},
	abstract = {In order to examine the effects of LADs on student learning outcomes, including achievement, involvement, motivation, and attitudes, this chapter compiles the data from some excellent research studies. As things stand, there is insufficient data to draw the conclusion that LADs have improved academic performance as promised. Little or no effects were reported in the majority of investigations, and well-powered controlled experiments provided scant evidence. Many studies confused the dashboard effect with student engagement levels by comparing LAD users and non-users. In a similar vein, the influence of LADs on attitudes and motivation seemed to be minimal, with only a few cases showing notable results. Small sample sizes emphasize the necessity of conducting more extensive research to corroborate these results. © 2025, IGI Global Scientific Publishing.},
	publisher = {IGI Global},
	isbn = {979-836938595-1; 979-836938593-7},
	language = {English},
	abbrev_source_title = {Revolutionizing Educ. With Remote Exp. and Learn. Anal.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Pozdniakov2025367,
	author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Echeverria, Vanessa and Swiecki, Zachari and Gašević, Dragan},
	title = {Investigating the Effect of Visualization Literacy and Guidance on Teachers’ Dashboard Interpretation},
	year = {2025},
	journal = {Journal of Learning Analytics},
	volume = {12},
	number = {1},
	pages = {367 – 390},
	doi = {10.18608/jla.2024.8471},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001875404&doi=10.18608%2fjla.2024.8471&partnerID=40&md5=5cd2d516b38f8d1debe36ae00505d8d1},
	affiliations = {Centre for Learning Analytics Monash (CoLAM), Faculty of Information Technology (FIT), Monash University, Australia; School of Electrical Engineering and Computer Science, The University of Queensland, Australia; Escuela Superior Politécnica del Litoral, Guayaquil, Ecuador},
	abstract = {Recent research on learning analytics dashboards has focused on designing user interfaces that offer various forms of visualization guidance (often referring to notions such as data storytelling or narrative visualization) to teachers (e.g., emphasizing data points or trends with colour and adding annotations), aiding them in interpreting visual elements to gain a comprehensive understanding of students’ learning processes. Yet, while some studies have explored how teachers interpret students’ data through these dashboards, many have overlooked the diverse technical capabilities of teachers, which can significantly impact their use of LA dashboards. In particular, visualization literacy (VL) skills can greatly influence how effectively teachers interpret dashboards. To the best of our knowledge, no comprehensive account exists that details how teachers with varying VL skills interpret visual representations of students’ data. In this paper, we address this gap by investigating how teachers interpret LA dashboards, both with and without visualization guidance, taking into account their VL. We illustrate this by analyzing teachers’ think-aloud sessions as they engage with dashboards in the context of monitoring synchronous online learning tasks undertaken by student groups using Zoom and Google Docs. Using epistemic network analysis, we examine the differences in interpretations between teachers with varying VL levels. Our findings revealed that teachers with low VL exhibited shallower dashboard interpretations than those with high VL. However, the association of VL with successful task completion rate was not significant. Also, visualization guidance did not enable teachers to deepen their interpretations. While some visualization guidance helped teachers to complete tasks correctly, excessive visualization guidance can also be detrimental. © 2025, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {dashboards; data literacy; data storytelling; human-centred design; Learning analytics; visualization guidance},
	correspondence_address = {S. Pozdniakov; Centre for Learning Analytics Monash (CoLAM), Faculty of Information Technology (FIT), Monash University, Australia; email: pozdniakov@uq.edu.au; R. Martinez-Maldonado; Centre for Learning Analytics Monash (CoLAM), Faculty of Information Technology (FIT), Monash University, Australia; email: roberto.martinezmaldonado@monash.edu},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Trevisan20241851,
	author = {Trevisan, O. and Christensen, R. and Drossel, K. and Friesen, S. and Forkosh-Baruch, A. and Phillips, M.},
	title = {Drivers of Digital Realities for Ongoing Teacher Professional Learning},
	year = {2024},
	journal = {Technology, Knowledge and Learning},
	volume = {29},
	number = {4},
	pages = {1851 – 1868},
	doi = {10.1007/s10758-024-09771-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195454928&doi=10.1007%2fs10758-024-09771-0&partnerID=40&md5=e9777248b6e92e9e99ae5386ad1d4685},
	affiliations = {Department of Philosophy, Sociology, Pedagogy and Applied Psychology, University of Padova, Padua, Italy; Department of Learning Technologies, University of North Texas, Denton, United States; Institute for Educational Science, Paderborn University, Paderborn, Germany; Werklund School of Education, University of Calgary, Calgary, Canada; Faculty of Education, Levinsky-Wingate Academic College, Tel Aviv, Israel; Faculty of Education, Monash University, Clayton, Australia},
	abstract = {In an era marked by the widespread use of digital technology, educators face the need to constantly learn and develop their own new literacies for the information era, as well as their competencies to teach and apply best practices using technologies. This paper underscores the vital role of ongoing teacher professional learning (OTPL) with a focus on reflective practices and pedagogical reasoning and action (PR&A) in shaping education quality and equity. Examining three key drivers of educational transformation—big data and learning analytics, Artificial Intelligence (AI), and shifting teacher identities—the paper explores their overall impact on teacher practices. This paper emphasizes technology as a crucial boundary object, a catalyst of educational transformation, when used to foster communication and professional growth. To this end, three boundary objects are identified, namely dashboards, AI-driven professional learning environments, and digital communities of practice. These tools illustrate technology’s capacity to mediate relationships between transformative educational drivers and teacher practices, offering a pathway to navigate shifting perspectives on OTPL. With a theoretical foundation in equitable education, the paper provides insights into the intricate relationship between boundary objects and evolving educational dynamics. It highlights technology's pivotal role in achieving both quality and equitable education in the contemporary educational landscape. It presents a nuanced understanding of how specific tools may contribute to effective OTPL amid rapid educational transformations. © The Author(s) 2024.},
	author_keywords = {Boundary objects; Digital realities in education; Equity; Ongoing teacher professional learning (OTPL); Pedagogical reasoning},
	keywords = {Computer aided instruction; Driver training; E-learning; Engineering education; Professional aspects; Boundary objects; Digital reality in education; Digital technologies; Equity; Learn+; Ongoing teacher professional learning; Pedagogical reasoning; Professional learning; Teacher practices; Teachers'; Metadata},
	correspondence_address = {O. Trevisan; Department of Philosophy, Sociology, Pedagogy and Applied Psychology, University of Padova, Padua, Italy; email: ottavia.trevisan@unipd.it},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Taufik2024,
	author = {Taufik, Rahman and Meliana, Selly and Handono, Aryo},
	title = {Implementing of clustering in learning analytics dashboard to support teacher in evaluation},
	year = {2024},
	journal = {AIP Conference Proceedings},
	volume = {2970},
	number = {1},
	doi = {10.1063/5.0208235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204395508&doi=10.1063%2f5.0208235&partnerID=40&md5=62614dafe2440fc4ca465a951e8516b0},
	affiliations = {Department of Computer Science, Faculty of Mathematics and Natural Sciences, Lampung University, Jl. Prof. Dr. Ir. Sumantri Brojonegoro No.1, Gedong Meneng, Rajabasa, Lampung, Bandar Lampung, 35141, Indonesia; Department of Computer Science, Faculty of Computing, Telkom University, Jl. Telekomunikasi No. 1, Terusan Buahbatu - Bojongsoang, Sukapura, Kec. Dayeuhkolot, Kabupaten Bandung, Jawa Barat, 40257, Indonesia},
	abstract = {Learning evaluation is one of the crucial processes of learning which aims to improve the effectiveness of the teaching-learning process. During the pandemic season, teachers adapted to use the Learning Management System (LMS) to conduct learning. However, not all LMS have features that help teachers to analyze students' learning evaluation. Learning Analytics Dashboard (LAD) can be a valuable tool because it can assist the teacher by visualizing student learning progress. Unlike previous LAD research that is mainly focused on the development from the aspect of learning analysis, the proposed LAD combines learning analytic and clustering methods to perform analysis and visualization. In this paper, we propose the implementation of a clustering algorithm into a learning analytics dashboard called Clustering Analytics Dashboard (CAD), to support learning evaluation. We use learning data logs in LMS for a programming introduction course that covers 364 first-year students and four tests, including pre-test, exercises, post-test, and mid-semester exams. It generates three clustered data by k-means algorithm and k-elbow method visualized in the CAD. Following the heuristic evaluation for dashboard performance, the CAD has no usability problem and can be used in analyzing students' learning evaluation. © 2024 Author(s).},
	correspondence_address = {R. Taufik; Department of Computer Science, Faculty of Mathematics and Natural Sciences, Lampung University, Bandar Lampung, Jl. Prof. Dr. Ir. Sumantri Brojonegoro No.1, Gedong Meneng, Rajabasa, Lampung, 35141, Indonesia; email: rahman.taufik@fmipa.unila.ac.id},
	editor = {Hadi S. and Perdana R. and Putrawan G.E. and Septiawan T.Y.},
	publisher = {American Institute of Physics},
	issn = {0094243X},
	isbn = {978-073544618-2},
	language = {English},
	abbrev_source_title = {AIP Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Villagrán2024138,
	author = {Villagrán, Ignacio and Hernández, Rocio and Schuit, Gregory and Neyem, Andrés and Fuentes, Javiera and Larrondo, Loreto and Margozzini, Elisa and Hurtado, María T. and Iriarte, Zoe and Miranda, Constanza and Varas, Julián and Hilliger, Isabel},
	title = {Enhancing Feedback Uptake and Self-Regulated Learning in Procedural Skills Training: Design and Evaluation of a Learning Analytics Dashboard},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {2},
	pages = {138 – 156},
	doi = {10.18608/jla.2024.8195},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202546173&doi=10.18608%2fjla.2024.8195&partnerID=40&md5=dd16edadfc43d6429e9d9351e8ce68c4},
	affiliations = {Health Science Department, Pontificia Universidad Católica de Chile, Santiago, 7820436, Chile; Computer Science Department, School of Engineering, Pontificia Universidad Católica de Chile, Santiago, 7820436, Chile; National Center for Artificial Intelligence (CENIA), Pontificia Universidad Católica de Chile, Santiago, Chile; Engineering Education Unit, School of Engineering, Pontificia Universidad Católica de Chile, Vicuña Mackenna 4860, Macul, Santiago, 7820436, Chile},
	abstract = {Remote technology has been widely incorporated into health professions education. For procedural skills training, effective feedback and reflection processes are required. Consequently, supporting a self-regulated learning (SRL) approach with learning analytics dashboards (LADs) has proven beneficial in online environments. Despite the potential of LADs, understanding their design to enhance SRL and provide useful feedback remains a significant challenge. Focusing on LAD design, implementation, and evaluation, the study followed a mixed-methods two-phase design-based research approach. The study used a triangulation methodology of qualitative interviews and SRL and sensemaking questionnaires to comprehensively understand the LAD’s effectiveness and student SRL and feedback uptake strategies during remote procedural skills training. Initial findings revealed the value students placed on performance visualization and peer comparison despite some challenges in LAD design and usability. The study also identified the prominent adoption of SRL strategies such as help-seeking, elaboration, and strategic planning. Sensemaking results showed the value of personalized performance metrics and planning resources in the LAD and recommendations to improve reflection and feedback uptake. Subsequent findings suggested that SRL levels significantly predicted the levels of sensemaking. The students valued the LAD as a tool for supporting feedback uptake and strategic planning, demonstrating the potential for enhancing procedural skills learning. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {feedback; health professions education; Learning analytics dashboard; procedural skills; self-regulated learning},
	correspondence_address = {I. Hilliger; Engineering Education Unit, School of Engineering, Pontificia Universidad Católica de Chile, Santiago, Vicuña Mackenna 4860, Macul, 7820436, Chile; email: ihillige@uc.cl},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Solano2024,
	author = {Solano, Andrés and Peláez, Carlos Alberto and Ospina, Johann A. and Luna-García, Huizilopoztli and Parra, Jorge Andrick and Ramírez, Gabriel Mauricio and Moreira, Fernando and López Sotelo, Jesús Alfonso and Villalba-Condori, Klinge Orlando},
	title = {Work Route for the Inclusion of Learning Analytics in the Development of Interactive Multimedia Experiences for Elementary Education},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {17},
	doi = {10.3390/app14177645},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203851914&doi=10.3390%2fapp14177645&partnerID=40&md5=2fe130f6f8d4d7b87da2de9ee6cbaf5a},
	affiliations = {Facultad de Ingeniería y Ciencias Básicas, Universidad Autónoma de Occidente, Cali, 760030, Colombia; Unidad Académica de Ingeniería Eléctrica, Universidad Autónoma de Zacatecas, Jardín Juarez 147, Centro, Zacatecas, 98000, Mexico; Facultad de Ingeniería, Universidad Autónoma de Bucaramanga, Bucaramanga, 680006, Colombia; Facultad de Ingenierías, Universidad de Medellín, Medellín, 050010, Colombia; Research on Economics, Management and Information Technologies, Universidade Portucalense, Porto, 4200-072, Portugal; Universidad Nacional Pedro Henríquez Ureña, Santo Domingo 1423, Dominican Republic},
	abstract = {Interactive multimedia experiences (IME) can be a pedagogical resource that has a strong potential to enhance learning experiences in early childhood. Learning analytics (LA) has become an important tool that allows us to understand more clearly how these multimedia experiences can contribute to the learning processes of these students. This article proposes a work route that defines a set of activities and techniques, as well as a flow for their application, by taking into consideration the importance of including LA guidelines when designing IMEs for elementary education. The work route’s graphical representation is inspired by the foundations of the Essence standard’s graphical notation language. The guidelines are grouped into five categories, namely (i) a data analytics dashboard, (ii) student data, (iii) teacher data, (iv) learning activity data, and (v) student progress data. The guidelines were validated through two approaches. The first involved a case study, where the guidelines were applied to an IME called Coco Shapes, which was aimed at transition students at the Colegio La Fontaine in Cali (Colombia), and the second involved the judgments of experts who examined the usefulness and clarity of the guidelines. The results from these approaches allowed us to obtain precise and effective feedback regarding the hypothesis under study. Our findings provide promising evidence of the value of our guidelines, which were included in the design of an IME and contributed to the greater personalized monitoring available to teachers to evaluate student learning. © 2024 by the authors.},
	author_keywords = {guidelines; interactive multimedia experiences; learning analytics; work route},
	keywords = {Adversarial machine learning; Contrastive Learning; Students; Elementary education; Enhance learning; Guideline; Interactive multimedia; Interactive multimedium experience; Learning analytic; Learning experiences; Pedagogical resources; Teachers'; Work route},
	correspondence_address = {A. Solano; Facultad de Ingeniería y Ciencias Básicas, Universidad Autónoma de Occidente, Cali, 760030, Colombia; email: afsolano@uao.edu.co; H. Luna-García; Unidad Académica de Ingeniería Eléctrica, Universidad Autónoma de Zacatecas, Zacatecas, Jardín Juarez 147, Centro, 98000, Mexico; email: hlugar@uaz.edu.mx; K.O. Villalba-Condori; Universidad Nacional Pedro Henríquez Ureña, Santo Domingo 1423, Dominican Republic; email: kvillalba@ucsm.edu.pe},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20763417},
	language = {English},
	abbrev_source_title = {Appl. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sperling2024103,
	author = {Sperling, Katarina},
	title = {The Fading of F(AI)th: Tracing the Technological Promises of a Wellbeing App in K-12 Education},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1171 LNNS},
	pages = {103 – 115},
	doi = {10.1007/978-3-031-73538-7_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218942541&doi=10.1007%2f978-3-031-73538-7_10&partnerID=40&md5=db71ed3ef0ac8730346271d2772560a7},
	affiliations = {Department of Behavioural Sciences and Learning, Linköping University, Norrköping, 601 74, Sweden},
	abstract = {This paper explores the implementation of a wellbeing app in a Swedish Upper Secondary School. The aim is to understand how ideas of data driven school improvement underpinned by promises of artificial intelligence (AI) and learning analytics (LA) change the work of teachers. The study draws on video-ethnography from 17 meetings between five teachers/form tutors. The produced data is analysed using actor-network theory to focus on the various stages of the implementation process and the interactions between the learning analytics dashboard (LAD) and the teachers. To capture the complexity of the data, the empirical material is presented through cartoon-inspired illustrations grounded in a Thinking through Cartoons methodology. Findings show how teachers took on new roles and responsibilities in relation to the wellbeing app, most notably the role of collecting data from students. Teachers came to act as data analysts which imposed constant negotiations and uncertainties. To address the declining engagement of students over time, a student-facing LAD was introduced. The teachers shifted their focus to motivate students to engage with their own data in different ways. Despite no improvements in students’ response rates teachers remained committed to the app, trusting that new AI and LA functionalities would compensate unsatisfactory outcomes. In conclusion, instead of improving teachers’ capacity to identify at-risk students, the wellbeing app increased teachers’ workload and led to different dilemmas related to teacher-student relations and teachers’ professional judgement. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {actor-network theory (ANT); Artificial Intelligence; data-driven schooling; EdTech; K12; learning analytics; PERMA-model; socio-materiality},
	keywords = {Artificial intelligence; Contrastive Learning; Economic and social effects; Teaching; Actor-network; Actor-network theory; Data driven; Data-driven schooling; Edtech; Learning analytic; PERMA-model; Socio materialities; Teachers'; Wellbeing; Students},
	correspondence_address = {K. Sperling; Department of Behavioural Sciences and Learning, Linköping University, Norrköping, 601 74, Sweden; email: katarina.sperling@liu.se},
	editor = {Herodotou C. and Papavlasopoulou S. and Santos C. and Milrad M. and Otero N. and Vittorini P. and Gennari R. and Di Mascio T. and Temperini M. and De la Prieta F.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303173537-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kaur20249221,
	author = {Kaur, Amanpreet and Chahal, Kuljit Kaur},
	title = {A learning analytics dashboard for data-driven recommendations on influences of non-cognitive factors in introductory programming},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {8},
	pages = {9221 – 9256},
	doi = {10.1007/s10639-023-12125-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169900856&doi=10.1007%2fs10639-023-12125-5&partnerID=40&md5=417cfab61ccf4ab28173f1e7322a857e},
	affiliations = {Department of Computer Science, Guru Nanak Dev University, Punjab, Amritsar, India},
	abstract = {Research so far has overlooked the contribution of students’ noncognitive factors to their performance in introductory programming in the context of personalized learning support. This study uses learning analytics to design and implement a Dashboard to understand the contribution of introductory programming students’ learning motivation, personality, and class participation factors to their programming performance and provide adaptive support to improve their motivation and persistence. Moreover, this study evaluates the effectiveness and usefulness of the dashboard in two phases: committee evaluation and laypersons evaluation. The evaluation results indicate dashboard’s effectiveness in students’ better-informed decision-making related to their learning approach. In both phases, the dashboard has been perceived as useful and easy-to-use tool. These findings indicate that the dashboard is perceived as a useful tool for providing timely feedback about non-cognitive factors contributing to students’ programming performance. The study provides insights into the noncognitive side of novice programmers and encourages further exploration of other aspects influencing their performance. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.},
	author_keywords = {Class participation; Data-driven recommendations; Introductory Programming course; Learning Analytics Dashboard; Motivational factors; Performance prediction; Personality traits},
	correspondence_address = {A. Kaur; Department of Computer Science, Guru Nanak Dev University, Amritsar, Punjab, India; email: sidhuamanpreet7@gmail.com},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Banihashem2025,
	author = {Banihashem, Seyyed Kazem and Gašević, Dragan and Noroozi, Omid},
	title = {A Critical Review of Using Learning Analytics for Formative Assessment: Progress, Pitfalls and Path Forward},
	year = {2025},
	journal = {Journal of Computer Assisted Learning},
	volume = {41},
	number = {3},
	doi = {10.1111/jcal.70056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004313675&doi=10.1111%2fjcal.70056&partnerID=40&md5=41ffeadb0fc47093728e3e47a131cd07},
	affiliations = {Open Universiteit, Heerlen, Netherlands; Monash University, Melbourne, VIC, Australia; Wageningen University and Research, Wageningen, Netherlands},
	abstract = {Background: While formative assessment is widely regarded as essential for improving teaching and learning, it remains difficult to operationalize due to systemic misalignment with other instructional practices, limited teacher capacity, low feedback quality, inferential uncertainty, domain-general approaches, and validity concerns. Objectives: This editorial introduces a special issue that critically examines how learning analytics can contribute to advancing formative assessment by addressing persistent challenges in its design and implementation. Results and Conclusion: The twelve studies featured in this issue demonstrate several innovations such as adaptive feedback, multimodal analytics, predictive modeling, dashboard design, and evidence-centered assessment frameworks. Collectively, these studies demonstrate how learning analytics can enhance formative assessment by personalizing feedback, scaling dialogic feedback, understanding the nature of feedback, improving assessment validity, automating assessment, uncovering deeper learning patterns, and improving assessment alignment with instructional goals. However, the issue also highlights several underexplored gaps, including the limited disciplinary adaptation of analytics tools, a lack of ongoing student involvement in feedback design, insufficient attention to ethical concerns and the physiological and motivational dimensions of assessment, and a limited understanding of the role of emerging technologies, in particular, Generative AI (GenAI). This editorial argues for a more critical, inclusive, and context-sensitive approach to learning analytics in formative assessment—one that centers pedagogy, teacher and student agency, and long-term educational value. The contributions of this special issue lay essential groundwork for future research, policy, and practice aimed at transforming formative assessment through learning analytics. © 2025 John Wiley & Sons Ltd.},
	author_keywords = {AI; feedback; formative assessment; GenAI; human agency; learning analytics},
	correspondence_address = {S.K. Banihashem; Open Universiteit, Heerlen, Netherlands; email: kazem.banihashem@ou.nl},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Shaikh2025545,
	author = {Shaikh, Mohammad Shahnawaz and Ali, Syed Ibad},
	title = {The joint creation of an instructor dashboard for online learning environments in college and university},
	year = {2025},
	journal = {Revolutionizing Education With Remote Experimentation and Learning Analytics},
	pages = {545 – 558},
	doi = {10.4018/979-8-3693-8593-7.ch032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002674997&doi=10.4018%2f979-8-3693-8593-7.ch032&partnerID=40&md5=735db1adb706739418ac34dd461e854c},
	affiliations = {Parul Institute of Engineering and Technology, Parul University, India},
	abstract = {Among the most significant components of a higher technology education is laboratory experimentation. Considering the goal of facilitating online access to cutting- edge laboratory simulations and their settings, the authors introduce an effective and excellent platform. In order to support the effort to enable remote lab access, instructors and researchers need to know more about the students who come to these labs. This chapter describes the co- design process for developing a low fidelity instructor dashboard for remote labs with the goal of supporting the pedagogical design of laboratories and enhancing student engagement and understanding in higher education laboratory experiments. The design methodology is described within the LATUX framework for co- design from the learning analytics discipline. © 2025, IGI Global Scientific Publishing.},
	publisher = {IGI Global},
	isbn = {979-836938595-1; 979-836938593-7},
	language = {English},
	abbrev_source_title = {Revolutionizing Educ. With Remote Exp. and Learn. Anal.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Poikaryil2025182,
	author = {Poikaryil, Oleeviya Babu and Babu, Tony Basil and Sagar, Gittil and Krishna, Vidvath and Mitra, Saikat},
	title = {Transformative Fusion: Leveraging Blockchain and AI for Educational Data Analytics in Modern Education Systems},
	year = {2025},
	journal = {Blockchain and AI in Shaping the Modern Education System},
	pages = {182 – 208},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003065240&partnerID=40&md5=5839cae792b47f586dc1fdefbe7469e0},
	affiliations = {Otto Von Guericke University, Magdeburg, Germany; RIT Government Engineering College, Kerala, India},
	abstract = {The combination of blockchain technology with artificial intelligence (AI) has the potential to transform educational data analytics, providing unprecedented opportunities for improving learning experiences and institutional efficiency in today’s education systems. Blockchain technology creates a decentralized, immutable ledger to assure data integrity, security, and transparency. Using blockchain, educational institutions may securely store and manage sensitive student data, academic records, and learning progress in a tamperproof manner, increasing stakeholder trust and reducing concerns about data privacy and security breaches. AI algorithms play a critical role in extracting insights from massive amounts of education data. AI can examine complicated datasets using machine learning, natural language processing, and predictive analytics to detect trends, tailor learning paths, forecast student performance, and enhance teaching tactics. Furthermore, AI-powered adaptive learning systems may dynamically change content delivery based on individual learning styles, preferences, and competence levels, resulting in more personalized and engaging learning experiences. The combination of blockchain with AI improves the efficiency and effectiveness of educational data analytics but also allows for the creation of novel applications such as credential verification, plagiarism detection, and learning analytics dashboards. Furthermore, blockchain-enabled educational platforms are interoperable, allowing for seamless data sharing and cooperation among a wide range of stakeholders, including students, instructors, administrators, and policymakers. However, achieving the full potential of blockchain and AI integration in education necessitates overcoming technical, legislative, and ethical barriers. Scalability, interoperability, data standardization, and algorithm bias are critical concerns that must be addressed to promote equal access, inclusion, and fairness in educational data analytics. Finally, the combination of blockchain and AI creates a breakthrough paradigm for educational data analytics, allowing stakeholders to make informed decisions, optimize learning outcomes, and drive continuous improvement in the modern education system. By adopting this collaborative approach, educational institutions may pave the way for a more adaptable, responsive, and student-centered learning environment in the digital age. © 2025 Randhir Kumar, Prabhat Kumar, Sobin C.C. and N.P. Subheesh.},
	correspondence_address = {O.B. Poikaryil; Otto Von Guericke University, Magdeburg, Germany; email: oleeviyazehr@gmail.com},
	publisher = {CRC Press},
	isbn = {978-104040717-2; 978-103280170-4},
	language = {English},
	abbrev_source_title = {Blockchain and AI in Shap. the Mod. Educ. Syst.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Akhuseyinoglu2024374,
	author = {Akhuseyinoglu, Kamil and McDonald, Emma and Klasnja Milicevic, Aleksandra and Demmans Epp, Carrie and Brusilovsky, Peter},
	title = {Exploring Adaptive Social Comparison for Online Practice},
	year = {2024},
	journal = {UMAP 2024 - Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
	pages = {374 – 379},
	doi = {10.1145/3631700.3664899},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198945840&doi=10.1145%2f3631700.3664899&partnerID=40&md5=f8a588770deb6611aefcf3c5d64b6c80},
	affiliations = {University of Pittsburgh, Pittsburgh, PA, United States; University of Alberta, Edmonton, AB, Canada; University of Novi Sad, Novi Sad, Serbia},
	abstract = {Students experience motivational issues during online learning which has led to explorations of how to better support their self-regulated learning. One way to support students uses social reference frames or social comparison in student-facing learning analytics dashboards (LADs) and open learner models (OLMs). Usually, the social reference frame communicates class averages. Despite the positive effects of class-average-based social comparison on students' activity levels and learning behaviors, comparison to class average can be misleading for some students and offer an irrelevant reference frame, motivating only low or high performers. Such conflicting findings highlight a need for an investigation of social reference frames that are not based on the "average"student. We extend the research on social comparison in education by conducting two complementary classroom studies. The first explores the effects of different fixed social reference frames in a non-mandatory practice system, while the second introduces an adaptive social reference frame that dynamically selects the peers who serve as a comparison group when students are engaged in online programming practice. We reported our analyses from both studies and shared students' subjective evaluations of the system and its adaptive comparison functionality. © 2024 Owner/Author.},
	author_keywords = {adaptive educational systems; classroom experiment; computer science education; learning analytics; OLM; self-regulated learning},
	keywords = {Computer programming; E-learning; Education computing; Learning systems; Online systems; Adaptive educational system; Classroom experiment; Computer Science Education; Educational systems; Learning analytic; Online learning; Open learner models; Reference frame; Self-regulated learning; Student experiences; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070466-6},
	language = {English},
	abbrev_source_title = {UMAP - Adjun. Proc. ACM Conf. User Model., Adapt. Personal.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cohn2025595,
	author = {Cohn, Clayton and Snyder, Caitlin and Fonteles, Joyce Horn and Ashwin, T.S. and Montenegro, Justin and Biswas, Gautam},
	title = {A multimodal approach to support teacher, researcher and AI collaboration in STEM+C learning environments},
	year = {2025},
	journal = {British Journal of Educational Technology},
	volume = {56},
	number = {2},
	pages = {595 – 620},
	doi = {10.1111/bjet.13518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204455857&doi=10.1111%2fbjet.13518&partnerID=40&md5=f9366b797486b5b160c76e5f93154ed1},
	affiliations = {Department of Computer Science, Vanderbilt University, School of Engineering, Institute for Software Integrated Systems, Nashville, TN, United States; Martin Luther King, Jr. Academic Magnet High School, Career and Technical Education, Engineering, Nashville, TN, United States},
	abstract = {Abstract: Recent advances in generative artificial intelligence (AI) and multimodal learning analytics (MMLA) have allowed for new and creative ways of leveraging AI to support K12 students' collaborative learning in STEM+C domains. To date, there is little evidence of AI methods supporting students' collaboration in complex, open-ended environments. AI systems are known to underperform humans in (1) interpreting students' emotions in learning contexts, (2) grasping the nuances of social interactions and (3) understanding domain-specific information that was not well-represented in the training data. As such, combined human and AI (ie, hybrid) approaches are needed to overcome the current limitations of AI systems. In this paper, we take a first step towards investigating how a human-AI collaboration between teachers and researchers using an AI-generated multimodal timeline can guide and support teachers' feedback while addressing students' STEM+C difficulties as they work collaboratively to build computational models and solve problems. In doing so, we present a framework characterizing the human component of our human-AI partnership as a collaboration between teachers and researchers. To evaluate our approach, we present our timeline to a high school teacher and discuss the key insights gleaned from our discussions. Our case study analysis reveals the effectiveness of an iterative approach to using human-AI collaboration to address students' STEM+C challenges: the teacher can use the AI-generated timeline to guide formative feedback for students, and the researchers can leverage the teacher's feedback to help improve the multimodal timeline. Additionally, we characterize our findings with respect to two events of interest to the teacher: (1) when the students cross a difficulty threshold, and (2) the point of intervention, that is, when the teacher (or system) should intervene to provide effective feedback. It is important to note that the teacher explained that there should be a lag between (1) and (2) to give students a chance to resolve their own difficulties. Typically, such a lag is not implemented in computer-based learning environments that provide feedback. Practitioner notes What is already known about this topic Collaborative, open-ended learning environments enhance students' STEM+C conceptual understanding and practice, but they introduce additional complexities when students learn concepts spanning multiple domains. Recent advances in generative AI and MMLA allow for integrating multiple datastreams to derive holistic views of students' states, which can support more informed feedback mechanisms to address students' difficulties in complex STEM+C environments. Hybrid human-AI approaches can help address collaborating students' STEM+C difficulties by combining the domain knowledge, emotional intelligence and social awareness of human experts with the general knowledge and efficiency of AI. What this paper adds We extend a previous human-AI collaboration framework using a hybrid intelligence approach to characterize the human component of the partnership as a researcher-teacher partnership and present our approach as a teacher-researcher-AI collaboration. We adapt an AI-generated multimodal timeline to actualize our human-AI collaboration by pairing the timeline with videos of students encountering difficulties, engaging in active discussions with a high school teacher while watching the videos to discern the timeline's utility in the classroom. From our discussions with the teacher, we define two types of inflection points to address students' STEM+C difficulties—the difficulty threshold and the intervention point—and discuss how the feedback latency interval separating them can inform educator interventions. We discuss two ways in which our teacher-researcher-AI collaboration can help teachers support students encountering STEM+C difficulties: (1) teachers using the multimodal timeline to guide feedback for students, and (2) researchers using teachers' input to iteratively refine the multimodal timeline. Implications for practice and/or policy Our case study suggests that timeline gaps (ie, disengaged behaviour identified by off-screen students, pauses in discourse and lulls in environment actions) are particularly important for identifying inflection points and formulating formative feedback. Human-AI collaboration exists on a dynamic spectrum and requires varying degrees of human control and AI automation depending on the context of the learning task and students' work in the environment. Our analysis of this human-AI collaboration using a multimodal timeline can be extended in the future to support students and teachers in additional ways, for example, designing pedagogical agents that interact directly with students, developing intervention and reflection tools for teachers, helping teachers craft daily lesson plans and aiding teachers and administrators in designing curricula. © 2024 The Author(s). British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
	author_keywords = {human-AI collaboration; K12 education; MMLA; multimodal learning analytics; STEM+C learning; teacher supports; timeline dashboard},
	keywords = {Adversarial machine learning; C (programming language); Collaborative learning; Contrastive Learning; Economic and social effects; Educational technology; Personnel training; Teaching; Human-artificial intelligence collaboration; K-12 education; Multi-modal learning; Multimodal learning analytic; STEM+C learning; Teachers'; Teachers' support; Timeline dashboard; Students},
	correspondence_address = {C. Cohn; Vanderbilt University Institute for Software Integrated Systems, 1025 16th Ave S Nashville, 37212, United States; email: clayton.a.cohn@vanderbilt.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Villamañe2025265,
	author = {Villamañe, Mikel and Renobales-Irusta, Aitor and Álvarez, Ainhoa},
	title = {A Preliminary Study on the Use of Generative Artificial Intelligence to Enrich Dashboards},
	year = {2025},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {265 – 272},
	doi = {10.5220/0013265600003932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003721557&doi=10.5220%2f0013265600003932&partnerID=40&md5=edefcd9e0a11db24f13cab8a408fdce0},
	affiliations = {Department of Computer Languages and Systems, University of the Basque Country UPV/EHU, Spain},
	abstract = {The use of dashboards to show information to teachers in educational environments is a widespread technique. However, teachers often have problems to understand the charts and therefore to take decisions based on the information shown. This is, often dashboards just show information and do not help teachers to interpret which problems do students have with the course and, consequently, dashboards do not assist teachers to provide adequate interventions. In this context, the aim of this work is to analyse whether the use of Generative artificial intelligence (GenAI) can help teachers understanding dashboards and decide in turn when to provide interventions and what kind of interventions could be the most beneficial for the students. Copyright © 2025 by SCITEPRESS - Science and Technology Publications, Lda.},
	author_keywords = {GenAI; Learning Analytics Dashboards},
	keywords = {Engineering education; Generative adversarial networks; Teaching; Decision-based; Educational environment; Generative artificial intelligence; Learning analytic dashboard; Teachers'; Students},
	editor = {du Boulay B. and Di Mascio T. and Tovar E. and Meinel C.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758746-7},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pei2024,
	author = {Pei, Bo and Cheng, Ying and Ambrose, Alex and Dziadula, Eva and Xing, Wanli and Lu, Jie},
	title = {LearningViz: a dashboard for visualizing, analyzing and closing learning performance gaps—a case study approach},
	year = {2024},
	journal = {Smart Learning Environments},
	volume = {11},
	number = {1},
	doi = {10.1186/s40561-024-00346-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211104720&doi=10.1186%2fs40561-024-00346-1&partnerID=40&md5=051f279635588adc22831a0ca2c01413},
	affiliations = {Department of Educational and Psychological Studies, College of Education, University of South Florida, 4110 USF Apple Dr, Tampa, 33620, FL, United States; Department of Psychology, University of Notre Dame, Notre Dame, 46556, IN, United States; Notre Dame Learning, University of Notre Dame, Notre Dame, 46556, IN, United States; Department of Economics, University of Notre Dame, Notre Dame, 46556, IN, United States; School of Teaching & Learning, College of Education, University of Florida, 1221 SW 5th Ave, Gainesville, 32601, FL, United States; Mary Frances Early College of Education, University of Georgia, 217 River’s Crossing, Athens, 30603, GA, United States},
	abstract = {The availability of large-scale learning data presents unprecedented opportunities for investigating student learning processes. However, it is challenging for instructors to fully make sense of this data and effectively support their teaching practices. This study introduces LearningViz, an interactive learning analytics dashboard to help instructors identify, analyze, and close performance gaps among students in their classes. In this dashboard, we incorporated three modules to enhance human and computer interactions for better supporting the teaching practices: the Student Overall Performance Analysis Module, which provides a comprehensive understanding of students’ learning in the course; the Student Group Performance Analysis Module, which examines performance gaps across different groups and identifies factors contributing to these gaps; and the Final Exam Item Analysis Module, which evaluates the quality of exam questions and identifies strategies for closing performance gaps. The overall design of the platform follows a user-centered approach, integrating data analysis with various visualization strategies in a unified platform. A case study is then conducted to highlight the effectiveness of LearningViz in supporting instructors analyzing students’ learning patterns and associated factors impacting learning performance. We further conduct a usability test with several domain experts, to evaluate the usefulness and effectiveness of this platform in supporting the teaching practices. Our findings underscore the platform's ability to support instructors in detecting performance gaps among students, investigating influential factors, evaluating assessment quality and implementing targeted instructional strategies for closing performance gaps. © The Author(s) 2024.},
	author_keywords = {Data visualization; Learning dashboard; Performance gaps analysis; Visual learning analytics},
	correspondence_address = {B. Pei; Department of Educational and Psychological Studies, College of Education, University of South Florida, Tampa, 4110 USF Apple Dr, 33620, United States; email: bpei@usf.edu},
	publisher = {Springer},
	issn = {21967091},
	language = {English},
	abbrev_source_title = {Smart Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Joshi2024607,
	author = {Joshi, Vasundhara},
	title = {Enhancing Collaboration and Performance Among EMS Students Through Multimodal Learning Analytics},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {607 – 611},
	doi = {10.1145/3678957.3688613},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212592101&doi=10.1145%2f3678957.3688613&partnerID=40&md5=17d465e5270f15e44ba01c68c5651760},
	affiliations = {University of Maryland, Baltimore County, MD, United States},
	abstract = {Physiological synchrony plays an important role in measuring collaboration and performance within teams. However, there has been little investigation into awareness of physiological synchrony and its impact on the collaboration and performance. In my dissertation, I am proposing a study to investigate the impact of awareness of near real-time physiological synchrony, through multimodal learning analytic dashboard, on Emergency Medical Services (EMS) students’ perceived collaboration and performance. Also, I plan to investigate the best practices for presenting multimodal data to EMS trainees in collaborative learning environment. The research aims to enhance students’ engagement and reflection on their collaborative interactions and performance. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {collaboration; electrodermal activity; learning analytics dashboards; Multimodal data visualization; physiological synchrony},
	keywords = {Adversarial machine learning; Electrotherapeutics; Physiological models; Collaboration; Electrodermal activity; Emergency medical services; Learning analytic dashboard; Multi-modal; Multi-modal learning; Multimodal data visualization; Near-real time; Performance; Physiological synchrony; Students},
	correspondence_address = {V. Joshi; University of Maryland, Baltimore County, United States; email: vasu1@umbc.edu},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070462-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cheng202419729,
	author = {Cheng, Nuo and Zhao, Wei and Xu, Xiaoqing and Liu, Hongxia and Tao, Jinhong},
	title = {The influence of learning analytics dashboard information design on cognitive load and performance},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {15},
	pages = {19729 – 19752},
	doi = {10.1007/s10639-024-12606-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189184052&doi=10.1007%2fs10639-024-12606-1&partnerID=40&md5=62517811fe89e39d251c65ca1f700c2b},
	affiliations = {School of Information Science and Technology, Northeast Normal University, Changchun Jilin, China},
	abstract = {Learning analytics dashboards are becoming increasingly common tools for providing feedback to learners. However, there is limited empirical evidence regarding the effects of learning analytics dashboard design features on learners’ cognitive load, particularly in digital learning environments. To address this gap, we developed goal-based, explanatory, and instructional learning analytics dashboards in authentic online courses based on cognitive load theory, and evaluated the effects of the three information designs on cognitive load and performance. The study adopted a quasi-experimental approach over a semester-long course, involving 93 learners divided into four groups, each provided with differently designed information on their learning analytics dashboard. The results show that the incorporation of goals, explanations, and instructional information as support elements in the learning analytics dashboard did not have a significant impact on learners’ cognitive load and performance. Both cognitive load and learning performance results were consistent and mutually validating. Additionally, the study found that compared to a control group without additional information, the group using the explanatory dashboard experienced an increase in germane cognitive load, and evidenced the effectiveness of explanatory information design. Overall, this study provides important insights for the enhancement and practical design of learning analytics dashboards and feedback methods. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Cognitive load; Information design; Learning analytics dashboard; Learning performance},
	correspondence_address = {W. Zhao; School of Information Science and Technology, Northeast Normal University, Changchun Jilin, China; email: zhaow577@nenu.edu.cn},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Viberg20241974,
	author = {Viberg, Olga and Kizilcec, René F. and Wise, Alyssa Friend and Jivet, Ioana and Nixon, Nia},
	title = {Advancing equity and inclusion in educational practices with AI-powered educational decision support systems (AI-EDSS)},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {5},
	pages = {1974 – 1981},
	doi = {10.1111/bjet.13507},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198137990&doi=10.1111%2fbjet.13507&partnerID=40&md5=e7c286dd46836050c7b9892c11ffe8ac},
	affiliations = {Department of Human-Centered Technology, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Information Science, Cornell University, Ithaca, NY, United States; Deparment of Teaching and Learning, Vanderbilt University, Nashville, TN, United States; CATALPA, FernUniversität in Hagen, Hagen, Germany; School of Education, University of California, Irvine, Irvine, CA, United States},
	abstract = {A key goal of educational institutions around the world is to provide inclusive, equitable quality education and lifelong learning opportunities for all learners. Achieving this requires contextualized approaches to accommodate diverse global values and promote learning opportunities that best meet the needs and goals of all learners as individuals and members of different communities. Advances in learning analytics (LA), natural language processes (NLP), and artificial intelligence (AI), especially generative AI technologies, offer potential to aid educational decision making by supporting analytic insights and personalized recommendations. However, these technologies also raise serious risks for reinforcing or exacerbating existing inequalities; these dangers arise from multiple factors including biases represented in training datasets, the technologies' abilities to take autonomous decisions, and processes for tool development that do not centre the needs and concerns of historically marginalized groups. To ensure that Educational Decision Support Systems (EDSS), particularly AI-powered ones, are equipped to promote equity, they must be created and evaluated holistically, considering their potential for both targeted and systemic impacts on all learners, especially members of historically marginalized groups. Adopting a socio-technical and cultural perspective is crucial for designing, deploying, and evaluating AI-EDSS that truly advance educational equity and inclusion. This editorial introduces the contributions of five papers for the special section on advancing equity and inclusion in educational practices with AI-EDSS. These papers focus on (i) a review of biases in large language models (LLMs) applications offers practical guidelines for their evaluation to promote educational equity, (ii) techniques to mitigate disparities across countries and languages in LLMs representation of educationally relevant knowledge, (iii) implementing equitable and intersectionality-aware machine learning applications in education, (iv) introducing a LA dashboard that aims to promote institutional equality, diversity, and inclusion, and (v) vulnerable student digital well-being in AI-EDSS. Together, these contributions underscore the importance of an interdisciplinary approach in developing and utilizing AI-EDSS to not only foster a more inclusive and equitable educational landscape worldwide but also reveal a critical need for a broader contextualization of equity that incorporates the socio-technical questions of what kinds of decisions AI is being used to support, for what purposes, and whose goals are prioritized in this process. © 2024 British Educational Research Association.},
	author_keywords = {AI; AI-EDSS; bias; education; equality; inclusion},
	correspondence_address = {O. Viberg; Department of Human-Centered Technology, KTH Royal Institute of Technology, Stockholm, Linstedsvägen 3, 10044, Sweden; email: oviberg@kth.se},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Kotiurova2024578,
	author = {Kotiurova, Irina A. and Shchegoleva, Liudmila V.},
	title = {Visualization of educational data in a German-language corpus of student texts; [Визуализация образовательных данных в немецкоязычном корпусе студенческих текстов]},
	year = {2024},
	journal = {Perspektivy Nauki i Obrazovania},
	volume = {68},
	number = {2},
	pages = {578 – 594},
	doi = {10.32744/pse.2024.2.35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193445218&doi=10.32744%2fpse.2024.2.35&partnerID=40&md5=b143179dc71a01d3383ca62a2dc96f2e},
	affiliations = {The Department of German and French Languages, Petrozavodsk State University, Petrozavodsk, Russian Federation; The Department of Applied Mathematics and Cybernetics, Petrozavodsk State University, Petrozavodsk, Russian Federation},
	abstract = {Introduction. Digital transformation of education involves the use of digital tools in managing the educational process as a whole and in the learning process in individual disciplines. The specifics of teaching a foreign language require special functionality from digital tools. The purpose of the article is to explore the possibilities of a corpus of student texts in a foreign language for analyzing the results of students’ educational work and forming an adapted learning path within the discipline related to the study of a foreign language. Materials and methods. The material for the study was the Petrozavodsk Annotated Corpus of Texts (PACT), containing written works in German and French written by students from 2019 to 2023. Texts are accompanied by attributive information about the author, writing conditions, evaluation and error corrections. A web application has been developed to work with the corpus. The application includes personal accounts for teachers and students. To analyze the state of the learning process and make subsequent decisions on managing the learning process, the web application contains several tools for visualizing error statistics at different levels of detail with the ability to select texts according to different conditions. Results of the study. As part of the study, patterns were identified that connect the types of errors with the genres of texts, with the severity of the errors, and with the emotional and physiological state of the student. Russian-speaking students studying German as a foreign language make the most mistakes in the choice of lexemes, spelling, punctuation and the place of the verb in a sentence. At the same time, genre differences can be observed to distribute the number of errors by their type. There is an increase in the relative number of gross errors by 1.5 times for senior students compared to the first year. Errors in the choice of lexeme are critical for understanding the content of the text. The severity of the error does not depend on the genre of the text. Conclusion. The results of the study can be used to build corpora of student texts with educational analytics functions in dashboard format. The results obtained can be useful in developing teaching materials for the “Foreign Language” discipline. © 2024 LLC Ecological Help. All rights reserved.},
	author_keywords = {corpus of student texts; data-based learning management; digitalization of education; educational data analysis; learning analytics},
	publisher = {LLC Ecological Help},
	issn = {23072334},
	language = {Russian},
	abbrev_source_title = {Perspekt. Nauki Obraz.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Henríquez20241884,
	author = {Henríquez, Valeria and Guerra, Julio and Scheihing, Eliana},
	title = {The impact of an academic counselling learning analytics tool: Evidence from 3 years of use},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {5},
	pages = {1884 – 1899},
	doi = {10.1111/bjet.13474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191815274&doi=10.1111%2fbjet.13474&partnerID=40&md5=da832a7807eaed8e5299a5d42920b0f7},
	affiliations = {Instituto de Informática, Universidad Austral de Chile, Valdivia, Chile},
	abstract = {Despite the importance of academic counselling for student success, providing timely and personalized guidance can be challenging for higher education institutions. In this study, we investigate the impact of counselling instances supported by a learning analytics (LA) tool, called TrAC, which provides specific data about the curriculum and grades of each student. To evaluate the tool, we measured changes in students' performance ranking position over 3 years and compared the performance of students who received counselling with and without the tool. Our results show that using the tool is related to an improvement in cohort ranking. We further investigated the characteristics of counselled students using cluster analyses. The findings highlight the potential beneficial influence on academic outcomes arising from the provision of guidance to students regarding their course load decisions via TrAC-mediated counselling. This study contributes to the field of LA by providing evidence of the impact of counselling supported by an LA tool in a real-world setting over a long period of time. Our results suggest that incorporating LA into academic counselling practices can improve student success. Practitioner notes What is already known about this topic By analysing student performance, teaching strategies and resource impact, learning analytics (LA) empowers institutions to make informed changes in curriculum design, resource allocation and educational policies. Through insights into academic progress, engagement and behaviour, LA counselling tools enable the identification of at-risk students and those needing additional support. In the related literature, there are areas for further exploration such as understanding the scalability and long-term effects of interventions on student success and retention. What this paper adds Through rigorous data analysis, the paper establishes a connection between LA utilization and enhanced student performance, offering concrete evidence of the effectiveness of LA interventions. By examining various factors such as academic stage and course load, the research offers valuable insights into the contextual nuances that optimize the outcomes of LA tool-based support. It adds to the growing body of evidence that supports the efficacy of data-driven interventions in education, fostering a more informed and evidence-based approach to student support and success. Implications for practice and policy Enhanced student support strategies: By tailoring counselling interventions to align with the identified effective conditions, educators can proactively address individual student needs, improving academic outcomes and retention rates. Informed decision making: The demonstrated positive impact highlights the potential of similar data-driven initiatives to foster student success. Policymakers can consider incentivizing the adoption of such interventions at institutional levels. Future directions for research: By identifying contextual factors that influence the efficacy of LA interventions, it encourages further exploration into how other LA interventions can be optimized for specific conditions. This can guide the development of more precise and effective student support strategies in the future. © 2024 British Educational Research Association.},
	author_keywords = {academic counselling; clustering analysis; learning analytics dashboard; learning analytics impact},
	keywords = {Cluster analysis; Curricula; Decision making; Academic counseling; Analytic tools; Clustering analysis; Condition; Data driven; Learning analytic dashboard; Learning analytic impact; Student performance; Student success; Student supports; Students},
	correspondence_address = {E. Scheihing; Facultad de Ingeniería, Instituto de Informática, Universidad Austral de Chile, Valdivia, General Lagos 2086, Ed. 10000, Campus Miraflores, Chile; email: escheihi@inf.uach.cl},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Núñez Villalobos2025,
	author = {Núñez Villalobos, David Alejandro},
	title = {Predictive Model Based on Machine Learning for Student Retention in Higher Education; [Modelo Predictivo basado en Aprendizaje Automático para la retención Estudiantil en Educación Superior]},
	year = {2025},
	journal = {European Public and Social Innovation Review},
	volume = {10},
	doi = {10.31637/epsir-2025-1307},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216791506&doi=10.31637%2fepsir-2025-1307&partnerID=40&md5=ab324a58451f62042ffc54d5633d5b4c},
	affiliations = {Universidad Bernardo O´Higgins, Chile},
	abstract = {Introduction: Traditionally, academic performance has been considered the guarantee for not dropping out of studies. In recent years, the use of data analysis methods based on different indicators and variables that education manages to measure dropout levels has become widespread. Methodology: However, learning analytics is less known but more useful, comprehensive, and student-centered, making it a more effective tool. Results: The obtained data allows for a more accurate view of how the model behaves at different thresholds, demonstrating its ability to differentiate between students who drop out and those who continue. Discussion: Through this work, institutions are provided with a deeper understanding of students, allowing them to identify difficulties early and provide personalized support. Conclusions: Therefore, learning analytics allows for the early identification of at-risk students with personalized learning, applied through dashboards and reports, using specific methods such as logistic regression and neural networks, social network analysis, sentiment evaluation, and sequence analysis, personalizing real-time monitoring, providing effective interventions adaptable to students' needs. © 2025, HISIN (History of Information Systems). All rights reserved.},
	author_keywords = {dashboards; dropout; Higher education; learning analytics; predictive; retention; school logistic regression; students},
	correspondence_address = {D.A. Núñez Villalobos; Universidad Bernardo O´Higgins, Chile; email: david.nunez@ubo.cl},
	publisher = {HISIN (History of Information Systems)},
	issn = {25299824},
	language = {Spanish},
	abbrev_source_title = {Eur. public soc. innov. rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Alfredo202558,
	author = {Alfredo, Riordan and Mejia-Domenzain, Paola and Echeverria, Vanessa and Rahayu, Dwi and Zhao, Linxuan and Alajlan, Haya and Swiecki, Zachari and Käser, Tanja and Gašević, Dragan and Martinez-Maldonado, Roberto},
	title = {TeamTeachingViz: Benefits, Challenges, and Ethical Considerations of Using a Multimodal Analytics Dashboard to Support Team Teaching Reflection},
	year = {2025},
	journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
	pages = {58 – 69},
	doi = {10.1145/3706468.3706475},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000384966&doi=10.1145%2f3706468.3706475&partnerID=40&md5=6c93b8b78854a94ed72d3be6bf68e511},
	affiliations = {Monash University, Clayton, VIC, Australia; Epfl, Lausanne, Switzerland; Escuela Superior Politécnica Del Litoral, Guayaquil, Ecuador},
	abstract = {Team teaching in higher education can be challenging, especially for educators managing large classes with limited pedagogical training and few opportunities to reflect on their practices. Emerging sensing technologies and analytics can capture and analyse patterns of collaboration, communication, and movement of team teaching. Yet, few studies have presented these data to educators for reflection. To address this gap, we examine the benefits, challenges, and concerns of presenting multimodal teaching data (positional, audio, and spatial pedagogy observations) to educators via the TeamTeachingViz dashboard. We evaluated TeamTeachingViz in an authentic classroom context where educators explored their own data and team teaching strategies. Multimodal data was collected from 36 in-the-wild classroom sessions involving 12 educators grouped in various combinations over 4 weeks, followed by semi-structured interviews to reflect on their practices. Findings suggest that educators improved their self-awareness by using data-driven insights to understand their movements and interactions, enabling continuous improvement in team teaching. However, they noted the need for additional data, such as student behaviours and speech content, to better contextualise these insights. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {co-teaching; in-the-wild; LA dashboard; multimodal learning analytics; spatial pedagogy; teaching analytics; teaching reflection},
	keywords = {Co-teaching; In-the-wild; LA dashboard; Multi-modal; Multi-modal learning; Multimodal learning analytic; Spatial pedagogy; Teaching analytics; Teaching reflection; Team teaching},
	correspondence_address = {R. Alfredo; Monash University, Clayton, Australia; email: riordan.alfredo@monash.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070701-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Anal. Knowl., LAK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Fuller2024471,
	author = {Fuller, Julia S. and Lokey-Vega, Anissa},
	title = {From Data to Action: Faculty Experiences with a University-Designed Learning Analytics System},
	year = {2024},
	journal = {International Journal on E-Learning: Corporate, Government, Healthcare, and Higher Education},
	volume = {23},
	number = {4},
	pages = {471 – 487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215410979&partnerID=40&md5=eb7d1c0b17b1838bd804c0ed3613c7d9},
	affiliations = {Kennesaw State University, United States},
	abstract = {This case study reviews the implementation of a learning analytics (LA) system at a large southeastern university. The LA system uses cloud computing to automate data collection and distribution, providing faculty with insights into student performance and engagement. The system includes weekly alert emails and dashboards offering detailed insights into student learning. The study explores faculty perceptions of the LA system, focusing on its uses, benefits, weaknesses, and barriers to adoption. Data were collected through surveys and focus groups involving faculty who participated in a pilot initiative. Findings reveal that when provided LA, faculty will make data-driven changes to their teaching strategies and are likely to include changes to their feedback, communication, and interactions. Additionally, while LA helped faculty identify performance trends and support students, it also presented challenges such as a learning curve and Learning Management System (LMS) integration issues. Recommendations for improving LA adoption include ongoing training to optimize use of the analytics and facilitate data-informed decisions that support student success and course improvements, clear institutional policies regarding data privacy, and a focus on the long-term impact on student outcomes and teaching practices. © 2024, Association for the Advancement of Computing in Education. All rights reserved.},
	author_keywords = {course optimization; faculty perceptions; instructor action; learning analytics},
	publisher = {Association for the Advancement of Computing in Education},
	issn = {15372456},
	language = {English},
	abbrev_source_title = {Int. J. E-Learn. Corp. Gov. Healthc. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {LAK 2024 Conference Proceedings - 14th International Conference on Learning Analytics and Knowledge},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187642394&partnerID=40&md5=88f06d024c9f32ba44350ee29582d650},
	abstract = {The proceedings contain 95 papers. The topics discussed include: equity-forward learning analytics: designing a dashboard to support marginalized student success; automating human tutor-style programming feedback: leveraging GPT-4 tutor model for hint generation and GPT-3.5 student model for hint validation; novice programmers inaccurately monitor the quality of their work and their peers’ work in an introductory computer science course; improving model fairness with time-augmented Bayesian knowledge tracing; long-term prediction from topic-level knowledge and engagement in mathematics learning; epistemic network analysis for end-users: closing the loop in the context of multimodal analytics for collaborative team learning; and generative artificial intelligence in learning analytics: contextualizing opportunities and challenges through the learning analytics cycle.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang20248523,
	author = {Huang, Lingyun and Zheng, Juan and Lajoie, Susanne P. and Chen, Yuxin and Hmelo-Silver, Cindy E. and Wang, Minhong},
	title = {Examining university teachers’ self-regulation in using a learning analytics dashboard for online collaboration},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {7},
	pages = {8523 – 8547},
	doi = {10.1007/s10639-023-12131-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169157868&doi=10.1007%2fs10639-023-12131-7&partnerID=40&md5=dd7ea14d7949300d8036385303b7a538},
	affiliations = {Department of Curriculum and Instruction, Faculty of Education and Human Development, The Education University of Hong Kong, Hong Kong; Department of Education & Human Services, College of Education, Lehigh University, Bethlehem, PA, United States; Department of Educational and Counselling Psychology, McGill University, Montreal, QC, Canada; University of South Alabama, Mobile, AL, United States; School of Education, Indiana University Bloomington, Bloomington, IN, United States; Faculty of Education, The Hong Kong University, Hong Kong},
	abstract = {Learning analytics dashboards (LADs) are often used to display real-time data indicating student learning trajectories and outcomes. Successful use of LADs requires teachers to orient their dashboard reviews with clear goals, apply appropriate strategies to interpret visualized information on LADs and monitor and evaluate their interpretations to meet goals. This process is known as self-regulated learning (SRL). Critical as it is, little research investigates teachers’ SRL in LAD usage. The present study addressed the gap by examining teachers’ SRL and sought to understand how teachers’ SRL relates to their use of LADs. To this end, a case study was designed in which ten participants were invited to use a LAD for asynchronous online problem-based learning. Think-aloud techniques and process mining methods were applied. The findings show that teachers were cognitive regulation in the early stage of LAD usage and became more metacognitive regulated later. The comparison of SRL between the good and the weak regulators indicates that the good self-regulators enacted more monitoring and evaluation events. Thus their regulator pattern was more non-linear. The qualitative analysis of think-aloud protocols reveals that teachers with good SRL are more likely to use the LAD to diagnose issues in student learning and collaboration. The study highlights the importance of SRL for teachers’ success in using LAD for data-driven instructions. The study also reinforces the importance of fostering teachers’ SRL, which accounts for teachers’ professional success in the digital era. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.},
	author_keywords = {Learning analytics dashboard; Process mining; Self-regulated learning process; Think‐aloud protocols},
	correspondence_address = {L. Huang; Department of Curriculum and Instruction, Faculty of Education and Human Development, The Education University of Hong Kong, Hong Kong; email: lingyunhuang@eduhk.hk},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Echeverria2025,
	author = {Echeverria, Vanessa and Nieto, Gloria Fernandez and Zhao, Linxuan and Palominos, Evelyn and Srivastava, Namrata and Gašević, Dragan and Pammer-Schindler, Viktoria and Martinez-Maldonado, Roberto},
	title = {A learning analytics dashboard to support students' reflection on collaboration},
	year = {2025},
	journal = {Journal of Computer Assisted Learning},
	volume = {41},
	number = {1},
	doi = {10.1111/jcal.13088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208582646&doi=10.1111%2fjcal.13088&partnerID=40&md5=c481c3f7598ac74bf484da3b8ac7e2f4},
	affiliations = {Centre for Learning Analytics, Faculty of Information Technology, Monash University, VIC, Australia; Centro de Tecnologías de Información, Escuela Superior Politécnica del Litoral, Guayas, Guayaquil, Ecuador; Penn Center for Learning Analytics, University of Pennsylvania, Philadelphia, United States; Institute of Interactive Systems and Data Science, Graz University of Technology, Graz, Austria},
	abstract = {Background: Dashboards play a prominent role in learning analytics (LA) research. In collaboration activities, dashboards can show traces of team participation. They are often evaluated based on students' perceived satisfaction and engagement with the dashboard. However, there is a notable methodological gap in understanding how these dashboards support the nuanced process of student reflection. Objective: This paper presents empirical evidence on how students from high and low-performing groups reflect individually on their performance while using a Learning Analytics Dashboard (LAD). Methods: We address this in the context of education in healthcare, wherein we captured actions and positioning data from a simulation-based collaborative activity and generated a collaborative LAD. A total of 41 nursing students were invited to participate in a post-hoc semi-structured individual interview to use a collaborative LAD while answering a set of prompts to reflect on their individual and group performance. Students' reflections were coded and analysed using Bain's 5R reflection framework. We used epistemic network analysis to capture the dynamic reflection process and to understand the connections between the reflection stages (from low to high). We compared how different these connections were for students in high and low-performing groups. Results and Conclusions: Our results revealed that most students were only able to achieve low and middle stages of reflection. Yet, students in low-performing groups predominantly followed low-to-middle stages of reflection. In contrast, students from high-performing groups demonstrated the ability to transition between low-to-middle and low-to-high stages of reflection. Based on these findings, we discuss implications for both research and practice, particularly emphasising the necessity to scaffold reflection when using LADs. © 2024 John Wiley & Sons Ltd.},
	author_keywords = {collaboration analytics dashboard; epistemic network analysis; learning analytics dashboards; students' reflection},
	correspondence_address = {V. Echeverria; Centre for Learning Analytics, Faculty of Information Technology, Monash University, 3168, Australia; email: vanessa.echeverria@monash.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Paulsen202414279,
	author = {Paulsen, Lucas and Lindsay, Euan},
	title = {Learning analytics dashboards are increasingly becoming about learning and not just analytics - A systematic review},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {11},
	pages = {14279 – 14308},
	doi = {10.1007/s10639-023-12401-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181498996&doi=10.1007%2fs10639-023-12401-4&partnerID=40&md5=016e883f872b0f990c24a6acba972636},
	affiliations = {Department of Communication & Psychology, Aalborg University, Aalborg, Denmark; Department of Sustainability and Planning, Aalborg University, Aalborg, Denmark},
	abstract = {This systematic review explores the emerging themes in the design and implementation of student-facing learning analytics dashboards in higher education. Learning Analytics has long been criticised for focusing too much on the analytics, and not enough on the learning. The review is then guided by an interest in whether these dashboards are still primarily analytics-driven or if they have become pedagogically informed over time. By mapping the identified themes of technological maturity, informing frameworks, affordances, data sources, and analytical levels over publications per year, the review identifies an emerging trajectory towards student-focused dashboards. These dashboards are informed by theory-oriented frameworks, designed to incorporate affordances that supporting student learning, and realised through integration of more than just activity data from learning management systems – allowing the dashboards to better support students' learnings processes. Based on this emerging trajectory, the review provides a series of design recommendations for student-focused dashboards that are connected to learning sciences as well as analytics. © The Author(s) 2024.},
	author_keywords = {Dashboards; Higher education; Learning analytics; Systematic review; Trajectories},
	correspondence_address = {L. Paulsen; Department of Communication & Psychology, Aalborg University, Aalborg, Denmark; email: lupa@ikp.aau.dk},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Colling2024538,
	author = {Colling, Leona and Kholin, Mareike and Meurers, Detmar},
	title = {A Learning Analytics Dashboard for K-12 English Teachers - Bridging the Gap between Student Process Data and Teacher Needs},
	year = {2024},
	journal = {UMAP 2024 - Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
	pages = {538 – 548},
	doi = {10.1145/3631700.3665228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198949341&doi=10.1145%2f3631700.3665228&partnerID=40&md5=9bc30d392c63e6a59686e4ea4a9f55d1},
	affiliations = {Department of Linguistics, University of Tübingen, Tübingen, Germany; German Institute for Adult Education, Leibniz Centre for Lifelong Learning, Bonn, Germany; Leibniz Institute für Wissensmedien (IWM), Tübingen, Germany},
	abstract = {Educational technologies are being used more and more in secondary school settings. This increases the amount of students' learning related data produced and stored. To keep up with this rise and to get most out of the collected data, teachers need digital tools that support and facilitate their pedagogical decision-making process. Learning analytics dashboards can be a good source to provide teachers with necessary insights into their students' learning processes. However, for such tools to be effective and actionable, they have to be aligned with teachers' needs and thus, provide and visualize data in a concise and structured way. We therefore conducted a survey study with 11 English teachers from K-12 secondary schools in Germany who evaluated the assumed usefulness of possible dashboard features. Based on these findings, we developed a teacher dashboard incorporating the most desired functionalities, such as a quickly accessible summary of strengths, weaknesses and support needs, or an overview of current misconceptions and competencies alongside additional metrics in order to support multiple teaching practices. The implementation and the underlying calculations are described, focusing on the importance of learners' process data to provide teachers with a detailed and revealing view on their students' and class learning states. In an evaluation study of the dashboard's prototype with mock data, teachers (n=6) gave high ratings for the dashboard's usability. © 2024 Owner/Author.},
	author_keywords = {computer-assisted language learning; intelligent tutoring systems; learning analytics; teacher dashboard},
	keywords = {Computer aided instruction; Decision making; Digital devices; E-learning; Learning systems; Linguistics; Computer assisted language learning; Intelligent tutoring; Intelligent tutoring system; Learning analytic; Process data; Secondary schools; Student learning; Teacher dashboard; Teachers'; Tutoring system; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070466-6},
	language = {English},
	abbrev_source_title = {UMAP - Adjun. Proc. ACM Conf. User Model., Adapt. Personal.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{de Vreugd2024249,
	author = {de Vreugd, Lars and van Leeuwen, Anouschka and Jansen, Renée and van der Schaaf, Marieke},
	title = {Learning Analytics Dashboard Design and Evaluation to Support Student Self-Regulation of Study Behaviour},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {3},
	pages = {249 – 262},
	doi = {10.18608/jla.2024.8529},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213828511&doi=10.18608%2fjla.2024.8529&partnerID=40&md5=6597766ea213c2b986dced0695fb4a2c},
	affiliations = {Department of Education, Utrecht University, Heidelberglaan 1, Utrecht, 3584 CS, Netherlands; Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Heidelberglaan 100, Utrecht, 3508 GA, Netherlands},
	abstract = {For university students, self-regulation of study behaviour is important. However, students are not always capable of effective self-regulation. Providing study behaviour information via a learning analytics dashboard (LAD) may support phases within self-regulated learning (SRL). However, it is unclear what information a LAD should provide, how to present information in a usable manner, and what the information’s perceived usefulness is in supporting self-regulation of study behaviour. This study entails a sequential mixed design: assessing information needs in focus groups (n=7), exploring usability via think-aloud interviews (n=8), assessing usability with the System Usability Scale (n=42), and assessing perceived usefulness via interviews (n=16). Results showed that students and tutors agreed on the relevance of the constructs chosen from literature but differed in ranking the importance of new constructs. Usability exploration led to several design improvements. Perceived usefulness assessment showed the LAD supported the appraisal of study behaviour. A need for reference frames to facilitate data interpretation was vocalized. Impacts on study behaviour varied, possibly because preparatory activities were not used. Impact could be improved by further integrating the LAD into existing learning processes. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {dashboard design; higher education; Learning analytics dashboard (LAD); needs assessment; perceived usefulness; self-regulated learning (SRL); usability test},
	correspondence_address = {L. de Vreugd; Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Utrecht, Heidelberglaan 100, 3508 GA, Netherlands; email: l.b.devreugd-2@umcutrecht.nl},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Berková202416441,
	author = {Berková, Kateřina and Chalupová, Martina and Smrčka, František and Musil, Marek and Frendlovská, Dagmar},
	title = {A design of the panel for the progress and formative self-assessment detection in the learning analytics},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {13},
	pages = {16441 – 16467},
	doi = {10.1007/s10639-024-12496-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184472480&doi=10.1007%2fs10639-024-12496-3&partnerID=40&md5=13ab0cafe79963a4cc3250d81b6e0e54},
	affiliations = {Department of Economic Teaching Methodology, Faculty of Finance and Accounting, Prague University of Economics and Business, W. Ch. Square 4, Prague, 130 67, Czech Republic; Department of Economic Studies, College of Polytechnics Jihlava, Tolstého 16, Jihlava, Czech Republic; Department of Technical Studies, College of Polytechnics Jihlava, Tolstého 16, Jihlava, Czech Republic},
	abstract = {Learning analytics dashboards (LADs) are very important tools for contemporary education. Not only researchers, but also schools at different levels of education and students are evaluating in this way today. A large number of studies have addressed the issue, but there are few studies that have explored the possibilities of transferring the semaphore method of formative assessment and self-assessment to the digital form of LADs. This study responds to the given absence and illuminates the built environment of the panel and its various functionalities using a prototype LAD. The paper contains a block diagram and a use case that can be used to create an application. This study includes evidence based on guided interviews with 8 teacher-academics from an international university setting on the usefulness of LAD features, the suitability of the semaphore method, and the optimal frequency of teacher assessment and student self-assessment. The study revealed that the most useful elements were considered to be the simplicity of the dashboard, a user-friendly environment, the semaphore method allowing scaling of scores, and also colour, and the comparison of teacher evaluation and student self-assessment. The semaphore method is attractive because of its simplicity, clarity in assessment and transparency in tracking progress. The proposed LAD allows the same competency to be assessed several times in succession as part of progress monitoring. It is optimal to assess three times per semester in university settings. A practical implication of the study is the use of the LAD for the purpose of analyzing the causes in success rates at the level of degree programs, faculties or universities. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Block diagram; Formative assessment; Learning analytics dashboard; Qualitative Research; Self-assessment detection; Semaphore method},
	correspondence_address = {K. Berková; Department of Economic Teaching Methodology, Faculty of Finance and Accounting, Prague University of Economics and Business, Prague, W. Ch. Square 4, 130 67, Czech Republic; email: katerina.berkova@vse.cz},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Valtonen2025601,
	author = {Valtonen, Teemu and Paavilainen, Teija and López-Pernas, Sonsoles and Saqr, Mohamed and Hirsto, Laura},
	title = {Elementary and Secondary School Teachers’ Perceptions of Learning Analytics: A Qualitative Approach},
	year = {2025},
	journal = {Technology, Knowledge and Learning},
	volume = {30},
	number = {2},
	pages = {601 – 619},
	doi = {10.1007/s10758-025-09847-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004350568&doi=10.1007%2fs10758-025-09847-5&partnerID=40&md5=3505f1cec799f8c0b81850c8f2dcd2b7},
	affiliations = {Faculty of Philosophy, School of Applied Educational Science and Teacher Education, University of Eastern Finland, Joensuu, Finland; Facuty of Science, Forestry and Technology, School of Computing, University of Eastern Finland, Joensuu, Finland},
	abstract = {This study focuses on learning analytics from the perspective of elementary and secondary classroom teachers (grades one to nine). The aim is to explore teachers’ perceptions about the use of learning analytics, the challenges and opportunities associated with the tools, and the future of the analytics. The research is based on qualitative data: open-ended responses from 144 teachers. Analysis was conducted using qualitative content analysis and latent class analysis. The results highlight the prominent role of simple drill and practice applications with dashboards and differing teacher perceptions of analytics. Learning analytics helps teachers better understand class learning activities, focus their attention and attain professional development goals. Challenges discussed include the need for new skill development, increased workloads and pedagogical limitations of the current technology. The study shows the necessity for more versatile learning analytic tools with diverse pedagogical practices. It also demonstrates that teachers’ skills must be enhanced to use analytics for pedagogically sound actions. © The Author(s) 2025.},
	author_keywords = {Classroom; Elementary level; Latent class analysis; Learning analytics; Qualitative research; Secondary level; Teachers},
	keywords = {Classroom; Elementary levels; Elementary schools; Latent class analysis; Learning analytic; Qualitative research; Secondary level; Secondary schools; Teachers'; Teachers' perceptions; Teaching},
	correspondence_address = {T. Valtonen; Faculty of Philosophy, School of Applied Educational Science and Teacher Education, University of Eastern Finland, Joensuu, Finland; email: Teemu.valtonen@uef.fi},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shegupta2024,
	author = {Shegupta, Ummay Ubaida and Islam, Md Shoriful and Hardt, Wolfram},
	title = {Predictive Learning Analytics Utilizing Formative Assessments and Recommender System for Study Success},
	year = {2024},
	journal = {ISCSET 2024 - 13th International Symposium on Computer Science and Educational Technology},
	doi = {10.1109/ISCSET58624.2024.10807906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215514108&doi=10.1109%2fISCSET58624.2024.10807906&partnerID=40&md5=5bfdacfd2027f345951539826b423176},
	affiliations = {Chemnitz University of Technology, Faculty of Computer Science, Chemnitz, Germany},
	abstract = {Learning analytics aims to understand, intervene, optimize, and improve learning. It deploys data produced from students' learning and learning environment. Within this do-main, predictive learning analytics has emerged as a transformative paradigm in education, leveraging data-driven methodologies to forecast student performance. This study represents the technical realization of a predictive learning analytics system using the data from formative assessments and recommendation system. Providing the pedagogical embeddement of the formative assessments along with educational recommender system in a hybrid learning environment, this study shows a prototype of predictive analytics and visualization for students and teachers. Formative assessments is rooted with the theory of scaffolding and recommendation plays vital role as consultation. These concepts combinedly shape early detection of tutoring for study success. Henceforth, the digital learning footprints of the students from online assessment and recommender systems contain the clues which can be detected for predetermining the performance. In this study, a predictive learning analytics (PLA) system is designed and developed that detects students at risk and those performing average and above average, enabling the option of interventions. By analyzing student data through Python and ASP.NET MVC, the system can accurately forecasts academic performance. An interactive dashboard allows educators and students to compare predicted outcomes with actual grades. The findings of this study steer to detect the need and point of tutoring support by combining current performance data with predictive insights to initiate study success. © 2024 IEEE.},
	author_keywords = {dashboard; Data visualization; learning analyt-ics; predictive learning analytics; predictive models; study success; tutoring},
	keywords = {Adversarial machine learning; Federated learning; Predictive analytics; Students; Analytics systems; Dashboard; Formative assessment; Learning analyt-ic; Learning environments; Predictive learning analytic; Predictive models; Student learning; Study success; Tutoring; Contrastive Learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039080-3},
	language = {English},
	abbrev_source_title = {ISCSET - Int. Symp. Comput. Sci. Educ. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Toyokawa2025,
	author = {Toyokawa, Yuko and Prasad, Prajish and Horikoshi, Izumi and Majumdar, Rwitajit and Ogata, Hiroaki},
	title = {Supporting program comprehension with data-enhanced active reading},
	year = {2025},
	journal = {Research and Practice in Technology Enhanced Learning},
	volume = {20},
	doi = {10.58459/rptel.2025.20039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217827867&doi=10.58459%2frptel.2025.20039&partnerID=40&md5=80c35e5d2e8a10b5275ddd9f5a7a60f4},
	affiliations = {Graduate School of Informatics, Kyoto University, Yoshidahonmachi, Sakyo Ward, Kyoto, 606-8501, Japan; School of Computing and Data Sciences, FLAME University, Maharashtra, Pune, India; Academic Center for Computing and Media Studies, Kyoto University, Yoshidahonmachi, Sakyo Ward, Kyoto, 606-8501, Japan; Research and Educational Institute for Semiconductors and Informatics, Kumamoto University, 2-39-1 Kurokami, Chuo-Ku, Kumamoto, Kumamoto City, 860-0862, Japan},
	abstract = {This study proposes a novel pedagogical approach to applying active reading (AR) strategies and the learning analytics dashboard to program comprehension (PC) in programming courses. The objective was to visualize the code-reading behaviors of novice programming learners using learning logs and promote code comprehension. The strategy was applied to students in computer science classes at a liberal arts college in India. The results show that the utilization of the dashboard positively influenced students’ learning behaviors outside the classroom. It was recognized as an effective means of supporting PC, highlighting the need to elaborate on how to adopt dashboards in code reading tasks. The study confirms that reflecting on learning using the dashboard can promote learners’ metacognitive skills, regardless of subject or language. It contributes to AR research by demonstrating new practical benefits of AR strategies for PC. © The Author(s).},
	author_keywords = {Active reading; Learning analytics; Program comprehension},
	correspondence_address = {Y. Toyokawa; Graduate School of Social Informatics, Kyoto University, Japan Academic Center for Computing and Media Studies, Kyoto University, Japan; email: toyokawa.yuko.2j@kyoto-u.ac.jp.jp},
	publisher = {Asia-Pacific Society for Computers in Education},
	issn = {17937078},
	language = {English},
	abbrev_source_title = {Res. Pract. Technol. Enhanc.  Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Hershkovitz2024,
	author = {Hershkovitz, Arnon and Ambrose, G. Alex and Soffer, Tal},
	title = {Instructors’ Perceptions of the Use of Learning Analytics for Data-Driven Decision Making},
	year = {2024},
	journal = {Education Sciences},
	volume = {14},
	number = {11},
	doi = {10.3390/educsci14111180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210177313&doi=10.3390%2feducsci14111180&partnerID=40&md5=a40be3f43f238df142389ce8a0c6d0c0},
	affiliations = {Department of Mathematics, Science, and Technology Education, Tel Aviv University, Tel Aviv-Yafo, 6997801, Israel; Kaneb Center for Teaching Excellence, University of Notre Dame, Notre Dame, 46556, IN, United States; Virtual TAU, The Center for Digital Pedagogy, School of Education, Tel Aviv University, Tel Aviv-Yafo, 6997801, Israel},
	abstract = {In recent years, much effort has been put into developing dedicated dashboards for instructors, in which data about students’ activity are presented. However, in many cases, such endeavors take a top-down approach and do not involve instructors in the design process. In this paper, we present a study of instructors and teaching assistants in a research university in Israel (N = 253) who responded to an online questionnaire regarding their perceptions of data on students’ activity on course websites. Specifically, they were asked about the types of data they were most interested in, the aspects of student learning that they would consider important, and the actions they would take upon viewing the data. Overall, we found that participants’ scores were medium-high (2.5–3.5 on a 5-point Likert scale), with scores being higher for women compared with men and positively correlated with experience with Moodle. An overarching theme arises from our analyses of instructors’ interests and intentions, which portrays their idea of teaching as somewhat traditional and instructor-centered; however, their declared actions make it clear that they are willing to make some desirable changes to the benefits of students. Finally, we found that instructors’ perceptions of data use and data importance are positive predictors of taking action upon viewing student data. © 2024 by the authors.},
	author_keywords = {data-driven decision making; instructors’ perceptions; learning analytics; student data},
	correspondence_address = {A. Hershkovitz; Department of Mathematics, Science, and Technology Education, Tel Aviv University, Tel Aviv-Yafo, 6997801, Israel; email: arnonhe@tauex.tau.ac.il},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Li2025,
	author = {Li, Qiujie and Jung, Yeonji and Wise, Alyssa Friend},
	title = {How instructors use learning analytics: the pivotal role of pedagogy},
	year = {2025},
	journal = {Journal of Computing in Higher Education},
	doi = {10.1007/s12528-025-09432-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217647590&doi=10.1007%2fs12528-025-09432-w&partnerID=40&md5=d71226341addf308086d08b497a1ee6b},
	affiliations = {Learning Sciences and Assessment Academic Group, National Institute of Education, Nanyang Technological University, 1 Nanyang Walk, Singapore, 637616, Singapore; Department of Instruction and Curriculum Leadership, The University of Memphis, 3798 Walker Ave, Memphis, 38152, TN, United States; LIVE Learning Innovation Incubator, Vanderbilt University, 1400 18th Ave S, Nashville, 37212, TN, United States},
	abstract = {This study fills a gap in knowledge regarding experienced instructors’ use of learning analytics, focusing on differences in their approach, the knowledge and skills they activate, and the development of these knowledge and skills. Through a qualitative analysis of think-aloud interviews with 13 analytics-experienced instructors, two distinct profiles of analytics use emerged. Instructors in the first profile prioritized monitoring student engagement and performance to foster desirable behaviors, using analytics to align students with course expectations. Instructors in the second profile focused on understanding student perceptions of learning, aligning the course design with diverse learning behaviors and needs. To arrive at such use, instructors went beyond mere acquisition of technical knowledge to also integrate pedagogical knowledge into their analytics practices. Lastly, the study uncovered specific learning analytics supports, such as ongoing individual consultations, invaluable for developing the needed technical and pedagogical knowledge. Together, the results of this study reveal the pivotal role of pedagogy in analytics use, calling for refinement of conceptual models and tailoring of practical support for instructors. © The Author(s) 2025.},
	author_keywords = {Data-informed decision making; Instructional dashboards; Instructional improvement; Learning analytics; Pedagogical support},
	correspondence_address = {Y. Jung; Department of Instruction and Curriculum Leadership, The University of Memphis, Memphis, 3798 Walker Ave, 38152, United States; email: yeonji.jung@memphis.edu},
	publisher = {Springer},
	issn = {10421726},
	language = {English},
	abbrev_source_title = {J. Comput. High. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Lubbe2025,
	author = {Lubbe, Anitia and Marais, Elma and Kruger, Donnavan},
	title = {Cultivating independent thinkers: The triad of artificial intelligence, Bloom’s taxonomy and critical thinking in assessment pedagogy},
	year = {2025},
	journal = {Education and Information Technologies},
	doi = {10.1007/s10639-025-13476-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000043525&doi=10.1007%2fs10639-025-13476-x&partnerID=40&md5=6d6a9bd0ae009bc40960351c650d25d1},
	affiliations = {Research Unit Self-Directed Learning, North-West University, Potchefstroom, South Africa; Research Unit Community-Based Educational Research, North-West University, Potchefstroom, South Africa},
	abstract = {Amalgamating generative artificial intelligence (Gen AI), Bloom’s taxonomy and critical thinking present a promising avenue to revolutionize assessment pedagogy and foster higher-order cognitive skills needed for learning autonomy in the domain of self-directed learning. Gen AI, a subset of artificial intelligence (AI), has emerged as a frontrunner in creative tasks, revolutionizing various domains such as art, music, writing and design and showcasing its ability to generate original content across various domains, including education. Incorporating social, cultural, economic and pedagogical dimensions, AI in education encompasses the incorporation of AI technologies like intelligent tutoring systems, chatbots, robots, learning analytics dashboards, adaptive learning systems and automated assessment to bolster and elevate the educational process. The significance of the impact on the creativity component of Krathwohl’s revised Bloom’s taxonomy arises from the utilization of Gen AI in creative tasks, which prompts concerns regarding the authenticity and originality of AI-generated content. This conceptual research study seeks to investigate the affordances of this amalgamation and aims to reframe the higher cognitive levels of Bloom's taxonomy to enhance critical thinking and self-directed learning among students. This study grounds the reader in the existing literature and sets a course for where research in this field should be heading, thus adding value, rather than only providing an overview of the literature. The overall aim of this research was to explore the affordances of the amalgamation of AI, Bloom’s taxonomy and critical thinking to support assessment pedagogy for self-directed learning. This paper identifies the gap in the current literature about reconceptualizing assessment pedagogy for developing higher-order thinking skills in a Gen AI higher education landscape. This paper presents a case of revisiting Bloom’s taxonomy, advocating the importance of AI fluency and assessment literacy for the development of critical thinking skills and self-directed learning. © The Author(s) 2025.},
	author_keywords = {Artificial intelligence; Assessment pedagogy; Bloom’s taxonomy; Critical thinking; Generative artificial intelligence (Gen AI); Self-directed learning},
	correspondence_address = {A. Lubbe; Research Unit Self-Directed Learning, North-West University, Potchefstroom, South Africa; email: Anitia.Lubbe@nwu.ac.za},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Alfredo202462,
	author = {Alfredo, Riordan and Echeverria, Vanessa and Zhao, Linxuan and Lawrence, Luettamae and Fan, Jie Xiang and Yan, Lixiang and Li, Xinyu and Swiecki, Zachari and Gašević, Dragan and Martinez-Maldonado, Roberto},
	title = {Designing a Human-Centred Learning Analytics Dashboard In-Use},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {3},
	pages = {62 – 81},
	doi = {10.18608/jla.2024.8487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213957633&doi=10.18608%2fjla.2024.8487&partnerID=40&md5=199c9741abf6e78e6bb80429646d42d0},
	affiliations = {Centre for Learning Analytics Monash (CoLAM), Faculty of Information Technology (FIT), Monash University, Australia; CoLAM, FIT at Monash University, Australia; Escuela Superior Politécnica del Litoral, Guayaquil, Ecuador; Utah State University, Logan, 84321, UT, United States},
	abstract = {Despite growing interest in applying human-centred design methods to create learning analytics (LA) systems, most efforts have concentrated on initial design phases, with limited exploration of how LA tools and practices can co-evolve during the actual learning and teaching activities. This paper examines how a human-centred LA dashboard can be further refined and adapted by teachers while actively using it in a real-world scenario (i.e., design-in-use), beyond its intended design (i.e., design-for-use). We use instrumental genesis as a theoretical lens to analyze the temporary and permanent instrumentalization of design features and individual and collective instrumentation of the LA dashboard. The analysis of semi-structured individual interviews with five nursing teachers who used an LA dashboard to guide team reflections with 224 students (56 teams) revealed technical and pedagogical changes that occurred in both the system’s features (instrumentalization) and teaching practices (instrumentation). We found that teachers adopted the LA dashboard beyond initially intended ways by (i) providing emotional support with the analytics, (ii) reducing details in AI-powered data visualizations for easier comprehension, (iii) creating data narratives to address data limitations, and (iv) collectively developing new practices to use the LA dashboard for co-teaching. Therefore, teachers’ design-in-use of the LA dashboard highlights the ongoing need for design improvements to address challenges posed by dynamic data and complex algorithms underlying AI and analytics interfaces. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {AI-powered; co-design; dashboard; Design-in-use; human-centred learning analytics; instrumental genesis; nursing education},
	correspondence_address = {R. Alfredo; Centre for Learning Analytics Monash (CoLAM), Faculty of Information Technology (FIT), Monash University, Australia; email: riordan.alfredo@monash.edu; R. Martinez-Maldonado; CoLAM, FIT at Monash University, Australia; email: roberto.martinezmaldonado@monash.edu},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Hatala202441,
	author = {Hatala, Marek and Nazeri, Sina},
	title = {Associations between Students’ Standing Seen in Learning Analytics Dashboards and Their Following Learning Behaviours: A Study of Three Reference Frames},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {3},
	pages = {41 – 61},
	doi = {10.18608/jla.2024.8547},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213727922&doi=10.18608%2fjla.2024.8547&partnerID=40&md5=54bf9f494d4ddef5e77a11a0d4b07402},
	affiliations = {School of Interactive Arts and Technology, Simon Fraser University, Surrey, BC, Canada},
	abstract = {An essential part of making dashboards more effective in motivating students and leading to desirable behavioural change is knowing what information to communicate to the student and how to frame and present it. Most of the research studying dashboards’ impact on learning analyzes learning indicators of students as a group. Understanding how a student’s learning unfolds after viewing the dashboard is necessary for personalized dashboard selection and its content. In the context of the discussion activity, we analyzed 28,290 actions of 896 students after they saw their learning status on the dashboards, which were integrated into 21 discussions in 11 courses. We provide a comparative perspective on three dashboard types: the class average, the leaderboard, and message-quality dashboards. Our results indicate that students’ behaviours after viewing three dashboards were associated with their displayed standing in the discussion: views showing the student’s status below the frame of reference were associated with a higher likelihood of posting, and views of the student outperforming the norm with diminished further posting, although demonstrating higher discussion engagement. We reiterate a need to understand the impact of dashboard states on students’ behaviour, creating a foundation for a personalized selection of dashboard views based on individual students’ standing. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {asynchronous online discussions; class average; leaderboard; learning behaviour; Student-facing dashboards},
	correspondence_address = {M. Hatala; School of Interactive Arts and Technology, Simon Fraser University, Surrey, Canada; email: mhatala@sfu.ca},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Gallagher2024742,
	author = {Gallagher, Timothy and Slof, Bert and van der Schaaf, Marieke and Toyoda, Ryo and Tehreem, Yusra and Garcia Fracaro, Sofia and Kester, Liesbeth},
	title = {Reference frames for learning analytics dashboards: The progress and social reference frame and occupational self-efficacy},
	year = {2024},
	journal = {Journal of Computer Assisted Learning},
	volume = {40},
	number = {2},
	pages = {742 – 760},
	doi = {10.1111/jcal.12912},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178236441&doi=10.1111%2fjcal.12912&partnerID=40&md5=e6cd746a5088d47e5af5b224a7ab4be7},
	affiliations = {Education Department, Utrecht University, Utrecht, Netherlands; Curriculum Research, Netherlands Institute for Curriculum Development, Amersfoort, Netherlands; Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Utrecht, Netherlands; School of Engineering (Chemical Engineering), Newcastle University, Newcastle Upon Tyne, United Kingdom; Faculty of Technology, University of Applied Sciences Emden/Leer, Emden, Germany; Cluster of Excellence Cognitive Interaction Technology, Bielefeld University, Bielefeld, Germany; Site Management - Group Engineering, Merck KGaA, Darmstadt, Germany; Chemical Engineering, KU Leuven, Leuven, Belgium},
	abstract = {Background: The potential of learning analytics dashboards in virtual reality simulation-based training environments to influence occupational self-efficacy via self-reflection phase processes in the Chemical industry is still not fully understood. Learning analytics dashboards provide feedback on learner performance and offer points of comparison (i.e., comparison with one's own past performance or comparison with peer performance) to help learners make sense of their feedback. Objectives: We present a theoretical framework for describing learning analytics reference frames and investigate the impact of feedback delivered through dashboards with different reference frames on occupational self-efficacy, while controlling for workplace self-reflection. Methods: This experimental study engaged 42 chemical operator employees, aged between 18 and 55 years, each with at least one year of experience. We utilised a two-group design to ask two research question each with three competing hypotheses related to changes in occupational self-efficacy, employing Bayesian informative hypothesis evaluation. Results and Conclusions: Results for the primary research question suggest that dashboards with progress reference frames do not elicit greater change to self-efficacy than those with social reference frames, however, they may elicit equal change. Furthermore, dashboards with social reference frames may elicit greater change to self-efficacy than those with progress reference frames. Exploratory results found that dashboards with progress reference frames may elicit greater positive directional change than those with social reference frames and that they may elicit equal directional change. These findings contribute to the understanding of self-efficacy beliefs within the Chemical industry, with potential impacts on skill development. The research may inform the design of targeted interventions and training programs to influence self-efficacy. From a practical perspective, this research suggests that careful consideration is needed when choosing reference frames in learning analytics dashboards due to their potential consequences on the formation of learner self-efficacy. © 2023 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {learning analytics dashboards; reference frames; self-efficacy; self-reflection; self-regulated learning; social comparison},
	correspondence_address = {T. Gallagher; Utrecht, Heidelberglaan 1, CS, R3584, Netherlands; email: t.r.gallagher@uu.nl},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Li2025,
	author = {Li, Kam Cheong and Wong, Billy Tak-Ming and Liu, Mengjin},
	title = {Development of a multi-model analytics system to enhance decision-making in student admission},
	year = {2025},
	journal = {Interactive Technology and Smart Education},
	doi = {10.1108/ITSE-12-2024-0328},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004035656&doi=10.1108%2fITSE-12-2024-0328&partnerID=40&md5=cad9c3f9108601c217ddb91d502ec51c},
	affiliations = {Institute for Research in Open and Innovative Education, Hong Kong Metropolitan University, Hong Kong; University Engagement Office, Hong Kong Baptist University, Hong Kong},
	abstract = {Purpose: Student admission and enrolment are pivotal processes for universities, directly influencing institutional planning and academic outcomes. To enhance this decision-making process, this paper aims to present the development of a multi-model analytics system to predict the likelihood of student candidates accepting admission offers and achieving good academic results. Design/methodology/approach: The multi-model analytics system integrates six machine learning models to support data classification and regression. A majority voting approach was adopted to combine the results from the top three models and generate a comprehensive prediction. In addition, interactive analytics dashboards were developed to facilitate data visualisation, enabling stakeholders to derive actionable insights from admission trends and outcomes. Findings: Evaluation results showed that the system achieved an accuracy of 62%, a recall of 83% and a precision of 63%. These results demonstrate the system’s capability in forecasting student admission and enrolment, with a particular strength in identifying students who ultimately enrolled in a programme. Practical implications: Beyond student recruitment, the system supports strategic planning, resource allocation and the development of teaching and learning accommodations. By analysing trends in students’ background information, universities can better align their offerings with the needs and preferences of incoming cohorts. Originality/value: This study introduces a novel multi-model analytics approach to support student admission and enrolment. The system’s predictive capabilities and visualisation tools offer a scalable solution for enhancing institutional decision-making and operational efficiency. © 2025, Emerald Publishing Limited.},
	author_keywords = {Academic analytics; Dashboard; Learning analytics; Machine learning; Predictive analytics; Student admission},
	correspondence_address = {B.T.-M. Wong; Institute for Research in Open and Innovative Education, Hong Kong Metropolitan University, Hong Kong; email: tamiwong@hkmu.edu.hk},
	publisher = {Emerald Publishing},
	issn = {17415659},
	language = {English},
	abbrev_source_title = {Interact. Technol. Smart Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Soltani2025392,
	author = {Soltani, Kaouther and Hocine, Nadia and Sehaba, Karim},
	title = {A Systematic Literature Review of Adaptive Collaborative Systems Based on Dashboards},
	year = {2025},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {1},
	pages = {392 – 399},
	doi = {10.5220/0013286300003932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003624776&doi=10.5220%2f0013286300003932&partnerID=40&md5=d188fa8934d086b00472dda3d7bbe712},
	affiliations = {CSTL laboratory, University of Mostaganem, Av. Hamadou Hossine, Mostaganem, Algeria},
	abstract = {Collaborative learning plays an important role in improving individuals’ critical 21st century skills including teamwork, creativity, and critical thinking. Research studies in computer-supported collaborative learning relied on multiple technologies and analytics methods to analyze team members’ interaction with the learning system. They generally seek to assess and support collaborative learning and aid instructors to orchestrate the classroom in co-located collaboration group settings. To enhance awareness among students and teachers about collaboration, learning systems often offer dashboards with visual presentations of educational data and collaborative work progress. Despite the growing research interest on adapting the systems for collaborative learning support, only a few studies investigated how dashboards can be adapted to improve students’ learning and collaboration skills. This paper systematically reviewed research studies on adaptive learning systems based on dashboards, following the PRISMA protocol. The objective is to examine the role of dashboards in customizing learning systems and enhancing collaborative learning and teaching. This could pave the way for research opportunities in designing and developing future adaptive dashboards that foster collaborative learning. Copyright © 2025 by SCITEPRESS - Science and Technology Publications, Lda.},
	author_keywords = {Adaptation; Computer-Supported Collaborative Learning; Dashboards; Learning Analytics},
	keywords = {Engineering education; Human engineering; Teaching; Adaptation; Collaborative learning; Collaborative systems; Computer Supported Collaborative Learning; Critical thinking; Dashboard; Learning analytic; Multiple technology; Research studies; Systematic literature review; Students},
	editor = {du Boulay B. and Di Mascio T. and Tovar E. and Meinel C.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758746-7},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hutchins2024802,
	author = {Hutchins, Nicole M. and Biswas, Gautam},
	title = {Co-designing teacher support technology for problem-based learning in middle school science},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {3},
	pages = {802 – 822},
	doi = {10.1111/bjet.13363},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165633373&doi=10.1111%2fbjet.13363&partnerID=40&md5=6a3381f64cd210936c3380f4515aa5e7},
	affiliations = {School of Engineering Institute for Software Integrated Systems, Vanderbilt University, Nashville, TN, United States},
	abstract = {This paper provides an experience report on a co-design approach with teachers to co-create learning analytics-based technology to support problem-based learning in middle school science classrooms. We have mapped out a workflow for such applications and developed design narratives to investigate the implementation, modifications and temporal roles of the participants in the design process. Our results provide precedent knowledge on co-designing with experienced and novice teachers and co-constructing actionable insight that can help teachers engage more effectively with their students' learning and problem-solving processes during classroom PBL implementations. Practitioner notes What is already known about this topic Success of educational technology depends in large part on the technology's alignment with teachers' goals for their students, teaching strategies and classroom context. Teacher and researcher co-design of educational technology and supporting curricula has proven to be an effective way for integrating teacher insight and supporting their implementation needs. Co-designing learning analytics and support technologies with teachers is difficult due to differences in design and development goals, workplace norms, and AI-literacy and learning analytics background of teachers. What this paper adds We provide a co-design workflow for middle school teachers that centres on co-designing and developing actionable insights to support problem-based learning (PBL) by systematic development of responsive teaching practices using AI-generated learning analytics. We adapt established human-computer interaction (HCI) methods to tackle the complex task of classroom PBL implementation, working with experienced and novice teachers to create a learning analytics dashboard for a PBL curriculum. We demonstrate researcher and teacher roles and needs in ensuring co-design collaboration and the co-construction of actionable insight to support middle school PBL. Implications for practice and/or policy Learning analytics researchers will be able to use the workflow as a tool to support their PBL co-design processes. Learning analytics researchers will be able to apply adapted HCI methods for effective co-design processes. Co-design teams will be able to pre-emptively prepare for the difficulties and needs of teachers when integrating middle school teacher feedback during the co-design process in support of PBL technologies. © 2023 British Educational Research Association.},
	author_keywords = {co-design; HLCA; problem-based learning},
	keywords = {Curricula; Design; Engineering education; Human computer interaction; Students; Co-designing; Co-designs; Design-process; HLCA; Middle school; Problem based learning; School teachers; Support technology; Teachers'; Work-flows; Educational technology},
	correspondence_address = {N.M. Hutchins; School of Engineering, Institute for Software Integrated Systems, Vanderbilt University, Nashville, United States; email: nicole.m.hutchins@vanderbilt.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@CONFERENCE{2025,
	title = {15th International Conference on Learning Analytics and Knowledge, LAK 2025},
	year = {2025},
	journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000271466&partnerID=40&md5=e075c052bfd7759f69447b1add722844},
	abstract = {The proceedings contain 100 papers. The topics discussed include: designing visual explanations and learner controls to engage adolescents in AI-supported exercise selection; platform-based adaptive experimental research in education: lessons learned from the digital learning challenge; one size does not fit all: considerations when using webcam-based eye tracking to models of neurodivergent learners’ attention and comprehension; diversity considerations in team formation design, algorithm, and measurement; scaling up collaborative dialogue analysis: an AI-driven approach to understanding dialogue patterns in computational thinking education; TeamTeachingViz: benefits, challenges, and ethical considerations of using a multimodal analytics dashboard to support team teaching reflection; and from complexity to parsimony: integrating latent class analysis to uncover multimodal learning patterns in collaborative learning.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070701-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Anal. Knowl., LAK},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hirsch2024,
	author = {Hirsch, Sunita and Uckelmann, Dieter},
	title = {Effective Feedback Systems in Learning Analytics: Didactic and Psychological Foundations, Implementations, and Perspectives},
	year = {2024},
	journal = {2024 21st International Conference on Information Technology Based Higher Education and Training, ITHET 2024},
	doi = {10.1109/ITHET61869.2024.10837632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218084799&doi=10.1109%2fITHET61869.2024.10837632&partnerID=40&md5=0aff4c29a2dffbf8230e97d4ec83f401},
	affiliations = {Stuttgart University of Applied Sciences, Stuttgart, Germany},
	abstract = {Learning Analytics (LA) and LA-based feedback systems have made substantial advancements, providing tools and frameworks designed to improve educational outcomes. However, their long-term effectiveness is often constrained by a predominant focus on technical elements, which can overshadow crucial didactic, psychological, and design-related considerations. This paper introduces an integrative framework for designing LA-based feedback systems that mitigates these limitations by incorporating insights from cognitive and motivational theories. The framework aims to support the development of learner-centered environments that address various learning needs. Based on this framework, practical considerations and recommendations are provided to guide the implementation of feedback systems that move beyond technical constraints. An implemen-tation example illustrates how the framework can be applied using real-time data analysis and learner assessments aiming to improve the usability, effectiveness, and acceptance of feedback systems. This approach highlights the importance of integrating multidisciplinary perspectives in LA to achieve meaningful and impactful educational practices across diverse contexts. © 2024 IEEE.},
	author_keywords = {Dashboard; Educational Technology; Feedback; Learner-Centered Design; Learning Analytics},
	keywords = {Adversarial machine learning; Federated learning; Dashboard; Feedback systems; Integrative framework; Learner-centred; Learner-centred design; Learning analytic; Multidisciplinary perspectives; Real time data analysis; Technical constraints; Contrastive Learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151663-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Inf. Technol. Based High. Educ. Train., ITHET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sloan-Lynch20241,
	author = {Sloan-Lynch, Jay and Morse, Robert},
	title = {Equity-Forward Learning Analytics: Designing a Dashboard to Support Marginalized Student Success},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {1 – 11},
	doi = {10.1145/3636555.3636844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187554250&doi=10.1145%2f3636555.3636844&partnerID=40&md5=3eb86ccdd80ba7e2c71aec9c51e47e28},
	affiliations = {Pearson, United States; Ivy Tech Community College, United States},
	abstract = {Student outcomes in US higher education exhibit deep and persistent inequities. The continued underperformance of historically marginalized students remains a serious concern across higher education, reflected in increasing efforts among institutions to infuse diversity, equity, and inclusion into their academic and social communities. Yet despite widespread recognition of these inequities, few studies in the learning analytics literature engage in practical ways with issues of educational equity or DEI considerations. In this paper, we share our work supporting a large college's strategic DEI goals through the creation of a Course Diversity Dashboard informed by research into how students' study behaviors and performance interact with their gender and ethnic identities to impact course outcomes. The dashboard enables users to explore inequalities in course outcomes and take concrete actions to improve student study strategies, time management, and prior knowledge. Results from our research revealed the existence of previously hidden learner inequities in all courses included in our study as well as critical differences in underrepresented minority students' prior knowledge. And while we did not find evidence of meaningful differences in the study behaviors of student subgroups, our findings further validate the effectiveness of evidence-informed study strategies in an authentic educational setting. © 2024 Owner/Author.},
	author_keywords = {DEI; educational equity; learning analytics dashboards; study strategies},
	keywords = {DEI; Educational equity; High educations; Learning analytic dashboard; Prior-knowledge; Student outcomes; Student studies; Student success; Study strategy; Underperformance; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Liu20251745,
	author = {Liu, Yiming and Hu, Xiao and Ng, Jeremy Tzi Dong and Ma, Zhengyang and Lai, Xiaoyan},
	title = {Ready or not? Investigating in-service teachers’ integration of learning analytics dashboard for assessing students’ collaborative problem solving in K–12 classrooms},
	year = {2025},
	journal = {Education and Information Technologies},
	volume = {30},
	number = {2},
	pages = {1745 – 1776},
	doi = {10.1007/s10639-024-12842-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198087614&doi=10.1007%2fs10639-024-12842-5&partnerID=40&md5=6502060e454736e659bcb6930bd7db6a},
	affiliations = {Faculty of Education, The University of Hong Kong, SAR, Hong Kong; Computational Media and Arts Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; School of Educational Sciences, Guangdong Polytechnic Normal University, Guangzhou, China},
	abstract = {Collaborative problem solving (CPS) has emerged as a crucial 21st century competence that benefits students’ studies, future careers, and general well-being, prevailing across disciplines and learning approaches. Given the complex and dynamic nature of CPS, teacher-facing learning analytics dashboards (LADs) have increasingly been adopted to support teachers’ CPS assessments by analysing and visualising various dimensions of students’ CPS. However, there is limited research investigating K-12 teachers’ integration of LADs for CPS assessments in authentic classrooms. In this study, a LAD was implemented to assist K-12 teachers in assessing students’ CPS skills in an educational game. Based on the person-environment fit theory, this study aimed to (1) examine the extent to which teachers’ environmental and personal factors influence LAD usage intention and behaviour and (2) identify personal factors mediating the relationships between environmental factors and LAD usage intention and behaviour. Survey data of 300 in-service teachers from ten Chinese K-12 schools were collected and analysed using partial least squares structural equation modelling (PLS-SEM). Results indicated that our proposed model showed strong in-sample explanatory power and out-of-sample predictive capability. Additionally, subjective norms affected technological pedagogical content knowledge (TPACK) and self-efficacy, while school support affected technostress and self-efficacy. Moreover, subjective norms, technostress, and self-efficacy predicted behavioural intention, while school support, TPACK, and behavioural intention predicted actual behaviour. As for mediation effects, school support indirectly affected behavioural intention through self-efficacy, while subjective norms indirectly affected behavioural intention through self-efficacy and affected actual behaviour through TPACK. This study makes theoretical, methodological, and practical contributions to technology integration in general and LAD implementation in particular. © The Author(s) 2024.},
	author_keywords = {21st century skills; Collaborative problem solving; K-12 teachers; Learning analytics dashboard; Person-environment fit; Technology integration},
	correspondence_address = {Y. Liu; Faculty of Education, The University of Hong Kong, SAR, Hong Kong; email: eduliuym@connect.hku.hk},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Yang202535,
	author = {Yang, Christopher C. Y. and Wu, Jiun-Yu and Ogata, Hiroaki},
	title = {Learning analytics dashboard-based self-regulated learning approach for enhancing students’ e-book-based blended learning},
	year = {2025},
	journal = {Education and Information Technologies},
	volume = {30},
	number = {1},
	pages = {35 – 56},
	doi = {10.1007/s10639-024-12913-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200053203&doi=10.1007%2fs10639-024-12913-7&partnerID=40&md5=00c7803e29cd42813fd3034c86686e88},
	affiliations = {Department of Computer Science, National Taipei University of Education, Taipei, Taiwan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Institute of Education & Center for Teacher Education, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Academic Center for Computing and Media Studies, Kyoto University, Kyoto, Japan},
	abstract = {Blended learning (BL) combines traditional classroom activities with online learning resources, enabling students to obtain higher academic performance through well-defined interactive learning strategies. However, lacking the capacity to self-regulate their learning, many students might fail to comprehensively study the learning materials after face-to-face learning. In this study, a learning analytics dashboard (LAD)-based self-regulated learning (SRL) approach is proposed to enhance the students’ practices of SRL in an e-book-based BL environment. The proposed approach aims to support students to precisely reflect on their face-to-face e-book reading activities, effectively review the e-book learning materials after the face-to-face learning sessions, and, finally, set new goals for their next face-to-face learning session by using a LAD. To evaluate the effects of the proposed approach, a quasi-experimental design was deployed in a university-level course that adopted a BL model. The experimental group learned through the proposed approach using an e-book and the LAD, whereas the control group learned using the conventional BL approach using only the e-book. The results of the one-way analysis of covariance (ANCOVA) and Mann–Whitney U test demonstrate a statistically significant difference (p-value less than 0.01) between both groups in terms of students’ learning outcomes, awareness of SRL, self-efficacy (SE), and e-book reading engagements. This provides educators with evidence of the effectiveness of an explicit SRL approach in BL, which not only improves student learning outcomes from the given course and awareness of self-regulation and SE but also increases course engagement compared to students who learn with conventional BL approaches. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Blended learning; Learning analytics dashboard; Learning outcomes; Reading engagements; Self-regulated learning},
	correspondence_address = {C.C.Y. Yang; Department of Computer Science, National Taipei University of Education, Taipei, Taiwan; email: cyyang@mail.ntue.edu.tw},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Alcock2024316,
	author = {Alcock, Sarah and Rienties, Bart and Aristeidou, Maria and Kouadri Mostéfaoui, Soraya},
	title = {How do visualizations and automated personalized feedback engage professional learners in a Learning Analytics Dashboard?},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {316 – 325},
	doi = {10.1145/3636555.3636886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187556654&doi=10.1145%2f3636555.3636886&partnerID=40&md5=6413d789086359452208644cca85558a},
	affiliations = {Institute of Educational Technology, The Open University, United Kingdom; Computing and Communication, the Open University, United Kingdom},
	abstract = {Learning Analytics Dashboards (LAD) are the subject of research in a multitude of schools and higher education institutions, but a lack of research into learner-facing dashboards in professional learning has been identified. This study took place in an authentic professional learning context and aims to contribute insights into LAD design by using an academic approach in a practice-based environment. An existing storytelling LAD created to support 81 accountants was evaluated using Technology Acceptance Model, finding a learner expectation for clarity, conciseness, understanding and guidance on next steps. High usage levels and a 'take what you need' approach was identified, with all visualizations and automated personalized feedback being considered useful although to varying degrees. Professional learners in this study focus on understanding and acting upon weaknesses rather than celebrating strengths. The lessons for LAD design are to offer choice and create elements which support learners to take action to improve performance at a multitude of time points and levels of success. © 2024 Owner/Author.},
	author_keywords = {accountancy; assessment; data storytelling; feedback; LAD; Learning Analytics Dashboard; personalization; professional learning; Technology Acceptance Model},
	keywords = {Learning systems; Visualization; Accountancy; Assessment; Data storytelling; Learning analytic dashboard; Personalizations; Personalized feedback; Professional learning; School education; Technology acceptance model; Professional aspects},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Herodotou2025306,
	author = {Herodotou, Christothea and Carr, Jessica and Shrestha, Sagun and Comfort, Catherine and Bayer, Vaclav and Maguire, Claire and Lee, John and Mulholland, Paul and Fernandez, Miriam},
	title = {Prescriptive analytics motivating distance learning students to take remedial action: A case study of a student-facing dashboard},
	year = {2025},
	journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
	pages = {306 – 316},
	doi = {10.1145/3706468.3706508},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000261740&doi=10.1145%2f3706468.3706508&partnerID=40&md5=cffb4b95155608ce51b8d7e08856e16c},
	affiliations = {The Open University, Milton Keynes, United Kingdom},
	abstract = {Student-facing learning analytics dashboards aim to help students to monitor their study progress, achieve learning goals and develop self-regulation skills. Only few of them present personalised data visualisations and aim to develop agentic students who take remedial action to improve their study habits, learning and performance. In this paper, a student-facing dashboard, designed following principles of participatory research, was tested with 30 undergraduate students, who engaged with it over a period of 4 to 15 weeks and while studying an online course. This is one of the few dashboards available that presents all different types of analytics to students: descriptive, predictive and prescriptive. A mixed methods approach was used to assess its usefulness and impact on motivation to study and take remedial action to support learning. Data analysis showcased that such a dashboard can be "a roadmap to success"by motivating students to study more and improve their performance, in addition to helping with monitoring, planning and reflection. While all dashboard features were perceived as being useful, special value was placed on prescriptive elements, in particular material recommendations and contacting tutors and university support teams, emphasizing the significance of making explicit on a dashboard the actions students should take to improve their performance. Implications for future studies are discussed. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {learning analytics dashboards; prescriptive analytics; student-facing dashboards},
	keywords = {Adversarial machine learning; Contrastive Learning; Case-studies; Distance-learning; Learning analytic dashboard; Learning goals; Performance; Prescriptive analytic; Remedial actions; Self regulation; Student-facing dashboard; Study habits; Students},
	correspondence_address = {M. Fernandez; The Open University, Milton Keynes, United Kingdom; email: miriam.fernandez@open.ac.uk},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070701-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Anal. Knowl., LAK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Strickroth202538,
	author = {Strickroth, Sven and Kreidenweis, Melanie and Götzfried, Andreas},
	title = {Supporting Agile Classroom Orchestration with a Live Teacher Dashboard},
	year = {2025},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1260 LNNS},
	pages = {38 – 50},
	doi = {10.1007/978-3-031-85652-5_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001255155&doi=10.1007%2f978-3-031-85652-5_4&partnerID=40&md5=604346c4b10c846f287a5b9b347e5a35},
	affiliations = {Institute for Informatics, LMU Munich, Oettingenstraße 67, Munich, 80538, Germany},
	abstract = {This paper presents a real-time teacher dashboard optimized to support agile classroom orchestration based on a Kanban board. The implemented prototype allows teachers to prepare and implement lessons and monitor student progress in real-time. Teachers can easily duplicate Kanban boards for multiple groups and identify groups of students who are falling behind or excelling and may need special support. Students can access and use the prepared Kanban boards in a privacy friendly way, raise their hand virtually, and upload their work for review. The prototype was used and evaluated in two case studies. The results indicate that the developed prototype with its features including the dashboard is usable and helpful for preparing, implementing, and reviewing lessons. Implications and future work are discussed. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Agile Teaching; Learning Analytics; Real-time Dashboard; Teacher Dashboard; Teaching Support Tool},
	keywords = {Teaching; Agile teaching; Kanbans; Learning analytic; Multiple-group; Real- time; Real-time dashboards; Student progress; Teacher dashboard; Teachers'; Teaching support tools; Students},
	correspondence_address = {S. Strickroth; Institute for Informatics, LMU Munich, Munich, Oettingenstraße 67, 80538, Germany; email: sven.strickroth@ifi.lmu.de},
	editor = {Auer M.E. and Rüütmann T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303185651-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Thomas2024404,
	author = {Thomas, Danielle R and Lin, Jionghao and Gatz, Erin and Gurung, Ashish and Gupta, Shivang and Norberg, Kole and Fancsali, Stephen E and Aleven, Vincent and Branstetter, Lee and Brunskill, Emma and Koedinger, Kenneth R},
	title = {Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study Quasi-Experimental Investigation},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {404 – 415},
	doi = {10.1145/3636555.3636896},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187554515&doi=10.1145%2f3636555.3636896&partnerID=40&md5=84ebc13252057d34d88a7f69bed53573},
	affiliations = {Carnegie Mellon University, Pittsburgh, United States; Stanford University, Stanford, United States},
	abstract = {Artificial intelligence (AI) applications to support human tutoring have potential to significantly improve learning outcomes, but engagement issues persist, especially among students from low-income backgrounds. We introduce an AI-assisted tutoring model that combines human and AI tutoring and hypothesize this synergy will have positive impacts on learning processes. To investigate this hypothesis, we conduct a three-study quasi-experiment across three urban and low-income middle schools: 1) 125 students in a Pennsylvania school; 2) 385 students (50% Latinx) in a California school, and 3) 75 students (100% Black) in a Pennsylvania charter school, all implementing analogous tutoring models. We compare learning analytics of students engaged in human-AI tutoring compared to students using math software only. We find human-AI tutoring has positive effects, particularly in student's proficiency and usage, with evidence suggesting lower achieving students may benefit more compared to higher achieving students. We illustrate the use of quasi-experimental methods adapted to the particulars of different schools and data-availability contexts so as to achieve the rapid data-driven iteration needed to guide an inspired creation into effective innovation. Future work focuses on improving the tutor dashboard and optimizing tutor-student ratios, while maintaining annual costs per student of approximately $700 annually. © 2024 Owner/Author.},
	author_keywords = {AI-assisted tutoring; Design-based research; Human-AI tutoring; Tutoring},
	keywords = {Education computing; Iterative methods; Learning systems; Artificial intelligence-assisted tutoring; Design-based research; Experimental investigations; Human-artificial intelligence tutoring; Learning outcome; Learning process; Low incomes; Pennsylvania; Student learning; Tutoring; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kitto202569,
	author = {Kitto, Simon and Chiang, H. L. Michelle and Ng, Olivia and Cleland, Jennifer},
	title = {More, better feedback please: are learning analytics dashboards (LAD) the solution to a wicked problem?},
	year = {2025},
	journal = {Advances in Health Sciences Education},
	volume = {30},
	number = {1},
	pages = {69 – 85},
	doi = {10.1007/s10459-024-10358-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001073525&doi=10.1007%2fs10459-024-10358-8&partnerID=40&md5=380a704b9a1d7e020428df73742a1b8a},
	affiliations = {Lee Kong Chian School of Medicine, Nanyang Technological University, HQ Building, Novena Campus, 11 Mandalay Road, Singapore, 308232, Singapore; National Healthcare Group (NHG), Singapore, Singapore},
	abstract = {There is a long-standing lack of learner satisfaction with quality and quantity of feedback in health professions education (HPE) and training. To address this, university and training programmes are increasingly using technological advancements and data analytic tools to provide feedback. One such educational technology is the Learning Analytic Dashboard (LAD), which holds the promise of a comprehensive view of student performance via partial or fully automated feedback delivered to learners in real time. The possibility of displaying performance data visually, on a single platform, so users can access and process feedback efficiently and constantly, and use this to improve their performance, is very attractive to users, educators and institutions. However, the mainstream literature tends to take an atheoretical and instrumentalist view of LADs, a view that uncritically celebrates the promise of LAD’s capacity to provide a ‘technical fix’ to the ‘wicked problem’ of feedback in health professions education. This paper seeks to recast the discussion of LADs as something other than a benign material technology using the lenses of Miller and Rose’s technologies of government and Barry’s theory of Technological Societies, where such technical devices are also inherently agentic and political. An examination of the purpose, design and deployment of LADs from these theoretical perspectives can reveal how these educational devices shape and govern the HPE learner body in different ways, which in turn, may produce a myriad of unintended– and ironic– effects on the feedback process. In this Reflections article we wish to encourage health professions education scholars to examine the practices and consequences thereof of the ever-expanding use of LADs more deeply and with a sense of urgency. © The Author(s) 2024.},
	author_keywords = {Digital dashboards; Educational technology; Feedback; Health professions education; Learning analytics},
	keywords = {Educational Technology; Feedback; Formative Feedback; Health Occupations; Humans; Learning; constructive feedback; education; educational technology; feedback system; human; learning; medical profession},
	correspondence_address = {J. Cleland; Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore, HQ Building, Novena Campus, 11 Mandalay Road, 308232, Singapore; email: Jennifer.cleland@ntu.edu.sg},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13824996},
	pmid = {39186167},
	language = {English},
	abbrev_source_title = {Adv. Health Sci. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kleimola20254959,
	author = {Kleimola, Riina and Hirsto, Laura and Ruokamo, Heli},
	title = {Promoting higher education students’ self-regulated learning through learning analytics: A qualitative study},
	year = {2025},
	journal = {Education and Information Technologies},
	volume = {30},
	number = {4},
	pages = {4959 – 4986},
	doi = {10.1007/s10639-024-12978-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001063605&doi=10.1007%2fs10639-024-12978-4&partnerID=40&md5=6d5939551ced15608961343b8f16a044},
	affiliations = {Faculty of Education, University of Lapland, Rovaniemi, Finland; School of Applied Educational Science and Teacher Education, University of Eastern Finland, Joensuu, Finland},
	abstract = {Learning analytics provides a novel means to support the development and growth of students into self-regulated learners, but little is known about student perspectives on its utilization. To address this gap, the present study proposed the following research question: what are the perceptions of higher education students on the utilization of a learning analytics dashboard to promote self-regulated learning? More specifically, this can be expressed via the following threefold sub-question: how do higher education students perceive the use of a learning analytics dashboard and its development as promoting the (1) forethought, (2) performance, and (3) reflection phase processes of self-regulated learning? Data for the study were collected from students (N = 16) through semi-structured interviews and analyzed using a qualitative content analysis. Results indicated that the students perceived the use of the learning analytics dashboard as an opportunity for versatile learning support, providing them with a means to control and observe their studies and learning, while facilitating various performance phase processes. Insights from the analytics data could also be used in targeting the students’ development areas as well as in reflecting on their studies and learning, both individually and jointly with their educators, thus contributing to the activities of forethought and reflection phases. However, in order for the learning analytics dashboard to serve students more profoundly across myriad studies, its further development was deemed necessary. The findings of this investigation emphasize the need to integrate the use and development of learning analytics into versatile learning processes and mechanisms of comprehensive support and guidance. © The Author(s) 2024.},
	author_keywords = {Higher education student; Learning analytics; Learning analytics dashboard; Qualitative study; Self-regulated learning},
	correspondence_address = {R. Kleimola; Faculty of Education, University of Lapland, Rovaniemi, Finland; email: rheleniu@ulapland.fi},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Misiejuk202512,
	author = {Misiejuk, Kamila and López-Pernas, Sonsoles and Kaliisa, Rogers and Saqr, Mohammed},
	title = {Mapping the Landscape of Generative Artificial Intelligence in Learning Analytics: A Systematic Literature Review},
	year = {2025},
	journal = {Journal of Learning Analytics},
	volume = {12},
	number = {1},
	pages = {12 – 31},
	doi = {10.18608/jla.2025.8591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001733235&doi=10.18608%2fjla.2025.8591&partnerID=40&md5=53c03aba05c4b4a06676a967ba9d26d7},
	affiliations = {Center of Advanced Technology for Assisted Learning and Predictive Analytics (CATALPA), FernUniversität in Hagen, Universitätsstrasse 27, Hagen, 58097, Germany; School of Computing, University of Eastern Finland, Joensuu Campus, Yliopistokatu 2, Joensuu, FI-80100, Finland; Department of Education, the University of Oslo, Post Box 1092, Blindern, Oslo, 0317, Norway},
	abstract = {Generative artificial intelligence (GenAI) has opened new possibilities for designing learning analytics (LA) tools, gaining new insights about student learning processes and their environment, and supporting teachers in assessing and monitoring students. This systematic literature review maps the empirical research of 41 papers utilizing GenAI and LA and interprets the results through the lens of the LA/EDM process cycle. Currently, GenAI is mostly implemented to automate discourse coding, scoring, or classification tasks. Few papers used GenAI to generate data or to summarize text. Classroom integrations of GenAI and LA mostly explore facilitating human–GenAI collaboration, rather than implementing automated feedback generation or GenAI-powered learning analytics dashboards. Most papers use Generative Adversarial Network models to generate synthetic data, BERT models for classification or prediction tasks, BERT or GPT models for discourse coding, and GPT models for tool integration. Although most studies evaluate the GenAI output, we found examples of using GenAI without the output validation, especially when its output feeds into an LA pipeline aiming to, for example, develop a dashboard. This review offers a comprehensive overview of the field to aid LA researchers in the design of research studies and a contribution to establishing best practices to integrate GenAI and LA. © 2025, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {educational data mining; GenAI; Generative artificial intelligence; learning analytics; systematic review},
	correspondence_address = {K. Misiejuk; Center of Advanced Technology for Assisted Learning and Predictive Analytics (CATALPA), FernUniversität in Hagen, Hagen, Universitätsstrasse 27, 58097, Germany; email: kamila.misiejuk@fernuni-hagen.de},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Poquet20241811,
	author = {Poquet, Oleksandra},
	title = {A shared lens around sensemaking in learning analytics: What activity theory, definition of a situation and affordances can offer},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {4},
	pages = {1811 – 1831},
	doi = {10.1111/bjet.13435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183008290&doi=10.1111%2fbjet.13435&partnerID=40&md5=893f384119c6d2a575a0126e10b0199e},
	affiliations = {Department of Educational Sciences, Technical University of Munich, School of Social Sciences and Technology, München, Germany; Education Futures, Centre for Change and Complexity in Learning, University of South Australia, Adelaide, SA, Australia},
	abstract = {The paper argues that learning analytics as a research field can benefit from a theory-informed shared language to describe sensemaking of learning and teaching data. To make the case for such shared language, first, I critically review prominent sensemaking theories to then demonstrate how studies in learning analytics do not use coherent descriptions of sensemaking, eclectically combining the paradigms that have underlying differences. I then propose a conceptualization of sensemaking that overcomes the differences between these theories and explains how the concepts of activity system, the definition of the situation and affordances can be used to capture individual differences in sensemaking. The paper concludes with a preliminary framework and examples demonstrating its utility in raising new theoretical questions, informing design principles and providing shared language for researchers in learning analytics.Practitioner notesWhat is already known about this topic Sensemaking happens when individuals try to explain unknown situations. Learning analytics uses sensemaking as a lens to understand dashboard use. Systematic analysis of sensemaking is essential for learning analytics. What this paper adds The paper notes that noticing and perceiving are commonly examined in learning analytics on dashboard use. The paper suggests a revision of fundamental assumptions in sensemaking. A paper proposes a toy model of sensemaking that includes operationalization of the definition of the situation, activity where sensemaking happens and processes of noticing and perceiving affordances. Implications for practice and/or policy Learning analytics must examine sensemaking of data about teaching and learning in a systematic manner. Internal perceptions of the social environment and activity that are informed by the data need to be considered in evaluating dashboard use. © 2024 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
	author_keywords = {activity theory; definition of a situation; ecological perception theory; information elaboration; learning analytics; sensemaking},
	keywords = {Educational technology; Activity Theory; Affordances; Definition of a situation; Ecological perception theory; Information elaboration; Learning analytic; Learning and teachings; Research fields; Sense making; Shared language; Activity coefficients},
	correspondence_address = {O. Poquet; Department of Educational Sciences, TUM School of Social Sciences and Technology, Technische Universität München, München, Marsstraße 20-22, 80335, Germany; email: sasha.poquet@tum.de},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gantikow2024347,
	author = {Gantikow, Alexander and Durski, Sara and Isking, Andreas and Libbrecht, Paul and Müller, Wolfgang and Ostermann, Simon and Rebholz, Sandra},
	title = {AI-based analysis of e-portfolios; [KI-basierte Analyse von E-Portfolios]},
	year = {2024},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {P-356},
	pages = {347 – 360},
	doi = {10.18420/delfi2024_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217743008&doi=10.18420%2fdelfi2024_31&partnerID=40&md5=c22364aad05745d1dd5099e25f78faf2},
	affiliations = {Pädagogische Hochschule Weingarten, Kirchplatz 2, Weingarten, 88250, Germany; IU Internationale Hochschule, Juri-Gagarin-Ring 152, Erfurt, 99084, Germany; Deutsches Forschungszentrum für Künstliche Intelligenz, Multilingualität und Sprachtechnologie, Stuhlsatzenhaus 3, Saarbrücken, 66123, Germany; Ostbayerische Technische Hochschule Amberg-Weiden, Kaiser-Wilhelm-Ring 23, Amberg, 92224, Germany},
	author_keywords = {Artificial Intelligence; Dashboard; E-Portfolios; Learning Analytics; Natural Language Processing},
	editor = {Schulz S. and Universitat Hamburg, Mittelweg 177, Hamburg and Kiesler N. and Technische Hochschule Nurnberg Georg Simon Ohm, Kesserplatz 12, Nurnberg},
	publisher = {Gesellschaft fur Informatik (GI)},
	issn = {16175468},
	isbn = {978-388579255-0},
	language = {German},
	abbrev_source_title = {Lect. Notes Informatics (LNI), Proc. - Series Ges. Inform. (GI)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Ali202557,
	author = {Ali, Syed Ibad and Shaikh, Mohammad Shahnawaz and Kelkar, Parineeta and Chowdhury, Soumitra},
	title = {Analyzing and visualizing learning data: A system designer's perspective},
	year = {2025},
	journal = {Revolutionizing Education With Remote Experimentation and Learning Analytics},
	pages = {57 – 68},
	doi = {10.4018/979-8-3693-8593-7.ch004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002674956&doi=10.4018%2f979-8-3693-8593-7.ch004&partnerID=40&md5=c915627224e20baecd8fb040d28b87ba},
	affiliations = {Parul Institute of Engineering and Technology, Parul University, India; Ajeenkya D.Y. Patil University, Pune, India},
	abstract = {In this work, the authors consider learning analytics for primary and secondary schools from the perspective of the designer of a learning system through blockchain. They provide an overview of practically useful analytics techniques with blockchain that describes their applications and specific illustrations. They highlight data biases and caveats that complicate the analysis and its interpretation. Although they intentionally focus on techniques for internal use by designers, many of these techniques may inspire the development of dashboards for teachers or students. They also identify the consequences and challenges for research. © 2025, IGI Global Scientific Publishing.},
	publisher = {IGI Global},
	isbn = {979-836938595-1; 979-836938593-7},
	language = {English},
	abbrev_source_title = {Revolutionizing Educ. With Remote Exp. and Learn. Anal.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Hsu2025,
	author = {Hsu, Chia-Yu and Horikoshi, Izumi and Li, Huiyong and Majumdar, Rwitajit and Ogata, Hiroaki},
	title = {Designing data-informed support for building learning habits in the Japanese K12 context},
	year = {2025},
	journal = {Research and Practice in Technology Enhanced Learning},
	volume = {20},
	doi = {10.58459/rptel.2025.20014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215069844&doi=10.58459%2frptel.2025.20014&partnerID=40&md5=a4a34ca6026d431d96383e6b923d55e2},
	affiliations = {Graduate School of Informatics, Kyoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan; Research Institute for Information Technology, Kyushu University, Japan; Research and Education Institute for Semiconductors and Informatics, Kumamoto University, Japan},
	abstract = {While building proper learning habits has been said to enhance academic performance, it is challenging to give long-term support for building habits in educational contexts due to the lack of continuous tracing of one’s habitual behaviors. With the accumulation of learning logs and the advancement of Learning Analytics (LA) techniques, this paper illustrates the data-informed support for building learning habits, which involves persuading one to change behaviors. Specifically, we tackled 2 research objectives following the Persuasive Systems Design (PSD) model. First, we defined indicators of learning habits from log data and analyzed 115,340 learning logs of 96 learners from a Japanese junior high school. As a result, the learners’ types of habits could be detected even though some might not be efficient and the stages of habits fluctuated over time. We also identified differences when comparing the learning habits extracted from the log data with those reported in the questionnaire. Second, based on the understanding of the learner profiles, we designed elements of an LA dashboard to support habit-building by applying the design principles from the PSD model. Overall, the learners recognized the feasibility of integrating data-informed support into their daily learning. Therefore, we look forward to the evidence of its effectiveness on the behavior change that can be depicted by the transition between stages of different types of learning habits. © The Author(s). 2024.},
	author_keywords = {Behavior change; Learning analytics; Learning design; Learning habits; Persuasive system},
	correspondence_address = {C.-Y. Hsu; Graduate School of Informatics, Kyoto University, Japan; email: hsu.chiayu.25t@st.kyoto-u.ac.jp},
	publisher = {Asia-Pacific Society for Computers in Education},
	issn = {17937078},
	language = {English},
	abbrev_source_title = {Res. Pract. Technol. Enhanc.  Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Echeverria2024112,
	author = {Echeverria, Vanessa and Yan, Lixiang and Zhao, Linxuan and Abel, Sophie and Alfredo, Riordan and Dix, Samantha and Jaggard, Hollie and Wotherspoon, Rosie and Osborne, Abra and Buckingham Shum, Simon and Gasevic, Dragan and Martinez-Maldonado, Roberto},
	title = {TeamSlides: a Multimodal Teamwork Analytics Dashboard for Teacher-guided Reflection in a Physical Learning Space},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {112 – 122},
	doi = {10.1145/3636555.3636857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186622882&doi=10.1145%2f3636555.3636857&partnerID=40&md5=4f4ad9d3e6cbe74a2da13d91bbee9292},
	affiliations = {Monash University, Melbourne, VIC, Australia; Escuela Superior Politécnica Del Litoral, Guayaquil, Ecuador; Macquarie University, Sydney, Australia; University of Technology Sydney, Sydney, Australia},
	abstract = {Advancements in Multimodal Learning Analytics (MMLA) have the potential to enhance the development of effective teamwork skills and foster reflection on collaboration dynamics in physical learning environments. Yet, only a few MMLA studies have closed the learning analytics loop by making MMLA solutions immediately accessible to educators to support reflective practices, especially in authentic settings. Moreover, deploying MMLA solutions in authentic settings can bring new challenges beyond logistic and privacy issues. This paper reports the design and use of TeamSlides, a multimodal teamwork analytics dashboard to support teacher-guided reflection. We conducted an in-the-wild classroom study involving 11 teachers and 138 students. Multimodal data were collected from students working in team healthcare simulations. We examined how teachers used the dashboard in 22 debrief sessions to aid their reflective practices. We also interviewed teachers to discuss their perceptions of the dashboard's value and the challenges faced during its use. Our results suggest that the dashboard effectively reinforced discussions and augmented teacher-guided reflection practices. However, teachers encountered interpretation conflicts, sometimes leading to mistrust or misrepresenting the information. We discuss the considerations needed to overcome these challenges in MMLA research. © 2024 ACM.},
	author_keywords = {dashboards; MMLA; reflection; team dynamics; teamwork analytics; visualisation},
	keywords = {Computer aided instruction; Analytic solution; Dashboard; Multi-modal; Multi-modal learning; Multimodal learning analytic; Reflective practise; Teachers'; Team dynamics; Teamwork analytic; Teamwork skills; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ahrar2025931,
	author = {Ahrar, Arash and Doroodian, Mohammadreza and Hatala, Marek},
	title = {Exploring Eye-tracking Features to Understand Students' Sensemaking of Learning Analytics Dashboards},
	year = {2025},
	journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
	pages = {931 – 937},
	doi = {10.1145/3706468.3706543},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000386261&doi=10.1145%2f3706468.3706543&partnerID=40&md5=6073641dbe43755ba3362a8cba7baca5},
	affiliations = {Simon Fraser University, Surrey, BC, Canada},
	abstract = {Learning analytics dashboards (LADs) are widely used in learning analytics as visual tools to present information about learning activities and outcomes. However, only few studies have explored how students make sense from LAD elements and what cognitive processes follow after viewing each element. In this study, we explore how eye-tracking data can help researchers to identify salient LAD elements critical to students' sensemaking process. Our findings reveal that the eye-tracking derived features, including fixation duration and eye movement patterns, are highly indicative of students' social comparison tendencies and offer valuable insights into their sensemaking processes. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {eye tracking; learning analytics dashboards; motivation; sensemaking},
	keywords = {Contrastive Learning; Cognitive process; Derived features; Eye-tracking; Learning Activity; Learning analytic dashboard; Learning outcome; Sense making; Tracking data; Tracking feature; Visual tools; Students},
	correspondence_address = {A. Ahrar; Simon Fraser University, Surrey, Canada; email: arash_ahrar@sfu.ca},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070701-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Anal. Knowl., LAK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ogata20241711,
	author = {Ogata, Hiroaki and Liang, Changhao and Toyokawa, Yuko and Hsu, Chia-Yu and Nakamura, Kohei and Yamauchi, Taisei and Flanagan, Brendan and Dai, Yiling and Takami, Kyosuke and Horikoshi, Izumi and Majumdar, Rwitajit},
	title = {Co-designing Data-Driven Educational Technology and Practice: Reflections from the Japanese Context},
	year = {2024},
	journal = {Technology, Knowledge and Learning},
	volume = {29},
	number = {4},
	pages = {1711 – 1732},
	doi = {10.1007/s10758-024-09759-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197371908&doi=10.1007%2fs10758-024-09759-w&partnerID=40&md5=1ca86647cf4422b2bc5e32b7460a3b7c},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Center for Innovative Research and Education in Data Science, Kyoto University, Kyoto, Japan; Education Data Science Center, National Institute for Educational Policy Research, Tokyo, Japan; Research and Educational Institute for Semiconductors and Informatics, Kumamoto University, Kumamoto, Japan},
	abstract = {This paper explores co-design in Japanese education for deploying data-driven educational technology and practice. Although there is a growing emphasis on data to inform educational decision-making and personalize learning experiences, challenges such as data interoperability and inconsistency with teaching goals prevent practitioners from participating. Co-design, characterized by involving various stakeholders, is instrumental in addressing the evolving needs of technology deployment. Japan's educational context aligns with co-design implementation, with a learning and evidence analytics infrastructure facilitating data collection and analysis. From the Japanese co-design practice of educational technologies, the paper highlights a 6-phase co-design framework: motivate, pilot, implement, refine, evaluate, and maintain. The practices focus on data-driven learning strategies, technology interventions, and across-context dashboards, covering assorted learning contexts in Japan. By advocating for a co-design culture and data-driven approaches to enhance education in Japan, we offer insights for education practitioners, policymakers, researchers, and industry developers. © The Author(s) 2024.},
	author_keywords = {Case study; Co-design; Data-driven support; Learning analytics (LA); Technology deployment},
	keywords = {Decision making; Engineering education; Learning systems; Case-studies; Co-designing; Co-designs; Data driven; Data-driven support; Decisions makings; Educational decision; Japanese educations; Learning analytic; Technology deployment; Educational technology},
	correspondence_address = {C. Liang; Academic Center for Computing and Media Studies, Kyoto University, Kyoto, Japan; email: bluster3a@gmail.com},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Munim2025,
	author = {Munim, Ziaul Haque and Kjeldsberg, Fabian and Bustgaard, Morten and Bhagat, Sahil and Haavardtun, Per and Kim, Tae-Eun and Lindroos, Emilia and Thorvaldsen, Haakon and Nyairo, Franklin and Lampiola, Jani},
	title = {Predictive Performance Assessment in Simulation Training using Machine Learning},
	year = {2025},
	journal = {International Journal of Artificial Intelligence in Education},
	doi = {10.1007/s40593-025-00464-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000474269&doi=10.1007%2fs40593-025-00464-y&partnerID=40&md5=9d0730c8f0faeb76f9d8fd3a4838451a},
	affiliations = {Faculty of Technology, Natural and Maritime Sciences, University of South-Eastern Norway, Horten, Norway; Department of Technology and Safety, University of Tromsø (Uit), the Arctic University of Norway, Tromsø, Norway; Faculty of Technology and Seafaring, Novia University of Applied Sciences, Turku, Finland},
	abstract = {Maritime simulators are a central tool for the education and training of navigators, allowing them to develop and improve their skills in a controlled and replicable environment. Despite efforts to enhance the simulation training performance assessment, there are few reliable approaches to take advantage of readily available data from simulator logs to inform performance evaluation and training adjustments. Harnessing this data more effectively could enhance the way we assess simulation training and provide a more transparent understanding of learning progress and areas for improvement. To develop a learning analytics dashboard (LAD) for performance assessment in maritime simulation training, we analyse simulator log data with 27 potential input features to predict student performance as the target feature. After filtering down to 13 potential input features using data visualization and expert validation, a cloud artificial intelligence platform is used for predicting student performance. A total of 58 algorithms were trained, of which the eXtreme Gradient Boosted Trees Classifier algorithm is adopted for prediction. The results demonstrate the potential for utilizing machine learning algorithms in analysing maritime navigation training data paving the way for a new direction in simulation training assessment. © The Author(s) 2025.},
	author_keywords = {Artificial intelligence; Learning analytics; Machine learning; Simulator training; Training and assessment},
	keywords = {Contrastive Learning; Marine navigation; Predictive analytics; Input features; Learning analytic; Machine-learning; Maritime simulators; Performance assessment; Predictive performance; Simulation training; Simulator training; Student performance; Training and assessment; Adversarial machine learning},
	correspondence_address = {Z.H. Munim; Faculty of Technology, Natural and Maritime Sciences, University of South-Eastern Norway, Horten, Norway; email: ziaul.h.munim@usn.no},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Liu202410437,
	author = {Liu, Yiming and Huang, Lingyun and Doleck, Tenzin},
	title = {How teachers’ self-regulation, emotions, perceptions, and experiences predict their capacities for learning analytics dashboard: A Bayesian approach},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {9},
	pages = {10437 – 10472},
	doi = {10.1007/s10639-023-12163-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173742743&doi=10.1007%2fs10639-023-12163-z&partnerID=40&md5=5702a085b34328df84404d318f296425},
	affiliations = {Faculty of Education, The University of Hong Kong, SAR, Hong Kong; Department of Curriculum and Instruction, The Education University of Hong Kong, 10 Lo Ping Road, Tai Po, New Territories, SAR, Hong Kong; Faculty of Education, Simon Fraser University, Vancouver, BC, Canada},
	abstract = {Learning analytics dashboards (LADs) are emerging tools that convert abstract, complex information with visualizations to facilitate teachers’ data-driven pedagogical decision-making. While many LADs have been designed, teachers’ capacities for using such LADs are not well articulated in the literature. To fill the gap, this study provided a conceptual definition highlighting data visualization literacy and integrating abilities as two critical components in LAD capacities. Moreover, this study assessed teachers’ LAD capacities through a knowledge test and examined the combined effect of teachers’ self-regulation, emotions, perceptions of LAD usefulness and ease of use, and online teaching experience on teachers’ achievements of the LAD capacity knowledge test. The results of a Bayesian path analysis based on the sample of 150 teachers show that (1) teachers’ self-regulation and perceived LAD usefulness were the two main factors that made significant impacts on their LAD capacities, (2) the factors of negative emotions and perceived ease of use had effects on teachers’ LAD capacities, but such effects were mediated by self-regulation and perceived usefulness, and (3) online teaching experience had little effect on LAD capacities. This is the first study that conceptually researches teachers’ capacities for LAD uses. The findings offer novel perspectives into the complexity of LAD using process and demonstrate the importance of teachers’ self-regulation, emotions, and perceptions of usefulness in enhancing teachers’ abilities to use LADs for pedagogical decisions and actions. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.},
	author_keywords = {Bayes path analysis; Emotions; Learning analytics dashboard capacities; Perceived ease of use; Perceived usefulness; Self-regulation},
	correspondence_address = {L. Huang; Department of Curriculum and Instruction, The Education University of Hong Kong, 10 Lo Ping Road, Tai Po, New Territories, SAR, Hong Kong; email: lingyunhuang@eduhk.hk},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Abouelenein2025,
	author = {Abouelenein, Yousri Attia Mohamed and Selim, Shaimaa Abdul Salam and Aldosemani, Tahani Ibrahim},
	title = {Impact of an adaptive environment based on learning analytics on pre-service science teacher behavior and self-regulation},
	year = {2025},
	journal = {Smart Learning Environments},
	volume = {12},
	number = {1},
	doi = {10.1186/s40561-024-00340-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218188516&doi=10.1186%2fs40561-024-00340-7&partnerID=40&md5=968ed3ee61f7a6e379f5016f40ada362},
	affiliations = {Department of Educational Technology, Faculty of Education, Damietta University, Damietta, Egypt; Curriculum and Instruction of Science, Faculty of Education, Damietta University, Damietta, Egypt; Department of Educational Technology and Instructional Design at Prince Sattam bin, Abdulaziz University, Jeddah, Saudi Arabia},
	abstract = {Learning analytics provides valuable data to inform the best decisions for each learner. This study, based on adaptive environment (AE) learning analytics dashboards, examines how instructor interventions affect student self-regulation abilities and academic performance. It identifies the self-regulation categories requiring the most support to correct learning paths. Little is known about how interventions in an AE can influence learners' self-regulation based on performance indicators, particularly in science education. The study included 95 Faculty of Education and the Department of Science students. Using a longitudinal clustering approach, researchers identified three unique self-regulated learning (SRL) profiles: oriented, adaptive, and minimally self-regulated learners. While the results showed that the learning analyses were useful in guiding the process of appropriate interventions through an adaptive environment for each student by providing indicators and raising the level of self-regulation for each group separately, the results also showed that there was no change in the classification of self-regulation into groups and that no students moved between groups. These findings highlight the complexity of SRL, suggesting that while interventions can impact engagement and behavior, they may not be sufficient to change the learner's underlying profile. In academic performance, statistically significant differences were found, with the oriented self-regulation group outperforming the adaptive and minimally self-regulated groups. The findings underscore the importance of learning analytics and their indicators for timely interventions in adaptive environments. Additionally, the AE was highly effective, offering students opportunities to review material, which improved their study techniques, test-taking strategies, and overall learning experience. © The Author(s) 2025.},
	author_keywords = {Adaptive environment; Data science applications in education; Self-regulation of learning; Student performance},
	correspondence_address = {Y.A.M. Abouelenein; Department of Educational Technology, Faculty of Education, Damietta University, Damietta, Egypt; email: dr.yousri@du.edu.eg; S.A.S. Selim; Curriculum and Instruction of Science, Faculty of Education, Damietta University, Damietta, Egypt; email: Shaimaa1083@du.edu.eg; T.I. Aldosemani; Department of Educational Technology and Instructional Design at Prince Sattam bin, Abdulaziz University, Jeddah, Saudi Arabia; email: t.aldosemani@psau.edu.sa},
	publisher = {Springer},
	issn = {21967091},
	language = {English},
	abbrev_source_title = {Smart Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Sciarrone2024,
	author = {Sciarrone, Filippo and Temperini, Marco},
	title = {A Sentence-Embedding-Based Dashboard to Support Teacher Analysis of Learner Concept Maps},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {9},
	doi = {10.3390/electronics13091756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192728272&doi=10.3390%2felectronics13091756&partnerID=40&md5=5162076f96dd1d2e5ecf49b7fbdf078a},
	affiliations = {Faculty of Technological and Innovation Sciences, Universitas Mercatorum, Rome, 00186, Italy; Department of Computer Control and Management Engineering, Sapienza University of Rome, Rome, 00189, Italy},
	abstract = {Concept mapping is a valuable method to represent a domain of knowledge, also with the aim of supporting educational needs. Students are called upon to construct their own knowledge through a meaningful learning process, linking new concepts to concepts they have already learned, i.e., connecting new knowledge to knowledge they already possess. Moreover, the particular graphic form of a concept map makes it easy for the teacher to construct and interpret both. Consequently, for an educator, the ability to assess concept maps offered by students, facilitated by an automated system, can prove invaluable. This becomes even more apparent in educational settings where there is a large number of students, such as in Massive Open Online Courses. Here, we propose two new measures devised to evaluate the similarity between concept maps based on two deep-learning embedding models: InferSent and Universal Sentence Encoder. An experimental evaluation with a sample of teachers confirms the validity of one such deep-learning model as the baseline of the new similarity measure. Subsequently, we present a proof-of-concept dashboard where the measures are used to encode a concept map in a 2D space point, with the aim of helping teachers monitor students’ concept-mapping activity. © 2024 by the authors.},
	author_keywords = {concept map; deep learning; learning analytics},
	correspondence_address = {F. Sciarrone; Faculty of Technological and Innovation Sciences, Universitas Mercatorum, Rome, 00186, Italy; email: filippo.sciarrone@unimercatorum.it; M. Temperini; Department of Computer Control and Management Engineering, Sapienza University of Rome, Rome, 00189, Italy; email: marte@diag.uniroma1.it},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Maertens2024,
	author = {Maertens, Rien and Van Neyghem, Maarten and Geldhof, Maxiem and Van Petegem, Charlotte and Strijbol, Niko and Dawyndt, Peter and Mesuere, Bart},
	title = {Discovering and exploring cases of educational source code plagiarism with Dolos},
	year = {2024},
	journal = {SoftwareX},
	volume = {26},
	doi = {10.1016/j.softx.2024.101755},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192340325&doi=10.1016%2fj.softx.2024.101755&partnerID=40&md5=00d029dbb1c46c2a29fa90fa879d33ee},
	affiliations = {Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium},
	abstract = {Source code plagiarism is a significant issue in educational practice, and educators need user-friendly tools to cope with such academic dishonesty. This article introduces the latest version of Dolos, a state-of-the-art ecosystem of tools for detecting and preventing plagiarism in educational source code. In this new version, the primary focus has been on enhancing the user experience. Educators can now run the entire plagiarism detection pipeline from a new web app in their browser, eliminating the need for any installation or configuration. Completely redesigned analytics dashboards provide an instant assessment of whether a collection of source files contains suspected cases of plagiarism and how widespread plagiarism is within the collection. The dashboards support hierarchically structured navigation to facilitate zooming in and out of suspect cases. Clusters are an essential new component of the dashboard design, reflecting the observation that plagiarism can occur among larger groups of students. To meet various user needs, the Dolos software stack for source code plagiarism detection now includes a self-hostable web app, a JSON application programming interface (API), a command line interface (CLI), a JavaScript library and a preconfigured Docker container. Clear documentation and a free-to-use instance of the web app can be found at https://dolos.ugent.be. The source code is also available on GitHub. © 2024 The Authors},
	author_keywords = {Academic dishonesty; Cheating; Educational data mining; Learning analytics; Online learning; Plagiarism; Programming language; Source code; Web app},
	keywords = {Application programming interfaces (API); Application programs; Codes (symbols); Computer programming languages; E-learning; HTTP; Intellectual property; Academic dishonesty; Cheating; Educational data mining; Learning analytic; Online learning; Plagiarism; Plagiarism detection; Source code plagiarisms; Source codes; Web App; Data mining},
	correspondence_address = {R. Maertens; Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium; email: rien.maertens@ugent.be},
	publisher = {Elsevier B.V.},
	issn = {23527110},
	language = {English},
	abbrev_source_title = {SoftwareX},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wiley2024845,
	author = {Wiley, Korah and Dimitriadis, Yannis and Linn, Marcia},
	title = {A human-centred learning analytics approach for developing contextually scalable K-12 teacher dashboards},
	year = {2024},
	journal = {British Journal of Educational Technology},
	volume = {55},
	number = {3},
	pages = {845 – 885},
	doi = {10.1111/bjet.13383},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170236373&doi=10.1111%2fbjet.13383&partnerID=40&md5=cc34d0a1e652d15c7e3fc6ada9a89c97},
	affiliations = {Digital Promise, Center for Inclusive Innovation, Washington, DC, United States; Department of Signal Theory and Communications and Telematics Engineering, ETS de Ingenieros de Telecomunicación, Universidad de Valladolid, Valladolid, Spain; Graduate School of Education, University of California at Berkeley, Berkeley, CA, United States},
	abstract = {This paper describes a Human-Centred Learning Analytics (HCLA) design approach for developing learning analytics (LA) dashboards for K-12 classrooms that maintain both contextual relevance and scalability—two goals that are often in competition. Using mixed methods, we collected observational and interview data from teacher partners and assessment data from their students' engagement with the lesson materials. This DBR-based, human-centred design process resulted in a dashboard that supported teachers in addressing their students' learning needs. To develop the dashboard features that could support teachers, we found that a design refinement process that drew on the insights of teachers with varying teaching experience, philosophies and teaching contexts strengthened the resulting outcome. The versatile nature of the approach, in terms of student learning outcomes, makes it useful for HCLA design efforts across diverse K-12 educational contexts. Practitioner notes What is already known about this topic Learning analytics that are aligned to both a learning theory and learning design support student learning. LA dashboards that support users to understand the associated learning analytics data provide actionable insight. Design-based research is a promising methodology for Human-Centred Learning Analytics design, particularly in the K-12 educational context. What this paper adds Leveraging a longstanding, yet fluid, research-practice partnership is an effective design-based research adaptation for addressing the high variation in instructional practices that characterize K-12 education. Using both quantitative and qualitative data that reflects students' developing knowledge effectively supports teachers' inquiry into student learning. Teachers' use of learning analytics dashboards is heavily influenced by their perspectives on teaching and learning. Implications for practice and/or policy Impact on student learning outcomes, alongside usability and feasibility, should be included as a necessary metric for the effectiveness of LA design. LA dashboard developers should both leverage learning data that reflect students' developing knowledge and position teachers to take responsive pedagogical action to support student learning. LA researchers and developers should utilize a long-term, yet fluid, research-practice partnership to form a multi-stakeholder, multidisciplinary design team for Human-Centred Learning Analytics design. © 2023 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association.},
	author_keywords = {design-based research; human-centred learning analytics; K-12 education; knowledge integration; learning outcomes; teacher dashboard},
	keywords = {Design; Knowledge management; Learning systems; Philosophical aspects; Analytic design; Design-based research; Human-centered learning analytic; K-12 education; Knowledge integration; Learning outcome; Student learning; Student learning outcomes; Teacher dashboard; Teachers'; Students},
	correspondence_address = {K. Wiley; Digital Promise, Washington, 1001 Connecticut Avenue NW, Suite 935, 20036, United States; email: kwiley@digitalpromise.org},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Serrano2025263,
	author = {Serrano, Vanessa and Cuadros, Jordi and Fernández-Ruano, Laura and García-Zubía, Javier and Hernández-Jayo, Unai and Lluch, Francesc},
	title = {Learning Analytics Dashboards for Assessing Remote Labs Users' Work: A Case Study with VISIR-DB},
	year = {2025},
	journal = {Technology, Knowledge and Learning},
	volume = {30},
	number = {1},
	pages = {263 – 290},
	doi = {10.1007/s10758-024-09752-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001082579&doi=10.1007%2fs10758-024-09752-3&partnerID=40&md5=c5463662cb24c797d6dc0ced1aa97870},
	affiliations = {IQS Univ. Ramon Llull, Via Augusta 390, Barcelona, 08017, Spain; Education and Psychology Sciencies Faculty, Univ. Rovira I Virgili, Carretera de Valls S/N, Tarragona, 43007, Spain; Faculty of Engineering, University of Deusto, Avda. Universidades 24, Bilbao, 48007, Spain},
	abstract = {In science and engineering education, remote laboratories are designed to bring ubiquity to experimental scenarios, by having real laboratories operated through the Internet. Despite that remote laboratories enable the collection of students' work data, the educational use of these data is still underdeveloped. Learning analytics dashboards are common tools to present and analyze educational data to provide indicators to understand learning processes. This paper presents how data from remote labs, such as Virtual Instruments Systems In Reality (VISIR), can be analyzed through a learning analytics dashboard to help instructors provide better feedback to their pupils. Visualizations to study the use of the VISIR, to assess students’ performance in a particular activity and to facilitate the assisted assessment of students are introduced to the VISIR dashboard (VISIR-DB). These visualizations include a new recodification of circuits that keeps the fragment being measured, in order to better identify student’s intention. VISIR-DB also incorporates functions to check a priori steps in the resolution process and/or potential errors (observation items), and logical combinations of them to grade students' performance according to the expected outcomes (assessment milestones). Both work indicators, observation items and assessment milestones, can be defined in activity-specific text files and allow for checking the circuit as coded by the interface, the conceptual circuit it represents, its components, parameters, and measurement result. Main results in the use of VISIR for learning DC circuits course show that students mainly use VISIR when indicated by instructors and a great variability regarding to time of use and number of experiments performed. For the particular assessment activity, VISIR-DB helps to easily detect that there is a significant number of students that did not achieved any of the expected tasks. Additionally, it helps to identify students that still make a huge number of errors at the end of the course. Appropriate interventions can be taken from here. © The Author(s) 2024.},
	author_keywords = {Data mining; Learning analytics; Learning analytics dashboard; Remote laboratory; VISIR},
	keywords = {Data mining; Electric network analysis; Engineering education; Laboratories; Visualization; Case-studies; Educational use; Learning analytic; Learning analytic dashboard; Remote laboratories; Remote labs; Science and engineering; Student performance; Virtual instrument system in reality; Virtual instrument systems; Students},
	correspondence_address = {V. Serrano; IQS Univ. Ramon Llull, Barcelona, Via Augusta 390, 08017, Spain; email: vanessa.serrano@urv.cat},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Jin2025579,
	author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie Xiang and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
	title = {Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots},
	year = {2025},
	journal = {15th  International Conference on Learning Analytics and Knowledge, LAK 2025},
	pages = {579 – 590},
	doi = {10.1145/3706468.3706545},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000375269&doi=10.1145%2f3706468.3706545&partnerID=40&md5=da87f3334b31f12b744f1a743c70fb47},
	affiliations = {Monash University, Clayton, Australia; Escuela Superior Politécnica Del Litoral, Guayaquil, Ecuador},
	abstract = {Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners' varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners' ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners' GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners' GenAI literacy. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {data visualisation; generative AI chatbots; generative AI literacy; learning analytics dashboard},
	keywords = {Adversarial machine learning; Federated learning; Generative adversarial networks; Visual analytics; 'current; Chatbots; Educational effectiveness; Generative AI chatbot; Generative AI literacy; Interaction with data; Interactive learning; Learner interaction; Learning analytic dashboard; Personalized feedback; Contrastive Learning},
	correspondence_address = {Y. Jin; Monash University, Clayton, Australia; email: ariel.jin@monash.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070701-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Anal. Knowl., LAK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Gallagher20242840,
	author = {Gallagher, Timothy and Slof, Bert and van der Schaaf, Marieke and Arztmann, Michaela and Fracaro, Sofia Garcia and Kester, Liesbeth},
	title = {Learning analytics dashboard design: Workplace learner preferences for reference frames in immersive training in practice},
	year = {2024},
	journal = {Journal of Computer Assisted Learning},
	volume = {40},
	number = {6},
	pages = {2840 – 2855},
	doi = {10.1111/jcal.13042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198629837&doi=10.1111%2fjcal.13042&partnerID=40&md5=c772d97191133da10e7e490316f9ecf6},
	affiliations = {Department of Education, Utrecht University, Utrecht, Netherlands; Advice and Research Department, Netherlands Institute for Curriculum Development, Amersfoort, Netherlands; Utrecht Center for Research and Development of Education, University Medical Centre Utrecht, Utrecht, Netherlands; Live Science - Engineering & Technology - Smart Manufacturing & Digital Operations - Advanced Technologies, Merck KGaA, Darmstadt, Germany; Chemical Engineering Department, KU Leuven, Leuven, Belgium},
	abstract = {Background: Learning analytics dashboards are increasingly being used to communicate feedback to learners. However, little is known about learner preferences for dashboard designs and how they differ depending on the self-regulated learning (SRL) phases the dashboards are presented (i.e., forethought, performance, and self-reflection phases) and SRL skills. Insight into design preferences for dashboards with different reference frames (i.e., progress, social, internal achievement and external achievement) is important because the effectiveness of feedback can depend upon how a learner perceives it. Objective: This study examines workplace learner preferences for four dashboard designs for each SRL phase and how SRL skills relate to these preferences. Methods: Seventy participants enrolled in a chemical process apprenticeship program took part in the study. Preferences were determined using a method of adaptive comparative judgement and SRL skills were measured using a questionnaire. Preferences were tested on four dashboard designs informed by social and temporal comparison theory and goal setting theory. Multinomial logistic regressions were used to examine the relationship between dashboard preferences and SRL. Results and Conclusions: Results show that the progress reference frame is more preferred before and after task performance, and the social reference frame is less preferred before and after task performance. It was found that the higher the SRL skill score the higher the probability a learner preferred the progress reference frame compared to having no preference before task performance. The results are consistent with other findings, which suggest caution when using social comparison in designing dashboards which provide feedback. © 2024 The Author(s). Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {immersive learning environments; learning analytics dashboards; reference frames; social comparison theory; temporal comparison theory; workplace learning},
	correspondence_address = {T. Gallagher; Department of Education, Utrecht University, Utrecht, Heidelberglaan 1, Room 3.36, 3584 CS, Netherlands; email: t.r.gallagher@uu.nl},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jin2025152,
	author = {Jin, Flora Ji-Yoon and Maheshi, Bhagya and Lai, Wenhua and Li, Yuheng and Gasevic, Danijela and Chen, Guanliang and Charwat, Nicola and Chan, Philip Wing Keung and Martinez-Maldonado, Roberto and Gašević, Dragan and Tsai, Yi-Shan},
	title = {Students’ Perceptions of Generative AI–Powered Learning Analytics in the Feedback Process: A Feedback Literacy Perspective},
	year = {2025},
	journal = {Journal of Learning Analytics},
	volume = {12},
	number = {1},
	pages = {152 – 168},
	doi = {10.18608/jla.2025.8609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001829063&doi=10.18608%2fjla.2025.8609&partnerID=40&md5=915f3e5cec135d01de1d1fd41be5cbcb},
	affiliations = {Faculty of Information Technology, Monash University, Melbourne, Australia; Education College, Wenzhou University, Wenzhou, China; School of Public Health and Preventive Medicine, Monash University, Melbourne, Australia; Faculty of Business & Economics, Monash University, Melbourne, Australia; Faculty of Education, Monash University, Melbourne, Australia},
	abstract = {This paper explores the integration of generative AI (GenAI) in the feedback process in higher education through a learning analytics (LA) tool, examined from a feedback literacy perspective. Feedback literacy refers to students’ ability to understand, evaluate, and apply feedback effectively to improve their learning, which is crucial for fostering self-regulated learning and academic growth. GenAI has the potential to open new avenues of research and design in augmenting feedback practices by providing innovative, personalized, and scalable feedback solutions. The study investigates how GenAI functionalities, specifically ChatGPT explanation features and GenAI-powered dashboard visualizations, can support students in engaging with feedback. Using feedback literacy theory, a thematic analysis was conducted and triangulated with usage trace data to assess students’ perceptions of these functionalities. The study involved three key activities: introductory lab sessions, in-semester use of the GenAI-powered LA feedback tool, and post hoc interviews, with data collected from 18 students from various disciplines (information technology, education, business and economics, and engineering) throughout all phases. Initial findings from the lab sessions showed positive perceptions of the GenAI functionalities. However, trace data from in-semester use indicated modest engagement with GenAI. Post hoc interviews revealed that reduced engagement was due to a mismatch between the GenAI outputs and student expectations. While some students appreciated the GenAI functionalities, others found them redundant when they perceived the feedback as clear and easy to understand. This study highlights the potential of GenAI in the feedback process and underscores the challenges of aligning AI tools with diverse student needs. Future developments should focus on creating adaptive and discipline-specific GenAI solutions. © 2025, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {feedback engagement; feedback interaction; feedback literacy; Generative AI; learning analytics},
	correspondence_address = {F.J.-Y. Jin; Faculty of Information Technology, Monash University, Melbourne, Australia; email: flora.jin@monash.edu},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Maimaiti2025,
	author = {Maimaiti, Gulipari and Hew, Khe Foon},
	title = {Gamification bolsters self-regulated learning, learning performance and reduces strategy decline in flipped classrooms: A longitudinal quasi-experiment},
	year = {2025},
	journal = {Computers and Education},
	volume = {230},
	doi = {10.1016/j.compedu.2025.105278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218865588&doi=10.1016%2fj.compedu.2025.105278&partnerID=40&md5=23d4e05e509f46d15d234b3095f40944},
	affiliations = {Runme Shaw Building, The University of Hong Kong, Pokfulam Road, Hong Kong},
	abstract = {Flipped classrooms, which foster active learning, are becoming more prevalent in higher education. Yet, many students struggle with self-regulated learning (SRL) skills and prefer traditional learning methods. The use of SRL relies on both students' motivation and skills but it is unclear how these skills evolve over time since many previous studies often overlook the temporal effects of interventions. To address these challenges, we introduced a gamified self-regulated flipped learning (GSRFL) approach. This approach integrates gamification elements and self-regulation supports, such as a learning analytics dashboard, to motivate and aid students' behaviors across three main SRL stages: planning, execution, and self-evaluation. We conducted a longitudinal quasi-experimental study with first-year university students to examine the impact on their SRL behaviors. The longitudinal study offers a considerable methodological advantage by providing detailed information about an intervention's impact over time. The experimental group (N = 76) utilized the GSRFL approach, while the control group (N = 75) employed the same self-regulated flipped learning approach but without gamification. Results showed that gamification significantly improved students' English learning achievement and overall SRL behaviors. Longitudinal observations revealed a positive main intervention effect on metacognitive monitoring behaviors, despite a natural decline in SRL behaviors over time. Gamification effectively moderated the decline of underutilized SRL strategies like goal setting and time management. These results underscore gamification's potential to enhance academic performance and promote SRL skills. © 2025 Elsevier Ltd},
	author_keywords = {Flipped classroom; Gamification; Longitudinal study; Self-regulated learning},
	keywords = {Active learning; Adversarial machine learning; Contrastive Learning; Federated learning; Active Learning; Flipped classroom; Gamification; Learning approach; Learning performance; Learning skills; Longitudinal study; Quasi-experiments; Self-regulated learning; Self-regulated learning behaviors; Self-supervised learning},
	correspondence_address = {K.F. Hew; Faculty of Education, The University of Hong Kong, Hong Kong; email: kfhew@hku.hk},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Karademir20242681,
	author = {Karademir, Onur and Di Mitri, Daniele and Schneider, Jan and Jivet, Ioana and Allmang, Jörn and Gombert, Sebastian and Kubsch, Marcus and Neumann, Knut and Drachsler, Hendrik},
	title = {I don't have time! But keep me in the loop: Co-designing requirements for a learning analytics cockpit with teachers},
	year = {2024},
	journal = {Journal of Computer Assisted Learning},
	volume = {40},
	number = {6},
	pages = {2681 – 2699},
	doi = {10.1111/jcal.12997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192274461&doi=10.1111%2fjcal.12997&partnerID=40&md5=09b58190c6455f41ad65a94cf7ad8b75},
	affiliations = {DIPF, Leibniz Institute for Research and Information in Education, Frankfurt, Germany; Studiumdigitale, Goethe University, Frankfurt, Germany; FernUniversität in Hagen, Hagen, Germany; DHBW Karlsruhe, Karlsruhe, Germany; Freie Universität Berlin, Berlin, Germany; Leibniz Institute for Science and Mathematics Education, Kiel, Germany},
	abstract = {Background: Teacher dashboards can help secondary school teachers manage online learning activities and inform instructional decisions by visualising information about class learning. However, when designing teacher dashboards, it is not trivial to choose which information to display, because not all of the vast amount of information retrieved from digital learning environments is useful for teaching. Information elicited from formative assessment (FA), though, is a strong predictor for student performance and can be a useful data source for effective teacher dashboards. Especially in the secondary education context, FA and feedback on FA, have been extensively studied and shown to positively affect student learning outcomes. Moreover, secondary teachers struggle to make sense of the information displayed in dashboards and decide on pedagogical actions, such as providing feedback to students. Objectives: To facilitate the provision of feedback for secondary school teachers via a teacher dashboard, this study identifies requirements for designing a Learning Analytics Cockpit (LA Cockpit), that is, (1) a teacher dashboard that provides teachers with visualisations of results from formative assessment (FA) and (2) a feedback system that supports teachers in providing feedback to students. Methods: This study was conducted in the context of STEM classes and is based on semi-structured co-design interviews with German secondary school teachers. In these interviews, we first explored challenges teachers encountered in monitoring students' learning and providing feedback. Second, in the ideation phase, teachers were asked to define features an LA Cockpit for FA should have. Finally, in the evaluation phase, we provided teachers with a design template for an LA Cockpit, the LAC_Template, which was built upon our previous work and feedback theory, and asked them to evaluate and improve it. Further design requirements were derived based on the evaluation of the LAC_Template and teachers' suggestions for improvement. Results: We derived 16 requirements for designing an LA Cockpit for FA in secondary schools. Findings from the interviews indicated that the feedback system of an LA Cockpit should address teachers' time limitations in giving students individualised feedback. It should therefore be designed to minimise the steps required to deliver feedback. To reduce workload, teachers requested an automated reminder to send feedback, but with the ability to adjust feedback to the learning context. Such a semi-automated feedback system can help teachers support students individually but also underline the importance of actively involving teachers in the feedback loop and giving them control when using such technologies in secondary school practice. A challenge for future teacher dashboard designs could be to find a balance between technology and teacher control that utilises the strengths of both in a beneficial combination. © 2024 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {co-design; feedback; formative assessment; K-12; teacher dashboards},
	correspondence_address = {O. Karademir; DIPF, Leibniz Institute for Research and Information in Education, Frankfurt, Germany; email: o.karademir@dipf.de},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tretow-Fish2024,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md Saifuddin},
	title = {Applying Kano’s two-factor theory to prioritize learning analytics dashboard features for learning technology designers},
	year = {2024},
	journal = {Contemporary Educational Technology},
	volume = {16},
	number = {2},
	doi = {10.30935/cedtech/14286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195141439&doi=10.30935%2fcedtech%2f14286&partnerID=40&md5=1ee12f522589934518ff02dada5bec8b},
	affiliations = {DTU Compute, Lyngby, Denmark},
	abstract = {Existing methods for software requirements elicitation, five-point Likert scales and voting methods for requirements prioritization, and usability and user experience evaluation methods do not enable prioritizing the learning analytics dashboard requirements. Inspired by management and product design field, this research applies Kano’s two-factor theory to prioritize the features of learning analytics dashboards (LADs) of adaptive learning platform (ALP) called Rhapsode™ learner, based on students’ perceived usefulness to support designers’ decision-making. Comparing usability and user experience methods for evaluating LAD features, this paper contributes with the protocol and a case applying Kano method for evaluating the perceived importance of the dashboards in ALP. The paper applies Kano’s two-factor questionnaire on the 13 LADs features of Rhapsode™ learner. Responses from 17 students are collected using a questionnaire, which is used to showcase the strength of the two-factor theory through five tabular and graphical techniques. Through these five tabular and graphical techniques, we demonstrate the application and usefulness of the method as designers and management are often carried away by the possibilities of insights instead of actual usefulness. The results revealed a variation in the categorization of LADs depending on the technique employed. As the complexity of the techniques increases, additional factors that indicate data uncertainty are gradually incorporated, clearly highlighting the growing requirement for data. In the case of RhapsodeTM learner platform, results based on the students responses show that 11 of 13 LADs being excluded due to low significance level in categorization (technique 1) and low response rate. © 2024 by authors; licensee CEDTECH by Bastas.},
	author_keywords = {adaptive learning platforms; design methods; Kano’s two-factor theory; learning analytics dashboard},
	correspondence_address = {T.A.B. Tretow-Fish; DTU Compute, Lyngby, Denmark; email: tabtr@dtu.dk},
	publisher = {Bastas},
	issn = {1309517X},
	language = {English},
	abbrev_source_title = {Contemp. Edu. Tech.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}@ARTICLE{Fleur2023,
	author = {Fleur, Damien S. and van den Bos, Wouter and Bredeweg, Bert},
	title = {Social comparison in learning analytics dashboard supporting motivation and academic achievement},
	year = {2023},
	journal = {Computers and Education Open},
	volume = {4},
	doi = {10.1016/j.caeo.2023.100130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161616599&doi=10.1016%2fj.caeo.2023.100130&partnerID=40&md5=b949787b5c13147860b927b0cb841074},
	affiliations = {University of Amsterdam, Faculty of Science, Informatics Institute, Amsterdam, Netherlands; Universtiy of Amsterdam, Faculty of Social and Behavioural Sciences, Department of Psychology, Amsterdam, Netherlands; Center for Adaptive Rationality, Max Planck Institute for Human Development, Berlin, Germany; Amsterdam University of Applied Sciences, Faculty of Education, Amsterdam, Netherlands},
	abstract = {A promising contribution of Learning Analytics is the presentation of a learner's own learning behaviour and achievements via dashboards, often in comparison to peers, with the goal of improving self-regulated learning. However, there is a lack of empirical evidence on the impact of these dashboards and few designs are informed by theory. Many dashboard designs struggle to translate awareness of learning processes into actual self-regulated learning. In this study we investigate a Learning Analytics dashboard based on existing evidence on social comparison to support motivation, metacognition and academic achievement. Motivation plays a key role in whether learners will engage in self-regulated learning in the first place. Social comparison can be a significant driver in increasing motivation. We performed two randomised controlled interventions in different higher-education courses, one of which took place online due to the COVID-19 pandemic. Students were shown their current and predicted performance in a course alongside that of peers with similar goal grades. The sample of peers was selected in a way to elicit slight upward comparison. We found that the dashboard successfully promotes extrinsic motivation and leads to higher academic achievement, indicating an effect of dashboard exposure on learning behaviour, despite an absence of effects on metacognition. These results provide evidence that carefully designed social comparison, rooted in theory and empirical evidence, can be used to boost motivation and performance. Our dashboard is a successful example of how social comparison can be implemented in Learning Analytics Dashboards. © 2023},
	author_keywords = {Dashboard; Learning analytics; Motivation; Self-regulated learning; Social comparison},
	correspondence_address = {D.S. Fleur; Amsterdam, Science Park 900, 1098 XH, Netherlands; email: d.s.fleur@uva.nl},
	publisher = {Elsevier Ltd},
	issn = {26665573},
	language = {English},
	abbrev_source_title = {Comput. Educ. Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Gold Open Access}
}

@ARTICLE{Hooshyar2023,
	author = {Hooshyar, Danial and Tammets, Kairit and Ley, Tobias and Aus, Kati and Kollom, Kaire},
	title = {Learning Analytics in Supporting Student Agency: A Systematic Review},
	year = {2023},
	journal = {Sustainability (Switzerland)},
	volume = {15},
	number = {18},
	doi = {10.3390/su151813662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173036349&doi=10.3390%2fsu151813662&partnerID=40&md5=c6e67c3fdc5dcf81077ccd2bf6c01291},
	affiliations = {Centre for Educational Technology, Tallinn University, Tallinn, 10120, Estonia; Center for Digitalisation in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, 3500, Austria; School of Educational Sciences, Tallinn University, Tallinn, 10120, Estonia},
	abstract = {Student agency, or agency for learning, refers to an individual’s ability to act and cause changes during the learning process. Recently, learning analytics (LA) has demonstrated its potential in promoting agency, as it enables students to take an active role in their learning process and supports the development of their self-regulatory skills. Despite the growing interest and potential for supporting student agency, there have yet to be any studies reviewing the extant works dealing with the use of LA in supporting student agency. We systematically reviewed the existing related works in eight major international databases and identified 15 articles. Analysis of these articles revealed that most of the studies aimed to investigate student or educators’ agency experiences, propose design principles for LA, and to a lesser extent, develop LA methods/dashboards to support agency. Of those studies developing LA, none initially explored student agency experiences and then utilized their findings to develop evidence-based LA methods and dashboards for supporting student agency. Moreover, we found that the included articles largely rely on descriptive and diagnostic analytics, paying less attention to predictive analytics and completely overlooking the potential of prescriptive learning analytics in supporting agency. Our findings also shed light on nine key design elements for effective LA support of student agency, including customization, decision-making support, consideration of transparency and privacy, and facilitation of co-design. Surprisingly, we found that no studies have considered the use of LA to support student agency in K–12 education, while higher education has been the focal point of the LA community. Finally, we highlighted the fields of study and data visualization types that the studies mostly targeted and, more importantly, identified eight crucial challenges facing LA in its support of student agency. © 2023 by the authors.},
	author_keywords = {learning analytics; student agency; systematic review; technology-enhanced learning},
	keywords = {decision support system; facilitation; higher education; learning; student; visualization},
	correspondence_address = {D. Hooshyar; Centre for Educational Technology, Tallinn University, Tallinn, 10120, Estonia; email: danial@tlu.ee},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@CONFERENCE{Abdullah20246,
	author = {Abdullah, Aziman and Jieyu, Pang and Majid, Mazlina Abdul},
	title = {Smart Attendance and Engagement Dashboard for Smart Education},
	year = {2024},
	journal = {2024 Arab ICT Conference, AICTC 2024},
	pages = {6 – 10},
	doi = {10.1109/AICTC58357.2024.10735033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210549998&doi=10.1109%2fAICTC58357.2024.10735033&partnerID=40&md5=35972f537261829c926646bed0d14fcc},
	affiliations = {Universiti Malaysia Pahang Al-Sultan Abdullah, Faculty of Computing, Pahang, Malaysia},
	abstract = {This study aims to measure student engagement and attendance in blended learning environments with innovative systems based on cloud services. The system goes beyond traditional attendance tracking methods by providing educators with data on students' learning behaviors, including their level of participation and interest in the subject matter. The dashboard is based on cloud technology, which allows educators and policymakers to access and analyze data easily. The system's comprehensive data capture can help educators better understand their students' learning behaviors and make informed decisions about how to support their success. By providing policymakers with accurate and up-to-date information, this system has the potential to inform education policy and allocate resources more effectively to support student success.  © 2024 IEEE.},
	author_keywords = {learning analytics; smart attendance},
	keywords = {Adversarial machine learning; Federated learning; Blended learning environments; Cloud services; Innovative systems; Learning analytic; Learning behavior; Policy makers; Smart attendance; Student attendances; Student engagement; Student learning; Contrastive Learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034208-6},
	language = {English},
	abbrev_source_title = {Arab ICT Conf., AICTC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cisel202486,
	author = {Cisel, Matthieu},
	title = {Digital Dashboards for Summative Assessment and Indicators Misinterpretation: A Case Study},
	year = {2024},
	journal = {Canadian Journal of Education},
	volume = {47},
	number = {1},
	pages = {86 – 112},
	doi = {10.53967/cje-rce.5269},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191781061&doi=10.53967%2fcje-rce.5269&partnerID=40&md5=32e78eb49489b17cf9d77a51679a5ac2},
	affiliations = {Institut Des Humanités Numériques, CY Cergy Paris Université, France},
	abstract = {Over the last decade, teachers in France have been increasingly pressured to use digital learning environments, and to shift from grade-based to skill-based assessment. Educational dashboards, which measure student input electronically, could foster such a transition by providing insights into learners’ performances. However, such dashboards could also foster data misinterpretation during the summative assessment process, should the indicators that they display be used without a proper understanding of what they reflect. This article presents a methodology to detect potential mistakes in the interpretation of the indicators in the context of inquiry-based learning. During the design of a learning environment, we analyzed, through analytics and classroom observations in primary and middle schools, the issues that could arise from the use of a dashboard. Our data suggest that the amount of information practitioners needed to collect to make indicators relevant was burdensome, making the dashboard unfit for assessment purposes at the scale of a classroom. © 2022 Canadian Society for the Study of Education/Société canadienne pour l’étude de l’éducation},
	author_keywords = {case study; dashboard; learning analytics; skill evaluation; tableau de bord; traces d’interaction; étude de cas; évaluation par compétences},
	publisher = {Canadian Society for the Study of Education (CSSE)},
	issn = {03802361},
	language = {English},
	abbrev_source_title = {Can. J. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Yesilyurt202325,
	author = {Yesilyurt, Yusuf Emre},
	title = {AI-Enabled assessment and feedback mechanisms for language learning: Transforming pedagogy and learner experience},
	year = {2023},
	journal = {Transforming the Language Teaching Experience in the Age of AI},
	pages = {25 – 43},
	doi = {10.4018/978-1-6684-9893-4.ch002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174186707&doi=10.4018%2f978-1-6684-9893-4.ch002&partnerID=40&md5=6af2d4fe875d58dd6fa5716950477fc9},
	affiliations = {Burdur Mehmet Akif Ersoy University, Turkey},
	abstract = {This chapter examines the integration of artificial intelligence (AI) in language learning assessment and feedback. It highlights limitations of traditional models before exploring AI-driven innovations in automated scoring, speech recognition, multimodal analytics and adaptive testing. The ensuing pedagogical transformation is discussed. AI feedback mechanisms including automated writing evaluation, intelligent tutoring systems, conversational agents, affective computing and learning analytics dashboards are analyzed. Benefits are presented alongside challenges regarding ethics, overreliance on technology and transparency. Case studies provide examples across educational contexts. The future outlook considers emerging innovations, increased accessibility, research gaps, policies and human-AI partnerships. The conclusion emphasizes responsible, human-centric integration of AI to enhance pedagogy and learner experience. © 2023, IGI Global. All rights reserved.},
	publisher = {IGI Global},
	isbn = {978-166849894-1; 978-166849893-4},
	language = {English},
	abbrev_source_title = {Transform. the Lang. Teach. Exp. in the Age of AI},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Fleur2023100,
	author = {Fleur, Damien S. and Marshall, Max and Pieters, Miguel and Brouwer, Natasa and Oomens, Gerrit and Konstantinidis, Angelos and Winnips, Koos and Moes, Sylvia and van den Bos, Wouter and Bredeweg, Bert and van Vliet, Erwin A.},
	title = {IguideME: Supporting Self-Regulated Learning and Academic Achievement with Personalized Peer-Comparison Feedback in Higher Education},
	year = {2023},
	journal = {Journal of Learning Analytics},
	volume = {10},
	number = {2},
	pages = {100 – 114},
	doi = {10.18608/jla.2023.7853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170293039&doi=10.18608%2fjla.2023.7853&partnerID=40&md5=fe0222cddd44a1560661a784a77e9f84},
	affiliations = {Faculty of Science, University of Amsterdam, P.O. Box 94246, Amsterdam,  1090 GE, Netherlands; Teaching and Learning Centre, Faculty of Science, P.O. Box 94246, Amsterdam, 1090 GE, Netherlands; Center for Information Technology, University of Groningen, Nettelbosje 1, Groningen, 9747 AJ, Netherlands; Faculty of Economics and Business, University of Groningen, Nettelbosje 1, Groningen,  9747 AJ, Netherlands; Vrije Universiteit Amsterdam, University Library, De Boelelaan 1105, Amsterdam, 1081 HV, Netherlands; Department of Psychology, University of Amsterdam, P.O. Box 15916, Amsterdam, 1001 NK, Netherlands; Institute of Informatics, Faculty of Science, University of Amsterdam, P.O. Box 94246, Amsterdam, 1090 GE, Netherlands; Swammerdam Institute for Life Sciences, Center for Neuroscience, Faculty of Science, University of Amsterdam, P.O. Box 94246, Amsterdam, 1090 GE, Netherlands},
	abstract = {Personalized feedback is important for the learning process, but it is time consuming and particularly problematic in large-scale courses. While automatic feedback may help for self-regulated learning, not all forms of feedback are effective. Social comparison offers powerful feedback but is often loosely designed. We propose that intertwining meaningful feedback with well-designed peer comparison using a learning analytics dashboard provides a solution. Third-year bachelor students were randomly assigned to have access to the learning analytics dashboard IguideME (treatment, n=31) or no access (control, n=31). Dashboard users were asked to indicate their desired grade, which was used to construct peer-comparison groups. Personalized peer-comparison feedback was provided via the dashboard. The effects were studied using quantitative and qualitative data, including the Motivated Strategies for Learning Questionnaire (MSLQ) and the Achievement Goal Questionnaire (AGQ). Compared to the control group, the treatment group achieved higher scores for the MSLQ components “metacognitive self-regulation” and “peer learning,” and for the AGQ component “other-approach” (do better than others). The treatment group performed better on reading assignments and achieved higher grades for high-level Bloom exam questions. These data support the hypothesis that personalized peer-comparison feedback can be used to improve self-regulated learning and academic achievement. © 2023, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {Learning analytics dashboard; motivation; self-regulated learning; social comparison},
	correspondence_address = {D.S. Fleur; Faculty of Science, University of Amsterdam, Amsterdam, P.O. Box 94246,  1090 GE, Netherlands; email: d.s.fleur@uva.nl},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{López-Pernas2024119,
	author = {López-Pernas, Sonsoles and Gordillo, Aldo and Barra, Enrique and Saqr, Mohammed},
	title = {Tracking Students’ Progress in Educational Escape Rooms Through a Sequence Analysis Inspired Dashboard},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15160 LNCS},
	pages = {119 – 124},
	doi = {10.1007/978-3-031-72312-4_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205286932&doi=10.1007%2f978-3-031-72312-4_15&partnerID=40&md5=534149eafe1c13aa4eb3057004480d33},
	affiliations = {University of Eastern Finland, Joensuu, 80100, Finland; Universidad Politécnica de Madrid, Madrid, 28040, Spain},
	abstract = {Learning analytics dashboards are the main vehicle for providing educators with a visual representation of data and insights related to teaching and learning. Recent research has found that the data visualizations provided by dashboards are often very basic and do not take advantage of the latest research advances to analyze and depict the learning process. In this article, we present a success story of how we adapted a visualization used for research purposes for its integration in a dashboard for its use by teachers in daily practice. Specifically, we described the process of transforming and integrating a static sequence analysis visualization into an interactive web visualization in a learning analytics dashboard for monitoring students’ temporal trajectories in educational escape rooms in real time. We interviewed teachers to find out how they made use of the dashboard and present a qualitative content analysis of their responses. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {dashboards; educational escape rooms; game-based learning; learning analytics; sequence analysis},
	keywords = {Adversarial machine learning; Contrastive Learning; Data Analytics; Federated learning; Metadata; Teaching; Visual analytics; Visualization; Dashboard; Educational escape room; Game-based Learning; Learning analytic; Recent researches; Sequence analysis; Student progress; Teachers'; Teaching and learning; Visual representations; Students},
	correspondence_address = {S. López-Pernas; University of Eastern Finland, Joensuu, 80100, Finland; email: sonsoles.lopez@uef.fi},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172311-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Meyer2024374,
	author = {Meyer, Vanessa and Wiese, Lena and Al-Ghezi, Ahmed},
	title = {A Unified Teaching Platform for (No)SQL Databases},
	year = {2024},
	journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	volume = {1},
	pages = {374 – 381},
	doi = {10.5220/0012724300003690},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193925031&doi=10.5220%2f0012724300003690&partnerID=40&md5=396a844be94d6af49fd3cd3e05dc099a},
	affiliations = {Institute of Computer Science, Goethe University Frankfurt, Robert-Mayer-Str. 10, Frankfurt am Main, 60325, Germany},
	abstract = {Databases form the basic backend for information systems. This paper describes the development of a digital learning tool to promote learning of (No)SQL databases like PostgreSQL, Cassandra, Neo4J and MongoDB and the underlying data models using the React library. The learning tool will be uniformly connected to each of the mentioned databases. Thus, students can enter and execute their database queries, which are needed to solve tasks for a given example scenario, directly in our learning tool. This allows students to fully concentrate on learning the respective query languages. In this study, we present the web application’s architecture and front-end design, which will be continuously extended with additional components, such as a learning analytics dashboard. With this approach we want to contribute to the improvement of teaching methods in the field of databases and create a basis for the further development of interactive learning tools. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Databases; Learning Analytics; Learning Tool; NoSQL},
	keywords = {E-learning; Education computing; Learning systems; Query processing; Students; Cassandras; Database queries; Digital-learning; Learning analytic; Learning tool; MongoDB; no-SQL database; NoSQL; PostgreSQL; Teaching platform; Query languages},
	editor = {Filipe J. and Smialek M. and Brodsky A. and Hammoudi S.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21844992},
	isbn = {978-989758692-7},
	language = {English},
	abbrev_source_title = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cobos2023,
	author = {Cobos, Ruth},
	title = {Self-Regulated Learning and Active Feedback of MOOC Learners Supported by the Intervention Strategy of a Learning Analytics System},
	year = {2023},
	journal = {Electronics (Switzerland)},
	volume = {12},
	number = {15},
	doi = {10.3390/electronics12153368},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167687712&doi=10.3390%2felectronics12153368&partnerID=40&md5=b2e080c4b89eb196bd29065dce1739db},
	affiliations = {Department of Computer Science Engineering, Universidad Autónoma de Madrid (UAM), Madrid, 28049, Spain},
	abstract = {MOOCs offer great learning opportunities, but they also present several challenges for learners that hinder them from successfully completing MOOCs. To address these challenges, edX-LIMS (System for Learning Intervention and its Monitoring for edX MOOCs) was developed. It is a learning analytics system that supports an intervention strategy (based on learners’ interactions with the MOOC) to provide feedback to learners through web-based Learner Dashboards. Additionally, edX-LIMS provides a web-based Instructor Dashboard for instructors to monitor their learners. In this article, an enhanced version of the aforementioned system called edX-LIMS+ is presented. This upgrade introduces new services that enhance both the learners’ and instructors’ dashboards with a particular focus on self-regulated learning. Moreover, the system detects learners’ problems to guide them and assist instructors in better monitoring learners and providing necessary support. The results obtained from the use of this new version (through learners’ interactions and opinions about their dashboards) demonstrate that the feedback provided has been significantly improved, offering more valuable information to learners and enhancing their perception of both the dashboard and the intervention strategy supported by the system. Additionally, the majority of learners agreed with their detected problems, thereby enabling instructors to enhance interventions and support learners’ learning processes. © 2023 by the author.},
	author_keywords = {dashboard; data-driven intervention; e-learning tools; education; learning analytics; MOOCs; self-regulated learning; system applications and experience; technology-enhanced learning; web-based learning},
	correspondence_address = {R. Cobos; Department of Computer Science Engineering, Universidad Autónoma de Madrid (UAM), Madrid, 28049, Spain; email: ruth.cobos@uam.es},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Liu202478,
	author = {Liu, Yuchen and Pozdniakov, Stanislav and Martinez-Maldonado, Roberto},
	title = {The effects of visualisation literacy and data storytelling dashboards on teachers’ cognitive load},
	year = {2024},
	journal = {Australasian Journal of Educational Technology},
	volume = {40},
	number = {1},
	pages = {78 – 93},
	doi = {10.14742/ajet.8988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190814665&doi=10.14742%2fajet.8988&partnerID=40&md5=fbaf8366385e904a34dfbd1806f564ab},
	affiliations = {Faculty of Information Technology, Monash University, Australia; School of Electrical Engineering and Computer Science, University of Queensland, Australia},
	abstract = {Learning analytics (LA) dashboards are becoming increasingly available in various learning settings. However, teachers may face challenges in understanding and interpreting the data visualisations presented on those dashboards. In response to this, some LA researchers are incorporating visual cueing techniques, like data storytelling (DS), into LA dashboard design to reduce the data visualisation skills - often referred to as visualisation literacy (VL) - and cognitive effort required by teachers to effectively use dashboards. However, despite the potential of DS principles in simplifying data visualisations, there is limited evidence supporting their effectiveness in actually reducing teachers’ cognitive load. The study presented in this paper addresses this gap by investigating the potential impact of LA dashboards, with and without DS elements, on teachers with varying VL levels. Through a quasi-experimental study involving 23 teachers, we analysed changes in pupil dilation - a proxy for cognitive load - as they examined LA dashboards featuring student data captured while participating in synchronous, online collaborative learning tasks. Our findings suggest DS can reduce cognitive load, particularly for teachers with lower VL. These results provide insight into the effects of DS and VL on teachers’ cognitive load, thereby informing the design of LA dashboards. Implications for practice or policy: • Developers of LA dashboards need to pay more attention to incorporating visual and narrative elements that are easily comprehensible and target-oriented, based on users’ visualisation literacy levels. • Educational providers and LA designers can recommend dashboards with DS elements to teachers with low VL to enhance their work efficiency. © 2024 Articles published in the Australasian Journal of Educational Technology (AJET) are available under Creative Commons Attribution Non-Commercial No Derivatives Licence (CC BY-NC-ND 4.0). Authors retain copyright in their work and grant AJET right of first publication under CC BY-NC-ND 4.0. All Rights Reserved.},
	author_keywords = {cognitive load; data storytelling (DS); eye tracking; learning analytics (LA); visualisation literacy (VL)},
	correspondence_address = {Y. Liu; Faculty of Information Technology, Monash University, Australia; email: yuchen.liu@monash.edu},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	issn = {14495554},
	language = {English},
	abbrev_source_title = {Australas. J. Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Çöpgeven2024,
	author = {Çöpgeven, Nedime Selin and Firat, Mehmet},
	title = {EFFECTS OF DASHBOARD USAGE ON ELEARNING INTERACTIONS AND ACADEMIC ACHIEVEMENT OF DISTANCE EDUCATION STUDENTS},
	year = {2024},
	journal = {Journal of Educators Online},
	volume = {21},
	number = {1},
	doi = {10.9743/JEO.2024.21.1.18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189877885&doi=10.9743%2fJEO.2024.21.1.18&partnerID=40&md5=b2aee1d93abafe25baa10774c88532f6},
	affiliations = {Anadolu University, Turkey},
	abstract = {Learning processes can now be transferred to digital environments, allowing for the tracking of learners’ digital footprints. The field of learning analytics focuses on the efficient use of these digital records to improve both learning experiences and processes. Dashboards are the tangible outputs of learning analytics. The use of dashboards in elearning has gained attention due to their potential impact on student interactions and academic success. In this study, we used a posttest control group design to examine the effects of dashboard use on 15,321 distance education students’ elearning involvement and academic achievement. Results showed that dashboard use was associated with higher elearning interactions, but we observed no significant difference in end-of-term grades. This suggests that while dashboards may enhance student engagement in online learning, their effect on academic performance may be limited. The academic effects of dashboard use may only be observed in the long term. © 2024, Grand Canyon University. All rights reserved.},
	author_keywords = {dashboards; elearning interactions; learning analytics; open and distance learning},
	publisher = {Grand Canyon University},
	issn = {1547500X},
	language = {English},
	abbrev_source_title = {J. Educ. Online},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Göbel2024297,
	author = {Göbel, Stefan and Rotter, Elisabeth and Brabänder, Wolfgang and Maier, Angelika and Ziegler, Birgit},
	title = {Serious Games for Vocational Training},
	year = {2024},
	journal = {Proceedings of the European Conference on Games-based Learning},
	volume = {18},
	number = {1},
	pages = {297 – 303},
	doi = {10.34190/ecgbl.18.1.2710},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212924814&doi=10.34190%2fecgbl.18.1.2710&partnerID=40&md5=aefb8faf224d30dfd48317409db37688},
	affiliations = {Research Group Serious Games, Technical University of Darmstadt, Germany; Professorship for Vocational Education and Training, Technical University of Darmstadt, Germany; Inter-Company Training Center in Eastern Bavaria non-profit GmbH (UEBZO), Weiherhammer, Germany},
	abstract = {The research project ‘SG4BB’ (Serious Games for Vocational Education and Training; abbr.: VET) has developed an integrated platform for the description, search, retrieval, integration, and utilization of educational games. This paper summarizes project outcomes, including platform concepts, software components, and – as focus – practical insights derived from a case study involving the educational game ‘Corrugated’ as simulation and training environment for service technicians. SG4BB has followed a user-centered design in an interdisciplinary project team: Two learning providers specified their requirements for VET in their specific application domains. Based on those requirements, game developers, learning solution providers and researchers for VET have conceptualized and prototypically implemented both an integrated learning platform (SG4BB platform) and two case studies of Serious Games for VET: ‘Corrugated’ for service technicians and an IT security game. The platform follows a process pipeline: For search and retrieval of educational games for VET, an application profile for VET based on the standardized ‘Serious Games Metadata Format’ (DIN/SPEC 91380) has been elaborated. This format builds the semantic basis for the metadata-based catalog system ‘Serious Games Information Center’ (SG-IC) with filter functionality for VET. Learning providers and developers can use the SG-IC portal to describe and promote their educational games, enabling users to identify suitable games for their learning needs and integrate them via learning infrastructure. Educational games can interact with the backend (Learning Management System and Learning Record Store) through a middleware based on the xAPI standard, allowing for personalized gameplay and data collection for game-based learning analytics. The final evaluation of the SG4BB project focused on the utilization of the educational game ‘Corrugated’, targeting problem-solving skills for service technicians in the corrugated cardboard industry. Data from 26 participants playing the game for 60 minutes, along with problem-solving tests and user experience feedback, were analyzed to validate game-based assessment and to assess learning impact. Initial results reveal insights into specific game missions, playtimes, and success rates, indicating that participant behavior during gameplay influenced perceived learning progress, leading to varied learning paths. This paper provides valuable insights and technical information for VET practitioners on using educational games for training. Game interactions and learning outcomes can be monitored via a dashboard within the learning infrastructure, offering visualizations for user behavior (during play) and (learning) progress. © 2024 Dechema e.V.. All rights reserved.},
	author_keywords = {Case Study; Evaluation; Metadata; Middleware; Serious Games; Vocational Education And Training},
	keywords = {Application; Costs; Data Processing; Decision Making; Evaluation; Personnel Training; Records Management; Specifications; Apprentices; Cardboard; Costs; Decision making; Enterprise resource planning; Financial markets; Human resource management; Information management; Intellectual property core; Personnel training; Project management; Records management; Case-studies; Educational game; Evaluation; Gameplay; Integrated platform; Learning progress; Platform concept; Project outcomes; Vocational education and training; Vocational training; Middleware},
	editor = {Kilsa K. and Basaiawmoit R.V.},
	publisher = {Dechema e.V.},
	issn = {20490992},
	isbn = {978-191720419-4},
	language = {English},
	abbrev_source_title = {Proc. European Conf. Games-based Learn.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Curran2024,
	author = {Curran, F. Chris and Carlo, Steven and Harris-Walls, Katharine},
	title = {Making the Data Visible: A Systematic Review of Systems-Level Data Dashboards for Leadership and Policy in Education},
	year = {2024},
	journal = {Review of Educational Research},
	doi = {10.3102/00346543241288249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211155830&doi=10.3102%2f00346543241288249&partnerID=40&md5=d216f53da3dee5d183eefe82cede4e63},
	affiliations = {University of Florida, United States},
	abstract = {Systems-level data dashboards, those that provide education data aggregated to or used by leaders from school to state to federal levels, have become increasingly prevalent in the field of education both in the United States and in many education systems worldwide. This study provides a systematic review of the literature on systems-level data dashboards in K–12 schooling. The review demonstrates that research on systems-level dashboards lags that of student and teacher-focused learning analytics dashboards; that academic achievement remains the primary focus of dashboards, but contextual and non-test-score outcomes are now included in many dashboards and that use of dashboards by educators and the public is lower than desired but may be improved through alternative dissemination methods. It also demonstrates that research on the impacts of dashboards is particularly limited, a concern given the potential for unintended negative consequences. The article discusses the need to further incorporate systems-level dashboards into the organizational structures of education systems in order to enhance their utility for improving outcomes. The findings provide insights for stakeholders designing and using dashboards and hold the potential to improve dashboard use and student outcomes. © 2024 AERA.},
	author_keywords = {dashboard; data use; learning analytics; policy; systematic review},
	correspondence_address = {F.C. Curran; University of Florida, United States; email: chriscurran@coe.ufl.edu},
	publisher = {SAGE Publications Inc.},
	issn = {00346543},
	language = {English},
	abbrev_source_title = {Rev. Educ. Res.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Barbé202434,
	author = {Barbé, Rémi and Encelle, Benoît and Sehaba, Karim},
	title = {Investigating Learning Dashboards Adaptation},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	pages = {34 – 48},
	doi = {10.1007/978-3-031-72315-5_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205111148&doi=10.1007%2f978-3-031-72315-5_3&partnerID=40&md5=8ccfeed1b8d2675445a8eb2205cb6a63},
	affiliations = {Univ Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ Lyon 2, LIRIS, UMR5205, Villeurbanne, 69622, France; Univ Lyon, Univ Lyon 2, CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Bron, 69676, France},
	abstract = {Although there is a growing number of learning analytics dashboards (LADs), they often fail to improve learning and learners’ awareness due to their lack of adaptation capabilities. This paper presents a systematic review that follows the PRISMA statement and analyzes the adaptation features of LADs and their potential effects on learning. 24 of the 462 articles retrieved were scrutinized using an analysis framework centered on adaptation. The main finding is that there is more evidence of adaptable LADs than adaptive LADs, suggesting that adaptivity is worth exploring. The results mainly highlight 3 common LADs adaptable capabilities - most of which offer data exploration features - and 2 adaptive ones that change or refresh indicators on dashboards. Only a few articles investigate the adaptation of indicator visualizations or organization on dashboards. Currently, there is no work on the use of advanced computing techniques such as machine learning for LADs adaptation. Additionally, only 5 articles provide some evidence of dashboards adaptation features evaluation. As a result, a preliminary research agenda on LADs adaptation is suggested for enhancing LADs adoption and utility. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Adaptation; Learning Analytics Dashboards; Learning Indicators; Systematic Review},
	keywords = {Contrastive Learning; Federated learning; Adaptation; Adaptive learning; Adaptivity; Analysis frameworks; Computing techniques; Data exploration; Learning analytic dashboard; Learning indicator; Potential effects; Systematic Review; Adversarial machine learning},
	correspondence_address = {R. Barbé; Univ Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ Lyon 2, LIRIS, UMR5205, Villeurbanne, 69622, France; email: remi.barbe@liris.cnrs.fr},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ramaswami2023959,
	author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha and Umer, Rahila},
	title = {Use of Predictive Analytics within Learning Analytics Dashboards: A Review of Case Studies},
	year = {2023},
	journal = {Technology, Knowledge and Learning},
	volume = {28},
	number = {3},
	pages = {959 – 980},
	doi = {10.1007/s10758-022-09613-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137037645&doi=10.1007%2fs10758-022-09613-x&partnerID=40&md5=8327c52c6e1d44af400d554cc6003d75},
	affiliations = {School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; Engineering and Management Sciences, Balochistan University of Information Technology, Quetta, Pakistan},
	abstract = {Learning analytics dashboards (LADs) provide educators and students with a comprehensive snapshot of the learning domain. Visualizations showcasing student learning behavioral patterns can help students gain greater self-awareness of their learning progression, and at the same time assist educators in identifying those students who may be facing learning difficulties. While LADs have gained popularity, existing LADs are still far behind when it comes to employing predictive analytics into their designs. Our systematic literature review has revealed limitations in the utilization of predictive analytics tools among existing LADs. We find that studies leveraging predictive analytics only go as far as identifying the at-risk students and do not employ model interpretation or explainability capabilities. This limits the ability of LADs to offer data-driven prescriptive advice to students that can offer them guidance on appropriate learning adjustments. Further, published studies have mostly described LADs that are still at prototype stages; hence, robust evaluations of how LADs affect student outcomes have not yet been conducted. The evaluations until now are limited to LAD functionalities and usability rather than their effectiveness as a pedagogical treatment. We conclude by making recommendations for the design of advanced dashboards that more fully take advantage of machine learning technologies, while using suitable visualizations to project only relevant information. Finally, we stress the importance of developing dashboards that are ultimately evaluated for their effectiveness. © 2022, The Author(s).},
	author_keywords = {Early warning system; Learning analytics dashboard; Student feedback system; Systematic review},
	keywords = {Learning systems; Students; Visualization; Behavioral patterns; Case-studies; Early Warning System; Feedback systems; Learning analytic dashboard; Self awareness; Student feedback; Student feedback system; Student learning; Systematic Review; Predictive analytics},
	correspondence_address = {G. Ramaswami; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; email: g.ramaswami@massey.ac.nz},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Akçapınar2024810,
	author = {Akçapınar, Gökhan and López-Pernas, Sonsoles and Er, Erkan and Saqr, Mohammed},
	title = {How a Learning Analytics Dashboard Intervention Influences the Dynamics of Students’ Learning Behavior},
	year = {2024},
	journal = {Lecture Notes in Educational Technology},
	volume = {Part F3283},
	pages = {810 – 819},
	doi = {10.1007/978-981-97-1814-6_79},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201957276&doi=10.1007%2f978-981-97-1814-6_79&partnerID=40&md5=9266cb2ba7d1c8a5b094a0a811f05522},
	affiliations = {Hacettepe University, Ankara, 06050, Turkey; University of Eastern Finland, Joensuu, 80100, Finland; Middle East Technical University, Ankara, 06800, Turkey},
	abstract = {Interventions play a crucial role in completing the learning analytics cycle. However, there is limited research available on how students utilize these interventions or whether there is any change in their learning behaviors following the intervention. Existing studies primarily rely on students’ self-report perceptions, while neglecting the temporal aspect of the data in data-driven studies. This study examines the impact of a learning analytics intervention in the form of a learning analytics dashboard provided to students in a remote programming course on their learning behaviors. To achieve this goal, learning sessions before and after the introduction of the dashboard were identified using students’ learning traces in the learning management system. Subsequently, these learning sessions were analyzed using sequence analysis, process mining, and Bayesian Gaussian graphical models. Assignment submissions, formative quizzes, forum interactions, interactions with video materials, and participation in live classes were considered to determine students’ learning behaviors. The findings of the study indicate that there were changes in students’ learning behaviors after the introduction of the dashboard. Specifically, before the dashboard, learning sessions were mainly focused on assignments and quizzes, whereas after the dashboard, there was an increase in interactions with video materials. The results are also supported by the process mining analysis. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Bayesian Gaussian graphical models; Dashboard intervention; Learning analytics; Process mining; Sequence analysis},
	correspondence_address = {G. Akçapınar; Hacettepe University, Ankara, 06050, Turkey; email: gokhana@hacettepe.edu.tr},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Becerra2023,
	author = {Becerra, Álvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
	title = {User experience study using a system for generating multimodal learning analytics dashboards},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3612783.3612813},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183583754&doi=10.1145%2f3612783.3612813&partnerID=40&md5=b5d613f82f4970864afb63bb5c329ddc},
	affiliations = {Universidad Autónoma de Madrid, Spain},
	abstract = {In the article, we present a Web-based System called M2LADS, which supports the integration and visualization of multimodal data recorded in user experiences (UX) in a Learning Analytics (LA) system in the form of Web-based Dashboards. Based on the edBB platform, the multimodal data gathered contains biometric and behavioral signals including electroencephalogram data to measure learners' cognitive attention, heart rate for affective measures and visual attention from the video recordings. Additionally, learners' static background data and their learning performance measures are tracked using LOGGE tool. M2LADS provides opportunities to capture learners' holistic experience during their interactions with the learning analytic system in order to improve the system and the user experience of the learners.  © 2023 Owner/Author.},
	author_keywords = {Biometrics and Behavior; Dashboard; e-Learning; MOOC; Multimodal Learning Analytics; User Experience (UX)},
	keywords = {Behavioral research; Data visualization; E-learning; Learning systems; Video recording; Websites; Analytics systems; Biometric and behavior; Dashboard; E - learning; MOOC; Multi-modal data; Multi-modal learning; Multimodal learning analytic; User experience (UX); Users' experiences; Biometrics},
	editor = {Granollers i Saltiveri T. and Sendin Veloso M. and Garrido Navarro J.E. and Garcia Gonzalez R. and Teixido Cairol M. and Oliva Sole M.O. and Gil Iranzo R.M. and Almenara A.P. and Barrantes S.S. and Maritorena K.L. and Lega Llados F.J. and Goma J.V.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070790-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Soni202482,
	author = {Soni, Priyanshi and Prajapat, Shaligram},
	title = {Share Spell - From Fantasy to Reality: A Collaboration Platform with Learning Analytics for a Dynamic Online Learning Environment System},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {884 LNNS},
	pages = {82 – 110},
	doi = {10.1007/978-3-031-74443-3_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214212404&doi=10.1007%2f978-3-031-74443-3_5&partnerID=40&md5=88bb74f81fddb1a5c06419c74a9017c0},
	affiliations = {International Institute of Professional Studies, DAVV, Indore, India},
	abstract = {Growth of online learning and the need for interactions has increased globally and in India. The use of social media and online chat in educational environments became the backbone for this learning. Traditional classroom communication lacks freedom due to moderator control and time limitations. To support this, the Share Spell platform aims here as a secure, moderated communication model with a resource-sharing mechanism. It uses role-based access control to enhance information sharing and promote effective discussions in professional learning settings. Share Spell model here is for users to post and manage content within predefined categories, participate in discussions, and report inappropriate content, while administrators manage user access, categories, and reported content through a comprehensive dashboard. This work contributes to the development process of Massive online open courses for self-paced learners. The collaborative nature of MOOCs (Massive Open Online Courses), and ability to simulate professional environments to enhance communication and knowledge sharing among learners. The proposed model enhances learner performance, contributing to their success and growth using discussion forums. The prototype accommodates diverse learning styles, encourages professional behavior, and advanced analytics to continuously improve user experience and the effectiveness of knowledge sharing. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Communication Platform; Content Moderation; Knowledge Sharing; Role-Based Access Control; User Engagement Analysis},
	keywords = {Collaborative learning; Contrastive Learning; Federated learning; Collaboration platforms; Communication platforms; Content moderation; Engagement analysis; Environment systems; Knowledge-sharing; Online learning environment; Role-based Access Control; User engagement; User engagement analyze; Adversarial machine learning},
	correspondence_address = {P. Soni; International Institute of Professional Studies, DAVV, Indore, India; email: sonipriyanshi.ps99@gmail.com},
	editor = {Naik N. and Grace P. and Jenkins P. and Prajapat S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303174442-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cheng202497,
	author = {Cheng, Ka Lok and Chan, Carol Kwai Kuen and Tu, Yuanyang and Hu, Xiao},
	title = {Examining Students' Online Learning and Collaboration Using Analytics-Supported Assessment Tools and Dashboards},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	pages = {97 – 99},
	doi = {10.1109/ICALT61570.2024.00034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203834052&doi=10.1109%2fICALT61570.2024.00034&partnerID=40&md5=60e0121a1463ccd068b1efb51645dea6},
	affiliations = {Faculty of Education, The University of Hong Kong, Hong Kong, Hong Kong; Faculty of Engineering, The University of Hong Kong, Hong Kong, Hong Kong},
	abstract = {This paper reports on the preliminary findings of designing a learning analytical tool to assess and facilitate online collaborative learning in discussion forums. The analytics tool developed is grounded on collaboration theories to unravel students' online collaboration, encompassing three features: (a) participation and build-on posts, (b) lexical keywords for domain understanding, and (c) communicative acts for dialogic interactions. The tool was designed to analyze students' online discussions for two classes in a postgraduate educational studies course. Findings unravel student online collaboration behaviour, including (a) high engagement with online posts exceeding course requirements, (b) frequency/ links among keywords used (not used) indicate students' knowledge networks and gaps, and (3) dialogic communication acts commonly employed while higher-level acts (e.g., coordination) not yet adopted. Findings also indicate student groups using a higher frequency of communication acts (more dialogic in discussion) also obtained higher grades, providing some validation. Implications suggest how the tools can be used to assess social-semantic-dialogic online collaborative behaviour and how instructors can use analytics information to adapt their instructional strategies to address students' knowledge gaps and provide feedback. Students can also use the analytics information to regulate and improve online discussions. © 2024 IEEE.},
	author_keywords = {dialogic talk; learning analytics; Moodle plugins; online collaborative learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Students; Communication act; Dialogic talk; Knowledge gaps; Learning analytic; Moodle plugin; On-line collaborations; Online collaborative learning; Online learning; Plug-ins; Student knowledge; Collaborative learning},
	correspondence_address = {K.L. Cheng; Faculty of Education, The University of Hong Kong, Hong Kong, Hong Kong; email: chengkla@hku.hk},
	editor = {Altinay Z. and Chang M. and Kuo R. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036205-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Šumak2024472,
	author = {Šumak, Boštjan and López-De-Ipiña, Diego and Dziabenko, Olga and Correia, Sěrgio Duarte and De Carvalho, Luǐsa M. Serrano and Lopes, Secundino and Şimşek, Irfan and Can, Tuncer and Kline, Darja Ivanuša and Pušnik, Maja},
	title = {AI-Based Education Tools for Enabling Inclusive Education: Challenges and Benefits},
	year = {2024},
	journal = {2024 47th ICT and Electronics Convention, MIPRO 2024 - Proceedings},
	pages = {472 – 477},
	doi = {10.1109/MIPRO60963.2024.10569714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198224155&doi=10.1109%2fMIPRO60963.2024.10569714&partnerID=40&md5=bf579bd51a5de486022219e3a2da0c8c},
	affiliations = {University Of Maribor, Faculty Of Electrical Engineering And Computer Science, Maribor, Slovenia; University Of Deusto, Universidad De La Iglesia De Deusto Entidad Religiosa, Bilbao, Spain; Portalegre Polytechnic University, Portalegre, Portugal; Istanbul University - Cerrahpasa, Istanbul, Turkey; Institut Za Napredno Upravljanje Komunikacij, Maribor, Slovenia},
	abstract = {Advancements in artificial intelligence (AI) have sparked high hopes for the potential impact of AI on education and learning. AI tools designed for educational purposes encompass diverse solutions, including intelligent tutoring systems, chatbots, robotics, learning analytics dashboards, adaptive learning systems, and automated assessments. These tools have the capacity to fortify and augment the educational process. Integrating AI-based educational tools not only holds advantages for students, educators, and institutions, but also has the potential to facilitate or enhance inclusive education notably. This article presents the findings of analyzing available AI technologies and tools for education with the capacity to contribute to inclusive education. The study aims to identify and classify the challenges and benefits associated with AI-based education tools in the context of enabling inclusive education.  © 2024 IEEE.},
	author_keywords = {AI-based inclusive education tools; AI-enabled inclusive digital education; inclusive digital education},
	keywords = {Computer aided instruction; E-learning; Education computing; Artificial intelligence tools; Artificial intelligence-based inclusive education tool; Artificial intelligence-enabled inclusive digital education; Diverse solutions; Education tool; Inclusive digital education; Inclusive education; Intelligent tutoring; Potential impacts; Tutoring system; Learning systems},
	correspondence_address = {B. Šumak; University Of Maribor, Faculty Of Electrical Engineering And Computer Science, Maribor, Slovenia; email: bostjan.sumak@um.si; },
	editor = {Babic S. and Car Z. and Cicin-Sain M. and Cisic D. and Ergovic P. and Grbac T.G. and Gradisnik V. and Gros S. and Jokic A. and Jovic A. and Jurekovic D. and Katulic T. and Koricic M. and Mornar V. and Petrovic J. and Skala K. and Skvorc D. and Sruk V. and Svaco M. and Tijan E. and Vrcek N. and Vrdoljak B.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038249-5},
	language = {English},
	abbrev_source_title = {ICT Electron. Conv., MIPRO - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@BOOK{Koh20231367,
	author = {Koh, Elizabeth and Hu, Xiao},
	title = {Learning analytics for learning: Emerging international trends and case studies from the Asia-Pacific},
	year = {2023},
	journal = {International Handbook on Education Development in the Asia-Pacific},
	pages = {1367 – 1393},
	doi = {10.1007/978-981-19-6887-7_54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203112420&doi=10.1007%2f978-981-19-6887-7_54&partnerID=40&md5=6b36b05dae30f02d3b38f620352c18fa},
	affiliations = {National Institute of Education, Nanyang Technological University, Singapore, Singapore; Faculty of Education, The University of Hong Kong, Hong Kong SAR, China; The Institute of Data Science, University of Hong Kong, Hong Kong SAR, China},
	abstract = {In this chapter, an overview of learning analytics is provided-highlighting emerging international trends-illustrated with innovative case studies from the Asia-Pacific. As a growing field intersecting learning and pedagogical theories, human-centered design, and data science, learning analytics has many applications in K-12 and adult learning settings, from enhancing learning progress and learning awareness, improving cognitive learning outcomes, nurturing socioemotional and lifelong learning skills, to intervening with prompts, tasks, feedback, and learning strategies. While there are many recent movements such as multimodal learning analytics, trustable data, and actionable dashboards, they essentially drive towards the ultimate purpose-learning analytics is for optimizing learning. Upon reviewing influential literature in the field, we conceptualize a framework to map current research trends in learning analytics into seven dimensions, including the foundational lens, visual feedback, indicators and metrics, design approach, function/purpose type, data modality, and ethics. This framework demonstrates a global convergence in the field with wide application including the Asia-Pacific region. Case studies of learning analytics applications from Hong Kong and Singapore are illustrated to highlight the fruitful ways how learning and learning environments have been optimized, along the dimensions in the framework. The chapter concludes with a synthesis and critique of current learning analytics research and suggests implications for learning analytics researchers, developers, and users including practitioners. © Springer Nature Singapore Pte Ltd. 2023. All rights reserved.},
	author_keywords = {Case studies; Data-driven learning; Innovation; Learning analytics; Technology},
	correspondence_address = {E. Koh; National Institute of Education, Nanyang Technological University, Singapore, Singapore; email: elizabeth.koh@nie.edu.sg},
	publisher = {Springer Nature},
	isbn = {978-981196887-7; 978-981196886-0},
	language = {English},
	abbrev_source_title = {Int. Handb. on Educ. Dev. in the Asia-Pac.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Brown20249,
	author = {Brown, Michael and Wiedbusch, Megan and Patel, Milouni and Naderi, Evan and Capello, Sophia and Llinas, Andrea and Azevedo, Roger and Margondai, Ancuta},
	title = {Designing for Self-Regulated Learning: A Dual-View Intelligent Visualization Dashboard to Support Instructors and Students Using Multimodal Trace Data in Classrooms},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2117 CCIS},
	pages = {9 – 19},
	doi = {10.1007/978-3-031-61953-3_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196704616&doi=10.1007%2f978-3-031-61953-3_2&partnerID=40&md5=309829155ca148e49ad86360db02bd33},
	affiliations = {University of Central Florida, Orlando, United States},
	abstract = {Effective learning analytics dashboards (LADs) should offer both instructors and students valuable insights into student learning. Information about one’s learning, as both a product and a process, should be provided to the user as actionable data visualizations and aggregated indicators of learning. However, most dashboards often solely focus on the instructor’s perspective, neglecting the impact of providing students with their data in a student view. Furthermore, these dashboards assume instructors are proficient in data analytics and can quickly interpret complicated visualizations in-situ while accounting for context and conditional factors. This challenge is further exacerbated by the lack of theoretically informed learning analytics principles and design choices as many of the dashboards rely primarily on performance-based data, neglecting process and trace data of cognitive, metacognitive, affective, motivational, and social (CAMMS) processes. As such, we are introducing MetaDash, a multimodal self-regulated learning (SRL) dashboard with both an instructor and student view. This dual-view (i.e., instructor and student-facing) dashboard prototype is populated with aggregate and contextualized multimodal trace data grounded within models of SRL, affect dynamics, information processing, cognitive load, and multimodal learning analytics. In this paper, we leverage ideas derived from SRL to identify gaps in current learning analytics dashboards. We then present the design principles and architecture of MetaDash, including how we derived its structure and how it supports our framework. We discuss the affective dynamics and learning analytics on the landing page to understand user engagement and detail how analytics are customized for different phases within the architecture. We highlight the advantages of incorporating real-time data analysis for immediate decision-making. Future research will focus on refining MetaDash through enhancements informed by user and focus group testing, experimental studies, and the integration of user feedback to address challenges and expand the dashboard’s functionality and effectiveness. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Dashboard; Learning Analytics; Metacognition; Multimodal; Self-Regulated Learning},
	keywords = {Data Analytics; Data visualization; Decision making; Integration testing; Visualization; Dashboard; Data analytics; Effective learning; Learning analytic; Metacognition; Multi-modal; Self-regulated learning; Student learning; Students' views; Trace data; Students},
	correspondence_address = {M. Brown; University of Central Florida, Orlando, United States; email: michael.brown2@ucf.edu},
	editor = {Stephanidis C. and Antona M. and Ntoa S. and Salvendy G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303161952-6},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Alonso-Fernández2024,
	author = {Alonso-Fernández, Cristina and Jorro-Aragoneses, José L. and Alaíz, Carlos M. and Rodríguez, Pilar},
	title = {Learning Analytics Tools to Analyze Progress and Results with Moodle LMS Data},
	year = {2024},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	doi = {10.1109/EDUCON60312.2024.10578707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199035625&doi=10.1109%2fEDUCON60312.2024.10578707&partnerID=40&md5=c9ec41894ecc59b87a9509ec876874dd},
	affiliations = {Universidad Autónoma de Madrid, Computer Science Department, Madrid, Spain},
	abstract = {Teachers can benefit from the information provided by learning analytics data for multiple purposes. Visual learning analytics dashboards provide near real-time information while more complex offline tools are commonly used to synthesize and transform the data gathered into interpretable information for teachers. The extended use of Learning Management Systems in universities, such as Moodle or Canvas, provides a rich environment to capture learning analytics data from students' interactions while they are progressing in their courses. In this paper, we present two different learning analytics tools aimed at teachers to obtain information about students' progress and results using data from the Moodle LMS at different stages of their learning process: (1) a progress visualization plugin for Moodle, which provides teachers with real-time information about the progress achieved by students in their courses, and the different goals set for their plans; and (2) an analytics Jupyter Notebook tool with a pre-defined set of analysis and visualizations to apply to data gathered from default activities in Moodle. The plugin is in an initial validation stage, while the analysis tool has been tested in a case study in a university course. Combined, both contributions can enrich the information that teachers have during and after the academic year, adapting their classes to better fit students' progress and needs, as well as providing overall results and comparison between groups after the course has finished.  © 2024 IEEE.},
	author_keywords = {dashboards; learning analytics; LMS; Moodle; visualization},
	keywords = {Data visualization; Information management; Learning systems; Students; Teaching; Analytic tools; Dashboard; Learning analytic; LMS; Moodle; Plug-ins; Real-time information; Student progress; Teachers'; Visual learning; Visualization},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {979-835039402-3},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Masiello2024,
	author = {Masiello, Italo and Mohseni, Zeynab and Palma, Francis and Nordmark, Susanna and Augustsson, Hanna and Rundquist, Rebecka},
	title = {A Current Overview of the Use of Learning Analytics Dashboards},
	year = {2024},
	journal = {Education Sciences},
	volume = {14},
	number = {1},
	doi = {10.3390/educsci14010082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183134033&doi=10.3390%2feducsci14010082&partnerID=40&md5=c0664ad1bff3b7feaea5edfb1f82a7d8},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, 352 52, Sweden; Faculty of Computer Science, University of New Brunswick, Fredericton, E3B 5A3, NB, Canada; Department of Learning, Informatics, Management and Ethics, Karolinska Institutet, Solna, 171 77, Sweden; Department of Pedagogy and Learning, Linnaeus University, Växjö, 352 52, Sweden},
	abstract = {The promise of Learning Analytics Dashboards in education is to collect, analyze, and visualize data with the ultimate ambition of improving students’ learning. Our overview of the latest systematic reviews on the topic shows a number of research trends: learning analytics research is growing rapidly; it brings to the front inequality and inclusiveness measures; it reveals an unclear path to data ownership and privacy; it provides predictions which are not clearly translated into pedagogical actions; and the possibility of self-regulated learning and game-based learning are not capitalized upon. However, as learning analytics research progresses, greater opportunities lie ahead, and a better integration between information science and learning sciences can bring added value of learning analytics dashboards in education. © 2024 by the authors.},
	author_keywords = {LAD; learning analytics dashboards; trends},
	correspondence_address = {I. Masiello; Department of Computer Science and Media Technology, Linnaeus University, Växjö, 352 52, Sweden; email: italo.masiello@lnu.se},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gonzalez2024,
	author = {Gonzalez, Nubia Andrea del Pilar and Chiappe, Andrés},
	title = {Learning analytics and personalization of learning: a review; [Análise de aprendizagem e personalização de aprendizagem: uma revisão]; [Análisis de aprendizaje y personalización del aprendizaje: una revisión]},
	year = {2024},
	journal = {Ensaio},
	volume = {32},
	number = {122},
	doi = {10.1590/S0104-40362024003204234},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187151456&doi=10.1590%2fS0104-40362024003204234&partnerID=40&md5=a278551cfb1994e04e23081ef8826d3c},
	affiliations = {Universidad de La Sabana, Chía, Colombia; Universidad de La Sabana, Chía, Colombia},
	abstract = {Education in the 21st century is increasingly mediated by digital technologies in a context in which enormous amounts of information are daily generated. Regarding this and considering the imminent application of emerging trends such as “Internet of Things” (IoT), the study of its educational effects becomes a matter of great relevance for both educational researchers and practitioners. In this context, “Learning Analytics” takes on special importance as a perspective to approach the aforementioned issue, especially from a very relevant topic: the personalization of learning. In this sense, a systematic review of literature about learning analytics published in the last two decades was carried out to identify its potential as a factor in strengthening the personalization of learning. The results show a set of key factors that include aspects related to assessment, the use of dashboards, social learning networks, and intelligent tutoring, and the importance of monitoring, feedback, and support. © (2024), (SciELO-Scientific Electronic Library Online). All Rights Reserved.},
	author_keywords = {21st-Century Skills; Data Science Applications in Education; Evaluation Methodologies; Information Literacy; Pedagogical Issues},
	publisher = {Fundacao Cesgranrio},
	issn = {01044036},
	language = {English},
	abbrev_source_title = {Ensaio},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Giorgashvili2024135,
	author = {Giorgashvili, Tornike and Jivet, Ioana and Artelt, Cordula and Biedermann, Daniel and Bengs, Daniel and Goldhammer, Frank and Hahnel, Carolin and Mendzheritskaya, Julia and Mordel, Julia and Onofrei, Monica and Winter, Marc and Wolter, Ilka and Horz, Holger and Drachsler, Hendrik},
	title = {Exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	pages = {135 – 151},
	doi = {10.1007/978-3-031-72315-5_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205116649&doi=10.1007%2f978-3-031-72315-5_10&partnerID=40&md5=7de055dbe6f650e3b905c5ca728e857a},
	affiliations = {Studium Digitale and Faculty of Computer Science, Educational Psychology, Goethe University, Frankfurt am Main, Germany; DIPF | Leibniz Institute for Research and Information in Education, Frankfurt, Germany; LIfBi | Leibniz Institute for Educational Trajectories, Bamberg, Germany; Ruhr University Bochum, Bochum, Germany; Centre for International Student Assessment (ZIB), Munich, Germany; CATALPA, FernUniversität in Hagen, Hagen, Germany},
	abstract = {Learning Analytics Dashboards (LAD) have been developed as feedback tools to help students self-regulate their learning (SRL), using the large amounts of data generated by online learning platforms. Despite extensive research on LAD design, there remains a gap in understanding how learners make sense of information visualised on LADs and how they self-reflect using these tools. We address this gap through an experimental study where a LAD delivered personalised SRL feedback based on interactions and progress to a treatment group, and minimal feedback based on the average scores of the class to a control group. Following the feedback, students were asked to state in writing how they would change their study behaviour. Using a coding scheme covering learning strategies, metacognitive strategies and learning materials, three human coders coded 1,251 self-reflection texts submitted by 417 students at three time points. Our results show that learners who received personalised feedback intend to focus on different aspects of their learning in comparison to the learners who received minimal feedback and that the content of the dashboard influences how students formulate their self-reflection texts. Based on our findings, we outline areas where support is needed to improve learners’ sense-making of feedback on LADs and self-reflection in the long term. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Formative Feedback; Learning Analytics Dashboards; Learning Design; Psychometrics; Self-Reflection; Self-Regulated Learning},
	keywords = {Adversarial machine learning; Federated learning; Self-supervised learning; Students; Authentic learning; Feed-back based; Feedback tool; Formative feedbacks; Learning analytic dashboard; Learning designs; Learning settings; Psychometric; Self reflection; Self-regulated learning; Contrastive Learning},
	correspondence_address = {T. Giorgashvili; Studium Digitale and Faculty of Computer Science, Educational Psychology, Goethe University, Frankfurt am Main, Germany; email: giorgash@sd.uni-frankfurt.de},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Reid20241037,
	author = {Reid, David P. and Drysdale, Timothy D.},
	title = {Student-Facing Learning Analytics Dashboard for Remote Lab Practical Work},
	year = {2024},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {17},
	pages = {1037 – 1050},
	doi = {10.1109/TLT.2024.3354128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182934351&doi=10.1109%2fTLT.2024.3354128&partnerID=40&md5=889d4aa66539564ca0fb01a7eb4b27d4},
	affiliations = {University of Edinburgh, School of Engineering, Edinburgh, EH9 3FB, United Kingdom},
	abstract = {The designs of many student-facing learning analytics (SFLA) dashboards are insufficiently informed by educational research and lack rigorous evaluation in authentic learning contexts, including during remote laboratory practical work. In this article, we present and evaluate an SFLA dashboard designed using the principles of formative assessment to provide feedback to students during remote lab activities. Feedback is based upon graphical visualizations of student actions performed during lab tasks and comparison to expected procedures using TaskCompare - our custom, asymmetric graph dissimilarity measure that distinguishes students who miss expected actions from those who perform additional actions, a capability missing in existing graph distance (symmetrical dissimilarity) measures. Using a total of $N = 235$ student graphs collected during authentic learning in two different engineering courses, we describe the validation of TaskCompare and evaluate the impact of the SFLA dashboard on task completion during remote lab activities. In addition, we use components of the motivated strategies for learning questionnaire as covariates for propensity score matching to account for potential bias in self-selection of use of the dashboard. We find that those students who used the SFLA dashboard achieved significantly better task completion rate (nearly double) than those who did not, with a significant difference in TaskCompare score between the two groups (Mann-Whitney $U = 453.5$, $p < 0.01$ and Cliff's $\delta = 0.43$, large effect size). This difference remains after accounting for self-selection. We also report that students' positive rating of the usefulness of the SFLA dashboard for completing lab work is significantly above a neutral response ($S = 21.0$ and $p < 0.01$). These findings provide evidence that our SFLA dashboard is an effective means of providing formative assessment during remote laboratory activities. © 2008-2011 IEEE.},
	author_keywords = {Feedback; formative assessment; graphs; learning analytics (LA); online learning; remote learning; self-regulated learning (SRL)},
	keywords = {Curricula; E-learning; Facings; Feedback; Industrial research; Job analysis; Laboratories; Atmospheric measurement; Formative assessment; Graph; Learning analytic; Online learning; Particle measurement; Remote laboratories; Remote learning; Self-regulated learning; Task analysis; Video; Students},
	correspondence_address = {T.D. Drysdale; University of Edinburgh, School of Engineering, Edinburgh, EH9 3FB, United Kingdom; email: timothy.drysdale@ed.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Lee-Cultura2024181,
	author = {Lee-Cultura, Serena and Sharma, Kshitij and Giannakos, Michail N.},
	title = {Multimodal Teacher Dashboards: Challenges and Opportunities of Enhancing Teacher Insights Through a Case Study},
	year = {2024},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {17},
	pages = {181 – 201},
	doi = {10.1109/TLT.2023.3276848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162847147&doi=10.1109%2fTLT.2023.3276848&partnerID=40&md5=b9ba0504d8d22e7cb3d0482445293543},
	affiliations = {Norwegian University of Science and Technology, Learner-Computer Interaction Lab, Trondheim, 7034, Norway},
	abstract = {Teacher dashboards provide insights on students' progress through visualizations and scores derived from data generated during teaching and learning activities (e.g., response times and task correctness) to improve teaching. Despite the potential usefulness of enhancing teacher dashboards, and the respective teaching practices, with rich information regarding students' cognitive and affective states (e.g., cognitive load), few studies on teacher dashboards have considered such information. In this study, we drew on contemporary developments of multimodal (MM) learning analytics and designed an MM teacher dashboard with a notification system. The proposed system: 1) receives data from various sensors; 2) computes relevant cognitive and affective measurements; 3) visualizes the resulting measurements in a clean customizable interface; and 4) notifies instructors during moments of interest, so they may determine an appropriate method to support struggling students. To evaluate our MM teacher dashboard, we first collected multimodal data (MMD), performance data, and video recordings of students' interactions during an in situ study where 26 students engaged with a motion-based learning task. Then, we used our MM teacher dashboard to present the collected MMD and video recordings to 20 experienced teachers and educational researchers and collected qualitative data regarding respondents' insights on the advantages and challenges of visualizing students' MMD. Results showed that teachers found an MM teacher dashboard enhanced with a notification system, useful to complement their pedagogical practices. We offer empirically founded guidelines for design and integration of an MM teacher dashboard with notification systems, aimed to enhance teachers' understanding of students' learning states (e.g., real-time awareness of students' stress). © 2008-2011 IEEE.},
	author_keywords = {Educational technologies; learning analytics; multimodal; teacher dashboards},
	keywords = {Data visualization; Interactive computer systems; Job analysis; Students; Teaching; Video recording; Visualization; Educational tech- nologies; Learning analytic; Multi-modal; Multi-modal data; Notification systems; Real - Time system; Task analysis; Teacher dashboard; Teachers'; Tracking; Real time systems},
	correspondence_address = {S. Lee-Cultura; Norwegian University of Science and Technology, Learner-Computer Interaction Lab, Trondheim, 7034, Norway; email: serenal@stud.ntnu.no},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Yang2024892,
	author = {Yang, Yuanyuan and Majumdar, Rwitajit and Li, Huiyong and Flanagan, Brendan and Ogata, Hiroaki},
	title = {Design of a learning dashboard to enhance reading outcomes and self-directed learning behaviors in out-of-class extensive reading},
	year = {2024},
	journal = {Interactive Learning Environments},
	volume = {32},
	number = {3},
	pages = {892 – 909},
	doi = {10.1080/10494820.2022.2101126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134514340&doi=10.1080%2f10494820.2022.2101126&partnerID=40&md5=b3134175025d3abc017750a129141baf},
	affiliations = {Graduate School of Informatics, Kyoto University, Kyoto, Japan; Academic Center for Computing and Media Studies, Kyoto University, Kyoto, Japan},
	abstract = {Self-directed learning (SDL) requires students to take initiative to learn and control their own learning process. Literature highlights the importance of SDL for lifelong learning. Yet, little understanding is known regarding how to support SDL at the school level, specifically for out-of-class learning context. To fill up this gap, this research developed a learning dashboard and integrated SDL process management in GOAL system. It was implemented to provide support for out-of-class online self-directed extensive reading (SDER) at a high school level. A two-group study conducted during a three-week spring vacation found the experimental group (N = 35, with SDL support) achieved significantly more reading outcomes than the control group (N = 12, without SDL support). Detailed GOAL interaction behavior analysis of the experimental group showed that viewing learning dashboard was significantly correlated with reading outcomes as well as interactions related to SDL process management. These findings highlights positive effect of SDL support in GOAL on students' out-of-class SDER outcomes as well as their SDL behaviors. The study provided implications for research related to extensive reading and SDL support for out-of-class learning. © 2022 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {extensive reading; Learning analytics; learning dashboard; out-of-class learning; self-directed learning; self-direction},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{Bahari2023,
	author = {Bahari, Mahadi and Arpaci, Ibrahim and Azmi, Nurulhuda Firdaus Mohd and Shuib, Liyana},
	title = {Predicting the Intention to Use Learning Analytics for Academic Advising in Higher Education},
	year = {2023},
	journal = {Sustainability (Switzerland)},
	volume = {15},
	number = {21},
	doi = {10.3390/su152115190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199227065&doi=10.3390%2fsu152115190&partnerID=40&md5=c94757a01b453ee3aebe2a310b2a83dd},
	affiliations = {Department of Information Systems, Faculty of Management, Universiti Teknologi Malaysia, Johor, 81310, Malaysia; College of Business Administration, University of Business Technology, Jeddah, 23435, Saudi Arabia; UTM Big Data Centre, Universiti Teknologi Malaysia, Skudai, 81310, Malaysia; Department of Software Engineering, Faculty of Engineering and Natural Sciences, Bandirma Onyedi Eylul University, Balikesir, 10200, Turkey; Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia},
	abstract = {Learning analytics (LA) is a rapidly growing educational technology with the potential to enhance teaching methods and boost student learning and achievement. Despite its potential, the adoption of LA remains limited within the education ecosystem, and users who do employ LA often struggle to engage with it effectively. As a result, this study developed and assessed a model for users’ intention to utilize LA dashboards. The model incorporates constructs from the “Unified Theory of Acceptance and Use of Technology”, supplemented with elements of personal innovativeness, information quality, and system quality. The study utilized exploratory research methodology and employed purposive sampling. Participants with prior experience in LA technologies were selected to take part in the study. Data were collected from 209 academic staff and university students in Malaysia (59.33% male) from four top Malaysian universities using various social networking platforms. The research employed “Partial Least Squares Structural Equation Modeling” to explore the interrelationships among the constructs within the model. The results revealed that information quality, social influence, performance expectancy, and system quality all positively impacted the intention to use LA. Additionally, personal innovativeness exhibited both direct and indirect positive impacts on the intention to use LA, mediated by performance expectancy. This study has the potential to offer valuable insights to educational institutions, policymakers, and service providers, assisting in the enhancement of LA adoption and usage. This study’s contributions extend beyond the present research and have the potential to positively impact the field of educational technology, paving the way for improved educational practices and outcomes through the thoughtful integration of LA tools. The incorporation of sustainability principles in the development and deployment of LA tools can significantly heighten their effectiveness, drive user adoption, and ultimately nurture sustainable educational practices and outcomes. © 2023 by the authors.},
	author_keywords = {academic advising; educational institutions; learning analytics; user intention},
	keywords = {Malaysia; higher education; learning; research method; social network; student; sustainability; teaching},
	correspondence_address = {M. Bahari; Department of Information Systems, Faculty of Management, Universiti Teknologi Malaysia, Johor, 81310, Malaysia; email: mahadi@utm.my; I. Arpaci; Department of Software Engineering, Faculty of Engineering and Natural Sciences, Bandirma Onyedi Eylul University, Balikesir, 10200, Turkey; email: iarpaci@bandirma.edu.tr},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Heinemann2024251,
	author = {Heinemann, Birte and Görzen, Sergej and Dragoljić, Ana and Meiendresch, Lars Florian and Troll, Marc and Schroeder, Ulrik},
	title = {A Learning Analytics Dashboard to Investigate the Influence of Interaction in a VR Learning Application},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3667},
	pages = {251 – 259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192005727&partnerID=40&md5=b8ebbad300600c5e4a85d01ff981b56a},
	affiliations = {RWTH Aachen University, Ahornstraße 55, Aachen, 52074, Germany},
	abstract = {Learning in Virtual Reality offers various ways to make the learning process interactive, but the implementation of such features is complex, time-consuming and expensive. In order to evaluate the efficiency of interactive tasks, a Learning Analytics dashboard, presented in this paper, was created for both teachers/educators and content creators. The dashboard presents data from a study with different interactive/immersive and non-interactive/non-immersive variants of a learning application for the rendering pipeline, a showcase topic from computer graphics. The dashboard has been implemented with transferability in mind by using xAPI as a data format and can thus be easily transferred to other contexts. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Dashboard; Learning Analytics; Multi-modal Learning Analytics; Rendering Pipeline; Virtual Reality},
	keywords = {E-learning; Learning systems; Pipelines; Rendering (computer graphics); Content creators; Dashboard; Immersive; Learning analytic; Learning process; Multi-modal learning; Multi-modal learning analytic; Rendering pipelines; Teachers'; Virtual reality},
	correspondence_address = {B. Heinemann; RWTH Aachen University, Aachen, Ahornstraße 55, 52074, Germany; email: heinemann@cs.rwth-aachen.de},
	editor = {Hlosta M. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Moser I. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Flanagan B. and Kyoto University, Center for Innovative Research and Education in Data Science, Room 302 Konoe-kan, 69 Konoe-cho, Sakyo-ku, Yoshida, Kyoto and Fernandez-Nieto G.M. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Yan L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Stewart A. and University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, PA and Winer A. and Open University of Israel, POB 808, 1 University Road, Raanana and Geri N. and Open University of Israel, POB 808, 1 University Road, Raanana and Ramnarain U. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and van der Westhuizen C. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and Shimada A. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Okubo F. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Tseng H.-T. and National Central University, Department of Information Management, 300 Jhongda Road, Zhongli District, Taoyuan City and Yang A.C.M. and National Chung-Hsing University, Department of Computer Science and Engineering, 145 Xingda Road, South District, Taichung and Lu O.H.T. and National Chengchi University, International College of Innovation (ICI), No. 64, Sec 2, Zhinan Rd, Wenshan District, Taipei City and Ogata H. and Kyoto University, Academic Center for Computing and Media Studies, Yoshida Nihonmatsu-cho , Sakyo-ku, Kyoto and Echeverria V. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Martinez-Maldonado R. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Tsai Y.-s. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lawrence L. and Utah State University, Instructional Technology of Learning Sciences, Old Main Hill, Logan, UT and Singh S. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Pozdniakov S. and Chen L.K. and University of Maryland Baltimore County, Department of Information Systems, 1000 Hilltop Circle, Baltimore, MD and Gong J. and Yarnall L. and SRI, SRI Education, 333 Ravenswood Ave, Menlo Park, CA and Nguyen A. and University of Oulu, Faculty of Education and Psychology, Pentti Kaiteran katu 1 Linnanmaa, Oulu and Sha L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lin J. and Carnegie Mellon University, Human-Computer Interaction Institute, 4804 Forbes Avenue, Pittsburgh, PA and Cukurova M. and University College London, UCL Knowledge Lab, 20 Bedford Way, London and Sharma K. and Norwegian University of Science and Technology, Department of Computer Science, IT-bygget, 147, Gloshaugen and Zhao L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Li Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Jin Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Gasevic D. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Mills C. and University of Minnesota, 250 Education Sciences Bldg, 56 E River Rd, Minneapolis, MN and Hutt S. and University of Denver, 2155 E Wesley Drive, Denver, CO},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{2024,
	title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205105826&partnerID=40&md5=22b3be799700285565dc06b4e080e3d1},
	abstract = {The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Weagant202421,
	author = {Weagant, Riley and Zhao, Zixin and Bradley, Adam and Collins, Christopher},
	title = {AdVizor: Using Visual Explanations to Guide Data-Driven Student Advising},
	year = {2024},
	journal = {Proceedings - 2024 IEEE VIS Workshop on Visualization Education, Literacy, and Activities, EduVIS 2024},
	pages = {21 – 29},
	doi = {10.1109/EduVIS63909.2024.00008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212838299&doi=10.1109%2fEduVIS63909.2024.00008&partnerID=40&md5=4a16c30363bc849f729cf2d48e0b9b10},
	affiliations = {Ontario Tech University, Canada},
	abstract = {Academic advising can positively impact struggling students' success. We developed AdVizor, a data-driven learning analytics tool for academic risk prediction for advisors. Our system is equipped with a random forest model for grade prediction probabilities uses a visualization dashboard to allows advisors to interpret model predictions. We evaluated our system in mock advising sessions with academic advisors and undergraduate students at our university. Results show that the system can easily integrate into the existing advising workflow, and visualizations of model outputs can be learned through short training sessions. AdVizor supports and complements the existing expertise of the advisor while helping to facilitate advisor-student discussion and analysis. Advisors found the system assisted them in guiding student course selection for the upcoming semester. It allowed them to guide students to prioritize the most critical and impactful courses. Both advisors and students perceived the system positively and were interested in using the system in the future. Our results encourage the development of intelligent advising systems in higher education, catered for advisors. © 2024 IEEE.},
	author_keywords = {Academic Advising; Academic Risk Prediction; Information Visualization; Learning Analytics},
	keywords = {Adversarial machine learning; Contrastive Learning; Data visualization; Decision trees; Intelligent systems; Students; Visual analytics; Visualization; Academic advising; Academic risk prediction; Analytic tools; Data driven; Grade predictions; Information visualization; Learning analytic; Random forest modeling; Risk predictions; Student success; Prediction models},
	correspondence_address = {Z. Zhao; Ontario Tech University, Canada; email: zixin.zhao@ontariotechu.net},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036904-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE VIS Workshop Vis. Educ., Lit., Act., EduVIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{El-Khalili2024,
	author = {El-Khalili, Nuha and Abu Arqoub, Muhammad and Hasan, Mohammad Al-Shaikh and Banna, Abed Alkarim and Arafah, Mohammad},
	title = {Empowering Learning Analytics with Business Intelligence},
	year = {2024},
	journal = {2nd International Conference on Cyber Resilience, ICCR 2024},
	doi = {10.1109/ICCR61006.2024.10533111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195149000&doi=10.1109%2fICCR61006.2024.10533111&partnerID=40&md5=52aa225c35326ce33ff8ec6bd1f9beba},
	affiliations = {University Of Petra, Software Engineering Department, Amman, Jordan; University Of Petra, Computer Science Department, Amman, Jordan; Brunel University London, Computer Science Department, London, United Kingdom},
	abstract = {Business Intelligence (BI) tools can provide benefits to various stakeholders in Higher Education Institutions (HEI) and support the academic process. We use BI tools to visualize data produced from learning analytics systems at the University of Petra (UOP). The utilized data come from two different sources: a learning outcomes calculation system and a student registration system. In this work, we visualize the data as dashboards using power BI to help students and advisors to monitor the progress of student attainment of program outcomes over the courses and years of study, thus facilitating the prediction of student performance. We also visualize the attainment of program outcomes in relation to student attributes, which facilitate data- driven decision making. The future work of this work is to collect data for a full cohort, to be used for prediction of student performance.  © 2024 IEEE.},
	author_keywords = {Business Intelligence; Learning Analytics; Outcomes-based Education; Quality Education (SDG 4)},
	keywords = {Decision making; Information analysis; Learning systems; Analytics systems; Business-intelligence; Higher education institutions; Intelligence tool; Learning analytic; Outcome-based education; Program outcomes; Quality education; Quality education (SDG 4); Student performance; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039496-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Cyber Resil., ICCR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Kaveri202385,
	author = {Kaveri, Anceli and Silvola, Anni and Muukkonen, Hanni},
	title = {Supporting Student Agency with a Student-Facing Learning Analytics Dashboard: Perceptions of an Interdisciplinary Development Team},
	year = {2023},
	journal = {Journal of Learning Analytics},
	volume = {10},
	number = {2},
	pages = {85 – 99},
	doi = {10.18608/jla.2023.7729},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170285801&doi=10.18608%2fjla.2023.7729&partnerID=40&md5=0136946544dd1c903b833f36c71bd894},
	affiliations = {University of Oulu, Faculty of Education and Psychology, Learning and Learning Processes Research Unit, University of Oulu, P.O. Box 2000, Oulu, FIN-90014, Finland},
	abstract = {Learning analytics dashboard (LAD) development has been criticized for being too data-driven and for developers lacking an understanding of the nontechnical aspects of learning analytics (LA). The ability of developers to address their understanding of learners as well as systematic efforts to involve students in the development process are central to creating pedagogically grounded student-facing dashboards. However, limited research is available about developer perceptions on supporting students with LA. We examined an interdisciplinary LA development team’s (IDT) perceptions of and intentions to support student agency, and the student-facing LAD development process. Qualitative content analysis supported by a social cognitive theory framework was conducted on interviews (N = 12) to analyze the IDT’s perceptions of student agency. IDT members had differing conceptions of student agency but agreed that it manifests in strategic study progression and planning, as well as in active interpretation and use of LA-based feedback. IDT members had differing views on student involvement in the LAD development process. Communication challenges within an IDT and limited resources were mentioned, impeding development work. The results of this study highlight the importance of fostering communication among IDT members about guiding pedagogical design principles and the systematic use of educational concepts in LA development processes. © 2023, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {ethics; Interdisciplinary development work; student agency; student-facing dashboard},
	correspondence_address = {A. Kaveri; University of Oulu, Faculty of Education and Psychology, Learning and Learning Processes Research Unit, University of Oulu, Oulu, P.O. Box 2000, FIN-90014, Finland; email: anceli.kaveri@oulu.fi},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Kew202445,
	author = {Kew, Si Na and Koh, Elizabeth and Choo, Zi Luan and Jonathan, Christin Rekha},
	title = {A Systematic Review on Student-Facing Learning Analytics Dashboards: Reference Frames and Indicators},
	year = {2024},
	journal = {Proceedings - 2024 6th International Conference on Computer Science and Technologies in Education, CSTE 2024},
	pages = {45 – 50},
	doi = {10.1109/CSTE62025.2024.00015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199983737&doi=10.1109%2fCSTE62025.2024.00015&partnerID=40&md5=670b7f743cf5ea1f74b3fb235d6ec0cf},
	affiliations = {Universiti Teknologi Malaysia, Faculty of Social Sciences and Humanities, Malaysia; National Institute of Education, Nanyang Technological University, Singapore},
	abstract = {As the integration of technology in education undergoes continuous development, Learning Analytics Dashboards (LADs) have become vital tools for both instructors and learners, facilitating the monitoring and optimization of the learning experience. Student-facing LADs have been designed with various reference frames which enable various feedback, comparisons and reflection. However, there has been limited examination of the reference frames and their indicators employed in student-facing LADs as well as its evaluation. This research aims to address this gap by conducting a systematic literature review using PRISMA to synthesize existing literature to identify and offer insights on reference frames and key indicators used in student-facing LADs. We identified 42 articles and analyzed that social reference frames as compared to progress reference frames are commonly employed in LADs. Key indicators include class performance average, class performance mean, average performance of the class, etc. These insights contribute to the ongoing development and best practices of LAD design. The knowledge and findings can help educators, researchers, system designers and policymakers decide how best to incorporate these tools into educational settings.  © 2024 IEEE.},
	author_keywords = {indicators; learning analytics dashboard; PRISMA; reference frame; systematic literature review},
	keywords = {Petroleum reservoir evaluation; Students; Continuous development; Development Learning; Key indicator; Learning analytic dashboard; Performance; PRISMA; Reference frame; Systematic literature review; Systematic Review; Technology in educations; Facings},
	correspondence_address = {S.N. Kew; Universiti Teknologi Malaysia, Faculty of Social Sciences and Humanities, Malaysia; email: snkew@utm.my},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035180-4},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Comput. Sci. Technol. Educ., CSTE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dyulicheva202486,
	author = {Dyulicheva, Yulia Yu.},
	title = {Application of Learning Analytics in Higher Education: Datasets, Methods and Tools; [Применение учебной аналитики в высшем образовании: датасеты, методы и инструменты]},
	year = {2024},
	journal = {Vysshee Obrazovanie v Rossii},
	volume = {33},
	number = {5},
	pages = {86 – 111},
	doi = {10.31992/0869-3617-2024-33-5-86-111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197223186&doi=10.31992%2f0869-3617-2024-33-5-86-111&partnerID=40&md5=ccedddc814339d3f59304b606eeef6e9},
	affiliations = {Department of the Physical Technology Institute, V.I. Vernadsky Crimean Federal University, 4 Vernadsky Ave., Simferopol, 295007, Russian Federation},
	abstract = {The accumulation of big educational data on the platforms of universities and social media leads to the need to develop tools for extracting regularities from educational data, which can be used for understanding the behavioral patterns of students and teachers, improve teaching methods and the quality of the educational process, as well as form sound strategies and policies for universities development. This article provides an analysis and systematization of datasets on available repositories, taking into account the learning analytics problems solved on their basis. In particular, the article notes the predominance of datasets aimed at solving analytical problems at the level of student’s behavior understanding, Datasets aimed at solving analytical problems at the level of understanding the needs of teachers and administrative and managerial staff of universities are practically absent. Meanwhile, the full potential of learning analytics tools can only be revealed by introducing an integrated approach to the analysis of educational data, taking into account the needs of all participants and organizers of the educational process. This review article discusses learning analytics methods related to the study of social interaction patterns between students and teachers, and learning analytics tools from the implementation of simple dashboards to complex frameworks that explore various levels of learning analytics. The problems and limitations that prevent learning analytics from realizing its potential in universities are considered. It is noted that universities are generally interested in introducing learning analytics tools that can improve the quality of the educational process by developing strategies for targeted support for individual groups of students, however, teachers treat such initiatives with caution due to a lack of data analysis skills and correct interpretation of analysis results. The novelty of this analytical review is associated with the consideration of learning analytics at different levels of its implementation in the context of approaches to openness, processing and analysis of educational data. This article will be of interest to developers of learning analytics tools, scientific and pedagogical workers, and administrative and managerial staff of universities from the point of view of forming an idea of the integrity of the university analytics process, taking into account various levels of analytics implementation aimed at understanding the needs and requirements of all participants in the educational process. © 2024 Moscow Polytechnic University. All rights reserved.},
	author_keywords = {datasets; learning analytics; policy analytics; student behavior analytics; teacher behavior analytics; university strategy},
	correspondence_address = {Y.Yu. Dyulicheva; Department of the Physical Technology Institute, V.I. Vernadsky Crimean Federal University, Simferopol, 4 Vernadsky Ave., 295007, Russian Federation; email: dyulicheva_yu@mail.ru},
	publisher = {Moscow Polytechnic University},
	issn = {08693617},
	language = {Russian},
	abbrev_source_title = {Vysshee Obrazovanie Rossii},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Khulbe2023981,
	author = {Khulbe, Manisha and Tammets, Kairit},
	title = {Mediating Teacher Professional Learning with a Learning Analytics Dashboard and Training Intervention},
	year = {2023},
	journal = {Technology, Knowledge and Learning},
	volume = {28},
	number = {3},
	pages = {981 – 998},
	doi = {10.1007/s10758-023-09642-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148654916&doi=10.1007%2fs10758-023-09642-0&partnerID=40&md5=f135adc2257cdd904dd377aff648053e},
	affiliations = {Tallinn University, Tallinn, Estonia},
	abstract = {Insights derived from classroom data can help teachers improve their practice and students’ learning. However, a number of obstacles stand in the way of widespread adoption of data use. Teachers are often sceptical about the usefulness of data. Even when willing to work with data, they often do not have the relevant skills. Tools for analysis of learning data can, theoretically, aid teachers in data use, but often fall short of their potential as they are commonly designed without reference to educational theory and rarely consider end-user’s needs. Keeping these challenges in mind, we designed a professional development program that aimed at, among other things, improving teachers’ beliefs regarding data and their data literacy skills. After the training, we found that teachers had more positive attitudes regarding data. However, some data literacy skills proved quite difficult to learn. We present and analyse our intervention here and forward a proposal for improving the effectiveness of data use interventions by leveraging theory-based Learning Analytics (LA) dashboards as mediating tools that scaffold teachers’ acquisition of new knowledge and skills during and beyond the intervention. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Data use intervention; Engagement; Learning analytics; Learning analytics dashboard; Teacher-facing dashboard; Teachers’ data use},
	keywords = {Knowledge management; Scaffolds; Students; Data use intervention; Engagement; Learning analytic; Learning analytic dashboard; Professional learning; Teacher-facing dashboard; Teachers'; Teacher’ data use; Training intervention; Personnel training},
	correspondence_address = {M. Khulbe; Tallinn University, Tallinn, Estonia; email: manisha@tlu.ee},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Barthakur202449,
	author = {Barthakur, Abhinava and Marrone, Rebecca and Esnaashari, Shadi and Kovanovic, Vitomir and Dawson, Shane},
	title = {A Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	pages = {49 – 63},
	doi = {10.1007/978-3-031-72315-5_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205123908&doi=10.1007%2f978-3-031-72315-5_4&partnerID=40&md5=dda1262269879cd573d67eff08b30bce},
	affiliations = {University of South Australia, Adelaide, Australia; Johns Hopkins University, Maryland, United States},
	abstract = {Within the education sector, there is growing recognition of the importance of diverse data sets in aiding strategic decisions and supporting personalized learning. To date, this call for increased and more nuanced data has been translated into institutional use of data dashboards or learning analytics dashboards. While these dashboards have been extensively developed and adopted in higher education, there is limited research investigating the use of dashboards in K-12 education. To address this gap, this study presents a systematic literature review examining dashboards as a decision-making system in K-12 settings. Our analysis indicates significant underuse of data in these dashboards, with a concerning scarcity of implementations and evaluations in real-world classroom environments. To counteract these shortcomings, we propose a set of recommendations designed to enhance dashboard development by promoting the use of Learner Profiles (LPs). These guidelines aim to support educational outcomes and student success by informing the design and deployment of fine-grained dashboards aligned with the specific needs of K-12 education. By highlighting the current gaps and offering forward-looking recommendations, our study clarifies the present landscape and serves as a foundation for future research, with significant implications for educators, policymakers, and scholars interested in using LPs to improve student learning outcomes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Dashboards; Decision-making; K-12; Learner Profiles; Systematic literature review},
	keywords = {Adversarial machine learning; Decision making; Federated learning; Students; Teaching; Dashboard; Decision-making systems; Decisions makings; Education sectors; K-12; K-12 education; Learner profiles; Systematic literature review; Systematic Review; Teaching and learning; Contrastive Learning},
	correspondence_address = {A. Barthakur; University of South Australia, Adelaide, Australia; email: abhinava.barthakur@mymail.unisa.edu.au},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bourguet2023920,
	author = {Bourguet, Marie-Luce},
	title = {Methodology for the Participatory Design of a Learner-Facing Analytics Dashboard},
	year = {2023},
	journal = {31st International Conference on Computers in Education, ICCE 2023 - Proceedings},
	volume = {2},
	pages = {920 – 922},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181765624&partnerID=40&md5=f9405a1bddac832cbd836636db9ebc08},
	affiliations = {Queen Mary University of London, United Kingdom},
	abstract = {In this work-in-progress paper, we describe the participatory design approach we adopted for the inclusive design of a student-facing learning analytics dashboard. The objective is to involve learners throughout the design process to help prevent instructors’ biases ending up in the design. The design participants developed learner personas, use scenarios and storyboards to capture the broad spectrum of students' abilities, skills, objectives, and situations. These guided the decisions made for the essential features, functions, and interactive behaviours of the dashboard and for its initial functional implementation. © 2023 Asia-Pacific Society for Computers in Education.},
	author_keywords = {dashboard; learning analytics; Participatory design; personas},
	keywords = {Design; Students; Broad spectrum; Dashboard; Design approaches; Design-process; Essential features; Feature function; Inclusive design; Learning analytic; Participatory design; Persona; Facings},
	correspondence_address = {M.-L. Bourguet; Queen Mary University of London, United Kingdom; email: marie-luce.bourguet@qmul.ac.uk},
	editor = {Shih J.-L. and Kashihara A. and Chen W. and Chen W. and Ogata H. and Baker R. and Chang B. and Dianati S. and Madathil J. and Yousef A.M.F. and Yang Y. and Zarzour H.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968902-6},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Saqr2024781,
	author = {Saqr, Mohammed and López-Pernas, Sonsoles},
	title = {Why Learning and Teaching Learning Analytics is Hard: An Experience from a Real-Life LA Course Using LA Methods},
	year = {2024},
	journal = {Lecture Notes in Educational Technology},
	volume = {Part F3283},
	pages = {781 – 789},
	doi = {10.1007/978-981-97-1814-6_76},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202527284&doi=10.1007%2f978-981-97-1814-6_76&partnerID=40&md5=3ac729373ca294f7950078b7edad852b},
	affiliations = {University of Eastern Finland, Joensuu, 80100, Finland},
	abstract = {Learning analytics emerged more than a decade ago to harness the power of data to understand and optimize learning, learners’ behavior, and learning environments. Ever since, the field has grown to encompass a diverse range of methods, research strands and traditions. Recent literature reviews tell us that most common applications of learning analytics include predictive analytics, social network analysis, sequence and process analysis, visualizations, and dashboards to mention a few. In the same vein, the research field has attracted several interdisciplinary researchers and practitioners from computer science, education, data science, engineering, administration, and from the education technology industry. Whereas such diverse backgrounds and perspectives bring a wealth of different perspectives to the field, it makes teaching and learning analytics hard to narrow down in a single course. This study reports on the analysis of students’ approach to learning learning analytics, reflects on the insights that learning analytics offers, and makes recommendations for future researchers who are teaching or investigating similar courses. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {computer science education; data mining; learning analytics; psychological networks; sequence analysis},
	correspondence_address = {M. Saqr; University of Eastern Finland, Joensuu, 80100, Finland; email: Mohammed.saqr@uef.fi},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yan2024180,
	author = {Yan, Lixiang and Zhao, Linxuan and Echeverria, Vanessa and Jin, Yueqiao and Alfredo, Riordan and Li, Xinyu and Gaševi’c, Dragan and Martinez-Maldonado, Roberto},
	title = {VizChat: Enhancing Learning Analytics Dashboards with Contextualised Explanations Using Multimodal Generative AI Chatbots},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14830 LNAI},
	pages = {180 – 193},
	doi = {10.1007/978-3-031-64299-9_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200213627&doi=10.1007%2f978-3-031-64299-9_13&partnerID=40&md5=6683146504130e2c6091bdb9badc406a},
	affiliations = {Monash University, Clayton, 3108, VIC, Australia},
	abstract = {Learning analytics dashboards (LADs) serve as pivotal tools in transforming complex learner data into actionable insights for educational stakeholders. Despite their potential, the effectiveness of LADs, particularly the visualisations they utilise, has been under scrutiny. Concerns have been raised about their potential to cause cognitive overload, especially for users with limited data visualisation literacy, thus questioning their practical utility in supporting decision-making and reflective practices. This tool paper tackles these concerns by introducing VizChat, an open-sourced, prototype chatbot designed to augment LADs by providing contextualised, AI-generated explanations for visualisations. Developed on multimodal generative AI (GPT-4V) and retrieval-augmented generation (Langchain), VizChat offers on-demand, contextually relevant explanations that aim to improve user comprehension without overwhelming them with excessive information. Through a case study, we demonstrated VizChat’s diverse capabilities, including actively seeking clarifications on ambiguous queries, personalising responses based on previous user interactions, providing contextually relevant explanations of specific visualisations, integrating information from multiple visualisations for a comprehensive response, and offering detailed insights into the data collection and analysis processes behind each visualisation. Such efforts support the paradigm shift from exploratory to explanatory approaches in LADs, highlighting the potential of integrating generative AI and chatbots to enhance the educational value of learning analytics. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Chatbots; Generative Artificial Intelligence; GPT; Learning Analytics; LLM; Multimodal; Visualisation},
	keywords = {Data visualization; Decision making; Metadata; Chatbots; Cognitive overload; Decision-making practices; Generative artificial intelligence; GPT; Learning analytic; Limited data; LLM; Multi-modal; Reflective practise; Visualization},
	correspondence_address = {L. Yan; Monash University, Clayton, 3108, Australia; email: lixiang.yan@monash.edu},
	editor = {Olney A.M. and Chounta I.-A. and Liu Z. and Santos O.C. and Bittencourt I.I.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303164298-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{2024,
	title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15160 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205289233&partnerID=40&md5=2837101108a17fc39a69174e5b40c6cf},
	abstract = {The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172311-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Salas-Pilco2023,
	author = {Salas-Pilco, Sdenka Zobeida and Xiao, Kejiang and Hu, Xinyun},
	title = {Correction to: Artificial Intelligence and Learning Analytics in Teacher Education: A Systematic Review (Education Sciences, (2022), 12, 8, (569), 10.3390/educsci12080569)},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {9},
	doi = {10.3390/educsci13090897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172161101&doi=10.3390%2feducsci13090897&partnerID=40&md5=f0d184858c5cd1fcbc0b9402af0a2458},
	affiliations = {Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Hubei Research Center for Educational Informatization, Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Faculty of Education and Human Development, The Education University of Hong Kong, Hong Kong},
	abstract = {There was an error in the original publication [1]. The authors have requested changes be made to the published paper as they describe Taiwan as a country in the article and hope to change the description to “Country/Region” and “China Taiwan”. A correction has been made to the first paragraph of Section 3. Results and Table 2: This review includes 30 studies based in 16 countries/regions, with the following distribution: Canada (3), China (8), Estonia (1), Germany (3), India (1), Indonesia (1), Japan (1), Korea (1), Malaysia (1), Morocco (1), Portugal (1), Rwanda (1), Spain (1) China Taiwan (1), Turkey (2), USA (3). The analysis guided by the research questions provides some insights into the impact of AI and LA on teacher education. Summary of the studies included in this review. Knowledge elaboration (K): discussion of topics and posts Behavior patterns (B): posting frequency; posts’ content Social interaction (S): network density, network cohesion, and network interactions Moodle platform LA dashboard Knowledge–Behavior–Social Dashboard tool (KBSD) DigComp framework (five dimensions): information and data literacy, communication and collaboration, digital content creation, safety, and problem solving AI tools: K-means clustering Video discourse data: number of words; number of turns; teacher–student turn-taking patterns Visualizing talk strategies: elaborating, reasoning, listening, and thinking with others Classroom discourse analyzer (CDA) is a VLA tool that automatically extracts and visualizes low-inference discourse information Short essays (500-word reflection) about the experience of solving a block-based visual programming scenario were analyzed Moodle platform Latent Dirichlet Allocation library in Python. Code.org Number of sessions, duration, number of actions, etc. Content access, content revision, discussion, assessment, help-seeking, and search MOOC R package AI tools: Expectation-maximization (EM) algorithm; Bayesian information criterion (BIC); TraMineR Access features: location, date, time, and regularity (average number of logins/week) Content features: screencasts; quizzes Moodle platform Video-based speech features: content, speech organization, appropriate word usage, proper etiquette, correct enunciation, fluent prosody, timing control Supervised algorithms: support-vector machine (SVM) classifier, logistic regression, random forests, and gradient-boosted decision trees Class, group, and individual work Student modalities: reading, writing, listening, and speaking Material: extended, minimal, native, or non-native Video on the ePortfolio in Moodle AI mobile communicative orientation of language teaching (COLT) scheme Discourse data: recordings of classroom conversations. Included variables: specificity, instructional talk, authentic questions, dialogic, cognitive level Random forests (RF) classifier and regression IBM Watson AI speech recognizer User action data: time, full names, event context, components, event names, activity, IP address and origin Performance data: grades Moodle platform R software Trustworthiness (0–100), novelty, and usefulness Actionability and receiving new information Level of experience CoTrack: a Raspberry-Pi-based prototype with microphones CoTrack’s dashboard showing speaking time and social networks Etherpad Discourse data and reflection elements: PSTs’ attitudes, experiences, device preferences, comments about the interface, and content and technical issues SimInClass: an AI-based-simulated virtual classroom Google Classroom learning platform Performance: GPA, math grade, TIMSS, age, gender, federal state, school type, type of student AI tools: SVM, LR, LR with elastic net regularization, and tree-based methods Behavior patterns: recordings of PSTs’ viewing a 360 degrees video with students’ actions Short writings: PSTs select one pivotal moment and explain why it is significant AI tools: machine learning algorithm Digital competence areas: Personal: age, gender, teaching experience, confidence, and years using digital technology in teaching Contextual: classroom equipment, students’ access to technology, network infrastructure, and curriculum Professional engagement: digital resources, assessment, empowering learners, and facilitating learners’ digital competence SPSS STATA, fast-and-frugal trees (FFTrees) classifier in machine learning ILDE dashboard: profile views, comments, created designs, re-used designs, and edits. The Integrated Learning Design Environment (ILDE) dashboard IBM SPSS 22 Heidi SQL and Tableau Self-regulated behaviors: Activating: online access location, day of the week, time of day Sustaining: access frequency Structuring: average logins per week, exam review patterns, number of reviewed quizzes/day Moodle platform Social bot: user intentions, bot messages System Usability Scale: frequency, ease of use, confidence, consistency Chatbots: Feedbot for self- study, Litbot for mentoring students’ reading Learning action logs about search terms, visited websites, time spent on each website, and the order in which sites were visited Thinking app (Chrome extension) that tracks online behaviors Psychological variables: Practical knowledge: educational beliefs, interpersonal relationships, teaching strategies, self-reflection Motivation: intrinsic motivation, extrinsic motivation, amotivation Other: gender, teaching experience, average academic performance The SLBM-TAIS educational module Based on the Indonesian Teacher Engagement Index (ITEI): positive psychology, positive education, teacher performance, nationalistic character, and leadership engagement Django: a website framework for Python Chart.js for data visualization. MongoDB as the database Discussion data Dimensions based on Bloom’s taxonomy: remember, understand, apply, analyze, evaluate, create MOOC platform Types of AI tasks: text recognition, sentiment analysis, image classification, categorical/numerical data IBM Watson AI model Mitsuku chatbot Google AI experiment named Emoji Scavenger Hunt Scratch Reflection elements: circumstances, description, evaluation, alternatives, consequences Doc2Vec features Four classifiers: decision trees, multinomial logistic regression, multinomial naïve Bayes, stochastic gradient descent Epistemic agency, democratic knowledge, improvable ideas, reflective and transformative assessment, and community knowledge Knowledge Forum (online notes) LMS log data: date, login frequency, views per week, participation in discussions Moodle LMS platform Based on the Teaching and Learning International Survey (TALIS) 2013: types of activities, participation rates, intensity of participation, mentoring and induction programs Group Mnet technique (glmnet package). R software PSTs’ teaching competency framework (six dimensions): professional foundation, instructional design, teaching implementation, technology application, teaching evaluation, reflective development AI tools: Back Propagation (BP) neural network Delphi and Analytic Hierarchy Process (AHP) methods Matlab software Discourse characteristics: number of posts per teacher, length of post per teacher, much or little new information, high or low topic relevance Word2vec toolkit to generate lexical vectors based on AI-NLP Vision-based mobile augmented reality from the university campus (e.g., plants, flowers, trees) through scene detection, retrieval, superposition, visualization, and interaction MobileNetV2 network: a lightweight convolutional neural network by Google for mobile devices Note. CDA = classroom discourse analyzer, DT = decision tree, FFTrees = fast-and-frugal trees, GBTD = gradient-boosted decision trees, KBSD = Knowledge–Behavior–Social Dashboard, ITEI = Indonesian Teacher Engagement Index, RF = random forests, NLP = natural language processing, SLBM-TAIS = service-learning-based module training AI subjects, SVM = support-vector machine, WISE = web-based inquiry science environment. The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the authors.},
	correspondence_address = {K. Xiao; Hubei Research Center for Educational Informatization, Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; email: xiaokj@ccnu.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Bhurre2024720,
	author = {Bhurre, Shraddha and Prajapat, Shaligram and Raikwar, Sunny and Goswami, Prakshep and Kothari, Soham and khanuja, Gurpreet and Yadav, Kartikey and Choure, Purvi},
	title = {Experimental Demonstration for Learning Analytics and Data Mining on e-assessment},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {884 LNNS},
	pages = {720 – 741},
	doi = {10.1007/978-3-031-74443-3_42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214256715&doi=10.1007%2f978-3-031-74443-3_42&partnerID=40&md5=a6e384f62056b58eca37a27b06e4dcd9},
	affiliations = {International Institute of Professional Studies, DAVV, MP, Indore, India; Dr. APJ Kalam University, Indore, India},
	abstract = {Every subject and course has a learning goal that we work towards during the teaching-learning process, whether it be online or offline. Under the current system, assignments, project analysis, semester exams, and internal exams are used to evaluate students’ learning. Several factors, including participation in class, prior knowledge, engagement time, activity logs, forum posts, understanding level, etc., influence how well students learn throughout a course or session. All these factors will be difficult to analyze in offline mode. All of these activities determine whether or not the learning objective is met. This study examines an experiment that provided blended learning data on students’ academic details, learning behaviors, and evaluation modules to determine the success of the two subjects. It discussed the details of each phase involved in the experiment. Students enrolled in integrated courses, MTech(PG-1) and MCA(PG-2) were analyzed in this study procedure through 4 weeks of offline classes. Moodle Gnomio was used for the online processes related to the Registration process, Quizzes, and discussion forums. A total of 6 quizzes for PG-1(M-Tech) and PG-2(MCA) were organized, and learning resources were provided before the exam. This study discusses detailed experiment setup, and Statistical analysis involving difficulty level of quizzes. This study proposed a framework for the dashboard that utilize this dataset and involves analysis related to student performance, grade distribution, inferring learning patterns, and course success. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Blended Learning; Learning Analytics; Moodle; Online Learning},
	keywords = {Active learning; Adversarial machine learning; Federated learning; Students; Blended learning; Current system; E assessments; Experimental demonstrations; Learning analytic; Learning goals; Moodle; Offline; Online learning; Teaching-learning process; Contrastive Learning},
	correspondence_address = {S. Bhurre; International Institute of Professional Studies, DAVV, Indore, MP, India; email: shraddhabhurre@gmail.com},
	editor = {Naik N. and Grace P. and Jenkins P. and Prajapat S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303174442-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Conde2024820,
	author = {Conde, Miguel Á. and Castellano Ruiz, Diego and Rodríguez-Sedano, Francisco J.},
	title = {Using Students Discord Interactions in the Evaluation of Teamwork Competence Acquisition},
	year = {2024},
	journal = {Lecture Notes in Educational Technology},
	volume = {Part F3283},
	pages = {820 – 829},
	doi = {10.1007/978-981-97-1814-6_80},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201968070&doi=10.1007%2f978-981-97-1814-6_80&partnerID=40&md5=b4d56876c1444c741df3629b054a1a9a},
	affiliations = {Department of Mechanics, Computer Science and Aerospace Engineering, Robotics Group, Universidad de León, Campus de Vegazana S/N, León, 24071, Spain; Industrial, Informatics and Aeronautical Engineering School, Universidad de León, Campus de Vegazana S/N, León, 24071, Spain; Department of Electric, Systems and Automatics Engineering, Robotics Group, Universidad de León, Campus de Vegazana S/N, León, 24071, Spain},
	abstract = {Nowadays competences such as teamwork are highly valued in the labor world. Students must develop it at educational institutions, which implies they should interact between them when working in groups. The evaluation of such interactions and other behaviors can allow us to decide if the competence has been acquired. However, this present three main problems: 1) with an important number of students observation is not possible; 2) it does not include the interactions carried out to address a problem or a project beyond the institution, and 3) the use of institutional tools such as forums or chats to develop these tasks discourage the students. In order to solve these issues instant messaging tools have been used as a solution. However not all of them are open or used by the students. In the last few years one of most used instant messaging tools has been Discord. This work presents a development to track and evaluate the interactions of the students at such a platform and how the evidence can be used to evaluate teamwork competence. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Dashboard; Discord; Instant Messaging; Learning Analytics},
	correspondence_address = {M.Á. Conde; Department of Mechanics, Computer Science and Aerospace Engineering, Robotics Group, Universidad de León, León, Campus de Vegazana S/N, 24071, Spain; email: mcong@unileon.es},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lee2024,
	author = {Lee, Jeongwon and Kim, Dongho},
	title = {From awareness to empowerment: self-determination theory-informed learning analytics dashboards to enhance student engagement in asynchronous online courses},
	year = {2024},
	journal = {Journal of Computing in Higher Education},
	doi = {10.1007/s12528-024-09416-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210020816&doi=10.1007%2fs12528-024-09416-2&partnerID=40&md5=526ee835940ef31028fc4cd67860bdd1},
	affiliations = {Department of Educational Studies, College of Education and Human Ecology, The Ohio State University, 29 W Woodruff Ave, Columbus, 43210, OH, United States; Department of Vocational Education and Workforce Development, College of Agriculture and Life Sciences, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul, 08826, South Korea},
	abstract = {Although learning analytics dashboards (LADs) are being recognized as tools that can enhance engagement—a crucial factor for the success of asynchronous online higher education—their impact may be limited without a solid theoretical basis for motivation. Furthermore, the processes through which students make decisions using dashboards and engage are not well understood. This study aimed to design a LAD informed by self-determination theory and to investigate university students’ experiences with it. The findings, including those from stimulated recall interviews using eye-tracking data, shed light on how the LAD fosters student engagement. Interacting with the LAD fulfilled students’ basic psychological needs. Awareness and reflection on learning status facilitated by the LAD boosted enthusiasm for active learning participation. The LAD offered essential information to support autonomous, strategic decisions, empowering students to take proactive actions toward personal goals while reinforcing their belief in achieving them. Despite its potential benefits, various improvements have been identified to further enhance its effectiveness. Based on the findings, we discuss the implications of this study for future research in the field. © The Author(s) 2024.},
	author_keywords = {Data-informed decision making; Learning analytics dashboard; Post-secondary online education; Student engagement; Theory-driven learning analytics},
	correspondence_address = {D. Kim; Department of Vocational Education and Workforce Development, College of Agriculture and Life Sciences, Seoul National University, Seoul, 1 Gwanak-ro, Gwanak-gu, 08826, South Korea; email: dkim24@snu.ac.kr},
	publisher = {Springer},
	issn = {10421726},
	language = {English},
	abbrev_source_title = {J. Comput. High. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Alam20231436,
	author = {Alam, Md. I. and Malone, Lauren and Nadolny, Larysa and Brown, Michael and Cervato, Cinzia},
	title = {Investigating the impact of a gamified learning analytics dashboard: Student experiences and academic achievement},
	year = {2023},
	journal = {Journal of Computer Assisted Learning},
	volume = {39},
	number = {5},
	pages = {1436 – 1449},
	doi = {10.1111/jcal.12853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170686056&doi=10.1111%2fjcal.12853&partnerID=40&md5=13414b684d68de1bfa211c638b32d324},
	affiliations = {School of Education, Iowa State University, Ames, IA, United States; Department of Communication, University of Tampa, Tampa, FL, United States; Rightpoint Consulting LLC, Chicago, IL, United States},
	abstract = {Background: The substantial growth in gamification research has connected gamified learning to enhanced engagement, improved performance, and greater motivation. Similar to gamification, personalized learning analytics dashboards can enhance student engagement. Objectives: This study explores the student experiences and academic achievements using a gamified dashboard in a large, introductory STEM course. Methods: We examined two groups of students enrolled in different sections of a one-semester-long physical geology course with a total enrollment of 223 students. The only difference between the groups was that one had access to the dashboard. The data collection included students' assignments, overall performances, and exam scores. Students in both sections completed a Science Literacy Concept Inventory survey at the beginning and end of the term. Additionally, students completed an end-of-term survey containing open-ended questions on their experience and interactions with specific elements. Results: Students shared mostly positive comments about their experience with the dashboard, and the final grade of students with access to the dashboard was 13% higher, on average, compared to their peers in the non-dashboard section. Conclusion: With low costs and little time invested, gamified dashboards could have a significant impact on student performance in large STEM lecture courses. © 2023 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {21st century abilities; games; human–computer interface; post-secondary education; teaching/learning strategies},
	correspondence_address = {M.I. Alam; School of Education, Iowa State University, Ames, United States; email: imtiaj@iastate.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Covill2024639,
	author = {Covill, Derek and Tooze, James and Prieto, Pablo and Owen Lloyd, Gareth and Grundy, Cate},
	title = {DEVELOPING AN OPEN-SOURCE LEARNING ANALYTICS TOOL FOR PROVIDING INSIGHTS TO SUPPORT STUDENTS AND IMPROVE TEACHING PRACTICE},
	year = {2024},
	journal = {Proceedings of the 26th International Conference on Engineering and Product Design Education: Rise of the Machines: Design Education in the Generative AI Era, E and PDE 2024},
	pages = {639 – 644},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003907528&partnerID=40&md5=ab6b02a64c338f55248265551f019ec8},
	affiliations = {University of Brighton, United Kingdom},
	abstract = {Learning analytics and data-driven approaches have gained real traction in higher education institutions, enabling insights into student attendance, engagement, and performance trends. This paper introduces the development of an open-source course-level data analytics tool, 'the student record,' designed to complement the conventional institutional approach with a responsive, context-specific, and usercentred method for gathering, analysing, and presenting student attendance data. In developing the tool, our team experimented with Microsoft Excel's natural language interface and artificial intelligence capabilities and currently the tool uses predefined python scripts in a Jupyter Notebook to generate visual dashboards, flags, and recommendations based on statistical process control (SPC) principles and machine learning models. This approach aims to facilitate a dynamic student engagement dialogue between staff and students, fostering a rolling academic health check to support students and provide contextual insights for module teams and course leaders. The tool's ethical considerations prioritise transparency, data privacy, and student accessibility to their own data, aligning with personal academic tutoring systems. The paper outlines the tool's development, capabilities, and a critical discussion of key aspects, including AI integration, data security, and ethical implications. © 2024 Proceedings of the 26th International Conference on Engineering and Product Design Education: Rise of the Machines: Design Education in the Generative AI Era, E and PDE 2024. All rights reserved.},
	author_keywords = {contextual insights; ethics; information system; machine learning; student attendance and engagement},
	keywords = {Anonymity; Curricula; Ethical technology; Natural language processing systems; Sensitive data; Teaching; Analytic tools; Contextual insight; Data-driven approach; Higher education institutions; Machine-learning; Open-source learning; Student attendances; Student engagement; Student performance; Teaching practices; Students},
	editor = {Bohemia E. and Bohemia E. and Buck L. and Grierson H. and Kim J. and Storer I. and Whitehead T.},
	publisher = {The Design Society},
	isbn = {978-191225420-0},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Eng. Prod. Des. Educ.: Rise Mach.: Des. Educ. Gener. AI Era, E PDE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Raza202487,
	author = {Raza, Ali and Sumner, Tamara and Penuel, William R.},
	title = {The Science Student Electronic Exit Ticket (SEET) System: Visualizations to Help Teachers Notice and Reflect on Classroom Inequalities},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {1},
	pages = {87 – 100},
	doi = {10.18608/jla.2024.8199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190291575&doi=10.18608%2fjla.2024.8199&partnerID=40&md5=1c97eee46ffd813d3b99097a380b87dc},
	affiliations = {Department of Computer Science and Institute of Cognitive Science, University of Colorado Boulder, UCB, 552, Boulder, 80309-0552, CO, United States; Institute of Cognitive Science, University of Colorado Boulder, UCB, 552, Boulder, 80309-0552, CO, United States},
	abstract = {This study examined the ways in which an equity analytics tool — the SEET system — supported middle school science teachers’ reflections on the experiences of diverse students in their classrooms. The tool provides teachers with “equity visualizations” — disaggregated classroom data by gender and race — designed to support teachers to notice and reflect on inequitable patterns in student participation in classroom knowledge-building activities, as well as “whole class visualizations” that enable teachers to look at participation patterns. The visualizations were based on survey data collected from students reflecting on the day’s lessons, responding to questions aligned with three theoretical constructs indicative of equitable participation in science classrooms: coherence, relevance, and contribution. The study involved 42 teachers, divided into two cohorts, participating in a two-month professional learning series. Diary studies and semi-structured interviews were used to probe teachers’ perceptions of the visualizations’ usability, usefulness, and utility for supporting their reflections on student experiences and instructional practices. A key result is that only the “equity visualizations” prompted teacher reflections on diverse student experiences. However, despite the support equity visualizations provided for this core task, the teachers consistently ranked the whole class visualizations as more usable and useful. Notes for Practice ● Teachers can use data visualizations of student experience to reflect on classroom inequities in science lessons. “Equity visualizations” such as disaggregating data by gender, race/ethnicity can engage teachers in sensemaking about equitable instruction. * For adopting visualizations of learning analytics in practice, teachers require ease-of-use, familiarity, and simplicity. ● Teachers need support to engage in sensemaking when using visualizations of equity from their classroom to use them more frequently as compared to visualizations that don’t break down data by gender, race/ethnicity (“whole class” visualizations). © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {equity visualizations; Learning analytic dashboards; learning sciences; science education; studies of teacher adoption and use},
	correspondence_address = {A. Raza; Department of Computer Science and Institute of Cognitive Science, University of Colorado Boulder, UCB, Boulder, 552, 80309-0552, United States; email: a.raza@colorado.edu},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{de Vreugd2023,
	author = {de Vreugd, Lars and Jansen, Renée and van Leeuwen, Anouschka and van der Schaaf, Marieke},
	title = {The role of reference frames in learners’ internal feedback generation with a learning analytics dashboard},
	year = {2023},
	journal = {Studies in Educational Evaluation},
	volume = {79},
	doi = {10.1016/j.stueduc.2023.101303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170697351&doi=10.1016%2fj.stueduc.2023.101303&partnerID=40&md5=f9c1b6933885cd0043cd13c9691ae759},
	affiliations = {Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Heidelberglaan 100, Utrecht, 3508 GA, Netherlands; Department of Education, Utrecht University, Heidelberglaan 1, Utrecht, 3584 CS, Netherlands},
	abstract = {Being able to self-regulate can positively impact learners’ academic achievement. An inherent catalyst of Self-Regulated Learning (SRL) is internal feedback, the new knowledge which is generated when comparing current knowledge against reference information. Learners may not always generate internal feedback, hampering further SRL. Supporting SRL can be done with a Learning Analytics Dashboard (LAD), in which reference frames allow for comparisons and facilitate internal feedback generation. This study explores internal feedback generation using a LAD and the effect of reference frame availability. A multiple method design examined the interplay of reference frames, comparison processes, internal feedback generation and preparatory activities engagement. Differences between three conditions were explored using Bain ANOVA's. Results showed that reference frames almost exclude other external comparators and are used in parallel with an internal comparator. A peer reference frame leads to most verbalizations of internal feedback, and potentially to most verbalizations of preparatory activities. © 2023 The Authors},
	author_keywords = {Appraisal; Internal feedback; Learning analytics dashboard; Self-regulated learning},
	correspondence_address = {L. de Vreugd; Utrecht Center for Research and Development of Health Professions Education, University Medical Centre Utrecht, Utrecht, Heidelberglaan 100, 3508 GA, Netherlands; email: l.b.devreugd-2@umcutrecht.nl},
	publisher = {Elsevier Ltd},
	issn = {0191491X},
	language = {English},
	abbrev_source_title = {Stud. Educ. Eval.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Silvola202378,
	author = {Silvola, Anni and Sjöblom, Amanda and Näykki, Piia and Gedrimiene, Egle and Muukkonen, Hanni},
	title = {Learning analytics for academic paths: student evaluations of two dashboards for study planning and monitoring},
	year = {2023},
	journal = {Frontline Learning Research},
	volume = {11},
	number = {2},
	pages = {78 – 98},
	doi = {10.14786/flr.v11i2.1277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179339156&doi=10.14786%2fflr.v11i2.1277&partnerID=40&md5=1d807c52dc6294a2df6512787d804e1c},
	affiliations = {University of Oulu, Finland; Aalto University, Finland; University of Jyväskylä, Finland},
	abstract = {An in-depth understanding of student experiences and evaluations of learning analytics dashboards (LADs) is needed to develop supportive learning analytics tools. This study investigates how students (N = 140) evaluated two student-facing LADs as a support for academic path-level self-regulated learning (SRL) through the concrete processes of planning and monitoring studies. Aim of the study was to gain new understanding about student perspectives for LAD use on academic path-level context. The study specifically focused on the student evaluations of the dashboard support and challenges, and the differences of student evaluations based on their self-efficacy beliefs and resource management strategies. The findings revealed that students evaluated dashboard use helpful for their study planning and monitoring, while the challenge aspects mostly included further information needs and development ideas. Students with higher self-efficacy evaluated the dashboards as more helpful for study planning than those with lower self-efficacy, and students with lower help-seeking skills evaluated the dashboards as more helpful for study monitoring than those with higher help-seeking skills. The results indicate that the design of LAD can help students to focus on different aspects of study planning and monitoring and that students with different beliefs and capabilities might benefit from different LAD designs and use practices. The study provides theory-informed approach for investigating LAD use in academic path-level context and extends current understanding of students as users of LADs. © 2023, European Association for Research on Learning and Instruction. All rights reserved.},
	author_keywords = {Academic Paths; Learning-Analytics; Multiple-Case Study; Self-Regulated Learning; Student-Facing Dashboards},
	correspondence_address = {A. Silvola; Learning and Learning Processes Research Unit, Faculty of Education and Psychology, University of Oulu, Oulu, Erkki Koiso-Kanttilan katu 1, 90570, Finland; email: Anni.Silvola@oulu.fi},
	publisher = {European Association for Research on Learning and Instruction},
	issn = {22953159},
	language = {English},
	abbrev_source_title = {Frontline Learn.  Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Seidel202426,
	author = {Seidel, Niels and Meyer, Valerie and Radović, Slavisa},
	title = {Co-Design of an Adaptive Personalized Learner Dashboard},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	pages = {26 – 28},
	doi = {10.1109/ICALT61570.2024.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203843900&doi=10.1109%2fICALT61570.2024.00014&partnerID=40&md5=1baa32c7f463a954e279b96da2497c5b},
	affiliations = {CATALPA, FernUniversität in Hagen, Hagen, Germany; FernUniversität in Hagen, Hagen, Germany},
	abstract = {Learning Analytics Dashboards (LAD) equip learners with visual insights into their study activities, enabling informed decision-making. This paper introduces a LAD plugin tailored to individual needs to improve distance learners’ skills in metacognition and self-regulation. Through a co-design approach involving focus groups and interviews, students identified desired features like comprehensive resource overviews, deadline tracking, progress highlights, and enhanced interactions with peers and instructors. The final dashboard design allows learners to assess and track their knowledge, progress, and upcoming tasks, with metrics that facilitate comparisons against their goals and provide adaptive feedback. A user study (N=177) confirmed that users are engaged with the dashboard, but the planning and reflection tools were used less than the monitoring tools. © 2024 IEEE.},
	author_keywords = {Adaptive Learning; Co-Design; Learning Analytics Dashboard},
	keywords = {Contrastive Learning; Decision making; Economic and social effects; Federated learning; Self-supervised learning; Adaptive learning; Co-designs; Decisions makings; Distance learners; Informed decision; Learning analytic dashboard; Metacognition; Plug-ins; Self regulation; Visual insights; Adversarial machine learning},
	editor = {Altinay Z. and Chang M. and Kuo R. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036205-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mohseni2023,
	author = {Mohseni, Zeynab and Masiello, Italo and Martins, Rafael M.},
	title = {Co-Developing an Easy-to-Use Learning Analytics Dashboard for Teachers in Primary/Secondary Education: A Human-Centered Design Approach},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {12},
	doi = {10.3390/educsci13121190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180651196&doi=10.3390%2feducsci13121190&partnerID=40&md5=02b5e309c73d70805a6768aaa030d040},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, 351 95, Sweden},
	abstract = {Learning Analytics Dashboards (LADs) can help provide insights and inform pedagogical decisions by supporting the analysis of large amounts of educational data, obtained from sources such as Digital Learning Materials (DLMs). Extracting requirements is a crucial step in developing a LAD, as it helps identify the underlying design problem that needs to be addressed. In fact, determining the problem that requires a solution is one of the primary objectives of requirements extraction. Although there have been studies on the development of LADs for K12 education, these studies have not specifically emphasized the use of a Human-Centered Design (HCD) approach to better comprehend the teachers’ requirements and produce more stimulating insights. In this paper we apply prototyping, which is widely acknowledged as a successful way for rapidly implementing cost-effective designs and efficiently gathering stakeholder feedback, to elicit such requirements. We present a three-step HCD approach, involving a design cycle that employs paper and interactive prototypes to guide the systematic and effective design of LADs that truly meet teacher requirements in primary/secondary education, actively engaging them in the design process. We then conducted interviews and usability testing to co-design and develop a LAD that can be used in classroom’s everyday learning activities. Our results show that the visualizations of the interactive prototype were easily interpreted by the participants, verifying our initial goal of co-developing an easy-to-use LAD. © 2023 by the authors.},
	author_keywords = {educational data; human-centered design; interactive prototype; K12; learning analytics dashboard; paper prototype; usability test},
	correspondence_address = {Z. Mohseni; Department of Computer Science and Media Technology, Linnaeus University, Växjö, 351 95, Sweden; email: zeynab.mohseni@lnu.se},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Israel-Fishelson2024794,
	author = {Israel-Fishelson, Rotem and Kohen-Vacs, Dan},
	title = {Towards Optimization of Learning Analytics Dashboards That are Customized for the Students' Requirements},
	year = {2024},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {17},
	pages = {794 – 802},
	doi = {10.1109/TLT.2023.3332500},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177092730&doi=10.1109%2fTLT.2023.3332500&partnerID=40&md5=c51048f650ce6013e4ba1e6a9c24fc16},
	affiliations = {Holon Institute of Technology, Faculty of Instructional Technologies, Holon, 5810201, Israel},
	abstract = {Educational dashboards enable students to monitor and reflect on academic performance and administrative aspects of the learning processes. Occasionally, educational institutions integrate dashboards using the information found in their learning management systems or their students' information desks. Learning analytics offers ways to enrich these dashboards and expose students to analyzed information beyond the monitored data provided such as smart recommendations. Despite the large variety of dashboards, the students' centric perspective and the ability to adapt the dashboard to their personal needs is not a common practice. To identify and support the needs of students who wish to track aspects of their learning routine, it is very important to position the students at the core of the design process of these dashboards. This article presents a new phase in our research to expand our understanding of the students' needs in monitoring their educational routines and preferences while using an advanced form of a learning analytics dashboard. We propose an optimized approach for designing educational dashboards. In this sense, we examine and seek to integrate the components that are prominently required by students. Hence, we address both the type of components as well as their arrangement within the customized dashboard. The outcomes of our efforts reveal findings concerning students' trends and habits when exploiting these dashboards. It also offers pivotal insights and recommendations for the optimized implementation of learning analytics dashboards that are aligned with the students' authentic requirements.  © 2008-2011 IEEE.},
	author_keywords = {Dashboard component; design cluster; learning analytics dashboard; learning management systems (LMS); students information desk (SID)},
	keywords = {Design; Information management; Learning systems; Academic performance; Dashboard component; Design cluster; Educational institutions; Learning analytic dashboard; Learning management system; Learning process; Optimisations; Student information desk; Students},
	correspondence_address = {D. Kohen-Vacs; Holon Institute of Technology, Faculty of Instructional Technologies, Holon, 5810201, Israel; email: mrkohen@hit.ac.il},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tepgec2024,
	author = {Tepgec, Mustafa and Heil, Joana and Ifenthaler, Dirk},
	title = {Feedback literacy matters: unlocking the potential of learning analytics-based feedback},
	year = {2024},
	journal = {Assessment and Evaluation in Higher Education},
	doi = {10.1080/02602938.2024.2367587},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197162086&doi=10.1080%2f02602938.2024.2367587&partnerID=40&md5=ebc9b4ed4d4f48994fb5265b5c66d9c6},
	affiliations = {Hacettepe University, Turkey; University of Mannheim, Germany; Curtin University, Australia},
	abstract = {Despite the widespread implementation of learning analytics (LA)-based feedback systems, there exists a gap in empirical investigations regarding their influence on learning outcomes. Moreover, existing research primarily focuses on individual differences, such as self-regulation and motivation, overlooking the potential of feedback literacy (FL). FL, an emerging skill set, goes beyond comprehending feedback; it entails effectively applying feedback to enhance the learning experience. This study aims to investigate the impact of LA-based feedback on knowledge acquisition and transfer, specifically focusing on the role of FL. Ninety-five students participated in a quasi-experimental design with three feedback conditions: Process feedback with FL practice, Process feedback only, and Outcome feedback. The study utilized a learning environment with an LA dashboard and prompting features. Participants underwent pre-tests and post-tests evaluating their knowledge acquisition and transfer related to effective instructional methodologies for online teaching. The study shows that LA-based process feedback enhances knowledge transfer but not acquisition. Notably, FL moderates this impact, emphasizing its crucial role in maximizing LA-based feedback benefits. The study underscores the importance of prioritizing FL development in educational institutions. The study offers valuable insights into LA, FL, and learning outcomes, guiding informed and customized feedback practices in education. © 2024 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {feedback literacy; Learning analytics; learning outcomes; quasi-experiment},
	correspondence_address = {M. Tepgec; Hacettepe University, Turkey; email: mustafatepgec@gmail.com},
	publisher = {Routledge},
	issn = {02602938},
	language = {English},
	abbrev_source_title = {Assess. Eval. High. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Kohlhase2024,
	author = {Kohlhase, Michael and Berges, Marc and Grubert, Jens and Henrich, Andreas and Landes, Dieter and Leidner, Jochen L. and Mittag, Florian and Nicklas, Daniela and Schmid, Ute and Sedlmaier, Yvonne and Ulbrich-vom Ende, Achim and Wolter, Diedrich},
	title = {Project VoLL-KI: Learning from Learners},
	year = {2024},
	journal = {KI - Kunstliche Intelligenz},
	doi = {10.1007/s13218-024-00846-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192086943&doi=10.1007%2fs13218-024-00846-9&partnerID=40&md5=daf8f2f884c2eb020684a363afe025fd},
	affiliations = {Department for Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Computer Science, University of Sheffield, Sheffield, United Kingdom; Informatik, Hochschule Coburg, Coburg, Germany; Informatik, Otto-Friedrich Universität Bamberg, Bamberg, Germany; Wirtschaftswissenschaften, Hochschule Coburg, Coburg, Germany},
	abstract = {“Learning from Learners” (“Von Lernenden Lernen”, “VoLL-KI ” for short) is a is collaborative research project with the goal of creating a practical toolbox of instruments at different levels of abstraction to improve the learning experience and outcomes for students of artificial intelligence. Learning and teaching at tertiary education institutions are currently IT-based but not AI-supported. The VoLL-KI project aims to go this crucial next step. Using AI approaches (e.g., ML, symbolic AI, statistical AI), several educational technologies are developed on the different granularity of the study programs (e.g., course, semester, program). So, dashboards for study planning, recommender systems improving student advisory services and learning material selection, VR-based learning experiences, educational chatbots, and adaptive learning environments are developed. The systems are mostly deployed as prototypes. © The Author(s) 2024.},
	author_keywords = {Computer-aided education; Computer-aided learning (CAL); Data-driven learning quality management; Intelligent tutoring systems; Learning analytics; Study course monitoring; Teaching support for artificial intelligence education},
	keywords = {Artificial intelligence; Computer aided instruction; Information management; Learning systems; Students; Teaching; Computer-aided education; Computer-aided learning; Data driven; Data-driven learning quality management; Intelligent tutoring; Intelligent tutoring system; Learning analytic; Learning quality; Study course monitoring; Teaching support for artificial intelligence education; Tutoring system; Quality management},
	correspondence_address = {M. Berges; Department for Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; email: marc.berges@fau.de},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09331875},
	language = {English},
	abbrev_source_title = {KI - Kunstl. Intell.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ramaswami2023115,
	author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha},
	title = {Effectiveness of a Learning Analytics Dashboard for Increasing Student Engagement Levels},
	year = {2023},
	journal = {Journal of Learning Analytics},
	volume = {10},
	number = {3},
	pages = {115 – 134},
	doi = {10.18608/jla.2023.7935},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180640044&doi=10.18608%2fjla.2023.7935&partnerID=40&md5=31e6fb5a28ec6a96a3ccdc788f433c20},
	affiliations = {Massey University, Auckland, New Zealand},
	abstract = {Learning Analytics Dashboards (LADs) are gaining popularity as a platform for providing students with insights into their learning behaviour patterns in online environments. Existing LAD studies are mainly centred on displaying students’ online behaviours with simplistic descriptive insights. Only a few studies have integrated predictive components, while none possess the ability to explain how the predictive models work and how they have arrived at specific conclusions for a given student. A further gap exists within existing LADs with respect to prescriptive analytics that generate data-driven feedback to students on how to adjust their learning behaviour. The LAD in this study attempts to address this gap and integrates a full spectrum of current analytics technologies for sense-making while anchoring them within theoretical educational frameworks. This study’s LAD (SensEnablr) was evaluated for its effectiveness in impacting learning in a student cohort at a tertiary institution. Our findings demonstrate that student engagement with learning technologies and course resources increased significantly immediately following interactions with the dashboard. Meanwhile, results showed that the dashboard boosted the respondents’ learning motivation levels and that the novel analytics insights drawn from predictive and prescriptive analytics were beneficial to their learning. This study, therefore, has implications for future research when investigating student outcomes and optimizing student learning using LAD technologies. © 2023, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {dashboard; dashboard evaluation; descriptive analytics; Learning analytics; predictive and prescriptive analytics; student engagement behaviours; usability},
	correspondence_address = {G. Ramaswami; Massey University, Auckland, New Zealand; email: g.ramaswami@massey.ac.nz},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access}
}

@CONFERENCE{Duch2024385,
	author = {Duch, Dynil and May, Madeth and George, Sébastien},
	title = {Empowering Students: A Reflective Learning Analytics Approach to Enhance Academic Performance},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {385 – 396},
	doi = {10.5220/0012634600003693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193974930&doi=10.5220%2f0012634600003693&partnerID=40&md5=f476a7c38efe680301468b95cc4d7551},
	affiliations = {LIUM, Le Mans Université, Cedex 9, Le Mans, 72085, France; Institute of Digital Research & Innovation, Cambodia Academy of Digital Technology, Phnom Penh, Cambodia},
	abstract = {The surge in online education has accentuated the importance of practical Learning Analytics (LA) tools, traditionally designed to support educators. In the meantime, a notable gap exists in empowering students directly through user progress insights and reflective components. This paper presents our research effort in designing a novel approach: a Self-reflective Tool (SRT) with data indicators on student performance designed to actively engage students in their learning journey. Our research explores the landscape of existing LA tools, pinpointing the lack of technological supports for students, and the limitations in empowering students. The methodology involves data extraction, and a comparative analysis of classifiers to predict student performance (SP). Our reflective tool is therefore built, not only to support students in their learning activities, but also to provide them with a more relevant assistance according to their SP. Surveys are made to assess our proposal of SRT. The findings illustrate how students perceive it and how SRT oriented data indicators increase awareness, regulation, and motivation of individual learning patterns. Our qualitative analysis also demonstrates a positive correlation between student engagement with the reflective tool and improvements in academic outcomes. This research contributes to the discourse on LA by emphasizing the importance of reflective tools for students in Metacognition Online Learning Environments (MOLE), providing valuable insights for future developments in student-centric approaches to education. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Data Indicators; Data Visualization; Educational Dashboards; Empowering Students; Learning Analytics; Learning Behavior; Learning Patterns; Predictive Learning; Reflective Tools; Student Performance},
	keywords = {Computer aided instruction; Data visualization; E-learning; Predictive analytics; Analytic tools; Data indicator; Educational dashboard; Empowering student; Learning analytic; Learning behavior; Learning patterns; Predictive learning; Reflective tool; Student performance; Students},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Khelifi202438,
	author = {Khelifi, Tesnim and Rabah, Nourhène Ben and Le Grand, Bénédicte and Daoudi, Ibtissem},
	title = {EX-LAD: an Explainable Learning Analytics Dashboard in Higher Education},
	year = {2024},
	journal = {EPiC Series in Computing},
	volume = {97},
	pages = {38 – 51},
	doi = {10.29007/dsxd},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191655379&doi=10.29007%2fdsxd&partnerID=40&md5=fee1a4957be1040321533ad694bc4614},
	affiliations = {Centre de Recherche en Informatique, Université Paris 1 Panthéon Sorbonne 90 rue de Tolbiac, Paris, 75013, France; LA Recherche en Intelligence Artificielle UR22ES01, ENSI, 2010, Tunisia},
	abstract = {This paper introduces an EXplainable Learning Analytic Dashboard (EX-LAD) that presents learning analytics data on student performance, engagement, and perseverance in a clear and easily understandable manner. The main goal of this study is to make this information accessible to both teachers and students, who may not possess extensive knowledge in data analysis, and demonstrate the effectiveness of the relationship between performance, engagement, and perseverance in identifying student difficulties. This dashboard enables teachers to gain valuable information about their student’s progress, identify at-risk learners, and provide targeted support. Similarly, students can use this dashboard to track their own learning journey, identify their strengths and weaknesses, and make informed decisions to improve their academic performance. It integrates visualizations to represent various aspects of student learning, such as performance, engagement, and perseverance. To demonstrate the effectiveness of our dashboard, we conducted a case study using real data collected from ESIEE-IT, an engineering school in France, during the academic year 2021-2022. This case study serves as concrete evidence of the impact and values our dashboard brings to the educational context. © 2024, EasyChair. All rights reserved.},
	author_keywords = {Dashboard; Explainability; learning analytics; Technology Enhanced Learning; visualization},
	keywords = {Visualization; Case-studies; Dashboard; Explainability; High educations; Informed decision; Learning analytic; Performance; Student performance; Teachers'; Technology enhanced learning; Students},
	editor = {Kambhampaty K. and Hu G. and Roy I.},
	publisher = {EasyChair},
	issn = {23987340},
	language = {English},
	abbrev_source_title = {EPIC Sre. Comp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Cai202481,
	author = {Cai, Zhenyu and Davis, Richard and Tormey, Roland and Dillenbourg, Pierre},
	title = {Learning Analytics Beyond Traditional Classrooms: Addressing the Tensions of Cognitive and Meta-Cognitive Goals in Exercise Sessions},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15160 LNCS},
	pages = {81 – 86},
	doi = {10.1007/978-3-031-72312-4_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205287837&doi=10.1007%2f978-3-031-72312-4_9&partnerID=40&md5=eb0693f363e2b9a5347279ec4e9891d7},
	affiliations = {EPFL, Lausanne, Switzerland},
	abstract = {A range of learning analytics (LA) tools have been designed and integrated into university classes to facilitate teaching and learning. However, exercise sessions, the educational setting that complements lectures with practical activities, are commonly overlooked by LA researchers and designers. Little work has focused on involving the key stakeholders, teaching assistants (TAs), and incorporating human-centered design approaches in this context. To address this gap, we conducted a qualitative study to understand TAs’ common approaches and challenges of teaching in exercise sessions, and to explore their visions for LA dashboards that could be adapted into their current practices. Our results indicated that TAs in exercise sessions held two sets of goals in supporting students’ cognitive and meta-cognitive activities, and while LA tools were seen as offering numerous potential benefits, they were also seen as introducing tensions threatened to disrupt the delicate balance of both goals. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Exercise Sessions; Higher Education; Learning Analytics; Teacher Dashboards},
	keywords = {Active learning; Adversarial machine learning; Federated learning; Analytic tools; Educational settings; Exercise session; High educations; Learning analytic; Metacognitives; Teacher dashboard; Teachers'; Teaching and learning; Teaching assistants; Contrastive Learning},
	correspondence_address = {Z. Cai; EPFL, Lausanne, Switzerland; email: zhenyu.cai@epfl.ch},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172311-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Poellhuber2024151,
	author = {Poellhuber, Bruno and Roy, Normand and Lepage, Alexandre},
	title = {Artificial Intelligence in Higher Education: Opportunities, Issues, and Challenges},
	year = {2024},
	journal = {Human-Centered AI: a Multidisciplinary Perspective for Policy-Makers, Auditors, and Users},
	pages = {151 – 162},
	doi = {10.1201/9781003320791-17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195950349&doi=10.1201%2f9781003320791-17&partnerID=40&md5=f0209dcbbb833a4fa34352b46be22416},
	affiliations = {Université de Montréal, Québec, Montréal, Canada},
	abstract = {Since November 2022, ChatGPT has had very high visibility in higher education, raising an impressive amount of debate and discussion. These conversations have been focused on both the various risks and issues raised by such powerful AI tools but also on the diverse possibilities they offer to assist, facilitate, and even augment the work of learners and teachers. For many people, ChatGPT represents an eruption of AI in the field of education. Yet this sudden media attention obscures the fact that AI has been present in higher education for many years already. The field of learning analytics is growing significantly in education, resulting in descriptive or predictive analyses based on the traces left by learners in digital environments, and giving rise to predictive dropout models and dashboards that have been implemented in some universities (Ifenthaler & Yau, 2020). Technological developments by large cloud providers make it much easier to accumulate data for analysis (data mining) or to develop intelligent conversational agents (chatbots) that can be used to support students (Heryandi, 2020). The field of AI in education (AIED) focuses on learning analytics, conversational robots and natural language processing, adaptive learning, speech and visual recognition, expert systems, and decision support systems. It now also encompasses generative AI. © 2024 selection and editorial matter, Catherine Régis, Jean-Louis Denis, Maria Axente, & Atsuo Kishimoto; individual chapters, the contributors.},
	publisher = {CRC Press},
	isbn = {978-100386079-2; 978-103234162-0},
	language = {English},
	abbrev_source_title = {Human-Centered AI: a Multidisciplinary Perspective for Policy-Makers, Auditors, and Users},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Navarro2024,
	author = {Navarro, Miriam and Becerra, Álvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Fierrez, Julian},
	title = {VAAD: Visual Attention Analysis Dashboard Applied to e-Learning},
	year = {2024},
	journal = {26th International Symposium on Computers in Education, SIIE 2024},
	doi = {10.1109/SIIE63180.2024.10604520},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201240140&doi=10.1109%2fSIIE63180.2024.10604520&partnerID=40&md5=948a51786d74bef8028110129fc1a836},
	affiliations = {School of Engineering, Universidad Autonoma de Madrid, Spain},
	abstract = {In this paper, we present an approach in the Multimodal Learning Analytics field. Within this approach, we have developed a tool to visualize and analyze eye movement data collected during learning sessions in online courses. The tool is named VAAD -an acronym for Visual Attention Analysis Dashboard-. These eye movement data have been gathered using an eye-tracker and subsequently processed and visualized for interpretation. The purpose of the tool is to conduct a descriptive analysis of the data by facilitating its visualization, enabling the identification of differences and learning patterns among various learner populations. Additionally, it integrates a predictive module capable of anticipating learner activities during a learning session. Consequently, VAAD holds the potential to offer valuable insights into online learning behaviors from both descriptive and predictive perspectives.  © 2024 IEEE.},
	author_keywords = {biometrics; dashboard; eye-tracker; learning analytics; machine learning; multimodal learning; online learning},
	keywords = {Behavioral research; Data visualization; E-learning; Eye movements; Eye tracking; Learning systems; Modal analysis; Dashboard; E - learning; Eye movement datum; Eye trackers; Learning analytic; Learning sessions; Machine-learning; Multi-modal learning; Online learning; Visual Attention; Population statistics},
	editor = {Conde M.A. and Conde M.A. and Conde M.A. and do Rosario Rodrigues M. and Garcia-Penalvo F.J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037661-6},
	language = {English},
	abbrev_source_title = {Int. Symp. Comput. Educ., SIIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203837124&partnerID=40&md5=2961b44bdde6bf9b9064081090ecc3f9},
	abstract = {The proceedings contain 87 papers. The topics discussed include: unlocking access: can audio replace Odia Braille in rural India’s post-pandemic shift to online learning?; technical acceptance, issues, and recommendations of novice Chinese teachers towards 360-degree videos; perspective of AI Chatbots in K-12 education; towards lesson planning interfaces for integration of students’ out-of-classroom experiences; evaluating personality impact on engagement and confusion detection in learning environments; co-design of an adaptive personalized learner dashboard; auto-scoring of math self-explanations by combining visual and language analysis; and game learning analytics in educational digital games: preliminary results of a systematic mapping of analysis techniques and visualization strategies.},
	editor = {Altinay Z. and Chang M. and Kuo R. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036205-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Clark2023,
	author = {Clark, Andrew and Shephard, Craig and Robson, Andrew and McKechnie, Joel and Morrison, R. Blake and Rankin, Abbie},
	title = {A Multifaceted Approach to Developing an Australian National Map of Protected Cropping Structures},
	year = {2023},
	journal = {Land},
	volume = {12},
	number = {12},
	doi = {10.3390/land12122168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180685503&doi=10.3390%2fland12122168&partnerID=40&md5=47c794def95d8750679e7501710dc446},
	affiliations = {Applied Agricultural Remote Sensing Centre, The University of New England, Armidale, 2350, NSW, Australia},
	abstract = {As the global population rises, there is an ever-increasing demand for food, in terms of volume, quality and sustainable production. Protected Cropping Structures (PCS) provide controlled farming environments that support the optimum use of crop inputs for plant growth, faster production cycles, multiple growing seasons per annum and increased yield, while offering greater control of pests, disease and adverse weather. Globally, there has been a rapid increase in the adoption of PCS. However, there remains a concerning knowledge gap in the availability of accurate and up-to-date spatial information that defines the extent (location and area) of PCS. This data is fundamental for providing metrics that inform decision making around forward selling, labour, processing and infrastructure requirements, traceability, biosecurity and natural disaster preparedness and response. This project addresses this need, by developing a national map of PCS for Australia using remotely sensed imagery and deep learning analytics, ancillary data, field validation and industry engagement. The resulting map presents the location and extent of all commercial glasshouses, polyhouses, polytunnels, shadehouses and permanent nets with an area of >0.2 ha. The outcomes of the project revealed deep learning techniques can accurately map PCS with models achieving F-Scores > 0.9 and accelerate the mapping where suitable imagery is available. Location-based tools supported by web mapping applications were critical for the validation of PCS locations and for building industry awareness and engagement. The final national PCS map is publicly available through an online dashboard which summarises the area of PCS structures at a range of scales including state/territory, local government area and individual structure. The outcomes of this project have set a global standard on how this level of mapping can be achieved through a collaborative, multifaceted approach. © 2023 by the authors.},
	author_keywords = {aerial imagery; deep learning; geographical information systems; greenhouses; nets; protected cropping; remote sensing; satellite imagery},
	keywords = {Australia; adaptive management; aerial survey; crop yield; cropping practice; food production; GIS; greenhouse ecosystem; growth response; machine learning},
	correspondence_address = {A. Clark; Applied Agricultural Remote Sensing Centre, The University of New England, Armidale, 2350, Australia; email: andrew.clark@une.edu.au},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {2073445X},
	language = {English},
	abbrev_source_title = {Land},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{2024,
	title = {Proceedings of the 16th International Conference on Computer Supported Education, CSEDU 2024},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193919367&partnerID=40&md5=c320e1020e470f4dc2f052a4e5112c86},
	abstract = {The proceedings contain 158 papers. The topics discussed include: students want to experiment while teachers care more about assessment! exploring how novices and experts engage in course design; exploring the impact of Covid-19 pandemic on the online learning experience of higher education students in Morocco; bridging skills and scenarios: initial steps towards using faded worked examples as personalized exercises in vocational education; the role of privacy and security concerns and trust in online teaching: experiences of higher education students in the kingdom of Saudi Arabia; large language models in civic education on the supervision and risk assessment of public works; on few-shot prompting for controllable question-answer generation in narrative comprehension; adaptation in learning analytics dashboards: a systematic review; analyzing learner strategies in programming using clickstream data; and predicting students’ final exam scores based on their regularity of engagement with pre-class activities in a flipped classroom.},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pinargote2024150,
	author = {Pinargote, Adriano and Calderón, Eddy and Cevallos, Kevin and Carrillo, Gladys and Chiluiza, Katherine and Echeverria, Vanessa},
	title = {Automating Data Narratives in Learning Analytics Dashboards using GenAI},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3667},
	pages = {150 – 161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192012021&partnerID=40&md5=7c94b5f57d67ba6c30bf4b67b1503a05},
	affiliations = {Escuela Superior Politecnica del Litoral, Information Technology Center, Campus Gustavo Galindo, Km. 30.5 Vía Perimetral, P.O. Box 09-01, Guayaquil, 5863, Ecuador; Monash University, Clayton, VIC, Australia},
	abstract = {This paper presents an innovative approach leveraging Generative Artificial Intelligence to automate data narratives within Learning Analytics Dashboards for collaborative learning scenarios. Focusing on the analysis of class meeting transcripts, the study delves into specific collaboration skill metrics, transforming raw data into a cohesive narrative. Validation through inter-rater reliability, utilizing Cohen’s Kappa coefficient, establishes the reliability of both human and AI assessments. The integration of Large Language Models, such as ChatGPT3.5, is explored, shedding light on their potential in educational narrative assessment. The proposed methodology not only enhances understanding of class dynamics but also contributes a practical tool for educators, seamlessly translating raw data into visually compelling narratives. The paper concludes with insights from a pilot test, revealing student perceptions and addressing concerns around AI impact on dashboard utility and fairness. This research advances the intersection of data storytelling and Learning Analytics Dashboards, offering valuable insights into collaborative learning dynamics. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Artificial Intelligence; Dashboards; GenAI; Narrative Storytelling},
	keywords = {Data visualization; Metadata; Collaboration skills; Collaborative learning; Dashboard; GenAI; Innovative approaches; Interrater reliability; Learning scenarios; Meeting transcripts; Narrative storytelling; Skill metric; Artificial intelligence},
	correspondence_address = {A. Pinargote; Escuela Superior Politecnica del Litoral, Information Technology Center, Guayaquil, Campus Gustavo Galindo, Km. 30.5 Vía Perimetral, P.O. Box 09-01, 5863, Ecuador; email: adriano.pinargote@cti.espol.edu.ec},
	editor = {Hlosta M. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Moser I. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Flanagan B. and Kyoto University, Center for Innovative Research and Education in Data Science, Room 302 Konoe-kan, 69 Konoe-cho, Sakyo-ku, Yoshida, Kyoto and Fernandez-Nieto G.M. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Yan L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Stewart A. and University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, PA and Winer A. and Open University of Israel, POB 808, 1 University Road, Raanana and Geri N. and Open University of Israel, POB 808, 1 University Road, Raanana and Ramnarain U. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and van der Westhuizen C. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and Shimada A. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Okubo F. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Tseng H.-T. and National Central University, Department of Information Management, 300 Jhongda Road, Zhongli District, Taoyuan City and Yang A.C.M. and National Chung-Hsing University, Department of Computer Science and Engineering, 145 Xingda Road, South District, Taichung and Lu O.H.T. and National Chengchi University, International College of Innovation (ICI), No. 64, Sec 2, Zhinan Rd, Wenshan District, Taipei City and Ogata H. and Kyoto University, Academic Center for Computing and Media Studies, Yoshida Nihonmatsu-cho , Sakyo-ku, Kyoto and Echeverria V. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Martinez-Maldonado R. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Tsai Y.-s. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lawrence L. and Utah State University, Instructional Technology of Learning Sciences, Old Main Hill, Logan, UT and Singh S. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Pozdniakov S. and Chen L.K. and University of Maryland Baltimore County, Department of Information Systems, 1000 Hilltop Circle, Baltimore, MD and Gong J. and Yarnall L. and SRI, SRI Education, 333 Ravenswood Ave, Menlo Park, CA and Nguyen A. and University of Oulu, Faculty of Education and Psychology, Pentti Kaiteran katu 1 Linnanmaa, Oulu and Sha L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lin J. and Carnegie Mellon University, Human-Computer Interaction Institute, 4804 Forbes Avenue, Pittsburgh, PA and Cukurova M. and University College London, UCL Knowledge Lab, 20 Bedford Way, London and Sharma K. and Norwegian University of Science and Technology, Department of Computer Science, IT-bygget, 147, Gloshaugen and Zhao L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Li Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Jin Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Gasevic D. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Mills C. and University of Minnesota, 250 Education Sciences Bldg, 56 E River Rd, Minneapolis, MN and Hutt S. and University of Denver, 2155 E Wesley Drive, Denver, CO},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@BOOK{López-Pernas2024151,
	author = {López-Pernas, Sonsoles and Misiejuk, Kamila and Tikka, Santtu and Kopra, Juho and Heinäniemi, Merja and Saqr, Mohammed},
	title = {Visualizing and Reporting Educational Data with R},
	year = {2024},
	journal = {Learning Analytics Methods and Tutorials: A Practical Guide Using R},
	pages = {151 – 194},
	doi = {10.1007/978-3-031-54464-4_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207987421&doi=10.1007%2f978-3-031-54464-4_6&partnerID=40&md5=84ca820243a8713928ee2ae77cc8eaa4},
	affiliations = {School of Computing, University of Eastern Finland, Joensuu, Finland; Centre for the Science of Learning & Technology (SLATE), University of Bergen, Bergen, Norway; Department of Mathematics and Statistics, University of Jyväskylä, Jyväskylä, Finland; Institute of Biomedicine, University of Eastern Finland, Kuopio, Finland},
	abstract = {Visualizing data is central in learning analytics research, underpins learning dashboards, and is a prime method for reporting results and insights to stakeholders. In this chapter, the reader will be guided through the process of generating meaningful and aesthetically pleasing visualizations of different types of student data using well-known R packages. The main visualization types will be demonstrated with an explanation of their usage and use cases. Furthermore, learning-related examples will be discussed in detail. For instance, readers will learn how to visualize learners' logs extracted from learning management systems to show how trace data can be used to track students' learning activities. In addition to creating compelling plots, readers will also be able to generate professional-looking tables with summary statistics. © The Editor(s) (if applicable) and The Author(s) 2024. This book is an open access publication.},
	author_keywords = {Data visualization; ggplot2; Learning analytics; Visual analytics},
	correspondence_address = {S. López-Pernas; School of Computing, University of Eastern Finland, Joensuu, Finland; email: sonsoles.lopez@uef.fi},
	publisher = {Springer Nature},
	isbn = {978-303154464-4; 978-303154463-7},
	language = {English},
	abbrev_source_title = {Learning Analytics Methods and Tutorials: A Practical Guide Using R},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tretow-Fish2023430,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin},
	title = {Methods for Evaluating Learning Analytics and Learning Analytics Dashboards in Adaptive Learning Platforms: A Systematic Review},
	year = {2023},
	journal = {Electronic Journal of e-Learning},
	volume = {21},
	number = {5},
	pages = {430 – 449},
	doi = {10.34190/ejel.21.5.3088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180458888&doi=10.34190%2fejel.21.5.3088&partnerID=40&md5=5e219839d7380ae5a69ec9e26ba7d59a},
	affiliations = {Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark},
	abstract = {This research paper highlights and addresses the lack of a systematic review of the methods used to evaluate Learning Analytics (LA) and Learning Analytics Dashboards (LAD) of Adaptive Learning Platforms (ALPs) in the current literature. Addressing this gap, the authors built upon the work of Tretow-Fish and Khalid (2022) and analyzed 32 papers, which were grouped into six categories (C1-6) based on their themes. The categories include C1) the evaluation of LA and LAD design and framework, C2) the evaluation of user performance with LA and LAD, C3) the evaluation of adaptivity, C4) the evaluation of ALPs through perceived value, C5) the evaluation of Multimodal methods, and C6) the evaluation of the pedagogical implementation of ALP’s LA and LAD. The results include a tabular summary of the papers including the categories, evaluation unit(s), methods, variables and purpose. While there are numerous studies in categories C1-4 that focus on the design, development, and impact assessment of ALP's LA and LAD, there are only a few studies in categories C5 and C6. For the category of C5), very few studies applied any evaluation methods assessing the multimodal features of LA and LADs on ALPs. Especially for C6), evaluating the pedagogical implementation of ALP's LA and LAD, the three dimensions of signature pedagogy are used to assess the level of pedagogy evaluation. Findings showed that no studies focus on evaluating the deep or implicit structure of ALP's LA. All studies examine the structural surface dimension of learning activities and interactions between students, teachers, and ALP's LA and LAD, as examined in categories C2-C5. No studies were exclusively categorized as a C6 category, indicating that all studies evaluate ALP's LA and LAD on the surface structure dimension of signature pedagogy. This review highlights the lack of pedagogical methodology and theory in ALP's LA and LAD, which are recommended to be emphasized in future research and ALP development and implementation. © The Authors.},
	author_keywords = {Adaptive Learning Platform; Learning Analytics; Methods of evaluation; Systematic literature review},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {14794403},
	language = {English},
	abbrev_source_title = {Electron. J. e-Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{Groher2024618,
	author = {Groher, Iris and Vierhauser, Michael and Hartl, Erik},
	title = {A Learning Analytics Dashboard for Improved Learning Outcomes and Diversity in Programming Classes},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {618 – 625},
	doi = {10.5220/0012735000003693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193971951&doi=10.5220%2f0012735000003693&partnerID=40&md5=c0accdc4b40258a85c85cbc864e98bcb},
	affiliations = {Johannes Kepler University Linz, Institute of Business Informatics, Linz, Austria; University of Innsbruck, Department of Computer Science, Innsbruck, Austria},
	abstract = {The increased emphasis on competency management and learning objectives in higher education has led to a rise in Learning Analytics (LA) applications. These tools play a vital role in measuring and optimizing learning outcomes by analyzing and interpreting student-related data. LA tools furthermore provide course instructors with insights on how to refine teaching methods and material and address diversity in student performance to tailor instruction to individual needs. This tool demonstration paper introduces our Learning Analytics Dashboard, designed for an introductory Python programming course. With a focus on gender diversity, the dashboard analyzes graded Jupyter Notebooks, to provide insights into student performance across assignments and exams. An initial assessment of the dashboard, applying it to our Python programming course in the previous year, has provided us with interesting insights and information on how to further improve our class and teaching materials. We present the dashboard’s design, features, and outcomes while outlining our plans for its future development and enhancement. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Assurance of Learning; Dashboard; Diversity; Learning Analytics; Learning Objectives},
	keywords = {Curricula; High level languages; Teaching; Assurance of learning; Dashboard; Diversity; Learning analytic; Learning objectives; Learning outcome; Programming course; Python programming; Student performance; Teaching materials; Students},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Gujju2024300,
	author = {Gujju, Krishnavamsi and Bandi, Sahithi and Moraes, Marcia},
	title = {Review of Learning Analytics Dashboards for Students},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1058 LNNS},
	pages = {300 – 312},
	doi = {10.1007/978-3-031-65522-7_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201009656&doi=10.1007%2f978-3-031-65522-7_27&partnerID=40&md5=3a8cc96cebf0afe8cda12503a59f7a4e},
	affiliations = {Department of Computer Science, Colorado State University, Fort Collins, United States},
	abstract = {In our comprehensive literature review, we systematically explored the impact of Learning Analytics Dashboards (LADs) on student engagement, motivation, and academic performance within higher education settings. Utilizing a methodical approach, we selected and analyzed 21 studies that met our inclusion criteria focusing on diverse research designs, sample sizes, and outcome measures. Our methodology involved a rigorous evaluation of studies to understand the depth of LAD’s effects on various student populations and learning environments. The results revealed that LADs could significantly enhance student engagement and motivation, leading to improved academic performance. However, the findings also underscored a pressing need for further research into the design and implementation of these dashboards, highlighting the importance of addressing challenges like information overload and the necessity for dashboards to cater to different student demographics. This literature review offers valuable insights into the effective design and implementation of learning dashboards, proposing that future LAD developments should prioritize user-centric designs to maximize learning outcomes and enrich the educational experience in higher education. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Design; Feedback; Learning Analytics; Learning Analytics Dashboard for Students; Learning Management System and Development},
	keywords = {Computer aided instruction; Learning systems; Motivation; Academic performance; Design and implementations; High educations; Learning analytic; Learning analytic dashboard for student; Learning management system; Learning management system and development; Literature reviews; Management development; Student engagement; Students},
	correspondence_address = {K. Gujju; Department of Computer Science, Colorado State University, Fort Collins, United States; email: krish15@colostate.edu},
	editor = {Daimi K. and Al Sadoon A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303165521-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gilliot2024109,
	author = {Gilliot, Jean-Marie and Sadallah, Madjid},
	title = {A framework for co-designing effective LADs supporting sensemaking and decision making},
	year = {2024},
	journal = {International Journal of Learning Technology},
	volume = {19},
	number = {1},
	pages = {109 – 130},
	doi = {10.1504/IJLT.2024.137899},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190504899&doi=10.1504%2fIJLT.2024.137899&partnerID=40&md5=21c7630abc466b6f84b733b264b9df18},
	affiliations = {Lab-STICC UMR CNRS 6285, IMT Atlantique, Brest, F-29238, France},
	abstract = {Learning analytics dashboards (LAD) deserve increasing attention, yet their adoption remains limited. Designing effective LAD is a difficult process, and LADs often fail in turning insights into action. We argue that providing explicit decision-making features in a participatory design process may help to develop LADs supporting action. We first examine how the decision-making process is reflected on LADs. Second, we review the literature to identify major design space dimensions and examine how to include decision-making features. Third, we propose the DEFLAD design framework to synthesise this review which provides explicit decision-making features in three dimensions: goal expression as a situation awareness level, visualisation and related interactions, as support of decision-making process. Fourth, we consider how this framework is involved through every stage of a human-centred design (HCD) process to express and manage such features. The main contribution of this paper is to provide a framework integrating the decision-making features in a participatory design process of LADs. Furthermore, we demonstrate the implementation of our proposals through the development of a card-based toolkit to assist in the ideation phase of participatory design, and present feedback from participants of a workshop utilising this tool as a proof of concept. © 2024 Inderscience Enterprises Ltd.},
	author_keywords = {decision making; design space; human-centred learning analytics; learning analytics; learning analytics dashboard; participatory design; sensemaking},
	correspondence_address = {M. Sadallah; Lab-STICC UMR CNRS 6285, IMT Atlantique, Brest, F-29238, France; email: madjid.sadallah@imt-atlantique.fr},
	publisher = {Inderscience Publishers},
	issn = {14778386},
	language = {English},
	abbrev_source_title = {Int. J. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{de Vetten202487,
	author = {de Vetten, Arjen},
	title = {An Experimental Study into the Effects of an Advisory Dashboard on Students’ Online and Offline Learning},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15160 LNCS},
	pages = {87 – 92},
	doi = {10.1007/978-3-031-72312-4_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205311121&doi=10.1007%2f978-3-031-72312-4_10&partnerID=40&md5=8e30f8a18d294c29ff054acb139620c2},
	affiliations = {ICLON Graduate School of Teaching, Leiden University, Leiden, Netherlands},
	abstract = {Learning analytics dashboards can provide students with personalized actionable feedback to enhance students’ learning. Previous studies have shown positive effects of such advisory dashboards on course engagement and self-regulatory activities. To date, no studies have investigated the effects of advisory dashboards on students’ offline learning activities, such as taking and reviewing written notes, while previous research suggests that many students also employ offline learning activities. Using a randomized control trial, the current study investigated the effects of an advisory dashboard on students’ online and offline remediation activities. Before the start of a second-year course, 65 Bachelor of Law students completed a prior knowledge test concerning the topics of a preceding first-year course. The experimental group (n = 30) received their test results and personalized feedback to review particular knowledge clips and quizzes to remediate their prior knowledge. The control group (n = 35) received their test results and a generic, non-personalized remediation advice. A combination of digital trace and questionnaire data measured students’ remediation activities, including the review of knowledge clips, online quizzes, readings and written notes. The findings did not reveal significant effects of the personalized actionable feedback on students’ remediation activities. However, overall students showed a strong preference for offline activities to remediate their prior knowledge. This calls for further studies on students’ offline learning activities in response to personalized actionable feedback. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Actionable feedback; Advisory dashboards; Learning analytics; Offline learning; Personalized learning; Prior knowledge},
	keywords = {Active learning; Contrastive Learning; Curricula; Federated learning; Self-supervised learning; Students; Actionable feedback; Advisory dashboard; Learning Activity; Learning analytic; Off-line learning; Offline; Online learning; Personalized learning; Prior-knowledge; Student learning; Remediation},
	correspondence_address = {A. de Vetten; ICLON Graduate School of Teaching, Leiden University, Leiden, Netherlands; email: a.j.de.vetten@iclon.leidenuniv.nl},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172311-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2023,
	author = {Liu, Qian and Gladman, Tehmina and Muir, Julia and Wang, Chen and Grainger, Rebecca},
	title = {Analytics-Informed Design: Exploring Visualization of Learning Management Systems Recorded Data for Learning Design},
	year = {2023},
	journal = {SAGE Open},
	volume = {13},
	number = {3},
	doi = {10.1177/21582440231193590},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169443791&doi=10.1177%2f21582440231193590&partnerID=40&md5=d0a547b1bfa8a4d899daefb780a6ebf5},
	affiliations = {University of Otago, Dunedin, New Zealand; Education Unit, University of Otago Wellington, New Zealand},
	abstract = {One apparent challenge associated with learning analytics (LA) has been to promote adoption by university educators. Researchers suggest that a visualization dashboard could serve to help educators use LA to improve learning design (LD) practice. We therefore used an educational design approach to develop a pedagogically useful and easy-to-use LA visualization solution to support data-informed LD. We interviewed four staff in a medical degree program at a New Zealand university, designed and piloted a dashboard, and evaluated it through interviews. As a proof-of-concept project, our study showed that educational design research could be meaningfully used to develop a visualization dashboard that is easy-to-use and useful. In particular, the preliminary design principles identified provide implications for practitioners who are seeking to use LA to inform LD. Finally, we reflect on the purpose of visualization dashboards in relation to the literature and identify areas for future developments. © The Author(s) 2023.},
	author_keywords = {education; educational design research; higher education; learning analytics; learning design; social sciences; visualization},
	correspondence_address = {Q. Liu; University of Otago, Dunedin, New Zealand; email: qian.liu@otago.ac.nz},
	publisher = {SAGE Publications Inc.},
	issn = {21582440},
	language = {English},
	abbrev_source_title = {SAGE Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Balaban202472,
	author = {Balaban, Igor and Zlatovic, Miran and Matus, Marko},
	title = {Using learning analytics dashboards to monitor student progress: the case of a blended computer science university course},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	pages = {72 – 74},
	doi = {10.1109/ICALT61570.2024.00027},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203796734&doi=10.1109%2fICALT61570.2024.00027&partnerID=40&md5=3b284764cddd9c8a8790ae00dc5e1d8d},
	affiliations = {University of Zagreb, Faculty of Organization and Informatics, Varazdin, Croatia},
	abstract = {The research presented here focuses on students' perceptions of using learning analytics dashboards, specifically for tracking progress indicators within the Moodle Learning Management System. The study aims to uncover the connections between progress tracking, motivation, satisfaction, andfinalgrades. The research involved 126 students in a blended course covering economics and informatics. Progress through course materials was tracked using conditional activities, and students' progress was measured using self-assessment quizzes and badges. Results indicated a positive correlation between progress indicators and motivation, as well as a strong correlation between progress indicators and satisfaction. However, no significant correlation was found between progress indicators and final course scores. In conclusion, the study confirms that tracking progress indicators positively impacts student motivation and satisfaction but does not directly affect final grades. Future research should explore the mediating role of motivation and satisfaction in the relationship betweenprogress tracking andfinal course grades. © 2024 IEEE.},
	author_keywords = {Education 4.0; Higher Education; Learning analytics dashboards; Student Progress},
	keywords = {Students; Course material; Education 4.0; High educations; Informatics; Learning analytic dashboard; Learning management system; Self-assessment; Student perceptions; Student progress; University course; Federated learning},
	correspondence_address = {I. Balaban; University of Zagreb, Faculty of Organization and Informatics, Varazdin, Croatia; email: igor.balaban@foi.hr},
	editor = {Altinay Z. and Chang M. and Kuo R. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036205-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hasnine202483,
	author = {Hasnine, Mohammad Nehal and Nguyen, Ho Tan and Akçapınar, Gökhan and Morita, Ryugo and Ueda, Hiroshi},
	title = {Classroom Monitoring using Emotional Data},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3667},
	pages = {83 – 88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191969253&partnerID=40&md5=763b660d820f19f57292536343309f5c},
	affiliations = {Research Center for Computing and Multimedia Studies, Hosei University, Kajinocho 3-7-2, Tokyo, Japan; Department of Computer Education and Instructional Technology, Hacettepe University, Beytepe, Ankara, 06800, Turkey},
	abstract = {Emotions are an integrated part of learning. Emotions can reveal many hidden factors about learning and have the potential to provide actionable insights to teachers to increase the quality of teaching. This study uses multimodal learning analytics methodologies to introduce a classroom monitoring system for teachers teaching online courses. The system is an integrated component of the MOEMO (Motion and Emotion) learning analytics framework that visualizes students' affective and emotional states while taking online classes. Using this classroom monitoring system, a teacher could understand the moments when students were disengaged so that the teacher could intervene to make those disengaged students engaged. The system reports actionable insights on students' engagements and concentrations to the teacher. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {affective states; Classroom monitoring; emotion analysis; engagement; MMLA; teacher-facing dashboard},
	keywords = {E-learning; Learning systems; Teaching; Affective state; Classroom monitoring; Emotion analysis; Engagement; MMLA; Monitoring system; Multi-modal learning; Quality of teaching; Teacher-facing dashboard; Teachers'; Students},
	editor = {Hlosta M. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Moser I. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Flanagan B. and Kyoto University, Center for Innovative Research and Education in Data Science, Room 302 Konoe-kan, 69 Konoe-cho, Sakyo-ku, Yoshida, Kyoto and Fernandez-Nieto G.M. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Yan L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Stewart A. and University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, PA and Winer A. and Open University of Israel, POB 808, 1 University Road, Raanana and Geri N. and Open University of Israel, POB 808, 1 University Road, Raanana and Ramnarain U. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and van der Westhuizen C. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and Shimada A. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Okubo F. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Tseng H.-T. and National Central University, Department of Information Management, 300 Jhongda Road, Zhongli District, Taoyuan City and Yang A.C.M. and National Chung-Hsing University, Department of Computer Science and Engineering, 145 Xingda Road, South District, Taichung and Lu O.H.T. and National Chengchi University, International College of Innovation (ICI), No. 64, Sec 2, Zhinan Rd, Wenshan District, Taipei City and Ogata H. and Kyoto University, Academic Center for Computing and Media Studies, Yoshida Nihonmatsu-cho , Sakyo-ku, Kyoto and Echeverria V. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Martinez-Maldonado R. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Tsai Y.-s. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lawrence L. and Utah State University, Instructional Technology of Learning Sciences, Old Main Hill, Logan, UT and Singh S. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Pozdniakov S. and Chen L.K. and University of Maryland Baltimore County, Department of Information Systems, 1000 Hilltop Circle, Baltimore, MD and Gong J. and Yarnall L. and SRI, SRI Education, 333 Ravenswood Ave, Menlo Park, CA and Nguyen A. and University of Oulu, Faculty of Education and Psychology, Pentti Kaiteran katu 1 Linnanmaa, Oulu and Sha L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lin J. and Carnegie Mellon University, Human-Computer Interaction Institute, 4804 Forbes Avenue, Pittsburgh, PA and Cukurova M. and University College London, UCL Knowledge Lab, 20 Bedford Way, London and Sharma K. and Norwegian University of Science and Technology, Department of Computer Science, IT-bygget, 147, Gloshaugen and Zhao L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Li Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Jin Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Gasevic D. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Mills C. and University of Minnesota, 250 Education Sciences Bldg, 56 E River Rd, Minneapolis, MN and Hutt S. and University of Denver, 2155 E Wesley Drive, Denver, CO},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Yamada2024280,
	author = {Yamada, Masanori and Geng, Xuewang and Goda, Yoshiko and Teasley, Stephanie D.},
	title = {Investigating Metacognitive Behaviors with Online Learning Support Tools},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	pages = {280 – 284},
	doi = {10.1109/ICALT61570.2024.00088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203822868&doi=10.1109%2fICALT61570.2024.00088&partnerID=40&md5=2f186694db63e4e416a7a5a9cf366260},
	affiliations = {Kyushu University, Fukuoka, Japan; School of Informatics, Kumamoto University, Kumamoto, Japan; School of Information, University of Michigan, Ann Arbor, United States},
	abstract = {As information technology advanced, accuracy of technology-driven assessment is being improved. In order to assess learning performance and awareness, assessment of metacognition level with technology can be useful to understand learner's learning comprehension and awareness. Metacognition is one of the most important elements for successful learning. However, current way to evaluate metacognition level focuses on psychological method such as questionnaire and interview. The recent growth of learning analytics research has demonstrated the relationships between metacognition, learning awareness, and learning behaviors. This study aims to investigate metacognitive learning behaviors using small grain data on eBook and learning analytics dashboard (LAD) over eight weeks in a university course. To do so, we determined high and low metacognitive learner groups using the Metacognitive Awareness Inventory and investigated the differences between the two groups in eBook and LAD. The findings suggest that four learning behaviors eBook and LAD were detected as metacognitive learning behaviors, and contribute to the improvement of technology-driven assessment. © 2024 IEEE.},
	author_keywords = {Learning analytics; Learning behavior; Metacognition; Small-grain data},
	keywords = {Adversarial machine learning; Federated learning; E-books; Learning analytic; Learning behavior; Learning support tool; Meta-cognitive behavior; Meta-cognitive learning; Metacognition; Online learning; Small grains; Small-grain data; Contrastive Learning},
	correspondence_address = {M. Yamada; Kyushu University, Fukuoka, Japan; email: mark@mark-lab.net},
	editor = {Altinay Z. and Chang M. and Kuo R. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036205-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Joseph-Richard2024220,
	author = {Joseph-Richard, Paul and Uhomoibhi, James},
	title = {Which Data Sets Are Preferred by University Students in Learning Analytics Dashboards? A Situated Learning Theory Perspective},
	year = {2024},
	journal = {INFORMS Transactions on Education},
	volume = {24},
	number = {3},
	pages = {220 – 237},
	doi = {10.1287/ited.2023.0289},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193969913&doi=10.1287%2fited.2023.0289&partnerID=40&md5=d6d45fa6a29426ab1420ab07ec12b7f8},
	affiliations = {Department of Management, Leadership and Marketing, Ulster University Business School, Belfast, BT15 1ED, United Kingdom; School of Engineering, Ulster University-Belfast Campus, Belfast, BT15 1ED, United Kingdom},
	abstract = {Scholarly interests in developing personalized learning analytics dashboards (LADs) in universities have been increasing. LADs are data visualization tools for both teachers and learners that allow them to support student success and improve teaching and learning. In most LADs, however, a teacher-centric, institutional view drives their designs, treating students only as passive end-users, which results in LADs being less useful to students. To address this limitation, we used a card-sorting technique and asked 42 students at a university in Northern Ireland to construct dashboards that reflect their priorities. Using a situated theory of learning as a lens and with the help of multiple qualitative methods, we collected data on what constitutes useful dashboards. Findings suggest that situated learning data sets, such as information on how students learn by talking and listening to others in their communities, need to be integrated into LADs. Students preferred to see the inclusion of qualitative narratives, self-directed learning data and financial information (money spent versus resources utilized) in LADs. As well as raising new questions on how such LADs could be designed, this study challenges institutional overreliance on measurable digital footprints as proxies for academic success. We call for recognizing the wider social learning that happens in landscapes of practice so that LADs become more useful to students.  Copyright © 2023 The Author(s).},
	author_keywords = {customized design; learning analytics dashboards; personalization; situated theory of learning; student engagement; student-led design},
	correspondence_address = {P. Joseph-Richard; Department of Management, Leadership and Marketing, Ulster University Business School, Belfast, BT15 1ED, United Kingdom; email: p.joseph-richard@ulster.ac.uk},
	publisher = {INFORMS Inst.for Operations Res.and the Management Sciences},
	issn = {15320545},
	language = {English},
	abbrev_source_title = {Trans. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Villalobos20243,
	author = {Villalobos, Esteban and Pérez-Sanagustín, Mar and Broisin, Julien},
	title = {From Learning Actions to Dynamics: Characterizing Students’ Individual Temporal Behavior with Sequence Analysis},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14829 LNAI},
	pages = {3 – 17},
	doi = {10.1007/978-3-031-64302-6_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200207321&doi=10.1007%2f978-3-031-64302-6_1&partnerID=40&md5=e14af49b29c4c8881c2abcc88f3f8085},
	affiliations = {IRIT, Université Toulouse III - Paul Sabatier, Toulouse, France},
	abstract = {Researchers recognize the pivotal role of temporal analysis in unraveling learning processes from learners’ trace data. However, most temporal analysis methods focus on clustering similar trajectories, and very few offer metrics to characterize the learners’ temporal learning behavior. This study draws upon a set of sequence indicators that characterize students’ temporal behavior dynamics. These metrics, focusing on sequence length, diversity, and complexity, provide insights into students’ learning engagement with the course. Applied to a dataset of 91 students collected from a Blended Learning course, we studied these metrics in relation to the learners’ final grades and their self-regulatory profiles. Additionally, we assessed the causal effects of introducing a Learning Analytics Dashboard, an intervention aimed at fostering self-regulated learning, on students’ temporal behavior and final grades by applying Inverse Probability Weighting (IPW). The results show that these metrics serve (1) to characterize individual students’ dynamics through the course and (2) to provide information about the effects of the intervention. In particular, we show that students who interacted with the dashboard had significantly more complex behavior, but no difference in their final course grades. We also revealed that engagement measured as consistent activity might be a stronger predictor than specific learning strategies in an order. This research contributes with a methodological approach for extracting metrics that enrich traditional methods, emphasizing the unique dynamics of individual students, and paving the way for future interventions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Inverse Probability Weighting; Learning Analytics; Sequence Analysis; Temporal Analysis},
	keywords = {Dynamics; Inverse problems; Learning systems; Phase sequence indicators; Analysis method; Inverse probability weighting; Learning actions; Learning analytic; Learning process; Probability weighting; Sequence analysis; Temporal analysis; Temporal behavior; Trace data; Students},
	correspondence_address = {E. Villalobos; IRIT, Université Toulouse III - Paul Sabatier, Toulouse, France; email: esteban.villalobos@irit.fr},
	editor = {Olney A.M. and Chounta I.-A. and Liu Z. and Santos O.C. and Bittencourt I.I.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303164301-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Hu20246628,
	author = {Hu, Yung-Hsiang and Liao, Bo-Kai and Hsieh, Chieh-Lun},
	title = {Effectiveness of a gamified learning analytics dashboard with coregulation mechanism for self-regulated learning in college ethics courses},
	year = {2024},
	journal = {Interactive Learning Environments},
	volume = {32},
	number = {10},
	pages = {6628 – 6644},
	doi = {10.1080/10494820.2023.2277741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176108382&doi=10.1080%2f10494820.2023.2277741&partnerID=40&md5=dfcaa995194147afb528a50275ecaef4},
	affiliations = {Center for General Education, College of Future, National Yunlin University of Science and Technology, Yunlin, Taiwan; Department of Aquaculture, College of Life Sciences, National Taiwan Ocean University, Keelung City, Taiwan; Graduate School, Emilio Aguinaldo College, Manila, Philippines},
	abstract = {It is known that teachers commonly utilize learning platforms equipped with Learning Analytics Dashboards (LAD) to support students in their Self-Regulated Learning (SRL) endeavors. However, students may struggle to effectively employ LAD due to a lack of sufficient metacognitive skills. Co-regulation of learning (CoRL) has been proven to facilitate metacognitive knowledge sharing. However, the implementation of LAD with CoRL mechanisms in self-paced, asynchronous learning environments, aimed at enhancing students' SRL, remains unclear. Investigating how students utilize a LAD with CoRL and how such a system can promote SRL in selfpaced, asynchronous courses is an important topic. This study designed a gamified LAD utilizing a futures trading market interactive interface as the CoRL mechanism. A quasi-experimental design was adopted to assess the effects of the gamified LAD with CoRL on SRL, learning engagement, and academic achievement among 60 students from two Business Ethics classes over the course of a semester. The gamified LAD with CoRL had positive effects on the SRL and learning engagement of the asynchronous learners in the experimental group. Significant differences were observed in the academic achievement of the experimental and control groups. The gamified LAD with CoRL had positive effects on learners in self-paced, asynchronous courses. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {architectures for educational technology systems; distance education and online learning; Teaching/learning strategies},
	correspondence_address = {Y.-H. Hu; Center for General Education, College of Future, National Yunlin University of Science and Technology, Yunlin, Taiwan; email: hsiang@yuntech.edu.tw},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Kuromiya2024,
	author = {Kuromiya, Hiroyuki and Majumdar, Rwitajit and Horikoshi, Izumi and Ogata, Hiroaki},
	title = {Learning analytics for student homework activities during a long break: Evidence from K-12 education in Japan},
	year = {2024},
	journal = {Research and Practice in Technology Enhanced Learning},
	volume = {19},
	doi = {10.58459/rptel.2024.19034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188707352&doi=10.58459%2frptel.2024.19034&partnerID=40&md5=6b7544397ac33101f71ef69f32ff2944},
	affiliations = {Graduate School of Social Informatics, Kyoto University, Japan; Research and Educational Institute for Semiconductors and Informatics, Kumamoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan},
	abstract = {Learning Analytics (LA) is an emergent field that aims to better understand students and provide intelligence to learners, teachers, and administrators using learning log data. Although the use of technology in class is increasing in the K-12 sector and tertiary education, cases of effective implementation of LA in secondary schools have rarely been reported. This study offers an example of LA implemented in a junior high Math class during long vacations in Japan. This paper comprises two studies: first, we analyzed 121 students’ answer logs and their exam performance after vacation by the K-means clustering method. We found that students’ progress patterns were categorized into four types of engagement—early, late, high, and low—and the early and high-engagement groups obtained significantly higher scores than the low-engagement group. In the second study, we implemented a real-time dashboard that visualizes students’ progress patterns and gives students insights about their progress during the vacation period. We found that the dashboard significantly increased students’ interactions with the assignment, and the questionnaire survey determined that the LA dashboard motivated students to learn during the long vacation period. Considering the previous studies of LA, we estimate that LA-based interventions enhance students’ self-regulation skills, which is crucial for learning during long vacation periods. Our study offers a novel approach to implementing LA in K-12 education. © The Author(s).},
	author_keywords = {Evidence-based education; K-12 education; Learning analytics; Learning and Evidence Analytics Framework (LEAF); Long vacation period},
	correspondence_address = {H. Kuromiya; Graduate School of Informatics, Kyoto University, Kyoto, Japan; email: khiroyuki1993@gmail.com},
	publisher = {Asia-Pacific Society for Computers in Education},
	issn = {17937078},
	language = {English},
	abbrev_source_title = {Res. Pract. Technol. Enhanc.  Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kasepalu2023575,
	author = {Kasepalu, Reet and Chejara, Pankaj and Prieto, Luis P. and Ley, Tobias},
	title = {Studying teacher withitness in the wild: comparing a mirroring and an alerting & guiding dashboard for collaborative learning},
	year = {2023},
	journal = {International Journal of Computer-Supported Collaborative Learning},
	volume = {18},
	number = {4},
	pages = {575 – 606},
	doi = {10.1007/s11412-023-09414-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180697379&doi=10.1007%2fs11412-023-09414-z&partnerID=40&md5=2d6f154ce5bcf6eea0d7952af67d6c39},
	affiliations = {School of Educational Sciences, Tallinn University, Tallinn, Estonia; School of Digital Technologies, Tallinn University, Tallinn, Estonia; Department for Continuing Education Research and Educational Technologies, University for Continuing Education, Krems an der Donau, Austria},
	abstract = {Teachers in a collaborative learning (CL) environment have the demanding task of monitoring several groups of students at the same time and intervening when needed. This withitness (both the situational awareness and interventions taken in class) of the teacher might be increased with the help of a guiding dashboard alerting the teacher of problems and providing suggestions for interventions. This paper introduces a quasi-experiment carried out in authentic classrooms. We examined how a mirroring and an alerting & guiding dashboard affected the withitness of teachers in a face-to-face learning environment while students discussed and used a collaborative writing tool. Twenty-four teachers were observed, interviewed, and answered surveys in three different conditions altogether: with no extra information about the situation, using a dashboard mirroring low-level data about the collaboration, and additionally an AI assistant indicating problems in pedagogical terms and potential solutions (i.e., a guiding dashboard). The results show that the situational awareness of the teachers increased with the introduction of a mirroring dashboard. The workload of the participating teachers dropped more with the introduction of an alerting & guiding dashboard, helping teachers feel less frustrated and more accomplished. © 2023, The Author(s).},
	author_keywords = {Artificial intelligence; Awareness; Collaborative learning; Dashboard; Intelligence amplification; Learning analytics; Teacher withitness},
	correspondence_address = {R. Kasepalu; School of Educational Sciences, Tallinn University, Tallinn, Estonia; email: reetkase@tlu.ee},
	publisher = {Springer},
	issn = {15561607},
	language = {English},
	abbrev_source_title = {Int. J. Comput.-Supported Collab. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Maheshi2024118,
	author = {Maheshi, Bhagya and Milesi, Mikaela Elizabeth and Palihena, Hiruni and Zheng, Aaron and Martinez-Maldonado, Roberto and Tsai, Yi-Shan},
	title = {Data Storytelling for Feedback Analytics},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3667},
	pages = {118 – 123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192015029&partnerID=40&md5=283505b916ea28166f334936670fc290},
	affiliations = {Monash University, 3800, VIC, Australia},
	abstract = {Feedback is an essential process of learning in higher education. Yet, capturing students’ interactions with feedback is challenging, which makes it difficult to evaluate its impact. Learning Analytics (LA) is a potential solution to address this issue as it is capable of capturing and analysing learners’ activities in a technology-enabled learning environment. LA often use dashboards to deliver insights derived from educational data, yet questions remain on how to most effectively communicate key insights to students. Data Storytelling (DS) is a promising technique to address this challenge by combining data, visuals and narrative to convey key insights. Co-design can facilitate the crafting of visualisations and data stories that best aligns with goals of the students. This study presents the preliminary findings from a design sprint conducted with students to co-design a prototype for a dashboard of an LA solution – PolyFeed – that captures and analyses students’ interactions with feedback. In developing the dashboards, students used DS principles – Explanatory titles, Annotations, Highlighting important data points, and Decluttering – to improve the selected visualisations. The results show that the student groups perceived visualising strengths and weaknesses identified in feedback, action plans based on feedback, and trends in their performance as key aspects to include in FA dashboard. However, they primarily used two DS principles: explanatory titles and highlighting key data points to improve visualisations because the dataset was pre-dominantly qualitative. Therefore, the effective use of DS to support qualitative data should be further explored. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Data Storytelling; Feedback Analytics; Feedback Traceability; Information Visualisation; Learning Analytics},
	keywords = {Computer aided instruction; Visualization; Co-designs; Data storytelling; Datapoints; Feedback analytic; Feedback traceability; High educations; Information visualization; Learning analytic; Process of learning; Student interactions; Students},
	correspondence_address = {B. Maheshi; Monash University, 3800, Australia; email: Bhagya.GangodaGamachchige@monash.edu},
	editor = {Hlosta M. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Moser I. and Swiss Distance University of Applied Sciences (Fernfachhochschule Schweiz - FFHS), The Institute for Research in Open, Distance and eLearning (IFeL), Schinerstrasse 18, Brig and Flanagan B. and Kyoto University, Center for Innovative Research and Education in Data Science, Room 302 Konoe-kan, 69 Konoe-cho, Sakyo-ku, Yoshida, Kyoto and Fernandez-Nieto G.M. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Yan L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Stewart A. and University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, PA and Winer A. and Open University of Israel, POB 808, 1 University Road, Raanana and Geri N. and Open University of Israel, POB 808, 1 University Road, Raanana and Ramnarain U. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and van der Westhuizen C. and University of Johannesburg, Faculty of Education, PO Box 524, Auckland Park, Kingsway Campus and Shimada A. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Okubo F. and Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka and Tseng H.-T. and National Central University, Department of Information Management, 300 Jhongda Road, Zhongli District, Taoyuan City and Yang A.C.M. and National Chung-Hsing University, Department of Computer Science and Engineering, 145 Xingda Road, South District, Taichung and Lu O.H.T. and National Chengchi University, International College of Innovation (ICI), No. 64, Sec 2, Zhinan Rd, Wenshan District, Taipei City and Ogata H. and Kyoto University, Academic Center for Computing and Media Studies, Yoshida Nihonmatsu-cho , Sakyo-ku, Kyoto and Echeverria V. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Martinez-Maldonado R. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Tsai Y.-s. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lawrence L. and Utah State University, Instructional Technology of Learning Sciences, Old Main Hill, Logan, UT and Singh S. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Pozdniakov S. and Chen L.K. and University of Maryland Baltimore County, Department of Information Systems, 1000 Hilltop Circle, Baltimore, MD and Gong J. and Yarnall L. and SRI, SRI Education, 333 Ravenswood Ave, Menlo Park, CA and Nguyen A. and University of Oulu, Faculty of Education and Psychology, Pentti Kaiteran katu 1 Linnanmaa, Oulu and Sha L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Lin J. and Carnegie Mellon University, Human-Computer Interaction Institute, 4804 Forbes Avenue, Pittsburgh, PA and Cukurova M. and University College London, UCL Knowledge Lab, 20 Bedford Way, London and Sharma K. and Norwegian University of Science and Technology, Department of Computer Science, IT-bygget, 147, Gloshaugen and Zhao L. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Li Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Jin Y. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Gasevic D. and Monash University, Department of Human Centred Computing, Wellington Rd, Clayton, VIC and Mills C. and University of Minnesota, 250 Education Sciences Bldg, 56 E River Rd, Minneapolis, MN and Hutt S. and University of Denver, 2155 E Wesley Drive, Denver, CO},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ley20231397,
	author = {Ley, Tobias and Tammets, Kairit and Pishtari, Gerti and Chejara, Pankaj and Kasepalu, Reet and Khalil, Mohammad and Saar, Merike and Tuvi, Iiris and Väljataga, Terje and Wasson, Barbara},
	title = {Towards a partnership of teachers and intelligent learning technology: A systematic literature review of model-based learning analytics},
	year = {2023},
	journal = {Journal of Computer Assisted Learning},
	volume = {39},
	number = {5},
	pages = {1397 – 1417},
	doi = {10.1111/jcal.12844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160082028&doi=10.1111%2fjcal.12844&partnerID=40&md5=88bc6a6a1caee5e089859e79a36184a6},
	affiliations = {Center for Digitalization in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, Austria; Center for Educational Technology, Tallinn University, Tallinn, Estonia; Centre for the Science of Learning & Technology (SLATE), University of Bergen, Bergen, Norway; Institute of Psychology, University of Tartu, Tartu, Estonia},
	abstract = {Background: With increased use of artificial intelligence in the classroom, there is now a need to better understand the complementarity of intelligent learning technology and teachers to produce effective instruction. Objective: The paper reviews the current research on intelligent learning technology designed to make models of student learning and instruction transparent to teachers, an area we call model-based learning analytics. We intended to gain an insight into the coupling between the knowledge models that underpin the intelligent system and the knowledge used by teachers in their classroom decision making. Methods: Using a systematic literature review methodology, we first identified 42 papers, mainly from the domain of intelligent tutoring systems and learning analytics dashboards that conformed to our selection criteria. We then qualitatively analysed the context in which the systems were applied, models they used and benefits reported for teachers and learners. Results and Conclusions: A majority of papers used either domain or learner models, suggesting that instructional decisions are mostly left to teachers. Compared to previous reviews, our set of papers appeared to have a stronger focus on providing teachers with theory-driven insights and instructional decisions. This suggests that model-based learning analytics can address some of the shortcomings of the field, like meaningfulness and actionability of learning analytics tools. However, impact in the classroom still needs further research, as in half of the cases the reported benefits were not backed with evidence. Future research should focus on the dynamic interaction between teachers and technology and how learning analytics has an impact on learning and decision making by teachers and students. We offer a taxonomy of knowledge models that can serve as a starting point for designing such interaction. © 2023 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {adaptive learning technology; hybrid human-AI technologies; intelligent tutoring systems; learning analytics; systematic literature review; teacher dashboards},
	correspondence_address = {T. Ley; University for Continuing Education Krems, Krems an der Donau, Austria; email: tobias.ley@donau-uni.ac.at},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Deshpande2024,
	author = {Deshpande, K.V. and Asbe, Shubham and Lugade, Akanksha and More, Yash and Bhalerao, Dipali and Partudkar, Anuradha},
	title = {LTA (Learn to Analyze) - A Teacher-Centric Analytical Dashboard for Illustrating Students Academic Progress, Backed by Machine Learning for Informed Performance Enhancement Recommendations},
	year = {2024},
	journal = {2024 3rd International Conference for Innovation in Technology, INOCON 2024},
	doi = {10.1109/INOCON60754.2024.10511389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193592396&doi=10.1109%2fINOCON60754.2024.10511389&partnerID=40&md5=e9ebd4257dc6a873a1258300372b9144},
	affiliations = {JSPM's Rajarshi Shahu College of Engineering, Tathawade, Department of Computer Engineering, Pune, India},
	abstract = {Previous research has firmly established that a communication gap between teachers and students can have detrimental effects on the learning process and student behaviors. In our study, we aim to explore how the implementation of a teacher-centric analytical dashboard can serve as a vital tool in visualizing and addressing this gap [1].Our research underscores the critical role of monitoring each student's academic progress by their teachers for the purpose of enhancing overall performance. This paper will delve into the significance of this practice and how an analytical dashboard tailored to the needs of educators can facilitate this process. Through this exploration, we will highlight the key features and advantages of a teacher-centric analytical dashboard in fostering effective communication and ultimately improving the learning experience for students. © 2024 IEEE.},
	author_keywords = {analyze; deep learning; education field; learning analytics; machine learning; students; teacher facing dashboard; teachers; visualize},
	keywords = {Deep learning; Learning systems; Analyze; Deep learning; Education field; Learn+; Learning analytic; Machine-learning; Teacher facing dashboard; Teachers'; Visualize; Students},
	correspondence_address = {K.V. Deshpande; JSPM's Rajarshi Shahu College of Engineering, Tathawade, Department of Computer Engineering, Pune, India; email: kvdeshpande_comp@jspmrscoe.edu.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038193-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Innov. Technol., INOCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Pan202315,
	author = {Pan, Zilong and Li, Chenglu and Zou, Wenting and Liu, Min},
	title = {Applying learning analytics approaches to detect and track students' cognitive states during virtual problem-solving activities},
	year = {2023},
	journal = {Perspectives on Learning Analytics for Maximizing Student Outcomes},
	pages = {15 – 43},
	doi = {10.4018/978-1-6684-9527-8.ch002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177612038&doi=10.4018%2f978-1-6684-9527-8.ch002&partnerID=40&md5=3caffe5e566281923958010b2442baef},
	affiliations = {Lehigh University, United States; University of Utah, United States; Pennsylvania State University, United States; The University of Texas at Austin, United States},
	abstract = {A virtual problem-based learning (PBL) environment can generate large amounts of textual or timeseries usage data, providing instructors with opportunities to track and facilitate students' problemsolving progress. However, instructors face the challenge of making sense of a large amount of data and translating it into interpretable information during PBL activities. This study proposes a learning analytics approach guided by flow theory to provide teachers with information about middle schoolers' real-time problem-solving cognitive states. The results indicate that the hidden Markov model (HMM) can identify students' specific cognitive states including flow, anxiety, and boredom state. Based on the findings, a teacher dashboard prototype was created. This study has demonstrated the promising potential of incorporating the HMM into learning analytics dashboards to translate a large amount of usage data into interpretable formats, thus, assisting teachers in tracking and facilitating PBL. © 2023, IGI Global. All rights reserved.},
	publisher = {IGI Global},
	isbn = {978-166849528-5; 978-166849527-8},
	language = {English},
	abbrev_source_title = {Perspect. on Learn. Analy. for Maxim. Stud. Outcomes},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gourlay2024,
	author = {Gourlay, Lesley},
	title = {Is A Star A Document? Catalogued Students and Learning Analytics},
	year = {2024},
	journal = {Postdigital Science and Education},
	doi = {10.1007/s42438-024-00489-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197181065&doi=10.1007%2fs42438-024-00489-x&partnerID=40&md5=cd07a45a205d1930fc23a5e37982cbc4},
	affiliations = {UCL Institute of Education, London, United Kingdom},
	abstract = {The media theorist Suzanne Briet proposed that through the recording of information about entities in the world, these entities are not only documented, but they themselves are rendered into documents. She asks us to consider the case of an antelope which is captured, brought to Europe, put in a zoo, and examined by experts and members of the public. She argues that the zoo is effectively a laboratory in which the antelope is analysed, displayed, and therefore itself becomes a document due to these material analytical assemblages around it. In this paper, I propose that Briet’s notion of the document can be applied to data visualisation used in learning analytics, and its effect on students. With reference to a philosophical discussion of the status of data visualisation in terms of Kant’s theory of the sublime versus Deleuze’s notion of the diagram, I argue that a learning analytics dashboard designed for individual student use not only renders the student into a document but also imbricates the student in a co-constitutive form of relationality with that document, which explicitly encourages and rewards a very particular form of action in the world in relation to the learning management system. I conclude that this has real-world effects not only in this inculcation, but in the reification of a particular neoliberal ideology of student engagement as a performance of observable, traceable, self-optimisation in a highly individualised educational worldview. © The Author(s) 2024.},
	author_keywords = {Documentation; Learning analytics; Surveillance; Suzanne briet},
	correspondence_address = {L. Gourlay; UCL Institute of Education, London, United Kingdom; email: l.gourlay@ucl.ac.uk},
	publisher = {Springer International Publishing},
	issn = {2524485X},
	language = {English},
	abbrev_source_title = {Postdigit Sci Educ},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Barbé202475,
	author = {Barbé, Rémi and Encelle, Benoît and Sehaba, Karim},
	title = {Adaptation in Learning Analytics Dashboards: A Systematic Review},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {75 – 86},
	doi = {10.5220/0012628600003693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193924496&doi=10.5220%2f0012628600003693&partnerID=40&md5=e291e9fa537fc7b1ab8db06b3c931edc},
	affiliations = {Univ. Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ. Lyon 2, LIRIS, UMR5205, Villeurbanne, F-69622, France; Univ. Lyon, Univ. Lyon 2, CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Bron, F-69676, France},
	abstract = {Although learning analytics dashboards (LAD) grow in numbers, they often fail to improve learner awareness as they lack adaptation capabilities. This paper presents a systematic review following the PRISMA statement, about the adaptation capabilities of LADs based on new definitions for LADs and learning indicators. A detailed analysis of 23 articles selected among 426 articles retrieved from databases was conducted based on a coding scheme, centered on adaptation and its dimensions, namely: to whom, what, to what, who, and how. The main result of this study is that there is more evidence of adaptable LADs than adaptive LADs. As a result, the road to adaptivity is worth exploring. The analysis of LAD’s common features led us to distinguish mainly 4 adaptable capabilities and 2 adaptive ones. Most of the adaptable capabilities consist of giving exploration power to the user and providing him with data filtering, zooming, or selection functionalities. In contrast, users have limited options when it comes to selecting indicators, their visualizations, and organization on the dashboard. Providing more flexible LADs could enhance their usability and increase learner awareness. Furthermore, the few adaptive features involve adaptations based on “if-then” rules and there are no reports of advanced computing techniques such as machine learning that could empower LAD’s adaptation. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Adaptation; Learning Analytics Dashboards; Learning Indicators; Systematic Review},
	keywords = {Adaptation; Adaptive features; Adaptivity; Coding scheme; Common features; Data filtering; Learning analytic dashboard; Learning indicator; Power; Systematic Review; E-learning},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Masiello2023,
	author = {Masiello, Italo and Fixsen, Dean L. and Nordmark, Susanna and Mohseni, Zeynab and Holmberg, Kristina and Rack, John and Davidsson, Mattias and Andersson-Gidlund, Tobias and Augustsson, Hanna},
	title = {Digital transformation in schools of two southern regions of Sweden through implementation-informed approach: A mixedmethods study protocol},
	year = {2023},
	journal = {PLoS ONE},
	volume = {18},
	number = {12 December},
	doi = {10.1371/journal.pone.0296000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180364012&doi=10.1371%2fjournal.pone.0296000&partnerID=40&md5=64f11d7470f76e36351397576bcf7c99},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; Active Implementation Research Network, Chapel Hill, NC, United States; Department of Education and Teachers' Practice, Linnaeus University, Växjö, Sweden; Department of Pedagogy and Learning, Linnaeus University, Växjö, Sweden; Department of Learning Informatics Management and Ethics, Karolinska Institutet, Solna, Sweden},
	abstract = {Background The enhancement of-or even a shift from-traditional teaching and learning processes to corresponding digital practices has been rapidly occurring during the last two decades. The evidence of this ongoing change is still modest or even weak. However, the adaptation of implementation science in educational settings, a research approach which arose in the healthcare field, offers promising results for systematic and sustained improvements in schools. The aim of this study is to understand how the systematic professional development of teachers and schools principals (the intervention) to use digital learning materials and learning analytics dashboards (the innovations) could allow for innovative and lasting impacts in terms of a sustained implementation strategy, improved teaching practices and student outcomes, as well as evidence-based design of digital learning material and learning analytics dashboards. Methods This longitudinal study uses a quasi-experimental cluster design with schools as the unit. The researchers will enroll gradually 145 experimental schools in the study. In the experimental schools the research team will form a School Team, consisting of teachers/learningtechnologists, school principals, and researchers, to support teachers' use of the innovations, with student achievement as the dependent variable. For the experimental schools, the intervention is based on the four longitudinal stages comprising the Active Implementation Framework. With an anticipated student sample of about 13,000 students in grades 1-9, student outcomes data are going to be analyzed using hierarchical linear models. Discussion The project seeks to address a pronounced need for favorable conditions for children's learning supported by a specific implementation framework targeting teachers, and to contribute with knowledge about the promotion of improved teaching practices and student outcomes. The project will build capacity using implementation of educational technology in Swedish educational settings.  © 2023 Masiello et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Child; Humans; Learning; Longitudinal Studies; Schools; Students; Sweden; article; child; controlled study; educational technology; evidence based practice; human; implementation science; learning; longitudinal study; open access publishing; professional development; school; statistical model; Sweden; teacher; teaching; learning; student; Sweden},
	correspondence_address = {I. Masiello; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; email: italo.masiello@lnu.se},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {38113198},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {36th International Conference on Computer Applications in Industry and Engineering, CAINE 2023},
	year = {2024},
	journal = {EPiC Series in Computing},
	volume = {97},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191720575&partnerID=40&md5=23ca27947da9b11b27f672c8e29e3aeb},
	abstract = {The proceedings contain 11 papers. The special focus in this conference is on Computer Applications in Industry and Engineering. The topics include: KWDOA: Adapted dataset for detection of the direction of arrival of the keyword; EX-LAD: an Explainable Learning Analytics Dashboard in Higher Education; a Workflow Model Based on Three Pillars: Processes, Technology and People within an Organization; Accelerating the execution of the Partition Problem on PYNQ FPGA platform; Peer-to-Peer Data Transfer Evaluation in SmartSSD-based Multi-devices System; an Evaluation of Strategies for Dimensionality Reduction; establishing Trust using Zero Knowledge Succinct Proof in Peer-to-peer Data Transfer; tensor decompositions in cancer study; A comprehensive review.},
	editor = {Kambhampaty K. and Hu G. and Roy I.},
	publisher = {EasyChair},
	issn = {23987340},
	language = {English},
	abbrev_source_title = {EPIC Sre. Comp.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kaliisa2023,
	author = {Kaliisa, Rogers and Jivet, Ioana and Prinsloo, Paul},
	title = {A checklist to guide the planning, designing, implementation, and evaluation of learning analytics dashboards},
	year = {2023},
	journal = {International Journal of Educational Technology in Higher Education},
	volume = {20},
	number = {1},
	doi = {10.1186/s41239-023-00394-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158003907&doi=10.1186%2fs41239-023-00394-6&partnerID=40&md5=106b2f915d5f20a8a0304cccc10e6753},
	affiliations = {Department of Education, The University of Oslo, Blindern 0317, P.O. Box 1092, Oslo, Norway; DIPF & Goethe University Frankfurt, Frankfurt, Germany; Department of Business Management, University of South Africa, Pretoria, South Africa},
	abstract = {Higher education institutions are moving to design and implement teacher-facing learning analytics (LA) dashboards with the hope that instructors can extract deep insights about student learning and make informed decisions to improve their teaching. While much attention has been paid to developing teacher-facing dashboards, less is known about how they are designed, implemented and evaluated. This paper presents a systematic literature review of existing studies reporting on teacher-facing LA dashboards. Out of the 1968 articles retrieved from several databases, 50 articles were included in the final analysis. Guided by several frameworks, articles were coded based on the following dimensions: purpose, theoretical grounding, stakeholder involvement, ethics and privacy, design, implementation, and evaluation criteria. The findings show that most dashboards are designed to increase teachers’ awareness but with limited actionable insights to allow intervention. Moreover, while teachers are involved in the design process, this is mainly at the exploratory/problem definition stage, with little input beyond this stage. Most dashboards were prescriptive, less customisable, and implicit about the theoretical constructs behind their designs. In addition, dashboards are deployed at prototype and pilot stages, and the evaluation is dominated by self-reports and users’ reactions with limited focus on changes to teaching and learning. Besides, only one study considered privacy as a design requirement. Based on the findings of the study and synthesis of existing literature, we propose a four-dimensional checklist for planning, designing, implementing and evaluating LA dashboards. © 2023, The Author(s).},
	author_keywords = {Dashboard evaluation; Learning analytics; Systematic review; Teacher-facing dashboards},
	correspondence_address = {R. Kaliisa; Department of Education, The University of Oslo, Oslo, Blindern 0317, P.O. Box 1092, Norway; email: rogers.kaliisa@iped.uio.no},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23659440},
	language = {English},
	abbrev_source_title = {Int. j. educ. technol. high. educ.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access}
}

@CONFERENCE{Wang202483,
	author = {Wang, Chao and Ng, Jeremy Tzi Dong and López, Nora Patricia Hernández and Hu, Xiao},
	title = {Preliminary Evaluation of Learning Analytics Dashboard for College Teachers' Online Professional Learning},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024},
	pages = {83 – 85},
	doi = {10.1109/ICALT61570.2024.00030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203807481&doi=10.1109%2fICALT61570.2024.00030&partnerID=40&md5=86f5a4a63102c2014585669c06eb50e3},
	affiliations = {The University of Hong Kong, Southern University of Science and Technology, Hong Kong, Hong Kong; Faculty of Education, The University of Hong Kong, Hong Kong, Hong Kong},
	abstract = {Widely accessible online courses provide a feasible platform for teachers' continuous online professional learning. The learning analytics dashboard (LAD) provides fine-grained and actionable feedback that supports learners' self-regulated learning. However, previous studies on LAD design and evaluation predominantly focused on student-facing LADs, with scarce attention on LADs designed for teacher-learners. This study introduces the LAD in an online learning platform for college teachers and conducts a preliminary evaluation with 18 participants. Results show their largely positive ratings on five criteria (e.g., perceived usefulness, ease of use, and behavioral changes) and offer feedback for further refinements of the LAD. This study will improve our understanding of LA-enabled teacher online professional learning and provide practical implications for designing and evaluating LA tools catered to teacher-learners. © 2024 IEEE.},
	author_keywords = {learning analytics dashboard; preliminary evaluation; teacher online professional learning},
	keywords = {Adversarial machine learning; Federated learning; Self-supervised learning; College teachers; Design and evaluations; Fine grained; Learning analytic dashboard; Online course; Preliminary evaluation; Professional learning; Self-regulated learning; Teacher online professional learning; Teachers'; Contrastive Learning},
	correspondence_address = {X. Hu; Faculty of Education, The University of Hong Kong, Hong Kong, Hong Kong; email: xiaoxhu@hku.hk},
	editor = {Altinay Z. and Chang M. and Kuo R. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036205-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Martins202489,
	author = {Martins, Ludmila and Garcia, Elena Cano},
	title = {Designing a Learning Dashboard to Promote Self-regulation in Higher Education},
	year = {2024},
	journal = {Lecture Notes in Educational Technology},
	volume = {Part F3676},
	pages = {89 – 116},
	doi = {10.1007/978-981-97-6136-4_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210592277&doi=10.1007%2f978-981-97-6136-4_5&partnerID=40&md5=6bf8c23dac774f69e07c665ef071e764},
	affiliations = {Departamento de Didáctica y Organización Educativa, Universitat de Barcelona, Barcelona, Spain},
	abstract = {Feedback, understood as an action, implies the process of making sense of information regarding the learning process and its use for self-improvement. In this sense, it is known that feedback could enhance self-regulation learning. Being a self-regulated learner entails skills that allow students to achieve their learning goals. There are different sources of feedback, but particularly with the incorporation of technologies that provide the possibilities to collect and analyse data from learning activities, learning analytics could be a source of feedback. However, it is fundamental to consider not only design factors and content but also the pedagogical background behind these tools. There are a significant number of dashboards developed, but it has been found that they face difficulties in addressing the strengthening of self-regulation. As part of a research and innovation project analysis of the effects of feedback supported by digital monitoring technologies on generic competencies (e-FeedSkill), we developed a learner dashboard with the logs that we collected from a specific didactical sequence settled in Moodle aimed at promoting self-regulation in higher education. In this paper, we present a case study describing and critically analysing the decisions made during the iterative process of designing and developing a learning analytics dashboard for higher education students. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Collaborative design; Feedback; Learning analytics; Self-regulated learning},
	correspondence_address = {L. Martins; Departamento de Didáctica y Organización Educativa, Universitat de Barcelona, Barcelona, Spain; email: ludmila.martins@ub.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Krecko20231370,
	author = {Krecko, Laura K. and Jung, Sarah and Martin, Shaun and Krebsbach, Craig and Rosser, Alexandra A. and Stahl, Christopher and Varley, Patrick and Greenberg, Jacob and Minter, Rebecca M.},
	title = {Enhancing the Value of Surgical Entrustable Professional Activities through Integrative Learning Analytics},
	year = {2023},
	journal = {Journal of Surgical Education},
	volume = {80},
	number = {10},
	pages = {1370 – 1377},
	doi = {10.1016/j.jsurg.2023.07.018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168375555&doi=10.1016%2fj.jsurg.2023.07.018&partnerID=40&md5=e0d0eddbcb6ccf68f1e8feba20e67bb3},
	affiliations = {Department of Surgery, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States; Insights Analytics, Madison, WI, United States; Department of Surgery, Duke University School of Medicine, Durham, North Carolina, United States},
	abstract = {OBJECTIVE: To demonstrate the value of integrating surgical resident Entrustable Professional Activity (EPA) data into a learning analytics platform that provides meaningful feedback for formative and summative decision-making. DESIGN: Description of the Surgical Entrustable Professional Activities (SEPA) analytics dashboard, and examples of summary analytics and intuitive display features. SETTING: Department of Surgery, University of Wisconsin Hospital and Clinics. PARTICIPANTS: Surgery residents, faculty, and residency program administrators. RESULTS: We outline the major functionalities of the SEPA dashboard and offer concrete examples of how these features are utilized by various stakeholders to support progressive entrustment decisions for surgical residents. CONCLUSIONS: Our intuitive analytics platform allows for seamless integration of SEPA microassessment data to support Clinical Competency Committee (CCC) decisions for resident evaluation and provides point of training feedback to faculty and trainees in support of progressive autonomy. © 2023 Association of Program Directors in Surgery},
	author_keywords = {competency-based education; data visualization; entrustable professional activities; learning analytics; workplace-based assessment},
	keywords = {administrative personnel; adult; article; curriculum; data visualization; decision making; human; learning; resident; Wisconsin; workplace},
	correspondence_address = {R.M. Minter; Department of Surgery, University of Wisconsin School of Medicine and Public Health, Madison, H4, 710D CSC, 600 Highland Avenue, 53792-7375, United States; email: minter@surgery.wisc.edu},
	publisher = {Elsevier Inc.},
	issn = {19317204},
	pmid = {37596105},
	language = {English},
	abbrev_source_title = {J. Surg. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Psathas2023329,
	author = {Psathas, Georgios and Tegos, Stergios and Demetriadis, Stavros N. and Tsiatsos, Thrasyvoulos},
	title = {Exploring the impact of chat-based collaborative activities and SRL-focused interventions on students’ self-regulation profiles, participation in collaborative activities, retention, and learning in MOOCs},
	year = {2023},
	journal = {International Journal of Computer-Supported Collaborative Learning},
	volume = {18},
	number = {3},
	pages = {329 – 351},
	doi = {10.1007/s11412-023-09394-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168585371&doi=10.1007%2fs11412-023-09394-0&partnerID=40&md5=55ca80457fdc5b3ff5914e1654bfb450},
	affiliations = {Aristotle University of Thessaloniki, Thessaloniki, Greece},
	abstract = {Despite their potential to deliver a high-quality learning experience, massive open online courses (MOOCs) pose several issues, such as high dropout rates, difficulties in collaboration between students, low teaching involvement, and limited teacher–student interaction. Most of these issues can be attributed to the large number, diversity, and variation in self-regulated learning (SRL) skills of participants in MOOCs. Many instructional designers try to overcome these issues by incorporating collaborative activities. Others try to scaffold students’ SRL levels by making SRL-focused interventions. However, limited research combines the study of SRL-focused interventions with students’ engagement in collaborative activities, course retention, and learning outcomes of MOOC environments. We deployed a programming-oriented MOOC in which we incorporated chat-based collaborative activities, supported by a learning analytics dashboard. Students were asked to complete SRL-focused questionnaires at the beginning and the end of the course. Based on their score, we calculated an average score that forms their SRL level, creating three groups: (a) control, (b) general intervention, and (c) personalized intervention in which we provided personalized interventions. We compared the students’ learning outcomes, participation in collaborative activities, and retention in the MOOC. These comparisons provided evidence regarding the positive impact of different intervention modes on students’ engagement in collaborative activities and their learning outcomes, with respect to their various SRL profiles. Students allocated to the general and personalized intervention groups displayed increased participation in the collaborative activities and learning outcomes, as compared to students assigned to the control group. We also documented that the SRL interventions positively affected students’ course retention. © 2023, The Author(s).},
	author_keywords = {Collaboration; Collaborative activities; Massive open online courses; Self-regulated learning; SRL interventions},
	correspondence_address = {G. Psathas; Aristotle University of Thessaloniki, Thessaloniki, Greece; email: gpsathas@csd.auth.gr},
	publisher = {Springer},
	issn = {15561607},
	language = {English},
	abbrev_source_title = {Int. J. Comput.-Supported Collab. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Misiejuk202465,
	author = {Misiejuk, Kamila and Khalil, Mohammad},
	title = {The Co-design Process of an Instructor Dashboard for Remote Labs in Higher Education},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14722 LNCS},
	pages = {65 – 76},
	doi = {10.1007/978-3-031-61672-3_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197268801&doi=10.1007%2f978-3-031-61672-3_5&partnerID=40&md5=05cc2fbbd9312e3835be5f9ac45c04d6},
	affiliations = {Centre for the Science of Learning and Technology (SLATE), Faculty of Psychology, University of Bergen, Bergen, Norway},
	abstract = {Laboratory experimentation is one of key elements of higher scientific education. Remote Intelligent Access to Labs in Higher Education (RIALHE) is an ambitious project involving three European partners aimed at promoting online access to state-of-the-art laboratory simulations and their environments. As part of the initiative to facilitate remote lab access, researchers and instructors require insights into the students attending these labs. This paper presents the co-design process for developing a low-fidelity instructor dashboard for remote labs in higher education, aiming to support the pedagogical design of labs and enhance student engagement and understanding in higher education laboratory experimentation. Our design journey is documented within the LATUX framework for co-designs from the field of learning analytics. Challenges encountered throughout the co-design principles are discussed, along with considerations for future directions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Co-design; Instructor dashboards; Learning Analytics; Remote labs},
	keywords = {Design; Distance education; Students; Co-designs; Design-process; High educations; Instructor dashboard; Key elements; Learning analytic; On-line access; Remote labs; Scientific education; State of the art; Laboratories},
	correspondence_address = {M. Khalil; Centre for the Science of Learning and Technology (SLATE), Faculty of Psychology, University of Bergen, Bergen, Norway; email: mohammad.khalil@uib.no},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303161671-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings of the 16th International Conference on Computer Supported Education, CSEDU 2024},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193939211&partnerID=40&md5=56229edd20cce24304e02781bd40a76d},
	abstract = {The proceedings contain 158 papers. The topics discussed include: students want to experiment while teachers care more about assessment! exploring how novices and experts engage in course design; exploring the impact of Covid-19 pandemic on the online learning experience of higher education students in Morocco; bridging skills and scenarios: initial steps towards using faded worked examples as personalized exercises in vocational education; the role of privacy and security concerns and trust in online teaching: experiences of higher education students in the kingdom of Saudi Arabia; large language models in civic education on the supervision and risk assessment of public works; on few-shot prompting for controllable question-answer generation in narrative comprehension; adaptation in learning analytics dashboards: a systematic review; analyzing learner strategies in programming using clickstream data; and predicting students’ final exam scores based on their regularity of engagement with pre-class activities in a flipped classroom.},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gunnars2024,
	author = {Gunnars, Fabian},
	title = {Smartbands and Behavioural Interventions in the Classroom: Multimodal Learning Analytics Stress-Level Visualisations for Primary Education Teachers},
	year = {2024},
	journal = {International Journal of Disability, Development and Education},
	doi = {10.1080/1034912X.2024.2355625},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193282582&doi=10.1080%2f1034912X.2024.2355625&partnerID=40&md5=076bf0e656c15dfec993279a9b566045},
	affiliations = {Department of Education, Mid Sweden University, Sundsvall, Sweden},
	abstract = {Students’ stress levels may affect their well-being, attentiveness and learning outcomes in primary education classrooms. Positive behavioural interventions and support actions conducted by teachers may alleviate students’ stress levels, especially when addressing special educational needs. In this multimodal learning analytics study, students in a classroom were all given a smartband for their wrist during regular curriculum activities. Data comprised the semester of a single subject as a part of a research project conducted in Sweden. Biobehavioural stress-related arousal of students’ autonomic nervous system was visualised and analysed through distinguished behavioural modes. Additional data include naturalistic observational notes and two short teacher interviews. Research methodology and strategies for innovative implementation were presented and discussed alongside contextual details. For example, stress-level visualisations can aid actionable adjustments of behavioural intervention intensity and provide students’ attentiveness overview for teachers that sequence curricular activities during planning. Findings show an interdisciplinary basis for cost-effective real-time dynamic solutions that involve visual dashboards with advantages to understanding student learning, both at a school-wide system level and for the classroom, if viewed optimistically. However, research on the topic is still in its infancy, notably with ethical risks as a growing pain. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {biobehavioural analysis; classroom; learning analytics; Positive behavioural interventions and support; primary education; wearables},
	correspondence_address = {F. Gunnars; Department of Education, Mid Sweden University, Sundsvall, Sweden; email: fabian.gunnars@miun.se},
	publisher = {Routledge},
	issn = {1034912X},
	language = {English},
	abbrev_source_title = {Int. J. Disabil. Dev. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lomos20243163,
	author = {Lomos, Catalina and Luyten, J.W. and Kesting, Frauke and Lima da Cunha, Filipe},
	title = {Explaining variation in teachers’ use of ICT: a learning analytics approach},
	year = {2024},
	journal = {Interactive Learning Environments},
	volume = {32},
	number = {7},
	pages = {3163 – 3180},
	doi = {10.1080/10494820.2023.2170419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148654276&doi=10.1080%2f10494820.2023.2170419&partnerID=40&md5=536cf376873a6c4c8887bb6fb37f3784},
	affiliations = {LISER, Luxembourg Institute of Socio-Economic Research, Belval, Esch-sur-Alzette, Luxembourg; Department of Learning, Data-Analytics and Technology, BMS, University of Twente, Enschede, Netherlands; SCRIPT, Luxembourg, Luxembourg},
	abstract = {Significant attention has been paid to the use of ICT by teachers, especially during the COVID-19 health crisis. This usage has mostly been captured through self-reported survey measurements. Learning analytics can complement such findings, by using log data to document precisely how long teachers use ICT, and what ICT behaviors they perform online. Using log data of 800 teachers, the present study documents their use of ICT in mathematics on a digital learning platform used across Luxembourg during COVID-19 remote education. Our findings confirm the large differences between teachers’ use of ICT found in previous research, measured here through the time spent active on the platform. The types of ICT behaviors teachers engage with online, measured via the SAMR model, explain most of this variation. Specifically, more time on the platform is associated with activities that create a meaningful learning experience, and redefined tasks that could engage students as active learners. Experience with the technology, and participation in incentive events and teacher training, explain another significant part of this variation. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {learning analytics; mathematics; SAMR model; teacher digital dashboard; Teachers’ ICT behaviors},
	correspondence_address = {C. Lomos; LISER, Luxembourg Institute of Socio-Economic Research, Esch-sur-Alzette, Belval, Luxembourg; email: catalina.lomos@liser.lu},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Kaliisa2023937,
	author = {Kaliisa, Rogers and Dolonen, Jan Arild},
	title = {CADA: a teacher-facing learning analytics dashboard to foster teachers’ awareness of students’ participation and discourse patterns in online discussions},
	year = {2023},
	journal = {Technology, Knowledge and Learning},
	volume = {28},
	number = {3},
	pages = {937 – 958},
	doi = {10.1007/s10758-022-09598-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127702421&doi=10.1007%2fs10758-022-09598-7&partnerID=40&md5=33ed2bb71a61af588fdfffc4ccbb9b54},
	affiliations = {Department of Education, University of Oslo, Oslo, Norway},
	abstract = {Despite the potential of learning analytics (LA) to support teachers’ everyday practice, its adoption has not been fully embraced due to the limited involvement of teachers as co-designers of LA systems and interventions. This is the focus of the study described in this paper. Following a design-based research (DBR) approach and guided by concepts from the socio-cultural perspective and human-computer interaction (HCI), we design, test, and evaluate a teacher-facing LA dashboard, the Canvas Discussion Analytics Dashboard (CADA), in real educational settings. The goal of this dashboard is to support teachers’ roles in online environments through insights into students’ participation and discourse patterns. We evaluate CADA through 10 in-depth interviews with university teachers to examine their experiences using CADA in seven blended undergraduate and graduate courses over a one-year period. The findings suggest that engaging teachers throughout the analytics tool design process and giving them control/agency over LA tools can favour their adoption in practice. Additionally, the alignment of dashboard metrics with relevant theoretical constructs allows teachers to monitor the learning designs and make course design changes on the fly. The teachers in this study emphasise the need for LA dashboards to provide actionable insights by moving beyond what things are towards how things should be. This study has several contributions. First, we make an artefact contribution (e.g. CADA), an LA dashboard to support teachers with insights into students’ online discussions. Second, by leveraging theory, and working with the teachers to develop and implement a dashboard in authentic teaching environments, we make an empirical, theoretical and methodological contribution to the field of learning analytics and technology enhanced learning. We synthesise these through practical design and implementation considerations for researchers, dashboard developers, and higher education institutions. © 2022, The Author(s).},
	author_keywords = {Asynchronous online discussions; Discourse; Learning design; Participation; Teacher facing learning analytics dashboard},
	keywords = {Curricula; Design; E-learning; Human computer interaction; Learning systems; Social networking (online); Students; Teaching; Analytic tools; Asynchronous online discussion; Discourse; Discourse patterns; Learning designs; Online discussions; Participation; Student participation; Teacher facing learning analytic dashboard; Teachers'; Facings},
	correspondence_address = {R. Kaliisa; Department of Education, University of Oslo, Oslo, Norway; email: rogers.kaliisa@iped.uio.no},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Hybrid Gold Open Access}
}@CONFERENCE{Rodda2023,
	author = {Rodda, Alena and Stahmann, Philip},
	title = {Towards a Student-Centered Learning Analytics Dashboard: Design, Development and Evaluation},
	year = {2023},
	journal = {29th Annual Americas Conference on Information Systems, AMCIS 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192951230&partnerID=40&md5=19c12540cb56e2c0058c075976753aa4},
	affiliations = {Osnabrueck University, Germany},
	abstract = {This paper explores the development of a student-centered Learning Analytics Dashboard (LAD) to promote self-regulated learning. With increasing digitization, online teaching has become an important feature in higher education. However, online learning leads to new challenges for students such as isolation or high self-management requirements. LADs can support students by providing data and analytics on their learning behavior and progress. Yet, there is limited research on the design of LADs, especially with respect to student needs. In this paper, we use design science research methodology to design, develop and evaluate a LAD in two iterations. We assess the usability, visual aesthetics, and Task Technology Fit of the dashboard against the background of self-regulated learning theory. The results show that our LAD is capable of supporting students in the tasks of self-evaluation and self-assessment. © 2023 29th Annual Americas Conference on Information Systems, AMCIS 2023. All rights reserved.},
	author_keywords = {Dashboard; Design Science; Higher Education; Learning Analytics; Task Technology Fit},
	keywords = {Design; E-learning; Information systems; Information use; Dashboard; Design development; Design evaluation; Design science; Digitisation; High educations; Learning analytic; Self-regulated learning; Student centred learning; Task technology fit; Students},
	publisher = {Association for Information Systems},
	isbn = {978-171389359-2},
	language = {English},
	abbrev_source_title = {Annu. Am. Conf. Inf. Syst., AMCIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Judel2023261,
	author = {Judel, Sven and Nitzke, Paul and Schroeder, Ulrik},
	title = {An assistance system for the annotation of learning analytics reports; [Ein Assistenzsystem zur Annotation von Learning Analytics Reports]},
	year = {2023},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {P-338},
	pages = {261 – 262},
	doi = {10.18420/delfi2023-46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178554665&doi=10.18420%2fdelfi2023-46&partnerID=40&md5=fdbc8f1c753414dbc1f21e94f65c0981},
	affiliations = {RWTH Aachen, Lerntechnologien, Germany; RWTH Aachen, Germany},
	author_keywords = {Annotation; Assistenz; Dashboard; Learning Analytics},
	editor = {Ropke R. and RWTH Aachen, Ahornstrabe 55, Aachen and Schroeder U. and RWTH Aachen, Ahornstrabe 55, Aachen},
	publisher = {Gesellschaft fur Informatik (GI)},
	issn = {16175468},
	isbn = {978-388579732-6},
	language = {German},
	abbrev_source_title = {Lect. Notes Informatics (LNI), Proc. - Series Ges. Inform. (GI)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sridhar2023,
	author = {Sridhar, K. and Shinde, Govind and Chaurasia, Amrita and Rani, N.R. Asha},
	title = {Data science: simulating and development of outcome based teaching method},
	year = {2023},
	journal = {Proceedings of the International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering, ICECONF 2023},
	doi = {10.1109/ICECONF57129.2023.10083713},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153034563&doi=10.1109%2fICECONF57129.2023.10083713&partnerID=40&md5=e641d26f2a5b95617d947cd1d3cbbeae},
	affiliations = {Department of Mechanical Engineering, Lendi Institute of Engineering and Technology, Andhra Pradesh, Vizianagaram, India; Department of Management, H K Institute of Management Studies and Research, Maharashtra, Mumbai, India; School of Commerce Finance and Accounting, Christ Demd to Be University Ncr Campus, UP, Gaziabad, India; Department of Civil Engineering, Alliance College of Engineering and Design, Alliance University, India},
	abstract = {The educational researcher has a wealth of options to apply analytics to extract meaningful insights to improve teaching and learning due to the growing availability of educational data. Teaching analytics, in contrast to learning analytics, examines the quality of the classroom environment and the efficacy of the instructional methods used to improve student learning. To investigate the potential of analytics in the classroom without jeopardizing students' privacy, we suggest a data science strategy that uses simulated data using pseudocode to build test cases for educational endeavors. Hopefully, this method's findings will contribute to creating a teaching outcome model (TOM) that can be used to motivate and evaluate educator performance. In Splunk, the study's simulated methodology was carried out. Splunk is a real-time Big Data dashboard that can gather and analyze massive amounts of machine-generated data. We provide the findings as a set of visual dashboards depicting recurring themes and developments in classroom effectiveness. Our study's overarching goal is to help bolster a culture of data-informed decision-making at academic institutions by applying a scientific method to educational data. © 2023 IEEE.},
	keywords = {Data Science; Education computing; Learning systems; Students; Teaching; Classroom environment; Instructional methods; Performance; Pseudo codes; Science strategies; Student learning; Teaching analytics; Teaching and learning; Teaching methods; Test case; Decision making},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835033435-7},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Artif. Intell. Knowl. Discov. Concurr. Eng., ICECONF},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Pishtari2023,
	author = {Pishtari, Gerti and Ley, Tobias and Khalil, Mohammad and Kasepalu, Reet and Tuvi, Iiris},
	title = {Model-Based Learning Analytics for a Partnership of Teachers and Intelligent Systems: A Bibliometric Systematic Review},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {5},
	doi = {10.3390/educsci13050498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160032427&doi=10.3390%2feducsci13050498&partnerID=40&md5=45381239f920c885e6bdfa4a9d31beb9},
	affiliations = {Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems, Danube University Krems, Krems an der Donau, 3500, Austria; School of Educational Sciences, Tallinn University, Tallinn, 10120, Estonia; Centre for the Science of Learning & Technology (SLATE), Faculty of Psychology, University of Bergen, Bergen, 5007, Norway; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, 33100, Finland},
	abstract = {This paper presents a bibliometric systematic review on model-based learning analytics (MbLA), which enable coupling between teachers and intelligent systems to support the learning process. This is achieved through systems that make their models of student learning and instruction transparent to teachers. We use bibliometric network analysis and topic modelling to explore the synergies between the related research groups and the main research topics considered in the 42 reviewed papers. Network analysis depicts an early stage community, made up of several research groups, mainly from the fields of learning analytics and intelligent tutoring systems, which have had little explicit and implicit collaboration but do share a common core literature. Th resulting topics from the topic modelling can be grouped into the ones related to teacher practices, such as awareness and reflection, learning orchestration, or assessment frameworks, and the ones related to the technology used to open up the models to teachers, such as dashboards or adaptive learning architectures. Moreover, results show that research in MbLA has taken an individualistic approach to student learning and instruction, neglecting social aspects and elements of collaborative learning. To advance research in MbLA, future research should focus on hybrid teacher–AI approaches that foster the partnership between teachers and technology to support the learning process, involve teachers in the development cycle from an early stage, and follow an interdisciplinary approach. © 2023 by the authors.},
	author_keywords = {adaptive learning technology; bibliometric analysis; dashboards; intelligent tutoring systems; model-based learning analytics; topic modelling},
	correspondence_address = {G. Pishtari; Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems, Danube University Krems, Krems an der Donau, 3500, Austria; email: gerti.pishtari@donau-uni.ac.at},
	publisher = {MDPI},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Veljanova2023546,
	author = {Veljanova, Hristina and Barreiros, Carla and Gosch, Nicole and Staudegger, Elisabeth and Ebner, Martin and Lindstaedt, Stefanie},
	title = {Operationalising Transparency as an Integral Value of Learning Analytics Systems – From Ethical and Data Protection to Technical Design Requirements},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14040 LNCS},
	pages = {546 – 562},
	doi = {10.1007/978-3-031-34411-4_37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169039685&doi=10.1007%2f978-3-031-34411-4_37&partnerID=40&md5=f527ac4386ce4200b4d6208f75696771},
	affiliations = {Institute of the Foundations of Law, University of Graz, Graz, Austria; Institute Interactive Systems and Data Science, Graz University of Technology, Graz, Austria; Department of Educational Technology, Graz University of Technology, Graz, Austria; Know-Center GmbH, Graz, Austria},
	abstract = {With the rising complexity of technology and its introduction into educational settings, the question of trusting and designing trustworthy learning analytics (LA) systems has gained importance. Transparency is one of the values that can contribute to enhancing an LA system’s trustworthiness. It has been included and discussed as a separate core value or principle in many ethical frameworks for LA. Even though these frameworks provide valuable contributions, they are mostly limited to the conceptual level. Defining what transparency entails in the context of LA is an important aspect, nevertheless, the translation and operationalisation of such abstract concepts into technology should be equally considered. In this paper, we focus on the question of how transparency can be translated into concrete design requirements in order to enhance the trustworthiness of LA systems. We present a normative framework in the form of an interdisciplinary Criteria Catalogue for trustworthy LA, which consists of seven core areas, including transparency. Second, we demonstrate how transparency can be translated and operationalised into more specific and low-level elements by using an example of the Learners’ Corner LA dashboard developed within the project “Learning Analytics – Students in Focus”. Third, we share the results of a study conducted to better understand students’ information needs in relation to LA tools and evaluate our design choices for the introduction of three quick information buttons within the Learners’ Corner. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {human-centred LA; Learning analytics; transparency; trustworthy LA systems},
	keywords = {Ethical technology; Learning systems; Students; Abstract concept; Analytics systems; Conceptual levels; Core values; Educational settings; Human-centered learning analytic; Integral values; Learning analytic; Technical design; Trustworthy learning analytic system; Transparency},
	correspondence_address = {H. Veljanova; Institute of the Foundations of Law, University of Graz, Graz, Austria; email: hristina.veljanova@uni-graz.at},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303134410-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen202210517,
	author = {Chen, Xieling and Zou, Di and Xie, Haoran},
	title = {A decade of learning analytics: Structural topic modeling based bibliometric analysis},
	year = {2022},
	journal = {Education and Information Technologies},
	volume = {27},
	number = {8},
	pages = {10517 – 10561},
	doi = {10.1007/s10639-022-11046-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128331888&doi=10.1007%2fs10639-022-11046-z&partnerID=40&md5=9d8195a0d5d7a48a79b09593e435ae26},
	affiliations = {Department of Mathematics and Information Technology, The Education University of Hong Kong, Hong Kong SAR, 10 Lo Ping Road, New Territories, Tai Po, Hong Kong; Department of English Language Education, The Education University of Hong Kong, Hong Kong SAR, 10 Lo Ping Road, New Territories, Tai Po, Hong Kong; Department of Computing and Decision Sciences, Lingnan University, Hong Kong SAR, New Territories, Tuen Mun, Hong Kong},
	abstract = {Learning analytics (LA) has become an increasingly active field focusing on leveraging learning process data to understand and improve teaching and learning. With the explosive growth in the number of studies concerning LA, it is significant to investigate its research status and trends, particularly the thematic structure. Based on 3900 LA articles published during the past decade, this study explores answers to questions such as “what research topics were the LA community interested in?” and “how did such research topics evolve?” by adopting structural topic modeling and bibliometrics. Major publication sources, countries/regions, institutions, and scientific collaborations were examined and visualized. Based on the analyses, we present suggestions for future LA research and discussions about important topics in the field. It is worth highlighting LA combining various innovative technologies (e.g., visual dashboards, neural networks, multimodal technologies, and open learner models) to support classroom orchestration, personalized recommendation/feedback, self-regulated learning in flipped classrooms, interaction in game-based and social learning. This work is useful in providing an overview of LA research, revealing the trends in LA practices, and suggesting future research directions. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Learning analytics; Research topics; Social network analysis; Structural topic modeling; Topic evolution},
	correspondence_address = {D. Zou; Department of English Language Education, The Education University of Hong Kong, Hong Kong SAR, Tai Po, 10 Lo Ping Road, New Territories, Hong Kong; email: dizoudaisy@gmail.com},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@CONFERENCE{Sapsai202338,
	author = {Sapsai, Iryna and Valencia Usme, Yeimy Paola and Abke, Joerg},
	title = {Learning Analytics Dashboard for Educators: Proposed Project to Design with Pedagogical Background},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {38 – 47},
	doi = {10.1145/3593663.3593686},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163511759&doi=10.1145%2f3593663.3593686&partnerID=40&md5=d0749023f47e5c6b83582202b4f34c5c},
	affiliations = {Faculty of Engineering, University of Applied Science, Aschaffenburg, Germany},
	abstract = {In this article, the authors describe a prototype of a Learning Analytics Dashboard (LAD) for educators. It is based on the analysis of pedagogical actions and taking into the process and learning style of students in an online environment based on learning analytics (LA). A description of the Dashboard structure, divided into levels and categories based on available learning analytics, will allow the educator to dive deeper into the online course themselves and explore more. It will also allow them to determine the level of student performance, identify gaps in learning materials, and research student data. The authors have identified further directions for the development of a LAD for a professor, including modeling algorithms for researching student behavior and learning style using Artificial Intelligence and presenting LA in a visualized form. This paper shows the stages of creating a professor's LAD prototype as a functional part of the adaptive learning system in the HASKI-System to analyze visual information obtained from LA and the possibilities to monitor the learning process, learning progress, student activity, and make decisions on careful intervention in the students' learning process.  © 2023 ACM.},
	author_keywords = {adaptive learning system; distance education pedagogy; information visualization; learning analytics; Learning Analytics Dashboard; pedagogical actions; pedagogical knowledge},
	keywords = {Behavioral research; E-learning; Information systems; Information use; Learning systems; Adaptive learning systems; Distance education pedagogy; Information visualization; Learning analytic; Learning analytic dashboard; Learningstyles; Online course; Online environments; Pedagogical action; Pedagogical knowledge; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039956-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{2023,
	title = {LAK 2023 Conference Proceedings - Towards Trustworthy Learning Analytics - 13th International Conference on Learning Analytics and Knowledge},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149331744&partnerID=40&md5=dd2c8ba6ee6e3be615e96ce1e200d7e9},
	abstract = {The proceedings contain 71 papers. The topics discussed include: predicting item response theory parameters using question statements texts; logs or self-reports? misalignment between behavioral trace data and surveys when modeling learner achievement goal orientation; TikTok as learning analytics data: framing climate change and data practices; learning analytics dashboards: what do students actually ask for?; predictive learning analytics and university teachers: usage and perceptions three years post implementation; each encounter counts: modeling language learning and forgetting; how do teachers use dashboards enhanced with data storytelling elements according to their data visualization literacy skills?; learner-centered analytics of feedback content in higher education; and how to build more generalizable models for collaboration quality? lessons learned from exploring multi-contexts audio-log datasets using multimodal learning analytics.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rodda202367,
	author = {Rodda, Alena},
	title = {Student-Centered Design and Evaluation of a Learning Analytics Dashboard},
	year = {2023},
	journal = {Lecture Notes in Business Information Processing},
	volume = {485 LNBIP},
	pages = {67 – 80},
	doi = {10.1007/978-3-031-42788-6_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174441932&doi=10.1007%2f978-3-031-42788-6_5&partnerID=40&md5=fc90fd6467a16f591a19e799664468ea},
	affiliations = {Osnabrueck University, Katharinenstr. 3, Osnabrueck, 49074, Germany},
	abstract = {The digitization of teaching at universities has increased significantly in recent years, with online and hybrid courses becoming more popular. These formats allow students a high degree of autonomy, but also require them to work independently and organize themselves. However, students often lack these skills. Learning analytics (LA) evaluations, provided as dashboards, can help students to continuously monitor their learning progress and compare themselves to their peers. Nevertheless, the student perspective has often been underrepresented in LA research. There is also a lack of standardized knowledge and processes for implementing LA and making LA information available to end users. This paper aims to develop and evaluate a LA dashboard for a university course based on the requirements of the students, using data from a university’s learning management and examination system. Three dashboard versions are designed and evaluated quantitatively and qualitatively in a study with 114 participants. The results will be discussed, along with limitations and potential future research directions. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboards; Information Design; Learning Analytics},
	keywords = {Information management; Analytic evaluation; Dashboard; Degree of autonomy; Design and evaluations; Digitisation; Hybrid course; Information design; Learning analytic; Online course; Student-centred; Students},
	correspondence_address = {A. Rodda; Osnabrueck University, Osnabrueck, Katharinenstr. 3, 49074, Germany; email: alena.rodda@uni-osnabrueck.de},
	editor = {Jallouli R. and Bach Tobji M.A. and Belkhir M. and Soares A.M. and Casais B.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18651348},
	isbn = {978-303142787-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Bus. Inf. Process.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pozdniakov2023339,
	author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Srivastava, Namrata and Liu, Yuchen and Gasevic, Dragan},
	title = {Single or Multi-page Learning Analytics Dashboards? Relationships Between Teachers’ Cognitive Load and Visualisation Literacy},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {339 – 355},
	doi = {10.1007/978-3-031-42682-7_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171973213&doi=10.1007%2f978-3-031-42682-7_23&partnerID=40&md5=82f3f79305f9943cc0b77ecc984fc249},
	affiliations = {Monash University, Melbourne, Australia},
	abstract = {There has been a proliferation of learning analytics (LA) interfaces designed to support teachers, such as LA dashboards. However, although teacher dashboards have been extensively studied, there is limited understanding of the relationship between single-page or multi-page dashboard designs and the cognitive demands placed on teachers to use them. Additionally, teachers typically have varying levels of visualisation literacy (VL), which may make it easier or more difficult for them to engage with single-page versus multi-page dashboard designs. In this paper, we explore how teachers, with varying VL, use single-page and multi-page LA dashboards. We conducted a quasi-experimental study with 23 higher education teachers of varied VL inspecting single and multi-page LA dashboards. We used an eye-tracking device to measure cognitive load while teachers inspected the LA dashboards in online group work. We investigated how proxy metrics derived from eye-tracking data related to teachers’ cognitive load varied depending on the type of the dashboard teacher used and the level of VL teachers have. Our findings suggest that the design of the LA dashboard had an impact on the cognitive load experienced by the teachers. Post-hoc analysis revealed that teachers with low VL had a marginally lower cognitive load when using single-page dashboards. We argue that the LA dashboard design for teachers should account for teachers’ levels of VL and provide design recommendations. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {dashboards; data literacy; eye-tracking; learning analytics},
	keywords = {Eye tracking; Cognitive demands; Cognitive loads; Dashboard; Data literacy; Education teachers; Eye tracking devices; Eye-tracking; High educations; Learning analytic; Teachers'; Visualization},
	correspondence_address = {S. Pozdniakov; Monash University, Melbourne, Australia; email: stanislavpoznyakof@gmail.com},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Cobos202329,
	author = {Cobos, Ruth},
	title = {The Learning Analytics System that Improves the Teaching-Learning Experience of MOOC Instructors and Students},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13869 LNCS},
	pages = {29 – 40},
	doi = {10.1007/978-3-031-33023-0_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163392064&doi=10.1007%2f978-3-031-33023-0_3&partnerID=40&md5=d44a584e3b960cf5838a841d1bd08f93},
	affiliations = {Computer Science Department, Universidad Autónoma de Madrid, Madrid, Spain},
	abstract = {Great learning opportunities are provided through MOOCs. However, MOOCs provide a number of challenges for students. Many students find it difficult to successfully finish MOOCs due to a variety of factors, including feelings of loneliness, a lack of support, and a lack of feedback. Additionally, the instructors of these courses are highly concerned about this situation and want to reduce these difficulties for their students. Due to the large number of students registered in these courses, this is not a simple task. To help both instructors and students, we created edX-LIMS, a learning analytics (LA) system that allows MOOC instructors to monitor the progress of their students and carry out an intervention strategy in their students’ learning thanks to a Web-based Instructor Dashboard. Furthermore, this LA system provides MOOC students with detailed feedback on their course performance as well as advice on how to improve it thanks to Web-based Learner Dashboards. This LA system have been used for more than two year in a MOOC at edX. During this period the Dashboards supported by the system have been improved, and as a result, MOOC students now appreciate the fact that they feel guided, engagement and motivated to complete the course, among other feelings. MOOC instructor have improved their student monitoring tasks and are better able to identify students who need assistance. Moreover thanks to the services that the intervention strategy supported by the LA system offer to them, now students and instructors feel that are connected. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Engagement; Feedback; Intervention; Learning Analytics; Massive Open Online Course; Motivation},
	keywords = {E-learning; Learning systems; Websites; Analytics systems; Dashboard; Engagement; Intervention; Intervention strategy; Learning analytic; Learning experiences; Massive open online course; Teaching-learning; Web based; Students},
	correspondence_address = {R. Cobos; Computer Science Department, Universidad Autónoma de Madrid, Madrid, Spain; email: ruth.cobos@uam.es},
	editor = {González-González C.S. and Area-Moreira M. and Fernández-Manjón B. and Li F. and García-Peñalvo F.J. and Sciarrone F. and Spaniol M. and García-Holgado A. and Hemmje M. and Hao T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303133022-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Göcök20231965,
	author = {Göcök, Gian-Luca and Simic, Dejan and Leible, Stephan and Lewandowski, Tom and Kučević, Emir},
	title = {Enhancing educational insights: A real-Time data analytics stack for project-based learning},
	year = {2023},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {P-337},
	pages = {1965 – 1973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181141079&partnerID=40&md5=a4e971988ec522e91936444a862e7e5d},
	affiliations = {Universität Hamburg, Department of Informatics, Vogt-Kölln-Straße 30, Hamburg, 22527, Germany},
	abstract = {This paper presents a real-Time data analytics (DA) stack designed for a project-based course utilizing Jira for project management at a university. The DA stack follows an Extract, Transform, and Load process to visualize students' usage data within dashboards. The DA stack supports course management by providing insights into students' activities and progress.We demonstrate theDAstack's effectiveness through an evaluative case study, which was found to support course objectives and foster improved behavioral adaptations from lecturers to students. Furthermore, we propose a generic DA stack for generalizing and adopting it for similar applications, considering the extensibility and maintainability inherent in the open-source tools used. Moreover, we provide the GitHub repository to view our source code. This study contributes to the relatively underexplored field of real-Time learning analytics and offers a starting point for the customization and adoption of the proposed DA stack in different educational contexts. © 2023 Gesellschaft fur Informatik (GI). All rights reserved.},
	author_keywords = {Business intelligence; Data analytics; Educational data mining; Learning analytics; Project-based learning},
	keywords = {Behavioral research; Data mining; Open systems; Project management; Students; Business-intelligence; Case-studies; Course management; Data analytics; Educational data mining; Learning analytic; Project based learning; Project-based course; Real-time data; Usage data; Data Analytics},
	editor = {Klein M. and Gesellschaft fur Informatik, Anna-Louisa-Karsch-Strasse 2, Berlin and Krupka D. and Gesellschaft fur Informatik, Anna-Louisa-Karsch-Strasse 2, Berlin and Winter C. and Gesellschaft fur Informatik, Ahrstrasse 45, Bonn and Wohlgemuth V.},
	publisher = {Gesellschaft fur Informatik (GI)},
	issn = {16175468},
	isbn = {978-388579731-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Informatics (LNI), Proc. - Series Ges. Inform. (GI)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Smith2023177,
	author = {Smith, Matt and De Laet, Tinne and Barata, Ana},
	title = {Learning Analytics for Co-Creation and Interactive Courseware},
	year = {2023},
	journal = {Postdigital Science and Education (Netherlands)},
	volume = {Part F3831},
	pages = {177 – 194},
	doi = {10.1007/978-3-031-31875-7_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212500309&doi=10.1007%2f978-3-031-31875-7_10&partnerID=40&md5=3ceebde74336725d7b7d86f6d481302d},
	affiliations = {University of Wolverhampton, Wolverhampton, United Kingdom; Katholieke Universiteit Leuven, Leuven, Belgium; Instituto Politecnico do Porto, Porto, Portugal},
	abstract = {This chapter explores the use of learning analytics and their dashboards in higher education. We briefly look at some of the pedagogical theories that underpin, and the teaching solutions that enable, social and dialogic learning and then discuss online learning, drawing heavily on a pan-European research project that we have been working on to illustrate our points. Students’ online interactions create data traces that can be used to measure aspects of learning behaviour in real time at an individual level. The resultant data can be interpreted by educators and others, and we discuss some of the challenges and potential drawbacks this could offer, as well as the potential for offering bespoke support in a timely manner to students or cohorts that learning analytics offers. For this chapter we drew on a large Delphi group of experts from across the globe and from their input we offer a series of insights at each of the main stages of learning analytics: the data collection, the analysis, the interpretation, the actions that follow, and the results. We end by noting that learning analytics will have a key role to play in the future of higher education, but context needs always to be present in interpretation: understanding students and their learning must never be reduced to data traces and statistics alone. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {co-creation; LA; LAD; learning analytics; learning dashboards; online pedagogies},
	correspondence_address = {M. Smith; University of Wolverhampton, Wolverhampton, United Kingdom; email: matt.smith@wlv.ac.uk},
	publisher = {Springer Nature},
	issn = {26625326},
	language = {English},
	abbrev_source_title = {Postdigital Sci. Edu.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Drzyzga2023176,
	author = {Drzyzga, Gilbert and Harder, Thorleif and Janneck, Monique},
	title = {Participative Development of a Learning Dashboard for Online Students Using Traditional Design Concepts},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1997 CCIS},
	pages = {176 – 191},
	doi = {10.1007/978-3-031-49368-3_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180773218&doi=10.1007%2f978-3-031-49368-3_11&partnerID=40&md5=0671f67e8c1a2aeb5bf1f949f85b9ca9},
	affiliations = {Institute for Interactive Systems, Technische Hochschule Lübeck, Lübeck, Germany},
	abstract = {In order to improve online learning outcomes, a Learning Dashboard (LD) for online students is being developed as a plugin for the learning management system Moodle to support self-regulation. The project itself focuses on the factors that lead to success and failure in online learning. Using a user-centered design approach, the LD will provide students with feedback and functional elements through different cards. 24 online students completed a three-part term paper in which they examined the elements of two wireframes of the LD in relation to Wertheimer's Gestalt Laws and in terms of factual and interaction problems. We also received 11 card designs from them as a voluntary bonus assignment. Assignments 1 & 2 had to be completed successfully in order to be admitted to the exam. The study was designed to encourage student participation and improve accessibility by taking into account their expertise. The results showed that clearer overviews, clarification of how content elements fit together, more compact solutions, and intuitive controls improved clarity and usability. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Digital degree programs; Dropout rates; Factual and interaction problems; Gestalt laws; Learning analytics; Self-regulation; User-centered design},
	keywords = {Deregulation; E-learning; Learning systems; User centered design; Degree program; Design concept; Digital degree program; Dropout rate; Factual and interaction problem; Gestalt law; Interaction problems; Learning analytic; Online learning; Self regulation; Students},
	correspondence_address = {G. Drzyzga; Institute for Interactive Systems, Technische Hochschule Lübeck, Lübeck, Germany; email: gilbert.drzyzga@th-luebeck.de},
	editor = {da Silva H.P. and da Silva H.P. and Cipresso P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303149367-6},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Antonova2023108,
	author = {Antonova, Albena and Dankov, Yavor},
	title = {Smart Services in Education: Facilitating Teachers to Deliver Personalized Learning Experiences},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {597 LNNS},
	pages = {108 – 117},
	doi = {10.1007/978-3-031-21438-7_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148700488&doi=10.1007%2f978-3-031-21438-7_9&partnerID=40&md5=2e8171a69a6b6683a5b61edae7d21f6d},
	affiliations = {Faculty of Mathematics and Informatics, Sofia University “St. Kl. Ohridski”, Sofia, 1164, Bulgaria},
	abstract = {Information technologies continuously transform the educational landscape, while the dynamic labour market expects fresh graduates and talents ready for the fast-changing job requirements. Smart services, defined as da-ta-enabled and contextualized digital services, can propose new models for learning personalization and adaptation. However, the teachers proved to be essential in introducing the needed changes in the educational system. The present research aims to outline the role of smart services in educational transformation, supporting teachers to adopt personalized and student-oriented teaching strategies. The paper is structured as follows. Firstly, it outlines the specifics of the smart services and explores the teacher’s challenges in embracing the new educational roles and teaching methods. Then, the third section identifies how smart services can support teachers’ strategies for learning personalization and learning experiences differentiation. Last is pro-vided with complex individual and class dashboard models of learning indicators and analytics, evaluating smart services effectiveness. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Learning analytics; Learning personalization; Personalized learning experiences; Smart services},
	correspondence_address = {Y. Dankov; Faculty of Mathematics and Informatics, Sofia University “St. Kl. Ohridski”, Sofia, 1164, Bulgaria; email: yavor.dankov@fmi.uni-sofia.bg},
	editor = {Silhavy R. and Silhavy P. and Prokopova Z.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303121437-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Munim2023406,
	author = {Munim, Z.H. and Schramm, H.J. and Krabbel, H. and Nyairo, F. and Haavardtun, P. and Kim, T.-E. and Bustgaard, M.},
	title = {User Requirements for Learning Analytics Dashboard in Maritime Simulator Training},
	year = {2023},
	journal = {2023 IEEE International Conference on Industrial Engineering and Engineering Management, IEEM 2023},
	pages = {406 – 410},
	doi = {10.1109/IEEM58616.2023.10406321},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186089305&doi=10.1109%2fIEEM58616.2023.10406321&partnerID=40&md5=919b6cb62f14f0b831febe30ec40131a},
	affiliations = {University of South-Eastern Norway, Faculty of Technology, Natural and Maritime Sciences, Horten, Norway; Wu University of Economics and Business, Department of Global Business and Trade, Vienna, Austria; Copenhagen Business School, Department Operations Management, Copenhagen, Denmark; Novia University of Applied Sciences, Turku, Finland; University of Troms⊘(UiT), Department of Technology and Safety, Tromso, Norway},
	abstract = {This study investigates user requirements for the design of a Learning Analytics Dashboard (LAD) tailored for assessment in maritime simulator training. User requirements for LAD components and visualization elements were examined. Further, perceptions towards the integration of LAD in performance assessment was explored using Likert-scale questions. Data was collected from three Nordic maritime institutions. Situational awareness emerged as the most important component of a maritime LAD, with heat maps preferred for visualization. Both teachers and students have positive perceptions towards the utilization of LAD. Disparities in user requirement and perception towards LAD use across universities, study levels, and simulator modality experience were explored. These insights are pivotal for the advancement and tailoring of LADs in maritime simulator training contexts. © 2023 IEEE.},
	author_keywords = {Learning Analytics; Learning Dashboard; Maritime Education; Simulator Training; User Perception},
	keywords = {Learning analytic; Learning dashboard; Likert scale; Maritime education; Maritime simulators; Performance assessment; Simulator training; Situational awareness; User perceptions; User requirements; Visualization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032315-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Ind. Eng. Eng. Manag., IEEM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Heredia Jimenez202375,
	author = {Heredia Jimenez, Vanessa and Valeriano, Irving and Torres, Danny and Jimenez-Macías, Alberto and Ortiz-Rojas, Margarita},
	title = {Beyond Numbers: Exploring the Qualitative Dimension of a Learning Analytics Dashboard’s Usefulness},
	year = {2023},
	journal = {Lecture Notes in Educational Technology},
	volume = {Part F2610},
	pages = {75 – 85},
	doi = {10.1007/978-981-99-7353-8_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194400316&doi=10.1007%2f978-981-99-7353-8_7&partnerID=40&md5=602fad340370ec379d79623a2dffd89a},
	affiliations = {Escuela Superior Politécnica del Litoral, ESPOL, Centro de Tecnologías de Información, Campus Gustavo Galindo Km. 30.5 Vía Perimetral, Guayaquil, Ecuador; Universidad Carlos III de Madrid, Avda de la Universidad, 30, Leganes, 28911, Spain},
	abstract = {Learning Analytics dashboards provide reflection and decision-making opportunities for teachers and students. When it comes to evaluating dashboards, most studies use a mix of quantitative methods to understand behavior and qualitative methods such as interviews and focus groups to understand needs and insights. One limitation of the latter is that they usually imply a small sample size due to the large amount of work it demands in transcribing, reading, coding, and analyzing the information. This study challenges this limitation by presenting an in-depth exploration of the qualitative aspect involved in evaluating the perceived usefulness of an academic counseling system. Although a mixed methods approach was adopted, this study, that involved 113 teachers, places particular emphasis on the qualitative component, shedding light on unique insights that enrich the understanding of the user’s experience. The quantitative information gathered through a questionnaire allowed us to find statistical differences before and after the system implementation. The qualitative information in the same questionnaire, provided feedback on the reason why they liked the new changes. The approached used, allowed us to reach more users and analyze in a fastest way, allowing us to have strong reasons too keep the proposed design. These were mainly attributed to visualization and interaction aspects. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023.},
	author_keywords = {dashboards; learning analytics; mixed methods},
	correspondence_address = {M. Ortiz-Rojas; Escuela Superior Politécnica del Litoral, ESPOL, Centro de Tecnologías de Información, Guayaquil, Campus Gustavo Galindo Km. 30.5 Vía Perimetral, Ecuador; email: margarita.ortiz@cti.espol.edu.ec},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Heredia-Jimenez2023,
	author = {Heredia-Jimenez, Vanessa and Yaguana, Jhony and Jiménez-Macías, Alberto and Ortiz-Rojas, Margarita},
	title = {Using Design-Based Research for an Academic Dropout and Retention Dashboard},
	year = {2023},
	journal = {2023 9th International Conference on eDemocracy and eGovernment, ICEDEG 2023},
	doi = {10.1109/ICEDEG58167.2023.10122065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160796969&doi=10.1109%2fICEDEG58167.2023.10122065&partnerID=40&md5=fb99225dc1d048fecf4430c2642a8f82},
	affiliations = {Information Technology Center Escuela Superior Politécnica Del Litoral, Guayaquil, Ecuador; Universidad Carlos III de Madrid, Department of Telematic, Leganés, Spain; Studies Ghent University, Department of Educational, Ghent, Belgium},
	abstract = {Student dropout and retention are a major concern in Higher Education Institutions(HEIs). HEIs use the benefits of Learning Analytics (LA) dashboards to address this concern by monitoring student's academic progress and identify students at risk. This study adds to the existing body of knowledge, the experience of designing, implementing, and evaluating a dropout and retention dashboard embedded in an academic counseling system. Through the use of a Design-Based Research methodology, we show the process of going from the needs analysis level, through 3 iterations to test and evaluate the dashboard, to end with preliminary design principles. The lessons learned serve as a guide for LA designers in the implementation of such dashboards.  © 2023 IEEE.},
	author_keywords = {Academic advising; Analytical dashboard; Data visualization; Design-Based Research; Learning dashboards; Student retention},
	keywords = {Design; Students; Academic advising; Analytical dashboard; Body of knowledge; Design-based research; Higher education institutions; Learning dashboard; Need analysis; Preliminary design; Research methodologies; Student retention; Data visualization},
	editor = {Vaca C. and Riofrio D. and Pincay J. and Teran L. and Teran L.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032450-1},
	language = {English},
	abbrev_source_title = {Int. Conf. eDemocracy eGovernment, ICEDEG},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Becerra20231564,
	author = {Becerra, Alvaro and Daza, Roberto and Cobos, Ruth and Morales, Aythami and Cukurova, Mutlu and Fierrez, Julian},
	title = {M2LADS: A System for Generating MultiModal Learning Analytics Dashboards},
	year = {2023},
	journal = {Proceedings - International Computer Software and Applications Conference},
	volume = {2023-June},
	pages = {1564 – 1569},
	doi = {10.1109/COMPSAC57700.2023.00241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168901925&doi=10.1109%2fCOMPSAC57700.2023.00241&partnerID=40&md5=850afe1c52291268a49f97d4ca1bf346},
	affiliations = {Universidad Autonoma de Madrid, School of Engineering, Spain; University College London, London, United Kingdom},
	abstract = {In this article, we present a Web-based System called M2LADS, which supports the integration and visualization of multimodal data recorded in learning sessions in a MOOC in the form of Web-based Dashboards. Based on the edBB platform, the multimodal data gathered contains biometric and behavioral signals including electroencephalogram data to measure learners' cognitive attention, heart rate for affective measures, visual attention from the video recordings. Additionally, learners' static background data and their learning performance measures are tracked using LOGCE and MOOC tracking logs respectively, and both are included in the Web-based System. M2LADS provides opportunities to capture learners' holistic experience during their interactions with the MOOC, which can in turn be used to improve their learning outcomes through feedback visualizations and interventions, as well as to enhance learning analytics models and improve the open content of the MOOC. © 2023 IEEE.},
	author_keywords = {Biometrics and Behavior; Computer Science & Information Technology; e-Learning; MOOC; Multimodal Learning Analytics; Open Education; Web-based Technology},
	keywords = {Behavioral research; Data visualization; E-learning; Engineering education; Learning systems; Video recording; Visualization; Websites; Biometric and behavior; Computer science & information technology; E - learning; MOOC; Multi-modal data; Multi-modal learning; Multimodal learning analytic; Open educations; Web-based system; Web-based technologies; Biometrics},
	correspondence_address = {A. Becerra; Universidad Autonoma de Madrid, School of Engineering, Spain; email: alvaro.becerra@uam.es; R. Daza; Universidad Autonoma de Madrid, School of Engineering, Spain; email: roberto.daza@uam.es; R. Cobos; Universidad Autonoma de Madrid, School of Engineering, Spain; email: ruth.cobos@uam.es; A. Morales; Universidad Autonoma de Madrid, School of Engineering, Spain; email: aythami.morales@uam.es; J. Fierrez; Universidad Autonoma de Madrid, School of Engineering, Spain; email: m.cukurova@ucl.ac.uk},
	editor = {Shahriar H. and Teranishi Y. and Cuzzocrea A. and Sharmin M. and Towey D. and Majumder AKM.J.A. and Kashiwazaki H. and Yang J.-J. and Takemoto M. and Sakib N. and Banno R. and Ahamed S.I.},
	publisher = {IEEE Computer Society},
	issn = {07303157},
	isbn = {979-835032697-0},
	coden = {PSICD},
	language = {English},
	abbrev_source_title = {Proc Int Comput Software Appl Conf},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Miteva202299,
	author = {Miteva, Dafinka and Stefanova, Eliza},
	title = {eAnalytics: A MODEL OF A LEARNING ANALYTICS VISUALIZATION SYSTEM},
	year = {2022},
	journal = {Annual of Sofia University "St. Kliment Ohridski" Faculty of Mathematics and Informatics},
	volume = {109},
	pages = {99 – 119},
	doi = {10.60063/gsu.fmi.109.99-119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206103962&doi=10.60063%2fgsu.fmi.109.99-119&partnerID=40&md5=8678a38748441f1b26add7b3339c9dbf},
	affiliations = {Faculty of Mathematics and Informatics, Sofia University, “St. Kliment Ohridski” 5 James Bourchier Blvd, Sofia, 1164, Bulgaria},
	abstract = {Collecting big data from e-learning is already a fact. Huge opportunities open up for learning analytics to deeply understand and effectively optimize the process of teaching and learning. At the same time, large amounts of data require more time, efforts and resources to extract useful information from them. This paper presents a research proposing a model of a learning analytics system aiming through advances in big data visualization methods to facilitate data interpretation and assist timely and accurate decision making. The study describes an architectural model called eAnalytics. It consists of three main components: Data sources connection, Data management and Learning analytics visualization. The last component provides a choice of three methods for visualizing analytics: via a ready-to-use virtual dashboard, via a virtual dashboard template, or by composing personalized analytics. The paper depicts the prototyping of the model and its validation by conducting two types of testing: for functional compliance and by applying “Think aloud” protocol. Finally, important conclusions are drawn and some directions for future work are outlined. © 2022, Sofia University St Kliment Ohridski Faculty of Mathematics and Informatics. All rights reserved.},
	author_keywords = {Big Data; education; Learning Analytics; visualization},
	publisher = {Sofia University St Kliment Ohridski Faculty of Mathematics and Informatics},
	issn = {13139215},
	language = {English},
	abbrev_source_title = {Ann. Sofi. Univ. Sv. Kliment Ohridski, Fac. Math. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Pozdniakov202389,
	author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Echeverria, Vanessa and Srivastava, Namrata and Gasevic, Dragan},
	title = {How Do Teachers Use Dashboards Enhanced with Data Storytelling Elements According to their Data Visualisation Literacy Skills?},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {89 – 99},
	doi = {10.1145/3576050.3576063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149344242&doi=10.1145%2f3576050.3576063&partnerID=40&md5=79f5cfd2aeec5b5f943bba5524e62de3},
	affiliations = {Monash University, Australia; Escuela Superior Politecnica del Litoral Ecuador},
	abstract = {There is a proliferation of learning analytics (LA) dashboards aimed at supporting teachers. Yet, teachers still find it challenging to make sense of LA dashboards, thereby making informed decisions. Two main strategies to address this are emerging: i) upskilling teachers' data literacy; ii) improving the explanatory design features of current dashboards (e.g., adding visual cues or text) to minimise the skills required by teachers to effectively use dashboards. While each approach has its own trade-offs, no previous work has explored the interplay between the dashboard design and such "data skills". In this paper, we explore how teachers with varying visualisation literacy (VL) skills use LA dashboards enhanced with (explanatory) data storytelling elements. We conducted a quasi-experimental study with 23 teachers of varied VL inspecting two versions of an authentic multichannel dashboard enhanced with data storytelling elements. We used an eye-tracking device while teachers inspected the students' data captured from Zoom and Google Docs, followed by interviews. Results suggest that high VL teachers adopted complex exploratory strategies and were more sensitive to subtle inconsistencies in the design; while low VL teachers benefited the most from more explicit data storytelling guidance such as accompanying complex graphs with narrative and semantic colour encoding.  © 2023 ACM.},
	author_keywords = {dashboard; data literacy; data storytelling; human-centred design; learning analytics},
	keywords = {Data visualization; Economic and social effects; Eye tracking; Visualization; 'current; Dashboard; Data literacy; Data storytelling; Design features; Human-centred designs; Informed decision; Learning analytic; Teachers'; Visual cues; Semantics},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@CONFERENCE{Tsoni2023,
	author = {Tsoni, Rozita and Garani, Georgia and Verykios, Vassilios S.},
	title = {Incorporating Data Warehouses into Data Pipelines for Deploying Learning Analytics Dashboards},
	year = {2023},
	journal = {14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023},
	doi = {10.1109/IISA59645.2023.10345957},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182030772&doi=10.1109%2fIISA59645.2023.10345957&partnerID=40&md5=71a4327f97d4b60bfb4154915b4f0f6c},
	affiliations = {School of Science and Technology, Hellenic Open University, Greece; School of Technology, University of Thessaly, Greece},
	abstract = {From the data loading to the final reporting, a Learning Analytics (LA) cycle should be an articulated yet structured and repeatable process. Data from the online students' activity can be arranged and organized in Data Warehouses (DWs) to facilitate pre-processing tasks. These data can feed an LA cycle for producing the final reporting. In this work, we propose an integrated process of educational data management for creating insightful knowledge. Firstly, an education-oriented DW schema is presented. Additionally, a data pipeline that loads data from the DW and supports all the LA processes is described. The results are presented to the front-end user through an LA dashboard that focuses on students' social interaction in their learning community. The process is tested in educational data from a Distance Learning postgraduate program. © 2023 IEEE.},
	author_keywords = {Dashboards; Data Pipelines; Data warehouses; Learning Analytics; Social Network Analysis},
	keywords = {Data handling; Distance education; Information management; Pipelines; Social networking (online); Software testing; Students; Dashboard; Data pipelines; End-users; Front end; Learning analytic; Learning community; Load data; Pre-processing; Social interactions; Social Network Analysis; Data warehouses},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031806-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Inf., Intell., Syst. Appl., IISA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Núñez2023217,
	author = {Núñez, Ana-Gabriela and Echeverria, Vanessa and Zuñiga-Prieto, Miguel and Auria, Benito and De Laet, Tinne},
	title = {TMBQ-LT: A Student-Facing Learning Tool to Support Time Management Skills},
	year = {2023},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {1},
	pages = {217 – 224},
	doi = {10.5220/0011847500003470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160814314&doi=10.5220%2f0011847500003470&partnerID=40&md5=daa35a4c4731565d27e7f3517503b8dc},
	affiliations = {Department of Computer Science, Universidad de Cuenca, Cuenca, Ecuador; Escuela Superior Politécnica del Litoral, ESPOL, Centro de Tecnologías de Información, Guayaquil, Ecuador; Monash University, Clayton, VIC, Australia; Faculty of Engineering Science, Engineering and Science Education Center, KU Leuven, Leuven, Belgium},
	abstract = {To be successful in Higher Education, students must acquire good self-regulation and learning skills. Past studies have reported that undergraduate students are overconfident in recognizing their self-regulatory strategies. This overconfidence can be detrimental during the first years of their undergraduate program if they are not properly nurtured. The lack of students’ motivation, self-regulation and time management strategies can lead to higher rates of drop-out. In this sense, student-facing learning tools can provide timely feedback to support awareness, strengthen this self-regulation and time management skills, and thus be instrumental for students in attaining their learning goals. In this paper, we present the TMBQ-LT, a student-facing tool that consists of 1) a set of questions derived from the Time Management Behavior Questionnaire (TMBQ), 2) a visualization showing student’s time management (TM) predispositions and 3) tailored recommendations based on students’ self-reported TM skills. This paper illustrates a case study on the deployment of the TMBQ - LT by students from three HE institutions and provides recommendations for future implementations and adoption of the tool. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Learning Analytics Dashboard; Student-Facing Dashboard; Time Management},
	keywords = {Deregulation; Facings; Higher education students; Learning analytic dashboard; Learning tool; Management behavior; Management skills; Self regulation; Self-learning; Student-facing dashboard; Support time; Time management; Students},
	editor = {Jovanovic J. and Chounta I.-A. and Uhomoibhi J. and McLaren B.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758641-5},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Susnjak2022,
	author = {Susnjak, Teo and Ramaswami, Gomathy Suganya and Mathrani, Anuradha},
	title = {Learning analytics dashboard: a tool for providing actionable insights to learners},
	year = {2022},
	journal = {International Journal of Educational Technology in Higher Education},
	volume = {19},
	number = {1},
	doi = {10.1186/s41239-021-00313-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124942435&doi=10.1186%2fs41239-021-00313-7&partnerID=40&md5=698ace34ba189d3f89a5bb626e3c6b47},
	affiliations = {School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand},
	abstract = {This study investigates current approaches to learning analytics (LA) dashboarding while highlighting challenges faced by education providers in their operationalization. We analyze recent dashboards for their ability to provide actionable insights which promote informed responses by learners in making adjustments to their learning habits. Our study finds that most LA dashboards merely employ surface-level descriptive analytics, while only few go beyond and use predictive analytics. In response to the identified gaps in recently published dashboards, we propose a state-of-the-art dashboard that not only leverages descriptive analytics components, but also integrates machine learning in a way that enables both predictive and prescriptive analytics. We demonstrate how emerging analytics tools can be used in order to enable learners to adequately interpret the predictive model behavior, and more specifically to understand how a predictive model arrives at a given prediction. We highlight how these capabilities build trust and satisfy emerging regulatory requirements surrounding predictive analytics. Additionally, we show how data-driven prescriptive analytics can be deployed within dashboards in order to provide concrete advice to the learners, and thereby increase the likelihood of triggering behavioral changes. Our proposed dashboard is the first of its kind in terms of breadth of analytics that it integrates, and is currently deployed for trials at a higher education institution. © 2022, The Author(s).},
	author_keywords = {Actionable insights; Counterfactuals; Dashboard; Explainable AI; Learner analytics; Model interpretability},
	correspondence_address = {T. Susnjak; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; email: t.susnjak@massey.ac.nz},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23659440},
	language = {English},
	abbrev_source_title = {Int. j. educ. technol. high. educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 97; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Poellhuber2023592,
	author = {Poellhuber, Louis-Vincent and Poellhuber, Bruno and Desmarais, Michel and Leger, Christian and Manh-Chien Vu, Mathieu},
	title = {Cluster-Based Performance of Student Dropout Prediction as a Solution for Large Scale Models in a Moodle LMS},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {592 – 598},
	doi = {10.1145/3576050.3576146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149295940&doi=10.1145%2f3576050.3576146&partnerID=40&md5=932b2234f14eb6f271e1b65c6096a132},
	affiliations = {Universite de Montreal, Canada; Polytechnique Montreal, Canada; Cegep A Distance, Canada},
	abstract = {Learning management systems provide a wide breadth of data waiting to be analyzed and utilized to enhance student and faculty experience in higher education. As universities struggle to support students' engagement, success and retention, learning analytics is being used to build predictive models and develop dashboards to support learners and help them stay engaged, to help teachers identify students needing support, and to predict and prevent dropout. Learning with Big Data has its challenges, however: managing great quantities of data requires time and expertise. To predict students at risk, many institutions use machine learning algorithms with LMS data for a given course or type of course, but only a few are trying to make predictions for a large subset of courses. This begs the question: "How can student dropout be predicted on a very large set of courses in an institution Moodle LMS?"In this paper, we use automation to improve student dropout prediction for a very large subset of courses, by clustering them based on course design and similarity, then by automatically training, testing, and selecting machine learning algorithms for each cluster. We developed a promising methodology that outlines a basic framework that can be adjusted and optimized in many ways and that further studies can easily build on and improve.  © 2023 ACM.},
	author_keywords = {dropout prediction; engagement; learning analytics; Moodle LMS},
	keywords = {Clustering algorithms; Curricula; Education computing; Information management; Learning algorithms; Learning systems; Machine learning; Predictive analytics; Teaching; Cluster-based; Dropout prediction; Engagement; High educations; Large-scale modeling; Learning analytic; Learning management system; Machine learning algorithms; Moodle LMS; Performance; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Tretow-Fish2023531,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin and Leweke, Victor Anton Charles},
	title = {Prototyping the Learning Analytics Dashboards of an Adaptive Learning Platform: Faculty Perceptions Versus Designers’ Intentions},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14040 LNCS},
	pages = {531 – 545},
	doi = {10.1007/978-3-031-34411-4_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169048493&doi=10.1007%2f978-3-031-34411-4_36&partnerID=40&md5=7b108639fe62098d72e73ea79f2045ac},
	affiliations = {Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark},
	abstract = {This study contributes with a case study on redesigning three Learning Analytics Dashboards (LADs) of the adaptive learning platform Rhapsode™ with instructions for pedagogical actions. Applying self determination theory’s elements of competence and relatedness and mental models in a design thinking process, the differences among the teachers perceptions and the designers intentions are highlighted through several methods to answer the questions of: How might we improve the learning analytics dashboards by prioritizing course instructors’ perceived competence and relatedness? and How might we redesign learning analytics dashboards by including course instructors’ purpose, insights, and recommending actions? These questions are answered first by developing three Role-based Personas of Alina Action, Niels Novice, and Paul Privacy along with scenarios and user stories. Second, prototypes of interfaces are designed and tested in three iterations showing insights, recommended actions, and explanation of mechanics. Feedback from the tests on the prototypes receives positive feedback from all teacher personas. The teacher persona of Niels Novice also supplies a criticism of the insights and recommended actions on the basis of creating undesired interpretation, potential bias, taking away freedom of interpretation, and authoritative system that “instructs/orders” action. Additionally, the scope of the study cannot meet the persona of Paul Privacy’s reservations on students’ possible experience of surveillance. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Actionable Learning Analytics Dashboard; Adaptive Learning Platform; Design Thinking; Mental model; Motivation theory},
	keywords = {Cognitive systems; Curricula; Design; E-learning; Teaching; Actionable learning analytic dashboard; Adaptive learning; Adaptive learning platform; Case-studies; Design thinking; Faculty perceptions; Learning platform; Mental model; Motivation theories; Teachers'; Learning systems},
	correspondence_address = {T.A.B. Tretow-Fish; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark; email: compute@compute.dtu.dk},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303134410-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zamecnik2022,
	author = {Zamecnik, Andrew and Kovanović, Vitomir and Grossmann, Georg and Joksimović, Srećko and Jolliffe, Gabrielle and Gibson, David and Pardo, Abelardo},
	title = {Team interactions with learning analytics dashboards},
	year = {2022},
	journal = {Computers and Education},
	volume = {185},
	doi = {10.1016/j.compedu.2022.104514},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128914722&doi=10.1016%2fj.compedu.2022.104514&partnerID=40&md5=8508503051ac41c0ad3e16291ca5fcde},
	affiliations = {University of South Australia, Adelaide, 5000, SA, Australia; Curtin University, Perth, WA, 6000, Australia},
	abstract = {Student-facing visualisations have attracted increased attention with recent developments in data-driven tools to support individual and group work. Learning analytics dashboards (LADs), a data-enhanced feedback tool that allows students to make sense of their learning by providing insights into their learning behaviours represents one of the prominent examples of this trend. While these visualisation tools are increasingly used to study and enhance students' learning in academic contexts, current research is limited regarding the effects of the LADs in K-12 environments. There is a missed opportunity to empower teams and allow instructors and researchers to understand how teams use the LAD to regulate their learning. In this study, we developed a K-12 LAD for supporting students' collaborative work and evaluated with respect to students' perceived usefulness of the proposed LAD and the association between its use and course performance. The study followed a mixed-methods approach, combining quantitative analysis of log data from the dashboard and qualitative analysis of students’ perceptions using surveys and focus groups. Our results show that different roles within teams have distinguished engagement patterns with the LAD and that the tool improves the collaborative learning experience. We postulate that the implications of this study will aid future research work when investigating the behaviours of teams and optimising their learning using LADs. © 2022 Elsevier Ltd},
	author_keywords = {Blended learning; Collaboration; Dashboard; K-12; Learning analytics},
	keywords = {Visualization; Blended learning; Collaboration; Dashboard; Data driven; Feedback tool; Group work; K-12; Learning analytic; Learning behavior; Team interaction; Students},
	correspondence_address = {A. Zamecnik; University of South Australia, Adelaide, 5000, Australia; email: Andrew.Zamecnik@mymail.unisa.edu.au},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Conde2023444,
	author = {Conde, Miguel Á. and Georgiev, Atanas and López-Pernas, Sonsoles and Jovic, Jovana and Crespo-Martínez, Ignacio and Raspopovic Milic, Miroslava and Saqr, Mohammed and Pancheva, Katina},
	title = {Definition of a Learning Analytics Ecosystem for the ILEDA Project Piloting},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14040 LNCS},
	pages = {444 – 453},
	doi = {10.1007/978-3-031-34411-4_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169029771&doi=10.1007%2f978-3-031-34411-4_30&partnerID=40&md5=a2f826487fd06f3615be8fc045f7fd39},
	affiliations = {Robotics Research Group, Engineering School, University of León, León, 24071, Spain; Faculty of Mathematics and Informatics, Sofia University, Sofia, Bulgaria; School of Computing, University of Eastern Finland, Joensuu Campus, Joensuu, Finland; Faculty of Information Technology, Belgrade Metropolitan University, Tadeuša Košćuška 63, Belgrade, 11000, Serbia},
	abstract = {Understanding how students progress in their learning is an important step towards achieving the success of the educational process. One way of understanding student progress is by using learning analytics methods on different student data. The ILEDA project aims to improve online and blended learning by using educational data analytics. For this purpose, the project involves four universities from four different countries and develops several activities. One of these activities. That aims to facilitate the analysis of student progress, is the definition of a Learning Analytics Ecosystem. The aim of defining the ecosystem is to generate solutions that will benefit all institutions and that will allow to look for possible patterns and common issues needing addressing. This paper describes the development of such an ecosystem and its future implementations. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboards; Ecosystems; Evidences; Interoperability; Learning Analytics},
	keywords = {Data Analytics; Students; Analytic method; Blended learning; Dashboard; Data analytics; Educational process; Evidence; Learning analytic; Online learning; Student progress; Ecosystems},
	correspondence_address = {M.Á. Conde; Robotics Research Group, Engineering School, University of León, León, 24071, Spain; email: mcong@unileon.es},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303134410-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Seeling2023,
	author = {Seeling, Patrick and McGarry, Michael P. and Johnson, Matthew},
	title = {Reveal Online Learning Clickstream Data to Provide Actionable Intelligence},
	year = {2023},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	doi = {10.1109/FIE58773.2023.10343069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183055650&doi=10.1109%2fFIE58773.2023.10343069&partnerID=40&md5=ef2ab4cc1abfbe60dc86e039e1143a85},
	affiliations = {Central Michigan University, Dept. of Computer Science, Mount Pleasant, MI, United States; University of Texas at El Paso, Dept. of Electrical and Computer Eng., El Paso, TX, United States; Central Michigan University, Dept. of Couns., Ed. Leadersh., & Higher Ed., Mount Pleasant, MI, United States},
	abstract = {This paper describes our universally applicable approach to the gathering of learning process data to support learning analytics with the ultimate goal of generating actionable intelligence for learners and instructors. This support is needed as increasingly, course content is provided in an online environment (independent of a class delivery modality, e.g., face-to-face, hybrid, hyflex, or online) where learners are operating independently and in absence of timely feedback loops. Providing learners with automatically generated feedback can stimulate their self-regulation toward success. Specifically, we describe an approach that generates learning process analytics dashboard data that are driven by clickstream data. Our approach enables the gathering of learning process data outside the Learning Management System (LMS) confines to support the generation of models that can produce actionable intelligence and enable deeper exploration options for the instructor. Our approach thus enables continuous education improvement and its operationalization (EdOps). © 2023 IEEE.},
	author_keywords = {Adaptive Learning; Learning Analytics; Learning Management Systems},
	keywords = {E-learning; Feedback; Information management; Learning systems; Adaptive learning; Clickstream data; Course contents; Learning analytic; Learning management system; Learning process; Online environments; Online learning; Process data; Support learning; Curricula},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {979-835033642-9},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Fu20232393,
	author = {Fu, Qian and Bai, Xue and Zheng, Yafeng and Du, Runsheng and Wang, Dongqing and Zhang, Tianyi},
	title = {VisOJ: real-time visual learning analytics dashboard for online programming judge},
	year = {2023},
	journal = {Visual Computer},
	volume = {39},
	number = {6},
	pages = {2393 – 2405},
	doi = {10.1007/s00371-022-02586-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135739359&doi=10.1007%2fs00371-022-02586-z&partnerID=40&md5=2b1d1966ff75e0ff711732a6565d83c0},
	affiliations = {School of Educational Technology, Faculty of Education, Beijing Normal University, Beijing, China; School of Mathematics and Information Science, Henan University of Economics and Law, Zhengzhou, China; Institute of Advanced Studies in Humanities and Social Sciences, Beijing Normal University at Zhuhai, Zhuhai, China; School of Computer and Information Engineering, Henan University of Economics and Law, Zhengzhou, China; School of Engineering and Applied Science, University of Pennsylvania, Philadelphia, PA, United States},
	abstract = {Online Judge (OJ) is an important aid for programming learning that can help students evaluate learning effects in real-time, while teachers can adjust practice tasks in time according to the records of the tool. With these advantages, OJ shows great value for promoting teaching and learning in programming. The existing OJ system usually only provides information such as problem status list and recent rank list. However, it is unable to provide teachers with more fine-grained analysis information, such as the distribution of students’ incorrect responses and level of knowledge mastery. And it also cannot provide students with effective comparative information on their learning status. This research developed a visual learning analytics dashboard named VisOJ for the OJ system, which includes two types of user interfaces: teacher and student. The teacher interface presents students' learning status and ranking trends, which help teachers monitor and give feedback on their learning activities. The student interface provides views such as error type analysis and evaluation, which promote students' self-reflection and self-regulation. Preliminary case studies and expert interviews prove the usability of the dashboard. In the end, we summarize our main work and suggest future research directions. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Learning analytics dashboard; Online judge; Programming study; Visual analytics},
	keywords = {E-learning; Learning systems; User interfaces; Learning analytic dashboard; Learning effects; On-line programming; Online judges; Programming learning; Programming study; Real- time; Teachers'; Visual analytics; Visual learning; Students},
	correspondence_address = {Y. Zheng; Institute of Advanced Studies in Humanities and Social Sciences, Beijing Normal University at Zhuhai, Zhuhai, China; email: zlzyf@126.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {01782789},
	coden = {VICOE},
	language = {English},
	abbrev_source_title = {Visual Comput},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Mohseni202312,
	author = {Mohseni, Zeynab and Masiello, Italo and Martins, Rafael M.},
	title = {Towards a Teacher-Oriented Framework of Visual Learning Analytics by Scenario-Based Development},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3539},
	pages = {12 – 17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178303190&partnerID=40&md5=290c942f1456950f6a234068deb5d874},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden},
	abstract = {Visual Learning Analytics (VLA) tools (such as dashboards) serve as a centralized hub for monitoring and analyzing educational data. Dashboards can assist teachers in data-informed pedagogical decision-making and/or students in following their own learning progress. However, the design of VLA tools should include features of trust in order to make analytics overt among its users. In this study, we propose a framework for the development of VLA tools from beginning to end that describes how we intend to develop the digital and technical infrastructure in our project for teachers. With that aim, we offer one scenario describing how data is managed, transferred, analyzed, and visualized by teachers. The suggested framework intends to make it easier for developers to understand the various steps involved in co-designing and developing a reliable VLA tool and to comprehend the importance of the teacher's participation in design. VLA tools developed based on the proposed framework have the potential to assist teachers in understanding and analyzing educational data, monitoring students' learning paths based on their learning outcomes and activities, simplifying regular tasks, and giving teachers more time to support teaching/learning and growth. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Educational Data; Scenario-based Development; Visual Learning Analytics Tool; VLA Development Framework},
	keywords = {Students; Analytic tools; Centralised; Development frameworks; Educational data; Scenario based development; Teachers'; Visual learning; Visual learning analytic development framework; Visual learning analytic tool; Decision making},
	correspondence_address = {Z. Mohseni; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; email: zeynab.mohseni@lnu.se},
	editor = {Di Mitri D. and DIPF, Leibniz Institute for Research and Information in Education, Rostocker Str. 6, Frankfur and Ortega-Arranz A. and Universidad de Valladolid, School of Computer Engineering, Paseo de Belen 15, Valladolid and Poquet O. and Technical University of Munich, TUM School of Social Sciences and Technology, Arcisstrasse 2180333, Munich},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Divjak202344,
	author = {Divjak, Blazenka and Svetec, Barbi and Horvat, Damir},
	title = {Learning analytics dashboards: What do students actually ask for?},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {44 – 56},
	doi = {10.1145/3576050.3576141},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149273260&doi=10.1145%2f3576050.3576141&partnerID=40&md5=ae1e34c870ef1746967b96b32711075b},
	affiliations = {University of Zagreb, Faculty of Organization and Informatics, Croatia},
	abstract = {Learning analytics (LA) has been opening new opportunities to support learning in higher education (HE). LA dashboards are an important tool in providing students with insights into their learning progress, and predictions, leading to reflection and adaptation of learning plans and habits. Based on a human-centered approach, we present a perspective of students, as essential stakeholders, on LA dashboards. We describe a longitudinal study, based on survey methodology. The study included two iterations of a survey, conducted with second-year ICT students in 2017 (N = 222) and 2022 (N = 196). The study provided insights into the LA dashboard features the students find the most useful to support their learning. The students highly appreciated features related to short-term planning and organization of learning, while they were cautious about comparison and competition with other students, finding such features possibly demotivating. We compared the 2017 and 2022 results to establish possible changes in the students' perspectives with the COVID-19 pandemic. The students' awareness of the benefits of LA has increased, which may be related to the strong focus on online learning during the pandemic. Finally, a factor analysis yielded a dashboard model with five underlying factors: comparison, planning, predictions, extracurricular, and teachers.  © 2023 ACM.},
	author_keywords = {dashboard; higher education; human-centered; learning analytics; students' perspectives},
	keywords = {Education computing; Dashboard; High educations; Human-centered; Learning analytic; Learning progress; Longitudinal study; Short term planning; Student perspectives; Support learning; Survey methodology; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Gauthier2022,
	author = {Gauthier, Andrea and Rizvi, Saman and Cukurova, Mutlu and Mavrikis, Manolis},
	title = {Is it time we get real? A systematic review of the potential of data-driven technologies to address teachers' implicit biases},
	year = {2022},
	journal = {Frontiers in Artificial Intelligence},
	volume = {5},
	doi = {10.3389/frai.2022.994967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140411402&doi=10.3389%2ffrai.2022.994967&partnerID=40&md5=1bdc8efa1793bac3416959863e54bb3a},
	affiliations = {UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom},
	abstract = {Data-driven technologies for education, such as artificial intelligence in education (AIEd) systems, learning analytics dashboards, open learner models, and other applications, are often created with an aspiration to help teachers make better, evidence-informed decisions in the classroom. Addressing gender, racial, and other biases inherent to data and algorithms in such applications is seen as a way to increase the responsibility of these systems and has been the focus of much of the research in the field, including systematic reviews. However, implicit biases can also be held by teachers. To the best of our knowledge, this systematic literature review is the first of its kind to investigate what kinds of teacher biases have been impacted by data-driven technologies, how or if these technologies were designed to challenge these biases, and which strategies were most effective at promoting equitable teaching behaviors and decision making. Following PRISMA guidelines, a search of five databases returned n = 359 records of which only n = 2 studies by a single research team were identified as relevant. The findings show that there is minimal evidence that data-driven technologies have been evaluated in their capacity for supporting teachers to make less biased decisions or promote equitable teaching behaviors, even though this capacity is often used as one of the core arguments for the use of data-driven technologies in education. By examining these two studies in conjunction with related studies that did not meet the eligibility criteria during the full-text review, we reveal the approaches that could play an effective role in mitigating teachers' biases, as well as ones that may perpetuate biases. We conclude by summarizing directions for future research that should seek to directly confront teachers' biases through explicit design strategies within teacher tools, to ensure that the impact of biases of both technology (including data, algorithms, models etc.) and teachers are minimized. We propose an extended framework to support future research and design in this area, through motivational, cognitive, and technological debiasing strategies. Copyright © 2022 Gauthier, Rizvi, Cukurova and Mavrikis.},
	author_keywords = {artificial intelligence in education; bias; decision support systems; equity; learning analytics (LA); teachers},
	correspondence_address = {A. Gauthier; UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom; email: andrea.gauthier@ucl.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Chavan2022125,
	author = {Chavan, Pankaj and Mitra, Ritayan},
	title = {Tcherly: A Teacher-Facing Dashboard for Online Video Lectures},
	year = {2022},
	journal = {Journal of Learning Analytics},
	volume = {9},
	number = {3},
	pages = {125 – 151},
	doi = {10.18608/jla.2022.7555},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145057139&doi=10.18608%2fjla.2022.7555&partnerID=40&md5=9f3699f4fc80a49197b0a5eb9a846241},
	affiliations = {IDP in Educational Technology, IIT Bombay, Mumbai, 400076, India},
	abstract = {The use of online video lectures in universities, primarily for content delivery and learning, is on the rise. Instructors’ ability to recognize and understand student learning experiences with online video lectures, identify particularly difficult or disengaging content and thereby assess overall lecture quality can inform their instructional practice related to such lectures. This paper introduces Tcherly, a teacher-facing dashboard that presents class-level aggregated time series data on students’ self-reported cognitive-affective states they experienced during a lecture. Instructors can use the dashboard to evaluate and improve their instructional practice related to video lectures. We report the detailed iterative prototyping design process of the Tcherly Dashboard involving two stakeholders (instructors and designers) that informed various design decisions of the dashboard, and also provide usability and usefulness data. We demonstrate, with real-life examples of Tcherly Dashboard use generated by the researchers based on data collected from six courses and 11 lectures, how the dashboard can assist instructors in understanding their students’ learning experiences and evaluating the associated instructional materials. © 2022, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {learning analytics; student feedback; teacher dashboard; Video lecture},
	correspondence_address = {P. Chavan; IDP in Educational Technology, IIT Bombay, Mumbai, 400076, India; email: pankajchavan@iitb.ac.in},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Foung2022,
	author = {Foung, Dennis and Kohnke, Lucas},
	title = {Rediscovering the Uptake of Dashboard Feedback: A Conceptual Replication of Foung (2019)},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {23},
	doi = {10.3390/su142316169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143832228&doi=10.3390%2fsu142316169&partnerID=40&md5=a99afb5927d22abb597f2317e945af4d},
	affiliations = {School of Journalism, Writing and Media, The University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Department of English Language Education, The Education University of Hong Kong, Hong Kong},
	abstract = {Learning analytics has been widely used in the context of language education. Among the studies that have used this approach, many have developed a dashboard that aims to provide students with recommendations based on data so that they can act on these suggestions and improve their performance. To further our understanding of dashboard research, this study aims to replicate an earlier study using a new data mining strategy, association rule mining, to explore if the new strategy can (1) generate comparable results; and (2) provide new insights into feedback uptake in dashboard systems. The original study was conducted with 423 students at a Hong Kong university and implemented a dashboard for a suite of first-year composition courses. It used a classification tree to identify factors that could predict the uptake of tool-based and general recommendations made by the dashboard. After performing association rule mining with the original data set, this study found that this approach allowed for the identification of additional useful factors associated with the uptake of general and tool-based recommendations with a higher accuracy rate. The results of this study provide new insights for dashboard research and showcase the potential use of association rule mining in the context of language education. © 2022 by the authors.},
	author_keywords = {association rule mining; dashboards; Hong Kong; learning analytics; market basket analysis; undergraduates},
	keywords = {China; Hong Kong; conceptual framework; language; learning; spatiotemporal analysis; strategic approach; student},
	correspondence_address = {D. Foung; School of Journalism, Writing and Media, The University of British Columbia, Vancouver, V6T 1Z4, Canada; email: dennis.foung@ubc.ca},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Abad-Troya202391,
	author = {Abad-Troya, José and Cadme-Samaniego, Irma E.},
	title = {Enhancing Educational Efficiency: Learning Analytics in the Management of Course Development in Virtual Environments},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3691},
	pages = {91 – 101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194769080&partnerID=40&md5=8922f2b7a09480aa16ebe272d9bc3e63},
	affiliations = {Universidad Técnica Particular de Loja, San Cayetano Alto, Loja, 110107, Ecuador},
	abstract = {Learning analytics provide a set of elements for data analysis in the educational field. This analysis is complemented with semantic web tools that allow obtaining a wider benefit, overcoming the interoperability barrier, and the capacity to generate new knowledge. The present work aims to facilitate the management of courses offered in the various online education platforms through learning analytics. The analytics process includes extracting, transforming, and loading data stored in an RDF data repository. It has also required designing and implementing an ontology representing MOOC courses. Finally, the visualization of the obtained indicators will be available in a dashboard with access for end users. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Learning analytics; MOOCs; ontologies; semantic web},
	keywords = {Curricula; E-learning; Metadata; Resource Description Framework (RDF); Course development; Data repositories; Learning analytic; Loading data; MOOC; On-line education; Ontology's; RDF data; Semantic-Web; Web tools; Ontology},
	correspondence_address = {J. Abad-Troya; Universidad Técnica Particular de Loja, Loja, San Cayetano Alto, 110107, Ecuador; email: jmabad1@utpl.edu.ec},
	editor = {Cardona-Reyes H. and Lara-Alvarez C.A. and Ortiz-Esparza M.A. and Villalba-Condori K.O.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Majumdar2023245,
	author = {Majumdar, Rwitajit and Takami, Kyosuke and Ogata, Hiroaki},
	title = {Learning with Explainable AI-Recommendations at School: Extracting Patterns of Self-Directed Learning from Learning Logs},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Advanced Learning Technologies, ICALT 2023},
	pages = {245 – 249},
	doi = {10.1109/ICALT58122.2023.00078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174580838&doi=10.1109%2fICALT58122.2023.00078&partnerID=40&md5=3cfeeb8675be76c2c0b6930ddc2a835e},
	affiliations = {Kyoto University, Academic Center for Computing and Media Studies, Japan; National Institute for Educational Policy Research (NIER), Japan},
	abstract = {Educational explainable AI (XAI) applications are gaining research focus and have distinct needs in the domain of Education. This research presents Educational eXplainable AI Tool (EXAIT), a system for math quiz recommendations, along with an explanation. EXAIT was implemented in a Japanese public high school where students received the top 5 math problems based on Bayesian Knowledge Tracing (BKT) algorithm in a learning analytics dashboard. It aimed to help them complete their summer vacation assignments having 240 questions. On click, the students were redirected to an eBook platform to submit their accuracy and confidence level in each problem. We conducted a study with a quasi-experimental design and divided into 3 groups based on compliance of use. RecoExp group received and used explanations regarding why an item was recommended and how it aims to maximize learners' knowledge-gaining path. RecoCon was the control group that received just the recommendations and used it and RecoNone group did not use the system at all during the time period. We provide a framework to analyze learning logs from EXAIT and extract emerging self-directed learning patterns. Analyzing 222 students' EXAIT logs, we found learners who had checked explanations while selecting recommendations had significantly higher performance. Further differential process mining highlighted significant active daily engagement transitions of the RecoExp group in the self-directed activity.  © 2023 IEEE.},
	author_keywords = {LA; LEAF; pattern mining; SDL; XAI},
	keywords = {Learning systems; Bayesian knowledge tracings; Higher School; LA; LEAF; Pattern mining; Problem-based; Research focus; SDL; Self-directed learning; XAI; Students},
	editor = {Chang M. and Chen N.-S. and Kuo R. and Rudolph G. and Sampson D.G. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030054-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Kim2022493,
	author = {Kim, Yoon Jeon and Scianna, Jennifer},
	title = {What do Teachers Want to Know About Game-Based Learning Analytics: Cross-Case Study},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {1},
	pages = {493 – 498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151061626&partnerID=40&md5=8bd778c1bb709fe1e8682a984bc81d7b},
	affiliations = {University of Wisconsin-Madison, United States},
	abstract = {Game-based pedagogy requires innovation in learning analytics, so teachers can make sense of the complex data generated in the game in relation to evidence for learning. In this paper, we advocate for co-design as a process to elucidate the types of data that teachers want and need to effectively implement games in the classroom. We examine two cases to discuss affordances of co-design activities and present initial findings that built towards two prototypical dashboards. © 30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings.},
	author_keywords = {co-design; game-based learning analytics; teacher dashboard},
	keywords = {Computer games; Game design; Affordances; Co-designs; Complex data; Cross-case studies; Design activity; Game-Based; Game-based Learning; Game-based learning analytic; Teacher dashboard; Teachers'; Design},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Denden M. and Majumbar R. and Medina L.C. and Mishra S. and Murthy S. and Panjaburee P. and Sun D.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972149-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Buvari2023698,
	author = {Buvari, Sebastian and Viberg, Olga and Iop, Alessandro and Romero, Mario},
	title = {A Student-Centered Learning Analytics Dashboard Towards Course Goal Achievement in STEM Education},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {698 – 704},
	doi = {10.1007/978-3-031-42682-7_64},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171977964&doi=10.1007%2f978-3-031-42682-7_64&partnerID=40&md5=f0b4dafde7f6ff0610cb2f9f19aa01e2},
	affiliations = {EECS, KTH Royal Institute of Technology, Stockholm, Sweden},
	abstract = {Online learning has become an everyday form of learning for many students across different disciplines, including STEM subjects in the setting of higher education. Studying in these settings requires students to self-regulate their learning to a higher degree as compared to campus-based education. A vital aspect of self-regulated learning is the application of goal-setting strategies. Universities act to support students’ goal-setting through the achievement of course learning outcomes, which work both as a promise and metric of academic achievement. However, a lack of clear integration between course activities and course learning outcomes leaves a dissonance between students’ study efforts and the course progress. This demo study presents a student-centered learning analytics dashboard aimed at assisting students in their achievement of course learning goals in the setting of STEM higher education. The dashboard was designed using a design science methodological approach. Thirty-seven students have contributed to its development and evaluation during different stages of the design process, including the conceptual iterative design and prototyping. The preliminary results show that students found the tool to be easy to use and useful for the achievement of the course goals. © 2023, The Author(s).},
	author_keywords = {Learning Analytics Dashboard; Learning Outcomes; Participatory Design; STEM Higher Education},
	keywords = {Curricula; Design; Iterative methods; Goal-setting; Goals achievement; High educations; Learning analytic dashboard; Learning outcome; Online learning; Participatory design; STEM education; STEM high education; Student centred learning; Students},
	correspondence_address = {O. Viberg; EECS, KTH Royal Institute of Technology, Stockholm, Sweden; email: oviberg@kth.se},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Aguirre Reid2023329,
	author = {Aguirre Reid, Sören and Kammer, Frank and Schüller, Daria and Siepermann, Markus and Wölfer, Jonas},
	title = {Know the Knowledge of Your Students: A Flexible Analytics Tool for Student Exercises},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13873 LNCS},
	pages = {329 – 344},
	doi = {10.1007/978-3-031-32808-4_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161231921&doi=10.1007%2f978-3-031-32808-4_21&partnerID=40&md5=7e0ddfbe1e6215179ea1faf238f70cb6},
	affiliations = {Technische Hochschule Mittelhessen, Wiesenstraße 14, Gießen, 35390, Germany},
	abstract = {Intelligent tutoring systems (ITS) have the power to influence lecturers’ practices in the classroom and to improve students’ learning. Many ITS provide standardized analytical methods to evaluate classroom performance or the results of the exercises. But they lack more sophisticated, flexible and individual analyses. This paper presents an e-learning Analytics Tool (EAT) for an ITS that provides a dashboard with key figures and a flexible analytics board (FAB). This enables lecturers to analyze students’ performance in detail and identify misconceptions. For instance, the FAB allows us to classify student solutions, reveal conceptual errors in exercises, and analyze each part of an exercise. By this, common mistakes can be identified, and tailored feedback can be given to the students. Following the design science approach, the platform is designed in a general way so that it can be used for different types of exercises (e.g., Math, Excel, SQL). To assess the artifact, we conducted group interviews with German University lecturers from various courses. The results show that lecturers require a good overview of the submitted student solutions to provide timely feedback. They also appreciate the flexible analytics tool for detailed analyses of student solutions to understand student mistakes better. The employed architecture allows general analyses of exercises and the content of students’ solutions. In addition, the EAT is not bound to a specific kind of exercise, but can cope with different kinds like SQL and Excel. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Flexible Analysis; Intelligent Tutoring System; ITS; Learning Analytics and Evaluation},
	keywords = {Computer aided instruction; Education computing; Intelligent vehicle highway systems; Learning systems; Analytic tools; Dashboard; Flexible analyse; Intelligent tutoring; Intelligent tutoring system; Learning analytic and evaluation; Tutoring system; Students},
	correspondence_address = {J. Wölfer; Technische Hochschule Mittelhessen, Gießen, Wiesenstraße 14, 35390, Germany; email: Jonas.Woelfer@mni.thm.de},
	editor = {Gerber A. and Baskerville R.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303132807-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Majumdar2023731,
	author = {Majumdar, Rwitajit and Prasad, Prajish and Kadam, Kapil and Gatare, Kinnari and Warriem, Jayakrishnan Madathil},
	title = {LA-ReflecT: A Platform Facilitating Micro-learning and Its Multimodal Learning Analytics},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {731 – 735},
	doi = {10.1007/978-3-031-42682-7_69},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172031982&doi=10.1007%2f978-3-031-42682-7_69&partnerID=40&md5=12d7cb9b437e13cb1f896d62eacd151b},
	affiliations = {Kumamoto University, Kumamoto, Japan; FLAME University, Pune, India; Kolhapur Institute of Technology, Kolhapur, India; Independent Researcher, Mumbai, India; IIT Madras, Chennai, India},
	abstract = {The interactive demo highlights LA-ReflecT, an LTI-enabled platform that facilitates the creation of micro-learning activities with multimedia content, and helps track interactions and artefacts created by students within the platform as xAPI logs. The platform facilitates reflection on action in the form of presenting information on a dashboard as a part of the learning activity. LA-ReflecT also enables an app connecting with Bluetooth sensors that stream time series signals. The sensor data from a user is synchronized with their particular activity and can be linked to their learning log. We are doing multiple pilots with research partners in Japan and India. We are open to discussing adaptors who want to potentially pilot LA-ReflecT for creating microlearning material and investigating the potential of the data logged in the platform. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {LAreflecT; Micro-learning; Multimodal Learning Analytics},
	keywords = {Bluetooth sensors; Lareflect; Learning Activity; Micro-learning; Multi-modal learning; Multimedia contents; Multimodal learning analytic; Presenting informations; Stream time series; Time series signals},
	correspondence_address = {R. Majumdar; Kumamoto University, Kumamoto, Japan; email: dr.rwito@gmail.com},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Febriantoro202375,
	author = {Febriantoro, Wicaksono and Gauthier, Andrea and Cukurova, Mutlu},
	title = {The Promise of Physiological Data in Collaborative Learning: A Systematic Literature Review},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {75 – 88},
	doi = {10.1007/978-3-031-42682-7_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171976075&doi=10.1007%2f978-3-031-42682-7_6&partnerID=40&md5=a0ab4170933a95a0a625f3ef2ce93c5a},
	affiliations = {UCL Knowledge Lab, Institute of Education, University College London (UCL), London, United Kingdom},
	abstract = {Collaborative learning is an important approach in education. Researchers are increasingly interested in using physiological data, such as Electrodermal Activity (EDA), as an objective tool to measure bodily reactions during collaborative activities. However, it remains unclear how physiological data can contribute to our understanding, monitoring and support of the collaborative learning process. To address this gap, a Systematic Literature Review (SLR) was conducted, focusing on the contribution of physiological data to collaborative learning, the features of physiological data that correlate with effective outcomes, and interventions designed to support collaboration based on physiological data. The review identified 13 relevant publications that revealed physiological data can indeed be useful for detecting certain aspects of collaboration including students’ cognitive, behavioral, and affective (emotion and motivation) states. Physiological arousal in the form of EDA peaks and physiological synchrony (interdependence or associated activity between individuals’ physiological signals) were the most commonly used features. Surprisingly, only one publication presented a prototype of a learning analytics dashboard that used physiological data to guide student reflections. Furthermore, the review highlights the potential for integrating physiological measures with other data sources, such as speech, eye gaze, and facial expression, to uncover psychophysiological reactions and accompanying social and contextual processes related to collaborative learning. Future research should consider embedding methods for the physiological detection and modeling of learning constructs within explicit, feedback-driven interventions for collaborative learning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {collaborative learning; physiological data},
	keywords = {Psychophysiology; Collaborative activities; Collaborative learning; Collaborative learning process; Data-source; Electrodermal activity; Eye-gaze; Physiological data; Physiological measures; Physiological signals; Systematic literature review; Learning systems},
	correspondence_address = {W. Febriantoro; UCL Knowledge Lab, Institute of Education, University College London (UCL), London, United Kingdom; email: Wicaksono.febriantoro.21@ucl.ac.uk},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Nakamizo2022230,
	author = {Nakamizo, Yuta and Liang, Changhao and Horikoshi, Izumi and Majumdar, Rwitajit and Flanagan, Brendan and Ogata, Hiroaki},
	title = {GWpulse: Supporting Learner Modeling and Group Awareness in Online Forum with Sentiment Analysis},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {1},
	pages = {230 – 232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151046964&partnerID=40&md5=4d56009ae32f8924d7eb041d864f7fe6},
	affiliations = {Kyoto University, Japan},
	abstract = {Collaborative learning in online context has been in educational practice and also gained attention during the emergency remote teaching due to the pandemic. This study follows the Group Learning Orchestration Based on Evidence (GLOBE) framework that considers four phases of technology-supported group work and proposes data-driven services for each phase. In this paper, we present an analysis tool named "GWpulse'' that processes learning log data and shares the analysis results as an attribute of the learner model considered in GLOBE and also presents it in the group work dashboard to facilitate group awareness. In the current version GWpulse considered logs of forum activity generated during group activities in the learning management system. Apart from including that data in the learner model, it also visualizes the activity data for the orchestration, evaluation and reflection phases. GWpulse dashboard displays the basic statistics of their students' forum activities such as time interval and the number of posts, as well as a novel indicator of "Assistance Needed Level" calculated using sentiment analysis method that classifies textual statements into positive and negative. © 30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings.},
	author_keywords = {Group awareness; learner modeling; learning analytics; sentiment analysis},
	keywords = {E-learning; Learning systems; Collaborative learning; Evidence framework; Group awareness; Group learning; Group work; Learner modeling; Learning analytic; Online forums; Remote teaching; Sentiment analysis; Sentiment analysis},
	correspondence_address = {Y. Nakamizo; Kyoto University, Japan; email: nakamizo.yuta.83a@st.kyoto-u.ac.jp},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Denden M. and Majumbar R. and Medina L.C. and Mishra S. and Murthy S. and Panjaburee P. and Sun D.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972149-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hadiprawoto2023142,
	author = {Hadiprawoto, Triana R. and Ridley, Arran L.},
	title = {Transparent Dashboards: Open data practices for promoting competition-As-motivation in business dashboards},
	year = {2023},
	journal = {IEEE Pacific Visualization Symposium},
	volume = {2023-April},
	pages = {142 – 146},
	doi = {10.1109/PacificVis56936.2023.00023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163306597&doi=10.1109%2fPacificVis56936.2023.00023&partnerID=40&md5=bdf0a194e0b47dffd78ee7caf7b86e8e},
	affiliations = {Universitas Indonesia, Indonesia; University of Leeds, United Kingdom},
	abstract = {Dashboards are a common and familiar format of data visualization and are deployed in a number of fields and across domains, such as business, medical and health, learning analytics, and urban analytics, amongst others. In this paper, we conduct interviews with users of business dashboards, in particular, performance dashboards and scorecards, in order to gain an understanding of how they might be used in daily practice. We discuss how dashboards are not only used, as the literature suggests, to gain a quick understanding of the data but are deployed, by making the data available to everyone, as a means of motivating the users through creating a competitive framing of the data. We discuss the implications of this and how our findings can inform and support approaches to dashboard design, implementation, and usage.  © 2023 IEEE.},
	author_keywords = {dashboards; data visualization; motivation},
	keywords = {Competition; Motivation; Open Data; Visualization; Dashboard; Data practices; Design implementation; Open datum; Performance; Promoting competition; Data visualization},
	correspondence_address = {T.R. Hadiprawoto; Universitas Indonesia, Indonesia; email: triana.rh@ui.ac.id},
	publisher = {IEEE Computer Society},
	issn = {21658765},
	isbn = {979-835032124-1},
	language = {English},
	abbrev_source_title = {IEEE Pacific Visual. Symp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Deshpande2023,
	author = {Deshpande, K.V. and Asbe, Shubham and Lugade, Akanksha and More, Yash and Bhalerao, Dipali and Partudkar, Anuradha},
	title = {Learning Analytics Powered Teacher Facing Dashboard to Visualize, Analyze Students' Academic Performance and give Key DL(Deep Learning) Supported Key Recommendations for Performance Improvement.},
	year = {2023},
	journal = {2023 International Conference for Advancement in Technology, ICONAT 2023},
	doi = {10.1109/ICONAT57137.2023.10080832},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153255913&doi=10.1109%2fICONAT57137.2023.10080832&partnerID=40&md5=c84e666a96cc0a42f9b70d8a8e81f83b},
	affiliations = {JSPM's Rajarshi Shahu College of Engineering, Tathawade, Department of Computer Engineering, Pune, India},
	abstract = {COVID-19 has forced the government to close educational institutes to reduce the spread of the virus. As a result of this decision, students lose contact with teachers and a communication gap also arises. This survey attempts to bridge the gap between students and teachers. Through this survey, we sought to understand where the students are lacking and what are the different steps that can be taken by the teacher to improve the performance of the student and whether this concept should be reviewed or not. We found that most of the researchers who have published papers that we have read did the same mistake in their research, therefore we realized that the concept of AI should be studied again, and we should try not to repeat the same mistake in our research.The main aim of our project is to build 'Teacher facing dashboard' which can help the teacher to summarize,visualize and analyze the data of the education field(academics) and also understanding the students performance using Machine Learning(ML) and Deep Learning (DL).  © 2023 IEEE.},
	author_keywords = {analyze; deep learning; education field; learning analytics; machine learning; students; teacher facing dashboard; teachers; visualize},
	keywords = {Deep learning; Facings; Learning systems; Viruses; Analyze; Deep learning; Education field; Learning analytic; Machine-learning; Performance; Teacher facing dashboard; Teachers'; Visualize; Students},
	correspondence_address = {K.V. Deshpande; JSPM's Rajarshi Shahu College of Engineering, Tathawade, Department of Computer Engineering, Pune, India; email: kvdeshpande_comp@jspmrscoe.edu.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547517-4},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Technol., ICONAT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Simic2023,
	author = {Simic, Dejan and Leible, Stephan and Schmitz, Dennis and Gücük, Gian-Luca and Kučević, Emir},
	title = {Enhancing Project-based Learning through Data-driven Analysis and Visualisation: A Case Study},
	year = {2023},
	journal = {International Conference on Information Systems, ICIS 2023: "Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies"},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192577918&partnerID=40&md5=90c79824fd036e005d8c8e8722a08e92},
	affiliations = {Department of Computer Science, University of Hamburg, Hamburg, Germany},
	abstract = {This paper investigates the application of data-driven analysis and visualisation to enhance project-based courses within a higher education setting. The research focuses on a digital course where students utilise digital tools such as Jira and Confluence, which generate event logs capturing students' actions. These event logs were leveraged in conjunction with process mining and business intelligence (BI) techniques to collect and analyse the data, visualised through the iterative development and evaluation of an artefact in the form of BI dashboards following the design science research paradigm. The dashboards provide lecturers with insights into student behaviour and progress, enabling them to derive actionable suggestions for adapting student behaviour. The findings demonstrate that incorporating data-driven approaches positively impacted student engagement and improved learning outcomes. This case study contributes to the fields of learning analytics and educational data mining, offering insights into utilising data-driven approaches to enhance project-based learning experiences. Copyright © 2023 Simic, Leible, Schmitz, Gücük, and Kučević.},
	author_keywords = {data analytics; design science research; educational data mining; Learning analytics; project-based courses},
	keywords = {Curricula; Data Analytics; Design; Digital devices; Iterative methods; Students; Visualization; Business-intelligence; Case-studies; Data analytics; Data-driven analysis; Design-science researches; Educational data mining; Event logs; Learning analytic; Project based learning; Project-based course; Data mining},
	publisher = {Association for Information Systems},
	isbn = {978-171389362-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Inf. Syst., ICIS: "Rising like Phoenix: Emerg. Pandemic Reshaping Hum. Endeavors Digit. Technol."},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mohseni2022,
	author = {Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
	title = {SBGTool v2.0: An Empirical Study on a Similarity-Based Grouping Tool for Students’ Learning Outcomes †},
	year = {2022},
	journal = {Data},
	volume = {7},
	number = {7},
	doi = {10.3390/data7070098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137286745&doi=10.3390%2fdata7070098&partnerID=40&md5=afec50ab8d602074d5a04a005d503dbd},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, 351 95, Sweden},
	abstract = {Visual learning analytics (VLA) tools and technologies enable the meaningful exchange of information between educational data and teachers. This allows teachers to create meaningful groups of students based on possible collaboration and productive discussions. VLA tools also allow a better understanding of students’ educational demands. Finding similar samples in huge educational datasets, however, involves the use of effective similarity measures that represent the teacher’s purpose. In this study, we conducted a user study and improved our web-based similarity-based grouping VLA tool, (SBGTool) to help teachers categorize students into groups based on their similar learning outcomes and activities. SBGTool v2.0 differs from SBGTool due to design changes made in response to teacher suggestions, the addition of sorting options to the dashboard table, the addition of a dropdown component to group the students into classrooms, and improvement in some visualizations. To counteract color blindness, we have also considered a number of color palettes. By applying SBGTool v2.0, teachers may compare the outcomes of individual students inside a classroom, determine which subjects are the most and least difficult over the period of a week or an academic year, identify the numbers of correct and incorrect responses for the most difficult and easiest subjects, categorize students into various groups based on their learning outcomes, discover the week with the most interactions for examining students’ engagement, and find the relationship between students’ activity and study success. We used 10,000 random samples from the EdNet dataset, a large-scale hierarchical educational dataset consisting of student–system interactions from multiple platforms at the university level, collected over a two-year period, to illustrate the tool’s efficacy. Finally, we provide the outcomes of the user study that evaluated the tool’s effectiveness. The results revealed that even with limited training, the participants were able to complete the required analysis tasks. Additionally, the participants’ feedback showed that the SBGTool v2.0 gained a good level of support for the given tasks, and it had the potential to assist teachers in enhancing collaborative learning in their classrooms. © 2022 by the authors.},
	author_keywords = {data visualization; EdNet; educational data; learning analytics dashboard; SBGTool; similarity-based grouping; user study; visual learning analytics},
	keywords = {Eye protection; Large dataset; Students; Visualization; Analytic tools; Ednet; Educational data; Learning analytic dashboard; Similarity-based grouping; Similarity-based grouping VLA tool,; Teachers'; User study; Visual learning; Visual learning analytic; Data visualization},
	correspondence_address = {Z. Mohseni; Department of Computer Science and Media Technology, Linnaeus University, Växjö, 351 95, Sweden; email: zeynab.mohseni@lnu.se},
	publisher = {MDPI},
	issn = {23065729},
	language = {English},
	abbrev_source_title = {Data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Knoop-van Campen20233447,
	author = {Knoop-van Campen, Carolien A. N. and Wise, Alyssa and Molenaar, Inge},
	title = {The equalizing effect of teacher dashboards on feedback in K-12 classrooms},
	year = {2023},
	journal = {Interactive Learning Environments},
	volume = {31},
	number = {6},
	pages = {3447 – 3463},
	doi = {10.1080/10494820.2021.1931346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107351083&doi=10.1080%2f10494820.2021.1931346&partnerID=40&md5=3d6a454b557fcc05e64d492fb324489c},
	affiliations = {Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Learning Analytics Research Network (LEARN), NYU Steinhardt, New York, NY, United States},
	abstract = {Teacher dashboards provide real-time information about students’ performance and progress, which help K-12 teachers to adjust feedback to student’ specific needs during learning. Prior research indicated two problems with respect to how teachers provide feedback: (i) teachers do not always select the most effective feedback to support student’ learning and (ii) feedback is not allocated equally to students with different abilities. Specifically, process feedback is considered most effective yet is relatively scarce. In order to understand how dashboards influence the type and allocation of feedback, we compared characteristics of feedback given after dashboard consultation (dashboard-prompted feedback) to feedback triggered by teachers themselves or in response to students’ questions (human-prompted feedback) in thirty-five K-12 classrooms. Results showed that dashboards led to equal amounts of task and process feedback, while human-prompts led to much more task than process feedback and this difference was especially large for low-ability students. Hence the different types of dashboard-prompted feedback were more equally distributed among students of different ability levels. These results indicate that dashboards can have an important equalizing effect on teacher feedback practices. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {ability levels; adaptive learning technology; feedback; K-12; learning analytics; Teacher dashboards},
	correspondence_address = {C.A.N. Knoop-van Campen; Behavioural Science Institute, Radboud University, Nijmegen, Montessorilaan 3, 6525 HR, Netherlands; email: c.knoop-vancampen@bsi.ru.nl},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Chou2023142,
	author = {Chou, Tsung-Nan},
	title = {Apply an Integrated Responsible AI Framework to Sustain the Assessment of Learning Effectiveness},
	year = {2023},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {142 – 149},
	doi = {10.5220/0012058400003470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160817446&doi=10.5220%2f0012058400003470&partnerID=40&md5=808ea98d6231bc3c99195ca13bae8aaf},
	affiliations = {Department of Finance, Chaoyang University of Technology, Taichung, 41349, Taiwan},
	abstract = {Recent developments in educational data mining and learning analytics have increased the need for explainable artificial intelligence to interpret the decisions or predictions made by the algorithms. In order to analyse the impact of students' learning input on their learning effectiveness, an innovative responsible and trusted AI framework was developed and implemented as three separate modules that covered five different stages in this study. The first module developed various explainable artificial intelligence (XAI) models based on the model grafting and model fusion techniques that concatenated or synergized a global model with different local models. In addition, the local models were also supplemented by several explanation methods to provide additional explanatory information for the explainable XAI hybrid model. The second module constructed three different safeguard and auditing models to provide complementary predictions for students being misidentified as normal students and discovered the students at risk of failing a course. The adversarial training models developed in the third module applied AI generated synthetic data to train the proposed models and evaluate their performance with an attempt to search for any possible competent models that performed better. The framework was implemented by using Microsoft Power BI tools to create various visualized and interactive dashboards to demonstrate the analysis outcomes. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)},
	author_keywords = {Adversarial Training; Educational Data Mining; Explainable AI},
	keywords = {Artificial intelligence; Education computing; Students; Adversarial training; Different stages; Educational data mining; Explainable AI; Fusion techniques; Learning effectiveness; Local model; Model fusion; Model-based OPC; Student learning; Data mining},
	editor = {Jovanovic J. and Chounta I.-A. and Uhomoibhi J. and McLaren B.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758641-5},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Tsoni2022,
	author = {Tsoni, Rozita and Kalles, Dimitris and Verykios, Vassilios},
	title = {A Data Pipeline Approach for Building Learning Analytics Dashboards},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3549737.3549774},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138406653&doi=10.1145%2f3549737.3549774&partnerID=40&md5=b159317150aa4c189cfe8a0d9caf119a},
	affiliations = {Hellenic Open University, Patras, Greece},
	abstract = {In the era of data abundance, the ability to leverage data to assess the learning process is of great importance. Learning Analytics has been widely used and different approaches of deployment methods have been proposed, aiming to improve teaching and learning. Learning Analytics Dashboards (LAD), as the most dominant method to communicate results to the educational stakeholders, are found to be very effective. However, building a flexible and informative LAD is a complex procedure that incorporates several consecutive steps. The data pipeline framework which is used as a blueprint for generating LADs in this paper offers an important abstraction that helps the non-technical users to appreciate the effectiveness of the approach, as for every insight and report that is generated by a data scientist, there are most probably large such pipelines that implement the underlying functionality. This paper discusses the utility of data pipelines and presents the implementation of a LAD based on a data pipeline in Distance Learning students' data for summative assessment, along with some preliminary results.  © 2022 ACM.},
	author_keywords = {Data Pipelines; Distance Learning; Learning Analytics Dashboards; Summative Assessment},
	keywords = {Blueprints; Learning systems; Pipelines; Complex procedure; Data pipelines; Deployment methods; Distance-learning; Learning analytic dashboard; Learning process; Non-technical users; Summative assessments; Teaching and learning; Distance education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039597-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kim2023214,
	author = {Kim, Yoon Jeon and Scianna, Jennifer and Knowles, Mariah A.},
	title = {How Can We Co-design Learning Analytics for Game-Based Assessment: ENA Analysis},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1785 CCIS},
	pages = {214 – 226},
	doi = {10.1007/978-3-031-31726-2_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161428086&doi=10.1007%2f978-3-031-31726-2_15&partnerID=40&md5=5c524ab50cb21ef9d00955eb6c034a16},
	affiliations = {University of Wisconsin – Madison, Madison, WI, United States},
	abstract = {The broader education research community has adopted co-design, or participatory design, as a method to increase adoption of innovations in classrooms and to support professional learning of teachers. However, it can be challenging, due to co-design’s dynamic nature, to closely investigate how the co-process played out over time, and how it led to changes in teachers’ perceptions, beliefs, and/or practices. Applying Quantitative Ethnography, we investigate how teachers and researchers collaboratively designed assessment metrics and data visualizations for an educational math game; we discuss the interactions among the co-design activities, teachers’ learning, and qualities of the dashboard created as the output of the process. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {co-design; data visualization; ENA; game-based assessment; human-centered learning analytics; teacher professional learning},
	keywords = {Design; Game design; Visualization; Co-designs; Design learning; Education research; ENA; Game-Based; Game-based assessment; Human-centered learning analytic; Professional learning; Teacher professional learning; Teachers'; Data visualization},
	correspondence_address = {Y.J. Kim; University of Wisconsin – Madison, Madison, United States; email: yj.kim@wisc.edu},
	editor = {Damşa C. and Barany A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303131725-5},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Padakanti2023525,
	author = {Padakanti, Dhatri and Moraes, Marcia},
	title = {Learning analytics dashboard to support instructors: a literature review},
	year = {2023},
	journal = {International Conference on Higher Education Advances},
	pages = {525 – 532},
	doi = {10.4995/HEAd23.2023.16119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173937341&doi=10.4995%2fHEAd23.2023.16119&partnerID=40&md5=62e56f2e177d8def65f4c2e1637ac135},
	affiliations = {Computer Science Department, Colorado State University, United States},
	abstract = {The purpose of this study is to conduct an evaluation of the literature on learning analytics dashboards in order to address the following research questions: "How do instructors use learning analytics dashboards to send notifications?" and "How can a learning analytics dashboard help students get reminded of the due dates for assignments, quizzes, and exams?". A total of 20 papers were analyzed. Although the majority of them discussed how students utilize dashboards to track their progress or compare their progress with their peers, none of them mentioned how dashboards may be utilized to automatically notify students or send reminders, reducing the amount of work instructors have to do. This can be taken into account when developing a dashboard for learning analytics in the future. © 2023 International Conference on Higher Education Advances. All rights reserved.},
	author_keywords = {higher education; Learning analytics; learning analytics dashboard; learning management system},
	publisher = {Universidad Politecnica de Valencia.},
	issn = {26035871},
	isbn = {978-841396085-2},
	language = {English},
	abbrev_source_title = {Int. Conf. High. Educ. Adv.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Daniel202334,
	author = {Daniel, Ben Kei},
	title = {A Data-Driven Approach to Teaching Research Methods: IMethod, a Proof-of-Concept},
	year = {2023},
	journal = {Proceedings of the European Conference on Research Methods in Business and Management Studies},
	volume = {2023-September},
	pages = {34 – 43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190283280&partnerID=40&md5=3c306eec9ee0351e8b38f459770eef32},
	affiliations = {Higher Education Development Centre, University of Otago, 65/75 Union Place West, Dunedin, 9016, New Zealand},
	abstract = {Courses in research methods play a critical role in postgraduate education. However, postgraduate students face considerable challenges in learning the subject matter. The present paper introduces iMethod, a software application designed to track students' engagement with the content of research methods courses. iMethod harvested data, analysed students' engagement, and presented the outcome to a teacher through a dashboard rendered in real-time. As a proof-ofconcept, a usability study on iMethod was conducted with a sample of postgraduate students and early career academics (n=37) at a research-intensive university in New Zealand. Key findings suggest that students and academic staff found iMethod a valuable application for enhancing research methods learning. In particular, students value its content for understanding fundamental concepts while valuing its inquiry facilitation and providing helpful information on research methods. Participants said iMethod could expand knowledge, offers guidance, and the content is accessible to a diverse range of students. Lastly, participants reported that iMethod facilitated easy knowledge sharing, and the interface design was user-friendly and intuitive. The paper contributes to the growing need to promote research into the curriculum design of research methodology programmes and the quality of teaching research methods courses.  Copyright the authors, 2023. All Rights Reserved.},
	author_keywords = {iMethod; Learning Analytics; Research Methodology; Visualisation},
	correspondence_address = {B.K. Daniel; Higher Education Development Centre, University of Otago, Dunedin, 65/75 Union Place West, 9016, New Zealand; email: ben.daniel@otago.ac.nz},
	editor = {Matos F. and Rosa A.},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {20490968},
	isbn = {978-191458771-9},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Res. Meth.  Bus. Manag. Stud.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wiedbusch2022432,
	author = {Wiedbusch, Megan and Sonnenfeld, Nathan and Henderson, James},
	title = {Pedagogical Companions to Support Teachers' Interpretation of Students' Engagement from Multimodal Learning Analytics Dashboards},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {2},
	pages = {432 – 437},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151062128&partnerID=40&md5=700b21d1f970c40fba52849006af3acb},
	affiliations = {University of Central Florida, United States},
	abstract = {Teaching demands educators adapt and improvise their instruction for each student's unique needs and capabilities across contexts. This requires teachers to observe their students, evaluate their ongoing learning, and offer individualized scaffolding and feedback and foster sustained growth and development. This challenging practice has been made even more difficult by the recent emphasis on data-driven instructional decision making from dashboards, further requiring teachers to become both pedagogical and data experts. Despite the development of dashboards to alleviate some of the load of collecting and aggregating complex multimodal student data, there is a need to provide support for teachers in analyzing, interpreting, and applying their students' real-time multimodal learning analytical data (e.g., metacognitive accuracy, negative emotions) in the form of pedagogical companions. Before we can begin the design and development of these agents, we must first understand how educators are currently approaching multimodal learning analytics (MMLA) that report on more than just performance-based outcomes. In this on-going work, we begin by briefly reviewing MMLA in teacher dashboards, teacher data literacy, and the role of pedagogical companions in teacher augmentation technologies. We then describe the development of an in-progress study exploring how three teachers currently use fictious MMLA on self-regulated learning (SRL) processes and the emerging trends we see from their data. Finally, we postulate what these results suggest about the needs that embedded intelligent pedagogical companions may fill in future dashboard and agent design. © ICCE 2022.All rights reserved.},
	author_keywords = {agent design; Multimodal learning analytics; pedagogical companion; teacher dashboards},
	keywords = {Decision making; Scaffolds; Agent design; Data driven; Growth and development; Multi-modal learning; Multimodal learning analytic; Ongoing learning; Pedagogical companion; Student engagement; Teacher dashboard; Teachers'; Students},
	correspondence_address = {M. Wiedbusch; University of Central Florida, United States; email: meganwiedbusch@knights.ucf.edu},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Abdul Aziz N.A. and Chang M. and Diwakar A. and How S.P. and Jiang B. and Kaewsa-Ard A. and Kim M.S. and Lai C.-L. and Lee V.Y.A. and Liu L.Y. and Ogata H. and Omar M.K. and Shu H. and Song Y. and Yun W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968900-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Vigentini202287,
	author = {Vigentini, Lorenzo and Swibel, Brad and Hasler, Garth},
	title = {Developing a Growth Learning Data Mindset: A Secondary School Approach to Creating a Culture of Data Driven Improvement},
	year = {2022},
	journal = {Journal of Learning Analytics},
	volume = {9},
	number = {2},
	pages = {87 – 104},
	doi = {10.18608/jla.2022.7377},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137222351&doi=10.18608%2fjla.2022.7377&partnerID=40&md5=5ab1b9d8d871a624eccef29a1e3214ff},
	affiliations = {School of Computing Science Engineering — K17, UNSW Sydney, Sydney, 2052, NSW, Australia; St. Andrew’s Cathedral School, Sydney Square, Sydney, 2000, NSW, Australia},
	abstract = {While Learning Analytics (LA) have gained momentum in higher education, there are still few examples of application in the school sector. Even fewer cases are reported of systematic, organizational adoption to drive the support of student learning trajectories that includes teachers, pastoral leaders, and academic managers. This paper presents one such case — at the intersection of praxis, governance, and evaluation — from a practitioner perspective. The paper describes the added value of data-driven approaches to create a culture of improvement in students and teachers in a comprehensive coeducational independent day school in Sydney. Evaluating the work done over the past five years to develop LA dashboards, the authors reflect on the process, the inspirations coming from theory, and the impact of the dashboards in the secondary school context. The data presented is not experimental in nature but supplies tangible evidence for the systematic evaluation scaffolded using the SHEILA policy framework. The main contribution of the paper is a practical demonstration of how managers in a secondary school drew from existing literature and observed data to 1) reflect on the adoption of LA in schools and 2) connect the dots between theory and practice to support teachers grappling with the trajectories of student learning and development, thus encouraging students to self-regulate their learning. © 2022, Society for Learning Analytics Research. All rights reserved.},
	author_keywords = {data mindset; Growth learning; learning analytics adoption; secondary school},
	correspondence_address = {L. Vigentini; School of Computing Science Engineering — K17, UNSW Sydney, Sydney, 2052, Australia; email: l.vigentini@unsw.edu.au},
	publisher = {Society for Learning Analytics Research},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Villalobos2023430,
	author = {Villalobos, Esteban and Hilliger, Isabel and Pérez-Sanagustín, Mar and González, Carlos and Celis, Sergio and Broisin, Julien},
	title = {Analyzing Learners’ Perception of Indicators in Student-Facing Analytics: A Card Sorting Approach},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {430 – 445},
	doi = {10.1007/978-3-031-42682-7_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171992694&doi=10.1007%2f978-3-031-42682-7_29&partnerID=40&md5=0c37856424d7e2750511da91521e8b8e},
	affiliations = {IRIT, Université Toulouse III - Paul Sabatier, Toulouse, France; Pontificia Universidad Católica de Chile, Santiago, Chile; Universidad de Chile, Santiago, Chile},
	abstract = {Many studies have explored using different indicators to support students’ self-monitoring. This has motivated the development of student-facing analytics, such as dashboards and chatbots. However, there is a limited understanding of how learners interpret these indicators and act on that information. This study evaluates different indicators from a student perspective by adapting the card sorting technique, which is employed in Human-Centered Design. We chose eight indicators based on different comparative reference frames from the literature to create 16 cards to present both a visual and a text representation per indicator. Qualitative and quantitative data were collected from 21 students of three majors at two Latin American universities. According to the quantitative results, students’ agreement level about the indicators’ interpretability and actionability was relatively low. Nonetheless, the indicators that included temporality were found to be less interpretable but more actionable than those that did not. The analysis indicates that several students would use this information to improve their study habits only if their performance in the course is lower than expected. These findings might be used as a starting point to design student-facing analytics. Also, adapting the card sorting technique could be replicated to understand learners’ use of indicators in other TEL contexts. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Indicators; Learning Analytics Dashboards; Self-monitoring},
	keywords = {Facings; Sorting; Card-sorting; Chatbots; Human-centred designs; Learner perceptions; Learning analytic dashboard; Reference frame; Self-monitoring; Sorting techniques; Student perspectives; Text representation; Students},
	correspondence_address = {E. Villalobos; IRIT, Université Toulouse III - Paul Sabatier, Toulouse, France; email: esteban.villalobos@irit.fr},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Berková2022,
	author = {Berková, Kateřina and Frendlovská, Dagmar and Chalupová, Martina and Kubišová, Andrea and Hrmo, Roman and Krelová, Katarína Krpálková},
	title = {Pilot Research into the Perceived Importance of Educational Elements and an Application for Detecting Progress through the Perspective of Practice},
	year = {2022},
	journal = {Education Sciences},
	volume = {12},
	number = {10},
	doi = {10.3390/educsci12100669},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140598392&doi=10.3390%2feducsci12100669&partnerID=40&md5=637c763d2fcd605972384daaaed7ae8f},
	affiliations = {Department of Economic Studies, College of Polytechnics Jihlava, Jihlava, 586 01, Czech Republic; Department of Mathematics, College of Polytechnics Jihlava, Jihlava, 586 01, Czech Republic; Department of Didactics of Professional Subjects, DTI University, Dubnica nad Váhom, 018 41, Slovakia; Department of Economic Teaching Methodology, Prague University of Economics and Business, Prague, 130 67, Czech Republic},
	abstract = {Data analysis and the development of learning skills based on monitoring students’ progress are aspects in demand by schools and students. Quite a lot of studies deal with Learning Analytics Dashboards. There is a limited number of studies that take into account the supply of such tools on the market. In this pilot study, the researchers present findings on the attitudes of 19 higher education institutions from the Czech Republic, Belgium, Germany, Greece, the Netherlands and Poland, along with 14 secondary schools from the Czech Republic, towards the proposed web-based application for supporting learning and providing automated feedback on student progress in accounting education. The aim of this section was to find out how schools perceive the importance of the proposed application and its specific parameters. The study also presents the current product offer on the Czech market and the interest among 112 companies in developing such an application. The findings revealed that there is no such tool offered on the Czech market, and the majority of the analyzed companies are interested in its development. The schools evaluated the learning tool as being most important in the area of distance learning, and most useful for the visualization of accounting methods based mainly on imagination. The value of such an application is seen in supporting self-study, providing information on attitudes and current abilities, and tracking students’ learning progress. © 2022 by the authors.},
	author_keywords = {accounting; companies; distance learning; perceived usefulness; progress in learning; visualizing web application},
	correspondence_address = {K. Berková; Department of Economic Studies, College of Polytechnics Jihlava, Jihlava, 586 01, Czech Republic; email: katerina.berkova@vspj.cz},
	publisher = {MDPI},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Safsouf2023332,
	author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
	title = {Enhanced Online Academic Success and Self-Regulation Through Learning Analytics Dashboards},
	year = {2023},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {685 AICT},
	pages = {332 – 342},
	doi = {10.1007/978-3-031-43393-1_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174544100&doi=10.1007%2f978-3-031-43393-1_30&partnerID=40&md5=9520be9817196d92f02210a4b9d832e7},
	affiliations = {LIMIE Laboratory, ISGA Group, Centre Marrakech, Marrakech, Morocco; Laboratory MSSII, ENSET of Mohammedia, University Hassan II of Casablanca, Casablanca, Morocco; Lab-STICC, University Bretagne Sud, Rennes, France},
	abstract = {In the wake of the COVID-19 health crisis, governments around the world made educational continuity during school and university closure a priority. Many countries adopted online education as an alternative to face-to-face courses. This situation has led to an awareness of the importance of analyzing learning traces and data left by students to measure, evaluate and improve the learning process. This paper presents an interoperable online learning analytics dashboard that allows teachers to easily track the progress of their learners as well as to predict and remedy dropouts. For learners, the dashboard offers the possibility to visualize their learning process, analyze it and develop better self-regulation skills. The results of the study conducted on a blended learning course, showed that the dashboard led learners to spend more time on their online training, to perform the proposed activities much better and to respect the deadlines better, and finally to improve their academic success. © 2023, IFIP International Federation for Information Processing.},
	author_keywords = {Learner Success; Learning Analytics; Learning Analytics Dashboards; Learning Experience; Self-Regulated Learning},
	keywords = {Deregulation; E-learning; Learning systems; Face to face; Health crisis; Learner success; Learning analytic; Learning analytic dashboard; Learning experiences; Learning process; On-line education; Self regulation; Self-regulated learning; COVID-19},
	correspondence_address = {Y. Safsouf; LIMIE Laboratory, ISGA Group, Centre Marrakech, Marrakech, Morocco; email: yassine.safsouf@isga.ma},
	editor = {Keane T. and Lewin C. and Brinda T. and Bottino R.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303143392-4},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ali2023674,
	author = {Ali, Lubna and Judel, Sven and Shetty, Deekshith and Schroeder, Ulrik},
	title = {An Evaluation System to Trace the Usage of the OER Conversion Tool (convOERter)},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {674 – 679},
	doi = {10.1007/978-3-031-42682-7_60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171979198&doi=10.1007%2f978-3-031-42682-7_60&partnerID=40&md5=435774136a34567b54aa10b40e11fa08},
	affiliations = {Learning Technologies Research Group, RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany},
	abstract = {Open Educational Resources (OER) are available resources for teaching, learning, and research distributed under an open license. They are considered essential building blocks in educational systems, as they can be freely used, modified, and shared. However, there are still many challenges that hinder the proper utilization of OER at schools as well as in higher education institutions. One of these challenges is the lack of technical tools that support producing OER or converting existing educational materials to OER. In order to overcome this problem, the OER Conversion Tool convOERter has been developed at the Learning Technologies Research Group of RWTH Aachen University. The main functionality of the tool is to support converting existing educational materials to OER by extracting images from the input files and replacing them with OER-compliant images retrieved from OER image portals. Since it is crucial to understand the tool’s usage and to trace the interaction between the tool and the end users, an evaluation system, consisting of a logging module, analytics engines, and a dashboard has been developed and integrated. In this paper, we will introduce the system’s conceptual design and illustrate its main modules. We will also highlight how and to which extent convOERter is being used by tracing and analyzing the interaction logs of the integrated system. Additionally, we will summarize the results of a usability study that was conducted to assess the effectiveness of the evaluation system. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {convOERter; Evaluation System; Learning Analytics; OER; Open Educational Resources},
	keywords = {Learning systems; Convoerte; Educational materials; Evaluation system; Learning analytic; Open educational resources; Open license; Resource conversion; Teaching researches; Teaching-learning; Conceptual design},
	correspondence_address = {L. Ali; Learning Technologies Research Group, RWTH Aachen University, Aachen, Germany; email: ali@cs.rwth-aachen.de},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Ahmad2023279,
	author = {Ahmad, Atezaz and Yordanov, Ivaylo Ivanov and Yau, Jane and Schneider, Jan and Drachsler, Hendrik},
	title = {A Trusted Learning Analytics Dashboard for Displaying OER},
	year = {2023},
	journal = {Distributed Learning Ecosystems : Concepts, Resources, and Repositories},
	pages = {279 – 303},
	doi = {10.1007/978-3-658-38703-7_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164325492&doi=10.1007%2f978-3-658-38703-7_15&partnerID=40&md5=98776ac9a18decb3dd14010759c0b6a0},
	affiliations = {DIPF|Leibniz Institute for Research and Information in Education, Frankfurt am Main, Germany; Goethe University, Frankfurt am Main, Frankfurt, Germany},
	abstract = {Learning Analytics (LA) consists of miscellaneous steps that include data harvesting, storing, cleaning, anonymisation, mining, analysis, and visualisation so that the vast amount of educational data is comprehensible and ethically utilisable by educators or instructors to obtain the advantages and benefits that LA can bring to the educational scene. These include the potential to increase learning experiences and reduce dropout rates. In this chapter, we shed light on OER repositories, LA, and LA dashboards and present an implementation of a research-driven LA dashboard for displaying OER and their repositories that allows the visualisation of educational data in an understandable way for both educators and learners. Moreover, we present an LA dashboard for displaying OER that shows information about the existing German OER repositories as part of our EduArc project located in Germany. The LA dashboard consists of multiple adopted indicators and metrics such as the number of reading sessions, duration of reading sessions, number of reading interruptions, number of learning activities, student attendance, and student grades. The details of the research methodology, including a literature review to create this dashboard, as well as the display items of the dashboard are presented and further elaborated. © The Author(s) 2023.},
	correspondence_address = {A. Ahmad; DIPF|Leibniz Institute for Research and Information in Education, Frankfurt am Main, Germany; email: ahmad@dipf.de},
	publisher = {Springer Fachmedien Wiesbaden},
	isbn = {978-365838703-7; 978-365838702-0},
	language = {English},
	abbrev_source_title = {Distributed Learning Ecosystems : Concepts, Resources, and Repositories},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Oliveira2023,
	author = {Oliveira, Pedro Filipe and Matos, Paulo},
	title = {Learning Analytics to Validate Academic Performance Analysis},
	year = {2023},
	journal = {9th International Conference on Engineering and Emerging Technology, ICEET 2023},
	doi = {10.1109/ICEET60227.2023.10525855},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194051242&doi=10.1109%2fICEET60227.2023.10525855&partnerID=40&md5=f8c2556447545d6a34aa2e02ec7c2a16},
	affiliations = {Instituto Politécnico de Bragança, Research Centre in Digitalization and Intelligent Robotics (CeDRI), Laboratorio Associado Para A Sustentabilidade e Tecnologia em Regioes de Montanha (SusTEC), Bragança, 5300-253, Portugal},
	abstract = {The learning process is increasingly on the agenda. As well as the mechanisms that can be used to optimize it, both in terms of improving student performance, as well as improving teacher performance. On this subject, there has been continuous research, and increasingly trying to take advantage of technological development, and thus be able to take full advantage of technology and achieve a significant leverage in this field. This work is developed within the scope of the evaluation of school performance. Namely, with the introduction of additional and customized resources, such as thematic courses on the Coursera platform, and the utilization analysis of the e-learning platform used by the teaching institution. With this, it was possible to develop some tools, which are used as dashboards to give the teacher a greater perception of the student's learning process and performance. And if any student is in the prospect of failing, the teacher receives an immediate notification, so that he can carry out the respective follow-up, and thus be able to act proactively to avoid failure.  © 2023 IEEE.},
	author_keywords = {academic-performance; coursera; dashboard; learning-analytics},
	keywords = {Engineering education; Learning systems; Students; Academic performance; Courserum; Dashboard; Learning process; Learning-analytic; Performance; Performances analysis; Student performance; Teachers'; Technological development; Teaching},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031692-6},
	language = {English},
	abbrev_source_title = {Int. Conf. Eng. Emerg. Technol., ICEET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {Proceedings of the 5th European Conference on Software Engineering Education, ECSEE 2023},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163470474&partnerID=40&md5=4cfa3f4c03413c8edb4204d335a8151f},
	abstract = {The proceedings contain 32 papers. The topics discussed include: reflections on training next-gen industry workforce on secure software development; the gap between higher education and the software industry – a case study on technology differences; using automatic program assessment in a software development project course; using learning analytics to identify student learning profiles for software development courses; learning analytics dashboard for educators: proposed project to design with pedagogical background; towards learning style prediction based on personality; adaptive learning path sequencing based on learning styles within n-dimensional spaces; learning style classification by using Bayesian networks based on the index of learning style; systematic literature review for the use of AI based techniques in adaptive learning management systems; and flipped teaching in software engineering education: results of a long-term study.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039956-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rodda202397,
	author = {Rodda, Alena},
	title = {How Can Learning Analytics Enhance Online Teaching? A Teacher’s Perspective},
	year = {2023},
	journal = {Lecture Notes in Business Information Processing},
	volume = {485 LNBIP},
	pages = {97 – 110},
	doi = {10.1007/978-3-031-42788-6_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174441586&doi=10.1007%2f978-3-031-42788-6_7&partnerID=40&md5=6c5acc174482c9f1355391917e618535},
	affiliations = {Osnabrueck University, Katharinenstr. 3, Osnabrueck, 49074, Germany},
	abstract = {This paper examines the perspectives of teachers on the use of Learning Analytics (LA) to enhance online teaching in higher education institutions during the post-Covid era. The increasing shift towards online teaching as a result of the pandemic has presented a number of challenges for teachers. As online teaching is likely to remain a part of the higher education landscape, it is important to understand teachers’ views on the topic. This study explores how LA could support teachers in their online teaching. For this purpose, we conducted 18 interviews with instructors from German and Dutch universities about the changes that online teaching has led to, opportunities and threats of LA, the information teachers require about their students, and the ability of LA to enhance the advantages of online teaching and mitigate its disadvantages. Our results show that teachers’ opinions of LA are generally positive and that they would use LA if it were available in form of an intuitive and interactive dashboard. LA also offers the possibility to alleviate many of the problems in online teaching identified by the instructors. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {E-Learning; Higher Education; Learning Analytics; Online teaching},
	keywords = {E - learning; High educations; Higher education institutions; Learning analytic; Online teaching; Teachers'; Teachers' views; E-learning},
	correspondence_address = {A. Rodda; Osnabrueck University, Osnabrueck, Katharinenstr. 3, 49074, Germany; email: alena.rodda@uni-osnabrueck.de},
	editor = {Jallouli R. and Bach Tobji M.A. and Belkhir M. and Soares A.M. and Casais B.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18651348},
	isbn = {978-303142787-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Bus. Inf. Process.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Divjak2022173,
	author = {Divjak, Blaženka and Vondra, Petra and Aničić, Katarina Pažur},
	title = {Strategic Development of a National Pre-tertiary Learning Analytics System},
	year = {2022},
	journal = {Journal of Information and Organizational Sciences},
	volume = {46},
	number = {1},
	pages = {173 – 195},
	doi = {10.31341/jios.46.1.10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133639285&doi=10.31341%2fjios.46.1.10&partnerID=40&md5=27c0efa47def1bf1b58779d39616164e},
	affiliations = {Faculty of Organization and Informatics, University of Zagreb, Varaždin, Croatia},
	abstract = {This paper elaborates the design of a National Learning Analytics (LA) and Educational Data Mining System for pre-tertiary education in Croatia. The described approach consists of the following five phases: 1) objectives setting, 2) user needs analysis, 3) data availability analysis, 4) dashboards pre-design and 5) validation of functionalities. There is an evident research gap, as well as the lack of practical examples about the development of a Learning Analytics System (LAS) for pre-tertiary education on the national and/or regional level. Therefore, this research aims to make a scientific contribution by filling the recognized gap, but also contribute to solving the practical issues of national schools’ LAS development. To increase the usability of an LAS, the involvement of all end users is essential. In the described case, six main user groups were identified: 10-18 years old students, teachers, school management and support staff, regional and national authorities responsible for education, strategic bodies and researchers and, finally, project partners that work on system development. For each of them, separate dashboard functionalities have been designed through several rounds of consultations. Consultations with users started with focus groups and panels, to brainstorm the most important issues they would like to answer in order to enhance learning and teaching. Between the two rounds of consultation, there was an evaluation phase of the relevance of the gathered questions. Finally, targeted users provided feedback on the pre-production functionalities of each dashboard and validated them. In this process, several challenges were detected, including data gathering and protection, ethical issues and interpretation of results for students who are underage, and continuous adjustments to the users’ needs. © 2022, University of Zagreb, Faculty of Organization and Informatics. All rights reserved.},
	author_keywords = {Dashboard; Learning analytics; Learning analytics system; Needs analysis; Pre-tertiary education},
	publisher = {University of Zagreb, Faculty of Organization and Informatics},
	issn = {18463312},
	language = {English},
	abbrev_source_title = {J. Inf. Organ. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Li202312,
	author = {Li, Huiyong and Majumdar, Rwitajit and Yang, Yuanyuan and Ogata, Hiroaki},
	title = {Modeling Feedback for Self-Direction Skills in K-12 Educational Settings with Learning and Physical Activity Data},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3439},
	pages = {12 – 22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167825565&partnerID=40&md5=757c1fa685c56cfd2e19efb38596276b},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Japan; Graduate School of Informatics, Kyoto University, Japan},
	abstract = {This work aims to propose a learner model-based feedback model for self-direction skills (SDS) acquisition to address the challenge of providing learning services with multimodal data in K-12 settings. The feedback model leverages students' daily life activity data from learning systems and wearable devices, creates a learner model of SDS, and provides multi-dimensional feedback to K-12 students: (1) feedback on contextual activity; (2) feedback on self-direction management and (3) feedback on skill assessment. We also implement the feedback model with two learning dashboards in English learning and physical activity contexts for illustration and show the potential effects of the feedback model on student engagement and skill improvement with two case studies in K-12 settings. The results of the case studies indicate that K-12 students can continuously engage in both learning and physical activities, and take the feedback regularly with the learning dashboard support. The implications and challenges of SDS development with multimodal data in K-12 settings are also discussed. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {feedback; learner model; Learning analytics; multimodal data; self-direction skill},
	keywords = {Information management; Learning systems; Case-studies; Educational settings; Feedback model; Learner modeling; Learning Activity; Learning analytic; Model feedback; Multi-modal data; Physical activity; Self-direction skill; Students},
	editor = {Di Mitri D. and DIPF, Leibniz Institute for Research and Information in Education, Rostocker Str. 6, Frankfurt am Main and Srivastava N. and Monash University, Department of Human Centred Computing, Faculty of InformationTechnology, Clayton Campus, 20 Exhibition Walk, Clayton, VIC and Martinez-Maldonado R. and Monash University, Department of Human Centred Computing, Faculty of InformationTechnology, Clayton Campus, 20 Exhibition Walk, Clayton, VIC and Cukurova M. and University College London, UCL Institute of Education, UCL Knowledge Lab, 20 Bedford Way, London and Spikol D. and University of Copenhagen, Department of Computer Science, Universitetsparken 1 DK-2100, Copenhagen},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Park202398,
	author = {Park, Eunsung and Ifenthaler, Dirk and Clariana, Roy B.},
	title = {Adaptive or adapted to: Sequence and reflexive thematic analysis to understand learners' self-regulated learning in an adaptive learning analytics dashboard},
	year = {2023},
	journal = {British Journal of Educational Technology},
	volume = {54},
	number = {1},
	pages = {98 – 125},
	doi = {10.1111/bjet.13287},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141980571&doi=10.1111%2fbjet.13287&partnerID=40&md5=bc1aec4e7970335fa96ba64b23a3c700},
	affiliations = {Department of Curriculum and Instruction, Tennessee Tech University, Cookeville, United States; Learning, Design and Technology, University of Mannheim, Mannheim, Germany; Data Science in Higher Education Learning and Teaching, Curtin University, Bentley, Australia; Department of Learning and Performance System, The Pennsylvania State University, University Park, United States},
	abstract = {The real-time and granularized learning information and recommendations available from adaptive learning technology can provide learners with feedback that is personalized. However, at an individual level, learners often experience technological and pedagogical conflicts. Learners have more freedom to accept, ignore or reject the feedback while also having the challenges of building learning strategies and utilizing learning information that requires self-regulated learning skills. Given the conflicts, both understanding how learners learn and providing support for learners to be more self-regulated in the learning environment are imperative. This investigation explores how learners processed their learning in an adaptive technology-integrated learning analytics dashboard (ALAD). It employed mixed-methods using a lens of self-regulated learning (SRL). Three groups were identified based on clustering analysis of the learners' usage of warm-up (WU) tests. Sequence analysis revealed the time trends of each group's interactions with course content. Reflexive thematic analysis brought insights on how learners built their learning strategies (eg, ways of using WU tests and submodule assessments) and how they monitored and controlled their learning. It showed their dynamic interactions with core adaptive learning analytics dashboard elements. Challenges such as difficulties in rehearsing and monitoring through segmented course content arose from the new structural changes. We suggest the need of future improvement to individual learning support through the learning analytics dashboard to be more diverse and dynamic (real-time) over the course of learning while reducing potential undesirable consequences. Practitioner notes What is already known about this topic One purpose of learning analytics and adaptive learning is to help learners identify learning goals and take action to achieve their goals. Learning analytics intervention showed support in learners' reflection phase SRL. However, it is not clear how to better support actionable and strategic changes to learning. Learning improvement through learning analytics interventions varies depending on how learners utilize feedback and monitor their learning progress, interacting with their digital learning environments. What this paper adds Learners established certain learning strategies with core adaptive learning analytics dashboard elements (eg, use of assessments, monitoring strategies). Learners' perceptions about learning support from the ALAD were built by interacting with the learners' task and cognitive conditions. Based on the perceptions, individuals' various SRL strategies and the need for diverse support were found. Monitoring and rehearsals can be challenging when course content is broken down for individuals' support. Implications for practice and/or policy Courses with adaptive learning analytics dashboards need to be designed more carefully, considering possible undesirable consequences, and to improve SRL support. Learners need more diverse learning support at an individual level based on how they interact with the learning environment. © 2022 British Educational Research Association.},
	author_keywords = {adaptive learning; clustering analysis; learning analytics dashboard; reflexive thematic analysis; self-regulated learning; sequence analysis},
	keywords = {Computer aided instruction; Curricula; Learning systems; Adaptive learning; Clustering analysis; Course contents; Learning analytic dashboard; Learning strategy; Learning support; Reflexive thematic analyse; Self-regulated learning; Sequence analysis; Thematic analysis; Feedback},
	correspondence_address = {E. Park; Department of Curriculum and Instruction, Tennessee Tech University, United States; email: epark@tntech.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@CONFERENCE{Ouared2023184,
	author = {Ouared, Abdelkader and Amrani, Moussa and Schobbens, Pierre-Yves},
	title = {Learning Analytics Solution for Monitoring and Analyzing the Students’ Behavior in SQL Lab Work},
	year = {2023},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {184 – 195},
	doi = {10.5220/0011848200003470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160859359&doi=10.5220%2f0011848200003470&partnerID=40&md5=7e56d977dfbcbdbbbb4ddfbb4bcff999},
	affiliations = {Faculty of Computer Science, NaDI, University of Namur, Rue Grandgagnage, Namur, 5000, Belgium},
	abstract = {Computer-assisted learning is widely discussed in the literature to aid the comprehension of SQL queries (Structured Query Language) in higher education. However, it is difficult for educators/instructors to track, monitor and analyze students’ learning situation due to the higher education massification, and institutions with large classes. Consequently, we need to provide for educators a learning dashboard to monitor and analyze the digital traces issued from students during the practice learning in SQL course. We propose a system called LSQL (Learning Analytics for SQL) that is a solution based on the learning analytics’ methodology. To this end, we propose (i) learning environment dedicated to help students understand the syntax and logic of SQL and getting data issued from these students during online SQL lab work, (ii) trace model which is designed to more effectively represent and capture the complex interactions/actions carried by a student during practice learning activities in virtual/remote laboratories, and (iii) learning analytics dashboard for educators to visualize the statistics and metrics that represent the students’ behavior, and control the students progress in SQL skills to enhance the teaching activities. Tool support is fully available. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)},
	author_keywords = {Database; Learning Analytics; Learning Analytics Dashboard; SQL Language Learning; Students’ Behavior},
	keywords = {Computer aided instruction; E-learning; Education computing; Learning systems; Query languages; Query processing; Analytic solution; Computer assisted learning; High educations; Language learning; Learning analytic; Learning analytic dashboard; SQL language learning; SQL languages; SQL query; Students' behaviors; Students},
	editor = {Jovanovic J. and Chounta I.-A. and Uhomoibhi J. and McLaren B.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758641-5},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kasepalu2022971,
	author = {Kasepalu, Reet and Chejara, Pankaj and Prieto, Luis P. and Ley, Tobias},
	title = {Do Teachers Find Dashboards Trustworthy, Actionable and Useful? A Vignette Study Using a Logs and Audio Dashboard},
	year = {2022},
	journal = {Technology, Knowledge and Learning},
	volume = {27},
	number = {3},
	pages = {971 – 989},
	doi = {10.1007/s10758-021-09522-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105290094&doi=10.1007%2fs10758-021-09522-5&partnerID=40&md5=8d2c3e389e24f40f67f5ef0a5b604764},
	affiliations = {Department of Educational Sciences, Tallinn University, Tallinn, Estonia; Department of Digital Technologies, Tallinn University, Tallinn, Estonia},
	abstract = {Monitoring and guiding multiple groups of students in face-to-face collaborative work is a demanding task which could possibly be alleviated with the use of a technological assistant in the form of learning analytics. However, it is still unclear whether teachers would indeed trust, understand, and use such analytics in their classroom practice and how they would interact with such an assistant. The present research aimed to find out what the perception of in-service secondary school teachers is when provided with a dashboard based on audio and digital trace data when monitoring a collaborative learning activity. In a vignette study, we presented twenty-one in-service teachers with videos from an authentic collaborative activity, together with visualizations of simple collaboration analytics of those activities. The teachers perceived the dashboards as providers of useful information for their everyday work. In addition to assisting in monitoring collaboration, the involved teachers imagined using it for picking out students in need, getting information about the individual contribution of each collaborator, or even as a basis for assessment. Our results highlight the need for guiding dashboards as only providing new information to teachers did not compel them to intervene and additionally, a guiding dashboard could possibly help less experienced teachers with data-informed assessment. © 2021, The Author(s).},
	author_keywords = {Actionability; Collaborative analytics; Design-based research; Learning analytics; Monitoring students; Teacher support; Teaching augmentation},
	keywords = {Classroom practices; Collaborative activities; Collaborative learning activities; Collaborative Work; Face to face; Multiple-group; Secondary schools; Trace data},
	correspondence_address = {R. Kasepalu; Department of Educational Sciences, Tallinn University, Tallinn, Estonia; email: reetkase@tlu.ee},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gutiérrez-Braojos2023,
	author = {Gutiérrez-Braojos, C. and Rodríguez-Domínguez, C. and Daniela, L. and Carranza-García, F.},
	title = {An Analytical Dashboard of Collaborative Activities for the Knowledge Building},
	year = {2023},
	journal = {Technology, Knowledge and Learning},
	doi = {10.1007/s10758-023-09644-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149203756&doi=10.1007%2fs10758-023-09644-y&partnerID=40&md5=329e4097834a95ec84a098f8a106e8d9},
	affiliations = {Department of Research Methods, Assessment and Evaluation in Education, University of Granada, Granada, Spain; Department of Computer Languages and Systems, University of Granada, Granada, Spain; Department of Pedagogy, University of Riga, Riga, Latvia},
	abstract = {Knowledge building (KB) is an educatioanl theory framework that shows interest in the benefits that the technology offers to teaching and evaluation. In this study, a dashboard that facilitates the reflective assessment of KB communities supported by the knowlege forum platform was evaluated. The design-based research study was conducted with 126 undergraduate students enrolled in an educational research course at the University of (Name, country). Using a survey methodology, data was collected on the students’ perception regarding epistemic collective agency, research skills, and dashboard assessment. The conclusions about the value of the dashboard are broken down into two axes. On the one hand, the students state that they are satisfied with the dashboard, although they indicate that there is room for improvement. On the other hand, according to the KB reflective assessment, the dahsboard provided students with educational experiences that have empowered them in the collaborative construction of knowledge and promoted the development of their specific educational research skills. Future technological improvements and implementations of the Knowledge Building are discussed. © 2023, The Author(s).},
	author_keywords = {Design-based research; Knowledge building; Learning analytics dashboard; Technology},
	keywords = {Architectural design; Computer aided instruction; Curricula; Building community; Collaborative activities; Design-based research; Educational research; Knowledge building; Learning analytic dashboard; Research skills; Research studies; Technology; Undergraduate students; Students},
	correspondence_address = {C. Gutiérrez-Braojos; Department of Research Methods, Assessment and Evaluation in Education, University of Granada, Granada, Spain; email: calixtogb@ugr.es},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Costa202326,
	author = {Costa, Laécio A. and Silveira, Aleph C. and Souza, Marlo and Salvador, Laís N. and Santos, Celso A. S.},
	title = {Investigating Student and Teacher Perceptions in e-Learning with Learning Analytics and Ontologies},
	year = {2023},
	journal = {International Journal of Emerging Technologies in Learning},
	volume = {18},
	number = {8},
	pages = {26 – 47},
	doi = {10.3991/ijet.v18i08.32411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154024779&doi=10.3991%2fijet.v18i08.32411&partnerID=40&md5=a641c67efb99d36b1c93b2e43cb475ef},
	affiliations = {Informatics Collegiate, Instituto Federal do Sertão Pernambucano, PE, Petrolina, Brazil; Computer Science Graduate Program, Federal University of Bahia, BA, Salvador, Brazil; Department of Informatics, Federal University of Espírito Santo, ES, Vitória, Brazil},
	abstract = {This work is an approach that brings together Learning Analytics and Ontologies for a data classification that promotes improvements and behavioral changes for students and teachers on e-Learning platforms. Combining training courses, dashboards, user’s evaluations, and based on Design Science Research (DSR) methodology, artifacts were created. One of the most important artifacts of our work is the Sapes tool that aims to improve students’ perceptions of their learning path and to promote a better teacher overview to follow their students’ progress. The results showed high approval by the participating students and teachers, who perceived the Sapes tool as a good facilitator of the teaching-learning process, with possibilities for self-monitoring, dynamization of the learning sequence and better interactivity with colleagues, highlighted as absent in standard e-Learning courses. In addition, the application changed the behavior of users towards the content provided by the teacher, with students performing self-management and self-regulation that were not commonly performed previously. © 2023, International Journal of Emerging Technologies in Learning. All Rights Reserved.},
	author_keywords = {educational technologies; Learning Analytics; Learning Management System; ontology},
	keywords = {Curricula; E-learning; Learning systems; Personnel training; Students; Teaching; Behavioral changes; Data classification; E - learning; E-learning platforms; Learning analytic; Learning management system; Ontology's; Student perceptions; Teachers'; Teachers' perceptions; Ontology},
	correspondence_address = {L.A. Costa; Informatics Collegiate, Instituto Federal do Sertão Pernambucano, Petrolina, PE, Brazil; email: laecio.costa@ifsertao-pe.edu.br},
	publisher = {International Association of Online Engineering},
	issn = {18688799},
	language = {English},
	abbrev_source_title = {Int. J. Emerg. Technol. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Matsumoto2022705,
	author = {Matsumoto, Tomoka and Ishii, Yuna and Horikoshi, Izumi and Tamura, Yasuhisa},
	title = {Analysis of the Impact Student‐Facing Learning Analytics Dashboards on Learning Motivation and Behaviors according to the Motivational Type of Learners},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {2},
	pages = {705 – 708},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151061723&partnerID=40&md5=d479c10e12f2a2afdab0ac8ffbae86e3},
	affiliations = {Graduate School of Science and Technology, Sophia University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan; Faculty of Science and Technology, Sophia University, Japan},
	abstract = {The authors developed two types of dashboards according to learners' motivational type and analyzed the effects of differences in dashboard visualization formats on learning behaviors and motivation. The results showed that some subjects prefer the visualization format of the dashboard regardless of their motivational type. In addition, we confirmed that learners with increased motivation also had increased learning behaviors, such as viewing videos. © ICCE 2022.All rights reserved.},
	author_keywords = {Adaptive Learning; Dashboard; Learning Analytics; Motivation},
	keywords = {Visualization; Adaptive learning; Dashboard; Learning analytic; Learning behavior; Learning motivation; Motivation},
	correspondence_address = {T. Matsumoto; Graduate School of Science and Technology, Sophia University, Japan; email: t-matsumoto-5f0@eagle.sophia.ac.jp},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Abdul Aziz N.A. and Chang M. and Diwakar A. and How S.P. and Jiang B. and Kaewsa-Ard A. and Kim M.S. and Lai C.-L. and Lee V.Y.A. and Liu L.Y. and Ogata H. and Omar M.K. and Shu H. and Song Y. and Yun W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968900-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Choi2023,
	author = {Choi, Heeryung and Borrella, Inma and Ponce-Cueto, Eva},
	title = {Meta-LAD: Developing a Learning Analytics Dashboard with a Theoretically Grounded and Context-Specific Approach},
	year = {2023},
	journal = {2023 IEEE Learning with MOOCS, LWMOOCS 2023 - Conference Proceedings},
	doi = {10.1109/LWMOOCS58322.2023.10306139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179132741&doi=10.1109%2fLWMOOCS58322.2023.10306139&partnerID=40&md5=06a01de61d5ac5bc550021668f22c2fc},
	affiliations = {Massachusetts Institute of Technology, Center of Transportation and Logistics, Cambridge, MA, United States},
	abstract = {The use of Learning Analytics Dashboards (LADs) has gained popularity as a means of supporting the self-regulated learning (SRL) skills of learners in large-scale online courses. Despite many studies proposing LAD designs, LADs are often criticized for their weak theoretical foundations, lack of actionable feedback, and tendency to encourage excessive social comparison. Furthermore, many LAD designs have missed context-specific details. Hence, it is not uncommon for some dashboard designs to have negative effects on learners, such as discouragement or anxiety. In this study, we designed the Meta-LAD, a LAD that supports SRL processes using theoretical and contextual foundations. We used data from a credit-bearing Massive Open Online Course (MOOC) on supply chain management to contextually ground the dashboard. We performed usability testing interviews to evaluate the design and confirmed that the Meta-LAD could fulfill learners' needs for references and actionable feedback. This study contributes to the field of online learning by presenting a theoretically grounded and contextually specific LAD design process. This paper expands the understanding of how to support SRL in MOOCs.  © 2023 IEEE.},
	author_keywords = {Learning Analytics Dashboard; MOOC; Self-regulated Learning},
	keywords = {Curricula; E-learning; Design learning; Large-scales; Learning analytic dashboard; Learning process; Learning skills; Massive open online course; Metalearning; Online course; Self-regulated learning; Theoretical foundations; Supply chain management},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031559-2},
	language = {English},
	abbrev_source_title = {IEEE Learn. MOOCS, LWMOOCS - Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Aghaei2023663,
	author = {Aghaei, Kimia and Hatala, Marek and Mogharrab, Alireza},
	title = {How Students' Emotion and Motivation Changes after Viewing Dashboards with Varied Social Comparison Group: A Qualitative Study},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {663 – 669},
	doi = {10.1145/3576050.3576107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149342021&doi=10.1145%2f3576050.3576107&partnerID=40&md5=c1a079e62173110a1db1d64fb2f0f49f},
	affiliations = {School of Interactive Arts and Technology, Simon Fraser University, Surrey, BC, Canada},
	abstract = {The need to personalize learning analytics dashboards (LADs) is getting more recognized in learning analytics research community. In order to study the impact of these dashboards on learners, various types of prototypes have been designed and deployed in different settings. Applying Weiner's attribution theory, our goal in this study was to understand the effect of dashboard information content on learners. We wanted to understand how elements of assignment grade, time spent on an assignment, assignment view, and proficiency in the dashboard affect students' attribution of achievement and motivation for future work. We designed a qualitative study in which we analyzed participants' responses and indicated behavioural changes after viewing the dashboard. Through in-depth interviews, we aimed to understand students' interpretations of the designed dashboard, and to what extent social comparison impacts their judgments of learning. Students used multiple dimensions to attribute their success or failure to their ability and effort. Our results indicate that to maximize the benefits of dashboards as a vehicle for motivating change in students learning, the dashboard should promote effort in both personal and social comparison capacities.  © 2023 ACM.},
	author_keywords = {attribution theory; learning analytics dashboard; motivation; qualitative analysis; social comparison},
	keywords = {Economic and social effects; Motivation; Attribution theory; Comparison group; Information contents; Learning analytic dashboard; Qualitative analysis; Qualitative study; Research communities; Social comparison; Student emotions; Student motivation; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Hsu2022326,
	author = {Hsu, Chia-Yu and Horikoshi, Izumi and Li, Huiyong and Majumdar, Rwitajit and Ogata, Hiroaki},
	title = {Extracting Students' Self-Regulation Strategies in an Online Extensive Reading Environment using the Experience API (xAPI)},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {1},
	pages = {326 – 331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151065008&partnerID=40&md5=034cdc44108810b985c337726496af30},
	affiliations = {Graduate School of Informatics, Kyoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan},
	abstract = {Extensive Reading (ER) activity is useful in language learning where learners pick any reading materials in target language by themselves and continue reading. In this study, we aim to understand students' self-regulation behaviors and strategies in ER so that facilitators can give learning strategy-based instruction. For this purpose, we first explored a potential structure of a learners' model that can highlight their learning strategies and extracted from multi-system interaction logs recorded in Experience API (xAPI) format. To demonstrate, we collected data from 120 students across 3 months when they did ER activities. We analyzed and extracted the self-regulation strategies of the learners and found 2 groups by applying K-means cluster analysis. The results inform dashboard design and instructional support based on the visualized attributes of the cluster members. This study contributes towards using interoperability standards to record learner's online reading behaviors and demonstrate how teaching and learning activities can be supported by xAPI when such experiences are distributed across various learning tools. © 30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings.},
	author_keywords = {Extensive Reading; Learning Analytics; Learning Strategies; xAPI},
	keywords = {Cluster analysis; Deregulation; E-learning; Education computing; K-means clustering; Learning systems; Extensive reading; Language learning; Learner modeling; Learning analytic; Learning strategy; Potential structure; Reading activities; Self regulation; Target language; XAPI; Students},
	correspondence_address = {C.-Y. Hsu; Graduate School of Informatics, Kyoto University, Japan; email: hsu.chiayu.25t@st.kyoto-u.ac.jp},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Denden M. and Majumbar R. and Medina L.C. and Mishra S. and Murthy S. and Panjaburee P. and Sun D.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972149-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Rets2023149,
	author = {Rets, Irina and Herodotou, Christothea and Gillespie, Anna},
	title = {Six Practical Recommendations Enabling Ethical Use of Predictive Learning Analytics in Distance Education},
	year = {2023},
	journal = {Journal of Learning Analytics},
	volume = {10},
	number = {1},
	pages = {149 – 167},
	doi = {10.18608/jla.2023.7743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150712301&doi=10.18608%2fjla.2023.7743&partnerID=40&md5=8d7012c4d52fdeb1d9f321ddbe994c68},
	affiliations = {Institute of Educational Technology, The Open University, Walton Hall, Milton Keynes, MK76AA, United Kingdom},
	abstract = {The progressive move of higher education institutions (HEIs) towards blended and online environments, accelerated by COVID-19, and their access to a greater variety of student data has heightened the need for ethical learning analytics (LA). This need is particularly salient in light of a lack of comprehensive, evidence-based guidelines on ethics that address gaps voiced in LA ethics research. Studies on the topic are predominantly conceptual, representing mainly institutional rather than stakeholder views, with some areas of ethics remaining underexplored. In this paper, we address this need by using a case of four years of interdisciplinary research in developing the award-winning Early Alerts Indicators (EAI) dashboard at a distance learning university. Through a lens focused on ethical considerations and informed by the practical approach to ethics, we conducted a case study review, using 10 relevant publications that report on the development and implementation of the tool. Our six practical recommendations on how to ethically engage with LA can inform an ethical development of LA that not only protects student privacy, but also ensures that LA tools are used in ways that effectively support student learning and development. © 2023, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {case study; Learning analytics; learning analytics dashboards; practical ethics},
	correspondence_address = {I. Rets; Institute of Educational Technology, The Open University, Milton Keynes, Walton Hall, MK76AA, United Kingdom; email: irina.rets@open.ac.uk},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sciarrone202313,
	author = {Sciarrone, Filippo and Sferratore, Francesco Paolo and Temperini, Marco},
	title = {AI4T: A Teacher’s Dashboard for Visual Rendering of Students’ Assignments in Massive Open Online Courses},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14409 LNCS},
	pages = {13 – 27},
	doi = {10.1007/978-981-99-8385-8_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178620967&doi=10.1007%2f978-981-99-8385-8_2&partnerID=40&md5=f5c728e7b6aba606fb82e091310f12ab},
	affiliations = {Faculty of Technological and Innovation Sciences, Universitas Mercatorum, Piazza Mattei, 10, Rome, Italy; Pegaso University, Piazza Trieste e Trento, 48, Naples, Italy; DIAG-Department of Computer, Control and Management Engineering, Sapienza, University of Rome, Rome, Italy},
	abstract = {The COVID-19 pandemic has changed the way we do education in recent years. In fact, thanks in part to the progress of the Internet, there has been an exponential growth in courses delivered in distance mode. Among these, Massive Open Online Courses are undoubtedly those courses where the growth in enrolments has been strongest: in fact, even in universities there are distance courses with thousands of enrolments. In this scenario, it is really difficult, if not impossible, for a teacher to monitor the learning process of her/his class, unless he or she is equipped with one or more tools enabling him or her to follow the students, in their learning process, in a more analytical manner. In this paper we propose a web tool, the AI4T system, a dashboard usable as a web application, which allows the teacher, once an assignment has been assigned to her/his students, to monitor their outcomes through a representation in a two-dimensional space. We present an initial experiment with encouraging results. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Dashboard; Deep Learning; Learning Analytics; MOOCs},
	keywords = {COVID-19; Deep learning; E-learning; Learning systems; Teaching; Dashboard; Deep learning; Distance course; Exponential growth; Learning analytic; Learning process; Massive open online course; MOOC; Student assignments; Teachers'; Students},
	correspondence_address = {F. Sciarrone; Faculty of Technological and Innovation Sciences, Universitas Mercatorum, Rome, Piazza Mattei, 10, Italy; email: filippo.sciarrone@unimercatorum.it},
	editor = {Xie H. and Lai C.-L. and Chen W. and Xu G. and Popescu E.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981998384-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Majumdar2022481,
	author = {Majumdar, Rwitajit and Ogata, Hiroaki and Prasad, Prajish and Warriem, Jayakrishnan M.},
	title = {LA-ReflecT: A Platform for Data-informed Reflections in Micro-learning Tasks},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {2},
	pages = {481 – 485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151061045&partnerID=40&md5=867e9458fa4f3088abafdd60f27455cb},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Japan; NPTEL, Indian Institute of Technology Madras, India; Department of Computer Science, FLAME University, India},
	abstract = {Micro-learning experiences are built with short, focused activities in a technology-enhanced learning environment and also incorporates an assessment. While there are different operationalizations of the activity, it aims at learning byte-sized contents. The research initiates a design of LA-ReflecT, a platform for conducting micro-learning activities with a data-informed reflection cycle. Activities can have multiple short tasks which can have different multimedia and interaction elements. User interactions are logged in standardized xAPI format. Processed logs are presented in a dashboard to enable student's in-activity reflection. We present an initial draw implications of standardized interaction tracking that the application enables for further research on an embodied narrative of learning. © ICCE 2022.All rights reserved.},
	author_keywords = {LA-ReflecT; Learning Analytics; Learning Platform; Microlearning},
	keywords = {LA-reflect; Learning Activity; Learning analytic; Learning environments; Learning experiences; Learning platform; Learning tasks; Micro-learning; Technology enhanced learning; User interaction},
	correspondence_address = {R. Majumdar; Academic Center for Computing and Media Studies, Kyoto University, Japan; email: dr.rwito@gmail.com},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Abdul Aziz N.A. and Chang M. and Diwakar A. and How S.P. and Jiang B. and Kaewsa-Ard A. and Kim M.S. and Lai C.-L. and Lee V.Y.A. and Liu L.Y. and Ogata H. and Omar M.K. and Shu H. and Song Y. and Yun W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968900-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Nakamura2022702,
	author = {Nakamura, Kohei and Horikoshi, Izumi and Ogata, Hiroaki},
	title = {Teaching Analytics Across Multiple Systems: A Case Study at a Junior High School in Japan},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {2},
	pages = {702 – 704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151046061&partnerID=40&md5=9b67e1c6639160ce1e1753b7e4fb1a38},
	affiliations = {Graduate School of Informatics, Kyoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan},
	abstract = {This study analyzed and visualized the daily behaviors of teachers on multiple systems using Experience API (xAPI). The results revealed that the learning management system was routinely used, while the learning analytics dashboard was not. Further, we examined how the teacher used the dashboard during the experimental classes with a learning analytics researcher. The results showed that the use of e-book readers and dashboards was encouraged on the day when the researcher attended class together. Additionally, the timings when the teacher checked the dashboard were getting earlier in each class. These results imply that the repeated use of a dashboard and the help of an expert foster the literacy of teachers in using educational data in their classes. © ICCE 2022.All rights reserved.},
	author_keywords = {Data Literacy; Multiple Systems; Teaching Analytics; xAPI},
	keywords = {Case-studies; Daily behaviors; Data literacy; E-books; Junior high schools; Learning management system; Multiple systems; Teachers'; Teaching analytics; XAPI; Learning systems},
	correspondence_address = {K. Nakamura; Graduate School of Informatics, Kyoto University, Japan; email: nakamura.kohei.42r@st.kyoto-u.ac.jp; ; },
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Abdul Aziz N.A. and Chang M. and Diwakar A. and How S.P. and Jiang B. and Kaewsa-Ard A. and Kim M.S. and Lai C.-L. and Lee V.Y.A. and Liu L.Y. and Ogata H. and Omar M.K. and Shu H. and Song Y. and Yun W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968900-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ahmad2023423,
	author = {Ahmad, Atezaz and Kiesler, Natalie and Schiffner, Daniel and Schneider, Jan and Wollny, Sebastian},
	title = {Caught in the Lifelong Learning Maze: Helping People with Learning Analytics and Chatbots to Find Personal Career Paths},
	year = {2023},
	journal = {International Journal of Information and Education Technology},
	volume = {13},
	number = {3},
	pages = {423 – 429},
	doi = {10.18178/ijiet.2023.13.3.1822},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160266272&doi=10.18178%2fijiet.2023.13.3.1822&partnerID=40&md5=16610ff10e3a6cce652cfdfc31fb53d0},
	affiliations = {Leibniz Institute for Research and Information in Education, Frankfurt, Germany},
	abstract = {Current lifelong learning platforms offer users a query option to select a wide variety of courses. However, finding a suitable course among the seemingly endless catalogs of options presented by the platforms is not straightforward. We argue that digital counseling can enhance this process. In this paper, we present a set of three formative studies where we explored the main aspects that can provide the counseling needed. The methods comprise an analysis of user profile characteristics and learning analytics indicators (e.g., learning progress/self-regulation) by means of an expert workshop, evaluating the feasibility of current technologies (e.g., natural language processing) for automatically assessing users' competencies, and a survey on the use of Chatbots as the interaction interface between the users and the lifelong learning portals. The analysis resulted in the extraction of basic requirements for digital counseling. We conclude the paper by presenting a system design derived from these studies. © 2023 by the authors.},
	author_keywords = {Chatbot; dashboard; indicators; Learning analytics; lifelong learning; natural language processing},
	correspondence_address = {A. Ahmad; Leibniz Institute for Research and Information in Education, Frankfurt, Germany; email: a.ahmad@dipf.de},
	publisher = {International Journal of Information and Education Technology},
	issn = {20103689},
	language = {English},
	abbrev_source_title = {Int. J. Inf.  Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Aguilar-Cruz2022137,
	author = {Aguilar-Cruz, Paola Julie},
	title = {Understanding students’ engagement with a Serious Game to learn English: A sociocultural perspective},
	year = {2022},
	journal = {International Journal of Serious Games},
	volume = {9},
	number = {4},
	pages = {137 – 152},
	doi = {10.17083/ijsg.v9i4.554},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141387559&doi=10.17083%2fijsg.v9i4.554&partnerID=40&md5=11e4305ead4865675d6ac04c78f2001c},
	affiliations = {Universidad de la Amazonia, Caquetá, Florencia, Colombia; Jorge Eliécer Gaitán High School, Caquetá, Florencia, Colombia},
	abstract = {Research studies have demonstrated that students’ sociocultural background influences their learning and engagement processes in classroom activities. Additionally, research studies have shown inconclusive effects of how Serious Games improve students’ engagement. Therefore, this article describes the results of a research study that analyzed, from a sociocultural perspective, the incorporation of the Serious Game (SG) Be (the) 1: Challenge in a classroom setting with forty-seven high school students who live in vulnerable conditions in the Amazonian region of Colombia. A revised version of the Motivation Attitude Knowledge Engagement (MAKE) survey was implemented to inquire students’ engagement with the game, including open-ending questions. Moreover, game learning analytics (GLA) from a teachers’ dashboard was collected to track students’ achievements and progress during gameplay. Data was analyzed, triangulated, and interpreted through the lenses of the Reflective Play Activity Model (RPAM) to have a better understanding of students’ interactions with the game in the classroom. The main findings reveal that (1) when students developed intrinsic play, their cognitive, emotional, and behavioral engagement was low, but when they developed extrinsic play, their engagement increased, and (2) GLA serves to predict students’ engagement with a SG in marginalized settings. Additionally, this study refines the RPAM by deepening how this model can occur in face-to-face settings with students who, due to their sociocultural background, do not have access to discuss, construct, exchange, and share information about game features in online environments. © 2022, Serious Games Society. All rights reserved.},
	author_keywords = {educational technology; English language learning; game learning analytics; Serious games; student engagement},
	correspondence_address = {P.J. Aguilar-Cruz; Universidad de la Amazonia, Florencia, Caquetá, Colombia; email: paolaaguilarcruz@gmail.com},
	publisher = {Serious Games Society},
	issn = {23848766},
	language = {English},
	abbrev_source_title = {Int. j. serious games},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Dülger20236,
	author = {Dülger, Melis},
	title = {Developing Students' Self-regulated Learning Skills with Teacher Classroom Analytics Enhancing Teachers' Direct Instruction of Self-regulated Learning Strategies},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3539},
	pages = {6 – 11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178274276&partnerID=40&md5=bca6e508204b97a788be6ea00d056b81},
	affiliations = {Utrecht University, Heidelberglaan 1, Utrecht, 3584 CS, Netherlands},
	abstract = {Developing self-regulated learning (SRL) skills is crucial for students. They develop these skills as early as during the primary school years. Nonetheless, previous research indicates that students struggle with monitoring and controlling their learning. Teachers play a substantial role in developing SRL. Young students benefit from direct instruction in SRL strategies. However, for teachers monitoring students' SRL and providing appropriate and timely support are challenging tasks. Adaptive learning technologies (ALTs) are widely used in educational settings to support math learning. Although ALTs externally regulate the learning process by adapting the difficulty of problems, students are still responsible for choosing the appropriate level of effort, monitoring their accuracy, and setting learning goals. Teacher dashboards visualizing the learning process on ALTs may provide teachers with information on the learners' progress which might help them monitor students' SRL processes effectively. However, most dashboards do not provide information on SRL and target teachers' instruction. Thus, we aim to develop a teacher dashboard that provides visualized information on classroom-level SRL to facilitate teachers' instruction of SRL strategies. Subsequently, we will investigate whether this classroom-level teacher dashboard enhances teachers' instruction of SRL strategies, which may increase the SRL skills of primary school students during math learning. © 2023 Copyright for this paper by its authors. The use permitted unde Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {adaptive learning technologies; direct strategy instruction; learning analytics; Self-regulated learning; teacher dashboards},
	keywords = {Learning systems; Adaptive learning; Adaptive learning technology; Direct strategy instruction; Learning analytic; Learning skills; Learning technology; Self-regulated learning; Self-regulated learning strategies; Teacher dashboard; Teachers'; Students},
	editor = {Di Mitri D. and DIPF, Leibniz Institute for Research and Information in Education, Rostocker Str. 6, Frankfur and Ortega-Arranz A. and Universidad de Valladolid, School of Computer Engineering, Paseo de Belen 15, Valladolid and Poquet O. and Technical University of Munich, TUM School of Social Sciences and Technology, Arcisstrasse 2180333, Munich},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {Proceedings of the 18th European Conference on Technology Enhanced Learning, ECTEL 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171981574&partnerID=40&md5=a95eb3259f673d17be9a594d53f45e2e},
	abstract = {The proceedings contain 74 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: The “How” Matters: Evaluating Different Video Types for Cybersecurity MOOCs; Role of Multimodal Learning Systems in Technology-Enhanced Learning (TEL): A Scoping Review; Broader and Deeper: A Multi-Features with Latent Relations BERT Knowledge Tracing Model; why You Should Give Your Students Automatic Process Feedback on Their Collaboration: Evidence from a Randomized Experiment; interactive Web-Based Learning Materials Vs. Tutorial Chatbot: Differences in User Experience; Assessing the Quality of Multiple-Choice Questions Using GPT-4 and Rule-Based Methods; early Prediction of Learners At-Risk of Failure in Online Professional Training Using a Weighted Vote; how to Characterize and Analyze the Computational Thinking Skills of a Learning Game?; Evaluating ChatGPT’s Decimal Skills and Feedback Generation in a Digital Learning Game; a Transformer-Based Approach for the Automatic Generation of Concept-Wise Exercises to Provide Personalized Learning Support to Students; designing a Revision System: An Exploratory Qualitative Study to Identify the Needs of French Teachers and Students; Evaluation of a Hybrid AI-Human Recommender for CS1 Instructors in a Real Educational Scenario; Evaluating the Impact and Usability of an AI-Driven Feedback System for Learning Design; single or Multi-page Learning Analytics Dashboards? Relationships Between Teachers’ Cognitive Load and Visualisation Literacy; designing Technology for Doctoral Persistence and Well-Being: Findings from a Two-Country Value-Sensitive Inquiry into Student Progress; a Critical Consideration of the Ethical Implications in Learning Analytics as Data Ecology; learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements; understanding Peer Feedback Contributions Using Natural Language Processing; AI and Narrative Scripts to Educate Adolescents About Social Media Algorithms: Insights About AI Overdependence, Trust and Awareness; analyzing Learners’ Perception of Indicators in Student-Facing Analytics: A Card Sorting Approach; exploring the Potential of Immersive Virtual Environments for Learning American Sign Language.},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tran2022100,
	author = {Tran, Tich Phuoc and Jan, Tony and Kew, Si Na},
	title = {Learning Analytics for Improved Course Delivery: Applications and Techniques},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {100 – 106},
	doi = {10.1145/3568739.3568758},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147434890&doi=10.1145%2f3568739.3568758&partnerID=40&md5=dfe22372e11751f0383f780c68bec3a5},
	affiliations = {University of New South Wales, Australia; Torrens University, Australia; Universiti Teknologi Malaysia, Malaysia},
	abstract = {Learning Analytics (LA) is an emerging research field that harnesses the power of data modelling, data mining and visualization to enhance the understanding of teaching and learning as well as supporting the personalization of education. Typical LA applications include dashboards displaying course progress, intelligence reports tracking the use of educational resources, and systems that predict students’ academic performance and identify struggling students. In this article, we review the major elements of LA applications, including typical workflows, data types, and approaches to analytics. In addition to the basic reporting tools available in Learning Management Systems (LMSs), the article provides insights into how Machine Learning (ML) can detect the students at risk of failing. Finally, six educational applications in which data analytics helps improve course delivery are discussed. © 2022 Association for Computing Machinery.},
	author_keywords = {Learning analytics; Machine learning; Student at risk detection; Visual analytics},
	keywords = {Data Analytics; Data mining; Data visualization; Machine learning; Visualization; Course delivery; Learning analytic; Machine-learning; Modeling data; Power; Research fields; Risk detections; Student at risk detection; Teaching and learning; Visual analytics; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039809-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Chen2023,
	author = {Chen, Li and Geng, Xuewang and Lu, Min and Shimada, Atsushi and Yamada, Masanori},
	title = {How Students Use Learning Analytics Dashboards in Higher Education: A Learning Performance Perspective},
	year = {2023},
	journal = {SAGE Open},
	volume = {13},
	number = {3},
	doi = {10.1177/21582440231192151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169316888&doi=10.1177%2f21582440231192151&partnerID=40&md5=af23e2b97538c54b206f8c8ccb6d91cd},
	affiliations = {Kyushu University, Fukuoka, Japan; Akita University, Akita, Japan},
	abstract = {Developed to maximize learning performance, learning analytics dashboards (LAD) are becoming increasingly commonplace in education. An LAD’s effectiveness depends on how it is used and varies according to users’ academic levels. In this study, two LADs and a learning support system were used in a higher education course to support students’ cognitive and self-regulated learning (SRL) strategies. A total of 54 students’ learning logs on three systems and their learning performance scores were collected; descriptive statistics of learning behaviors, Mann-Whitney U test, and lag sequential analysis were used to explore how students with different learning performances used LADs to support their learning. Compared to low-performers, high-performers used the LADs more frequently during preview and review phases and conducted more monitoring and reflection strategies to support their learning. Finally, some practical implications for improving the design and use of LADs were provided. © The Author(s) 2023.},
	author_keywords = {learning analytics dashboard; learning behavior; learning performance; learning strategy; self-regulated learning},
	correspondence_address = {L. Chen; Kyushu University, Fukuoka, Japan; email: chenli@mark-lab.net},
	publisher = {SAGE Publications Inc.},
	issn = {21582440},
	language = {English},
	abbrev_source_title = {SAGE Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Yousef20235460,
	author = {Yousef, Ahmed Mohamed Fahmy and Khatiry, Ahmed Ramadan},
	title = {Cognitive versus behavioral learning analytics dashboards for supporting learner’s awareness, reflection, and learning process},
	year = {2023},
	journal = {Interactive Learning Environments},
	volume = {31},
	number = {9},
	pages = {5460 – 5476},
	doi = {10.1080/10494820.2021.2009881},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120610737&doi=10.1080%2f10494820.2021.2009881&partnerID=40&md5=e2f83e040ec6ee9f9c56c93054d8f323},
	affiliations = {Educational Technology Department, Faculty of Specific Education, Fayoum University, Fayoum, Egypt; Foundations of Education Department, Faculty of Education, Fayoum University, Fayoum, Egypt; Educational Studies Department, Rustaq College of Education, University of Technology and Applied Sciences, Muscat, Oman},
	abstract = {Several governments across the world have temporarily closed educational institutions due to the COVID-19 pandemic. In response, numerous universities have seen a growing trend towards online learning scenarios. Thus, learning takes place not just within a person, but within and across the networks. However, the current implementations of open learning scenarios are facing many challenges, including: a) there is no systematic feature to track, evaluate and report the online learning activities of students; b) lack of immediacy and personal feedback; and c) lack of self-reflection. Consequently, Learning Analytics (LA) is one of the most distinguished solutions to address these challenges. In this study, the two kinds of LA dashboard, behavioral and cognitive, have been investigated. The methodological approach taken in this investigation was adopted from a design-based research framework, which blends empirical educational research with the theory-driven design of online learning environments. The initial sample consisted of 320 undergraduate nursing students. The cohort was divided into two groups according to the two types of LA dashboard. The findings have argued that behavioral dashboards took precedence over data evaluation items, while cognitive dashboards had the advantage in achieving the goals of LA–e.g., awareness, self-reflection, and impact on learning process. © 2021 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {adaptive learning; distributed learning; Learning analytics; personalized learning; student dashboard},
	correspondence_address = {A.M.F. Yousef; Educational Technology Department, Faculty of Specific Education, Fayoum University, Fayoum, Egypt; email: ahmed.fahmy@fayoum.edu.eg},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Drzyzga2023262,
	author = {Drzyzga, Gilbert and Harder, Thorleif},
	title = {A Three Level Design Study Approach to Develop a Student-Centered Learner Dashboard},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1996 CCIS},
	pages = {262 – 281},
	doi = {10.1007/978-3-031-49425-3_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180791151&doi=10.1007%2f978-3-031-49425-3_16&partnerID=40&md5=bee5c57c2784499938a92a029ee02e48},
	affiliations = {Institute of Interactive Systems, Technische Hochschule Lübeck, Lübeck, Germany},
	abstract = {Online programs risk higher student dropout rates. Supporting learning tools such as learning analytics dashboards (LADs) can promote self-regulated learning and positively impact student outcomes. In this paper, a three-level design study is presented that demonstrates the reduction of cognitive load at multiple levels when students are involved in the LAD design process. Through a user-centered design process (including requirements analysis and expert interviews), a wireframe was developed using participatory methods and evaluated by 24 university students using the laws of Gestalt psychology, resulting in a clickable, low-fidelity prototype (LFD). This was then evaluated by 24 university students using the interaction principles of EN ISO 9241-110:2020. The refined LFD was further evaluated with university students in an eye-tracking study using the thinking-aloud technique (n = 10). The feedback emphasized the importance of participatory design and provided critical insights into the most effective use of the LAD and its elements, taking into account cognitive aspects. The results showed significant optimization in the small details and the big picture in the use of content elements, e.g., it is a crucial part to create a navigation structure adapted to the needs of an LAD and it is beneficial to present a reduced level of information during the initial access, with the option to add or access additional elements as needed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Cognitive load; Design process; Design study; Eye-tacking & thinking aloud; Gestalt laws; Interaction principles; Self-regulated learning; Usability; User experience; User-centered design},
	keywords = {Eye tracking; Students; Cognitive loads; Design studies; Design-process; Eye-tacking & thinking aloud; Gestalt law; Interaction principle; Self-regulated learning; Thinking aloud; Usability; Users' experiences; User centered design},
	correspondence_address = {G. Drzyzga; Institute of Interactive Systems, Technische Hochschule Lübeck, Lübeck, Germany; email: gilbert.drzyzga@th-luebeck.de},
	editor = {da Silva H.P. and da Silva H.P. and Cipresso P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303149424-6},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Haarde2023790,
	author = {Haarde, Fredrik and Khalil, Mohammad},
	title = {Poster: EduGraph: Dashboard for Personalised Feedback in Massive Open Online Courses},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {633 LNNS},
	pages = {790 – 795},
	doi = {10.1007/978-3-031-26876-2_75},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151132150&doi=10.1007%2f978-3-031-26876-2_75&partnerID=40&md5=11078e63c320d0986ded518a55188d0b},
	affiliations = {Centre for the Science of Learning and Technology, University of Bergen, Bergen, Norway},
	abstract = {This poster presents our work on exploring the data generated in an Open edX MOOC to understand how it can be analysed and used to impact learners’ motivation in online courses. The work presents the development of eduGraph, a learning analytics dashboard to disseminate insights about learners’ and their learning processes grounded in the self-regulated learning theory. Evaluations and conclusions are drawn thereafter. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Learning analytics; Massive open online courses (MOOCs); Personalised feedback; Self-regulated learning},
	keywords = {E-learning; Dashboard; Learner's motivations; Learning analytic; Learning process; Learning Theory; Massive open online course; Online course; Personalized feedback; Self-regulated learning; Curricula},
	correspondence_address = {M. Khalil; Centre for the Science of Learning and Technology, University of Bergen, Bergen, Norway; email: mohammad.khalil@uib.no},
	editor = {Auer M.E. and Pachatz W. and Rüütmann T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303126875-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Valle20232563,
	author = {Valle, Natercia and Antonenko, Pavlo and Valle, Denis},
	title = {Dashboard Applications to Support Motivation: A Design Case},
	year = {2023},
	journal = {Learning, Design, and Technology: An International Compendium of Theory, Research, Practice, and Policy},
	pages = {2563 – 2599},
	doi = {10.1007/978-3-319-17461-7_184},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208298296&doi=10.1007%2f978-3-319-17461-7_184&partnerID=40&md5=47226d6a6d71054528b8a5a7f1b56819},
	affiliations = {University of Florida, Gainesville, FL, United States},
	abstract = {Motivation plays a critical role in learners’ behavior, continuous engagement with an activity or topic, and academic achievement. While motivation is crucial in any learning situation, it is particularly beneficial in the context of online learning where cognitive and social engagement can be enhanced or restrained based on courses’ design, facilitation, and resources. Despite the influence of motivation on learning performance, there is still a knowledge gap in how to design and implement technology-enhanced applications to support learners’ motivation in online learning environments. Subscribing to the goal orientation and situated expectancy-value theories, this design case addresses this gap by describing the collaborative and iterative processes involved in the conceptualization, design, early interface evaluation, and implementation of learner-facing learning analytics dashboards to promote motivation in the context of an online statistics course. This case study highlights the recursive nature of the design, discusses the main implications and challenges of the design case, and provides a detailed technical description to illustrate the dashboards presented. Annotated programming codes are also provided along with an example of the dashboard that readers can access. © Springer Nature Switzerland AG 2023.},
	author_keywords = {Design case; Learning analytics dashboards; Motivation; Online learning},
	correspondence_address = {N. Valle; University of Florida, Gainesville, United States; email: nvalle@ufl.edu},
	publisher = {Springer International Publishing},
	isbn = {978-331917461-7; 978-331917460-0},
	language = {English},
	abbrev_source_title = {Learning, Design, and Technology: An International Compendium of Theory, Research, Practice, and Policy},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Pons202356,
	author = {Pons, Mika and Bruel, Jean-Michel and Raclet, Jean-Baptiste and Silvestre, Franck},
	title = {Finding Behavioral Indicators from Contextualized Commits in Software Engineering Courses with Process Mining},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14387},
	pages = {56 – 68},
	doi = {10.1007/978-3-031-48639-5_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180626730&doi=10.1007%2f978-3-031-48639-5_5&partnerID=40&md5=baec841d5bb3a02ddf937407459de514},
	affiliations = {IRIT, Université Toulouse 1 Capitole,  Toulouse, France; IRIT, Université Toulouse 2 Jean Jaurès, Toulouse, France; IRIT, Université Toulouse 3 Paul Sabatier, Toulouse, France},
	abstract = {Git4School is a dashboard helping teachers to monitor and make decisions during Git-based lab sessions in higher education com- puter science programs. This tool makes it possible to visualize the commits made by students over time according to the context and, in particular, the type of pedagogical intervention by the teacher (discussions between students on the problem, dissemination of a solution, etc.). Despite its visualizations providing indicators for decision-making, the tool does not provide information about the student’s behavior. There are existing studies dealing with Process Mining (PM) in education, specifically in computer science courses and using Git. Through an empirical exploratory study, we explore the possibility of taking advantage of these contextualized commits using PM. We analyzed data from 5 teaching units covering different higher education levels using the bupaR library. Firstly, we discovered promising indicators to predict students’ behavior during a lab session. Secondly, we identified several possibilities for future research on PM and contextualized commits. Finally, we have established a set of recommendations to help analyze contextualized commits using PM. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Behavioral patterns; Educational data mining; Git; Learning analytics; Process mining},
	keywords = {Data mining; Decision making; Education computing; Engineering education; Software engineering; Teaching; Behavioral indicators; Behavioral patterns; Educational data mining; Git; High educations; Learning analytic; Process mining; Science projects; Software engineering course; Teachers'; Students},
	correspondence_address = {M. Pons; IRIT, Université Toulouse 1 Capitole,  Toulouse, France; email: mika.pons@irit.fr},
	editor = {Capozucca A. and Ebersold S. and Bruel J. and Meyer B.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303148638-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Takami202291,
	author = {Takami, Kyosuke and Miyabe, Gou and Flanagan, Brendan and Ogata, Hiroaki},
	title = {Automated Test Set Quiz Maker Optimizing Solving Time and Parameters of Bayesian Knowledge Tracing Model Extracted from Learning Log},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {2},
	pages = {91 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151065453&partnerID=40&md5=78d9ba61048010f5113bf10a70af8ca8},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Japan; Saikyo Junior High School Attached to Saikyo High School, Kyoto, Japan},
	abstract = {Creating a set of quizzes for the students' test is almost an irreplaceable task to teachers. In practice, a teacher could use a learning analytics dashboard while creating a test to control the quiz difficulty and the amount of time it takes to solve. This paper draws inspiration from this practical example, and we propose an automated test set quiz maker by optimizing the time and learning parameters that have been estimated from the analysis of learning logs. First, we estimate the Bayesian Knowledge Tracing (BKT) model parameters: in particular the guess and slip probability from the quiz answer log history. The system automatically generates a test set of quizzes if the user inputs the desired amount of time it should take to solve the test by optimizing the selection of quizzes based on BKT parameters and estimated solving time. This function is expected to reduce the burden of preparing examination questions for teachers, and it can be used as a trial test before the exam for students. © ICCE 2022.All rights reserved.},
	author_keywords = {Automated test set quiz generation; Bayesian Knowledge Tracing; Knapsack Problem; Mathematical Optimization},
	keywords = {Automation; Learning systems; Parameter estimation; Statistical tests; Automated test; Automated test set quiz generation; Bayesian knowledge tracings; Knapsack problems; Mathematical optimizations; Student - tests; Teachers'; Test sets; Time parameter; Tracing model; Combinatorial optimization},
	correspondence_address = {K. Takami; Academic Center for Computing and Media Studies, Kyoto University, Japan; email: takami.kyosuke.2z@kyoto-u.ac.jp},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Abdul Aziz N.A. and Chang M. and Diwakar A. and How S.P. and Jiang B. and Kaewsa-Ard A. and Kim M.S. and Lai C.-L. and Lee V.Y.A. and Liu L.Y. and Ogata H. and Omar M.K. and Shu H. and Song Y. and Yun W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968900-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wang2023,
	author = {Wang, Han and Huang, Tao and Zhao, Yuan and Hu, Shengze},
	title = {The Impact of Dashboard Feedback Type on Learning Effectiveness, Focusing on Learner Differences},
	year = {2023},
	journal = {Sustainability (Switzerland)},
	volume = {15},
	number = {5},
	doi = {10.3390/su15054474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149887516&doi=10.3390%2fsu15054474&partnerID=40&md5=2d47f6e4b6e9c28502b2343e3f73163c},
	affiliations = {Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Faculty of Education, Jiujiang University, Jiujiang, 332005, China},
	abstract = {With the exponential growth of educational data, increasing attention has been given to student learning supported by learning analytics dashboards. Related research has indicated that dashboards relying on descriptive analytics are deficient compared to more advanced analytics. However, there is a lack of empirical data to demonstrate the performance and differences between different types of analytics in dashboards. To investigate these, the study used a controlled, between-groups experimental method to compare the effects of descriptive and prescriptive dashboards on learning outcomes. Based on the learning analytics results, the descriptive dashboard describes the learning state and the prescriptive dashboard provides suggestions for learning paths. The results show that both descriptive and prescriptive dashboards can effectively promote students’ cognitive development. The advantage of prescriptive dashboard over descriptive dashboard is its promotion in learners’ learning strategies. In addition, learners’ prior knowledge and learning strategies determine the extent of the impact of dashboard feedback on learning outcomes. © 2023 by the authors.},
	author_keywords = {dashboard; individual learner factors; learning analytics; learning effectiveness; personalized feedback},
	keywords = {education; knowledge based system; learning; research work; student},
	correspondence_address = {T. Huang; Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; email: tmht@mail.ccnu.cn},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Simic2023,
	author = {Simic, Dejan and Leible, Stephan and Schmitz, Dennis and Gücük, Gian-Luca and Kučević, Emir},
	title = {Enhancing Project-based Learning through Data-driven Analysis and Visualisation: A Case Study},
	year = {2023},
	journal = {Australasian Conference on Information Systems, ACIS 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200159244&partnerID=40&md5=fbedb362d89341e12280f8c5de98193f},
	affiliations = {Department of Computer Science, University of Hamburg, Hamburg, Germany},
	abstract = {This paper investigates the application of data-driven analysis and visualisation to enhance project-based courses within a higher education setting. The research focuses on a digital course where students utilise digital tools such as Jira and Confluence, which generate event logs capturing students' actions. These event logs were leveraged in conjunction with process mining and business intelligence (BI) techniques to collect and analyse the data, visualised through the iterative development and evaluation of an artefact in the form of BI dashboards following the design science research paradigm. The dashboards provide lecturers with insights into student behaviour and progress, enabling them to derive actionable suggestions for adapting student behaviour. The findings demonstrate that incorporating data-driven approaches positively impacted student engagement and improved learning outcomes. This case study contributes to the fields of learning analytics and educational data mining, offering insights into utilising data-driven approaches to enhance project-based learning experiences. Copyright © 2023 Simic, Leible, Schmitz, Gücük, and Kučević.},
	author_keywords = {data analytics; design science research; educational data mining; Learning analytics; project-based courses},
	keywords = {Curricula; Data Analytics; Design; Digital devices; Iterative methods; Students; Visualization; Business-intelligence; Case-studies; Data analytics; Data-driven analysis; Design-science researches; Educational data mining; Event logs; Learning analytic; Project based learning; Project-based course; Data mining},
	publisher = {Association for Information Systems},
	language = {English},
	abbrev_source_title = {Australas. Conf. Inf. Syst., ACIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Eppler2023354,
	author = {Eppler, Martin and Spletter, Christian},
	title = {Knowledge Visualization for Learning in Higher Education Contexts: Systemizing the Field},
	year = {2023},
	journal = {Proceedings of the European Conference on Knowledge Management, ECKM},
	volume = {1},
	pages = {354 – 361},
	doi = {10.34190/eckm.24.1.1495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177877289&doi=10.34190%2feckm.24.1.1495&partnerID=40&md5=3a1433a85713f65e1ca09f81c36bd16e},
	affiliations = {Institute for Media and Communications Management (MCM-HSG), St. Gallen, Switzerland},
	abstract = {In contexts of higher learning, students must be supported effectively in developing their knowledge, skills, and competencies. Thus, faculty members (incl. lecturers and administrators) are faced with the management task to organize and align innovative teaching and learning formats. As we know from research, the use of knowledge visualization is both a facilitating tool for cognitive processing and learning itself, and for strategic decision-making processes within organizations. However, the literature on the types of (IT-enabled) knowledge visualization for learning in higher education contexts is highly fragmented and dispersed and includes different branches for researchers and practitioners. This makes it difficult to achieve an overview and find systematic and consistent visual approaches along students’ learning paths. By highlighting the role of knowledge visualization to support organizing innovative teaching and learning, we provide a systematic, structured overview of such approaches. The goal of this paper is thus to structure the field of knowledge visualization for lifelong and university-based learning based on seminal papers. For this purpose, we present a segmentation approach with six areas to analyse the role of knowledge visualization for learning in higher education contexts, namely: Visualizing Learning Offers (e.g., Curriculum Visualization Tools), Visual Learning Environments (e.g., Metaverse), Learning Content Visualization (e.g., Visual Variation Patterns), Visual Techniques for Learning (e.g., Concept Mapping), Visual Learning Analytics (e.g., Learner Dashboards), and Visualizing Learning Outcomes (e.g., Digital Course Badges). Based on systemizing key concepts, our paper concludes with promising future research avenues for each of the six areas, as well as for the domain of knowledge visualization for higher learning itself. We conclude with specific ideas how the area of visualizing learning offers can act as a spearhead for empirical research (and practice transfer) in the knowledge visualization domain. This should help practitioners and researchers from higher education contexts who consider lifelong learning as knowledge management task. © the authors, 2023. All Rights Reserved.},
	author_keywords = {Higher education; Knowledge management; Knowledge visualization; Lifelong learning; Segmentation approach},
	keywords = {Computer aided instruction; Curricula; Decision making; Learning systems; Students; Teaching; Visualization; High educations; Higher learning; Innovative learning; Innovative teaching; Knowledge Visualization; Life long learning; Management tasks; Segmentation approach; Teaching and learning; Visual learning; Knowledge management},
	editor = {Matos F. and Rosa A.},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {20488963},
	isbn = {978-191458773-3},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Knowl. Manage., ECKM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jaramillo-Morillo20221574,
	author = {Jaramillo-Morillo, Daniel and Ruipérez-Valiente, José A. and Burbano Astaiza, Claudia Patricia and Solarte, Mario and Ramirez-Gonzalez, Gustavo and Alexandron, Giora},
	title = {Evaluating a learning analytics dashboard to detect dishonest behaviours: A case study in small private online courses with academic recognition},
	year = {2022},
	journal = {Journal of Computer Assisted Learning},
	volume = {38},
	number = {6},
	pages = {1574 – 1588},
	doi = {10.1111/jcal.12734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137199103&doi=10.1111%2fjcal.12734&partnerID=40&md5=a82c370c3063ebb1e2971a616c2d3860},
	affiliations = {Departamento de Telemática, Universidad del Cauca, Popayán, Colombia; Ingeniería de Sistemas, Fundación Universitaria de Popayán, Popayán, Colombia; Department of Information and Communications Engineering, University of Murcia, Murcia, Spain; Departamento de Educación Física Recreación y Deporte, Universidad del Cauca, Popayán, Colombia; Department of Science Teaching, Weizmann Institute of Science, Rehovot, Israel},
	abstract = {Background: Small private online courses (SPOCs) are one of the strategies to introduce the massive open online courses (MOOCs) within the university environment and to have these courses validates for academic credit. However, numerous researchers have highlighted that academic dishonesty is greatly facilitated by the online context in which SPOCs are offered. And while numerous algorithms have already been proposed, no research has been performed on how to transfer this information to instructors, so that they can intervene and decrease the prevalence of this issue. Objectives: In this article, we present a qualitative evaluation of a tool for detecting and monitoring students suspected of academic dishonesty in SPOCs in Selene, a Colombian instance of Open edX. Methods: The evaluation was carried out through semi-structured interviews with four instructors who taught SPOCs with academic recognition at the University of Cauca. Results: The evaluation results indicated that participants found the dashboard reliable and appropriate to detect academic dishonesty behaviours in order to intervene in these cases. Implications: But interventions are difficult to systematise, need an institutional policy, and there is uncertainty about whether these interventions can actually contribute to decreasing academic dishonesty. © 2022 John Wiley & Sons Ltd.},
	author_keywords = {academic dishonesty; educational data mining; learning analytics; online learning; visualization dashboard},
	correspondence_address = {D. Jaramillo-Morillo; Departamento de Telemática, Universidad del Cauca, Popayán, Colombia; email: dajaramillo@unicauca.edu.co; J.A. Ruipérez-Valiente; Department of Information and Communications Engineering, University of Murcia, Murcia, Spain; email: jruiperez@um.es},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Alfredo202357,
	author = {Alfredo, Riordan Dervin and Nie, Lanbing and Kennedy, Paul and Power, Tamara and Hayes, Carolyn and Chen, Hui and McGregor, Carolyn and Swiecki, Zachari and Gaševic, Dragan and Martinez-Maldonado, Roberto},
	title = {"That Student Should be a Lion Tamer!" StressViz: Designing a Stress Analytics Dashboard for Teachers},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {57 – 67},
	doi = {10.1145/3576050.3576058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149290861&doi=10.1145%2f3576050.3576058&partnerID=40&md5=b589d597176da4468a5a40654bf1968d},
	affiliations = {Monash University, Australia; University of Technology Sydney, Australia; University of Sydney, Australia; Ontario Tech University, Canada},
	abstract = {In recent years, there has been a growing interest in creating multimodal learning analytics (LA) systems that automatically analyse students' states that are hard to see with the "naked eye", such as cognitive load and stress levels, but that can considerably shape their learning experience. A rich body of research has focused on detecting such aspects by capturing bodily signals from students using wearables and computer vision. Yet, little work has aimed at designing end-user interfaces that visualise physiological data to support tasks deliberately designed for students to learn from stressful situations. This paper addresses this gap by designing a stress analytics dashboard that encodes students' physiological data into stress levels during different phases of an authentic team simulation in the context of nursing education. We conducted a qualitative study with teachers to understand (i) how they made sense of the stress analytics dashboard; (ii) the extent to which they trusted the dashboard in relation to students' cortisol data; and (iii) the potential adoption of this tool to communicate insights and aid teaching practices.  © 2023 ACM.},
	author_keywords = {Affective computing; Healthcare education; LA dashboard; Multimodal dataset; Stress detection; Visualisation},
	keywords = {Cognitive systems; Human engineering; Psychophysiology; User interfaces; Affective Computing; Analytics systems; Health care education; Learning analytic dashboard; Multi-modal dataset; Multi-modal learning; Physiological data; Stress detection; Stress levels; Teachers'; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Herodotou202368,
	author = {Herodotou, Christothea and Maguire, Claire and Hlosta, Martin and Mulholland, Paul},
	title = {Predictive Learning Analytics and University Teachers: Usage and perceptions three years post implementation},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {68 – 78},
	doi = {10.1145/3576050.3576061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149262065&doi=10.1145%2f3576050.3576061&partnerID=40&md5=3400efb79c5ad7082617f255cf83a0ef},
	affiliations = {The Open University, United Kingdom; The Swiss Distance University of Applied Sciences, Switzerland},
	abstract = {Predictive learning analytics (PLA) dashboards have been used by teachers to identify students at risk of failing their studies and provide proactive support. Yet, very few of them have been deployed at a large scale or had their use studied at a mature level of implementation. In this study, we surveyed 366 distance learning university teachers across four faculties three years after PLA has been made available across university as business as usual. Informed by the Unified Theory of Acceptance and Use of Technology (UTAUT), we present a context-specific version of UTAUT that reflects teachers' perceptions of PLA in distance learning higher education. The adoption and use of PLA was shown to be positively influenced by less experience in teaching, performance expectancy, self-efficacy, positive attitudes, and low anxiety, while negatively influenced by a lack of facilitating conditions and low effort expectancy, indicating that the type of technology and context within which it is used are significant factors determining our understanding of technology usage and adoption. This study provides significant insights as to how to design, apply and implement PLA with teachers in higher education.  © 2023 ACM.},
	author_keywords = {Predictive learning analytics; Technology Adoption; University teachers; UTAUT},
	keywords = {Education computing; Engineering education; Predictive analytics; Distance-learning; High educations; Large-scales; Post-implementation; Predictive learning analytic; Proactive supports; Teachers'; Technology adoption; The unified theory of acceptance and use of technology(UTAUT); University teachers; Distance education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039865-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Toyokawa2022742,
	author = {Toyokawa, Yuko and Horikoshi, Izumi and Majumdar, Rwitajit and Ogata, Hiroaki},
	title = {Digitally Enhanced Active Reading in a Learning Analytics Enhanced Environment},
	year = {2022},
	journal = {30th International Conference on Computers in Education Conference, ICCE 2022 - Proceedings},
	volume = {2},
	pages = {742 – 745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151058930&partnerID=40&md5=b9db658179b86292ece058f650830d3f},
	affiliations = {Graduate School of Informatics, Kyoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan},
	abstract = {Active reading (AR) strategies have learners challenge reading through deep engagement with the content to foster their independence and develop their performance and skills in reading. A number of studies have been conducted to examine the effectiveness of AR, yet there is no research that uses logs obtained from reading activities to scaffold and promote AR learning. Therefore, this study proposes to investigate AR from Learning Analytics (LA) perspectives. An e-book called BookRoll (BR) was used, and the logs obtained from the learning were visualized and shared as feedback. As part of it, we designed and developed Active Reading Dashboard (AR-D). In the framework of our LA-enhanced AR called Digitally Enhanced Active Reading (DEAR), AR experiments in language classes were conducted to reveal its effects. As a result, it was found that the process of AR could be visualized from learning logs, and DEAR could be applied in formal and informal learning contexts. The AR-D was found to influence learners' attitudes or perceptions toward reflecting on their own learning and striving to improve their reading strategies. As future work, continual implementation and verifying its application in different learning contexts are suggested. We shall also consider the importance of stakeholders' engagement in learning environments. © ICCE 2022.All rights reserved.},
	author_keywords = {Active reading; e-books; Learning Analytics; Learning Analytics dashboards; learning logs},
	keywords = {Computer aided instruction; E-learning; Electronic publishing; Active reading; E-books; Formal learning; Learning analytic; Learning analytic dashboard; Learning context; Learning log; Performance; Reading activities; Reading strategies; Scaffolds},
	correspondence_address = {Y. Toyokawa; Graduate School of Informatics, Kyoto University, Japan; email: toyokawa.yuko.59t@st.kyoto-u.ac.jp},
	editor = {Iyer S. and Shih J.-L. and Shih J.-L. and Chen W. and Chen W. and Khambari M.N.MD. and Abdul Aziz N.A. and Chang M. and Diwakar A. and How S.P. and Jiang B. and Kaewsa-Ard A. and Kim M.S. and Lai C.-L. and Lee V.Y.A. and Liu L.Y. and Ogata H. and Omar M.K. and Shu H. and Song Y. and Yun W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968900-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sabuncuoglu2023,
	author = {Sabuncuoglu, Alpay and Sezgin, T. Metin},
	title = {Developing a Multimodal Classroom Engagement Analysis Dashboard for Higher-Education},
	year = {2023},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {7},
	number = {EICS},
	doi = {10.1145/3593240},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163722064&doi=10.1145%2f3593240&partnerID=40&md5=52c4150de759410aa7280da10dc94842},
	affiliations = {UNVEST R and D Center, Istanbul, Turkey; Koc University, Is Bank AI Center, Istanbul, Turkey},
	abstract = {Developing learning analytics dashboards (LADs) is a growing research interest as online learning tools have become more accessible in K-12 and higher education settings. This paper reports our multimodal classroom engagement data analysis and dashboard design process and the resulting engagement dashboard. Our work stems from the importance of monitoring classroom engagement, which refers to students' active physical and cognitive involvement in learning that influences their motivation and success in a given course. To monitor this vital facade of learning, we developed an engagement dashboard using an iterative and user-centered process. We first created a multimodal machine learning model that utilizes face and pose features obtained from recent deep learning models. Then, we created a dashboard where users can view their engagement over time and discover their learning/teaching patterns. Finally, we conducted user studies with undergraduate and graduate-level participants to obtain feedback on our dashboard design. Our paper makes three contributions by (1) presenting a student-centric, open-source dashboard, (2) demonstrating a baseline architecture for engagement analysis using our open-Access data, and (3) presenting user insights and design takeaways to inspire future LADs. We expect our research to guide the development of tools for novice teacher education, student self-evaluation, and engagement evaluation in crowded classrooms.  © 2023 ACM.},
	author_keywords = {classroom engagement; interactive learning analytics dashboard; multimodal data analysis pipeline; multimodal learning dataset},
	keywords = {Data handling; Deep learning; Education computing; Information analysis; Learning systems; Modal analysis; Classroom engagement; Engagement analysis; Interactive learning; Interactive learning analytic dashboard; Learning dataset; Multi-modal; Multi-modal learning; Multimodal data analyse pipeline; Multimodal data analysis; Multimodal learning dataset; Students},
	publisher = {Association for Computing Machinery},
	issn = {25730142},
	language = {English},
	abbrev_source_title = {Proc. ACM Hum. Comput. Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access}
}

@ARTICLE{Hasnine2023,
	author = {Hasnine, Mohammad Nehal and Nguyen, Ho Tan and Tran, Thuy Thi Thu and Bui, Huyen T. T. and Akçapınar, Gökhan and Ueda, Hiroshi},
	title = {A Real-Time Learning Analytics Dashboard for Automatic Detection of Online Learners’ Affective States},
	year = {2023},
	journal = {Sensors},
	volume = {23},
	number = {9},
	doi = {10.3390/s23094243},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159372011&doi=10.3390%2fs23094243&partnerID=40&md5=18b9aef72f4dc9fa7e303f1f36b57edc},
	affiliations = {Research Center for Computing and Multimedia Studies, Hosei University, Tokyo, 102-8160, Japan; Department of Computer Education and Instructional Technology, Hacettepe University, Ankara, 06230, Turkey},
	abstract = {Students’ affective states describe their engagement, concentration, attitude, motivation, happiness, sadness, frustration, off-task behavior, and confusion level in learning. In online learning, students’ affective states are determinative of the learning quality. However, measuring various affective states and what influences them is exceedingly challenging for the lecturer without having real interaction with the students. Existing studies primarily use self-reported data to understand students’ affective states, while this paper presents a novel learning analytics system called MOEMO (Motion and Emotion) that could measure online learners’ affective states of engagement and concentration using emotion data. Therefore, the novelty of this research is to visualize online learners’ affective states on lecturers’ screens in real-time using an automated emotion detection process. In real-time and offline, the system extracts emotion data by analyzing facial features from the lecture videos captured by the typical built-in web camera of a laptop computer. The system determines online learners’ five types of engagement (“strong engagement”, “high engagement”, “medium engagement”, “low engagement”, and “disengagement”) and two types of concentration levels (“focused” and “distracted”). Furthermore, the dashboard is designed to provide insight into students’ emotional states, the clusters of engaged and disengaged students’, assistance with intervention, create an after-class summary report, and configure the automation parameters to adapt to the study environment. © 2023 by the authors.},
	author_keywords = {affective states detection; AI in education; dashboard; emotion; learning analytics framework; lecture video analysis},
	keywords = {Education, Distance; Emotions; Humans; Learning; Motivation; Students; E-learning; Laptop computers; Learning systems; Affective state; Affective state detection; AI in education; Dashboard; Emotion; Learning analytic framework; Lecture video; Lecture video analyse; Real- time; Video analysis; distance learning; emotion; human; learning; motivation; student; Students},
	correspondence_address = {M.N. Hasnine; Research Center for Computing and Multimedia Studies, Hosei University, Tokyo, 102-8160, Japan; email: nehal.hasnine.79@hosei.ac.jp},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {37177447},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sadallah202335,
	author = {Sadallah, Madjid and Gilliot, Jean-Marie},
	title = {Generating LADs that Make Sense},
	year = {2023},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {1},
	pages = {35 – 46},
	doi = {10.5220/0011839800003470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160867742&doi=10.5220%2f0011839800003470&partnerID=40&md5=0bdc72985cf00d0d8096d6a966c1f160},
	affiliations = {IMT Atlantique, Lab-STICC UMR CNRS 6285, Brest, F-29238, France},
	abstract = {Learning Analytics Dashboards (LADs) deliver rich and actionable representations of learning data to support meaningful and insightful decisions that ultimately leverage the learning process. Yet, because of their limited adoption and the complex nature of learning data, their design is still a major area of inquiry. In this paper, we propose to expand LAD codesign approaches. We first investigate how the user makes sense of the data delivered by LADs and how to support this sensemaking process at design. Second, we propose a generative tool, supporting sensemaking and decision making process, that extends end-users participation during the prototyping phase and empowers LAD designers. We also present an evaluation of the tool, including usability and user experience, demonstrating its effectiveness in supporting the design and prototyping of LADs. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Codesign; Dashboard Generation; Generative Design; Learning Analytics Dashboard},
	keywords = {Computer vision; Design; E-learning; Co-design approach; Co-designs; Complex nature; Dashboard generation; Generative design; Generative tools; Learning analytic dashboard; Learning data; Learning process; Sense making; Decision making},
	editor = {Jovanovic J. and Chounta I.-A. and Uhomoibhi J. and McLaren B.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758641-5},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}@ARTICLE{Kalir202277,
	author = {Kalir, Jeremiah H.},
	title = {Designing a Social Learning Analytics Tool for Open Annotation and Collaborative Learning},
	year = {2022},
	journal = {SpringerBriefs in Open and Distance Education},
	pages = {77 – 89},
	doi = {10.1007/978-981-19-0786-9_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130971298&doi=10.1007%2f978-981-19-0786-9_6&partnerID=40&md5=95d6fa5a6c73840d96b23af545aceaea},
	affiliations = {University of Colorado Denver, Denver, CO, United States},
	abstract = {This chapter examines why the social and technical practice of annotation—and, specifically, annotation that accompanies digital and openly accessible texts—is relevant to the development of learning analytics in open, flexible, and distance learning (OFDL). When annotated, the text of books become a context for discussion, analysis, and shared inquiry. Social annotation is a genre of learning technology that enables information sharing, peer interaction, collaboration, and the production of new knowledge. Collaborative activity mediated by social annotation—and whether anchored to this book, or to texts like ebooks, PDFs, blog posts, and open textbooks—generate digital information that may be gathered, analyzed, reported, and interpreted as discourse data. When texts, like books, anchor social annotation, it is feasible for researchers to derive insight about group activity, meaning-making, and collaboration through the analysis of discourse data. This chapter is a reflective, first-hand account about the co-design of a public dashboard that reports social learning analytics and encourages learners’ collaborative annotation across open texts and contexts. This chapter: (1) names the theoretical stances toward open and social learning that informed design and research; (2) describes key decisions and trade-offs pertinent to four iterations of the social learning analytics dashboard; and (3) considers epistemological, technological, and infrastructural implications for the development and use of social learning analytics in OFDL. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	correspondence_address = {J.H. Kalir; University of Colorado Denver, Denver, United States; email: remi.kalir@ucdenver.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {25094335},
	language = {English},
	abbrev_source_title = {SpringerBriefs  Open  Distance Educ.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{2022,
	title = {17th European Conference on Technology Enhanced Learning, EC-TEL 2022},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137993843&partnerID=40&md5=16be299283b60b3845bd82ac1b4a11d2},
	abstract = {The proceedings contain 61 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Learning to Give a Complete Argument with a Conversational Agent: An Experimental Study in Two Domains of Argumentation; video Segmentation and Characterisation to Support Learning; towards Generalized Methods for Automatic Question Generation in Educational Domains; adapting Learning Analytics Dashboards by and for University Students; Medical Students’ Perception of a Serious Game (ECOGAME) of Simulating an OSCE Station: Case of Mohammed VI University of Health Sciences (UM6SS); privacy-Preserving Synthetic Educational Data Generation; pyrates: A Serious Game Designed to Support the Transition from Block-Based to Text-Based Programming; Supporting Self-regulated Learning in BL: Exploring Learners’ Tactics and Strategies; CHEST: A Linked Open Data-based Application to Annotate and Carry Out Learning Tasks About Cultural Heritage; “Digital? Sicher!” – An Educational Game to Build Digital Competences; the Digitalization of Teaching Practices in K-12 Education: Insights from Teachers’ Perspective; towards Modelling the Technology Integration in Elementary School. A Diachronic Study of Teachers’ Digital Practices During and After Covid-19 Lockdown; designing a Moodle Plugin for Promoting Learners’ Self-regulated Learning in Blended Learning; the Disciplinary Learning Companion: The Impact of Disciplinary and Topic-Specific Reflection on Students’ Metacognitive Abilities and Academic Achievement; Promoting Universal Design for Learning Through Digital Assistive Tools in GamesHUB; deliberate Practice of Handwriting: Supervision Under the Ghost of an Expert; miranda: A Chatbot for Supporting Self-regulated Learning; superpowers in the Classroom: Hyperchalk is an Online Whiteboard for Learning Analytics Data Collection; privacy-Preserving and Scalable Affect Detection in Online Synchronous Learning; towards Effective Blended Learning Through the Eyes of Students: A Survey Study in Transition into Face-to-Face Education; process and Self-regulation Explainable Feedback for Novice Programmers Appears Ineffectual; preface.},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hirsto202260,
	author = {Hirsto, Laura and Saqr, Mohammed and López-Pernas, Sonsoles and Valtonen, Teemu},
	title = {A systematic narrative review of learning analytics research in K-12 and schools},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3383},
	pages = {60 – 67},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159303031&partnerID=40&md5=daeb6e778c566c2383eec29a8cf93ee6},
	affiliations = {School of Computing, University of Eastern Finland, Joensuu, Finland; School of Applied Educational Science and Teacher Education, University of Eastern Finland, Joensuu, Finland},
	abstract = {The field of learning analytics emerged in the last decade to take advantage of the increasing availability of data about learners that digital systems generate. Existing research in learning analytics has focused on higher education, as this context often relies heavily on digital platforms such as online learning management systems, making data collection easier. In this paper, we focus on LA research in the context of elementary level teaching. We provide a systematic narrative review in which we analyze the articles that had the most impact in the field. Our results show the existence of some recurring themes such as gamification and multimodal methods. We make a distinction between papers in which learning analytics is the target of the study (e.g., dashboards) and papers in which learning analytics methods were used as a means to study a given behavior/skill/phenomenon (e.g., problem-solving skills). Lastly, we found that most studies lack a strong theoretical foundation on education science and, thus, there is a need to develop more elaborated theoretical perspectives in future research on school-level learning analytics, as well as papers that deliver a real impact on learning and teaching. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)},
	author_keywords = {educational data mining; elementary school; K-12; learning analytics; literature review},
	keywords = {E-learning; Information management; Learning systems; Online systems; Digital platforms; Digital system; Educational data mining; Elementary schools; High educations; K-12; Learning analytic; Learning management system; Literature reviews; Online learning; Data mining},
	editor = {Hirsto L. and Hirsto L. and Lopez-Pernas S. and Lopez-Pernas S. and Saqr M. and Sointu E. and Valtonen T. and Vaisanen S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Peraić2022390,
	author = {Peraić, Ivan and Grubišić, Ani},
	title = {Development and Evaluation of a Learning Analytics Dashboard for Moodle Learning Management System},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13517 LNCS},
	pages = {390 – 408},
	doi = {10.1007/978-3-031-22131-6_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144379989&doi=10.1007%2f978-3-031-22131-6_30&partnerID=40&md5=56ad6a9f69026d08f9f15a9d9cbf4023},
	affiliations = {Department of Information Sciences, University of Zadar, Zadar, Croatia; Faculty of Science, University of Split, Split, Croatia},
	abstract = {Learning analytics provides a potential for adapting learning, teaching and knowledge testing processes to individual needs. One of the ways of using learning analytics is a dashboard for providing feedback to students and teachers. This paper presents the development and evaluation of the learning analytics dashboard for students (LAD-S). The LAD-S displays three views: a look at student success, system activities and prediction based on machine learning algorithms. We have used LAD-S as a part of Moodle online courses, one during the second semester in the 2020/2021, and the other two during the first semester in the 2021/2022. A survey was designed to examine students’ opinion about the LAD-S that included student’s self-awareness, influence of the dashboard on learning effectiveness, satisfaction with the type of data collected, usefulness and ease-of-use, intention to use the learning analytics dashboard. Data from 33 undergraduate and graduate students were collected. The results have shown that students are satisfied with all examined aspects of the LAD-S above the average. Students express the greatest satisfaction for ease of use (M = 3.79), clarity of collected data (M = 3.6), usefulness (M = 3.6), SUS questionnaire (M = 3.6), behavioral intention (M = 3.4) and satisfaction with individual functions of LAD-S (M = 3.4). Lower, yet above-average satisfaction was obtained for the impact of the LAD-S on more effective learning (M = 3.2); intention to use (M = 3.3) and satisfaction with the possibility of behavioral changes (M = 3.1). To verify the reliability of the measures used, the Cronbach’s alpha reliability coefficient was calculated for each scale. Satisfactory reliability of all measures used was obtained, with alpha coefficients ranging from 0.704 for the SUS questionnaire to 0.942 for the ease-of-use measure. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Evaluation; Learning analytics; Learning analytics dashboard},
	keywords = {E-learning; Learning algorithms; Learning systems; Machine learning; Reliability; Teaching; Ease-of-use; Evaluation; Feedback to students; Intention to use; Knowledge testing; Learning analytic; Learning analytic dashboard; Learning management system; Teachers'; Testing process; Students},
	correspondence_address = {I. Peraić; Department of Information Sciences, University of Zadar, Zadar, Croatia; email: iperaic@unizd.hr},
	editor = {Meiselwitz G. and Moallem A. and Zaphiris P. and Ioannou A. and Ioannou A. and Sottilare R.A. and Schwarz J. and Fang X.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303122130-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Zheng2022109,
	author = {Zheng, Lanqin and Zhong, Lu and Niu, Jiayu},
	title = {Effects of personalised feedback approach on knowledge building, emotions, co-regulated behavioural patterns and cognitive load in online collaborative learning},
	year = {2022},
	journal = {Assessment and Evaluation in Higher Education},
	volume = {47},
	number = {1},
	pages = {109 – 125},
	doi = {10.1080/02602938.2021.1883549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100985578&doi=10.1080%2f02602938.2021.1883549&partnerID=40&md5=043b6d7f3acde5e81146d4dcfb4aead7},
	affiliations = {Faculty of Education, Beijing Normal University, Beijing, China},
	abstract = {Learning analytics has been widely used in the field of education. Most studies have adopted a learning analytics dashboard to present data on learning processes or learning outcomes. However, only presenting learning analytics results was not sufficient and lacked personalised feedback. In response to these gaps, this study proposed a learning analytics-based personalised feedback approach and examined the effects of the proposed approach on collaborative knowledge building, emotional status, co-regulated behavioural patterns and cognitive load. The learning analytics-based personalised feedback approach adopted a deep neural network model, namely Bert (bidirectional encoder representations from transformers), to automatically classify discussion transcripts in online collaborative learning. In total, 60 undergraduate students participated in this exploratory study and were randomly assigned into experimental and control groups. The students in the experimental group learned with the learning analytics-based personalised feedback approach, and the students in the control group learned with the traditional online collaborative learning approach. The learning analytics-based approach was found to have significant impacts and no significant difference in cognitive load was noted between the experimental and control groups. © 2021 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Learning analytics; online collaborative learning; personalised feedback},
	correspondence_address = {L. Zheng; Faculty of Education, Beijing Normal University, Beijing, China; email: bnuzhenglq@bnu.edu.cn},
	publisher = {Routledge},
	issn = {02602938},
	language = {English},
	abbrev_source_title = {Assess. Eval. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@BOOK{Chaudy20211803,
	author = {Chaudy, Yaëlle and Connolly, Thomas M.},
	title = {Integrating assessment, feedback, and learning analytics in educational games: Literature review and design of an assessment engine},
	year = {2021},
	journal = {Research Anthology on Developments in Gamification and Game-Based Learning},
	volume = {4-4},
	pages = {1803 – 1846},
	doi = {10.4018/978-1-6684-3710-0.ch088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163656150&doi=10.4018%2f978-1-6684-3710-0.ch088&partnerID=40&md5=8cc5632e76753fcde156628adf17d03e},
	affiliations = {University of the West of Scotland, United Kingdom},
	abstract = {Assessment is a crucial aspect of any teaching and learning process. New tools such as educational games offer promising advantages: they can personalize feedback to students and save educators time by automating the assessment process. However, while many teachers agree that educational games increase motivation, learning, and retention, few are ready to fully trust them as an assessment tool. A likely reason behind this lack of trust is that educational games are distributed as black boxes, unmodifiable by educators and not providing enough insight about the gameplay. This chapter presents three systematic literature reviews looking into the integration of assessment, feedback, and learning analytics in educational games. It then proposes a framework and present a fully developed engine. The engine is used by both developers and educators. Designed to separate game and assessment, it allows teachers to modify the assessment after distribution and visualize gameplay data via a learning analytics dashboard. © 2022, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-166843711-7; 978-166843710-0},
	language = {English},
	abbrev_source_title = {Res. Anthol. on Dev. in Gamification and Game-Based Learn.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Valle20211724,
	author = {Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and Huggins-Manley, Anne Corinne},
	title = {Staying on target: A systematic literature review on learner-facing learning analytics dashboards},
	year = {2021},
	journal = {British Journal of Educational Technology},
	volume = {52},
	number = {4},
	pages = {1724 – 1748},
	doi = {10.1111/bjet.13089},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105201830&doi=10.1111%2fbjet.13089&partnerID=40&md5=52b5f2b1d1986f68fd04d2b9c868df6e},
	affiliations = {School of Teaching and Learning, University of Florida, Gainesville, FL, United States; School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, FL, United States},
	abstract = {The advances in technology to capture and process unprecedented amounts of educational data has boosted the interest in Learning Analytics Dashboard (LAD) applications as a way to provide meaningful visual information to administrators, parents, teachers and learners. Despite the frequent argument that LADs are useful to support target users and their goals to monitor and act upon the information provided, little is known about LADs’ theoretical underpinnings and the alignment (or lack thereof) between LADs intended outcomes and the measures used to evaluate their implementation. However, this knowledge is necessary to illuminate more efficient approaches in the development and implementation of LAD tools. Guided by the self-regulated learning perspective and using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, this systematic literature review addressed this gap by examining whether and how learner-facing LAD’s target outcomes align with the domain measures used to evaluate their implementations. Out of the 1297 papers retrieved from 15 databases, 28 were included in the final quantitative and qualitative analysis. Results suggested an intriguing lack of alignment between LADs’ intended outcomes (mostly cognitive domain) and their evaluation (mostly affective measures). Based on these results and on the premise that LADs are designed to support learners, a critical recommendation from this study is that LADs’ target outcomes should guide the selection of measures used to evaluate the efficacy of these tools. This alignment is critical to enable the construction of more robust guidelines to inform future endeavours in the field. Practitioner notes What is already known about this topic There has been an increased interest and investment in learning analytics dashboards to support learners as end-users. Learner-facing learning analytics dashboards are designed with different purposes, functionalities and types of data in an attempt to influence learners’ behaviour, achievement and skills. What this paper adds This paper reports trends and opportunities regarding the design of learner-facing learning analytics dashboards, contexts of implementation, as well as types and features of learner-facing learning analytics dashboard studies. The paper discusses how affect and motivation have been largely overlooked as target outcomes in learner-facing learning analytics dashboards. Implications for practice and/or policy Based on the evidence gathered through the review, this paper makes recommendations for theory (eg, inclusion of motivation as an important target outcome). The paper makes recommendations related to the design, implementation and evaluation of learning analytics dashboards. The paper also highlights the need for further integration between learner-facing learning analytics dashboards and open learner models. © 2021 British Educational Research Association.},
	author_keywords = {evaluation; learning analytics dashboards; systematic literature review; target outcomes},
	keywords = {Alignment; Facings; Motivation; Affective measures; Cognitive domain; Open learner models; Quantitative and qualitative analysis; Self-regulated learning; Systematic literature review; Systematic Review; Visual information; Learning systems},
	correspondence_address = {N. Valle; School of Teaching and Learning, University of Florida, Gainesville, United States; email: naterciavalle@gmail.com},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55}
}

@ARTICLE{Sadallah2022587,
	author = {Sadallah, Madjid and Gilliot, Jean-Marie and Iksal, Sébastien and Quelennec, Katia and Vermeulen, Mathieu and Neyssensas, Laurent and Aubert, Olivier and Venant, Rémi},
	title = {Designing LADs That Promote Sensemaking: A Participatory Tool},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {587 – 593},
	doi = {10.1007/978-3-031-16290-9_54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138012954&doi=10.1007%2f978-3-031-16290-9_54&partnerID=40&md5=08e031e013c0ff1360deb13ac4fbbe04},
	affiliations = {IMT Atlantique, Lab-STICC UMR CNRS 6285, Brest, 29238, France; University of Le Mans, Avenue Olivier Messiaen, Le Mans, 72085, France; Sorbonne Université and Univ. Lille, Lille, 59000, France; Center for Digital Systems, IMT Nord Europe, Univ. Lille, Lille, 59000, France; Ecole de Design Nantes Atlantique, Nantes, 44306, France; LS2N - UMR 6004 CNRS, Nantes Université, Nantes, France},
	abstract = {Learning Analytics Dashboards (LADs) are data visualization tools built to empower teachers and learners to make purposeful decisions that impact the learning process. Due to their relatively recent emergence and the scarcity of studies on their design principles, dashboard design remains a major area of investigation in learning analytics research, and large scale diffusion to their stakeholders remains limited. We promote human-centered approaches for LADs design since their success in terms of acceptance and adoption greatly depends on the level of stakeholder involvement in their design. In this paper, we present a tool to support the participatory design of LADs. First experiments during a pilot study with teachers demonstrate that the proposed tool encourages group work, and in-depth exploration of LADs use. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboards; Learning analytics; Participatory design; Sensemaking},
	keywords = {Learning systems; Dashboard; Data visualization tools; Design Principles; Large-scales; Learning analytic; Learning process; Participatory design; Sense making; Stakeholder involvement; Teachers'; Data visualization},
	correspondence_address = {M. Sadallah; IMT Atlantique, Lab-STICC UMR CNRS 6285, Brest, 29238, France; email: madjid.sadallah@imt-atlantique.fr},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{2022,
	title = {FLAIEC 2022 - Proceedings of the 1st Finnish Learning Analytics and Artificial Intelligence in Education Conference},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3383},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159264257&partnerID=40&md5=0b9ab74a7c77d02772fd392ddbdbf5ab},
	abstract = {The proceedings contain 11 papers. The topics discussed include: what are they telling us? accessible analysis of free text data from a national survey of higher education students; learning analytics in Moroccan higher education: justifications for use and challenges for successful implementation; how social interactions kindle productive online problem based learning: an exploratory study of the temporal dynamics; a chatbot-guided learning experience in the inquiry science classroom; using an automated learning analytics dashboard to capture sentiment in academic asynchronous online discussions; flipped online approach with learning analytics for supporting higher education students’ learning. course feedback results; and implementing learning analytics into teaching in higher education: teachers’ perceptions.},
	editor = {Hirsto L. and Hirsto L. and Lopez-Pernas S. and Lopez-Pernas S. and Saqr M. and Sointu E. and Valtonen T. and Vaisanen S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rako202266,
	author = {Rako, Sabina and Šimić, Diana and Rienties, Bart},
	title = {Supporting self-regulated learning in a blended learning environment using prompts and learning analytics},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3292},
	pages = {66 – 71},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143770905&partnerID=40&md5=7c2cb9a40d541298814199e01e019e35},
	affiliations = {University of Zagreb, Faculty of Organization and Informatics, Pavlinska 2, Varazdin, 42000, Croatia; University of Zagreb University Computing Centre, Josipa Marohnica 5, Zagreb, 10000, Croatia; Open University, Milton Keynes, MK7 6AA, United Kingdom},
	abstract = {Higher education institutions, teachers, and students face new difficulties and opportunities resulting from the introduction of modern technology into the learning process. The widespread of learning environments that integrate online learning and face-to-face learning may pose some opportunities as well as difficulties for some groups of students' self-regulation skills. Providing automated prompts may help to support those students with insufficient self-regulation skills. The use of learning analytics and multiple methods and data sources (data triangulation) may give better insight into the self-regulation process. The objective of the proposed research is to explore the students' evaluation of the usefulness of prompts implemented in a blended learning environment. A secondary objective is to develop and evaluate a real-time dashboard designed to notify teachers of student responses to deployed prompts. The research methodology will be grounded in action research and empirical research. The scientific contribution will be achieved through the development of artefacts and the performance of empirical research to advance understanding of the student's self-regulation in a blended learning environment. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {blended learning; dashboards; higher education; learning analytics; prompts; self-regulated learning},
	keywords = {Computer aided instruction; Deregulation; Learning systems; Blended learning; Blended learning environments; Dashboard; Empirical research; High educations; Higher education students; Learning analytic; Prompt; Self regulation; Self-regulated learning; Students},
	editor = {Jivet I. and Jivet I. and Di Mitri D. and Schneider J. and Papamitsiou Z. and Fominykh M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2021,
	author = {Chen, Yuxin and Hmelo-Silver, Cindy E. and Lajoie, Susanne P. and Zheng, Juan and Huang, Lingyun and Bodnar, Stephen},
	title = {Using Teacher Dashboards to Access Group Collaboration in Problem-based Learning},
	year = {2021},
	journal = {Interdisciplinary Journal of Problem-based Learning},
	volume = {15},
	number = {2},
	doi = {10.14434/ijpbl.v15i2.28792},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128604609&doi=10.14434%2fijpbl.v15i2.28792&partnerID=40&md5=2d4c7b3746e936e380ea795343a48087},
	affiliations = {Center for Research on Learning and Technology, Indiana University, United States; McGill University, Canada; The University of Hong Kong, Hong Kong; Eberhard Karls University of Tübingen, Germany},
	abstract = {Facilitating the collaboration of multiple groups is a critical element in problem-based learning (PBL). In face-to-face learning environments, PBL facilitators require sufficient information about a group’s progress and collaboration in real time to make decisions about when and how to facilitate. The capacity of facilitator is limited as PBL scales up. Online PBL settings can mitigate this challenge by presenting data from multiple groups to support facilitators using orchestration technology. A learning analytics dashboard with visual displays is one type of orchestration technology. This study examined 10 PBL facilitators’ use of such an orchestration technology to assess the collaboration patterns of multiple groups. Think-aloud protocols were collected from PBL facilitators as they used the technology to understand group collaboration patterns, which were illustrated through learning analytics visualizations. The think-aloud method enabled the PBL facilitators to verbalize their thought processes, and content analysis was conducted to analyze the transcripts. This study found that the expert facilitators made consistent formative assessments and strategically selected the most relevant visualizations to examine knowledge co-construction and group collaboration. In addition, they used multiple visualizations to calibrate and confirm their understanding of the students’ learning and group processes, rather than relying on one visualization. Understanding how facilitators use the information generated from a learning analytics dashboard to assess collaboration in an online PBL environment is critical for better support of online facilitation and the design of orchestration technology. © 2021, Purdue University Press. All rights reserved.},
	author_keywords = {content analysis; expertise; facilitation; online PBL; problem-based learning (PBL); teacher dashboard; think-aloud protocol},
	publisher = {Purdue University Press},
	issn = {15415015},
	language = {English},
	abbrev_source_title = {Interdiscip. J. Probl.- based Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@CONFERENCE{Akintunde2021,
	author = {Akintunde, Ruth Okoilu and Limke, Ally and Barnes, Tiffany and Heckman, Sarah and Lynch, Collin},
	title = {PEDI - Piazza Explorer Dashboard for Intervention},
	year = {2021},
	journal = {Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC},
	volume = {2010-October},
	doi = {10.1109/VL/HCC51201.2021.9576443},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118728533&doi=10.1109%2fVL%2fHCC51201.2021.9576443&partnerID=40&md5=76ba07905f98b97a480d7ec14051ff44},
	affiliations = {North Carolina State University, Raleigh, NC, United States},
	abstract = {Analytics about how students navigate online learning tools throughout the duration of an assignment is scarce. Knowledge about how students use online tools before a course's end could positively impact students' learning outcomes. We introduce PEDI (Piazza Explorer Dashboard for Intervention), a tool which analyzes and presents visualizations of forum activity on Piazza, a question and answer forum, to instructors. We outline the design principles and data-informed recommendations used to design PEDI. Our prior research revealed two critical periods in students' forum engagement over the duration of an assignment. Early engagement in the first half of an assignment duration positively correlates with class average performance. Whereas, extremely high engagement toward the deadline predicted lower class average performance. PEDI uses these findings to detect and flag troubling engagement levels and informs instructors through clear visualizations to promote data-informed interventions. By providing insights to instructors, PEDI may improve class performance and pave the way for a new generation of online tools.  © 2021 IEEE.},
	author_keywords = {forum activity; learning analytics dashboards; real time visualizations},
	keywords = {E-learning; Visualization; Critical periods; Design data; Design Principles; Forum activity; Learning analytic dashboard; On-line tools; Online learning tools; Performance; Real time visualization; Student learning outcomes; Students},
	editor = {Harms K. and Cunha J. and Oney S. and Kelleher C.},
	publisher = {IEEE Computer Society},
	issn = {19436092},
	isbn = {978-166544592-4},
	language = {English},
	abbrev_source_title = {Proc. of IEEE Symp. Vis. Lang. Hum.-Cent. Comput., VL/HCC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jayashanka2022151,
	author = {Jayashanka, Rangana and Hettiarachchi, E. and Hewagamage, K.P.},
	title = {Technology Enhanced Learning Analytics Dashboard in Higher Education},
	year = {2022},
	journal = {Electronic Journal of e-Learning},
	volume = {20},
	number = {2},
	pages = {151 – 170},
	doi = {10.34190/ejel.20.2.2189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125196307&doi=10.34190%2fejel.20.2.2189&partnerID=40&md5=1acb08163726c19c13528133da77c8ac},
	affiliations = {University of Colombo School of Computing, Colombo 7, Sri Lanka},
	abstract = {During the COVID-19 pandemic period, all the Sri Lankan universities delivered lectures in fully online mode using Virtual Learning Environments. In fully online mode, students cannot track their performance level, their progress in the course, and their performances compared to the rest of the class. This paper presents research work conducted at the University of Colombo School of Computing (UCSC), Sri Lanka, to solve the above problems and facilitate students learning in fully online and blended learning environments using Learning Analytics. The research objective is to design and create a Technology Enhanced Learning Analytics (TELA) dashboard for improving students’ motivation, engagement, and grades. The Design Science research strategy was followed to achieve the objectives of the research. Initially, a literature survey was conducted analyzing features and limitations in current Learning Analytic dashboards. Then, current Learning Analytic plugins for Moodle were studied to identify their drawbacks. Two surveys with 136 undergraduate students and interviews with 12 lecturers were conducted to determine required features of the TELA system. The system was designed as a Moodle Plugin. Finally, an evaluation of the system was done with third-year undergraduate students of the UCSC. The results showed that the TELA dashboard can improve students' motivation, engagement, and grades. As a result of the system, students could track their current progress and performance compared to the peers, which helps to improve their motivation to engage more in the course. Also, the increased engagement in the course enhances the student’s self-confidence since the student can see continuous improvement of his/her progress and performance which in turn improves the student’s grades. ©The Authors.},
	author_keywords = {Higher Education; Information Visualization; Learning Analytics; Moodle Plugin; Online Learning},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {14794403},
	language = {English},
	abbrev_source_title = {Electron. J. e-Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access}
}

@ARTICLE{Tackett2021,
	author = {Tackett, Sean and Green, David and Dyal, Michael and O'Keefe, Erin and Thomas, Tanya Emmanuelle and Nguyen, Tiffany and Vo, Duyen and Patel, Mausam and Murdock, Christopher J. and Wolfe, Erin M. and Shehadeh, Lina A.},
	title = {Use of commercially produced medical education videos in a cardiovascular curriculum: Multiple cohort study},
	year = {2021},
	journal = {JMIR Medical Education},
	volume = {7},
	number = {4},
	doi = {10.2196/27441},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117567132&doi=10.2196%2f27441&partnerID=40&md5=0f2e2ce0520acc6feff35eb990a8788d},
	affiliations = {Division of General Internal Medicine, Johns Hopkins Bayview Medical Center, Baltimore, MD, United States; Department of Medical Education, University of Miami, Miller School of Medicine, Miami, FL, United States; Department of Veteran Affairs, Miami, FL, United States; Division of Cardiology, Department of Medicine, University of Miami, Miller School of Medicine, Miami, FL, United States; Interdisciplinary Stem Cell Institute, University of Miami, Miller School of Medicine, Miami, FL, United States},
	abstract = {Background: Short instructional videos can make learning more efficient through the application of multimedia principles, and video animations can illustrate the complex concepts and dynamic processes that are common in health sciences education. Commercially produced videos are commonly used by medical students but are rarely integrated into curricula. Objective: Our goal was to examine student engagement with medical education videos incorporated into a preclinical Cardiovascular Systems course. Methods: Students who took the first-year 8-week Cardiovascular Systems course in 2019 and 2020 were included in the study. Videos from Osmosis were recommended to be watched before live sessions throughout the course. Video use was monitored through dashboards, and course credit was given for watching videos. All students were emailed electronic surveys after the final exam asking about the course's blended learning experience and use of videos. Osmosis usage data for number of video views, multiple choice questions, and flashcards were extracted from Osmosis dashboards. Results: Overall, 232/359 (64.6%) students completed surveys, with rates by class of 81/154 (52.6%) for MD Class of 2022, 39/50 (78%) for MD/MPH Class of 2022, and 112/155 (72.3%) for MD Class of 2023. Osmosis dashboard data were available for all 359 students. All students received the full credit offered for Osmosis engagement, and learning analytics demonstrated regular usage of videos and other digital platform features. Survey responses indicated that most students found Osmosis videos to be helpful for learning (204/232, 87.9%; P=.001) and preferred Osmosis videos to the traditional lecture format (134/232, 57.8%; P<.001). Conclusions: Commercial medical education videos may enhance curriculum with low faculty effort and improve students' learning experiences. Findings from our experience at one medical school can guide the effective use of supplemental digital resources for learning, and related evaluation and research. © 2019 American Academy of Osteopathy. All rights reserved.},
	author_keywords = {Commercial videos; E-Learning; Education; Flipped classroom; Health science education; Medical education; Medical students; Organ-systems courses; Teaching},
	correspondence_address = {L.A. Shehadeh; Interdisciplinary Stem Cell Institute, University of Miami, Miller School of Medicine, Miami, 1501 NW 10th Ave, 33136, United States; email: LShehadeh@med.miami.edu},
	publisher = {JMIR Publications Inc.},
	issn = {23693762},
	language = {English},
	abbrev_source_title = {JMIR Med. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hu20222013,
	author = {Hu, Yung-Hsiang},
	title = {Effects and acceptance of precision education in an AI-supported smart learning environment},
	year = {2022},
	journal = {Education and Information Technologies},
	volume = {27},
	number = {2},
	pages = {2013 – 2037},
	doi = {10.1007/s10639-021-10664-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112601612&doi=10.1007%2fs10639-021-10664-3&partnerID=40&md5=62554163f195d58c4e4142e61464f2d6},
	affiliations = {Center for General Education, College of Future, National Yunlin University of Science and Technology, Yunlin, Douliou, 64002, Taiwan},
	abstract = {The research presents precision education that aims to regulate students’ behaviors through the learning analytics dashboard (LAD) in the AI-supported smart learning environment (SLE). The LAD basically tracks and visualizes traces of learning actions to make students aware of their learning behaviors and reflect these against the agreed goals. This research aims to realize the digital transformation of the learning space, thereby improving students’ learning outcomes with the assistance of the learning dashboard. To examine whether there was a close relationship between the frequency of using the whole platform and academic results, the data was collected from 50 first-year university students who registered with the innovative thinking course. Based on the data, we constructed the Technology Acceptance Model (TAM) questionnaire and interview guide to realize the students’ acceptance and feedback towards the SLE. Students were clustered into high-mark and low-mark groups based on their final results. The Wilcoxon rank-sum test is used to identify a significant difference between the two groups using the precision education platform. Subsequently, the partial least squares structural equation modeling (PLS-SEM) is further utilized to analyze the relationship between system quality, perceived ease of use, and perceived usefulness on behavioral intention and learning transfer. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Architectures for educational technology system; Improving classroom teaching; Teaching/learning strategies},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30}
}

@CONFERENCE{Akçapinar20223812,
	author = {Akçapinar, Gökhan and Hasnine, Mohammad Nehal},
	title = {Discovering the effects of learning analytics dashboard on students' behavioral patterns using differential sequence mining},
	year = {2022},
	journal = {Procedia Computer Science},
	volume = {207},
	pages = {3812 – 3819},
	doi = {10.1016/j.procs.2022.09.443},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143343189&doi=10.1016%2fj.procs.2022.09.443&partnerID=40&md5=a7e4b332ac1c3947894b63d928a5032d},
	affiliations = {Department of Computer Education and Instructional Technology, Hacettepe University, Ankara, 06800, Turkey; Reseach Center for Computing and Multimedia Studies, Hosei University, 3-7-2 Kajinocho, Tokyo, 184-8584, Japan},
	abstract = {Interventions based on learning analytics have a very important place in closing the learning analytics loop. However, data-driven studies that test the effects of learning analytics-based interventions on students' online learning behaviors are very limited. In this study, the effect of the student-facing learning analytics dashboard (LAD) on the learning behavior of students in the online learning environment was investigated by using the differential pattern mining method. In a completely remote course, the learning behaviors of the participants before the introduction of the dashboard were compared with the learning behaviors they exhibited after the dashboard was introduced. In this way, it has become possible to analyze the behavior changes after the dashboard intervention. Wilcoxon signed-rank test was used to test whether these behavioral changes were statistically significant or not. According to the Wilcoxon signed-rank test results, while there is no significant difference in terms of students' assignment and quiz interactions, it is seen that there is a statistically significant increase in terms of students' forum-related activities such as reading other students' posts, starting a new discussion, and replying others' posts. Students' SCORM interactions (e.g, launch, complete) were also increased after engaging with the LAD. In addition, it was found that the overall interaction of students in the online learning environment increased by 57% when the LAD was used. © 2022 The Authors. Published by Elsevier B.V.},
	author_keywords = {dashboard; differential sequence mining; intervention; Learning analytics; temporal learning analytics},
	keywords = {Computer aided instruction; Data mining; E-learning; Dashboard; Differential sequence mining; Intervention; Learning analytic; Learning behavior; Online learning environment; Sequence mining; Temporal learning; Temporal learning analytic; Wilcoxon signed rank test; Students},
	correspondence_address = {G. Akçapinar; Department of Computer Education and Instructional Technology, Hacettepe University, Ankara, 06800, Turkey; email: gokhana@hacettepe.edu.tr},
	editor = {Cristani M. and Toro C. and Zanni-Merk C. and Howlett R.J. and Jain L.C.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{de Sousa20225,
	author = {de Sousa, Erverson B.G. and Mello, Rafael Ferreira},
	title = {Learning analytics to support teachers in the challenge of overcoming the learning gaps in k-12 students},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3292},
	pages = {5 – 11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143752230&partnerID=40&md5=fecdbaaacffcf5c095ad7fe72fb908d5},
	affiliations = {Cesar School, Recife, Brazil; Departamento de Computação, Universidade Federal Rural de Pernambuco, Recife, Brazil},
	abstract = {The emergency remote teaching caused by the covid-19 pandemic has potentiated the learning gaps of several students in Brazilian education, especially in the K-12 settings. Amidst the many challenges imposed by the pandemic, the adoption of digital tools in the school context has provided the generation of educational data, which can be collected and analyzed in order to provide evidence-based decision making, taking into account all the stakeholders in the teaching and learning process. Such decisions can provide for the personalization of learning, which aims to provide the student with educational resources that promote the building of weakened skills caused by learning gaps. The present thesis plan aims to present the work plan for the development of a Learning Analytics Dashboard tool for teachers in a basic education school in order to support data-driven pedagogical decision-making and to enable personalized monitoring of learning. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {k-12 students; Learning analytics; learning gaps; personalized learning},
	keywords = {Decision making; Digital devices; Decisions makings; Digital tools; Evidence- based decisions; K-12 student; Learning analytic; Learning gap; Personalized learning; Remote teaching; School context; Teachers'; Students},
	correspondence_address = {E.B.G. de Sousa; Cesar School, Recife, Brazil; email: ebgs@cesar.school},
	editor = {Jivet I. and Jivet I. and Di Mitri D. and Schneider J. and Papamitsiou Z. and Fominykh M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Villalobos2022407,
	author = {Villalobos, Esteban and Pérez-Sanagustin, Mar and Sanza, Cédric and Tricot, André and Broisin, Julien},
	title = {Supporting Self-regulated Learning in BL: Exploring Learners’ Tactics and Strategies},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {407 – 420},
	doi = {10.1007/978-3-031-16290-9_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137987944&doi=10.1007%2f978-3-031-16290-9_30&partnerID=40&md5=76212ab9bdc52e0af6dadf6fa1728f2f},
	affiliations = {IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; Université Paul-Valéry Montpellier 3, EPSYLON, Montpellier, France},
	abstract = {In the past years, Blended Learning (BL) has gained traction as a methodology in Higher Education Institutions. Despite the positive effects of BL, several studies have shown that students require high levels of self-regulation to succeed in these types of practices. Still, there is little understanding of how students organize their learning in BL authentic contexts. To fill this gap, this paper presents an exploratory study to analyze the learning tactics and strategies of 119 students in a BL course using the Moodle Learning Management System. Specifically, we examined the effects on students’ learning behavior before and after an intervention with a dashboard-based plug-in designed to support self-regulated learning (SRL). Using a data-driven approach based on Hidden Markov Models (HMM), we identified the tactics and strategies employed by the students along the course. The results show that students’ tactics and strategies changed significantly depending on the course design and the context in which learning occurs (in or beyond the class). Also, we found evidence indicating that the main factor that correlates to the students’ learning strategies is their previous knowledge and the students’ SRL ability profile. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Blended learning; Learning analytics; Self-regulated learning},
	keywords = {Curricula; Hidden Markov models; Learning systems; Authentic contexts; Blended learning; Exploratory studies; Higher education institutions; Learning analytic; Learning course; Learning management system; Self regulation; Self-regulated learning; Student learning; Students},
	correspondence_address = {E. Villalobos; IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; email: esteban.villalobos@irit.fr},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Tepgeç2022327,
	author = {Tepgeç, Mustafa and Ifenthaler, Dirk},
	title = {LEARNING ANALYTICS BASED INTERVENTIONS: A SYSTEMATIC REVIEW OF EXPERIMENTAL STUDIES},
	year = {2022},
	journal = {Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022},
	pages = {327 – 330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147522962&partnerID=40&md5=6510b88f15530b0a08ebc3724163d843},
	affiliations = {University of Mannheim, Mannheim, Germany; Curtin University, Australia},
	abstract = {Learning analytics includes interventions that will support learning and improve learning environments. Despite the fact that learning analytics is a promising field of study, the lack of empirical evidence on the effects of learning analytics-based interventions has been widely addressed in recent years. In this context, insights validated by experimental studies may play a crucial role. Therefore, there is a need for a report describing the methodological aspects and effects of current experimental interventions based on learning analytics. This systematic review provides an in-depth examination of learning analytics research that reports experimental findings to evaluate learning analytics-based interventions. The PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 protocol provided the basis for the work of this systematic review. This review contained 52 papers that met the inclusion and exclusion criteria. The results show that student-facing dashboards are the most common learning analytics-based intervention. Evidence from how user data is handled for interventions demonstrates that the most common method is the distillation of data for human judgment. This study confirms that a significant proportion of experimental studies employing learning analytics interventions have demonstrated significant effects on learning outcomes. The effectiveness of learning analytics-based interventions is also addressed in this review in terms of motivation, engagement, and system usage behaviors. The findings of this study will contribute to the literature in terms of describing the experimentally validated findings of learning analytics-based interventions in depth. © 2022 Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022. All rights reserved.},
	author_keywords = {Educational Data Mining; Experimental Studies; Intervention; Learning Analytics; Systematic Literature Review},
	keywords = {Computer aided instruction; Distillation; E-learning; Learning systems; 'current; Educational data mining; Experimental study; Intervention; Learning analytic; Learning environments; Methodological aspects; Support learning; Systematic literature review; Systematic Review; Data mining},
	editor = {Sampson D.G. and Sampson D.G. and Ifenthaler D. and Ifenthaler D. and Isaias P. and Rodrigues L.},
	publisher = {IADIS Press},
	isbn = {978-989870443-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Ifenthaler20221721,
	author = {Ifenthaler, Dirk and Yau, Jane Yin-Kim},
	title = {Analytics for Supporting Teaching Success in Higher Education: A Systematic Review},
	year = {2022},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2022-March},
	pages = {1721 – 1727},
	doi = {10.1109/EDUCON52537.2022.9766734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130446295&doi=10.1109%2fEDUCON52537.2022.9766734&partnerID=40&md5=261e8e9c480e549bba046ae967d49cec},
	affiliations = {University of Mannheim, Curtin University, Learning, Design and Technology, Mannheim, Germany; University of Mannheim, Dipf Leibniz Institute for Research and Information in Education, Mannheim, Germany},
	abstract = {Learning analytics are utilized to support learners' educational needs as well as to enhance their study success, for example, via the use of real-time prompts, motivational dashboards, and appropriate learning interventions, which have been shown to increase students' academic performance as well as their course retention rates. Yet, the perspective of higher education teachers in utilizing analytics to help analyze, reflect on, and improve their teaching design prior to delivery as well as to monitor and measure how the students engaged with their learning processes has been less recognized. In this paper, we present the results of a systematic review conducted from higher education teachers' perspective concerning how analytics can be deployed to adapt the curriculum to suit better students' educational needs in order to increase their study success. Thirty-five key studies were identified showing that analytics have been successful in influencing positively study success via teachers' academic curriculum intervention. Specifically, via analytics, higher education teachers could rapidly visualize common course pathways and identify any difficulties students experienced in real-time in order to increase their learning experiences and outcomes. © 2022 IEEE.},
	author_keywords = {higher education; learning analytics; systematic review; teacher},
	keywords = {Curricula; Teaching; Academic performance; Education teachers; Educational needs; High educations; Learning analytic; Real- time; Retention rate; Systematic Review; Teachers'; Teaching designs; Students},
	editor = {Jemni M. and Kallel I. and Akkari A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-166544434-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Roa Romero2021,
	author = {Roa Romero, Yadira and Tame, Hannah and Holzhausen, Ylva and Petzold, Mandy and Wyszynski, Jan-Vincent and Peters, Harm and Alhassan-Altoaama, Mohammed and Domanska, Monika and Dittmar, Martin},
	title = {Design and usability testing of an in-house developed performance feedback tool for medical students},
	year = {2021},
	journal = {BMC Medical Education},
	volume = {21},
	number = {1},
	doi = {10.1186/s12909-021-02788-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108854289&doi=10.1186%2fs12909-021-02788-4&partnerID=40&md5=20ae12665bc8fc90ccf8517ee6a68e28},
	affiliations = {Quality Assurance in Education, Charité – Universitätsmedizin, Berlin, Berlin, 10117, Germany; Dieter Scheffner Center for Medical Education and Educational Research, Dean’s Office of Study Affairs, Charité – Universitätsmedizin, Berlin, Berlin, 10117, Germany; Business Division IT, Charité – Universitätsmedizin, Berlin, Berlin, 10117, Germany},
	abstract = {Background: Feedback is essential in a self-regulated learning environment such as medical education. When feedback channels are widely spread, the need arises for a system of integrating this information in a single platform. This article reports on the design and initial testing of a feedback tool for medical students at Charité-Universitätsmedizin, Berlin, a large teaching hospital. Following a needs analysis, we designed and programmed a feedback tool in a user-centered approach. The resulting interface was evaluated prior to release with usability testing and again post release using quantitative/qualitative questionnaires. Results: The tool we created is a browser application for use on desktop or mobile devices. Students log in to see a dashboard of “cards” featuring summaries of assessment results, a portal for the documentation of acquired practical skills, and an overview of their progress along their course. Users see their cohort’s average for each format. Learning analytics rank students’ strengths by subject. The interface is characterized by colourful and simple graphics. In its initial form, the tool has been rated positively overall by students. During testing, the high task completion rate (78%) and low overall number of non-critical errors indicated good usability, while the quantitative data (system usability scoring) also indicates high ease of use. The source code for the tool is open-source and can be adapted by other medical faculties. Conclusions: The results suggest that the implemented tool LevelUp is well-accepted by students. It therefore holds promise for improved, digitalized integrated feedback about students’ learning progress. Our aim is that LevelUp will help medical students to keep track of their study progress and reflect on their skills. Further development will integrate users’ recommendations for additional features as well as optimizing data flow. © 2021, The Author(s).},
	author_keywords = {Assessment feedback; EPAs; Formative and summative assessment; Learning analytics; Usability testing},
	keywords = {Educational Measurement; Feedback; Humans; Students, Medical; User-Centered Design; User-Computer Interface; article; documentation; human; human experiment; learning; medical school; medical student; quantitative analysis; questionnaire; skill; usability testing; computer interface; education; feedback system},
	correspondence_address = {H. Tame; Quality Assurance in Education, Charité – Universitätsmedizin, Berlin, Berlin, 10117, Germany; email: hannah.tame@charite.de},
	publisher = {BioMed Central Ltd},
	issn = {14726920},
	pmid = {34162382},
	language = {English},
	abbrev_source_title = {BMC Med. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Alasalmi2022274,
	author = {Alasalmi, Tuija},
	title = {Comparative Analysis on Features Supporting Students’ Self-regulation in Three Different Online Learning Platforms},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1624 CCIS},
	pages = {274 – 289},
	doi = {10.1007/978-3-031-14756-2_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136986708&doi=10.1007%2f978-3-031-14756-2_14&partnerID=40&md5=1d4d6b76a5f006d2e104c98ccf865e79},
	affiliations = {Haaga-Helia University of Applied Sciences, Ratapihantie 13, Helsinki, 00320, Finland},
	abstract = {The paper discusses results of a survey focusing on student expectations and experiences on learning analytics and tools used for supporting self-regulation. The students participating in the survey were from three different organisations and they were also users of three different learning platforms. The results show differences between the students’ self-efficacy levels and identified tools and pedagogical solutions in each platform. The paper also discusses students’ preferences and need for learning analytics dashboards and peer comparisons as well as their potential for functioning as supporting measures for self-regulation. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Learning analytics; Learning platforms; Self-regulation},
	keywords = {Deregulation; E-learning; Surveys; Comparative analyzes; Learning analytic; Learning platform; Online learning; Self efficacy; Self regulation; Student expectations; Student experiences; Students},
	correspondence_address = {T. Alasalmi; Haaga-Helia University of Applied Sciences, Helsinki, Ratapihantie 13, 00320, Finland; email: tuija.alasalmi@haaga-helia.fi},
	editor = {Csapó B. and Uhomoibhi J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303114755-5},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Baneres2021,
	author = {Baneres, David and Guerrero-Roldán, Ana Elena and Rodríguez-González, M. Elena and Karadeniz, Abdulkadir},
	title = {A predictive analytics infrastructure to support a trustworthy early warning system},
	year = {2021},
	journal = {Applied Sciences (Switzerland)},
	volume = {11},
	number = {13},
	doi = {10.3390/app11135781},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109086842&doi=10.3390%2fapp11135781&partnerID=40&md5=8304fd914b20b88c7afb3f9f54e64ea7},
	affiliations = {eLearn Center, Universitat Oberta de Catalunya, Barcelona, 08018, Spain; Faculty of Computer Science, Multimedia and Telecommunications, Universitat Oberta de Catalunya, Barcelona, 08018, Spain; Open Education Faculty, Anadolu University, Eskişehir, 26210, Turkey},
	abstract = {Learning analytics is quickly evolving. Old fashioned dashboards with descriptive information and trends about what happened in the past are slightly substituted by new dashboards with forecasting information and predicting relevant outcomes about learning. Artificial intelligence is aiding this revolution. The accessibility to computational resources has increased, and specific tools and packages for integrating artificial intelligence techniques leverage such new analytical tools. However, it is crucial to develop trustworthy systems, especially in education where skepticism about their application is due to the risk of teachers’ replacement. However, artificial intelligence systems should be seen as companions to empower teachers during the teaching and learning process. During the past years, the Universitat Oberta de Catalunya has advanced developing a data mart where all data about learners and campus utilization are stored for research purposes. The extensive collection of these educational data has been used to build a trustworthy early warning system whose infrastructure is introduced in this paper. The infrastructure supports such a trustworthy system built with artificial intelligence procedures to detect at-risk learners early on in order to help them to pass the course. To assess the system’s trustworthiness, we carried out an evaluation on the basis of the seven requirements of the European Assessment List for trustworthy artificial intelligence (ALTAI) guidelines that recognize an artificial intelligence system as a trustworthy one. Results show that it is feasible to build a trustworthy system wherein all seven ALTAI requirements are considered at once from the very beginning during the design phase. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Predictive analytics; Software engineering in e-learning; Standards and guidelines; Trustworthy early warning system},
	correspondence_address = {D. Baneres; eLearn Center, Universitat Oberta de Catalunya, Barcelona, 08018, Spain; email: dbaneres@uoc.edu},
	publisher = {MDPI AG},
	issn = {20763417},
	language = {English},
	abbrev_source_title = {Appl. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@ARTICLE{2022,
	title = {11th International Conference on Games and Learning Alliance, GALA 2022},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13647 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144465082&partnerID=40&md5=e88016946ac72d5e1518b3158394f66d},
	abstract = {The proceedings contain 36 papers. The special focus in this conference is on Games and Learning Alliance. The topics include: More Than Meets the Eye - An Anti-Phishing Learning Game with a Focus on Phishing Emails; promoting Adaptive Number Knowledge Through Deliberate Practice in the Number Navigation Game; effects of a Game-Based Fraction Estimation Task on Math Anxiety; motivation and Emotions in a Health Literacy Game: Insights from Co-occurrence Network Analysis; swarming as a Bird/Fish: Investigating the Effect of First-Person Perspective Simulation on Players’ Connectedness with Nature; design of a Novel Serious Game for the Detection and Measurement of Obsessive-Compulsive Disorder; the Role of Games in Overcoming the Barriers to Paediatric Speech Therapy Training; ludic Didactics: For an Inspired, Motivating and Playful Education; comparison with Self vs Comparison with Others: The Influence of Learning Analytics Dashboard Design on Learner Dashboard Use; out of the Maze: Investigating Fluid Intelligence and Numeracy as Predictive Factors of Planning Skills Using Video Games; a Virtual Ship Evacuation Serious Game: Assessment of Data and Passenger Training; high-Level Decision-Making Non-player Vehicles; influence of a Mixed Reality Game on Students’ Personal Epistemology. An Empirical Study; experts’ Evaluation of a Proposed Taxonomy for Immersive Learning Systems; a Design Space of Educational Authoring Tools for Augmented Reality; the Effectiveness of Adaptive Digital Games for Learning: Calling for a Broader View on Assessment; gamification in Work Teams: A Q Study on How Team Members Experience Gamification; flow in a Game-Based Learning Platform Design for K-12; gamification for Spatial Digital Learning Environments in Higher Education: A Rapid Literature Review; constructing Gamified Learning Experiences.},
	editor = {Kiili K. and Antti K. and de Rosa F. and Dindar M. and Kickmeier-Rust M. and Bellotti F.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303122123-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li20221035,
	author = {Li, Yanyan and Zhang, Muhua and Su, You and Bao, Haogang and Xing, Shuang},
	title = {Examining teachers’ behavior patterns in and perceptions of using teacher dashboards for facilitating guidance in CSCL},
	year = {2022},
	journal = {Educational Technology Research and Development},
	volume = {70},
	number = {3},
	pages = {1035 – 1058},
	doi = {10.1007/s11423-022-10102-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133579963&doi=10.1007%2fs11423-022-10102-2&partnerID=40&md5=0667deda97da0d593fd4f04e06b082be},
	affiliations = {School of Educational Technology, Faculty of Education, Beijing Normal University, 19 Xinjiekouwai Street, Haidian Disrict, Beijing, 100875, China; College of Elementary Education, Capital Normal University, No.105 North Road, West Third Ring, Haidian District, Beijing, 100048, China; Center for Research on Technology-Enhanced Language Education, Beijing University of Posts and Telecommunications, 10 Xitucheng Street, Haidian Disrict, Beijing, 100876, China; National Institute of Education Science of China, Beisanhuanzhong Street, Haidian District, Beijing, 100088, China; Shenzhen Longhua No. 3 Experimental School, Longhua Disrict, Shen Zhen, 518109, China},
	abstract = {Learning analytics dashboards have been developed to facilitate teacher guidance in computer-supported collaborative learning (CSCL). As yet, little is known about how teachers interpret dashboard information to facilitate guidance in their teaching practice. This study examined teachers’ behavior patterns in interpreting information from dashboards, and obtained their views about the potential barriers in interpreting dashboard information. Fourteen pre-service teachers participated in the study and data were collected from multiple sources. In total, 1,346 min of video data on teachers’ guiding behavior and approximately 27,000 words from a cued retrospective report and interview data were generated. A two-stage approach was adopted to process the data. Based on the video analysis in the first stage, we extracted teachers’ four typical behavior patterns in finding and reading dashboard information and two behavior patterns when explaining information from dashboards. Thematic analysis at the second stage identified useful indicators for teacher guidance in CSCL and some major barriers teachers encountered in interpreting information. These findings may help improve the design of dashboards and show how teachers integrate dashboards into their daily teaching practice, thereby enhancing students’ collaboration and learning. © 2022, Association for Educational Communications and Technology.},
	author_keywords = {Behavior patterns; Computer-supported collaborative learning; Perceptions; Teacher dashboards; Teacher guidance},
	correspondence_address = {M. Zhang; College of Elementary Education, Capital Normal University, Beijing, No.105 North Road, West Third Ring, Haidian District, 100048, China; email: zhangmuhua@cnu.edu.cn},
	publisher = {Springer},
	issn = {10421629},
	language = {English},
	abbrev_source_title = {Educ. Technol. Res. Dev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Ritz2022921,
	author = {Ritz, Eva and Grüneke, Timo},
	title = {Learn Smarter, Not Harder - Exploring the Development of Learning Analytics Use Cases to Create Tailor-Made Online Learning Experiences},
	year = {2022},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2022-January},
	pages = {921 – 930},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152239559&partnerID=40&md5=eaecf03a53bb4e621f076d45860a2fec},
	affiliations = {University of St. Gallen, Switzerland; FIM Research Center, University of Bayreuth, Project Group Business and Information Systems, Engineering of Fraunhofer FIT, Germany},
	abstract = {Our world is significantly shaped by digitalization, fostering new opportunities for technology-mediated learning. Therefore, massive amounts of knowledge become available online. However, concurrently these formats entail less interaction and guidance from lecturers. Thus, learners need to be supported by intelligent learning tools that provide suitable knowledge in a tailored way. In this context, the use of learning analytics in its multifaceted forms is essential. Existing literature shows a proliferation of learning analytics use cases without a systematic structure. Based on a structured literature review of 42 papers we organized existing literature contributions systematically and derived four use cases: learning dashboards, individualized content, tutoring systems, and adaptable learning process based on personality. Our use cases will serve as a basis for a targeted scientific discourse and are valuable orientation for the development of future learning analytics use cases to give rise to the new form of Learning Experience Platforms. © 2022 IEEE Computer Society. All rights reserved.},
	keywords = {E-learning; Case learning; Intelligent learning; Learn+; Learning experiences; Learning process; Learning tool; Literature reviews; Online learning; Technology-mediated learning; Tutoring system; Learning systems},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813315-7},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Pozdniakov2022175,
	author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Tsai, Yi-Shan and Cukurova, Mutlu and Bartindale, Tom and Chen, Peter and Marshall, Harrison and Richardson, Dan and Gasevic, Dragan},
	title = {The Question-driven Dashboard: How Can We Design Analytics Interfaces Aligned to Teachers' Inquiry?},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {175 – 185},
	doi = {10.1145/3506860.3506885},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126222284&doi=10.1145%2f3506860.3506885&partnerID=40&md5=3c1a078c8a21d40519a4bc9a3f3de89e},
	affiliations = {Monash University, Australia; University College London, United Kingdom},
	abstract = {One of the ultimate goals of several learning analytics (LA) initiatives is to close the loop and support students' and teachers' reflective practices. Although there has been a proliferation of end-user interfaces (often in the form of dashboards), various limitations have already been identified in the literature such as key stakeholders not being involved in their design, little or no account for sense-making needs, and unclear effects on teaching and learning. There has been a recent call for human-centred design practices to create LA interfaces in close collaboration with educational stakeholders to consider the learning design, and their authentic needs and pedagogical intentions. This paper addresses the call by proposing a question-driven LA design approach to ensure that end-user LA interfaces explicitly address teachers' questions. We illustrate the approach in the context of synchronous online activities, orchestrated by pairs of teachers using audio-visual and text-based tools (namely Zoom and Google Docs). This study led to the design and deployment of an open-source monitoring tool to be used in real-time by teachers when students work collaboratively in breakout rooms, and across learning spaces.  © 2022 ACM.},
	author_keywords = {CSCL; dashboard; human-centred design; inquiry-driven practice; learning analytics; online learning},
	keywords = {Students; User interfaces; CSCL; Dashboard; End-user interfaces; Human-centred designs; Inquiry-driven practice; Learning analytic; Online learning; Reflective practise; Sense making; Teachers'; E-learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Green Open Access}
}

@ARTICLE{Oliver-Quelennec2022299,
	author = {Oliver-Quelennec, Katia and Bouchet, François and Carron, Thibault and Fronton Casalino, Kathy and Pinçon, Claire},
	title = {Adapting Learning Analytics Dashboards by and for University Students},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {299 – 309},
	doi = {10.1007/978-3-031-16290-9_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137994794&doi=10.1007%2f978-3-031-16290-9_22&partnerID=40&md5=dacb105d5981aa33404f1e3835d1e0dd},
	affiliations = {Sorbonne Université, CNRS, LIP6, Paris, 75005, France; Univ. Lille, CHU Lille, ULR 2694 - METRICS: Évaluation des technologies de santé et des pratiques médicales, Lille, 59000, France; Univ. Lille, GIVRE, DAPI, Lille, France},
	abstract = {Learning Analytics Dashboards (LADs) are becoming a key element in enabling learners to monitor their learning, plan and actually learn. However, LADs are sometimes not completely adapted to students, who are rarely involved in their design. Moreover, even when they are, the implemented LADs are often the same for all students, whereas previous works have shown the value of adapted LADs. Here we investigate which adaptations are requested by students, and attempt to identify which data and visualizations are suitable depending on the student’s profile. More specifically, we consider dynamic profiles as students’ expectations can vary over the course duration. By using LADs co-design sessions both online and on-site, we collected needs from N = 386 university students from different disciplines and degree level, split in 108 groups (2 to 4 students). After a manual annotation, we identified a total of 54 types of data and indicators, divided into 12 thematics. Our first analysis confirmed some previous results, particularly on the use of peer comparisons that do not fulfill every student’s needs. And we noticed other expectations according to the student’s learning context or the academic period. Future work will benefit from these results to define a model of adapted LADs. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Co-design; Dashboard; Indicator; Learning analytics dashboard},
	keywords = {Education computing; Co-designs; Dashboard; Key elements; Learn+; Learning analytic dashboard; Learning context; Manual annotation; Student expectations; University students; Students},
	correspondence_address = {K. Oliver-Quelennec; Sorbonne Université, CNRS, LIP6, Paris, 75005, France; email: katia.quelennec@univ-lille.fr},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wang2022161,
	author = {Wang, Zuo and Tzi Dong Ng, Jeremy and Liu, Ruilun and Hu, Xiao},
	title = {Learning Analytics Enabled Virtual Reality Content Creation Platform: System Design and Preliminary Evaluation},
	year = {2022},
	journal = {Proceedings - 2022 International Conference on Advanced Learning Technologies, ICALT 2022},
	pages = {161 – 163},
	doi = {10.1109/ICALT55010.2022.00055},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137007683&doi=10.1109%2fICALT55010.2022.00055&partnerID=40&md5=14c745f4352311c5da4cd3ffeb6a7a64},
	affiliations = {The University of Hong Kong, Faculty of Education, Hong Kong; The Univ. of Hong Kong, Shenzhen Institute of Research and Innovation, China},
	abstract = {Due to the popularity of virtual reality (VR) in education settings and the rise of maker education, this paper presents LAVR, a platform for VR content creation with learning analytics functions. We design the platform where students can easily create VR stories through a web interface. A learning analytics dashboard is implemented to provide students with feedback on their progress and the quality of the textual content in their VR stories. The platform also offers learning management features for helping teachers set up classrooms with assignments. While the platform will be employed in a forthcoming general education course, we have conducted a preliminary usability evaluation with 12 students and one teacher, and gathered feedback for further refinements before its official launch. The platform will contribute to integrating learning analytics with maker activities.  © 2022 IEEE.},
	author_keywords = {learning analytics; maker education; platform design; virtual reality content creation},
	keywords = {E-learning; Students; Analytic functions; Content creation; Learning analytic; Maker education; Platform design; Platform systems; Teachers'; Textual content; Virtual reality content creation; Web interface; Virtual reality},
	editor = {Chang M. and Chen N.-S. and Dascalu M. and Sampson D.G. and Tlili A. and Trausan-Matu S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166549519-6},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Corbu2021,
	author = {Corbu, Emilia Corina and Edelhauser, Eduard},
	title = {Responsive dashboard as a component of learning analytics system for evaluation in emergency remote teaching situations},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {23},
	doi = {10.3390/s21237998},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120057701&doi=10.3390%2fs21237998&partnerID=40&md5=0f5d288a1e0323ece821431a80e1aee6},
	affiliations = {Department of Mathematics and Informatics, University of Petrosani, Petrosani, 332003, Romania; Department of Management and Industrial Engineering, University of Petrosani, Petrosani, 332003, Romania},
	abstract = {The pandemic crisis has forced the development of teaching and evaluation activities ex-clusively online. In this context, the emergency remote teaching (ERT) process, which raised a mul-titude of problems for institutions, teachers, and students, led the authors to consider it important to design a model for evaluating teaching and evaluation processes. The study objective presented in this paper was to develop a model for the evaluation system called the learning analytics and evaluation model (LAEM). We also validated a software instrument we designed called the Eval-MathI system, which is to be used in the evaluation system and was developed and tested during the pandemic. The optimization of the evaluation process was accomplished by including and integrating the dashboard model in a responsive panel. With the dashboard from EvalMathI, six online courses were monitored in the 2019/2020 and 2020/2021 academic years, and for each of the six monitored courses, the evaluation of the curricula was performed through the analyzed parameters by highlighting the percentage achieved by each course on various components, such as content, adaptability, skills, and involvement. In addition, after collecting the data through interview guides, the authors were able to determine the extent to which online education during the COVID 19 pandemic has influenced the educational process. Through the developed model, the authors also found software tools to solve some of the problems raised by teaching and evaluation in the ERT environment. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {ELearning and digital transformation of education; Emergency remote teaching; IT for education; Learning analytics; Online education; Responsive dashboard},
	keywords = {COVID-19; Education, Distance; Humans; Learning; SARS-CoV-2; Students; Curricula; Education computing; Learning systems; Software testing; Teaching; Analytics systems; Digital transformation; Elearning and digital transformation of education; Emergency remote teaching; IT for education; Learning analytic; On-line education; Remote teaching; Responsive dashboard; Teaching situations; education; human; learning; student; E-learning},
	correspondence_address = {E. Edelhauser; Department of Management and Industrial Engineering, University of Petrosani, Petrosani, 332003, Romania; email: eduardedelhauser@upet.ro},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {34884005},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Jonathan2022250,
	author = {Jonathan, Christin and Koh, Elizabeth and Tan, Jennifer Pei-Ling},
	title = {Examining the Effectiveness of Self-Referenced and Peer-Referenced Learning Analytics Dashboards in Enhancing Students' Self-efficacy: Taking Individual Differences into Account},
	year = {2022},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {2022-June},
	pages = {250 – 257},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173588715&partnerID=40&md5=67baadd1a1db140944e051f8b080f395},
	affiliations = {National Institute of Education, Nanyang Technological University, Singapore; Oversea-Chinese Banking Corporation, Singapore},
	abstract = {This study examined the effectiveness of self-referenced and peer-referenced learning analytics (LA) dashboards in enhancing students' self-efficacy in critical reading, taking individual differences into account. A quasi-experiment with an embedded mixed methods approach was used, with 209 Grade 9 students who participated in critical reading online discussions in the English Language (EL) subject during a nine-week trial. Multiple regression analysis revealed that individual differences, namely, learning goals, performance goals, and gender, were significant predictors of critical reading self-efficacy, whereas dashboard type and initial achievement levels were not. Epistemic network analysis highlighted the importance of students' perceptions of how helpful and motivating they found the dashboards to be. Put together, the results highlight the theoretical and methodological importance of taking individual differences into account and have practical implications for designing more purposeful formative LA dashboards for enhancing students' self-efficacy. © ISLS.},
	keywords = {E-learning; Regression analysis; English languages; Individual Differences; Learning goals; Mixed method; Multiple regression analysis; Online discussions; Performance; Quasi-experiments; Self efficacy; Student perceptions; Students},
	editor = {Weinberger A. and Chen W. and Hernandez-Leo D. and Chen B.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-173733064-6},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hoffmann2022534,
	author = {Hoffmann, Christian and Mandran, Nadine and d’Ham, Cédric and Rebaudo, Sébastien and Haddouche, Mohamed Anis},
	title = {Development of Actionable Insights for Regulating Students’ Collaborative Writing of Scientific Texts},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {534 – 541},
	doi = {10.1007/978-3-031-16290-9_47},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138003171&doi=10.1007%2f978-3-031-16290-9_47&partnerID=40&md5=11c8297e0a600e1388c7ed39d6f82db7},
	affiliations = {Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, Grenoble, 38000, France; IMT Atlantique, LABSTICC, Brest, 29238, France},
	abstract = {We develop indicators for teachers to monitor and regulate students’ collaborative writing on a web-based science learning environment. Visualizations of carefully selected indicators are proposed to teachers in order to facilitate the tracking, analysis and management of the students’ collaborative work process over time. Our research method is based on a user-centered approach. Via focus groups and interviews, teachers have participated in the design of the indicators and visualizations. This communication presents (a) the mapping from collected data to educational constructs underlying our analytical approach for collaborative writing, (b) indicators and visualizations produced to provide actionable insights to teachers, and (c) lessons learned from our iterative human-centered design process. The results are transferable to other learning environments and design processes. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Collaborative learning; Collaborative writing; Learning analytics dashboards; User centered design},
	keywords = {Computer aided instruction; Data visualization; Iterative methods; Students; User centered design; Collaborative learning; Collaborative writing; Design-process; Learning analytic dashboard; Learning environments; Science learning; Scientific texts; Teachers'; Tracking analysis; Web based; Visualization},
	correspondence_address = {C. Hoffmann; Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, Grenoble, 38000, France; email: christian.hoffmann@univ-grenoble-alpes.fr},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kodumuru20221020,
	author = {Kodumuru, Saketh and Lucas, Brendan and Sabanwar, Vivek and Patil, Sachin and Avudiappan, Deepa and Parikh, Parth and Arya, Kavi},
	title = {Towards developing a learning analytics dashboard for a massive online robotics competition},
	year = {2022},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2022-March},
	pages = {1020 – 1025},
	doi = {10.1109/EDUCON52537.2022.9766808},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130497785&doi=10.1109%2fEDUCON52537.2022.9766808&partnerID=40&md5=064d25706aaa68ac726ef5d9bd3628f5},
	affiliations = {Sastra University, Computer Science and Engineering, Thanjavur, India; Computer Engineering Fr. Conceicao Rodrigues College of Engineering, Mumbai, India; Indian Institute of Technology Bombay, Department of Computer Science and Engineering, Mumbai, India},
	abstract = {A Learning Analytics Dashboard is a quick and efficient way for instructors to track the activities of students. In massive online learning scenarios like an international robotics competition, a dashboard is a critical tool for instructors to ensure continuous engagement of participants. Previous research on learning analytics dashboards focused on the effectiveness of dashboards and learning analytics on students along with factors affecting its success. This research discusses a dashboard developed for a massive robotics competition through which each year thousands of students are trained in engineering skills in an online Project Based Learning approach. The dashboard is developed using the dataset for the competition conducted during September 2020 to April 2021 in which more than 10,000 undergraduate students from 572 academic institutions across 7 countries participated. Team characteristics like demographics, feedback, scores, online activity, etc. are considered to cluster teams and develop models to predict the retention of participants. The Machine Learning (ML) model was able to achieve an accuracy of 80.7% and a recall value of 83.9% to identify dropping teams. Clustering provided insights on how these characteristics affected the performance of participants. These predictions along with participant engagement and feedback data was displayed on the dashboard. This visualization helps instructors identify teams requiring guidance or scaffolds to continue participation. Feedback from instructors shows the dashboard to be a promising tool for effectively managing massive online competitions. © 2022 IEEE.},
	author_keywords = {Engineering Education; Learning Analytics; Learning Analytics Dashboard; Machine Learning in Learning Analytics; Project Based Learning},
	keywords = {E-learning; Education computing; Engineering education; Machine learning; Robotics; Scaffolds; Engineering skills; Learning analytic; Learning analytic dashboard; Learning scenarios; Machine learning in learning analytic; Machine-learning; Online learning; Online robotics; Project based learning; Robotics competitions; Students},
	editor = {Jemni M. and Kallel I. and Akkari A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-166544434-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Taniguchi2022,
	author = {Taniguchi, Yuta and Owatari, Takuro and Minematsu, Tsubasa and Okubo, Fumiya and Shimada, Atsushi},
	title = {Live Sharing of Learning Activities on E-Books for Enhanced Learning in Online Classes},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {12},
	doi = {10.3390/su14126946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132025063&doi=10.3390%2fsu14126946&partnerID=40&md5=3505a686a8751f1105d41546f38d2d5b},
	affiliations = {Research Institute for Information Technology, Kyushu University, Fukuoka, 819-0395, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, 819-0395, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, 819-0395, Japan},
	abstract = {While positive effects of imitating other learners have been reported, the recent increases in the number of online classes have seriously limited opportunities to learn how others are learning. Providing information about others’ learning activities through dashboards could be a solution, but few studies have targeted learning activities on e-textbook systems; it remains unclear what information representations would be useful and how they would affect learning. We developed a dashboard system that enables live sharing of students’ learning activities on e-textbooks. An experiment was conducted applying the dashboard in an online class to evaluate its impact. The results of questionnaires and quizzes were analyzed along with learning activities on the e-textbook system. From the questionnaire results, the most useful feedback types were identified. Regarding the impact on learning, the study found that a higher percentage of students who used the dashboard followed the progress of the class than those who did not. The study also found that students who used the dashboard were more likely to achieve higher quiz scores than those who did not. This study is the first to reveal what specific feedback is useful and to successfully investigate the impact of its use on learning. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {continuous feedback; e-textbooks; learning analytics dashboard; online classes},
	keywords = {learning; questionnaire survey; student; World Wide Web},
	correspondence_address = {Y. Taniguchi; Research Institute for Information Technology, Kyushu University, Fukuoka, 819-0395, Japan; email: taniguchi.yuta.941@m.kyushu-u.ac.jp},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Ludwig2021363,
	author = {Ludwig, Sabrina and Rausch, Andreas and Deutscher, Viola and Seifried, Jürgen},
	title = {Problem Solving Analytics (PSA) in the Web-Based Office Simulation LUCA},
	year = {2021},
	journal = {L@S 2021 - Proceedings of the 8th ACM Conference on Learning @ Scale},
	pages = {363 – 364},
	doi = {10.1145/3430895.3460877},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108108084&doi=10.1145%2f3430895.3460877&partnerID=40&md5=5cf83775dab3c3a18ee811aa56766d29},
	affiliations = {University of Mannheim, Mannheim, Germany},
	abstract = {Open-ended e-learning environments allow for explorative behaviour in challenging scenarios and hence, foster problem-solving competences. The web-based office simulation LUCA (funded by the German Federal Ministry of Education and Research) addresses the domain-specific competences of students in commercial vocational education and training (VET). The office simulation provides authentic office tools such as a spreadsheet application and an ERP software to solve complex work scenarios. These scenarios are implemented via the "LUCA Editor"and can contain automated assistance based on evidence rules of certain behaviours ("scaffolding"). The real-time analysis of the resulting log files enables the analysis of individual problem-solving behaviour ("Problem Solving Analytics", PSA). Teachers and trainers can monitor their students' problem-solving efforts in the "LUCA Dashboard", where they can also provide individual assistance via a chat tool. In our contribution, the scientific foundations of PSA will be outlined, followed by a demonstration of the latest prototype of LUCA and visitors' interaction with the software. LUCA's alpha version will be released in September of this year and will be available for practitioners in vocational schools and companies. © 2021 Owner/Author.},
	author_keywords = {automated feedback; computer-based office simulation; learning analytics; log data analysis; open-ended learning environment; vocational education},
	keywords = {Application programs; Scaffolds; Students; Websites; Automated assistance; E-learning environment; German Federal Ministry of Education and Research; Real time analysis; Scientific foundations; Spreadsheet applications; Vocational education and training; Vocational schools; Computer aided instruction},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038215-1},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fernandez Nieto2022219,
	author = {Fernandez Nieto, Gloria Milena and Kitto, Kirsty and Buckingham Shum, Simon and Martinez-Maldonado, Roberto},
	title = {Beyond the Learning Analytics Dashboard: Alternative Ways to Communicate Student Data Insights Combining Visualisation, Narrative and Storytelling},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {219 – 229},
	doi = {10.1145/3506860.3506895},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126252573&doi=10.1145%2f3506860.3506895&partnerID=40&md5=fb59632377d55691f0393d489f3d5a46},
	affiliations = {Connected Intelligent Centre, University of Technology Sydney, Sydney, NSW, Australia; Monash University, Melbourne, Australia},
	abstract = {Learning Analytics (LA) dashboards have become a popular medium for communicating to teachers analytical insights obtained from student data. However, recent research indicates that LA dashboards can be complex to interpret, are often not grounded in educational theory, and frequently provide little or no guidance on how to interpret them. Despite these acknowledged problems, few suggestions have been made as to how we might improve the visual design of LA tools to support richer and alternative ways to communicate student data insights. In this paper, we explore three design alternatives to represent student multimodal data insights by combining data visualisation, narratives and storytelling principles. Based on foundations in data storytelling, three visual-narrative interfaces were designed with teachers: i) visual data slices, ii) a tabular visualisation, and iii) a written report. These were validated as a part of an authentic study where teachers explored activity logs and physiological data from co-located collaborative learning classes in the context of healthcare education. Results suggest that alternatives to LA dashboards can be considered as effective tools to support teachers' reflection, and that LA designers should identify the representation type that best fits teachers' needs.  © 2022 ACM.},
	author_keywords = {multimodal data; qualitative analysis; visual learning analytics},
	keywords = {Data visualization; Visualization; Analytic tools; Educational theory; Multi-modal data; Narrative and storytelling; Qualitative analysis; Recent researches; Teachers'; Visual design; Visual learning; Visual learning analytic; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41}
}

@ARTICLE{Aldosemani2022,
	author = {Aldosemani, Tahani I. and Khateeb, Ahmed Al},
	title = {Learning Loss Recovery Dashboard: A Proposed Design to Mitigate Learning Loss Post Schools Closure},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {10},
	doi = {10.3390/su14105944},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130712854&doi=10.3390%2fsu14105944&partnerID=40&md5=499361bd525d28ac0676a669f60a8cf5},
	affiliations = {Department of Educational Studies, College of Education, Prince Sattam Bin Abdulaziz University, Al-Kharj, 16278, Saudi Arabia; Department of English, College of Arts, King Faisal University, Al Ahsa, 31982, Saudi Arabia},
	abstract = {Research has shown the effectiveness of designing a Learning Analytics Dashboard (LAD) for learners and instructors, including everyone’s levels of progress and performance. An intertwined relationship exists between learning analytics (LA) and the learning process. Understanding information or data about learners and their learning journey can contribute to a deeper understanding of learners and the learning process. The design of an effective learning dashboard relies heavily on LA, including assessment of the learning process, i.e., gains and losses. A Learning Loss Recovery Dashboard (LLRD) can be designed as an instructional tool, to support the learning process as well as learners’ performance and their academic achievement. The current project proposes a LLRD prototype model to deal with potential learning loss; increase the achievement of learning outcomes; and provide a single, comprehensive learning process, where schools can evaluate and remedy any potential learning loss resulting from the distance-learning period that was caused by the COVID-19 pandemic. This systematic dashboard prototype functions to determine learning gains by K–12 learners. It is expected that the implementation of the proposed dashboard would provide students, teachers, and educational administrators with an integrated portal, for a holistic and unified remedial experience for addressing learning loss. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {learners’ assessment; learning analytics (LA); learning analytics dashboard (LAD); learning gains; learning loss},
	keywords = {assessment method; COVID-19; education; information; learning},
	correspondence_address = {T.I. Aldosemani; Department of Educational Studies, College of Education, Prince Sattam Bin Abdulaziz University, Al-Kharj, 16278, Saudi Arabia; email: t.aldosemani@psau.edu.sa},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Allen20221747,
	author = {Allen, Louis and Atkinson, Jack and Cordiner, Joan and Zandi, Mohammad and Moghadam, Peyman Z.},
	title = {Wiz 4.0: A Novel Data Visualisation and Analytics Dashboard for a Graphical Approach to Industry 4.0},
	year = {2022},
	journal = {Computer Aided Chemical Engineering},
	volume = {49},
	pages = {1747 – 1752},
	doi = {10.1016/B978-0-323-85159-6.50291-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136263005&doi=10.1016%2fB978-0-323-85159-6.50291-8&partnerID=40&md5=014fdcdc58444c733484d4d71f42eaf4},
	affiliations = {Department of Chemical and Biological Engineering, The University of Sheffield, S1 3DJ, Sheffield, United Kingdom},
	abstract = {Proliferation of data owing to the onset of Industry 4.0 (I4.0) has led to many traditional data analysis approaches becoming redundant. Novel and innovative solutions are required to facilitate the new era of data-driven manufacturing characteristic of I4.0. This work demonstrates one such approach in the formation of a bespoke web-based visualisation and machine learning analytics platform, designed to bridge the gap between the old ways and new. Our unique I4.0 data analytics platform, called Wiz 4.0, enables advanced big data analytics in conjunction with user-friendly features and multivariate data visualisations. This allows for both a holistic overview of manufacturing processes as well as detailed analysis of data. Wiz 4.0 lays the foundations of an industry defining software to grant deep insight into the inner relationships between process variables to the everyday user. The software provides the ability to analyse data using a variety of machine learning algorithms and plot the data in high dimensional space through the innovative no-code platform hosted on the Siemens MindSphere. This approach is set to revolutionise the value creation of data in the new IoT and smart factory paradigms emerging from the transition towards I4.0. © 2022 Elsevier B.V.},
	author_keywords = {analytics; dashboard; Industry 4.0; IoT; visualization},
	publisher = {Elsevier B.V.},
	issn = {15707946},
	language = {English},
	abbrev_source_title = {Comput. Aided Chem. Eng.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Jonathan2022250,
	author = {Jonathan, Christin and Koh, Elizabeth and Tan, Jennifer Pei-Ling},
	title = {Examining the Effectiveness of Self-Referenced and Peer-Referenced Learning Analytics Dashboards in Enhancing Students' Self-efficacy: Taking Individual Differences into Account},
	year = {2022},
	journal = {Proceedings of International Conference of the Learning Sciences, ICLS },
	pages = {250 – 257},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145549949&partnerID=40&md5=268d63c4fa69db6b524faf6e6f2d5f72},
	affiliations = {National Institute of Education, Nanyang Technological University, Singapore; Oversea-Chinese Banking Corporation, Singapore},
	abstract = {This study examined the effectiveness of self-referenced and peer-referenced learning analytics (LA) dashboards in enhancing students' self-efficacy in critical reading, taking individual differences into account. A quasi-experiment with an embedded mixed methods approach was used, with 209 Grade 9 students who participated in critical reading online discussions in the English Language (EL) subject during a nine-week trial. Multiple regression analysis revealed that individual differences, namely, learning goals, performance goals, and gender, were significant predictors of critical reading self-efficacy, whereas dashboard type and initial achievement levels were not. Epistemic network analysis highlighted the importance of students' perceptions of how helpful and motivating they found the dashboards to be. Put together, the results highlight the theoretical and methodological importance of taking individual differences into account and have practical implications for designing more purposeful formative LA dashboards for enhancing students' self-efficacy. © ISLS.},
	keywords = {E-learning; Regression analysis; English languages; Individual Differences; Learning goals; Mixed method; Multiple regression analysis; Online discussions; Performance; Quasi-experiments; Self efficacy; Student perceptions; Students},
	editor = {Weinberger A. and Chen W. and Hernandez-Leo D. and Chen B.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {18149316},
	isbn = {978-173733064-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Learn. Sci., ICLS },
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Shabaninejad2022384,
	author = {Shabaninejad, Shiva and Khosravi, Hassan and Abdi, Solmaz and Indulska, Marta and Sadiq, Shazia},
	title = {Incorporating Explainable Learning Analytics to Assist Educators with Identifying Students in Need of Attention},
	year = {2022},
	journal = {L@S 2022 - Proceedings of the 9th ACM Conference on Learning @ Scale},
	pages = {384 – 388},
	doi = {10.1145/3491140.3528292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132140667&doi=10.1145%2f3491140.3528292&partnerID=40&md5=45e734f226632d3e40722379b0c8efe1},
	affiliations = {The University of Queensland, Brisbane, Australia},
	abstract = {Increased enrolments in higher education, and the shift to online learning that has been escalated by the recent COVID pandemic, have made it challenging for instructors to assist their students with their learning needs. Contributing to the growing literature on instructor-facing systems, this paper reports on the development of a learning analytics (LA) technique called Student Inspection Facilitator (SIF) that provides an explainable interpretation of students learning behaviour to support instructors with the identification of students in need of attention. Unlike many previous predictive systems that automatically label students, our approach provides explainable recommendations to guide data exploration while still reserving judgement about interpreting student learning to instructors. The insights derived from applying SIF in an introductory Information Systems course with 407 enrolled students suggest that SIF can be utilised independent of the context and can provide a meaningful interpretation of students' learning behaviour towards facilitating proactive support of students. © 2022 ACM.},
	author_keywords = {at-risk students; explainable learning analytics; learning analytics dashboards},
	keywords = {Learning systems; Predictive analytics; Analytic technique; At-risk student; Data exploration; Explainable learning analytic; High educations; Learning analytic dashboard; Learning behavior; Online learning; Predictive systems; Student learning; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039158-0},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Hernández-Calderón2021,
	author = {Hernández-Calderón, Jose-Guillermo and Soto-Mendoza, Valeria and Montané-Jiménez, Luis Gerardo and Colula, Marion Alain Meunier and Tello-Carrillo, Janeth},
	title = {Designing an information visualization dashboard to proctor test-takers during language certification online testing},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3492724.3492731},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124023482&doi=10.1145%2f3492724.3492731&partnerID=40&md5=886b1c9a425835f05139839c6bfecbd8},
	affiliations = {Dirección de Los Centros de Idiomas y Autoacceso, Universidad Veracruzana, Mexico; Centro de Investigación en Matemáticas Aplicadas, Universidad Autónoma de Coahuila, Mexico; Facultad de Estadística e Informática, Universidad Veracruzana, Mexico; Coordinación Del Programa EXAVER, Universidad Veracruzana, Mexico},
	abstract = {The learning mechanisms and the evaluation process have been moved to an online mode in order to maintain social distancing and reduce the spread of the COVID-19. E-learning initiatives (including assessment and proctoring) produce a large amount of data, so visualization mechanisms are required to support the decision-making process. This problem is addressed from a practical context of study: the English Language Certification Tests of a University in the southeast of Mexico. The conceptual design of four conceptual dashboards are presented using a mixed methodology: the UCD process and a conceptual model for a dashboard generator process. The four conceptual dashboards were evaluated by five experts. Although the design proposals were simple and reflected most initial user requirements, the experts suggested to include more elements in all the dashboards to provide the information needed for the intended users and improve the decision-making process.  © 2021 ACM.},
	author_keywords = {information visualization; language; learning analytics; test-takers},
	keywords = {Data visualization; Decision making; E-learning; Information analysis; Information systems; Visualization; Decision-making process; E - learning; Language; Learning analytic; Learning initiatives; Learning mechanism; On-line testing; Online modes; Proctor tests; Test-tak; Conceptual design},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038717-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Valle2021,
	author = {Valle, Natercia and Antonenko, Pavlo and Valle, Denis and Dawson, Kara and Huggins-Manley, Anne Corinne and Baiser, Benjamin},
	title = {The influence of task-value scaffolding in a predictive learning analytics dashboard on learners' statistics anxiety, motivation, and performance},
	year = {2021},
	journal = {Computers and Education},
	volume = {173},
	doi = {10.1016/j.compedu.2021.104288},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111810944&doi=10.1016%2fj.compedu.2021.104288&partnerID=40&md5=68f247ae0dafacf307cb8cce7845ff4f},
	affiliations = {Educational Technology, University of Florida, Gainesville, FL, United States; School of Forest Resources and Conservation, University of Florida, Gainesville, FL, United States; Research and Evaluation Methodology, University of Florida, Gainesville, FL, United States; Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, United States},
	abstract = {There is an increasing trend of learning analytics dashboards (LADs) being used to provide feedback to learners. However, there is little empirical evidence about the influence of their design features on learners' cognitive and affective outcomes, especially in high-anxiety courses such as statistics. To address this gap, this study employed a two-group experimental design applied to an authentic setting to assess the influence of task-value scaffolding in a LAD on learners' anxiety, motivation, and learning performance in an online statistics course. This semester-long experiment was implemented in two instances of the course offering (Fall/2019 and Spring/2020) and involved a total of 146 students. The results showed that task-value scaffolding had a negative impact on learners’ computation anxiety and attitudes towards statistics in comparison to the control group. On the other hand, the treatment had no significant influence on other aspects of statistics anxiety, motivation, and learning outcomes. Taken jointly, these results suggest that the use of task-value scaffolding embedded in LADs can have detrimental effects on learners. More experimental studies are necessary to understand the positive and negative effects of LADs with motivational scaffolding. © 2021 Elsevier Ltd},
	author_keywords = {Data science applications in education; Distance education and online learning; Human-computer interface; Pedagogical issues; Post-secondary education},
	keywords = {Curricula; E-learning; Human computer interaction; Motivation; Predictive analytics; Scaffolds; Cognitive and affective outcomes; Data science application in education; Design features; Distance education and online learning; Human computer interfaces; Learning performance; Motivation and performance; Pedagogical issues; Postsecondary education; Statistics anxiety; Statistics},
	correspondence_address = {N. Valle; Gainesville, 1221 SW 5th Ave., 32601, United States; email: naterciavalle@gmail.com},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30}
}

@CONFERENCE{Amarasinghe2022,
	author = {Amarasinghe, S.N. and Thalakumbura, T.M.D.D. and Wijewardena, M.D.N.K. and Perera, D.H. and Manathunga, Kalpani and Senaweera, Oshada},
	title = {Remotify: The Emergency Remote Learning Solution using Learning Analytics},
	year = {2022},
	journal = {2022 IEEE 7th International conference for Convergence in Technology, I2CT 2022},
	doi = {10.1109/I2CT54291.2022.9824707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135629554&doi=10.1109%2fI2CT54291.2022.9824707&partnerID=40&md5=36d0b7ccbd2ff24aa98da16ecbde5025},
	affiliations = {Sri Lanka Institute of Information Technology, Faculty of Computing, Malabe, Sri Lanka},
	abstract = {Current pandemic situation has manipulated people to adapt to a new normal forcefully and due to the same reason education system is also evolving but the actual question is how productive the new methodologies utilized are. E-learning is not a novel concept but is becoming a necessity and the proposed platform could be identified as a direct response to the current emergency. This can also be known as an "ERT"situation; a shift of instructional delivery to an alternate delivery method in response to a crisis situation. The main intention in these situations is not to recreate a robust educational system but to provide access to institutions in a manner that is easy to set up and is dependable during an emergency while outperforming both E-learning & traditional classroom methods. To provide a solution to overcome barriers faced in a pandemic situation in a virtual classroom, the implemented system is encapsulated with a dashboard centralizing facts gathered from audio & video analyzing components which are analyzed against student performance utilizing personalized assessing techniques to deliver learning analytics. © 2022 IEEE.},
	author_keywords = {Dashboard; Emergency Remote Teaching; learning analytics; virtual classroom},
	keywords = {Computer aided instruction; Learning systems; Students; 'current; Dashboard; E - learning; Education systems; Emergency remote teaching; Learning analytic; Novel concept; Remote learning; Remote teaching; Virtual Classroom; E-learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542168-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Converg. Technol., I2CT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Campos202160,
	author = {Campos, Fabio C. and Ahn, June and Digiacomo, Daniela K. and Nguyen, Ha and Hays, Maria},
	title = {Making Sense of Sensemaking: Understanding How K–12 Teachers and Coaches React to Visual Analytics},
	year = {2021},
	journal = {Journal of Learning Analytics},
	volume = {8},
	number = {3},
	pages = {60 – 80},
	doi = {10.18608/jla.2021.7113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122179509&doi=10.18608%2fjla.2021.7113&partnerID=40&md5=85d3f15b8f5e43d6d013b7e5c39a3dfc},
	affiliations = {New York University, Steinhardt School of Culture, Education and Human Development, 82 Washington Square East, New York, NY, United States; University of California, Irvine, School of Education, 3200 Education, Irvine, CA, United States; University of Kentucky, School of Information Science, 320 Little Fine Arts Library, Lexington, KY, United States; University of California, Irvine, School of Education, 3200 Education, Irvine, CA, United States; University of Washington, College of Education, 2012 Skagit Lane, Seattle, WA, United States},
	abstract = {With the spread of learning analytics (LA) dashboards in K–12 schools, educators are increasingly expected to make sense of data to inform instruction. However, numerous features of school settings, such as specialized vantage points of educators, may lead to different ways of looking at data. This observation motivates the need to carefully observe and account for the ways data sensemaking occurs, and how it may differ across K–12 professional roles. Our mixed-methods study reports on interviews and think-aloud sessions with middle-school mathematics teachers and instructional coaches from four districts in the United States. By exposing educators to an LA dashboard, we map their varied reactions to visual data and reveal prevalent sensemaking patterns. We find that emotional, analytical, and intentional responses inform educators’ sensemaking and that different roles at the school afford unique vantage points toward data. Based on these findings, we offer a typology for representing sensemaking in a K–12 school context and reflect on how to expand visual LA process models. © 2021, UTS ePRESS. All rights reserved.},
	author_keywords = {Human-computer interaction; K–12 learning analytics; Learning dashboards; Sensemaking},
	correspondence_address = {F.C. Campos; New York University, Steinhardt School of Culture, Education and Human Development, New York, 82 Washington Square East, United States; email: fabioc@nyu.edu},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access}
}

@ARTICLE{Ouatiq2022287,
	author = {Ouatiq, Amina and Riyami, Bouchaib and Mansouri, Khalifa and Qbadou, Mohammed},
	title = {The Preferences and Expectation of Moroccan Teachers from Learning Analytics Dashboards in a Blended Learning Environment: Empirical Study},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {357 LNNS},
	pages = {287 – 297},
	doi = {10.1007/978-3-030-91738-8_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124149278&doi=10.1007%2f978-3-030-91738-8_27&partnerID=40&md5=51b2680d2e70e6429e6483881a902ec9},
	affiliations = {SSDIA Laboratory, ENSET Mohammedia, Hassan II University of Casablanca, Mohammedia, Morocco; Institut Supérieur du Génie Appliqué IGA Casablanca, Mohammedia, Morocco},
	abstract = {Learning analytic dashboards help instructors track, and supervise students in online or hybrid education in order to meet the needs of teachers and better understand their preferences and their expectations of the dashboards, an online questionnaire was conducted for Moroccan teachers in higher education to determine their needs and their uses of a dashboard in a scenario of blended learning, to learn more about the indicators they deem most relevant to their teaching activities. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Indicators; Learning analytics dashboard; Questionnaire; User’s needs; Visualization},
	correspondence_address = {A. Ouatiq; SSDIA Laboratory, ENSET Mohammedia, Hassan II University of Casablanca, Mohammedia, Morocco; email: amina.ouatiq@gmail.com},
	editor = {Maleh Y. and Alazab M. and Gherabi N. and Tawalbeh L. and Abd El-Latif A.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303091737-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Singh2022611,
	author = {Singh, Manjeet and Bangay, Shaun and Sajjanhar, Atul},
	title = {An Architecture for Capturing and Presenting Learning Outcomes using Augmented Reality Enhanced Analytics},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct, ISMAR-Adjunct 2022},
	pages = {611 – 612},
	doi = {10.1109/ISMAR-Adjunct57072.2022.00126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146055295&doi=10.1109%2fISMAR-Adjunct57072.2022.00126&partnerID=40&md5=7ffff2c9f42a038706fae2404873569a},
	affiliations = {Deakin University, School of Information Technology, Geelong, Australia},
	abstract = {Augmented Reality (AR) applications have the capabilities to collect a range of sensor data that is relevant to educators. We propose a platform for using AR to enhance learning analytics by 1) Capturing information from a range of sources including directly from sensors but also from interactions and outcomes within the AR experience. 2) Deriving metrics from this sensory data to provide five categories of measure representing the quality of the learning experience: namely (a) Learning Analytics, (b) Interaction Analytics, (c) Spatial Analytics, (d) Sensory Analytics and (d) Emotion Analytics. 3) Presenting real-time information as analytics to teachers directly as an information overlay using an AR view within the classroom and customised to each student. 4) Closing the student-teacher-student feedback loop so that analytics information feeds directly into teaching in addition to assessment after the event. We evaluate the feasibility of this architecture by 1) Providing a proof-of-concept demonstration showing that the required data can be collected on the targeted platforms. 2) Identifying relevant educational metrics and relating these to the sensor data being collected. 3) Creating educational augmented reality applications and validating these with learners. 4) Identifying teacher requirements with respect to the use of analytics dashboards. The proposed architecture ensures that teachers can differentiate teaching support for each student based on individual needs across the range of learning needs.  © 2022 IEEE.},
	author_keywords = {analytics; architecture; Augmented reality; education},
	keywords = {Architecture; Sensory perception; Students; Analytic; Augmented reality applications; Enhance learning; Interaction analytics; Learning experiences; Learning outcome; Real-time information; Sensors data; Sensory data; Teachers'; Augmented reality},
	correspondence_address = {M. Singh; Deakin University, School of Information Technology, Geelong, Australia; email: manjeet@deakin.edu.au},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166545365-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Mixed Augment. Real. Adjun., ISMAR-Adjunct},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Pascual202226,
	author = {Pascual, Iván and Cobos, Ruth},
	title = {A proposal for predicting and intervening on MOOC learners' performance in real time},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3238},
	pages = {26 – 38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139852433&partnerID=40&md5=9ff13f3972499039da5c63908206219a},
	affiliations = {Computer Science Department, Universidad Autónoma de Madrid, Spain},
	abstract = {There is a lot of data from MOOCs, but their instructors cannot process that much information. While many learners end up dropping out of the course in which they enrolled in, a substantial problem in this context, their engagement data reveals their lack of interest even before they drop out. In order to make use of this information, we propose a Machine Learning approach to predict in real-time whether a learner would drop out or pass the MOOC, and a web-based dashboard approach to support this information and provide interventions over these learners. Using it in an asynchronous MOOC for 4 months, we predicted, with 0.93 F1-Score, the dropouts and passes from that period. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Dashboard; Engagement; Intervention; Learning Analytics; Machine Learning; Massive Open Online Course; Prediction; Prescription},
	keywords = {Drops; E-learning; Machine learning; Dashboard; Drop-out; Engagement; Intervention; Learning analytic; Machine-learning; Massive open online course; Performance; Prescription; Real- time; Forecasting},
	editor = {Vazquez-Ingelmo A. and University of Salamanca, Department of Computer Science and Automatics, GRIAL Research Group, Paseo de Canalejas 169, Salamanca and Dimitriadis Y. and Martinez-Mones A. and Garcia-Penalvo F.J. and University of Salamanca, Department of Computer Science and Automatics, GRIAL Research Group, Paseo de Canalejas 169, Salamanca},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@BOOK{Rienties2022260,
	author = {Rienties, Bart and Herodotou, Christothea},
	title = {Making sense of learning data at scale},
	year = {2022},
	journal = {Handbook of Digital Higher Education},
	pages = {260 – 270},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174233137&partnerID=40&md5=55fa3dcd7422adf08dd4b51e32797566},
	affiliations = {Institute of Educational Technology, Open University, United Kingdom; The Open University, United Kingdom},
	abstract = {In many higher educational institutions teachers and managers have unprecedented levels of access to data of learners and their learning. In particular during COVID-19 teachers suddenly had to make sense of what their learners were doing away from the classroom. In this chapter we will provide a range of evidence-based guidelines and best-practices based upon implementing online learning and making sense of learning data on a large-scale institutional level. The Open University UK has been implementing learning analytics at scale and has made learning analytics dashboards available to thousands of teachers. How to make sense of these interactive data streams is complex at the best of times, especially in a situation when most teachers are working remotely. We will reflect on our lived experiences of helping teachers to make sense of learning data, and how their voices are essential for senior managers to build powerful data practices. © Rhona Sharpe, Sue Bennett and Tünde Varga-Atkins 2022. All rights reserved.},
	publisher = {Edward Elgar Publishing Ltd.},
	isbn = {978-180088849-4; 978-180088848-7},
	language = {English},
	abbrev_source_title = {Handb. of Digit. High. Educ.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Pal20221800,
	author = {Pal, Neeti and Dahiya, Omdev},
	title = {Role of Learning Management System for Evaluating Students' progress in Learning Environment},
	year = {2022},
	journal = {Proceedings of 5th International Conference on Contemporary Computing and Informatics, IC3I 2022},
	pages = {1800 – 1806},
	doi = {10.1109/IC3I56241.2022.10072794},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151933748&doi=10.1109%2fIC3I56241.2022.10072794&partnerID=40&md5=0a47169f9711c5d234ee54335d80db26},
	affiliations = {Lovely Professional University, School of Computer Applications, Punjab, India; Lovely Professional University, School of Computer Science and Engineering, Punjab, India},
	abstract = {The paper contributes to getting familiar with various tools and platforms incorporated with learning dashboards that provide digital teaching and learning. The article also includes the different components for learning analytics used by various universities in their LMSs dashboards to improve their teaching-learning achievements. Learning analytics dashboards plays a vital role in the virtual learning environment. These tools work by tracking learners' data, analyzing data, and presenting the results by revealing the patterns of learners' behavior and attitude. This paper contributes to an analysis of learning dashboards and tools. The article also explains how these tools track, extract and analyze the students' learning progress and monitor their activities. Various visualization techniques are also discussed in this paper. This study will help determine the impact of using learning tools to evaluate learners' learning outcomes.  © 2022 IEEE.},
	author_keywords = {Educational Data Mining; Learning Analytics; Learning Analytics Dashboard (LAD); Learning Management System; Moodle; Visualization techniques},
	keywords = {Data mining; E-learning; Information management; Learning systems; Students; Visualization; Digital teachings; Digital-learning; Educational data mining; Learning analytic; Learning analytic dashboard; Learning environments; Learning management system; Moodle; Student progress; Visualization technique; Computer aided instruction},
	correspondence_address = {N. Pal; Lovely Professional University, School of Computer Applications, Punjab, India; email: neetipal08@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039826-7},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Contemp. Comput. Informatics, IC3I},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Fiacco202275,
	author = {Fiacco, James and Jiang, Shiyan and Adamson, David and Rosé, Carolyn P.},
	title = {Learning analytics},
	year = {2022},
	journal = {International Encyclopedia of Education: Fourth Edition},
	pages = {75 – 82},
	doi = {10.1016/B978-0-12-818630-5.14012-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150552543&doi=10.1016%2fB978-0-12-818630-5.14012-6&partnerID=40&md5=674c8fa65bde9e9f5c83b9bde75fdc4c},
	affiliations = {Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, United States; School of Education, North Carolina State University, Raleigh, NC, United States; Turnitin, Pittsburgh, PA, United States; Language Technologies Institute, Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Educational Data Mining and Learning Analytics have emerged over the past decade as interdisciplinary fields encompassing learning (e.g., learning sciences), analytics (e.g., data science), and human-centered design (e.g., usability of dashboards). In this chapter, we provide a broad overview of research in these fields, with a focus on the area of modeling unstructured natural language data. We present key lessons learned and suggest potential steps forward for building a productive interdisciplinary community. We also discuss the need of learning from each other's perspectives and challenging the underlying assumptions and unintentional bias that we may bring into the process of mining educational data. © 2023 Elsevier Ltd. All rights reserved.},
	author_keywords = {Automated assessment; Collaborative process analysis; Data-driven instruction; Educational data mining; Learning analytics},
	publisher = {Elsevier},
	isbn = {978-012818629-9},
	language = {English},
	abbrev_source_title = {International Encyclopedia of Education: Fourth Edition},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nwachukwu202218,
	author = {Nwachukwu, Uchendu and Hernández-García, Ángel and Cuenca-Enrique, Carlos and Del-Río-Carazo, Laura},
	title = {InDash: An Interactions Dashboard to Analyze Moodle Logs},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3238},
	pages = {18 – 25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139861264&partnerID=40&md5=cb14b15a6dccf0fa46240a0ae30d9713},
	affiliations = {Zürcher Hochschule für Angewandte Wissenschaften, Gertrudstrasse 15, Winterthur, 8400, Switzerland; Departamento de Ingeniería de Organización, Administración de Empresas y Estadística, Escuela Técnica Superior de Ingenieros de Telecomunicación, Universidad Politécnica de Madrid, Avenida Complutense 30, Madrid, 28040, Spain},
	abstract = {This study presents InDash, a learning analytics web service and web application dashboard to collect, analyze and visualize Moodle log data in the form of interaction categories. The document provides an overview of learning analytics applications and data collection processes in learning analytics, with an emphasis on log-based learning analytics indicators. To showcase the use and application of InDash, we propose an example categorization of indicators, based on different learning cycle theories, and we detail the main components of the system: a web service that exposes Moodle log for data collection, and the web application for data categorization, analysis and visualization. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Dashboard; Data Extraction; Data Visualization; Descriptive Analytics; Learning Analytics; Logs; Moodle},
	keywords = {Data acquisition; Learning systems; Visualization; Web services; Websites; Dashboard; Data extraction; Descriptive analytic; Learning analytic; Log; Log data; Moodle; WEB application; Web applications; Web service applications; Data visualization},
	editor = {Vazquez-Ingelmo A. and University of Salamanca, Department of Computer Science and Automatics, GRIAL Research Group, Paseo de Canalejas 169, Salamanca and Dimitriadis Y. and Martinez-Mones A. and Garcia-Penalvo F.J. and University of Salamanca, Department of Computer Science and Automatics, GRIAL Research Group, Paseo de Canalejas 169, Salamanca},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Khosravi2021133,
	author = {Khosravi, Hassan and Shabaninejad, Shiva and Bakharia, Aneesha and Sadiq, Shazia and Indulska, Marta and Gašević, Dragan},
	title = {Intelligent Learning Analytics Dashboards: Automated Drill-Down Recommendations to Support Teacher Data Exploration},
	year = {2021},
	journal = {Journal of Learning Analytics},
	volume = {8},
	number = {3},
	pages = {133 – 154},
	doi = {10.18608/jla.2021.7279},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122214166&doi=10.18608%2fjla.2021.7279&partnerID=40&md5=e29e56af070fb507323b682357e45fd3},
	affiliations = {Institute for Teaching and Learning Innovation, The University of Queensland, St Lucia, Brisbane, 4072, QLD, Australia; School of Information Technology and Electrical Engineering, The University of Queensland, St Lucia, Brisbane, 4072, QLD, Australia; Business School, The University of Queensland, St Lucia, Brisbane, 4072, QLD, Australia; Faculty of Information Technology, Monash University, Melbourne, 3800, VIC, Australia},
	abstract = {Learning analytics dashboards commonly visualize data about students with the aim of helping students and educators understand and make informed decisions about the learning process. To assist with making sense of complex and multidimensional data, many learning analytics systems and dashboards have relied strongly on AI algorithms based on predictive analytics. While predictive models have been successful in many domains, there is an increasing realization of the inadequacies of using predictive models in decision-making tasks that affect individuals without human oversight. In this paper, we employ a suite of state-of-the-art algorithms, from the online analytics processing, data mining, and process mining domains, to present an alternative human-in-the-loop AI method to enable educators to identify, explore, and use appropriate interventions for subpopulations of students with the highest deviation in performance or learning process compared to the rest of the class. We demonstrate an application of our proposed approach in an existing learning analytics dashboard (LAD) and explore the recommended drill-downs in a course with 875 students. The demonstration provides an example of the recommendations from real course data and shows how recommendations can lead the user to interesting insights. Furthermore, we demonstrate how our approach can be employed to develop intelligent LADs. © 2021, UTS ePRESS. All rights reserved.},
	author_keywords = {Drill-down analysis; Intelligent dashboards; Learning analytics dashboards; Process mining in education},
	correspondence_address = {H. Khosravi; Institute for Teaching and Learning Innovation, The University of Queensland, Brisbane, St Lucia, 4072, Australia; email: h.khosravi@uq.edu.au},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jin2021604,
	author = {Jin, Sung-Hee},
	title = {Educational Effects on the Transparency of Peer Participation Levels in Asynchronous Online Discussion Activities},
	year = {2021},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {14},
	number = {5},
	pages = {604 – 612},
	doi = {10.1109/TLT.2021.3126388},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123597204&doi=10.1109%2fTLT.2021.3126388&partnerID=40&md5=5260c9ceb702d14be3aff211eab4cd28},
	affiliations = {Division of Humanities and Liberal Arts, Hanbat National University, Daejeon, South Korea},
	abstract = {Participation dashboards in online discussions are learning support tools that can have a positive effect on learners' learning outcomes and satisfaction levels, but their effectiveness differs according to how learners recognize and interpret them. However, there is a lack of research investigating the effectiveness of visualization methods regarding learners' participation levels. Accordingly, in this study, two visualization methods are applied to participation dashboards to show peer participation levels and to support online discussion activities. The Transparent Participation Dashboard (TPD) provides the exact participation levels for all learners who participate in an online discussion, whereas the Private Participation Dashboard (PPD) visualizes a learner's relative level of participation in comparison to the average value of a class. This study aimed to compare the effects of these two types of participation dashboards on the behavioral, cognitive, and affective aspects of online discussion activities. Toward this end, we conducted an experimental study. The participants included 62 undergraduate students who were randomly assigned to two groups. Thirty-two students were assigned to the Transparent group, which received the TPD. Thirty students were assigned to the Private group, which received the PPD. Our findings showed no significant difference in usability, quality of discussions, or learning outcomes between the two groups. However, the Transparent group was more active in its online discussions and expressed more negative satisfaction with the dashboard. This study's conclusions suggest that dashboards for promoting learner competitiveness can positively affect learners' behavioral aspects but they may negatively impact their emotions.  © 2008-2011 IEEE.},
	author_keywords = {Asynchronous online discussion; emotions; learning analytics; learning outcomes; participation dashboard; visual design directions},
	keywords = {E-learning; Learning systems; Students; Visualization; Asynchronous online discussion; Emotion; Learning analytic; Learning outcome; Online discussions; Participation dashboard; Private participation; Visual design; Visual design direction; Visualization method; Social networking (online)},
	correspondence_address = {S.-H. Jin; Division of Humanities and Liberal Arts, Hanbat National University, Daejeon, South Korea; email: shjin@hanbat.ac.kr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Pérez-Sanagustín2022324,
	author = {Pérez-Sanagustín, Mar and Pérez-Álvarez, Ronald and Maldonado-Mahauad, Jorge and Villalobos, Esteban and Sanza, Cédric},
	title = {Designing a Moodle Plugin for Promoting Learners’ Self-regulated Learning in Blended Learning},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {324 – 339},
	doi = {10.1007/978-3-031-16290-9_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137996525&doi=10.1007%2f978-3-031-16290-9_24&partnerID=40&md5=36d49893b88ea0e44fa0d05aa9455c18},
	affiliations = {IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; University of Costa Rica, Sede del Pacífico, Puntarenas, Costa Rica; Department of Computer Science, University of Cuenca, Cuenca, Ecuador},
	abstract = {After the COVID-19 pandemic, universities moved towards online and Blended Learning (BL) modes to offer greater curricular flexibility. Yet, recent research shows that students have difficulties regulating their learning strategies to adapt to the different learning modes that BL entails, which mixes face-to-face with online activities taking place in different learning contexts and environments. Prior work on Self-Regulated Learning (SRL) has explored the use of dashboard-based scaffolds for supporting students’ learning strategies. However, most existing solutions are designed for supporting students in online settings (i.e., MOOCs), disregarding the teachers’ role in BL settings and the support they need to monitor and promote students’ SRL. This paper presents the design process followed for transforming a tool designed for supporting students’ SRL in MOOCs into a Moodle plugin for BL. Following a design-based research methodological approach, we describe all the phases conducted for identifying the most appropriate indicators and visualizations for supporting SRL in BL practices, implementing and evaluating a first prototype. Results of a local evaluation with 114 teachers and a broad evaluation with 311 students shed some light on the type of indicators, dashboards and functionalities that should be considered when designing solutions for supporting SRL in BL settings. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Blended learning; Dashboards; Design-based research; Learning analytics; Self-regulated learning},
	keywords = {Design; E-learning; Learning systems; Scaffolds; Blended learning; Dashboard; Design-based research; Learning analytic; Learning mode; Learning settings; Learning strategy; Online learning; Plug-ins; Self-regulated learning; Students},
	correspondence_address = {M. Pérez-Sanagustín; IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; email: mar.perez-sanagustin@irit.fr},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Praharaj2022358,
	author = {Praharaj, Sambit and Scheffel, Maren and Schmitz, Marcel and Specht, Marcus and Drachsler, Hendrik},
	title = {Towards Collaborative Convergence: Quantifying Collaboration Quality with Automated Co-located Collaboration Analytics},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {358 – 369},
	doi = {10.1145/3506860.3506922},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126267168&doi=10.1145%2f3506860.3506922&partnerID=40&md5=46c4c205027caebd521ea922b7f77562},
	affiliations = {The Open University of the Netherlands, Limburg, Heerlen, Netherlands; Ruhr University Bochum, Bochum, Germany; Zuyd University of Applied Sciences, Heerlen, Netherlands; Delft University of Technology, Delft, Netherlands; DIPF Leibniz Institute for Research and Information in Education, Frankfurt am Main, Germany; Goethe University, Frankfurt am Main, Germany},
	abstract = {Collaboration is one of the four important 21st-century skills. With the pervasive use of sensors, interest on co-located collaboration (CC) has increased lately. Most related literature used the audio modality to detect indicators of collaboration (such as total speaking time and turn taking). CC takes place in physical spaces where group members share their social (i.e., non-verbal audio indicators like speaking time, gestures) and epistemic space (i.e., verbal audio indicators like the content of the conversation). Past literature has mostly focused on the social space to detect the quality of collaboration. In this study, we focus on both social and epistemic space with an emphasis on the epistemic space to understand different evolving collaboration patterns and collaborative convergence and quantify collaboration quality. We conduct field trials by collecting audio recordings in 14 different sessions in a university setting while the university staff and students collaborate over playing a board game to design a learning activity. This collaboration task consists of different phases with each collaborating member having been assigned a pre-fixed role. We analyze the collected group speech data to do role-based profiling and visualize it with the help of a dashboard.  © 2022 ACM.},
	author_keywords = {co-located collaboration; collaboration; collaboration analytics; multimodal learning analytics},
	keywords = {Co-located collaboration; Collaboration; Collaboration analytic; Collaboration patterns; Field trial; Group members; Multi-modal learning; Multimodal learning analytic; Social spaces; Turn-taking},
	correspondence_address = {S. Praharaj; The Open University of the Netherlands, Heerlen, Netherlands; email: sambitp6@gmail.com},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Pozdniakov2021176,
	author = {Pozdniakov, Stanislav and Martinez-Maldonado, Roberto and Singh, Shaveen and Chen, Peter and Richardson, Dan and Bartindale, Tom and Olivier, Patrick and Gasevic, Dragan},
	title = {Question-driven learning analytics: Designing a teacher dashboard for online breakout rooms},
	year = {2021},
	journal = {Proceedings - IEEE 21st International Conference on Advanced Learning Technologies, ICALT 2021},
	pages = {176 – 178},
	doi = {10.1109/ICALT52272.2021.00060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114879505&doi=10.1109%2fICALT52272.2021.00060&partnerID=40&md5=bfe24182cf204a513a57dfa909a53ca6},
	affiliations = {Centre for Learning Analytics at Monash, Faculty of Information Technology, Monash University, Australia; Monash University, Action Lab, Faculty of Information Technology, Australia},
	abstract = {One of the ultimate goals of several learning analytics (LA) initiatives is to close the loop and support students' and teachers' reflective practices. Although there has been a proliferation of end-user interfaces (often in the form of dashboards), various limitations have already been identified in the literature such as little account for sensemaking needs. This paper addresses these limitations by proposing a question-driven LA design approach to ensure that end-user LA interfaces explicitly address teachers' questions. We illustrate this in the context of synchronous online activities orchestrated by pairs of teachers using audio-visual and text-based tools (Zoom and Google Docs). This led to the design of an open-source monitoring tool to be used in real-time by teachers when students work collaboratively in breakout rooms, and across learning spaces.  © 2021 IEEE.},
	author_keywords = {Computer aided instruction; Learning management systems},
	keywords = {E-learning; Design approaches; End-user interfaces; Google docs; Monitoring tools; Online activities; Open sources; Reflective practices; Sensemaking; User interfaces},
	editor = {Chang M. and Chen N.-S. and Sampson D.G. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166544106-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Aguilar2022556,
	author = {Aguilar, Stephen J},
	title = {Experimental Evidence of Performance Feedback vs. Mastery Feedback on Students' Academic Motivation},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {556 – 562},
	doi = {10.1145/3506860.3506916},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126218952&doi=10.1145%2f3506860.3506916&partnerID=40&md5=416d38c5d280c5e091ff8132179aea91},
	affiliations = {Rossier School of Education, University of Southern California, Los Angeles, CA, United States},
	abstract = {Work throughout the learning analytics community has examined associations between Learning Analytics Dashboard (LAD) features and a number of important student outcomes, including academic motivation and self-regulated learning strategies. While there are many potential implications of visualized academic information within a LAD on student outcomes, there remains an unanswered question: are there causal differences between showing performance information (e.g., comparing students' progress to the class average) vs. mastery information (e.g., their individual score) on students' motivation? Grounded in Achievement Goal Theory, this study answers this question experimentally by analyzing the difference between college students' (n=445) reported achievement goal orientations as well as their motivated information seeking orientations after being presented with performance or mastery feedback. Results indicate that students in a performance condition which displayed "above average"achievement on an academic measure reported lower performance-avoidance goals (e.g., not wanting to do worse than everyone else), and performance-avoidance information-seeking goals (e.g., not wanting to seek out information showing that one does worse than peers) when compared to students in the mastery control condition. This study contributes to our understanding of the motivational implications of academic feedback presented to students, and suggests that comparative information has direct effects on student motivation. Results thus uncover a potential tension between what might seem intuitive feedback to give students versus what might be more motivationally appropriate. The implications of this work point to the need to understand LADs not simply as feedback mechanisms, but as embedded features of a learning environment that influence how students engage with course content.  © 2022 Owner/Author.},
	author_keywords = {Higher Education; Motivation; Non-cognitive factors; Visualizations},
	keywords = {Computer aided instruction; Curricula; Feedback; Information use; Learning systems; Students; Academic motivations; Cognitive factors; Condition; Experimental evidence; High educations; Information seeking; Non-cognitive factor; Performance; Student motivation; Student outcomes; Motivation},
	correspondence_address = {S.J. Aguilar; Rossier School of Education, University of Southern California, Los Angeles, United States; email: aguilars@usc.edu},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Bronze Open Access}
}

@CONFERENCE{Helgert2022125,
	author = {Helgert, Andre and Canbulat, Anil and Lingnau, Andreas and Strasmann, Carolin},
	title = {A Framework for Analyzing Interactions in a Video-based Collaborative Learning Environment},
	year = {2022},
	journal = {Proceedings - 2022 International Conference on Advanced Learning Technologies, ICALT 2022},
	pages = {125 – 127},
	doi = {10.1109/ICALT55010.2022.00045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137005435&doi=10.1109%2fICALT55010.2022.00045&partnerID=40&md5=7d5b215bac8e58119714f3f858280509},
	affiliations = {Institute of Computer Science, Ruhr West Univ. of Applied Sciences, Bottrop, Germany},
	abstract = {Studying in social isolation is a reality for many students that was further reinforced after the start of the COVID-19 pandemic. Research shows that isolation can lead to decreased learning efficiency and is intensified by the increased asynchronous online teaching during the pandemic. This change is not only challenging for students, but also for teachers, as students do not have a direct communication and feedback channel when learning content is presented in form of pre-recorded videos in a learning management system. In this paper, we present VGather2Learn Analytics, which is an extension to the already existing collaborative learning system VGather2Learn, which makes it possible for teachers to analyse the learning behavior of students in asynchronous video-teaching. The information presented in a dashboard will allow teachers to better understand how students interact while watching learning videos collaboratively and can improve online-teaching.  © 2022 IEEE.},
	author_keywords = {Computer-supported Collaborative Learning; Learning Analytics; Social Learning},
	keywords = {Computer aided instruction; E-learning; Learning systems; Collaborative learning environment; Communications channels; Computer Supported Collaborative Learning; Direct communications; Learning analytic; Learning efficiency; Online teaching; Social isolation; Social learning; Teachers'; Students},
	editor = {Chang M. and Chen N.-S. and Dascalu M. and Sampson D.G. and Tlili A. and Trausan-Matu S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166549519-6},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Lajoie2021460,
	author = {Lajoie, Susanne P.},
	title = {Student Modeling for Individuals and Groups: the BioWorld and HOWARD Platforms},
	year = {2021},
	journal = {International Journal of Artificial Intelligence in Education},
	volume = {31},
	number = {3},
	pages = {460 – 475},
	doi = {10.1007/s40593-020-00219-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092764305&doi=10.1007%2fs40593-020-00219-x&partnerID=40&md5=b0294b5a16179eed4958d345ba1baf7d},
	affiliations = {McGill University, Montreal, QC, Canada},
	abstract = {I first met Jim Greer at the NATO Advanced Study Institute on Syntheses of Instructional Sciences and Computing Science for Effective Instructional Computing Systems in 1990 in Calgary, Canada. It was during this meeting that I came to realize that Jim was one of those rare individuals that could help “translate” computer science principles to non-computer scientists. Through this translation process new knowledge could be developed through interdisciplinary partnerships with psychology and education. In this paper, I describe the manner in which Jim influenced my own journey in the field of Artificial Intelligence and Education. In particular, he has influenced two directions in my research, one direction is the manner in which technology can influence teaching and learning for individuals working solo. The second direction is how technology can influence teaching and learning through collaboration. In both situations I will discuss Jim Greer’s influence on my research with respect to learner modelling, educational data mining, and visualization. In the context of solo learning, I will discuss BioWorld, a system that fosters clinical reasoning in medical students, emphasizing the role of student modeling and educational data mining for fostering and identifying performance differences in clinical reasoning. In the context of collaborative learning, I will discuss HOWARD, an online platform for supporting small group problem-based learning in medical students. In particular, I will discuss the role of learning analytics used in a pedagogical dashboard to foster teachers’ interpretation of group learning. © 2020, International Artificial Intelligence in Education Society.},
	author_keywords = {Learner modeling; Learning analytics; Medical problem solving; Pedagogical dashboard; Visualization},
	keywords = {Artificial intelligence; Data mining; Data visualization; Medical computing; Students; Teaching; Collaborative learning; Computer scientists; Educational data mining; Instructional computing; Instructional science; Problem based learning; Teaching and learning; Translation process; Learning systems},
	correspondence_address = {S.P. Lajoie; McGill University, Montreal, Canada; email: Susanne.lajoie@mcgill.ca},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Tzi-Dong Ng2022444,
	author = {Tzi-Dong Ng, Jeremy and Wang, Zuo and Hu, Xiao},
	title = {Needs Analysis and Prototype Evaluation of Student-facing la Dashboard for Virtual Reality Content Creation},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {444 – 450},
	doi = {10.1145/3506860.3506880},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126194798&doi=10.1145%2f3506860.3506880&partnerID=40&md5=9b2c23c2822cead09e4aa0a603584209},
	affiliations = {Faculty of Education, The University of Hong Kong, Hong Kong, Hong Kong},
	abstract = {Being a promising constructionist pedagogy in recent years, maker education empowers students to take agency of their learning process through constructing both knowledge and real-world physical or digital products and fosters peer interactions for collective innovation. Learning Analytics (LA) excels at generating personalized, fine-grained feedback in near real-time and holds much potential in supporting process-oriented and peer-supported learning activities, including maker activities. In the context of virtual reality (VR) content creation for cultural heritage education, this study qualitatively solicited 27 students' needs on progress monitoring, reflection, and feedback during their making process. Findings have inspired the prototype design of a student-facing LA dashboard (LAVR). Leveraging multimodal learning analytics (MmLA) such as text and audio analytics to fulfill students' needs, the prototype has various features and functions including automatic task reminders, content quality detection, and real-time feedback on quality of audio-visual elements. A preliminary evaluation of the prototype with 10 students confirms its potential in supporting students' self-regulated learning during the making process and for improving the quality of VR content. Implications on LA design for supporting maker education are discussed. Future work is planned to include implementation and evaluation of the dashboard in classrooms.  © 2022 ACM.},
	author_keywords = {Dashboard; Needs analysis; Prototype evaluation; VR content creation},
	keywords = {Facings; Quality control; Virtual reality; Content creation; Dashboard; Digital products; Learning process; Making process; Need analysis; Physical products; Prototype evaluation; Real-world; Virtual reality content creation; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Duan2022117,
	author = {Duan, Xiaojing and Wang, Chaoli and Rouamba, Guieswende},
	title = {Designing a Learning Analytics Dashboard to Provide Students with Actionable Feedback and Evaluating Its Impacts},
	year = {2022},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {117 – 127},
	doi = {10.5220/0011116400003182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140894999&doi=10.5220%2f0011116400003182&partnerID=40&md5=29f03c3caf5cf32e4d310019db49b613},
	affiliations = {University of Notre Dame, Notre Dame, IN, United States; Purdue University Fort Wayne, Fort Wayne, IN, United States},
	abstract = {Various educational settings have begun to increasingly leverage the power of data analytics to optimize the learning environment and enhance the learning experience for students. However, despite this effort, significant research gaps still exist around utilizing educational data mining to provide students with actionable feedback and assess the comprehensive impact of data-informed feedback on students. In this study, a learning analytics dashboard was designed to provide students with actionable feedback to advance their self-regulated learning skills and improve their course performance. A rigorous inquiry using mixed methods was also conducted to study the dashboard’s impacts on students. It found that students’ use of the dashboard was positively correlated with their course performance, and those who viewed the dashboard had higher course ranks. In addition, it showed that students’ use of the dashboard was positively correlated with their homework submission time, and those who viewed the dashboard submitted homework earlier as the course progressed. The inquiry also revealed that students had mixed feelings about the dashboard, including motivation and anxiety. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Actionable Feedback; Learning Analytics Dashboard; Machine Learning; Self-regulated Learning},
	keywords = {Computer aided instruction; Data Analytics; Data mining; Machine learning; Actionable feedback; Course performance; Data analytics; Educational settings; Learning analytic dashboard; Learning environments; Learning experiences; Machine-learning; Power; Self-regulated learning; Students},
	editor = {Cukurova M. and Rummel N. and Gillet D. and McLaren B. and Uhomoibhi J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758562-3},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Albó20224,
	author = {Albó, Laia and Barria-Pineda, Jordan and Brusilovsky, Peter and Hernández-Leo, Davinia},
	title = {Knowledge-Based Design Analytics for Authoring Courses with Smart Learning Content},
	year = {2022},
	journal = {International Journal of Artificial Intelligence in Education},
	volume = {32},
	number = {1},
	pages = {4 – 27},
	doi = {10.1007/s40593-021-00253-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106517080&doi=10.1007%2fs40593-021-00253-3&partnerID=40&md5=96ffcfbbdb34ee9277c1d3dda27273b8},
	affiliations = {Department of Information and Communications Technologies, Universitat Pompeu Fabra, Roc Boronat, 138, Barcelona, 08018, Spain; School of Computing and Information, University of Pittsburgh, 135 N. Bellefield Ave, Pittsburgh, 15213, United States},
	abstract = {Over the last 10 years, learning analytics have provided educators with both dashboards and tools to understand student behaviors within specific technological environments. However, there is a lack of work to support educators in making data-informed design decisions when designing a blended course and planning appropriate learning activities. In this paper, we introduce knowledge-based design analytics that uncover facets of the learning activities that are being created. A knowledge-based visualization is integrated into edCrumble, a (blended) learning design authoring tool. This new approach is explored in the context of a higher education programming course, where instructors design labs and home practice sessions with online smart learning content on a weekly basis. We performed a within-subjects user study to compare the use of the design tool both with and without visualization. We studied the differences in terms of cognitive load, controllability, confidence and ease of choice, design outcomes, and user actions within the system to compare both conditions with the objective of evaluating the impact of using design analytics during the decision-making phase of course design. Our results indicate that the use of a knowledge-based visualization allows the teachers to reduce the cognitive load (especially in terms of mental demand) and that it facilitates the choice of the most appropriate activities without affecting the overall design time. In conclusion, the use of knowledge-based design analytics improves the overall learning design quality and helps teachers avoid committing design errors. © 2021, International Artificial Intelligence in Education Society.},
	author_keywords = {Authoring tool; Blended learning; Concept-level visualization; Design analytics; Knowledge-based analytics; Learning design; Smart learning content},
	keywords = {Decision making; Knowledge based systems; Teaching; Visualization; Design decisions; Higher education; Knowledge based design; Learning Activity; Learning contents; Learning designs; Programming course; Technological environment; Curricula},
	correspondence_address = {L. Albó; Department of Information and Communications Technologies, Universitat Pompeu Fabra, Barcelona, Roc Boronat, 138, 08018, Spain; email: laia.albo@upf.edu},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@CONFERENCE{Ahmad202258,
	author = {Ahmad, Atezaz and Schneider, Jan and Weidlich, Joshua and Di Mitri, Daniele and Yau, Jane Yin-Kim and Schiffner, Daniel and Drachsler, Hendrik},
	title = {What Indicators Can I Serve You with? An Evaluation of a Research-Driven Learning Analytics Indicator Repository},
	year = {2022},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {1},
	pages = {58 – 68},
	doi = {10.5220/0010995800003182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137976452&doi=10.5220%2f0010995800003182&partnerID=40&md5=cdcfa4a3c2e56184a2feeb7e383319af},
	affiliations = {DIPF, Leibniz Institute for Research and Information in Education, Frankfurt, Germany},
	abstract = {In recent years, Learning Analytics (LA) has become a very heterogeneous research field due to the diversity in the data generated by the Learning Management Systems (LMS) as well as the researchers in a variety of disciplines, who analyze this data from a range of perspectives. In this paper, we present the evaluation of a LA tool that helps course designers, teachers, students and educational researchers to make informed decisions about the selection of learning activities and LA indicators for their course design or LA dashboard. The aim of this paper is to present Open Learning Analytics Indicator Repository (OpenLAIR) and provide a first evaluation with key stakeholders (N=41). Moreover, it presents the results of the prevalence of indicators that have been used over the past ten years in LA. Our results show that OpenLAIR can support course designers in designing LA-based learning activities and courses. Furthermore, we found a significant difference between the relevance and usage of LA indicators between educators and learners. The top rated LA indicators by researchers and educators were not perceived as equally important from students' perspectives. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Evidence-based Research; Indicators; Learning Activities; Learning Analytics; Learning Events; Metrics; Tool},
	keywords = {E-learning; Information management; Analytic tools; Evidence based researches; Learning Activity; Learning analytic; Learning event; Learning management system; Metric; Open learning; Research fields; Research-driven; Curricula},
	editor = {Cukurova M. and Rummel N. and Gillet D. and McLaren B. and Uhomoibhi J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758562-3},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tretow-Fish202237,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin},
	title = {Evaluating Learning Analytics of Adaptive Learning Systems: A Work in Progress Systematic Review},
	year = {2022},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {435 LNICST},
	pages = {37 – 52},
	doi = {10.1007/978-3-031-06675-7_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131941380&doi=10.1007%2f978-3-031-06675-7_3&partnerID=40&md5=1f6f62698fa9028b553174c667cf4798},
	affiliations = {Department of Applied Mathematics and Computer Science at the Technical University of Denmark, Kongens Lyngby, Denmark},
	abstract = {There is currently no systematic overview of methods for evaluating Learning Analytics (LA) and Learning Analytics Dashboards (LAD) of Adaptive Learning Platforms (ALPs). 10 articles and 2 reviews are analyzed and synthesized. Focusing on the purposes of evaluation, methods used in the studies are grouped into five categories (C1-5): C1) evaluation of LA and LAD design and framework, C2) evaluation of performance with LA and LAD, C3) evaluation of adaptivity functions of the system, C4) evaluation of perceived value, and C5) Evaluation of pedagogical and didactic theory/context. While there is a relative high representation of evaluations in the C1-C4 categories of methods, which contribute to the design and development of the interaction and interface design features, the C5 category is not represented. The presence of pedagogical and didactical theory in the LA, LAD, and ALPs is lacking. Though traces of pedagogical theory is present none of the studies evaluates on its impact. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
	author_keywords = {Adaptive learning platforms; Evaluation; Learning analytics},
	keywords = {Learning systems; Adaptive learning; Adaptive learning platform; Adaptive learning systems; Evaluation; Evaluation methods; Learning analytic; Learning platform; Performance; Synthesised; Systematic Review; E-learning},
	correspondence_address = {T.A.B. Tretow-Fish; Department of Applied Mathematics and Computer Science at the Technical University of Denmark, Kongens Lyngby, Denmark; email: compute@compute.dtu.dk},
	editor = {Brooks E. and Sjöberg J. and Møller A.K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18678211},
	isbn = {978-303106674-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Afzaal2021,
	author = {Afzaal, Muhammad and Nouri, Jalal and Zia, Aayesha and Papapetrou, Panagiotis and Fors, Uno and Wu, Yongchao and Li, Xiu and Weegar, Rebecka},
	title = {Explainable AI for Data-Driven Feedback and Intelligent Action Recommendations to Support Students Self-Regulation},
	year = {2021},
	journal = {Frontiers in Artificial Intelligence},
	volume = {4},
	doi = {10.3389/frai.2021.723447},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120401479&doi=10.3389%2ffrai.2021.723447&partnerID=40&md5=9bb89f74ef3835f4155ee8b2f7122800},
	affiliations = {Department of Computer and Systems Sciences, Stockholm University, Stockholm, Sweden},
	abstract = {Formative feedback has long been recognised as an effective tool for student learning, and researchers have investigated the subject for decades. However, the actual implementation of formative feedback practices is associated with significant challenges because it is highly time-consuming for teachers to analyse students’ behaviours and to formulate and deliver effective feedback and action recommendations to support students’ regulation of learning. This paper proposes a novel approach that employs learning analytics techniques combined with explainable machine learning to provide automatic and intelligent feedback and action recommendations that support student’s self-regulation in a data-driven manner, aiming to improve their performance in courses. Prior studies within the field of learning analytics have predicted students’ performance and have used the prediction status as feedback without explaining the reasons behind the prediction. Our proposed method, which has been developed based on LMS data from a university course, extends this approach by explaining the root causes of the predictions and by automatically providing data-driven intelligent recommendations for action. Based on the proposed explainable machine learning-based approach, a dashboard that provides data-driven feedback and intelligent course action recommendations to students is developed, tested and evaluated. Based on such an evaluation, we identify and discuss the utility and limitations of the developed dashboard. According to the findings of the conducted evaluation, the dashboard improved students’ learning outcomes, assisted them in self-regulation and had a positive effect on their motivation. Copyright © 2021 Afzaal, Nouri, Zia, Papapetrou, Fors, Wu, Li and Weegar.},
	author_keywords = {AI; automatic data-driven feedback; dashboard; explainable machine learning-based approach; learning analytics; recommender system; self-regulated learning},
	correspondence_address = {M. Afzaal; Department of Computer and Systems Sciences, Stockholm University, Stockholm, Sweden; email: muhammad.afzaal@dsv.su.se},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 74; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2022,
	title = {LASI Spain 2022 - Proceedings of the Learning Analytics Summer Institute Spain 2022},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3238},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139865695&partnerID=40&md5=ea5a0eecfa266f9a336081c91b0c0c51},
	abstract = {The proceedings contain 10 papers. The topics discussed include: content-validation questionnaire of a meta-model to ease the learning of data visualization concepts; exploring the synergies between gamification and data collection in higher education; InDash: an interactions dashboard to analyze Moodle logs; a proposal for predicting and intervening on MOOC learners’ performance in real time; data mashups privacy preservation for learning analytics; unplugged institutions: towards a localization of the cloud for learning analytics privacy enhancement; using process mining to determine the relevance and impact of performing optional quizzes before evaluative assessments; human context in sentiment analysis symbolic technique; a proposal to measure the understanding of data visualization elements in visual analytics applications; and analyzing collaborative filtering for UNED freshman enrolment recommendation system.},
	editor = {Vazquez-Ingelmo A. and University of Salamanca, Department of Computer Science and Automatics, GRIAL Research Group, Paseo de Canalejas 169, Salamanca and Dimitriadis Y. and Martinez-Mones A. and Garcia-Penalvo F.J. and University of Salamanca, Department of Computer Science and Automatics, GRIAL Research Group, Paseo de Canalejas 169, Salamanca},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2022,
	title = {11th International Conference on Methodologies and Intelligent Systems for Technology Enhanced Learning, MIS4TEL 2021},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {326},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115646972&partnerID=40&md5=74d86a1b3e6cdc6a4303e1b1629fd301},
	abstract = {The proceedings contain 27 papers. The special focus in this conference is on Methodologies and Intelligent Systems for Technology Enhanced Learning. The topics include: What Children Learn in Smart-Thing Design at a Distance: An Exploratory Investigation; smart City Design as a 21 st Century Skill; engaging Children in Digital Storytelling; videotraining and Expert System: A New Peritoneal Dialysis Training Model; opinions and Experiences of Nursing Students About the High-Fidelity Simulation: A Multicentric Multi-method Sequential Study; time to Incorporate Artificial Intelligence into High-Fidelity Patient Simulators for Nursing Education: A Secondary Analysis of a Pilot Study; the Use of Robotics to Enhance Learning in Nursing Education: A Scoping Review; care Robots and Bioethics: A Discussion Paper on Moral Standing of New Training Opportunities; the Collaboration Among Pediatric Residents, Nursing and Midwifery Students for Newborn Health: A Quasi-experimental Study on Interprofessional High-Fidelity Patient Simulation; improved Automated Classification of Sentences in Data Science Exercises; gamification as a Motivational and Socio-educational Resource in Classrooms with Students at Risk of Social Exclusion; experiments on Gamification with Virtual and Augmented Reality for Practical Application Learning; a Tool to Assess Students’ Performance in Programming; Learning AnalyTICs: Exploring the Hypothetical Learning Trajectories Through Mathematical Games; applications of Gamification in the Context of Higher Education. A Theoretical Approach; a Framework for Online Education in Computer Science Degrees with a Focus on Motivation; the Influence of Gamification in Education: Possibilities, Regulation and Concerns; deep Learning to Monitor Massive Open Online Courses Dynamics; designing the Learning Analytics Cockpit - A Dashboard that Enables Interventions; preface.},
	editor = {De la Prieta F. and Gennari R. and Temperini M. and Di Mascio T. and Vittorini P. and Kubincova Z. and Popescu E. and Rua Carneiro D. and Lancia L. and Addone A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303086617-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Carlon2021267,
	author = {Carlon, May Kristine Jonson and Cross, Jeffrey S.},
	title = {Learning Analytics Dashboard Prototype for Implicit Feedback from Metacognitive Prompt Responses},
	year = {2021},
	journal = {29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings},
	volume = {1},
	pages = {267 – 272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125890979&partnerID=40&md5=204c75ac428ba066b6a37ad8bd3a12ab},
	affiliations = {School of Environment and Society, Tokyo Institute of Technology, Japan},
	abstract = {Online learning can be challenging to learners as they need to have autonomous learning skills to succeed, and to instructors as direct observation and real-time communication with learners are limited. Learning analytics dashboards have been used to assist the learners in developing autonomous learning skills and the instructors in keeping track of the learners’ progress. However, there is little information on systems supporting both learners and instructors in online learning environments. This paper builds on our previous work developing learners' metacognitive skills through open response prompts by using the learner inputs to create a dashboard that uncovers implicit feedback such as sentiments, misconceptions, and shallow learning. The instructor can consult the dashboard on-demand, and the input is from metacognitive prompts that only the individual learners see. Hence, the instructor can provide timely interventions based on inputs from learners who otherwise would not voice their concerns in more public channels such as discussion forums. © 2021 29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings. All rights reserved},
	author_keywords = {Learning analytics; Learning management system; Metacognitive prompting; Sentiment analysis; Text similarity; Topic modeling},
	keywords = {Computer aided instruction; E-learning; Learning systems; Online systems; Autonomous learning; Implicit feedback; Learning analytic; Learning management system; Learning skills; Metacognitive prompting; Metacognitives; Sentiment analysis; Text similarity; Topic Modeling; Sentiment analysis},
	correspondence_address = {J.S. Cross; School of Environment and Society, Tokyo Institute of Technology, Japan; email: cross.j.aa@m.titech.ac.jp},
	editor = {Rodrigo M.M.T. and Iyer S. and Mitrovic A. and Cheng H.N.H. and Kohen-Vacs D. and Matuk C. and Palalas A. and Rajenran R. and Seta K. and Wang J.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972147-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Ifenthaler2021184,
	author = {Ifenthaler, Dirk and Schumacher, Clara and Sahin, Muhittin},
	title = {System-based or teacher-based learning analytics feedback - What works best?},
	year = {2021},
	journal = {Proceedings - IEEE 21st International Conference on Advanced Learning Technologies, ICALT 2021},
	pages = {184 – 186},
	doi = {10.1109/ICALT52272.2021.00062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114891224&doi=10.1109%2fICALT52272.2021.00062&partnerID=40&md5=25e46bea997dee71336a41dc3f3921d1},
	affiliations = {University of Mannheim, Curtin University, Mannheim, Germany; Humboldt Universität zu Berlin, Berlin, Germany; University of Mannheim, Ege University, Bornova, Turkey},
	abstract = {Feedback has been identified as the most powerful moderator for supporting learning. Learning analytics haven been recognized for opportunities for providing timely and informative feedback to learners when they need it. This study seeks to investigate learners' perceptions and expected benefits of different forms of learning analytics feedback from different sources. In a quasi-experimental study including 230 students, four experimental groups were confronted with five learning scenarios receiving different learning analytics feedback. Findings indicate that perceived benefits from learning analytics feedback varies across different delivery sources and requires informative recommendations. Accordingly, designing and implementing feedback in learning analytics systems is more complex than just providing visualizations of behavioral data.  © 2021 IEEE.},
	author_keywords = {Dashboard; Feedback; Learning analytics; Pedagogical feature; Perceived benefit; Visualization},
	keywords = {Analytics systems; Behavioral data; Experimental groups; Feedback in learning; Learners' perceptions; Learning scenarios; Perceived benefits; Learning systems},
	editor = {Chang M. and Chen N.-S. and Sampson D.G. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166544106-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Alonso-Secades2022,
	author = {Alonso-Secades, Vidal and López-Rivero, Alfonso-José and Martín-Merino-acera, Manuel and Ruiz-García, Manuel-José and Arranz-García, Olga},
	title = {Designing an Intelligent Virtual Educational System to Improve the Efficiency of Primary Education in Developing Countries},
	year = {2022},
	journal = {Electronics (Switzerland)},
	volume = {11},
	number = {9},
	doi = {10.3390/electronics11091487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129396202&doi=10.3390%2felectronics11091487&partnerID=40&md5=444ae28392562aca068a890f0f0296f8},
	affiliations = {Computer Science Faculty, Pontifical University of Salamanca, C/Compañia, 5, Salamanca, 37002, Spain; ProFuturo Foundation, C/Gran Vía 28, Madrid, 28013, Spain; Education Faculty, Pontifical University of Salamanca, C/Compañia, 5, Salamanca, 37002, Spain},
	abstract = {Incorporating technology into virtual education encourages educational institutions to demand a migration from the current learning management system towards an intelligent virtual educational system, seeking greater benefit by exploiting the data generated by students in their day-to-day activities. Therefore, the design of these intelligent systems must be performed from a new perspective, which will take advantage of the new analytical functions provided by technologies such as artificial intelligence, big data, educational data mining techniques, and web analytics. This paper focuses on primary education in developing countries, showing the design of an intelligent virtual educational system to improve the efficiency of primary education through recommendations based on reliable data. The intelligent system is formed of four subsystems: data warehousing, analytical data processing, monitoring process and recommender system for educational agents. To illustrate this, the paper contains two dashboards that analyze, respectively, the digital resources usage time and an aggregate profile of teachers’ digital skills, in order to infer new activities that improve efficiency. These intelligent virtual educational systems focus the teaching–learning process on new forms of interaction on an educational future oriented to personalized teaching for the students, and new evaluation and teaching processes for each professor. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {dashboard; data cleaning; educational data mining; intelligent systems; learning analytics; machine learning; virtual education; web analytics},
	correspondence_address = {V. Alonso-Secades; Computer Science Faculty, Pontifical University of Salamanca, Salamanca, C/Compañia, 5, 37002, Spain; email: valonsose@upsa.es},
	publisher = {MDPI},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@CONFERENCE{Safsouf2021347,
	author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
	title = {Experimental Design of Learning Analysis Dashboards for Teachers and Learners},
	year = {2021},
	journal = {L@S 2021 - Proceedings of the 8th ACM Conference on Learning @ Scale},
	pages = {347 – 350},
	doi = {10.1145/3430895.3460990},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108115216&doi=10.1145%2f3430895.3460990&partnerID=40&md5=70819ad91094b1aaa6f43813b0e37a73},
	affiliations = {Laboratory Limie, Isga Group, Marrakesh, Morocco; Laboratory Ssdia, University Hassan Ii, Casablanca, Morocco; Lab-STICC, University Bretagne Sud, Vannes, France},
	abstract = {Since learning in higher education is increasingly taking place online, the multiplication of web-based educational content, learning management systems (LMSs) and collaborative communication platforms have generated a large volume of data on learners and their learning activities. In recent years, interest has been growing in analyzing this data to support real-time decision making and improve the learning experience. This paper presents the results of a study conducted in higher education in Morocco, which evaluates a learning analysis dashboards (LADs) for both teachers and learners. The study shows that the dashboard, called TABAT, allowed a synthetic visualization of learning progress in courses and led to improved student engagement and success rates. © 2021 Owner/Author.},
	author_keywords = {higher education; information visualization; learning analytical dashboard; learning analytics; self-regulated learning},
	keywords = {Decision making; Online systems; Collaborative communications; Educational contents; Learning Activity; Learning experiences; Learning management system; Learning progress; Real time decision-making; Student engagement; Information management},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038215-1},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{2021,
	title = {Proceedings of 2021 13th International Conference on Education Technology and Computers, ICETC 2021},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124711147&partnerID=40&md5=3d3a78ee5871b2a56372f4caee254ba7},
	abstract = {The proceedings contain 77 papers. The topics discussed include: the development of learning outcomes and prerequisite knowledge recommendation system; learning path recommendation using lesson sequence and learning object based on course graph; predictive model of student academic performance from LMS data based on learning analytics; graph learning based sentiment analysis system for Chinese course evaluation; automatic classroom question classification based on bloom’s taxonomy; from motivation components to academic achievement prediction; a method of speech separation between teachers and students in smart classrooms based on speaker diarization; design proposal of a personalized dashboard to optimize teaching-learning in virtual learning environments; and an experimental study of the efficacy of augmented reality in Chinese kindergarten-level students’ learning of English vocabulary.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038511-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2022,
	title = {International Conference on Information, Communication and Cybersecurity, ICI2C 2021},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {357 LNNS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124169983&partnerID=40&md5=5ff81f25a388014949a55f22f697876d},
	abstract = {The proceedings contain 54 papers. The special focus in this conference is on Information, Communication and Cybersecurity. The topics include: Metadata Quality in the Era of Big Data and Unstructured Content; weather Forecast Using Sliding Window Algorithm Based on Hadoop and MapReduce; semantic Web Technologies for Internet of Things Semantic Interoperability; composition of Large Modular Ontologies Based on Structure; detection and Prediction Using Similar Trajectory Measurements; Classification of Arrhythmias from ECG Using Fractal Dimensions and Wavelet Theory; benchmarking Classification Algorithms for Measuring the Performance on Maintainable Applications; application of Machine Learning Techniques for Credit Risk Management: A Survey; Applying Advanced IoT Network Topologies to Enhance Intelligent City Transportation Cost Based on a Constrained and Secured Applicative IoT CoAP Protocol; a Minimum and Maximum of Regional Information Method to Improve the Sobel Edge Detector; Applying Lightweight Elliptic Curve Cryptography ECC to Smart Energy IoT Platforms Based on the CoAP Protocol; service Selection in Cloud Computing Environment by Using Cuckoo Search; markov Decision Processes with Discounted Rewards: Improved Successive Over-Relaxation Method; speech Spectral Subtraction in Modulation Domain; COBIT 5 Concepts: Towards the Development of an Ontology Model; a Systematic Study on Tertiary Level Student Tuition Fee Waiver Management During Pandemic Using Machine Learning Approaches; towards a Model of Self-regulated e-learning and Personalization of Resources; the Preferences and Expectation of Moroccan Teachers from Learning Analytics Dashboards in a Blended Learning Environment: Empirical Study; towards a Smart City Stakeholders Classification: Case of Casablanca Smart City Project; emerging Learning Environments and Technologies Post Covid-19 Pandemic: What’s Next?.},
	editor = {Maleh Y. and Alazab M. and Gherabi N. and Tawalbeh L. and Abd El-Latif A.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303091737-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Villalobos202239,
	author = {Villalobos, Esteban and Pérez-Sanagustin, Mar and Tricot, André and Broisin, Julien},
	title = {Measuring and supporting self-regulated learning in blended learning contexts},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3292},
	pages = {39 – 45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143801951&partnerID=40&md5=1dd960dba82a5542e3d90c8863b1b633},
	affiliations = {IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; Université Paul-Valéry Montpellier 3, EPSYLON, France},
	abstract = {Despite the positive effects of Blended Learning (BL), several studies have shown that students require high levels of self-regulation to succeed in these types of practices. Still, there is little understanding of how students organize their learning in BL authentic contexts. This paper presents the objectives and current status of a project that seeks to understand how students' Self-regulated Learning (SRL) strategies manifest themselves in BL contexts holistically and how to foster it through technological solutions. The contributions of this project will be three-fold. First, we aim to develop novel analytical and technological solutions to understand better the dynamics of how self-regulated learning unveils in BL contexts. Second is the development of a dashboard-based support tool for students and teachers. And third, we will provide evaluations of the analytical framework and support tool in authentic BL contexts. We expect that these contributions will provide the community with a better understanding of the dynamics of SRL in BL. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Blended Learning; Learning Analytics; Self-regulated Learning},
	keywords = {E-learning; Authentic contexts; Blended learning; Current status; Learning analytic; Learning context; Self regulation; Self-regulated learning; Self-regulated learning strategies; Support tool; Technological solution; Students},
	correspondence_address = {E. Villalobos; IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; email: esteban.villalobos@irit.fr},
	editor = {Jivet I. and Jivet I. and Di Mitri D. and Schneider J. and Papamitsiou Z. and Fominykh M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kannan2022,
	author = {Kannan, Priya and Zapata-Rivera, Diego},
	title = {Facilitating the Use of Data From Multiple Sources for Formative Learning in the Context of Digital Assessments: Informing the Design and Development of Learning Analytic Dashboards},
	year = {2022},
	journal = {Frontiers in Education},
	volume = {7},
	doi = {10.3389/feduc.2022.913594},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133555873&doi=10.3389%2ffeduc.2022.913594&partnerID=40&md5=056f3eebaa807f883f44ce45d7fc889a},
	affiliations = {Educational Testing Service, Learning and Assessment Foundations and Innovations Research Center, Princeton, NJ, United States},
	abstract = {Learning analytic dashboards (LADs) are data visualization systems that use dynamic data in digital learning environments to provide students, teachers, and administrators with a wealth of information about student’s engagement, experiences, and performance on tasks. LADs have become increasingly popular, particularly in formative learning contexts, and help teachers make data-informed decisions about a student’s developing skills on a topic. LADs afford the possibility for teachers to obtain real-time data on student performance, response processes, and progress on academic learning tasks. However, data presented on LADs are often not based on an evaluation of stakeholder needs, and have been found to not be clearly interpretable and actionable for teachers to readily adapt their pedagogical actions based on these insights. We elaborate on how insights from research focused on interpretation and use of Score Reporting systems and research on open learner models (OLMs) can be used to inform a research agenda aimed at exploring the design and evaluation of LADs. Copyright © 2022 Kannan and Zapata-Rivera.},
	author_keywords = {dashboards; data visualization; learning analytics; open learner models; Score Reporting; user-oriented research},
	correspondence_address = {D. Zapata-Rivera; Educational Testing Service, Learning and Assessment Foundations and Innovations Research Center, Princeton, United States; email: DZapata@ets.org},
	publisher = {Frontiers Media S.A.},
	issn = {2504284X},
	language = {English},
	abbrev_source_title = {Front. Educ.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Battaglin2022,
	author = {Battaglin, Ricardo and Munoz, Roberto and Ramos, Vinicius Culmant and Cechinel, Cristian},
	title = {Predicting at-risk students with LMS data: a comparison between Adaboost and LSTM algorithms},
	year = {2022},
	journal = {2022 17th Latin American Conference on Learning Technologies, LACLO 2022},
	doi = {10.1109/LACLO56648.2022.10013469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147730518&doi=10.1109%2fLACLO56648.2022.10013469&partnerID=40&md5=e501df2e6e546b9074f390305773f05a},
	affiliations = {Universidade Federal de Santa Catarina, SC, Araranguá, Brazil; Universidad de Valparaıso, Valparaíso, Chile; Universidade Federal de Santa Catarina, SC, Florianópolis, Brazil},
	abstract = {The prediction of students at-risk (dropout and failure) is a largely explored problem on Learning Analytics and Educational Data Mining. The present work compares the results of two different algorithms used to generate predictive models to early detect students at-risk, LSTM and Adaboost. This comparison aims to improve the performances of the models already implemented and integrated on a Moodle dashboard. For the comparison, data from a total of 122 students was collected from Moodle over four semester of an Introductory Programming course offered at Federal University of Santa Catarina (UFSC). Models were generated for each one of the 17 weeks of the semester, and their AUROC measures were then calculated and compared to evaluate the differences between LSTM and Adaboost. The results have shown that even though LSTM models presented a better performance than Adaboost, these differences were not statistically significant.  © 2022 IEEE.},
	author_keywords = {at-risk students<sup>1</sup>; Educational Data Mining; Learning Analytics; LSTM},
	keywords = {Data mining; Education computing; Long short-term memory; Predictive analytics; Students; At-risk student1; Educational data mining; Introductory programming course; Learning analytic; LSTM; Performance; Predictive models; Adaptive boosting},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166546521-2},
	language = {Portuguese},
	abbrev_source_title = {Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Eickholt2022,
	author = {Eickholt, Jesse and Weible, Jennifer L. and Teasley, Stephanie D.},
	title = {Student-facing Learning Analytics Dashboard: Profiles of Student Use},
	year = {2022},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	volume = {2022-October},
	doi = {10.1109/FIE56618.2022.9962531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143838916&doi=10.1109%2fFIE56618.2022.9962531&partnerID=40&md5=a51f3286191b6b589cc8ab0a5fc49e20},
	affiliations = {Central Michigan University, Department of Computer Science, Mount Pleasant, MI, United States; Central Michigan University, Department of Teacher Education and Professional Development, Mount Pleasant, MI, United States; University of Michigan, School of Information, Ann Arbor, MI, United States},
	abstract = {Student-facing learning analytics dashboards (LADs) provide visualizations of course-related information to help students understand and personalize their educational practices. As such, they can be viewed as a meta-cognitive tool that enables awareness, self-reflection and sensemaking of academic performance. While student-facing LADs are becoming a standard feature in educational software, questions have been raised about students' willingness to adopt LADs and their ability to interpret feedback provided by student-facing LADs. The extent to which student-facing LADs can broadly improve educational outcomes depends, in part, on students' ability to readily incorporate LAD usage in their educational workflows.This study investigates the use of a student-facing LAD, My Learning Analytics (MyLA), over the span of one semester in a university introductory science course. MyLA draws data from the campus learning management system (Canvas) and displays three visualizations designed to provide students with actionable information. Adoption and use of MyLA was voluntary. As an exploratory study of MyLA's use in an introductory science course, this work addresses three research questions: i) What are the characteristics of students that use MyLA?, ii) How do students make use of MyLA in their coursework?, and iii) What patterns of use are exhibited by more frequent MyLA users? The results indicate that given the opportunity to use a student-facing LAD, 33% of students made repeated use of the tool. Demographic data (e.g., gender, domestic/international student) did not predict MyLA usage but significant differences in mean cumulative GPA were found between non-MyLA users and MyLA users. Broad patterns of MyLA use were aligned with major assessments in the course (e.g., MyLA was used more often around exam dates) and the grade distribution view was the most commonly accessed. Among the most highly active MyLA users, two distinct profiles were identified: aware and sensemakers. Aware users made use of the dashboard on more than 12 distinct days across the course, primarily around exam dates, and stated that they accessed the dashboard to compare their performance with others. Sensemakers made frequent use of all three MyLA views multiple times over the semester to monitor their own progress, compare their grades to others, and check what materials other students had viewed.LADs such as MyLA allow students to leverage what they already know about course assessment in their interpretation of the data presented, easing adoption and deployment of a student-facing LAD in higher education. As MyLA does not require that students have any additional training to interpret the visualizations they provide, LADs can readily be employed by students in introductory computing and engineering courses to provide them with feedback to help them plan for, monitor, and evaluate their academic progress. © 2022 IEEE.},
	author_keywords = {course level micro-learning analytics; learning analytics dashboard; self-regulated learning; student-facing learning analytics dashboard},
	keywords = {Facings; Information management; Visualization; Course level micro-learning analytic; Course related; Introductory science course; Learning analytic dashboard; Meta-cognitive tools; Micro-learning; Self reflection; Self-regulated learning; Sense making; Student-facing learning analytic dashboard; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {978-166546244-0},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Fernandez-Nieto2021695,
	author = {Fernandez-Nieto, Gloria Milena and Echeverria, Vanessa and Shum, Simon Buckingham and Mangaroska, Katerina and Kitto, Kirsty and Palominos, Evelyn and Axisa, Carmen and Martinez-Maldonado, Roberto},
	title = {Storytelling with Learner Data: Guiding Student Reflection on Multimodal Team Data},
	year = {2021},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {14},
	number = {5},
	pages = {695 – 708},
	doi = {10.1109/TLT.2021.3131842},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120550862&doi=10.1109%2fTLT.2021.3131842&partnerID=40&md5=b2fd06d9b8d56cefa4b6061b9ce4089a},
	affiliations = {Connected Intelligence Centre, University of Technology Sydney, Ultimo, 2007, NSW, Australia; Escuela Superior Politécnica Del Litoral, ESPOL, Guayaquil, Ecuador; Department of Computer Science, Norwegian University of Science and Technology, Trondheim, NO-7491, Norway; Faculty of Information Technology, Monash University, Clayton, 3800, VIC, Australia},
	abstract = {There is growing interest in creating learning analytics feedback interfaces that support students directly. While dashboards and other visualizations are proliferating, the evidence is that many fail to provide meaningful insights that help students reflect productively. The contribution of this article is qualitative and quantitative evidence from two studies evaluating a multimodal teamwork analytics tool in authentic clinical teamwork simulations. Collocated activity data are rendered to help nursing students reflect on errors and stress-related incidents during simulations. The user interface explicitly guides student reflection using data storytelling principles, tuned to the intended learning outcomes. The results demonstrate the potential of interfaces that 'tell one data story at a time,' by helping students to identify misconceptions and errors; think about strategies they might use to address errors, and reflect on their arousal levels. The results also illuminate broader issues around automated formative assessment, and the intelligibility and accountability of learning analytics.  © 2008-2011 IEEE.},
	author_keywords = {Collocated spaces; Feedback; Guidance; Multimodal learning analytics (MMLA); Reflection; Visualization},
	keywords = {Data visualization; Errors; Students; User interfaces; Analytic tools; Collocated space; Feedback interfaces; Guidance; Medical services; Multi-modal; Multi-modal learning; Multimodal learning analytic; Prototype; Teamwork; Visualization},
	correspondence_address = {G.M. Fernandez-Nieto; Connected Intelligence Centre, University of Technology Sydney, Ultimo, 2007, Australia; email: gloria.m.fernandeznieto@student.uts.edu.au},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@ARTICLE{Wang2022,
	author = {Wang, Jann-Yuan and Yang, Chia-Hsien and Liao, Wei-Chih and Yang, Kai-Chien and Chang, I-Wen and Sheu, Bor-Ching and Ni, Yen-Hsuan},
	title = {Highly Engaged Video-Watching Pattern in Asynchronous Online Pharmacology Course in Pre-clinical 4th-Year Medical Students Was Associated With a Good Self-Expectation, Understanding, and Performance},
	year = {2022},
	journal = {Frontiers in Medicine},
	volume = {8},
	doi = {10.3389/fmed.2021.799412},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124090615&doi=10.3389%2ffmed.2021.799412&partnerID=40&md5=13fe793a38e6b1bb003604902fae91e5},
	affiliations = {Division of Curriculum Integration, Center of Faculty Development, National Taiwan University College of Medicine, Taipei, Taiwan; Department of Internal Medicine, National Taiwan University College of Medicine, Taipei, Taiwan; Office of International Affairs and Global Master of Business Administration Program, National Taiwan University College of Management, Taipei, Taiwan; Department and Graduate Institute of Pharmacology, National Taiwan University College of Medicine, Taipei, Taiwan; School of Medicine, National Taiwan University College of Medicine, Taipei, Taiwan; Department of Obstetrics and Gynecology, National Taiwan University College of Medicine, Taipei, Taiwan; Department of Pediatrics, National Taiwan University College of Medicine, Taipei, Taiwan},
	abstract = {Background: Online video-based learning is more common in higher education. Investigating students' viewing behaviors while watching online video lectures is essential for instructors to understand their learning status so that the course content, structure, and media selection can be improved continuously. The current study identified the engagement level of the learners based on their online video-watching behaviors, and tested the correlation between the engagement level and learning outcome. Methods: The action logs of watching online video lectures in 2020 Spring Pharmacology of the 4th-year medical students of the 6-year course and their feedbacks by questionnaires after each exam during the semester were provided anonymously. The data were analyzed and visualized for an efficient way to comprehend and interpret. To define the student's engagement level in his or her video-based learning journey, three viewing criteria, “Completion,” “Pausing,” and “Repeated watching” were identified. We evaluated the association between the engagement level and the students' learning outcomes, including their learning satisfaction, knowledge acquisition progresses based on assessment results, and the grades measured by the instructors. Results: The graphs and the charts demonstrate whether the students allocated enough time to finish the video lectures (completion), paused for a while, then resumed the video (pausing), or replayed the specific sections of video content (repeated watching). The engagement level with video lectures, evaluated by pre-defined thresholds for “Completion,” “Pausing,” and “Repeated watching” had a positive correlation with the learning outcomes. Conclusions: We suggested that an engagement dashboard containing real-time visualized information on students' online video-watching behaviors can be developed to help instructors to monitor students' learning progress and improve teaching in a timely fashion. It can also help each student to re-feel the stimulation of peers, prompt self-monitoring, improve their learning attitudes and disciplines for better learning outcomes. This innovative way of assessing student's engagement during online video-based learning can also be used for quality assurance purposes. Copyright © 2022 Wang, Yang, Liao, Yang, Chang, Sheu and Ni.},
	author_keywords = {engagement; learning analytics; learning outcome; medical education; online video-based learning; video-watching pattern},
	keywords = {article; controlled study; educational status; expectation; female; human; human experiment; learning; male; medical education; medical student; outcome assessment; preclinical study; quality control; questionnaire; satisfaction; self monitoring; spring; videorecording},
	correspondence_address = {B.-C. Sheu; Division of Curriculum Integration, Center of Faculty Development, National Taiwan University College of Medicine, Taipei, Taiwan; email: bcsheu@ntu.edu.tw},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rets2021,
	author = {Rets, Irina and Herodotou, Christothea and Bayer, Vaclav and Hlosta, Martin and Rienties, Bart},
	title = {Exploring critical factors of the perceived usefulness of a learning analytics dashboard for distance university students},
	year = {2021},
	journal = {International Journal of Educational Technology in Higher Education},
	volume = {18},
	number = {1},
	doi = {10.1186/s41239-021-00284-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114165623&doi=10.1186%2fs41239-021-00284-9&partnerID=40&md5=f5d63b450be8af7cf310a110eea2eae3},
	affiliations = {Management School, Lancaster University, Lancaster, LA14YX, United Kingdom; Institute of Educational Technology, Open University UK, Milton Keynes, MK76AA, United Kingdom; Knowledge Media Institute, Open University UK, Milton Keynes, MK76AA, United Kingdom},
	abstract = {Learning analytics dashboards (LADs) can provide learners with insights about their study progress through visualisations of the learner and learning data. Despite their potential usefulness to support learning, very few studies on LADs have considered learners’ needs and have engaged learners in the process of design and evaluation. Aligning with that, there is a limited understanding of what specific student cohorts, in particular distance and online learners, may seek from LADs to effectively support their studies. In this study, we present findings from 21 interviews with undergraduate distance learners, mainly high performers, that aimed to capture student perceptions about the usefulness of specific LAD features and the factors that explain these perceptions. Our findings revealed that amongst the LAD features favoured by students was the potential to receive study recommendations, whereas comparison with peers was amongst the least favoured elements, unless informed by qualitative information. Factors including information trust, attitudes, age, performance and academic self-confidence were found to explain these perceptions. © 2021, The Author(s).},
	author_keywords = {Distance learning; Learning analytics dashboard; Perceived usefulness; Technology acceptance},
	correspondence_address = {I. Rets; Management School, Lancaster University, Lancaster, LA14YX, United Kingdom; email: i.rets@lancaster.ac.uk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23659440},
	language = {English},
	abbrev_source_title = {Int. j. educ. technol. high. educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hou2022542,
	author = {Hou, Xinying and Nagashima, Tomohiro and Aleven, Vincent},
	title = {Design a Dashboard for Secondary School Learners to Support Mastery Learning in a Gamified Learning Environment},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {542 – 549},
	doi = {10.1007/978-3-031-16290-9_48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138005552&doi=10.1007%2f978-3-031-16290-9_48&partnerID=40&md5=b664073f7fb8efad98200a43d1a476ce},
	affiliations = {University of Michigan, Ann Arbor, 48109, MI, United States; Carnegie Mellon University, Forbes Avenue, Pittsburgh, 5000, United States},
	abstract = {Although prior studies have shown the benefits of using learning analytics dashboards (LADs) in non-gamified contexts in higher education, few have focused on pre-college users and gamified learning environments. In this paper, we present the design of Gwynnette Dashboard, an interactive student-facing LAD for secondary school learners that aims at promoting mastery learning in a gamified intelligent tutoring system. It contains three main components: a planet chart with two control buttons, a connected skill progress bar with a skill mastery growth line, and an overall mastery progress bar. We also report two user-centered design changes after validating our design with 18 students iteratively. Our preliminary evaluation of a fully-developed version with 2 students revealed that this dashboard with linked representations of skill mastery status and skill growth was easy for learners to understand and motivated learners to use it to regulate learning. Our future work will focus on broader classroom studies to experimentally investigate the effectiveness of this dashboard to foster mastery learning and growth mindset. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Gamification; Learning analytics dashboards; Visualization},
	keywords = {Computer aided instruction; Education computing; Learning systems; User centered design; Control buttons; Gamification; High educations; Intelligent tutoring; Learning analytic dashboard; Learning environments; Mastery learning; Pre-college; Secondary schools; Tutoring system; Students},
	correspondence_address = {X. Hou; University of Michigan, Ann Arbor, 48109, United States; email: xyhou@umich.edu},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Amarasinghe2021307,
	author = {Amarasinghe, Ishari and Hernández-Leo, Davinia and Ulrich Hoppe, H.},
	title = {Deconstructing orchestration load: comparing teacher support through mirroring and guiding},
	year = {2021},
	journal = {International Journal of Computer-Supported Collaborative Learning},
	volume = {16},
	number = {3},
	pages = {307 – 338},
	doi = {10.1007/s11412-021-09351-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113189459&doi=10.1007%2fs11412-021-09351-9&partnerID=40&md5=57a7f0ddfb306b8116a867d3609160bc},
	affiliations = {Universitat Pompeu Fabra, Barcelona, Spain; University of Duisburg-Essen, Duisburg, Germany; RIAS Institute, Duisburg, Germany},
	abstract = {Under the notion of “CSCL scripts”, different pedagogical models for structuring and supporting collaboration in the classroom have been proposed. We report on a practical experience with scripts based on the Pyramid collaborative learning flow pattern supported by a specific classroom tool and a teacher-facing dashboard that implements mirroring and guiding support. The input data of our analysis stems from recordings of classroom interactions guided by several teachers using the PyramidApp with different levels of teaching support. For the analysis, we introduce a specific coding scheme enabling a quantitative comparison and deeper analysis using epistemic network analysis. The results show that the guiding support enabled teachers to perform more orchestration actions, more targeted interactions and to make more announcements to the class (regarding time, phase transitions, and students’ activity participation) when compared to the mirroring support. Teachers’ actionable differences observed under the mirroring and guiding support directed us to deconstruct the notion of orchestration load into different facets and to discuss how different support provisions correspond to the different facets of orchestration load. © 2021, The Author(s).},
	author_keywords = {Collaboration; CSCL scripts; Dashboards; Epistemic network analysis; Learning analytics; Orchestration},
	correspondence_address = {I. Amarasinghe; Universitat Pompeu Fabra, Barcelona, Spain; email: ishari.amarasinghe@upf.edu},
	publisher = {Springer},
	issn = {15561607},
	language = {English},
	abbrev_source_title = {Int. J. Comput.-Supported Collab. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kommers2022205,
	author = {Kommers, Piet},
	title = {Machine Learning for Learning Analytics for Meta-cognitive Support},
	year = {2022},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {261},
	pages = {205 – 217},
	doi = {10.1007/978-3-030-86316-6_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120898598&doi=10.1007%2f978-3-030-86316-6_10&partnerID=40&md5=460c5c78e9af5eb4942704f3f5b4b9ce},
	affiliations = {UNESCO Learning Technologies, University of Twente, Mooienhof 179, Enschede, 7512EE, Netherlands},
	abstract = {The motivation for this chapter is to show the evolutionary nature from earlier student tracking and 'intelligent tutoring systems' until the current stages of advanced learning analytics. This chapter's added value is its illustration of how learning analytics contributes to learners’ meta-cognitive awareness and how indirectly a teachers’ 'dashboard' allows teachers, parents, and remedial teachers to trace the more subtle cognitive entailments in the student’s mind. The sources for the chosen direction rest upon earlier research into media-support for conceptual learning. This chapter may elicit the discussion on how far technology-driven innovations can bypass the existing repertoire of earlier didactic solutions. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Big data; Conceptual representations; Deep learning and data mining; Didactic paradigms; Learning analytics; Machine learning; Meta-cognition},
	keywords = {Big data; Data mining; Deep learning; Cognitive support; Conceptual representation; Deep learning and data mining; Didactic paradigm; Learning analytic; Machine-learning; Meta cognitions; Metacognitives; Student tracking; Teachers'; Computer aided instruction},
	correspondence_address = {P. Kommers; UNESCO Learning Technologies, University of Twente, Enschede, Mooienhof 179, 7512EE, Netherlands; email: pkommers@gmail.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21903018},
	language = {English},
	abbrev_source_title = {Smart Innov. Syst. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Karademir202295,
	author = {Karademir, Onur and Ahmad, Atezaz and Schneider, Jan and Di Mitri, Daniele and Jivet, Ioana and Drachsler, Hendrik},
	title = {Designing the Learning Analytics Cockpit - A Dashboard that Enables Interventions},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {326},
	pages = {95 – 104},
	doi = {10.1007/978-3-030-86618-1_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115604866&doi=10.1007%2f978-3-030-86618-1_10&partnerID=40&md5=d5d8ce4d906180f26d4cec518f8c7ac0},
	affiliations = {DIPF | Leibniz Institute for Research and Information in Education, Rostocker Straße 6, Frankfurt am Main, 60323, Germany; TU Delft, Mekelweg 4, Delft, 2628 CD, Netherlands},
	abstract = {This paper presents results from our design and evaluation studies of the Learning Analytics Cockpit (LA Cockpit) for a quiz app, which aims to provide lecturers with important information about students’ knowledge levels. We define a LA Cockpit as a tool for instructors that enables them to steer students’ learning process by providing a LA Dashboard which visualizes students’ learning indicators and an intervention feature enabling instructors to give feedback based on students’ knowledge levels. To address the needs of lecturers we applied the Double Diamond (DD) design process model which consists of four stages: discover, define, develop & refine. Following the DD process, we first conducted a qualitative study by interviewing four lecturers and student teachers to discover their needs. Results from the interviews allowed us to define requirements of the lecturers. We used these results to develop the first version of the tool where we refined it through informal feedback by the interviewed teachers. In preparation for a larger effectiveness-study, we evaluated the LA Cockpit in terms of usefulness and usability in a preliminary study with 16 university lecturers. Results from this qualitative study indicate that the LA Cockpit can measure the students’ knowledge level and supports self-reflection for lecturers. Moreover, results show that the LA Cockpit enables lecturers to address knowledge gaps and provide interventions to students before the exams. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	correspondence_address = {O. Karademir; DIPF | Leibniz Institute for Research and Information in Education, Frankfurt am Main, Rostocker Straße 6, 60323, Germany; email: karademir@dipf.de},
	editor = {De la Prieta F. and Gennari R. and Temperini M. and Di Mascio T. and Vittorini P. and Kubincova Z. and Popescu E. and Rua Carneiro D. and Lancia L. and Addone A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303086617-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Gallagher202211,
	author = {Gallagher, Timothy and Slof, Bert and van der Schaaf, Marieke and Toyoda, Ryo and Tehreem, Yusra and Fracaro, Sofia Garcia and Kester, Liesbeth},
	title = {Comparison with Self vs Comparison with Others: The Influence of Learning Analytics Dashboard Design on Learner Dashboard Use},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13647 LNCS},
	pages = {11 – 21},
	doi = {10.1007/978-3-031-22124-8_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144390157&doi=10.1007%2f978-3-031-22124-8_2&partnerID=40&md5=f3b4062599c7e152edaf016219899bc6},
	affiliations = {Utrecht University, Utrecht, Netherlands; Netherlands Institute for Curriculum Development, Enschede, Netherlands; University Medical Centre Utrecht, Utrecht, Netherlands; Newcastle University, Newcastle Upon Tyne, United Kingdom; University of Applied Sciences Emden/Leer, Emden, Germany; Bielefeld University, Bielefeld, Germany; Merck KGaA & KU Leuven, Darmstadt, Germany; KU Leuven, Leuven, Belgium},
	abstract = {This study uses log-file data to investigates how chemical process plant employees interact and engage with two distinct learning analytics dashboard designs, which are implemented in a virtual reality simulation-based training environment. The learning analytics dashboard designs differ by reference frame: the progress reference frame, offers historical performance data as a point of comparison and the social reference frame offers aggregated average peer group performance data as a point of comparison. Results show that participants who receive a progress reference frame are likely to spend less time reviewing their dashboard than those who receive a social reference. However, those who receive a progress reference frame are more likely to spend more time reviewing detailed task feedback and engaging with the learning analytics dashboard. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Learning analytics dashboard; Social comparison; Virtual reality simulation-based training},
	keywords = {Personnel training; Virtual reality; Chemical process plants; Historical performance data; Learning analytic dashboard; Logfile; Peer groups; Reference frame; Simulation-based training; Social comparison; Virtual reality simulation-based training; Virtual reality simulations; E-learning},
	correspondence_address = {T. Gallagher; Utrecht University, Utrecht, Netherlands; email: t.r.gallagher@uu.nl},
	editor = {Kiili K. and Antti K. and de Rosa F. and Dindar M. and Kickmeier-Rust M. and Bellotti F.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303122123-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Conde2022251,
	author = {Conde, Miguel Á. and Andrés-Gómez, Adrián and Rodríguez-Sedano, Francisco J. and Fernández-Llamas, Camino},
	title = {Applying Natural Language Processing to Teamwork – A New Dashboard for CTMTC Methodology},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13329 LNCS},
	pages = {251 – 261},
	doi = {10.1007/978-3-031-05675-8_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133209008&doi=10.1007%2f978-3-031-05675-8_19&partnerID=40&md5=110a3c35944dc323e204f7b780ce1a88},
	affiliations = {Department of Mechanics, Computer Science and Aerospace Engineering, Robotics Group, Universidad de León, Campus de Vegazana S/N, León, 24071, Spain; School of Mechanical, Computer Science and Aerospace Engineering, Universidad de León, Campus de Vegazana SN, León, 24071, Spain; Department of Electric, Systems and Automatics Engineering, Robotics Group, Universidad de León, Campus de Vegazana S/N, León, 24071, Spain},
	abstract = {In our current society the acquisition of competences such as teamwork is essential. However, the evaluation of how this competence is developed is not easy and requires methodologies and tools to support the assessment process. In this sense several Learning Analytics tools have been developed. They explore students’ interactions in different types of tools such as forums or instant messaging apps. However those tools are especially focused on the quantitative evaluation of the interaction and are not very usable. This work presents a new dashboard that analyzes students’ Telegram interactions while they work as a team to address a project. The innovation of this tool lies in the functionalities included to explore not only numbers about messages, replies, type of messages, characters, etc., but the content of the texts. To do so natural language processing and sentiment analysis libraries were used. The tool has been tested successfully with 4 subject editions in which it is possible to appreciate an evolution in students’ interactions. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Learning analytics; Natural language processing; Teamwork; Telegram},
	keywords = {Students; 'current; Assessment process; Dashboard; Language processing; Learning analytic; Natural language processing; Natural languages; Student interactions; Teamwork; Telegram; Sentiment analysis},
	correspondence_address = {M.Á. Conde; Department of Mechanics, Computer Science and Aerospace Engineering, Robotics Group, Universidad de León, León, Campus de Vegazana S/N, 24071, Spain; email: mcong@unileon.es},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303105674-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Williamson2021287,
	author = {Williamson, Kimberly and Kizilcec, René F.},
	title = {Learning Analytics Dashboard Research Has Neglected Diversity, Equity and Inclusion},
	year = {2021},
	journal = {L@S 2021 - Proceedings of the 8th ACM Conference on Learning @ Scale},
	pages = {287 – 290},
	doi = {10.1145/3430895.3460160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106980048&doi=10.1145%2f3430895.3460160&partnerID=40&md5=a90e9c742240ed79d440ab5bccdd8d6a},
	affiliations = {Cornell University, Ithaca, NY, United States},
	abstract = {Learning analytic dashboards (LADs) have become more prevalent in higher education to help students, faculty, and staff make data-informed decisions. Despite extensive research on the design and usability of LADs, few studies have examined them in relation to issues of diversity, equity, and inclusion. We conducted a critical literature review to address three research questions: How does LAD research contribute to improving diversity, equity, and inclusion? How might LADs contribute to maintaining or exacerbating inequitable outcomes? And what future opportunities exist in this research space? Our review showed little use of LADs to address or improve issues of diversity, equity, and inclusion in the literature thus far. We argue that excluding these issues from LAD research is not an isolated oversight and it risks reinforcing existing inequities within the higher education system. We argue that LADs can be designed, researched, and deployed intentionally to advance equitable outcomes and help dismantle inequities in education. We highlight opportunities for future LAD research to address issues of diversity, equity, and inclusion. © 2021 Owner/Author.},
	author_keywords = {diversity; equity; inclusion; learning analytic dashboards; literature review},
	keywords = {Higher education; Higher education system; Informed decision; Literature reviews; Research questions},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038215-1},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Ouatiq2022,
	author = {Ouatiq, Amina and Riyami, Bouchaib and Mansouri, Khalifa and Qbadou, Mohammed and Aoula, Es-Saadia},
	title = {Towards the Co-Design of a Teachers' Dashboards in a Hybrid Learning Environment},
	year = {2022},
	journal = {2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology, IRASET 2022},
	doi = {10.1109/IRASET52964.2022.9738149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127973702&doi=10.1109%2fIRASET52964.2022.9738149&partnerID=40&md5=26c375b0fc5513ae760d2e10bb8cc8c7},
	affiliations = {M2S2I Laboratory Enset Mohammedia, Hassan Ii University of Casablanca, Mohammedia, Morocco; Institut Supérieur du Génie Appliqué, Iga, Casablanca, Morocco},
	abstract = {Learning Analytic Dashboards support learning, and try to empower stakeholders to make better-informed decisions. While creating dashboards for teachers is common in Learning analytics, designing it with them is not that common, especially in hybrid systems and using data from both the online and face-to-face sessions. This paper will be discussing co-designing a teacher dashboard with teachers through participatory workshop and interview, after getting their goals and expectation for dashboard in hybrid system. To arrive to a dashboard prototype, conform with teachers' needs and expectations.  © 2022 IEEE.},
	author_keywords = {co-design; Human-centered design; Learning analytics; Teacher's dashboard; visualization},
	keywords = {Computer aided instruction; Online systems; Co-designs; Face to face; Human-centred designs; Hybrid learning; Informed decision; Learning analytic; Learning environments; Support learning; Teacher dashboard; Teachers'; Hybrid systems},
	editor = {Benhala B. and Mansouri K. and Raihani A. and Qbadou M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542209-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Innov. Res. Appl. Sci., Eng. Technol., IRASET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Hellings2022,
	author = {Hellings, Jan and Haelermans, Carla},
	title = {The effect of providing learning analytics on student behaviour and performance in programming: a randomised controlled experiment},
	year = {2022},
	journal = {Higher Education},
	volume = {83},
	number = {1},
	doi = {10.1007/s10734-020-00560-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086320764&doi=10.1007%2fs10734-020-00560-z&partnerID=40&md5=30a297e7a8d2eaae312b58c3f31fd24d},
	affiliations = {Department of Computer Science, Amsterdam University of Applied Sciences, Wibautstraat 2-4, GM, Amsterdam, 1091, Netherlands; Research Centre for Education and the Labour Market (ROA), School of Business and Economics, Maastricht University, PO Box 616, Maastricht, 6200 MD, Netherlands},
	abstract = {We use a randomised experiment to study the effect of offering half of 556 freshman students a learning analytics dashboard and a weekly email with a link to their dashboard, on student behaviour in the online environment and final exam performance. The dashboard shows their online progress in the learning management systems, their predicted chance of passing, their predicted grade and their online intermediate performance compared with the total cohort. The email with dashboard access, as well as dashboard use, has positive effects on student behaviour in the online environment, but no effects are found on student performance in the final exam of the programming course. However, we do find differential effects by specialisation and student characteristics. © 2020, The Author(s).},
	author_keywords = {Higher education; Learning analytics dashboard; Randomised controlled experiment; Student behaviour; Student performance},
	correspondence_address = {C. Haelermans; Research Centre for Education and the Labour Market (ROA), School of Business and Economics, Maastricht University, Maastricht, PO Box 616, 6200 MD, Netherlands; email: Carla.haelermans@maastrichtuniversity.nl},
	publisher = {Springer Science and Business Media B.V.},
	issn = {00181560},
	language = {English},
	abbrev_source_title = {High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Nakanishi2021675,
	author = {Nakanishi, Taro and Kuromiya, Hiroyuki and Majumdar, Rwitajit and Ogata, Hiroaki},
	title = {Data-informed Teaching Reflection: A Pilot of a Learning Analytics Workflow in Japanese High School},
	year = {2021},
	journal = {29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings},
	volume = {1},
	pages = {675 – 677},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126632366&partnerID=40&md5=0bb2a75c6649c2bd932c37cb6ec49cfe},
	affiliations = {Graduate School of informatics, Kyoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan},
	abstract = {The use of ICT devices in the classroom for teaching has become more relevant in secondary education. However, the use of data driven technologies for supporting pedagogical practices are still limited in the Japanese school context. Promoting the use of ICT in the classroom is an important part of improving the quality of education. In this paper, we introduce the workflow of using e-book reader and learning analytics dashboard to improve teaching of a junior-high school Mathematics class in Japan. We recruited a teacher and forty students for the research and introduced the simple dashboard for daily teaching and learning in their class. An end of the study period survey results showed that the dashboard prompted a change in the way of teaching in the class and also the teacher became more positive towards using data-driven technologies for reflecting on teaching practices. © 2021 29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings. All rights reserved},
	author_keywords = {ebook reader; evidence-based education; LEAF; Learning analytics; secondary education},
	keywords = {Surveys; Teaching; Data driven; Ebook reader; Evidence-based; Evidence-based education; Higher School; LEAF; Learning analytic; Secondary education; Teachers'; Work-flows; Electronic publishing},
	correspondence_address = {T. Nakanishi; Graduate School of informatics, Kyoto University, Japan; email: nakanishi.taro.26r@st.kyoto-u.ac.jp},
	editor = {Rodrigo M.M.T. and Iyer S. and Mitrovic A. and Cheng H.N.H. and Kohen-Vacs D. and Matuk C. and Palalas A. and Rajenran R. and Seta K. and Wang J.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972147-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Maldonado-Mahauad2022455,
	author = {Maldonado-Mahauad, Jorge and Pérez-Sanagustín, Mar and Carvallo-Vega, Juan and Narvaez, Edwin and Calle, Mauricio},
	title = {Miranda: A Chatbot for Supporting Self-regulated Learning},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13450 LNCS},
	pages = {455 – 462},
	doi = {10.1007/978-3-031-16290-9_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137999377&doi=10.1007%2f978-3-031-16290-9_36&partnerID=40&md5=3fe8718ce690dc5eef863a881c655315},
	affiliations = {Department of Computer Science, University of Cuenca, Cuenca, Ecuador; IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; Corporación Ecuatoriana para el Desarrollo de la Investigación y la Academia, Cuenca, Ecuador},
	abstract = {Learning Analytics (LA) aims to understand and optimize the learning process in the environments in which they occur. It also offers opportunities for teachers to understand students’ behavior and promote the use of effective strategies that allow them to achieve their goals. Most of current solutions proposed in the literature for supporting students’ SRL are based on dashboards. However, if students do not interact with them, it becomes difficult to understand whether they have an impact in their self-regulated behavior. This demonstration, presents Miranda: A Chatbot that acts as a conversational agent to recommend and make suggestions on SRL strategies based on students’ the behavior. The first version of Miranda has been developed for Moodle, but it could be adapted to any other Learning Management System. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Chatbot; Conversational agent; Learning Analytics; Recommender system; Self-regulated learning},
	keywords = {Learning systems; Recommender systems; 'current; Chatbots; Conversational agents; Learning analytic; Learning management system; Learning process; Self-regulated learning; Students' behaviors; Teachers'; Students},
	correspondence_address = {J. Maldonado-Mahauad; Department of Computer Science, University of Cuenca, Cuenca, Ecuador; email: jorge.maldonado@ucuenca.edu.ec},
	editor = {Hilliger I. and Muñoz-Merino P.J. and De Laet T. and Ortega-Arranz A. and Farrell T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303116289-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Li2022528,
	author = {Li, Qiujie and Jung, Yeonji and D'Anjou, Bernice and Wise, Alyssa Friend},
	title = {Unpacking Instructors' Analytics Use: Two Distinct Profiles for Informing Teaching},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {528 – 534},
	doi = {10.1145/3506860.3506905},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126208474&doi=10.1145%2f3506860.3506905&partnerID=40&md5=6938a44b4914e1e579d19de4abd9b2cf},
	affiliations = {NYU Learn, New York University, New York City, NY, United States},
	abstract = {This study addresses the gap in knowledge about differences in how instructors use analytics to inform teaching by examining the ways that thirteen college instructors engaged with a set of university-provided analytics. Using multiple walk-through interviews with the instructors and qualitative inductive coding, two profiles of instructor analytics use were identified that were distinct from each other in terms of the goals of analytics use, how instructors made sense of and took actions upon the analytics, and the ways that ethical concerns were conceived. Specifically, one group of instructors used analytics to help students get aligned to and engaged in the course, whereas the other group used analytics to align the course to meet students' needs. Instructors in both profiles saw ethical questions as central to their learning analytics use, with instructors in one profile focusing on transparency and the other on student privacy and agency. These findings suggest the need to view analytics use as an integrated component of instructor teaching practices and envision complementary sets of technical and pedagogical support that can best facilitate the distinct activities aligned with each profile.  © 2022 ACM.},
	author_keywords = {Data-informed teaching; Instructional dashboards; Teacher inquiry},
	keywords = {Ethical technology; Teaching; Complementary sets; Data-informed teaching; Ethical concerns; Ethical question; Instructional dashboard; Pedagogical supports; Teacher inquiry; Teachers'; Teaching practices; Technical support; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Safsouf20221044,
	author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
	title = {Understand the influence of learning analytics dashboards on learner self-regulation and academic success},
	year = {2022},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2022-March},
	pages = {1044 – 1047},
	doi = {10.1109/EDUCON52537.2022.9766741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130441058&doi=10.1109%2fEDUCON52537.2022.9766741&partnerID=40&md5=207c73ed23042125169f94e7a368f261},
	affiliations = {Limie Laboratory, Isga Group, Marrakech, Morocco; University Hassan Ii, Laboratory Ssdia, Casablanca, Morocco; University Bretagne Sud, Lab-STICC, Vannes, France},
	abstract = {Since the beginning of the COVID-19 pandemic, many countries have adopted online education as an alternative to face-to-face courses. This has increased awareness of the importance of analyzing learning data left by students to improve and evaluate the learning process. This article presents a new tool, named TaBAT, created to work with different LMSs in the form of dashboards accessible online and allowing teachers to monitor the progress of their learners and at the same time and allow teachers to track the progress of their learners, while allowing learners to develop self-regulation skills and visualize their learning process. The results of a study conducted show that TaBAT helped learners to increase their progress and spend more time in the online course. © 2022 IEEE.},
	author_keywords = {Learning analytics; Learning experience; Self-regulated dashboards},
	keywords = {E-learning; Learning systems; Face to face; Learning analytic; Learning data; Learning experiences; Learning process; On-line education; Online course; Self regulation; Self-regulated dashboard; Teachers'; Deregulation},
	editor = {Jemni M. and Kallel I. and Akkari A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-166544434-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Ong2022101,
	author = {Ong, Shuoh-Chwen and Chua, Fang-Fang},
	title = {ChemistLab: An Educational Game with Learning Analytics Dashboard},
	year = {2022},
	journal = {Proceedings - 2022 International Conference on Advanced Learning Technologies, ICALT 2022},
	pages = {101 – 103},
	doi = {10.1109/ICALT55010.2022.00038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136978749&doi=10.1109%2fICALT55010.2022.00038&partnerID=40&md5=a995b136df4e365b789709301413da6a},
	affiliations = {Multimedia University, Faculty of Computing and Informatics, Selangor, Cyberjaya, Malaysia},
	abstract = {Educational games are games explicitly designed with educational purposes and aims to balance learning and playing. These educational games help people to learn and improve as they play. However, there is a lack of gameplay monitoring process whereby the real-time information of game progress is not being reflected. Most of the existing educational games do not consolidate with learning analytics dashboards which leads to no visualization of gameplay information and inadequate gameplay analysis. When players have information on how to improve their performance, they will be encouraged to revisit the game. Hence, an educational game with learning analytics dashboard, ChemistLab, is developed for learners to learn chemistry. The dashboard will visualize the performance and skills changes overtime which reflect the players' learning patterns and strategies used to improve their performance for better learning. The learning content of the game is extracted from the Malaysia Upper Secondary Education (Form 4) Chemistry syllabus. The expected output of the game is to allow users to observe their gameplay performance through the dashboard and gaining new knowledge through the game with the achievement of learning objectives.  © 2022 IEEE.},
	author_keywords = {Analytics dashboard; Chemistry; Educational game; Gaming analytics; Learning analytics},
	keywords = {Analytic dashboard; Educational game; Gameplay; Gameplay analysis; Gaming analytic; Learn+; Learning analytic; Monitoring process; Performance; Real-time information},
	editor = {Chang M. and Chen N.-S. and Dascalu M. and Sampson D.G. and Tlili A. and Trausan-Matu S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166549519-6},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nazaretsky20221,
	author = {Nazaretsky, Tanya and Bar, Carmel and Walter, Michal and Alexandron, Giora},
	title = {Empowering Teachers with AI: Co-Designing a Learning Analytics Tool for Personalized Instruction in the Science Classroom},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {1 – 12},
	doi = {10.1145/3506860.3506861},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126263708&doi=10.1145%2f3506860.3506861&partnerID=40&md5=6999ff0ab9521ff5623c7ad9c05cc1f5},
	affiliations = {Weizmann Institute of Science, Rehovot, Israel},
	abstract = {AI-powered educational technology that is designed to support teachers in providing personalized instruction can enhance their ability to address the needs of individual students, hopefully leading to better learning gains. This paper presents results from a participatory research aimed at co-designing with science teachers a learning analytics tool that will assist them in implementing a personalized pedagogy in blended learning contexts. The development process included three stages. In the first, we interviewed a group of teachers to identify where and how personalized instruction may be integrated into their teaching practices. This yielded a clustering-based personalization strategy. Next, we designed a mock-up of a learning analytics tool that supports this strategy and worked with another group of teachers to define an 'explainable learning analytics' scheme that explains each cluster in a way that is both pedagogically meaningful and can be generated automatically. Third, we developed an AI algorithm that supports this 'explainable clusters' pedagogy and conducted a controlled experiment that evaluated its contribution to teachers' ability to plan personalized learning sequences. The planned sequences were evaluated in a blinded fashion by an expert, and the results demonstrated that the experimental group - teachers who received the clusters with the explanations - designed sequences that addressed the difficulties exhibited by different groups of students better than those designed by teachers who received the clusters without explanations. The main contribution of this study is twofold. First, it presents an effective personalization approach that fits blended learning in the science classroom, which combines a real-time clustering algorithm with an explainable-AI scheme that can automatically build pedagogically meaningful explanations from item-level meta-data (Q Matrix). Second, it demonstrates how such an end-to-end learning analytics solution can be built with teachers through a co-design process and highlights the types of knowledge that teachers add to system-provided analytics in order to apply them to their local context. As a practical contribution, this process informed the design of a new learning analytics tool that was integrated into a free online learning platform that is being used by more than 1000 science teachers.  © 2022 ACM.},
	author_keywords = {Blended Learning; Learning Analytics; Participatory Design; Personalized Instruction; Teacher Dashboards},
	keywords = {Design; Learning systems; Students; Analytic tools; Blended learning; Co-designing; Learning analytic; Participatory design; Personalized instruction; Science classroom; Science teachers; Teacher dashboard; Teachers'; Clustering algorithms},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Green Open Access}
}

@CONFERENCE{Hsu2022350,
	author = {Hsu, Shu-Yi and Tutwiler, M. Shane},
	title = {How Much and for Whom? A Multi-Wave Study of the Impact of Self-Regulated Learning Scaffolds on MOOC Student Academic Performance},
	year = {2022},
	journal = {L@S 2022 - Proceedings of the 9th ACM Conference on Learning @ Scale},
	pages = {350 – 354},
	doi = {10.1145/3491140.3528312},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132183034&doi=10.1145%2f3491140.3528312&partnerID=40&md5=8dcec89c344630799a181020fe985418},
	affiliations = {Columbia University, New York City, NY, United States; University of Rhode Island, Kingston, RI, United States},
	abstract = {With an effort to ameliorate the high dropout rates and the low performance in the massive open online courses (MOOCs), this paper presents multi-wave, experimental studies with a longitudinal intervention of self-regulated learning scaffolds on 24 MOOCs for 2650 learners. The self-regulated learning user interface (SRLUI) is designed based on Zimmerman's SRL cyclical model with a learning dashboard, interactive user interface, nudging effect. SRLUI is designed with two goals: 1. manifesting learner self-regulated learning behavior 2. enhancing learning outcomes. In this study, our primary research question is, "What is the marginal effect of SRLUI on learning as evidenced by final course grade?"To answer the research question, we employed a multilevel Bayesian beta regression modeling approach, first to each intervention and then across all three interventions in the aggregate. Our findings were mixed. We found some evidence of enhanced learning for passing and non-passing students across some of the individual interventions. On the whole, we determined that there was no statistical evidence of positive impacts on learning for students who pass a given course, though there is evidence of a small positive impact on learning for students who did not ultimately pass a given course. We discuss potential reasons for this differential impact and its implication for future course design and research. © 2022 ACM.},
	author_keywords = {bayesian regression; learning analytics; moocs; multilevel modeling; self-regulated learning},
	keywords = {Curricula; Learning systems; Scaffolds; User interfaces; Academic performance; Bayesian regression; Learning analytic; Learning scaffolds; Massive open online course; Moocs; Multilevel modeling; Performance; Research questions; Self-regulated learning; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039158-0},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Williamson2022260,
	author = {Williamson, Kimberly and Kizilcec, Rene},
	title = {A Review of Learning Analytics Dashboard Research in Higher Education: Implications for Justice, Equity, Diversity, and Inclusion},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {260 – 270},
	doi = {10.1145/3506860.3506900},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126234616&doi=10.1145%2f3506860.3506900&partnerID=40&md5=ac328b285fed60964e0c4435d83f1b3b},
	affiliations = {Cornell University, Ithaca, NY, United States},
	abstract = {Learning analytics dashboards (LADs) are becoming more prevalent in higher education to help students, faculty, and staff make data-informed decisions. Despite extensive research on the design and implementation of LADs, few studies have investigated their relation to justice, equity, diversity, and inclusion (JEDI). Excluding these issues in LAD research limits the potential benefits of LADs generally and risks reinforcing long-standing inequities in education. We conducted a critical literature review, identifying 45 relevant papers to answer three research questions: how is LAD research improving JEDI, ii. how might it maintain or exacerbate inequitable outcomes, and iii. what opportunities exist in this space to improve JEDI in higher education. Using thematic analysis, we identified four common themes: (1) participant identities and researcher positionality, (2) surveillance concerns, (3) implicit pedagogies, and (4) software development resources. While we found very few studies directly addressing or mentioning JEDI concepts, we used these themes to explore ways researchers could consider JEDI in their studies. Our investigation highlights several opportunities to intentionally incorporate JEDI into LAD research by sharing software resources and conducting cross-border collaborations, better incorporating user needs, and centering considerations of justice in LAD efforts to improve historical inequities.  © 2022 ACM.},
	author_keywords = {Dashboards; Diversity; Equity; Higher Education; Inclusion; Justice; Literature Review},
	keywords = {Dashboard; Design and implementations; Diversity; Equity; High educations; Informed decision; Justice; Literature reviews; Potential benefits; Research questions; Software design},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039573-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44}
}

@ARTICLE{Caspari-Sadeghi2022,
	author = {Caspari-Sadeghi, Sima},
	title = {Applying Learning Analytics in Online Environments: Measuring Learners’ Engagement Unobtrusively},
	year = {2022},
	journal = {Frontiers in Education},
	volume = {7},
	doi = {10.3389/feduc.2022.840947},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125083086&doi=10.3389%2ffeduc.2022.840947&partnerID=40&md5=966dd238a25faa4a659f11d66182f1aa},
	affiliations = {Empirical Learning Sciences, University of Passau, Passau, Germany},
	abstract = {Prior to the emergence of Big Data and technologies such as Learning Analytics (LA), classroom research focused mainly on measuring learning outcomes of a small sample through tests. Research on online environments shows that learners’ engagement is a critical precondition for successful learning and lack of engagement is associated with failure and dropout. LA helps instructors to track, measure and visualize students’ online behavior and use such digital traces to improve instruction and provide individualized support, i.e., feedback. This paper examines 1) metrics or indicators of learners’ engagement as extracted and displayed by LA, 2) their relationship with academic achievement and performance, and 3) some freely available LA tools for instructors and their usability. The paper concludes with making recommendations for practice and further research by considering challenges associated with using LA in classrooms. Copyright © 2022 Caspari-Sadeghi.},
	author_keywords = {dashboards and visualization; engagement; learning analytics (LA); LMS—learning management systems; technology -enhanced assessment},
	correspondence_address = {S. Caspari-Sadeghi; Empirical Learning Sciences, University of Passau, Passau, Germany; email: sima.caspari-sadeghi@uni-passau.de},
	publisher = {Frontiers Media S.A.},
	issn = {2504284X},
	language = {English},
	abbrev_source_title = {Front. Educ.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Gold Open Access}
}

@ARTICLE{Azmi Murad2022855,
	author = {Azmi Murad, M.A. and Shah Jahan, A.F. and Mohd Sharef, N. and Ab Jalil, H. and Ismail, I.A. and Mohd Noor, M.Z.},
	title = {An Analytics Dashboard for Personalised E-learning: A Preliminary Study},
	year = {2022},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {835},
	pages = {855 – 866},
	doi = {10.1007/978-981-16-8515-6_65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127618467&doi=10.1007%2f978-981-16-8515-6_65&partnerID=40&md5=c9893da6c0b3f0fd89bf660f97eec091},
	affiliations = {Institut Pengajian Sains Sosial, Universiti Putra Malaysia UPM, Selangor D.E., Serdang, 43400, Malaysia; Fakulti Sains Komputer Dan Teknologi Maklumat, Universiti Putra Malaysia UPM, Selangor D.E., Serdang, 43400, Malaysia; Fakulti Pengajian Pendidikan, Universiti Putra Malaysia UPM, Selangor D.E., Serdang, 43400, Malaysia; Fakulti Rekabentuk Dan Seni Bina, Universiti Putra Malaysia UPM, Selangor D.E., Serdang, 43400, Malaysia},
	abstract = {Over the last few decades, information and communication technologies (ICT) have changed our lives to enhance the process of teaching and learning. E-learning is powerful and influential in the classroom or elsewhere, as long as there is computer and internet access. The vast majority of institutions utilized a Learning Management System (LMS) to administer online courses to create, deliver, moderate and facilitate academic content and activities. While LMSs are mainly being used as a repository for course materials and platforms for assessing learning, recent developments require e-learning to be more responsive to students’ needs for a more customized learning experience. This requires functional characteristics like personalization analytics, self-monitoring, and intervention. Besides being a primary learning source nowadays, e-learning has been useful to monitor students’ performance and retention levels. However, the current e-learning system does not allow the user to empower the learning experience and the research on the suitability of the learning content is still lacking. We proposed a general design and implementation of a learning analytics dashboard for students comprising a predictive analytic component that is useful to help monitor or predict their academic performance based on learning activities. The results show that the system, known as DashLearn, allows students to stay alert of their current academic performance compared to their peers, monitor attendance and assignment submission status, and predict their grade ahead of time for an early intervention leading to more optimized learning. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Learning analytics; Learning management system; Linear regression; Prediction; Visualization},
	keywords = {Curricula; E-learning; Learning systems; Predictive analytics; Students; Teaching; 'current; Academic performance; Computer access; E - learning; Information and Communication Technologies; Internet access; Learning analytic; Learning experiences; Learning management system; Teaching and learning; Forecasting},
	correspondence_address = {M.A. Azmi Murad; Institut Pengajian Sains Sosial, Universiti Putra Malaysia UPM, Serdang, Selangor D.E., 43400, Malaysia; email: masrah@upm.edu.my},
	editor = {Alfred R. and Lim Y.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18761100},
	isbn = {978-981168514-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Electr. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Kuromiya2021559,
	author = {Kuromiya, Hiroyuki and Majumdar, Rwitajit and Ogata, Hiroaki},
	title = {Mining Students’ Engagement Pattern in Summer Vacation Assignment},
	year = {2021},
	journal = {29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings},
	volume = {1},
	pages = {559 – 568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126239624&partnerID=40&md5=8829a335941eda9f82fa3500d3ee2fb9},
	affiliations = {Graduate School of Informatics, Kyoto University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan},
	abstract = {Learning Analytics (LA) is an emergent field which aims at a better understanding of students and providing intelligence to learners, teachers, and administrators using learning log data. Although the use of technology in class is increasing in the K-12 sector as well as territory education, cases of effective implementation of LA in secondary schools were rarely reported, especially in Japan. In this paper, we offer an example where LA is implemented at a junior-high Math class in Japan. We introduce our LA platform, LEAF - LMS and e-book integrated learning analytics dashboard - and its usage during summer vacation period in the target class. We analyzed 121 students’ question answering logs and their exam performance after the vacation by K-means clustering method. As a result, we found that students’ progress patterns were able to be categorized as four types: early engagement, late engagement, high engagement, and low engagement and the early and high engagement group got significantly higher scores than the low engagement group. It implies the importance of the engagement at the beginning of the vacation. Moreover, by comparing the previous studies in MOOCs, we concluded that self-regulation skills are an important factor for student success in a long vacation period, too. Finally, we introduce a monitoring tool which aims to detect and send messages to at-risk students at an early stage in the next summer vacation period. Our case will become the first model case of how to implement LA in secondary school in Japan. © 2021 29th International Conference on Computers in Education Conference, ICCE 2021 - Proceedings. All rights reserved},
	author_keywords = {Learning Analytics; Long Vacation Period; Pattern Mining; Secondary Education},
	keywords = {Education computing; K-means clustering; Learning analytic; Log data; Long vacation period; Pattern mining; Secondary education; Secondary schools; Student engagement; Summer vacations; Teachers'; Vacation period; Students},
	correspondence_address = {H. Kuromiya; Graduate School of Informatics, Kyoto University, Japan; email: khiroyuki1993@gmail.com},
	editor = {Rodrigo M.M.T. and Iyer S. and Mitrovic A. and Cheng H.N.H. and Kohen-Vacs D. and Matuk C. and Palalas A. and Rajenran R. and Seta K. and Wang J.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972147-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ. Conf., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}@ARTICLE{Sadallah20203165,
	author = {Sadallah, Madjid and Encelle, Benoît and Maredj, Azze-Eddine and Prié, Yannick},
	title = {Towards fine-grained reading dashboards for online course revision},
	year = {2020},
	journal = {Educational Technology Research and Development},
	volume = {68},
	number = {6},
	pages = {3165 – 3186},
	doi = {10.1007/s11423-020-09814-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088930580&doi=10.1007%2fs11423-020-09814-0&partnerID=40&md5=003642e75d4046a29677fdd4c1628020},
	affiliations = {Computer Science Department, University of Bejaia, Bejaia, 06000, Algeria; Research Center on Scientic and Technical Information CERIST, 05 Rue des 3 Frères Aissou - Ben Aknoun, Algiers, Algeria; Université de Lyon 1, LIRIS, UMR 5205 CNRS, Villeurbanne, 69622, France; Université de Nantes, LS2N - UMR 6004 CNRS, Nantes, France},
	abstract = {Providing high-quality courses is of utmost importance to drive successful learning. This compels course authors to continuously review their contents to meet learners’ needs. However, it is challenging for them to detect the reading barriers that learners face with content, and to identify how their courses can be improved accordingly. In this paper, we propose a learning analytics approach for assisting course authors performing these tasks. Using logs of learners’ activity, a set of indicators related to course reading activity are computed and used to detect issues and to suggest content revisions. The results are presented to authors through CoReaDa, a learning dashboard empowered with assistive features. We instantiate our proposals using the logs of a major European e-learning platform, and validate them through a study. Study results show the effectiveness of our approach providing authors with more awareness and guidance in improving their courses, to better suit learners’ requirements. © 2020, Association for Educational Communications and Technology.},
	author_keywords = {Content revision; Information visualization; Learning analytics; Learning dashboards; Reading indicators; Web-based interaction},
	correspondence_address = {M. Sadallah; Computer Science Department, University of Bejaia, Bejaia, 06000, Algeria; email: madjid.sadallah@gmail.com},
	publisher = {Springer},
	issn = {10421629},
	language = {English},
	abbrev_source_title = {Educ. Technol. Res. Dev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ammenwerth202067,
	author = {Ammenwerth, Elske and Netzer, Michael and Hackl, Werner O.},
	title = {Learning analytics and the community of inquiry: Indicators to analyze and visualize online-based learning},
	year = {2020},
	journal = {Studies in Health Technology and Informatics},
	volume = {271},
	pages = {67 – 68},
	doi = {10.3233/SHTI200076},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087012040&doi=10.3233%2fSHTI200076&partnerID=40&md5=419294c27c71cc8cd3f2306ec3adfabd},
	affiliations = {Institute of Medical Informatics, UMIT - Private University for Health Sciences, Medical Informatics and Technology, Hall in Tirol, Austria},
	abstract = {Background: The Community of Inquiry (CoI) describes success factors for online-based learning. Objectives: To develop approaches for automatic analysis of CoI to be visualized within student and teacher dashboards. Methods: Extending indicators from social network analysis and linguistics; evaluation within a case study. Results: The project is just starting. Conclusion: Results will help to better understand and improve cooperative online-based learning in higher education. © 2020 The authors, AIT Austrian Institute of Technology and IOS Press.},
	author_keywords = {Education; Health informatics; Pedagogy; Teaching},
	keywords = {Education, Distance; Humans; Learning; Students; Teaching; Bioinformatics; Health; Medical informatics; Automatic analysis; Community of inquiry; Higher education; Success factors; conference paper; human; human experiment; learning; linguistics; medical informatics; pedagogics; social network; teaching; education; student; teaching; E-learning},
	correspondence_address = {E. Ammenwerth; UMIT, EWZ 1, Hall in Tirol, 6060, Austria; email: elske.ammenwerth@umit.at},
	editor = {Schreier G. and Hayn D. and Eggerth A.},
	publisher = {IOS Press BV},
	issn = {09269630},
	isbn = {978-164368084-2},
	pmid = {32578543},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Vaidya2021125,
	author = {Vaidya, Anagha and Sharma, Sarika},
	title = {Representation and Visualization of Students’ Progress Data Through Learning Dashboard},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1441},
	pages = {125 – 135},
	doi = {10.1007/978-3-030-88244-0_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118178561&doi=10.1007%2f978-3-030-88244-0_13&partnerID=40&md5=3fdf324d28e8cc8d93b582348f00cd40},
	affiliations = {Symbiosis Institute of Computer Studies and Research, Symbiosis International (Deemed University), Atur Centre, Model Colony, Pune, 411016, India},
	abstract = {Learning process of students is very important, it motivates the students for acquiring skills of critical thinking and gives a learning experience. Hence, a systematic feedback is required by the students for measuring their learning processes. This measurement is performed through different educational techniques namely learning analytics (LA), Education Data Mining (EDM) and Learning Dashboard (LD). Students’ learning measurement can be performed by measuring their log activity, content they read, by tracking assignment solving method etc., however in a traditional learning system, students’ learning is measured through the marks they score in the different evaluations. Therefore, these evaluations must be well structured and carefully planned in advanced. Hence the systematic management tool is required which assists the teacher as well as students for their learning progress at any time. In this paper we propose and demonstrate the Learning Dashboard in traditional learning environment which measures the different skills of students through a systematic assessment plan and the results of these assessments are displayed through an analytical report which will be helpful for all stakeholders. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Educational data mining; Learning analytics; Learning dashboard; Learning management system; Visualization},
	keywords = {Computer aided instruction; Data visualization; Information management; Learning systems; Students; Visualization; Critical thinking; Educational data mining; Learning analytic; Learning dashboard; Learning experiences; Learning management system; Learning process; Student learning; Student progress; Traditional learning; Data mining},
	correspondence_address = {S. Sharma; Symbiosis Institute of Computer Studies and Research, Symbiosis International (Deemed University), Pune, Atur Centre, Model Colony, 411016, India; email: sarika4@gmail.com},
	editor = {Singh M. and Tyagi V. and Gupta P.K. and Flusser J. and Ören T. and Sonawane V.R.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303088243-3},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ming2021352,
	author = {Ming, Mark Wan Chi and Kee, Chong Siew},
	title = {MAXIMISING STUDENT'S LEARNING THROUGH LEARNING ANALYTICS},
	year = {2021},
	journal = {Proceedings of the International CDIO Conference},
	pages = {352 – 365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145922069&partnerID=40&md5=00fa5cdcc9e704bfe6452c9f769bf451},
	affiliations = {School of Electrical & Electronic Engineering, Department of Educational Development, Singapore Polytechnic, Singapore},
	abstract = {This paper documents an innovation that is employing the Conceive-Design-Implement-Operate (CDIO) Engineering Education Framework, with a strong emphasis on utilizing the affordances of technological tools – especially the use of Learning Analytics (LA) to diagnose student learning gaps and enhance instructional interventions. The School of Electrical & Electronic Engineering (EEE) implemented an Assessing Learning in Real Time (ALERT) strategy for a first-year module (Digital Electronics) involving 19 lecturers and 1211 students, during a COVID-19 circuit-breaker, where students were primarily in a home-based learning mode. ALERT is a joint initiative by the 5 Polytechnics and Institute of Technical Education to create a technology driven framework that incorporate the application of educational technology (EdTech) tools and data visualization software to facilitate learning. The research explored how students experienced specific interventions in real time learning (e.g., the use of readiness tests and an exit poll) through the use of learning analytics (LA) which captures, analyses, and presents student’s performance data in a visual dashboard. The findings provided valuable insights into how students experience their online learning in real time, clearly highlighting specific areas of pedagogic focus for enhancing learning effectiveness and efficiency; most notably the importance of well-crafted examples, exercises, and quiz questions to provide opportunities for sufficient practice and feedback. In summary, LA can significantly contribute to the affordances that technology offers teaching professionals in meeting the challenges of today’s rapidly changing educational landscape. © Proceedings of the International CDIO Conference. All rights reserved.},
	author_keywords = {Evidence-Based Teaching; Learning Analytics; Standards: 8, 11},
	correspondence_address = {M.W.C. Ming; School of Electrical and Electronics Engineering, Singapore Polytechnic, 500 Dover Road, Singapore; email: mark_wan@sp.edu.sg},
	editor = {Bennedsen J. and Edstrom K. and Gudjonsdottir M.S. and Saemundsdottir I. and Kuptasthien N. and Roslof J. and Sripakagorn A.},
	publisher = {Chalmers University of Technology},
	issn = {20021593},
	isbn = {978-616407616-7},
	language = {English},
	abbrev_source_title = {Proc. Int. CDIO. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gomez20211,
	author = {Gomez, Manuel J. and Ruipérez-Valiente, José A. and Martínez, Pedro A. and Kim, Yoon Jeon},
	title = {Applying learning analytics to detect sequences of actions and common errors in a geometry game},
	year = {2021},
	journal = {Sensors (Switzerland)},
	volume = {21},
	number = {4},
	pages = {1 – 16},
	doi = {10.3390/s21041025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100235390&doi=10.3390%2fs21041025&partnerID=40&md5=72f0505cc2932715ded7e097f61b60dd},
	affiliations = {Faculty of Computer Science, University of Murcia, Murcia, 30008, Spain; Playful Journey Lab, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States},
	abstract = {Games have become one of the most popular activities across cultures and ages. There is ample evidence that supports the benefits of using games for learning and assessment. However, incorporating game activities as part of the curriculum in schools remains limited. Some of the barriers for broader adoption in classrooms is the lack of actionable assessment data, the fact that teachers often do not have a clear sense of how students are interacting with the game, and it is unclear if the gameplay is leading to productive learning. To address this gap, we seek to provide sequence and process mining metrics to teachers that are easily interpretable and actionable. More specifically, we build our work on top of Shadowspect, a three-dimensional geometry game that has been developed to measure geometry skills as well other cognitive and noncognitive skills. We use data from its implementation across schools in the U.S. to implement two sequence and process mining metrics in an interactive dashboard for teachers. The final objective is to facilitate that teachers can understand the sequence of actions and common errors of students using Shadowspect so they can better understand the process, make proper assessment, and conduct personalized interventions when appropriate. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Educational games; Game-based assessment; Learning analytics; Sequence mining; Visualization dashboard},
	keywords = {Data mining; Geometry; Students; Final objective; Gameplay; Games for learning; Process mining; Productive learning; Sequence of actions; Three dimensional geometry; adoption; article; geometry; human; human experiment; learning; mining; skill; teacher; Curricula},
	correspondence_address = {J.A. Ruipérez-Valiente; Faculty of Computer Science, University of Murcia, Murcia, 30008, Spain; email: jruiperez@um.es; J.A. Ruipérez-Valiente; Playful Journey Lab, Massachusetts Institute of Technology, Cambridge, 02139, United States; email: jruiperez@um.es},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {33546167},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Bakharia2020215,
	author = {Bakharia, Aneesha and Corrin, Linda},
	title = {Reimagining the conceptualisation, design and delivery of learning analytics},
	year = {2020},
	journal = {ICCE 2020 - 28th International Conference on Computers in Education, Proceedings},
	volume = {1},
	pages = {215 – 224},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099453235&partnerID=40&md5=447aa8934de4a6144890f43bc607ac5b},
	affiliations = {University of Queensland, Brisbane, Australia; Swinburne University of Technology, Melbourne, Australia},
	abstract = {Learning analytics applications have the potential to bring value to educational environments by providing the ability to analyse and present data about students in ways that are meaningful and actionable for educators. Recent studies have highlighted the importance of involving educators in the design process for these systems to ensure that what is developed meets their needs. However, this can add significant time and resource investment to a development project and requires the involvement of a range of people with data science and developer skills. Across various industries, new approaches are being imagined and trialled to reduce reliance on technical staff and long development processes when designing data-based systems instead enabling users to create a story from data without needing programming skills. In this paper we review the innovations introduced by DIVE, a mixed initiative visualisation and analysis application developed by a team at the MIT Media Lab, and discuss how these can be adapted to the field of learning analytics. DIVE includes a range of features that can provide value to learning analytics applications such as automated dataset statistical analysis, visualisation recommendation, and data story generation. An analysis of these features informs a set of guidelines which will enable the reconceptualisation of co-design sessions, reducing the time required to design learning analytics applications and facilitating the automated generation of prototypes, and in some cases full dashboards and analytic applications. The paper concludes with a discussion of future enhancements that could be made to the functionality of DIVE, such as the need for a semantic layer on trace and assessment data, to enable the translation of data into meaningful insights on learning. © ICCE 2020 - 28th International Conference on Computers in Education, Proceedings. All rights reserved.},
	author_keywords = {Dashboards; Data Stories; Learning Analytics; Visualisation Recommendation},
	keywords = {Data Science; Semantics; Visualization; Automated generation; Design learning; Development process; Development project; Educational environment; Mixed initiative; Programming skills; Story generations; Design},
	correspondence_address = {A. Bakharia; University of Queensland, Brisbane, Australia; email: aneesha.bakharia@gmail.com},
	editor = {So H.-J. and Rodrigo Ma.M. and Mason J. and Mitrovic A. and Bodemer D. and Chen W. and Chen Z.-H. and Flanagan B. and Jansen M. and Nkambou R. and Wu L.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972145-5},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kaliisa2021,
	author = {Kaliisa, Rogers and Dolonen, Jan Arild},
	title = {CADA: A learning analytics dashboard to support teachers with visualizations about students’ participation and discourse in online discussions},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118218152&partnerID=40&md5=aab8aca568bd00d502f8a21c567c3691},
	affiliations = {Department of Education, University of Oslo, Oslo, Norway},
	abstract = {This paper introduces a Canvas discussion analytics tool (CADA), designed following a human-computer interaction approach to provide teachers with real-time insights about students’ participation and discourse in online discussions. CADA supports the automatic extraction and analysis of discussion forums posts and interactions from the Canvas LMS and provides visualizations that communicate at a glance and in detail about participation rate, concepts being used and their epistemic connections, contributions per participant, and sentiment scores. The outputs provided by CADA make students’ thinking visible to the teacher, which provides an informed basis to intervene and change the course activities. This work-in-progress paper outlines the functional features included in CADA, preliminary results, and the next steps for evaluating, redesign and research with CADA in authentic teaching environments. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Design based research; Learning analytics; Teacher dashboards},
	keywords = {E-learning; Human computer interaction; Students; Visualization; Analytic tools; Automatic extraction; Design-based research; Learning analytic; Online discussions; Real- time; Student participation; Teacher dashboard; Teachers'; Tool support; Social networking (online)},
	editor = {Viberg O. and Glassey R. and Spikol D. and Balter O.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Safsouf2021331,
	author = {Safsouf, Yassine and Mansouri, Khalifa and Poirier, Franck},
	title = {TABAT: DESIGN AND EXPERIMENTATION OF A LEARNING ANALYSIS DASHBOARD FOR TEACHERS AND LEARNERS},
	year = {2021},
	journal = {Journal of Information Technology Education: Research},
	volume = {20},
	pages = {331 – 350},
	doi = {10.28945/4820},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112666418&doi=10.28945%2f4820&partnerID=40&md5=9b7dbe5b7f2281029867d72be8c8f061},
	affiliations = {Lab-STICC, University Bretagne Sud, France and LIMIE Laboratory, ISGA Group, Marrakech, Morocco; Laboratory SSDIA, ENSET of Mohammedia, University Hassan II of Casablanca, Morocco; Lab-STICC, University Bretagne Sud, Vannes, France},
	abstract = {Aim/Purpose Since the beginning of the COVID-19 pandemic, many countries have adopted online education as an alternative to face-to-face courses. This has increased awareness of the importance of analyzing learning data left by students to improve and evaluate the learning process. This article presents a new tool, named TaBAT, created to work with different LMSs in the form of dashboards accessible online and allowing teachers to monitor the progress of their learners and at the same time allow learners to visualize their learning process. Background TaBAT is designed based on the results of our previous research on factors that can influence the success of online learners, where we proposed and statistically validated a model for assessing the success of online learners called e-LSAM (eLearner Success Assessment Model). Methodology Two studies are presented in this article. The first one is conducted on a group of students from two classes (each composed of two groups) of a higher institute in Morocco, who participated in courses organized in blended learning on the Moodle platform. For each class, one of the two groups had access to the experiment to use the TaBAT tool (exposed group) to analyze the learning traces, while the second group did not have access to the dashboard (control group). The second study aimed to understand the impact of the usage of the TaBAT tool on the two exposed groups. Contribution The purpose of this article is to present a new analysis tool as well as to test this tool and to evaluate its impact on self-regulation and the prediction of academic success and, finally, to see how these students evaluate this tool. Findings The results of the TaBAT usage demonstrate the effectiveness of the success al gorithm, based on our theoretical model e-LSAM. The results also prove that this tool was able to increase the performance of the students of both groups exposed. The general evaluations of the participants also confirmed these results. Impact on Society The article proposes a tool for institutions to facilitate the monitoring and control of students' learning process. The tool provides visual information for teachers to study and react to in the educational context and gives students visualizations to promote their self-reflection and increase their performance and academic success. Future Research Generalize the use of the TaBAT tool, incorporating both private and public in stitutions, in order to confirm the results obtained in this article and at the same time improve the self-regulation and academic success of learners. © 2021. All Rights Reserved.},
	author_keywords = {e-learning; higher education; information visualization; learners' success; learning analytical dashboard; learning analytics; self regulated learning},
	publisher = {Informing Science Institute},
	issn = {15479714},
	language = {English},
	abbrev_source_title = {J. Inf. Technol. Educ. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Solórzano Alcívar2021127,
	author = {Solórzano Alcívar, Nayeth and Zambrano Loor, Robert and Carrera Gallego, Diego},
	title = {Natural Language to Facilitate the Analysis of Statistical Evaluation of Educational Digital Games},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1456 CCIS},
	pages = {127 – 141},
	doi = {10.1007/978-3-030-89941-7_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121626286&doi=10.1007%2f978-3-030-89941-7_10&partnerID=40&md5=c4b65a1657b3e2edac937486799214be},
	affiliations = {Escuela Superior Politécnica del Litoral, ESPOL – FADCOM, Guayaquil, Ecuador; Escuela Superior Politécnica del Litoral, ESPOL – FIEC, Guayaquil, Ecuador; UPM Universidad Politécnica de Madrid, UPM, Madrid, Spain},
	abstract = {The application of educational digital games (EDG) requires multiple perspectives for an optimal adaptation. This study shows how relevant feedback is presented in simple outcome reports of EDG-based learning for teachers and parents in Natural Language (NL). NL as a Machine Learning process also can represent quantitative data sets in consumable Spanish language statements. The objective is to improve outcomes of EDG platforms using a cloud-based dashboard used to evaluate student EDG application behavioral efficiency. A novel tool is proposed to provide simple language explanations rather than statistical representations of feedback to parents and teachers in marginal areas of developing economies. With fuzzy logic, the researchers present verbatim explanations of student behavior towards educational EDG. Results reveal comprehensive, simple, or colloquial Spanish language information for parents and teachers to provide improved evaluation keys to enhance student learning via EDG related to the school curricula. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Artificial Intelligence; Educational technology; Fuzzy logic; Game-based learning; Learning Analytics; Machine learning; MIDI-AM; Playability; PQM-Metrics; Serious games; Spanish language; Usability},
	keywords = {Computer circuits; Curricula; E-learning; Educational technology; Fuzzy logic; Machine learning; Students; Digital games; Fuzzy-Logic; Game-based Learning; Learning analytic; MIDI-AM; Natural languages; Playability; PQM-metric; Simple++; Spanish language; Serious games},
	correspondence_address = {N. Solórzano Alcívar; Escuela Superior Politécnica del Litoral, ESPOL – FADCOM, Guayaquil, Ecuador; email: nsolorza@espol.edu.ec},
	editor = {Salgado Guerrero J.P. and Chicaiza Espinosa J. and Cerrada Lozada M. and Berrezueta-Guzman S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303089940-0},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lowes2020,
	author = {Lowes, Ricky},
	title = {Knowing You: Personal Tutoring, Learning Analytics and the Johari Window},
	year = {2020},
	journal = {Frontiers in Education},
	volume = {5},
	doi = {10.3389/feduc.2020.00101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089433105&doi=10.3389%2ffeduc.2020.00101&partnerID=40&md5=07775cc126440427084ae1ce6ab6c95d},
	affiliations = {Plymouth Business School, University of Plymouth, Plymouth, United Kingdom},
	abstract = {Recent decades have seen increased concern for the student experience by higher education institutions, along with more pressure on students due to the highly competitive job market and the financial implications of doing a degree. The growth in the number of non-traditional students attending higher education has added to pressures on students and staff. There are impacts on the mental health and well-being of both as university education becomes massified, commodified and increasingly time-pressured. In this context, informed and kindly human interaction is crucial to mitigate negative influences. However, staff are less likely than ever to know their students well enough to have meaningful and impactful exchanges. Student record systems and learning analytics present themselves as a promising tool to be used in finding solutions to the complex problems of student achievement and well-being. This conceptual paper explores the use of big data and learning analytics to facilitate the work of personal tutors (academic advisors), illustrated by practical examples from the Student Support System used at the University of Plymouth. It will argue that learning analytics systems have the potential to facilitate communication and sharing of information, and thus enhance the quality of communication between personal tutors and their tutees to improve student engagement and support the tutee. However, the major contention of the paper is that information requires the lens of a humanistic framework in order to be transformed into knowledge and insight. The heuristic of the Johari Window is presented as a possible tool to stimulate thinking and to integrate the information from learning analytics into a meaningful framework in order to develop a powerful way of knowing tutees better and thus creating more supportive relationships with them. As such, the paper proposes an original contribution to the underexplored field of the use of learning analytics in personal tutoring in the UK, and hopes to stimulate empirical research in this area. © Copyright © 2020 Lowes.},
	author_keywords = {dashboards; higher education; Johari Window; learning analytics; personal tutoring},
	correspondence_address = {R. Lowes; Plymouth Business School, University of Plymouth, Plymouth, United Kingdom; email: ricky.lowes@plymouth.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {2504284X},
	language = {English},
	abbrev_source_title = {Front. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Gutiérrez2020,
	author = {Gutiérrez, Francisco and Seipp, Karsten and Ochoa, Xavier and Chiluiza, Katherine and De Laet, Tinne and Verbert, Katrien},
	title = {LADA: A learning analytics dashboard for academic advising},
	year = {2020},
	journal = {Computers in Human Behavior},
	volume = {107},
	doi = {10.1016/j.chb.2018.12.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058469687&doi=10.1016%2fj.chb.2018.12.004&partnerID=40&md5=55da362c4cc1e60192f3a1b851588f00},
	affiliations = {Departement Computerwetenschappen, KU Leuven, Celestijnenlaan 200A, Leuven, 3001, Belgium; Department of Administration, Leadership, and Technology, NYU Steinhardt, 82 Washington Square East, 7th Floor, New York, 10003-6674, NY, United States; Escuela Superior Politécnica del Litoral (ESPOL), Km 30., Vía Perimetral 5, Guayaquil, Ecuador},
	abstract = {From the perspective of Learning and Educational Technologies, academic advising has been one of the most overlooked aspects of academic support systems, despite being critical for the learning process and final success of students. The majority of higher education institutions provides simple technical support to academic advisers with basic descriptive statistics. This article presents the general design and implementation of a Learning Analytics Dashboard for Advisers (LADA), to support the decision-making process of academic advisers through comparative and predictive analysis. Moreover, this work evaluates the use of this tool to support decision-making of actual advisers in two different higher education institutions (University A, University B), compared with more traditional procedures and tools. Results indicate that LADA enables expert advisers to evaluate significantly more scenarios (Median = 2), especially for high advising difficulty cases with students that failed many courses (MedianA=3,MedianB=2.5), in a not-significantly different amount of time. For inexperienced advisers, LADA is perceived as a valuable tool for more accurate and efficient decision-making, as they were able to make informed decisions in a similar amount of time compared to the experts. These results are encouraging for further developments in the field. © 2018 Elsevier Ltd},
	author_keywords = {Academic adviser; Academic advising; Data-driven decision-making; Learning analytics; Visualization},
	keywords = {Data visualization; Flow visualization; Learning systems; Predictive analytics; Students; Academic adviser; Academic advising; Data driven decision; Decision making process; Descriptive statistics; Further development; Higher education institutions; Learning analytics; article; decision making; education; human; human experiment; learning; student; Decision making},
	correspondence_address = {K. Verbert; Departement Computerwetenschappen, KU Leuven, Leuven, Celestijnenlaan 200A, 3001, Belgium; email: katrien.verbert@cs.kuleuven.be},
	publisher = {Elsevier Ltd},
	issn = {07475632},
	coden = {CHBEE},
	language = {English},
	abbrev_source_title = {Comput. Hum. Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 99; All Open Access, Green Open Access}
}

@CONFERENCE{An2020,
	author = {An, Pengcheng and Holstein, Kenneth and D'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
	title = {The TA Framework: Designing Real-time Teaching Augmentation for K-12 Classrooms},
	year = {2020},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3313831.3376277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089606673&doi=10.1145%2f3313831.3376277&partnerID=40&md5=2396e7204e251892b4974ec7588bcaf6},
	affiliations = {Eindhoven University of Technology, Eindhoven, Netherlands; Carnegie Mellon University, Pittsburgh, United States},
	abstract = {Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design. © 2020 ACM.},
	author_keywords = {ambient intelligence; augmented intelligence; classroom; dashboards; k-12; orchestration; teacher},
	keywords = {Human engineering; Ambient displays; Classroom activity; Design and analysis; Design spaces; Design tradeoff; Informative ness; Multiple disciplines; Unobtrusiveness; Economic and social effects},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036708-0},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 48; All Open Access, Green Open Access}
}

@BOOK{Quigley202179,
	author = {Quigley, Cormac and Leavy, Elaine and Kiely, Etain and Jordan, Garrett},
	title = {The design of blended learning experiences for clean data to allow proper observation of student participation},
	year = {2021},
	journal = {Technology-Enabled Blended Learning Experiences for Chemistry Education and Outreach},
	pages = {79 – 94},
	doi = {10.1016/B978-0-12-822879-1.00004-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129063540&doi=10.1016%2fB978-0-12-822879-1.00004-4&partnerID=40&md5=e7f912a8f5d09f75f624630facfa639f},
	affiliations = {Galway-Mayo Institute of Technology, Galway, Ireland},
	abstract = {This chapter shares the results and insights from a collaborative project to use learning analytics to capture and transform learning in the first year of undergraduate science programs. The multidisciplinary team is composed of academics and technical staff with a shared goal and numerous motivations. The shared goal was to use analytics to describe and optimize learning. This is an ongoing project first instigated in 2016, which has evolved from using descriptive analytics to create personalized feedback forms, to creating dashboards and is working toward using historical data to train models to monitor and predict engagement and disengagement (identify at-risk students). Data are collected through a blended learning model that has enabled students to take greater ownership of their learning and staff to enhance curriculum and learning strategies. © 2021 Elsevier Inc. All rights reserved.},
	author_keywords = {Clean data; Learning analytics; Moodle; Motivations; Multidisciplinary team; VLE},
	publisher = {Elsevier},
	isbn = {978-012822879-1},
	language = {English},
	abbrev_source_title = {Technology-Enabled Blended Learning Experiences for Chemistry Education and Outreach},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Campoberde2021498,
	author = {Campoberde, Jonnathan and Macias, Miguel A. and Maldonado-Mahauad, Jorge},
	title = {Proposal for the Design and Implementation of a XBlock in Open edX to Support Learning Analytics},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	pages = {498 – 501},
	doi = {10.1109/LACLO54177.2021.00088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127183536&doi=10.1109%2fLACLO54177.2021.00088&partnerID=40&md5=d532b4decfb7044d08f9208006bfaa70},
	affiliations = {Universidad De Cuenca, Departamento De Ciencias De La Computación, Cuenca, Ecuador},
	abstract = {Nowadays, when users using information systems, they generate a large amount of data leaving behind a trace as a result of their interaction, e.g., when students access educational materials on Virtual Learning Environments (VLE). This has developed into what we now know as Massive Open Online Courses (MOOCs), which have millions of registered students. Due to the large amount of data that is generated within these MOOCs, Learning Analytics (LA) has emerged as an alternative to improve teaching and learning processes through data analysis. Open edX in an attempt to incorporate Learning Analytics into its Insights development platform, which provides very simple visualizations. Likewise, other projects have been added, which over time have become obsolete or do not provide sufficient support to improve the learning process of students. Therefore, this study proposes the design, development, and evaluation of a learning analytics dashboard for the Open edX platform. The tool will incorporate indicators of student success in its visualizations to improve the learning process within the platform.  © 2021 IEEE.},
	author_keywords = {dashboard; Learning Analytics; Open edX; student success; XBlock},
	keywords = {Computer aided instruction; Information systems; Information use; Students; Visualization; Dashboard; Design and implementations; Large amounts of data; Learning analytic; Learning process; Massive open online course; Open edx; Student success; Support learning; Xblock; Learning systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {Spanish},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Britain2020,
	author = {Britain, Gabriel and Jain, Ajit and Lupfer, Nic and Kerne, Andruid and Perrine, Aaron and Seo, Jinsil and Sungkajun, Annie},
	title = {Design is (A)live: An environment integrating ideation and assessment},
	year = {2020},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3334480.3382947},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090194232&doi=10.1145%2f3334480.3382947&partnerID=40&md5=a44b074cd448bb39aae93f692212de44},
	affiliations = {Texas AandM University, College Station, TX, United States; Microsoft Corporation, Redmond, WA, United States; Illinois State University, Normal, IL, United States},
	abstract = {Design coursework is iterative and continuously-evolving. Separation of digital tools used in design courses disaffects instructors' and students' iterative process experiences. We present a system that integrates support for design ideation with a learning analytics dashboard. A preliminary study deployed the system in two courses, each with ∼15 students and 1 instructor, for three months. We conducted semi-structured interviews to understand user experiences. Findings indicate benefits when systems contextualize creative work with assessment by integrating support for ideation with a learning analytics dashboard. Instructors are better able to track students and their work. Students are supported in reflecting on relationships among deliverables. We derive implications for contextualizing design with feedback to support creativity, learning, and teaching. © 2020 Owner/Author.},
	author_keywords = {Creativity; Design assessment; Design education; Design ideation; Iterative design; Learning analytics dashboard},
	keywords = {Digital devices; Human engineering; Learning systems; Students; User experience; Contextualize; Creative work; Design course; Design ideation; Digital tools; Iterative process; Semi structured interviews; Curricula},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036819-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Chong2020126,
	author = {Chong, Sylvia and Lee, Yew Haur and Tang, Yoke Wah},
	title = {Data Analytics and Visualization to Support the Adult Learner in Higher Education},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {126 – 131},
	doi = {10.1145/3421682.3421698},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096534288&doi=10.1145%2f3421682.3421698&partnerID=40&md5=c74b0720449e3b1212389af8d9d8a0de},
	affiliations = {Singapore University of Social Sciences, Singapore},
	abstract = {Data analytics can be used by higher education to have a deeper understanding of the learners and their learning. As the use of data analytics become more common, educators are often required not only to make sense of the analytics, but also make meaning pedagogically to better support the learner and the learning. This paper discusses the conceptualization and implementation of targeted learner support and intervention with the use of learning analytics and data visualization for the adult learner in higher education. The key objective is to leverage on learners' metrics in a format with visual indicators that give an overview of various aspects of the learning so that higher education institutions can profile their adult learners and anticipate their needs with customized advisories and intervention approaches. The learner metrics is presented in two different dashboards, applying both descriptive and predictive analytics, to provide deeper insights.  © 2020 ACM.},
	author_keywords = {adult learners; data visualization; Learning analytics},
	keywords = {Data Analytics; Data visualization; Visualization; Adult learners; Higher education; Higher education institutions; Key objective; Visual indicators; Predictive analytics},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038877-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Ahn202155,
	author = {Ahn, June and Campos, Fabio and Nguyen, Ha and Hays, Maria and Morrison, Jan},
	title = {Co-designing for privacy, transparency, and trust in K-12 learning analytics},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {55 – 65},
	doi = {10.1145/3448139.3448145},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103881417&doi=10.1145%2f3448139.3448145&partnerID=40&md5=f61683212c05baf61c11bbe472046535},
	affiliations = {University of California Irvine, Irvine, CA, United States; New York University, New York, NY, United States; University of Washington Seattle, Seattle, WA, United States; Vanderbilt University, Nashville, TN, United States},
	abstract = {The process of using Learning Analytics (LA) to improve teaching works from the assumption that data should be readily shared between stakeholders in an educational organization. However, the design of LA tools often does not account for considerations such as data privacy, transparency and trust among stakeholders. Research in human-centered design of LA does attend to these questions, specifically with a focus on including direct input from K-12 educators. In this paper, we present a series of design studies to articulate and refine conjectures about how privacy and transparency might influence better trust-building and data sharing within four school districts in the United States. By presenting the development of four sequential prototypes, our findings illuminate the tensions between designing for existing norms versus potentially challenging these norms by promoting meaningful discussions around the use of data. We conclude with a discussion about practical and methodological implications of our work to the LA community. © 2021 Owner/Author.},
	author_keywords = {Co-Design; Dashboards; Ethics; HCI; K-12 education; Privacy},
	keywords = {Data Sharing; Transparency; Co-designing; Design studies; Educational organizations; Human-centered designs; K-12 educators; Trust building; Privacy by design},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038935-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Ada2020155,
	author = {Ada, Mireilla Bikanga and Turinicova, Katarina},
	title = {Developing a dual dashboard early detection system},
	year = {2020},
	journal = {Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020},
	pages = {155 – 157},
	doi = {10.1109/ICALT49669.2020.00052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091170856&doi=10.1109%2fICALT49669.2020.00052&partnerID=40&md5=d7594b0285d7bb703ac6c65483efa7bc},
	affiliations = {University of Glasgow, School of Computing Science, Glasgow, United Kingdom},
	abstract = {This paper describes the development of 'StudentsAtRisk', a prototype early detection system. It is based on engagement with course materials and can be used to identify students who are falling behind by automatically flagging them. The system also allows instructors to flag these students manually. On their dashboard, students can flag themselves, as engagement with the material might not reveal all those who struggle.  © 2020 IEEE.},
	author_keywords = {At-risk student; Early detection systems; Early warning systems; Higher education; Learning analytics},
	keywords = {Course material; Early detection system; Students},
	editor = {Chang M. and Sampson D.G. and Huang R. and Hooshyar D. and Chen N.-S. and Kinshuk K. and Pedaste M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816090-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Wu2021267,
	author = {Wu, Jiun-Yu and Yang, Christopher C.Y. and Liao, Chen-Hsuan and Nian, Mei-Wen},
	title = {Analytics 2.0 for Precision Education: An Integrative Theoretical Framework of the Human and Machine Symbiotic Learning},
	year = {2021},
	journal = {Educational Technology and Society},
	volume = {24},
	number = {1},
	pages = {267 – 279},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098754428&partnerID=40&md5=aef272bc4e0adc711d7d73aa1ac8628f},
	affiliations = {Institute of Education, National Chiao Tung University, Taiwan; Graduate School of Informatics, Kyoto University, Japan},
	abstract = {This methodological-theoretical synergy provides an integrative framework of learning analytics through the development of the human-and-machine symbiotic reinforcement learning. The framework intends to address the challenges of the current learning analytics model, including a lack of internal validity, generalizability, immediacy, transferability, and interpretability for precision education. The proposed framework consists of a master component (the brain) and its four subsuming components: social networking, the smart classroom, the intelligent agent, and the dashboard. The brain component takes in and analyzes multimodal streams of student data from the other components with the model-based reinforcement learning, which forms policies of adequate actions that maximize the long-term rewards for both the human and machine in the seamless learning environment. An example case plan in advanced statistics was demonstrated to illustrate the course description, data collected in each component, and how the components meet different features of the smart learning environment to deliver precision education. An empirical demonstration was provided using some selected mulitmodal data to inform the effectiveness of the proposed framework. The human-and-machine symbiotic reinforcement learning has theoretical and practical implications for the next-generation learning analytics models and research. © 2021. All Rights Reserved.},
	author_keywords = {Learning analytics; Precision education; Reinforcement learning; Smart learning environment; Symbiotic learning},
	correspondence_address = {J.-Y. Wu; Institute of Education, National Chiao Tung University, Taiwan; email: jiunyu.rms@gmail.com},
	publisher = {International Forum of Educational Technology,National Taiwan Normal Universityand Society,},
	issn = {11763647},
	language = {English},
	abbrev_source_title = {Educational Technology and Society},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25}
}

@ARTICLE{de Leng2020,
	author = {de Leng, Bas and Pawelka, Friedrich},
	title = {The use of learning dashboards to support complex in-class pedagogical scenarios in medical training: how do they influence students’ cognitive engagement?},
	year = {2020},
	journal = {Research and Practice in Technology Enhanced Learning},
	volume = {15},
	number = {1},
	doi = {10.1186/s41039-020-00135-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086338753&doi=10.1186%2fs41039-020-00135-7&partnerID=40&md5=870f00d0b6fb4f1d6fe2ae271303eb2b},
	affiliations = {Educational Institute (IfAS), Faculty of Medicine, Münster University (WWU), Münster, Germany},
	abstract = {This study aims to contribute to empirical and interdisciplinary knowledge on how visual learning analytics tools can support students’ cognitive engagement in complex in-class scenarios. Taking a holistic approach, instructional design, learning analytics, and students’ perceptions were examined together. The teaching of systematic viewing and image interpretation in radiology education was used to exemplify a complex in-class scenario, and a specific learning dashboard was designed as a support tool. The design was based on both educational and visualization theories and aligned with a pedagogical scenario integrating individual and class-wide activities. The quantity and quality of the cognitive engagement of a group of 26 students were explored. A mixed method approach was used, including computer log file analyses of individual work, analysis of video recordings of in-class small group discussions, and a focus group discussion with the students involved. The in-class scenario with the learning dashboard resulted in a good balance between individual tasks and group discussions and a high degree of active cognitive engagement. Constructive and interactive forms of cognitive engagement were, however, less evident. In addition, the products of these constructive (description of findings) and interactive (type of dialogue) cognitive engagements were of mediocre quality and therefore not optimal for knowledge transfer. The study also showed that the way the students and teacher understood their respective tasks and used the available interaction techniques of the learning dashboard highly influenced the students’ cognitive engagement. Finally, several ideas emerged that could help to overcome the deficits found in the training of participants and to improve the tasks set and the learning dashboard itself. © 2020, The Author(s).},
	correspondence_address = {B. de Leng; Educational Institute (IfAS), Faculty of Medicine, Münster University (WWU), Münster, Germany; email: bdeleng@uni-muenster.de},
	publisher = {Springer},
	issn = {17937078},
	language = {English},
	abbrev_source_title = {Res. Pract. Technol. Enhanc.  Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access}
}

@CONFERENCE{Dourado2021482,
	author = {Dourado, Raphael A. and Rodrigues, Rodrigo Lins and Ferreira, Nivan and Mello, Rafael Ferreira and Gomes, Alex Sandro and Verbert, Katrien},
	title = {A teacher-facing learning analytics dashboard for process-oriented feedback in online learning},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {482 – 489},
	doi = {10.1145/3448139.3448187},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103894563&doi=10.1145%2f3448139.3448187&partnerID=40&md5=d857ea3ae82e3c4c6787bc78d1425b2a},
	affiliations = {Universidade Federal de Pernambuco, Brazil; Universidade Federal Rural de Pernambuco, Brazil; KU Leuven, Belgium},
	abstract = {In online learning, teachers need constant feedback about their students' progress and regulation needs. Learning Analytics Dashboards for process-oriented feedback can be a valuable tool for this purpose. However, few such dashboards have been proposed in literature, and most of them lack empirical validation or grounding in learning theories. We present a teacher-facing dashboard for process-oriented feedback in online learning, co-designed and evaluated through an iterative design process involving teachers and visualization experts. We also reflect on our design process by discussing the challenges, pitfalls, and successful strategies for building this type of dashboard. © 2021 ACM.},
	author_keywords = {Learning analytics dashboards; Online learning; Process-oriented feedback; Visualization},
	keywords = {Facings; Constant feedback; Design process; Empirical validation; Iterative design; Learning Theory; Online learning; Process-oriented; E-learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038935-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Green Open Access}
}

@CONFERENCE{Epp2021,
	author = {Epp, Carrie Demmans},
	title = {Using analytics and artificial intelligence to support language learner decision making},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103196529&partnerID=40&md5=750e85d536c782869432834e42fefcd6},
	affiliations = {EdTeKLA Research Group, University of Alberta, 2-32 Athabasca Hall, Edmonton, AB, Canada; UBC Language Sciences Initiative, University of British Columbia, 4031 Audain Art Centre, Vancouver, BC, Canada},
	abstract = {Technology use is deeply rooted within language learning. From the early use of language labs and more recent use of multi-media, we have seen the wide use of technology by language learners. These technologies provide detailed tracking of learner activities that can be harnessed in a way that adapts the learning environment to better meet learner needs. This adaptation can be made by computer programs or humans when analytics, machine learning, and artificial intelligence are used to support the sensemaking and adaptation process. This paper presents an autonomy framework in the context of analytics use. It explores this framework through the discussion of several projects that aimed to enable language learner autonomy by using analytics to help language learners understand their abilities or by recommending potential learning materials and paths to language learners. © 2020 Copyright for this paper by its authors.},
	author_keywords = {Computer assisted language learning (CALL); Learner modelling; Learning analytics; Learning analytics dashboards; Mobile assisted language learning (MALL); Open learner models},
	keywords = {Computer aided instruction; Decision making; E-learning; Adaptation process; Autonomy framework; Language learning; Learner autonomies; Learning environments; Learning materials; Sensemaking; Technology use; Artificial intelligence},
	correspondence_address = {C.D. Epp; EdTeKLA Research Group, University of Alberta, 2-32 Athabasca Hall, Edmonton, Canada; email: EMAILcdemmansepp@ualberta.ca},
	editor = {Viberg O. and Mynard J. and Peeters W. and Saqr M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2021,
	title = {22nd International Conference on Artificial Intelligence in Education, AIED 2021},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12748 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126441385&partnerID=40&md5=8e064ff5d99e15b3b99f5ca36bb7e93b},
	abstract = {The proceedings contain 125 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: Protecting Student Privacy with Synthetic Data from Generative Adversarial Networks; learning Analytics and Fairness: Do Existing Algorithms Serve Everyone Equally?; exploiting Structured Error to Improve Automated Scoring of Oral Reading Fluency; data Augmentation for Enlarging Student Feature Space and Improving Random Forest Success Prediction; The School Path Guide: A Practical Introduction to Representation and Reasoning in AI for High School Students; Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses; early Prediction of Children’s Disengagement in a Tablet Tutor Using Visual Features; an Educational System for Personalized Teacher Recommendation in K-12 Online Classrooms; designing Intelligent Systems to Support Medical Diagnostic Reasoning Using Process Data; open Learner Models for Multi-activity Educational Systems; incorporating Item Response Theory into Knowledge Tracing; automated Model of Comprehension V2.0; pre-course Prediction of At-Risk Calculus Students; examining Learners’ Reflections over Time During Game-Based Learning; examining the Use of a Teacher Alerting Dashboard During Remote Learning; capturing Fairness and Uncertainty in Student Dropout Prediction – A Comparison Study; Dr. Proctor: A Multi-modal AI-Based Platform for Remote Proctoring in Education; multimodal Trajectory Analysis of Visitor Engagement with Interactive Science Museum Exhibits; analytics of Emerging and Scripted Roles in Online Discussions: An Epistemic Network Analysis Approach; towards Automatic Content Analysis of Rhetorical Structure in Brazilian College Entrance Essays; personal Vocabulary Recommendation to Support Real Life Needs; contrasting Automatic and Manual Group Formation: A Case Study in a Software Engineering Postgraduate Course.},
	editor = {Roll I. and McNamara D. and Sosnovsky S. and Luckin R. and Dimitrova V.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303078291-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wiedbusch2021,
	author = {Wiedbusch, Megan D. and Kite, Vance and Yang, Xi and Park, Soonhye and Chi, Min and Taub, Michelle and Azevedo, Roger},
	title = {A Theoretical and Evidence-Based Conceptual Design of MetaDash: An Intelligent Teacher Dashboard to Support Teachers' Decision Making and Students’ Self-Regulated Learning},
	year = {2021},
	journal = {Frontiers in Education},
	volume = {6},
	doi = {10.3389/feduc.2021.570229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102292353&doi=10.3389%2ffeduc.2021.570229&partnerID=40&md5=115e8f0372c68ee400d3ba08056a5da4},
	affiliations = {Laboratory for the Study of Metacognition and Advanced Learning Technologies, Department of Learning Sciences and Educational Research, College of Community Innovation and Education, University of Central Florida, Orlando, FL, United States; Department of STEM Education, College of Education, North Carolina State University, Raleigh, NC, United States; Department of Computer Science, College of Engineering, North Carolina State University, Raleigh, NC, United States; Department of Learning Sciences and Educational Research, College of Community Innovation and Education, University of Central Florida, Orlando, FL, United States},
	abstract = {Teachers’ ability to self-regulate their own learning is closely related to their competency to enhance self-regulated learning (SRL) in their students. Accordingly, there is emerging research for the design of teacher dashboards that empower instructors by providing access to quantifiable evidence of student performance and SRL processes. Typically, they capture evidence of student learning and performance to be visualized through activity traces (e.g., bar charts showing correct and incorrect response rates, etc.) and SRL data (e.g., eye-tracking on content, log files capturing feature selection, etc.) in order to provide teachers with monitoring and instructional tools. Critics of the current research on dashboards used in conjunction with advanced learning technologies (ALTs) such as simulations, intelligent tutoring systems, and serious games, argue that the state of the field is immature and has 1) focused only on exploratory or proof-of-concept projects, 2) investigated data visualizations of performance metrics or simplistic learning behaviors, and 3) neglected most theoretical aspects of SRL including teachers’ general lack of understanding their’s students’ SRL. Additionally, the work is mostly anecdotal, lacks methodological rigor, and does not collect critical process data (e.g. frequency, duration, timing, or fluctuations of cognitive, affective, metacognitive, and motivational (CAMM) SRL processes) during learning with ALTs used in the classroom. No known research in the areas of learning analytics, teacher dashboards, or teachers’ perceptions of students’ SRL and CAMM engagement has systematically and simultaneously examined the deployment, temporal unfolding, regulation, and impact of all these key processes during complex learning. In this manuscript, we 1) review the current state of ALTs designed using SRL theoretical frameworks and the current state of teacher dashboard design and research, 2) report the important design features and elements within intelligent dashboards that provide teachers with real-time data visualizations of their students’ SRL processes and engagement while using ALTs in classrooms, as revealed from the analysis of surveys and focus groups with teachers, and 3) propose a conceptual system design for integrating reinforcement learning into a teacher dashboard to help guide the utilization of multimodal data collected on students’ and teachers’ CAMM SRL processes during complex learning. © Copyright © 2021 Wiedbusch, Kite, Yang, Park, Chi, Taub and Azevedo.},
	author_keywords = {learning; multimodal data; self-regulated learning (SRL); teacher dashboards; teacher decision making},
	correspondence_address = {M.D. Wiedbusch; Laboratory for the Study of Metacognition and Advanced Learning Technologies, Department of Learning Sciences and Educational Research, College of Community Innovation and Education, University of Central Florida, Orlando, United States; email: MeganWiedbusch@knights.ucf.edu},
	publisher = {Frontiers Media S.A.},
	issn = {2504284X},
	language = {English},
	abbrev_source_title = {Front. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Gold Open Access}
}

@ARTICLE{Jivet2020,
	author = {Jivet, Ioana and Scheffel, Maren and Schmitz, Marcel and Robbers, Stefan and Specht, Marcus and Drachsler, Hendrik},
	title = {From students with love: An empirical study on learner goals, self-regulated learning and sense-making of learning analytics in higher education},
	year = {2020},
	journal = {Internet and Higher Education},
	volume = {47},
	doi = {10.1016/j.iheduc.2020.100758},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087836985&doi=10.1016%2fj.iheduc.2020.100758&partnerID=40&md5=452c8dc8221f332af461cb095bb9b551},
	affiliations = {Open University of the Netherlands, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; Zuyd University of Applied Sciences, Nieuw Eyckholt 300, Heerlen, 6419 AT, Netherlands; Delft University of Technology, Mekelweg 5, Delft, 2628 CD, Netherlands; Goethe University, Max-von-Laue-Str. 9, Frankfurt am Main, 60438, Germany; German Institute for International Educational Research (DIPF), Rostocker Straße 6, Frankfurt am Main, 60323, Germany},
	abstract = {Unequal stakeholder engagement is a common pitfall of adoption approaches of learning analytics in higher education leading to lower buy-in and flawed tools that fail to meet the needs of their target groups. With each design decision, we make assumptions on how learners will make sense of the visualisations, but we know very little about how students make sense of dashboard and which aspects influence their sense-making. We investigated how learner goals and self-regulated learning (SRL) skills influence dashboard sense-making following a mixed-methods research methodology: a qualitative pre-study followed-up with an extensive quantitative study with 247 university students. We uncovered three latent variables for sense-making: transparency of design, reference frames and support for action. SRL skills are predictors for how relevant students find these constructs. Learner goals have a significant effect only on the perceived relevance of reference frames. Knowing which factors influence students' sense-making will lead to more inclusive and flexible designs that will cater to the needs of both novice and expert learners. © 2020 The Authors},
	author_keywords = {Higher education; Learner goals; Learning analytics dashboard; Self-regulated learning; Sense-making; Student-facing learning analytics},
	keywords = {Computer applications; Internet; Empirical studies; Flexible designs; Mixed-methods research; Perceived relevances; Quantitative study; Self-regulated learning; Stakeholder engagement; University students; Students},
	correspondence_address = {I. Jivet; Open University of the Netherlands, Heerlen, Valkenburgerweg 177, 6419 AT, Netherlands; email: i.jivet@tudelft.nl},
	publisher = {Elsevier Ltd},
	issn = {10967516},
	language = {English},
	abbrev_source_title = {Internet Higher Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 106; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kasepalu2020393,
	author = {Kasepalu, Reet},
	title = {Overcoming the difficulties for teachers in collaborative learning using multimodal learning analytics},
	year = {2020},
	journal = {Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020},
	pages = {393 – 395},
	doi = {10.1109/ICALT49669.2020.00124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091147949&doi=10.1109%2fICALT49669.2020.00124&partnerID=40&md5=28f0077d841f3f07cb4c88028b62bfce},
	affiliations = {Tallinn University, School of Educational Sciences, Tallinn, Estonia},
	abstract = {During collaborative learning (CL) teachers have little to no information about what is happening in the groups, however, they are expected to plan, monitor, support, consolidate and reflect upon student interactions. How is a teacher able to provide support the students when she/he is not fully aware of the situation and progress of the students? Multimodal learning analytics (MMLA) could offer teachers valuable insights into the CL process, however, not many MMLA outputs are used in real practice today, and designing such MMLA dashboards remains a challenge. The aim of the present design-science research is to find out if multimodal learning analytics is able to help teachers help support students in CL. After having gone through two cycles of design based research, it is apparent that the involved teachers are interested in getting an overview of the activities within the groups and help with assessment. The involved teachers were ready to use collaboration analytics if it can assure a certain level of accuracy, more research is needed on how to use MMLA to support teachers in CL assessment.  © 2020 IEEE.},
	author_keywords = {Behavioural engagement; Collaboration analytics; Collaborative learning; Dominance; Multimodal learning analytics; Participation; Social loafing},
	keywords = {Collaborative learning; Design-based research; Design-science researches; Multi-modal learning; Ready to use; Student interactions; Students},
	correspondence_address = {R. Kasepalu; Tallinn University, School of Educational Sciences, Tallinn, Estonia; email: reetkase@tlu.ee},
	editor = {Chang M. and Sampson D.G. and Huang R. and Hooshyar D. and Chen N.-S. and Kinshuk K. and Pedaste M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816090-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Han2021,
	author = {Han, Jeongyun and Kim, Kwan Hoon and Rhee, Wonjong and Cho, Young Hoan},
	title = {Learning analytics dashboards for adaptive support in face-to-face collaborative argumentation},
	year = {2021},
	journal = {Computers and Education},
	volume = {163},
	doi = {10.1016/j.compedu.2020.104041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098208901&doi=10.1016%2fj.compedu.2020.104041&partnerID=40&md5=f2cd05068f671415563731571ca88257},
	affiliations = {Department of Transdisciplinary Studies, Seoul National University, Seoul, South Korea; Department of Education, Seoul National University, Seoul, South Korea},
	abstract = {Despite the potential of learning analytics for personalized learning, it is seldom used to support collaborative learning particularly in face-to-face (F2F) learning contexts. This study uses learning analytics to develop a dashboard system that provides adaptive support for F2F collaborative argumentation (FCA). This study developed two dashboards for students and instructors, which enabled students to monitor their FCA process through adaptive feedback and helped the instructor provide adaptive support at the right time. The effectiveness of the dashboards was examined in a university class with 88 students (56 females, 32 males) for 4 weeks. The dashboards significantly improved the FCA process and outcomes, encouraging students to actively participate in FCA and create high-quality arguments. Students had a positive attitude toward the dashboard and perceived it as useful and easy to use. These findings indicate the usefulness of learning analytics dashboards in improving collaborative learning through adaptive feedback and support. Suggestions are provided on how to design dashboards for adaptive support in F2F learning contexts using learning analytics. © 2020 The Authors},
	author_keywords = {Adaptive instruction; Argumentation; Collaborative learning; Dashboard; Learning analytics},
	keywords = {Computer science; Education; Adaptive feedback; Adaptive support; Collaborative argumentations; Collaborative learning; High quality; Learning context; Personalized learning; Positive attitude; Students},
	correspondence_address = {Y.H. Cho; Seoul National University, Seoul National University, Seoul, 1 Gwanak-ro, Gwanak-gu, South Korea; email: yhcho95@snu.ac.kr},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 94; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Maldonado-Mahauad202116,
	author = {Maldonado-Mahauad, Jorge and Aguilar, Bryan and Sigua, Edisson},
	title = {FlipMyLearning: A Tool for Monitoring and Predicting Learner Behavior in Moodle},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	pages = {16 – 23},
	doi = {10.1109/LACLO54177.2021.00010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127105675&doi=10.1109%2fLACLO54177.2021.00010&partnerID=40&md5=3c10fb3a1514b9e8b41a95d05b40ba94},
	affiliations = {Universidad De Cuenca, Departamento De Ciencias De La Computación, Cuenca, Ecuador},
	abstract = {The development of technology has meant that in the last two decades Information and Communication Technologies have become more and more involved in the teaching process and have tried to change traditional learning models. With the support of modern technology, platforms have been developed and perfected that encourage the adoption of a new virtual learning paradigm. These platforms store student and teacher interactions with course resources in database engines, information that can be very relevant, but in many cases has not been processed in a way that is useful for use by teachers and students. Therefore, this study aims to implement and evaluate a dashboard for student behavior analysis and dropout prediction in Moodle. The tool will help teachers to know what students do before, during and after a class mediated by virtual platforms. In addition, it will also help students manage their learning process and easily and effectively monitor their progress in the course. Given the analytical nature of the research, exploratory analysis of the Moodle data model, evaluation of existing visualizations and design of the tool based on Moodle architecture were used to develop a dashboard of visualizations and dropout prediction. As a result, FlipMyLearning was implemented, a plugin for the Moodle platform that allows the teacher to monitor the learning process of students for informed decision making. The developed plugin contains visualizations for both the teacher and the student, divided into different sections, each oriented to monitor different aspects of the course. The research conducted shows that the visualizations generated were useful for both teachers and students who participated in the evaluation process. In addition, variables such as time spent, number of sessions and indicators related to cognitive depth and social breadth are useful variables to identify groups of students at risk of dropping out.  © 2021 IEEE.},
	author_keywords = {Dashboard; Dropout; Learning Analytics; Moodle; Prediction},
	keywords = {Curricula; Decision making; E-learning; Engineering education; Forecasting; Learning systems; Teaching; Visualization; Dashboard; Dropout; Information and Communication Technologies; Learning analytic; Learning process; Moodle; Plug-ins; Teachers'; Teaching process; Traditional learning; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {Spanish},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Kesselbacher2020,
	author = {Kesselbacher, Max and Wiltschnig, Kevin and Bollin, Andreas},
	title = {Block-based learning analytics repository and dashboard: Towards an interface between researcher and educator},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3421590.3421662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094978731&doi=10.1145%2f3421590.3421662&partnerID=40&md5=f9f1b44eeb4b7969241349df7a15fe17},
	affiliations = {Universität Klagenfurt, Klagenfurt, Austria},
	abstract = {The collection of programming session data is a cornerstone of programming learning analytics research. For text-based programming, there are data collection projects, like BlueJ's Blackbox, which provide access to the data and thereby facilitate additional research as well as verification. For block-based programming, only data sets of finished projects but not of programming sessions are available. We introduce a data repository that is extendable by implementing instrumentation plugins for various IDEs. The currently supported features are: data collection of text-based and block-based programming sessions, curated user self-registration and filtered data download. This then enables us to implement an educator dashboard in the future, making use of live programming session data to incorporate educators and students into learning analytics research. © 2020 Owner/Author.},
	author_keywords = {Data repository; Learning analytics; Programming education},
	keywords = {Computer applications; Computer programming; Black boxes; Block based; Block-based learning; Data collection; Data repositories; Plug-ins; Programming learning; Data acquisition},
	editor = {Brinda T. and Armoni M.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038759-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Manganello202118,
	author = {Manganello, Flavio and Pozzi, Francesca and Passarelli, Marcello and Persico, Donatella and Dagnino, Francesca Maria},
	title = {A dashboard to monitor self-regulated learning behaviours in online professional development},
	year = {2021},
	journal = {International Journal of Distance Education Technologies},
	volume = {19},
	number = {1},
	pages = {18 – 34},
	doi = {10.4018/IJDET.2021010102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099664328&doi=10.4018%2fIJDET.2021010102&partnerID=40&md5=59cf7b65ac1bbcbdb29d300d3273e336},
	affiliations = {ITD-CNR, Italy},
	abstract = {This paper reports on usage and impact on learning achievements of a dashboard developed to help monitor self-regulated learning behaviours in an online professional development path. The design of the path as well as of the dashboard were grounded on a pre-existing conceptual framework distinguishing between four different types of self-regulated learning behaviours taking place in professional learning networks and underpinning professional practice sharing. One of the objectives of the path was to promote such behaviours among participants, and the dashboard was designed to support their self-monitoring. Data were collected through usage log files analysis, a survey, and pretest and posttest. The results shed light on participants' actual usage of the dashboard, their opinion regarding its usefulness in relation of its capability to measure and support their SRL processes, and the dashboard's actual impact on their learning achievements. Moreover, some limitations in the current configuration of the dashboard emerged, which can guide further development. © This article published as an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/) which permits unrestricted use, distribution, and production in any medium, provided the author of the original work and original publication source are properly credited.},
	author_keywords = {Continuous professional development; Dashboard; Data visualization; Learning achievements; Learning analytics; Moodle; Self-regulated learning; Self-regulated learning behaviours},
	keywords = {E-learning; Conceptual frameworks; Current configuration; Learning achievement; Professional development; Professional learning; Professional practices; Self-monitoring; Self-regulated learning; Professional aspects},
	publisher = {IGI Global},
	issn = {15393100},
	language = {English},
	abbrev_source_title = {Int. J. Distance Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Delgado2021100,
	author = {Delgado, María and Pando, Diego and Maldonado-Mahauad, Jorge},
	title = {Dicrev-Dash: Proposal for the Design, Creation and Evaluation of a Dashboard for Data Visualization},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3059},
	pages = {100 – 110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122676202&partnerID=40&md5=ffb8b8169212434b2feae5b8bd914915},
	affiliations = {University Of Cuenca, Av. 12 de Abril, Cuenca, Ecuador},
	abstract = {Today there are large amounts of data that are difficult to understand in spreadsheets or textual reports, so data visualizations have become an easy and fast way to convey the ideas or objectives that you want to achieve with that data. The objective of this article is to propose a methodology for creating dashboard data visualizations, taking into account the fundamental steps in the creation of a data methodology. To this end, the following question has been posed: What are the phases that must be considered to create an efficient and effective data visualization? This question will be answered in this article with the elaboration of the proposed methodology. Having said all the above, it is proposed to follow and prove this methodology in the future to create a dashboard of data visualizations for the learning analytics observatory.  ©? 2020 Copyright for this paper by its authors.},
	author_keywords = {Creation; Dashboard; Design; Evaluation; Methodology; Proposal; Visualization},
	keywords = {Data visualization; Creation; Dashboard; Data methodology; Evaluation; Large amounts of data; Methodology; Proposal; Visualization},
	editor = {Klinge Orlando K.O. and Universidad Catolica de Santa Maria, Calle San Jose s/n Umacollo, Arequipa and Maldonado-Mahauad J. and Universidad de Cuenca, Av. 12 de Abril. Solorzano Cuenca},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sansom2020386,
	author = {Sansom, Rebecca L. and Bodily, Robert and Bates, Caroline O. and Leary, Heather},
	title = {Increasing Student Use of a Learner Dashboard},
	year = {2020},
	journal = {Journal of Science Education and Technology},
	volume = {29},
	number = {3},
	pages = {386 – 398},
	doi = {10.1007/s10956-020-09824-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083776967&doi=10.1007%2fs10956-020-09824-w&partnerID=40&md5=2e29d253fc6044a0f109644de28d3d0c},
	affiliations = {Chemistry and Biochemistry, College of Physical and Mathematical Sciences, Brigham Young University, Provo, UT, United States; Senior Data Scientist, Lumen Learning, Portland, United States; Instructional Psychology & Technology, McKay School of Education, Brigham Young University, Provo, UT, United States},
	abstract = {Use of online learning systems, such as learner dashboards, is increasing in university chemistry courses. Learning analytics can support student learning by providing feedback on concept mastery. This paper investigated how student use of a chemistry learner dashboard might be increased through class structure, instructor practice, and dashboard design changes across three iterations in a general chemistry course. Once acceptable levels of student dashboard use were achieved, further investigation of how students interacted with the dashboard, including accessing the variety of available resources, was conducted. Survey data and clickstream data from the dashboard were collected and analyzed in a convergent mixed methods design. This study found that changes in course structure, teacher practice, and dashboard design increased use of the dashboard and utilization of the variety of materials offered in it. Recommendations for instructors to effectively utilize a learner dashboard and increase student trust in the system are provided. © 2020, Springer Nature B.V.},
	author_keywords = {Dashboards; Distributed learning environments; Human-computer interface; Interactive learning environments; Learning analytics; Online learning systems},
	correspondence_address = {R.L. Sansom; Chemistry and Biochemistry, College of Physical and Mathematical Sciences, Brigham Young University, Provo, United States; email: rsansom@chem.byu.edu},
	publisher = {Springer},
	issn = {10590145},
	language = {English},
	abbrev_source_title = {J. Sci. Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Wang2021487,
	author = {Wang, Dongqing and Han, Hou},
	title = {Applying learning analytics dashboards based on process-oriented feedback to improve students' learning effectiveness},
	year = {2021},
	journal = {Journal of Computer Assisted Learning},
	volume = {37},
	number = {2},
	pages = {487 – 499},
	doi = {10.1111/jcal.12502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093954552&doi=10.1111%2fjcal.12502&partnerID=40&md5=5b8c71cddf4dc3264ed9867d621a074e},
	affiliations = {School of Information Technology in Education, South China Normal University, Guangzhou, China; School of Chinese Language & Literature, South China Normal University, Guangzhou, China},
	abstract = {With the development of a technology-supported environment, it is plausible to provide rich process-oriented feedback in a timely manner. In this paper, we developed a learning analytics dashboard (LAD) based on process-oriented feedback in iTutor to offer learners their final scores, sub-scale reports, and corresponding suggestions on further learning content. We adopted a quasi-experimental design to investigate the effectiveness of the report on students' learning. Ninety-four freshman from two classes participated in this research. The two classes were divided into the LAD group and the original analytics report (OAR) based on a product-oriented feedback group. Before the experiment, all the students took the prior knowledge assessment. After a semester's instruction, all the students took the post-test of the summative assessment. Results indicated that students in the LAD group experienced better learning effectiveness than students in the OAR group. LAD based on process-oriented feedback was also effective in improving the skill learning effectiveness of the students with low-level prior knowledge. © 2020 John Wiley & Sons Ltd},
	author_keywords = {effective learning; learning analytics dashboard (LAD); prior knowledge; process-oriented feedback},
	correspondence_address = {H. Han; School of Chinese Language & Literature, South China Normal University, Guangzhou, China; email: hanhou99@qq.com},
	publisher = {Blackwell Publishing Ltd},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33}
}

@ARTICLE{Er2021169,
	author = {Er, Erkan and Dimitriadis, Yannis and Gašević, Dragan},
	title = {Collaborative peer feedback and learning analytics: theory-oriented design for supporting class-wide interventions},
	year = {2021},
	journal = {Assessment and Evaluation in Higher Education},
	volume = {46},
	number = {2},
	pages = {169 – 190},
	doi = {10.1080/02602938.2020.1764490},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085519783&doi=10.1080%2f02602938.2020.1764490&partnerID=40&md5=7118c2d8853e00bcb7d00392abb8cee2},
	affiliations = {School of Telecommunication Engineering, Universidad de Valladolid, Valladolid, Spain; Faculty of Information Technology, Monash University, Melbourne, Australia},
	abstract = {Although dialogue can augment the impact of feedback on student learning, dialogic feedback is unaffordable by instructors teaching large classes. In this regard, peer feedback can offer a scalable and effective solution. However, the existing practices optimistically rely on students’ discussion about feedback and lack a systematic design approach. In this paper, we propose a theoretical framework of collaborative peer feedback which structures feedback dialogue into three distinct phases and outlines the learning processes involved in each of them. Then, we present a web-based platform, called Synergy, which is designed to facilitate collaborative peer feedback as conceptualised in the theoretical framework. To enable instructor support and facilitation during the feedback practice, we propose a learning analytics support integrated into Synergy. The consolidated model of learning analytics, which concerns three critical pieces for creating impactful learning analytics practices, theory, design and data science, was employed to build the analytics support. The learning analytics support aims to guide instructors’ class-wide actions toward improving students’ learning experiences during the three phases of peer feedback. The actionable insights that the learning analytics support offers are discussed with examples. © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {collaborative peer feedback; dialogic feedback; instructor dashboards; learning analytics; Peer feedback},
	correspondence_address = {E. Er; School of Telecommunication Engineering, Universidad de Valladolid, Valladolid, Spain; email: erkanererkaner@gmail.com},
	publisher = {Routledge},
	issn = {02602938},
	language = {English},
	abbrev_source_title = {Assess. Eval. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Green Open Access}
}

@ARTICLE{Jarke2021,
	author = {Jarke, Juliane and Macgilchrist, Felicitas},
	title = {Dashboard stories: How narratives told by predictive analytics reconfigure roles, risk and sociality in education},
	year = {2021},
	journal = {Big Data and Society},
	volume = {8},
	number = {1},
	doi = {10.1177/20539517211025561},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109084359&doi=10.1177%2f20539517211025561&partnerID=40&md5=c718e45ecb5985d058ea6d75c85a5699},
	affiliations = {Institute for Information Management (ifib), Centre for Media, Communication and Information Research (ZeMKI), University of Bremen, Bremen, Germany; George Eckert Institute for International Textbook Research, Braunschweig, Germany; University of Goettingen, Goettingen, Germany},
	abstract = {In this paper, we explore how the development and affordances of predictive analytics may impact how teachers and other educational actors think about and teach students and, more broadly, how society understands education. Our particular focus is on the data dashboards of learning support systems which are based on Machine Learning (ML). While previous research has focused on how these systems produce credible knowledge, we explore here how they also produce compelling, persuasive and convincing narratives. Our main argument is that particular kinds of stories are written by predictive analytics and written into their data dashboards. Based on a case study of a leading predictive analytics system, we explore how data dashboards imply causality between the ‘facts’ they are visualising. To do so, we analyse the stories they tell according to their spatial and temporal dimensions, characters and events, sequentiality as well as tellability. In the stories we identify, teachers are managers, students are at greater or lesser risk, and students’ sociality is reduced to machine-readable interactions. Overall, only data marked as individual behaviours becomes relevant to the system, rendering structural inequalities invisible. Reflecting on the implications of these systems, we suggest ways in which the uptake of these systems can interrupt such stories and reshape them in other directions. © The Author(s) 2021.},
	author_keywords = {artificial intelligence; dashboards; data visualisation; datafication; education; learning analytics; machine learning; Predictive analytics; storytelling},
	correspondence_address = {J. Jarke; Institute for Information Management (ifib), Centre for Media, Communication and Information Research (ZeMKI), University of Bremen, Bremen, Germany; email: jarke@uni-bremen.de},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49; All Open Access, Gold Open Access}
}

@CONFERENCE{Alalawi2021,
	author = {Alalawi, Khalid and Athauda, Rukshan and Chiong, Raymond},
	title = {An Innovative Framework to Improve Course and Student Outcomes},
	year = {2021},
	journal = {CITISIA 2021 - IEEE Conference on Innovative Technologies in Intelligent System and Industrial Application, Proceedings},
	doi = {10.1109/CITISIA53721.2021.9719985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127525300&doi=10.1109%2fCITISIA53721.2021.9719985&partnerID=40&md5=2d7675a582132c961f80a4e9c6fa7467},
	affiliations = {The University of Newcastle, School of Information and Physical Sciences, Callaghan, Australia},
	abstract = {This paper presents a novel framework aimed at improving educational outcomes in tertiary-level courses. The framework integrates concepts from educational data mining, learning analytics and education research domains. The framework considers the entire life cycle of courses and includes processes and supporting technology artefacts. Well-established pedagogy principles such as Constructive Alignment (CA) and effective feedback principles are incorporated to the framework. Mapping of learning outcomes, assessment tasks and teaching/learning activities using CA enables generating revision/study plans and determining the progress and achievement of students, in addition to assisting with course evaluation. Student performance prediction models are used to identify students at risk of failure early on for interventions. Tools are provided for academics to select student groups for intervention and provide personalised feedback. Feedback reports are generated based on effective feedback principles. Learning analytics dashboards provide information on students' progress and course evaluation. An evaluation of the framework based on a case study and quasi-experimental design on real-world courses is outlined. This research and the framework have the potential to significantly contribute to this important field of study. © 2021 IEEE.},
	author_keywords = {constructive alignment; Educational technology framework; effective feedback; learning analytics; machine learning; student performance prediction},
	keywords = {Curricula; Data mining; Education computing; Educational technology; Life cycle; Machine learning; Constructive alignments; Course evaluations; Educational technology framework; Effective feedback; Feedback principle; Learning analytic; Performance prediction; Student outcomes; Student performance; Student performance prediction; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541784-6},
	language = {English},
	abbrev_source_title = {CITISIA - IEEE Conf. Innov. Technol. Intell. Syst. Ind. Appl., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Tlili2021215,
	author = {Tlili, Ahmed and Hattab, Sarra and Essalmi, Fathi and Chen, Nian-Shing and Huang, Ronghuai and Kinshuk and Chang, Maiga and Burgos, Daniel},
	title = {A smart collaborative educational game with learning analytics to support english vocabulary teaching},
	year = {2021},
	journal = {International Journal of Interactive Multimedia and Artificial Intelligence},
	volume = {6},
	number = {6},
	pages = {215 – 224},
	doi = {10.9781/ijimai.2021.03.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108527450&doi=10.9781%2fijimai.2021.03.002&partnerID=40&md5=43dff2895cc4bc65df02ba0ac66c7983},
	affiliations = {Smart Learning Institute of Beijing Normal University, Beijing, China; Higher Institute of Computer Science and Management of Kairouan, Kairouan, Tunisia; Management Information Systems Department, College of Business, University of Jeddah, Jeddah, Saudi Arabia; Department of Applied Foreign Languages, National Yunlin University of Science and Technology, 123 University Road, Section 3, Douliou, Yunlin, 64002, Taiwan; University of North Texas, 3940 N. Elm Street, G 150, Denton, 76207, TX, United States; School of Computing and Information Systems, Athabasca University, Canada; UNIR iTED, Universidad Internacional de La Rioja (UNIR), Logroño, Spain},
	abstract = {Learning Analytics (LA) approaches have proved to be able to enhance learning process and learning performance. However, little is known about applying these approaches for second language acquisition using educational games. Therefore, this study applied LA approaches to design a smart collaborative educational game, to enhance primary school children learning English vocabularies. Specifically, the game provided dashboards to the teachers about their students in a real-time manner. A pilot experiment was conducted in a public primary school where the students’ data from experimental and control groups, namely learning and motivation test scores, interview and observation, were collected and analyzed. The obtained results showed that the experimental group (who used the smart game with LA) had significantly higher motivation and performance for learning English vocabularies than the control group (who used the smart game without LA). The findings of this study can help researchers and practitioners incorporate LA in their educational games to help students enhance language acquisition. © 2021, Universidad Internacional de la Rioja. All rights reserved.},
	author_keywords = {Collaborative Learning; Data Analysis; Educational Games; Language Learning; Learning Analytics},
	correspondence_address = {A. Tlili; Smart Learning Institute of Beijing Normal University, Beijing, China; email: ahmed.tlili23@yahoo.com; D. Burgos; UNIR iTED, Universidad Internacional de La Rioja (UNIR), Logroño, Spain; email: daniel.burgos@unir.net},
	publisher = {Universidad Internacional de la Rioja},
	issn = {19891660},
	language = {English},
	abbrev_source_title = {Int. J. Interact. Multimed. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Munguia2020,
	author = {Munguia, Pablo and Brennan, Amelia and Taylor, Sarah and Lee, David},
	title = {A learning analytics journey: Bridging the gap between technology services and the academic need},
	year = {2020},
	journal = {Internet and Higher Education},
	volume = {46},
	doi = {10.1016/j.iheduc.2020.100744},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084942420&doi=10.1016%2fj.iheduc.2020.100744&partnerID=40&md5=db3f2ec8b88f99c7a5c276b6852fc53d},
	affiliations = {RMIT Studios, RMIT University, Melbourne, 3000, VIC, Australia; Information Technology Services, RMIT University, Melbourne, 3000, VIC, Australia},
	abstract = {Developing data visualisation tools to support academics in the classroom is a challenging process due to the key requirements of usefulness and scalability, and the constraints of a university ecosystem. Here we describe the evolution of an enterprise-level, teacher-facing dashboard, designed to display data about students' enrolments and use of the Learning Management System in a meaningful way, and summarise the challenges and lessons we encountered along the way. This large university has a maturing learning analytics unit, a new, data-friendly LMS system, and data-savvy and data-hungry executive leadership. Yet the experienced pathway and evolutionary steps evidence the points that need be resolved to successfully deliver and transition to learning analytics solutions that have previously been conceptually proposed or tested at small scales in other studies. The key findings through the process highlight the level of uplift (in tech, capacity and capability) that universities need to meet contemporary demands and future possibilities. © 2020},
	author_keywords = {Data pipelines; Data-driven insights; Educational platforms; Learning analytics; University strategy},
	keywords = {Data visualization; Learning systems; Learning management system; Small scale; Technology service; Information management},
	correspondence_address = {P. Munguia; RMIT Studios, RMIT University, Melbourne, 3000, Australia; email: pablo.munguia@rmit.edu.au},
	publisher = {Elsevier Ltd},
	issn = {10967516},
	language = {English},
	abbrev_source_title = {Internet Higher Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Costas-Jauregui2021,
	author = {Costas-Jauregui, Vladimir and Oyelere, Solomon Sunday and Caussin-Torrez, Bernardo and Barros-Gavilanes, Gabriel and Agbo, Friday Joseph and Toivonen, Tapani and Motz, Regina and Tenesaca, Juan Bernardo},
	title = {Descriptive Analytics Dashboard for an Inclusive Learning Environment},
	year = {2021},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	volume = {2021-October},
	doi = {10.1109/FIE49875.2021.9637388},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123837832&doi=10.1109%2fFIE49875.2021.9637388&partnerID=40&md5=6538ed71c21e7e85854343c8c863dd24},
	affiliations = {Centro MEMI Universidad Mayor de San Simon, Cochabamba, Bolivia; Luleå University of Technology, Department of Computer Science, Luleå, Sweden; Ingeniería de Sistemas Universidad Mayor de San Simón, Cochabamba, Bolivia; School of Systems Engineering Universidad Del Azuay, Cuenca, Ecuador; School of Computing University of Eastern Finland, Joensuu, Finland; Universidad de la República, Facultad de Ingenieréa, Montevideo, Uruguay},
	abstract = {The educational community continuously seeks ways to improve the learner-centered learning process through new approaches like Learning analytics and its dashboard, which is helpful to enhance the teaching and the learning process. It involves a process whose final goal is presenting results to support decision-making about improving the learning process. However, a descriptive Learning analytics interface for analyzing learning data of students, including the disadvantaged, where to view and interpret learners' historical data is -in general- missing in this research domain. Hence, more research is still required to establish the philosophy of learning analytics on inclusion with an interface for the stakeholders to understand learning and teaching in an inclusive learning environment. This paper fills this gap by providing an inclusive educational learning analytics dashboard to support teachers and students. This study aimed to present a learning analytics implementation in the context of a smart ecosystem for learning and inclusion. We gave the inclusive educational needs and discussed the workflow followed during the descriptive learning analytics dashboard development. Therefore, the study improved existing learning analytics dashboards with a descriptive approach and inclusiveness of students with disabilities. Owing to the software development nature of this study, agile methodology based on five stages was applied: requirement elicitation; data gathering; design and prototyping; implementation; and testing and integration. We performed an initial evaluation, which indicated that the dashboard is suitable for understanding teachers' and students' needs and expectations. Besides, the visualization of inclusive learning characteristics improves engagement and attainment of learning goals.  © 2021 IEEE.},
	author_keywords = {descriptive learning analytics; inclusion; learning environment},
	keywords = {Computer aided instruction; Decision making; Integration testing; Learning systems; Software design; Software prototyping; Decisions makings; Descriptive learning analytic; Educational community; Historical data; Learner-centred; Learning data; Learning environments; Learning process; New approaches; Teachers'; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {978-166543851-3},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Waldmann2020357,
	author = {Waldmann, Maximilian and Walgenbach, Katharina},
	title = {Digitalisierung der Hochschulbildung},
	year = {2020},
	journal = {Zeitschrift fur Padagogik},
	number = {3},
	pages = {357 – 372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162157180&partnerID=40&md5=47471f57f48d1ba70ab2adb13e499929},
	affiliations = {FernUniversität in Hagen, Fakultät für Kultur- und Sozialwissenschaften, Lehrgebiet Bildung und Differenz, Universitätsstr. 33, Hagen, 58084, Germany},
	abstract = {Leaning on theories of governmentality, the article explores which new formats of self-governing and being-governed are emerging at universities due to the implementation of learning analytics architectures. We carve out how dashboards function as interfaces with regimes of datafication, in which the digital traces left by the learning subjects are processed and presented in real time for the purposes of profiling, forecasting and comparison. We maintain that in the context of digital higher education, new interdependencies develop between practices of external government and self-government. The specific forms of interlocking external control and voluntary, self-normalising, internal control found here differ from the enactments of power in analogue contexts. © 2020 Verlag Julius Beltz GmbH. All rights reserved.},
	author_keywords = {Dashboards; Digitalisation; Governmentality; Higher Education; Learning Analytics},
	publisher = {Verlag Julius Beltz GmbH},
	issn = {00443247},
	language = {German},
	abbrev_source_title = {Z. Padagog.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Sharma202117,
	author = {Sharma, Priya and Akgun, Mahir and Li, Qiyuan},
	title = {Learning Analytics to Support Student Interaction and Learning Design: Initial Report on a Human-Centered Prototype Design},
	year = {2021},
	journal = {Learning Technologies and User Interaction: Diversifying Implementation in Curriculum, Instruction, and Professional Development},
	pages = {17 – 37},
	doi = {10.4324/9781003089704-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142059468&doi=10.4324%2f9781003089704-4&partnerID=40&md5=27d7ed6ba11e582f17e8ffe23415b074},
	affiliations = {University of Georgia, United States; College of Education, Pennsylvania State University, United States; Pennsylvania State University, United States},
	abstract = {This chapter presents a case study of designing a learning analytics dashboard powered by a machine-learning model to support interaction and engagement in online discussions. Learning analytics are becoming mainstream as more learning management systems (LMSs) embed different types of analytic data based on student interactions with the content and each other. However, our chapter focuses on a specific design case where a learning analytics dashboard (LAD) was designed to support learning and learning design in a particular context. The visualizations in the LAD were generated by automated machine-learning analyses of student-generated discussion data, and we describe how technology can be used by instructors within the learning context to finely tune the design of interactive activities in online courses. We identify implications for the design and use of machine-learning models in online learning by instructors and instructional designers © 2022 Taylor & Francis.},
	publisher = {Taylor and Francis},
	isbn = {978-100044124-6; 978-036753633-6},
	language = {English},
	abbrev_source_title = {Learning Technologies and User Interaction: Diversifying Implement. in Curriculum, Instruction, and Professional Development},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dieckmann2021113,
	author = {Dieckmann, Max and Hernández-Leo, Davinia},
	title = {Using epistemic information to improve learning gains in a computer-supported collaborative learning context},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3076},
	pages = {113 – 121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124082361&partnerID=40&md5=7e3019db68a7b69815792a6d53b1a5c0},
	affiliations = {Universitat Pompeu Fabra (UPF), Plaça de la Mercè, 10-12, Barcelona, 08002, Spain},
	abstract = {Computer-supported collaborative learning (CSCL) is a method in education where the students work together on a task while the teacher takes on the role of a coach who - aided by information technology - scaffolds their progress and allows them to discover a solution on their own. CSCL exercises are often run following a script, which breaks the activity in a set number of steps to facilitate productive collaboration. This makes it easier for the teacher to orchestrate the exercise - controlling the flow of the activity and attending to the students' needs as they arise. Teacher-facing dashboards are often used to enable orchestration by providing information about and controls to manipulate the state of the activity. Our research is centered on analyzing whether teachers and students can benefit from visualizing epistemic information, i.e. learning analytics data derived from examining the content of students' input. We expect that giving teachers access to epistemic information will facilitate orchestration, reduce the cognitive load required to oversee a CSCL activity, and create the opportunity for teacher-led debriefing - a technique used by educators to make students reflect on the activity they engaged in and thus help them get a deeper understanding of the content that was covered. We also expect that this will ultimately have a positive impact on students' learning gains. We will extend the dashboard of “PyramidApp” - a software tool that implements the CSCL “Pyramid” script - with epistemic information to test our hypothesis. Subsequently, we will analyze how our findings transfer to other CSCL scripts and tools. We thus hope to contribute to the existing knowledge of how learning analytics data can successfully be employed in a CSCL context. We will follow the design-based research method which emphasizes cooperation with teachers and aims to test and apply interventions in realistic scenarios. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Computer-supported collaborative learning; Design-based research; Epistemic information; Orchestration; Teacher-led debriefing},
	keywords = {Design; E-learning; Learning systems; Scaffolds; Software testing; Cognitive loads; Collaborative learning activities; Computer Supported Collaborative Learning; Design-based research; Epistemic information; Learning context; Learning gain; Orchestration; Teacher-lead debriefing; Teachers'; Students},
	editor = {Fominykh M. and Aristeidou M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jivet2021416,
	author = {Jivet, Ioana and Wong, Jacqueline and Scheffel, Maren and Valle Torre, Manuel and Specht, Marcus and Drachsler, Hendrik},
	title = {Quantum of choice: How learners' feedback monitoring decisions, goals and self-regulated learning skills are related},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {416 – 427},
	doi = {10.1145/3448139.3448179},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103913033&doi=10.1145%2f3448139.3448179&partnerID=40&md5=a23233f005ecfe2144ffbda5b4cdf4ca},
	affiliations = {TU Delft, Netherlands; Open Universiteit, Netherlands; Erasmus University Rotterdam, Netherlands; Ruhr-Universität Bochum, Germany; Goethe University Frankfurt, DIPF, Germany},
	abstract = {Learning analytics dashboards (LADs) are designed as feedback tools for learners, but until recently, learners rarely have had a say in how LADs are designed and what information they receive through LADs. To overcome this shortcoming, we have developed a customisable LAD for Coursera MOOCs on which learners can set goals and choose indicators to monitor. Following a mixed-methods approach, we analyse 401 learners' indicator selection behaviour in order to understand the decisions they make on the LAD and whether learner goals and self-regulated learning skills influence these decisions. We found that learners overwhelmingly chose indicators about completed activities. Goals are not associated with indicator selection behaviour, while help-seeking skills predict learners' choice of monitoring their engagement in discussions and time management skills predict learners' interest in procrastination indicators. The findings have implications for our understanding of learners' use of LADs and their design. © 2021 Owner/Author.},
	author_keywords = {Customisable dashboard; Feedback; Learner goal; Learning dashboard; Self-regulated learning},
	keywords = {Computer programming; Feedback tool; Help seeking; Indicator selections; Mixed method; Self-regulated learning; Time management; Computer applications},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038935-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Bronze Open Access}
}

@CONFERENCE{Farahmand2020345,
	author = {Farahmand, Arta and Dewan, M. Ali Akber and Lin, Fuhua},
	title = {Student-Facing Educational Dashboard Design for Online Learners},
	year = {2020},
	journal = {Proceedings - IEEE 18th International Conference on Dependable, Autonomic and Secure Computing, IEEE 18th International Conference on Pervasive Intelligence and Computing, IEEE 6th International Conference on Cloud and Big Data Computing and IEEE 5th Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2020},
	pages = {345 – 349},
	doi = {10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097654453&doi=10.1109%2fDASC-PICom-CBDCom-CyberSciTech49142.2020.00067&partnerID=40&md5=190b703aeabedaa147b9d207c6382d72},
	affiliations = {Athabasca University, School of Computing and Information Systems, Faculty of Science and Technology, Athabasca, Canada},
	abstract = {The current shift from traditional classrooms to online learning in higher education calls for more attention to self-regulated learning. This research is motivated by the growing interest in potential of using learning analytics dashboard (LAD) to increase individuals' self-regulation by creating visibility into their performance in various applications. This study explores how data visualization can be integrated with online learning to improve learners' performance through enhancing their skills in planning and organization. We are working on the design of a comprehensive LAD, focusing on micro-level of learning analytics to support learning activities of students. The LAD includes the following two features to enhance students' self-regulation in online learning: (1) a function to track students' progress compared to other students' over time; (2) reminders to help students with upcoming deadlines and auto-generating to do lists. The hypothesis is that the LAD will increase students' engagement, motivation, and self-regulation in an online learning environment. This study is significant because it contributes to the body of knowledge by exploring how student-generated data can be used to improve self-regulated learning. The practical contribution of this study is to create a personalized LAD for students based on the learner-generated data to benefit students' organization skill, planning skill, and motivation. © 2020 IEEE.},
	author_keywords = {data mining; information visualization; learning analytics dashboard; learning management system; online learning; self-regulated learning},
	keywords = {Big data; Computer aided instruction; Data visualization; Deregulation; E-learning; Motivation; Body of knowledge; Higher education; Online learning; Online learning environment; Self regulation; Self-regulated learning; Students' engagements; Support learning; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816609-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Dependable, Auton. Secur. Comput., IEEE Int. Conf. Pervasive Intell. Comput., IEEE Int. Conf. Cloud Big Data Comput. IEEE Cyber Sci. Technol. Congr., DASC/PiCom/CBDCom/CyberSciTech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Vázquez-Ingelmo2020169,
	author = {Vázquez-Ingelmo, Andrea and Therón, Roberto},
	title = {Benefits of the software product line paradigm in generating dashboards for educational contexts; [Beneficios de la aplicación del paradigma de líneas de productos software para generar dashboards en contextos educativos]},
	year = {2020},
	journal = {RIED-Revista Iberoamericana de Educacion a Distancia},
	volume = {23},
	number = {2},
	pages = {169 – 185},
	doi = {10.5944/ried.23.2.26389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092025606&doi=10.5944%2fried.23.2.26389&partnerID=40&md5=8cf19b02abbacad33028ffb7507f0354},
	affiliations = {Universidad de Salamanca, USAL, Spain},
	abstract = {Data are crucial to improve decision-making and to obtain greater benefits in any type of activity. However, the large amount of information generated by new technologies has made data analysis and knowledge generation a complex task. Numerous tools have emerged to facilitate this knowledge generation, such as dashboards. Although dashboards are very powerful tools, their effectiveness can be affected by a bad design or by not taking into account the context in which they are placed. Therefore, it is necessary to design and create tailored dashboards according to the audience and data domain. Creating tailored dashboards can be very beneficial, but also a costly process in terms of time and resources. This paper presents an application of the software product line paradigm to generate dashboards adapted to any context in a more straightforward way by reusing both software components and knowledge. One of the contexts that can be especially favored by this approach is the educational context, where Learning Analytics and the analysis of student performance to improve learning methodologies are becoming very popular. Having tailored dashboards for any role (student, teacher, administrator, etc.) can improve decision making processes by showing each user the information that interests them most in the way that best enables them to understand it. © 2020, Ibero-American Association for Distance Higher Education (AIESAD). All rights reserved.},
	author_keywords = {data literacy; educational research; educational technology},
	publisher = {Ibero-American Association for Distance Higher Education (AIESAD)},
	issn = {11382783},
	language = {Spanish},
	abbrev_source_title = {RIED Rev. Iberoam. Educ. Distancia.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2021,
	title = {LALA 2021 - Proceedings of the 4th Latin American Conference on Learning Analytics},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3059},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122650582&partnerID=40&md5=542a81761ace5552d8965046d212e111},
	abstract = {The proceedings contain 10 papers. The topics discussed include: adopting learning analytics in a Brazilian higher education institution: ideal and predicted expectations; proposal for the design and implementation of Miranda: a chatbot-type recommender for supporting self-regulated learning in online environments; applying group formation in practice on a Brazilian postgraduate course; modelling computer engineering student trajectories with process mining; a chatbot to support basic students questions; using relational inference engine to answer questions; learning analytics in computer programming courses; machine learning for learning personalization to enhance student academic performance; and Dicrev-Dash: proposal for the design, creation and evaluation of a dashboard for data visualization.},
	editor = {Klinge Orlando K.O. and Universidad Catolica de Santa Maria, Calle San Jose s/n Umacollo, Arequipa and Maldonado-Mahauad J. and Universidad de Cuenca, Av. 12 de Abril. Solorzano Cuenca},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{West202060,
	author = {West, Deborah and Luzeckyj, Ann and Toohey, Danny and Vanderlelie, Jessica and Searle, Bill},
	title = {Do academics and university administrators really know better? The ethics of positioning student perspectives in learning analytics},
	year = {2020},
	journal = {Australasian Journal of Educational Technology},
	volume = {36},
	number = {2},
	pages = {60 – 70},
	doi = {10.14742/ajet.4653},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081286808&doi=10.14742%2fajet.4653&partnerID=40&md5=55ed7956bbb8bd8c9d2b65f6789ac977},
	affiliations = {Flinders University, Australia; Centre for Innovation in Learning and Teaching, Flinders University, Australia; School of Engineering and Information Technology, Murdoch University, United Arab Emirates; Student Success, La Trobe University, Australia; Charles Darwin University, Australia},
	abstract = {Increasingly learning analytics (LA) has begun utilising staff- and student-facing dashboards capturing visualisations to present data to support student success and improve learning and teaching. The use of LA is complex, multifaceted and raises many issues for consideration, including ethical and legal challenges, competing stakeholder views and implementation decisions. It is widely acknowledged that LA development requires input from various stakeholders. This conceptual article explores the LA literature to determine how student perspectives are positioned as dashboards and visualisations are developed. While the sector acknowledges the central role of students, as demonstrated here, much of the literature reflects an academic, teacher-centric or institutional view. This view reflects some of the key ethical concerns related to informed consent and the role of power translating to a somewhat paternalistic approach to students. We suggest that as students are the primary stakeholders - they should be consulted in the development and application of LA. An ethical approach to LA requires that we engage with our students in their learning and the systems and information that support that process rather than assuming we know we know what students want, what their concerns are or how they would like data presented. Implications for practice or policy: • Universities should actively engage with students to understand their concerns related to learning analytics. • Universities should ensure that learning analytics dashboards are deployed in line with student requirements from their perspective. • Institutions need to provide students and staff with training in the use of learning analytics. • Universities should ensure that data is collected transparently and with students’ knowledge and, where appropriate, informed consent. © 2020. All Rights Reserved.},
	author_keywords = {data privacy; ethics; learning analytics; student concerns; student perspectives},
	correspondence_address = {D. West; Flinders University, Australia; email: deborah.west@flinders.edu.au},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	issn = {14495554},
	language = {English},
	abbrev_source_title = {Australas. J. Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access}
}

@CONFERENCE{Centenaro202160,
	author = {Centenaro, Belisa and Cechinel, Cristian and Ramos, Vinicius and Primo, Tiago and Munoz, Roberto},
	title = {Systematic Mapping of Moodle Dashboards Focused on Learning Analytics Tasks},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	pages = {60 – 66},
	doi = {10.1109/LACLO54177.2021.00013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127189573&doi=10.1109%2fLACLO54177.2021.00013&partnerID=40&md5=c79b47abb22c3ff30b48a916abb51d71},
	affiliations = {Universidade Federal De Santa Catarina, Araranguá, Brazil; Universidade Federal De Pelotas, Pelotas, Brazil; Universidad De Valparaíso, Escuela De Ingenieriá Informática, Chile},
	abstract = {Learning Analytics Dashboards are useful tools for presenting data visually. This work presents a systematic mapping study of publications from 2010 to 2020 (May) about Learning Analytics and visualization tools for Moodle. A total of 238 papers were collected from Scopus, Web of Science, and CAPES Portal. From those, 51 were selected to be analyzed according to a seven dimension model involving the following criteria: data sources; goals of analysis; stakeholders; research approach; maturity of the tool; ethical issues; and specificities of the tool. The analysis showed that most of the tools are developed to be used by the teachers, and that the most frequent goal of the tools is to allow the comparison of students' metrics. Moreover, the analysis also showed a huge amount of papers proposing (still not developed) tools focused on prediction and intervention, thus indicating a growing interest in this topic. At last, it was also observed a lack of information available regarding ethical issues over the collection, processing and storage of personal information by the existing LAD.  © 2021 IEEE.},
	author_keywords = {Data Visualization; Educational technology; Learning Analytics Dashboards; Moodle plugin; Systematic Mapping},
	keywords = {Digital storage; Educational technology; Ethical technology; Mapping; Visualization; Analytic tools; Data-source; Ethical issues; Learning analytic dashboard; Moodle plugin; Plug-ins; Systematic mapping; Systematic mapping studies; Visualization tools; Web of Science; Data visualization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {English},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Beheshti2020,
	author = {Beheshti, Elham and Lyons, Leilah and Mallavarapu, Aditi and Wallingford, Betty and Uzzo, Stephen},
	title = {Design considerations for data-driven dashboards: Supporting facilitation tasks for open-ended learning},
	year = {2020},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3334480.3382871},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090229624&doi=10.1145%2f3334480.3382871&partnerID=40&md5=db7c39b2c84dc23e0eb66ea7240ce4cc},
	affiliations = {New York Hall of Science, Corona, NY, United States; University of Illinois at Chicago, Chicago, IL, United States},
	abstract = {Data-driven dashboards have been increasingly integrated into various contexts, particularly in educational settings. There is a growing need to understand how to design learning dashboards to help educators support learning experiences by providing real-time formative feedback. We are studying the design of a learning dashboard that can support educational facilitation tasks in a museum setting. In our approach, we use discrete facilitation tasks as the cornerstone of our design process. Using this task-based approach, we conducted pilot studies and participatory design sessions to better understand the context of design. In this paper, we offer preliminary findings and design considerations for supporting and digitally augmenting facilitation tasks in a highly interactive, open-ended learning environment. © 2020 Owner/Author.},
	author_keywords = {Data-driven dashboards; Design; Learning analytics dashboards; Method; Participatory design; Socio-technical systems},
	keywords = {Computer aided instruction; Human engineering; Open Data; Design considerations; Design learning; Educational settings; Formative feedbacks; Learning environments; Participatory design; Support learning; Task based approach; Design},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036819-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Aguilar2021,
	author = {Aguilar, Stephen J. and Karabenick, Stuart A. and Teasley, Stephanie D. and Baek, Clare},
	title = {Associations between learning analytics dashboard exposure and motivation and self-regulated learning},
	year = {2021},
	journal = {Computers and Education},
	volume = {162},
	doi = {10.1016/j.compedu.2020.104085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097351612&doi=10.1016%2fj.compedu.2020.104085&partnerID=40&md5=14a323aa979f6d5f1fd550a364cc5d77},
	affiliations = {University of Southern California Rossier School of Education, United States; University of Michigan, United States; University of Michigan School of Information, United States},
	abstract = {Learning analytics dashboards (LADs) are intended to give relevant information to students and other stakeholders to inform potential next steps in the learning process. The current study examines the relationship between information indirectly presented through academic advisors' use of LADs, and college students' academic motivation, self-regulated learning, and academic achievement. We modeled how changes in student motivation and self-regulated learning (SRL) were related to what occurred during 1-on-1 meetings with academic advisors during which students had the potential to view representations of their achievement embedded within an Early Warning System (EWS) that visually represented aspects of their academic performance referenced with course averages. Constructs associated with SRL were moderated by advisor-advisee meetings. Results indicated that advisors' use of EWS while they met with students was negatively associated with the rate of decrease of students' reporting of using memorizing strategies but positively related when students' performance was compared to that of their peers. We discuss the moderating effects of students’ exposure to visualizations of academic performance on their SRL strategies and academic motivation. This study points to the importance of monitoring the effects of information presented via EWS on motivation and SRL. © 2020},
	author_keywords = {Dashboards; Higher education; Learning analytics; Motivation; Self-regulated learning},
	keywords = {Learning systems; Motivation; Academic achievements; Academic motivations; Academic performance; College students; Early warning systems; Moderating effect; Self-regulated learning; Student motivation; Students},
	correspondence_address = {S.J. Aguilar; University of Southern California Rossier School of Education, United States; email: aguilars@usc.edu},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 77}
}

@ARTICLE{Zheng2021,
	author = {Zheng, Juan and Huang, Lingyun and Li, Shan and Lajoie, Susanne P. and Chen, Yuxin and Hmelo-Silver, Cindy E.},
	title = {Self-regulation and emotion matter: A case study of instructor interactions with a learning analytics dashboard},
	year = {2021},
	journal = {Computers and Education},
	volume = {161},
	doi = {10.1016/j.compedu.2020.104061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094907180&doi=10.1016%2fj.compedu.2020.104061&partnerID=40&md5=baa049777b989f5b310b6e6cc8bec4de},
	affiliations = {Department of Educational Counselling & Psychology, McGill University, Montreal, QC, Canada; Department of Counseling and Educational Psychology, Learning Science Program, School of Education, Indiana University, Bloomington, 47406, IA, United States},
	abstract = {Learning analytics (LA) is providing new methodologies that are being applied to the design and application of dashboards to support teaching and learning. However, few studies attempt to understand how instructors interact with an LA dashboard and how self-regulated learning (SRL) activities and emotions of instructors occur and co-occur in the interaction. The current study investigates ten instructors’ SRL activities and epistemic emotions by analyzing the screen capture videos and think-aloud data while they interact with an LA dashboard designed to support the online asynchronous collaboration of multiple groups. The results reveal that instructors demonstrated two ways of navigating LA dashboards, and they relied heavily on the conversation explorer feature. Instructors were mostly engaged in elaboration, monitoring, and evaluation activities and they frequently experienced confusion and enjoyment. Expert instructors were more likely to refer to their personal teaching experience and demonstrated more epistemic emotions than novice instructors. This study contributes to the literature on SRL and teacher emotions by revealing the critical role of elaboration, monitoring, evaluation, and epistemic emotions when instructors attempt to understand a LA dashboard by themselves. These findings highlight the importance of providing pedagogical assistance to teachers who are trying to navigate between group dynamics and visualizations viewed using LA dashboards. © 2020 Elsevier Ltd},
	author_keywords = {Asynchronous online collaborative learning; Emotions; Learning analytics dashboard; Self-regulated learning},
	keywords = {Computer science; Asynchronous collaboration; Design and application; Evaluation activity; Screen capture; Self regulation; Self-regulated learning; Teaching and learning; Teaching experience; Education},
	correspondence_address = {J. Zheng; Department of Educational Counselling & Psychology, McGill University, Montreal, Canada; email: juan.zheng@mail.mcgill.ca},
	publisher = {Elsevier Ltd},
	issn = {03601315},
	coden = {COMED},
	language = {English},
	abbrev_source_title = {Comput Educ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45}
}

@CONFERENCE{Haynes2020297,
	author = {Haynes, Carl C.},
	title = {The Role of Self-Regulated Learning in the Design, Implementation, and Evaluation of Learning Analytics Dashboards},
	year = {2020},
	journal = {L@S 2020 - Proceedings of the 7th ACM Conference on Learning @ Scale},
	pages = {297 – 300},
	doi = {10.1145/3386527.3406732},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094893745&doi=10.1145%2f3386527.3406732&partnerID=40&md5=3f1f66a21f69b3440e57edd8616e7340},
	affiliations = {University of Michigan-Ann Arbor, Ann Arbor, United States},
	abstract = {Learning technologies are generating a vast quantity of data every day. This data is often presented to students through learning analytics dashboards (LADs) with a goal of improving learners' self-regulated learning. However, are students actually using these dashboards, and do they perceive that using dashboards lead to any changes in their behavior? In this paper we report on the development and implementation of several dashboard views, which we call My Learning Analytics (MyLA). This study found that students thought using the dashboard would have more of an effect on the way they planned their course activity at pre-use (after a demo) than post use. Low self-regulated learners believed so significantly less post-use and used the grade distribution view the least. Students made several suggestions for ways to improve the grade distribution view and rated MyLA's usability more positively at pre-than post-use. Given the low use and low perceived impact of the current dashboard, we suggest that researchers use participatory design to illicit students' needs and better incorporate student suggestions. © 2020 ACM.},
	author_keywords = {dashboards; learning analytics; self-regulated learning},
	keywords = {Learning technology; Participatory design; Self-regulated learning; Students},
	correspondence_address = {C.C. Haynes; University of Michigan-Ann Arbor, Ann Arbor, United States; email: cchaynes@umich.edu},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037951-9},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Hilliger2021592,
	author = {Hilliger, Isabel and Miranda, Constanza and Schuit, Gregory and Duarte, Fernando and Anselmo, Martin and Parra, Denis},
	title = {Evaluating a learning analytics dashboard to visualize student self-reports of time-on-task: A Case Study in a Latin American University},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {592 – 598},
	doi = {10.1145/3448139.3448203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103884959&doi=10.1145%2f3448139.3448203&partnerID=40&md5=1f4507f9da3c3f1cd7df72b8f9880d58},
	affiliations = {Pontificia Universidad Católica de Chile, Chile; Johns Hopkins University, United States},
	abstract = {In recent years, instructional design has become even more challenging for teaching staff members in higher education institutions. If instructional design causes student overload, it could lead to superficial learning and decreased student well-being. A strategy to avoid overload is reflecting upon the effectiveness of teaching practices in terms of time-on-task. This article presents a Work-In-Progress conducted to provide teachers with a dashboard to visualize student self-reports of time-on-task regarding subject activities. A questionnaire was applied to 15 instructors during a set trial period to evaluate the perceived usability and usefulness of the dashboard. Preliminary findings reveal that the dashboard helped instructors became aware about the number of hours spent outside of class time. Furthermore, data visualizations of time-on-task evidence enabled them to redesign subject activities. Currently, the dashboard has been adopted by 106 engineering instructors. Future work involves the development of a framework to incorporate user-based improvements. © 2021 ACM.},
	author_keywords = {Higher education; Instructional design; Learning analytics dashboards; Time-on-task},
	keywords = {Computer applications; Computer programming; Engineering instructors; Higher education institutions; Instructional designs; Latin americans; Perceived usability; Teaching practices; Teaching staff; Work in progress; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038935-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Revano2021,
	author = {Revano, Teodoro F. and Garcia, Manuel B.},
	title = {Designing Human-Centered Learning Analytics Dashboard for Higher Education Using a Participatory Design Approach},
	year = {2021},
	journal = {2021 IEEE 13th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2021},
	doi = {10.1109/HNICEM54116.2021.9731917},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126632773&doi=10.1109%2fHNICEM54116.2021.9731917&partnerID=40&md5=d4d8b4a35008736c5dafe42ee22c36ab},
	affiliations = {FEU Institute of Technology, College of Computer Studies, Manila, Philippines},
	abstract = {Higher education institutions (HEIs) are looking for new methods to assess and monitor student learning outcomes, as well as objectively determine the circumstances that contribute to their growth in different courses. Advances in new analytics tools that put visualizations and dashboards on top of live student data are making learning analytics more powerful than ever. This study utilized a participatory design (PD) technique to formulate an analytics dashboard intended for higher education. The rationale behind the study lies on the belief that an information system must be designed for users, rather than users having to accommodate a wide range of adjustments just to utilize such application. Students and teachers were recruited for their feedback and observations, respectively. After multiple PD sessions, four main crucial factors were derived: (1) who has access to data, (2) importance of time, (3) learning analytics should help students make the transition to university life, and (4) it should be discipline-specific. This study opens up a discussion on the importance of human-centered design through the use of PD and how learning analytics dashboard can be maximized to its potential when deployed in the academe.  © 2021 IEEE.},
	author_keywords = {Academic Analytics; Higher Education; Human-Centered Design; Learning Analytics Dashboard; Participatory Design},
	keywords = {Learning systems; Academic analytic; Analytic tools; Design approaches; Design technique; High educations; Higher education institutions; Human-centred designs; Learning analytic dashboard; Participatory design; Student learning outcomes; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540167-8},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Humanoid, Nanotechnol., Inf. Technol., Commun. Control, Environ., Manag., HNICEM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@CONFERENCE{Weng2020327,
	author = {Weng, Jian-Xuan and Huang, Anna Y.Q. and Lu, Owen H.T. and Chen, Irene Y.L. and Yang, Stephen J.H.},
	title = {The implementation of precision education for learning analytics},
	year = {2020},
	journal = {Proceedings of 2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2020},
	pages = {327 – 332},
	doi = {10.1109/TALE48869.2020.9368432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102977931&doi=10.1109%2fTALE48869.2020.9368432&partnerID=40&md5=32fb0df6555d06071565ebbf62f80afd},
	affiliations = {National Central University, Computer Science Information Engineering, Taoyuan City, Taiwan; National Pingtung University, College of Computer Science, Pingtung City, Taiwan; National Changhua University of Education, Department of Accounting, Changhua City, Taiwan},
	abstract = {This study is based on a novel conceptual framework, precision education, and takes a blended Python programming course as an example to explore how to implement precision education that includes diagnosis, prediction, prevention and treatment. Precision education follows the principles of personalized services for precision medicine. Its purpose is to strengthen the learning risk prediction and early intervention mentioned in emerging learning analytics through big data, artificial intelligence and other emerging technologies, thereby improving teacher teaching quality and student learning efficiency. This study is based on the design of the e-book learning dashboard, so that teachers can quickly understand students' learning status, and improve the e-book through students' feedback on the dashboard to achieve precision diagnosis. Next, this study uses machine learning algorithms to predict students' learning performance, and thus determine whether students are at-risk to achieve precision prediction. Finally, through the correspondence between reading strategy and reading sequence, and then clearly distinguish the types of students by grouping, and use it as a treatment target for precision treatment and prevention. It is hoped that this empirical study can be used as a case study for implementing precision education. © 2020 IEEE.},
	author_keywords = {Diagnosis; Learning analytics; Precision education; Prediction; Prevention; SQ3R; Treatment},
	keywords = {Diagnosis; Electronic publishing; Forecasting; Machine learning; Program diagnostics; Students; Conceptual frameworks; Early intervention; Emerging technologies; Learning performance; Personalized service; Precision prediction; Python programming; Reading strategies; Learning algorithms},
	correspondence_address = {A.Y.Q. Huang; National Central University, Computer Science Information Engineering, Taoyuan City, Taiwan; email: anna.yuqing@gmail.com},
	editor = {Mitsuhara H. and Goda Y. and Ohashi Y. and Rodrigo Ma.M.T. and Shen J. and Venkatarayalu N. and Wong G. and Yamada M. and Chi-Un Lei L.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816942-2},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Conf. Teach., Assess., Learn. Eng., TALE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{De Laet20201002,
	author = {De Laet, Tinne and Millecamp, Martijn and Ortiz-Rojas, Margarita and Jimenez, Alberto and Maya, Ricardo and Verbert, Katrien},
	title = {Adoption and impact of a learning analytics dashboard supporting the advisor—Student dialogue in a higher education institute in Latin America},
	year = {2020},
	journal = {British Journal of Educational Technology},
	volume = {51},
	number = {4},
	pages = {1002 – 1018},
	doi = {10.1111/bjet.12962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085922483&doi=10.1111%2fbjet.12962&partnerID=40&md5=93698c444346155e00846680f73b7f4a},
	affiliations = {Faculty of Engineering Science, KU Leuven, Belgium; KU Leuven, Belgium; Margarita Ortiz-Rojas is a researcher with ESPOL and PhD student at UGent, Belgium; Escuela Superior Politécnica del Litoral, ESPOL, Ecuador; ESPOL, Ecuador; HCI research group, KU Leuven, Belgium},
	abstract = {This paper presents a case study on the adoption and the impact of new modules in a learning analytics dashboard supporting the dialogue between student advisors and students when advising on a study plan for the next academic semester in Escuela Superior Politecnica del Litoral, a higher education institute in Ecuador. The impact and the adoption of the new dashboard modules were assessed using a mixed-methods approach. The quantitative approach builds on data of 172 advisors in 34 programs and 4481 advising sessions in 2019 (post) and 4747 advising sessions in 2018 (pre) to assess the adoption and use of the dashboard, the level of support experienced by the advisors, the impact of the new dashboard modules on the difference between the advised study plan and the plan students register for, and students’ academic achievement. The qualitative approach with observations of 14 staged advising dialogues and semi-structured interviews with eight advisors was used to assess how the dashboard was used and to get deeper understanding of the perceived usefulness and impact of the dashboard. The results show that an institution-wide deployment of dashboard modules tailored to the needs of the advisors can be achieved and can increase the level of support perceived by the advisors and significantly decrease the gap between the suggested study plans in advising dialogues and the study plans that students actually register for. On the short-term, however, no significant changes in academic achievement were observed. Practitioner Notes What is already known about this topic? Academic advising can positively impact retention, academic achievement and study completion. Learning analytics dashboards are promising pieces of educational technology for academic advising as they can trigger reflection and sense-making of educational data. Evaluation of learning analytics dashboards is often still immature and not well-connected to the actual goals of the dashboards. Large-scale evaluations looking at impact of dashboards are even scarcer. What this paper adds? This paper adds, to the scarce scientific evidence on academic advising dashboards, a large-scale case study on a dashboard supporting the advisor student dialogue during the composition of well-balanced study plans. The paper presents research evidence of the impact of the dashboard on the support advisors experience, the study plans suggested by the advisors and the ones actually registered by the students and students’ academic achievement. Evidence is based on a quantitative analysis, using data of 172 advisors from 34 programs representing more than 9000 advising dialogues, and a qualitative analysis using observations and interviews. Implications for practice and/or policy Dashboards to support academic advising dialogues can be realized institution-wide at scale. Training of student advisors supports a large scale deployment. Well-designed dashboards that focus on addressing needs of advisors increase the level of support that advisor experience when advising students. Dashboard accommodating the simulation of study plans and the workload associated with them, succeed in decreasing the variance in suggested plans between advisors and reduce the gap between the study plans that advisors suggest to student and the study plans that students actually register for. Short-term impact on academic achievement was not observed. © 2020 British Educational Research Association},
	keywords = {Petroleum reservoir evaluation; Academic achievements; Large-scale deployment; Perceived usefulness; Qualitative analysis; Qualitative approach; Quantitative approach; Scientific evidence; Semi structured interviews; Students},
	correspondence_address = {T. De Laet; Faculty of Engineering Science, KU Leuven, Belgium; email: Tinne.DeLaet@kuleuven.be},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; All Open Access, Green Open Access}
}

@ARTICLE{Moissa2021363,
	author = {Moissa, Barbara and Bonnin, Geoffray and Boyer, Anne},
	title = {Measuring and Predicting Students’ Effort: A Study on the Feasibility of Cognitive Load Measures to Real-Life Scenarios},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12884 LNCS},
	pages = {363 – 367},
	doi = {10.1007/978-3-030-86436-1_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115446432&doi=10.1007%2f978-3-030-86436-1_36&partnerID=40&md5=78748d870f35dabeb5dcb5065ec60501},
	affiliations = {Loria, Nancy, France},
	abstract = {Students’ effort is often considered to be a key element in the learning process. As such, it can be a relevant element to integrate in learning analytics tools, such as dashboards, intelligent tutoring systems, adaptive hypermedia systems, and recommendation systems. A prerequisite to do so is to measure and predict it from learning data, which poses some challenges. We propose to rely on the cognitive load theory to infer the students’ perceived effort using subjective, performance, behavioral and physiological data collected from 120 seventh grade students. We also estimate students’ effort in future tasks using the data from previous tasks. Our results show a high relevance of interaction data to measure students’ effort, especially when compared to physiological data. Moreover, we also found that using the data collected on previous tasks allows us to achieve slightly higher accuracy values than the data collected during the task execution. Finally, this approach also allowed us to predict students’ perceived effort in future tasks, which, to the best of our knowledge, is one of the first attempts towards this goal. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Cognitive load; Learning analytics; Multimodal data; Students’ effort; Students’ engagement},
	keywords = {Computer aided instruction; Forecasting; Hypermedia systems; Intelligent vehicle highway systems; Learning systems; Adaptive hypermedia systems; Analytic tools; Cognitive loads; Key elements; Learning analytic; Learning process; Multi-modal data; Physiological data; Student effort; Student engagement; Students},
	correspondence_address = {B. Moissa; Loria, Nancy, France; email: barbara.moissa@loria.fr},
	editor = {De Laet T. and Klemke R. and Alario-Hoyos C. and Hilliger I. and Ortega-Arranz A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303086435-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Alshabandar2020,
	author = {Alshabandar, Raghad and Hussain, Abir and Keight, Robert and Khan, Wasiq},
	title = {Students Performance Prediction in Online Courses Using Machine Learning Algorithms},
	year = {2020},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN48605.2020.9207196},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093827862&doi=10.1109%2fIJCNN48605.2020.9207196&partnerID=40&md5=4cd541243dd57c449ee47da818663233},
	affiliations = {Liverpool John Moores University, Department of Computer Science, Liverpool, United Kingdom},
	abstract = {Advances in Information and Communications Technology (ICT) have increased the growth of Massive open online courses (MOOCs) applied in distance learning environments. Various tools have been utilized to deliver interactive content including pictures, figures, and videos that can motivate the learners to build new cognitive skills. High ranking universities have adopted MOOCs as an efficient dashboard platform where learners from around the world can participate in such courses. The students learning progress is evaluated by using set computer-marked assessments. In particular, the computer gives immediate feedback to the student once he or she completes the online assessmentsThe researchers claim that student success rate in an online course can be related to their performance at the previous session in addition to the level of engagement. Insufficient attention has been paid by literature to evaluate whether student performance and engagement in the prior assessments could affect student achievement in the next assessmentsIn this paper, two predictive models have been designed namely students' assessments grades and final students' performance. The models can be used to detect the factors that influence students' learning achievement in MOOCs. The result shows that both models gain feasible and accurate results. The lowest RSME gain by RF acquire a value of 8.131 for students assessments grades model while GBM yields the highest accuracy in final students' performance, an average value of 0.086 was achieved. © 2020 IEEE.},
	author_keywords = {Massive Open Online Courses (MOOCs); Open University Learning Analytics Dataset (OULAD ); Receiver Operating Characteristic(ROC)},
	keywords = {Computer aided instruction; E-learning; Learning algorithms; Machine learning; Neural networks; Predictive analytics; Students; Distance learning environment; Immediate feedbacks; Information and communications technology; Interactive contents; Learning achievement; Massive open online course; Performance prediction; Student achievement; Electronic assessment},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816926-2},
	coden = {85OFA},
	language = {English},
	abbrev_source_title = {Proc Int Jt Conf Neural Networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49; All Open Access, Green Open Access}
}

@CONFERENCE{Singh2020384,
	author = {Singh, Shaveen and Meyer, Bernd and Wybrow, Michael},
	title = {UserFlow: A Tool for Visualizing Fine-grained Contextual Analytics in Teaching Documents},
	year = {2020},
	journal = {Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
	pages = {384 – 390},
	doi = {10.1145/3341525.3387410},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086469745&doi=10.1145%2f3341525.3387410&partnerID=40&md5=e1d06c7a042f8d51e2deaf4b42d123c5},
	affiliations = {Monash University, Faculty of Information Technology, Melbourne, VIC, Australia},
	abstract = {The adoption of innovative online teaching tools in Computer Science (CS) courses provides opportunities for data-informed instruction as a regular teaching practice in CS classrooms. In this paper, we present a design study for an interactive visual analytics dashboard, called UserFlow, that supports feedback collection from teaching documents and assists instructors in interpreting feedback and acting on it in a timely manner. The design study is conducted with eight domain experts comprising of four teaching instructors, two learning analytics (LA) experts and two instructional designers. UserFlow offers a set of novel visualization designs for presenting the four interleaving aspects of document engagement (i.e., annotations, document traversal path, reading/focus time and student information). We evaluated UserFlow in an undergraduate computer science course with over 700 students. Our results demonstrate the usefulness and need for such a tool for CS educators to inform teaching approaches and courseware improvement. © 2020 ACM.},
	author_keywords = {analytics; annotations; dashboards; digital education; engagement},
	keywords = {Education computing; Engineering education; Engineering research; Students; Teaching; Visualization; Domain experts; Instructional designer; Novel visualizations; Online teaching; Teaching approaches; Teaching practices; Undergraduate computer science course; Visual analytics; E-learning},
	publisher = {Association for Computing Machinery},
	issn = {1942647X},
	isbn = {978-145036874-2},
	language = {English},
	abbrev_source_title = {Annu. Conf. Innov. Technol. Comput. Sci. Educ. ITiCSE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Tenório2021406,
	author = {Tenório, Kamilla and Lemos, Bruno and Nascimento, Pedro and Santos, Rodrigo and Machado, Alexandre and Dermeval, Diego and Paiva, Ranilson and Isotani, Seiji},
	title = {Learning and Gamification Dashboards: A Mixed-Method Study with Teachers},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12677 LNCS},
	pages = {406 – 417},
	doi = {10.1007/978-3-030-80421-3_45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112280903&doi=10.1007%2f978-3-030-80421-3_45&partnerID=40&md5=9a961ec6f6fa589272a9ca3118d013c0},
	affiliations = {Computing Institute, Federal University of Alagoas, Maceió, 57072-900, AL, Brazil; School of Medicine, Federal University of Alagoas, Maceió, 57072-900, AL, Brazil; Institute of Mathematics and Computational Sciences, University of São Paulo, São Carlos, Brazil},
	abstract = {Previous studies have investigated the provision of students’ relevant data, usually available in intuitive dashboards, to assist teachers in pedagogical decision-making in learning systems. Researchers are also interested in investigating how students’ interaction data with gamification elements improve teachers’ understanding of students’ status and helps students with adequate pedagogical recommendations. However, there is a lack of understanding of how teachers perceive data visualizations provided through dashboards recently explored in gamified educational systems. In this paper, the authors investigate teachers’ perceptions about three different dashboards with visualizations about 1) students’ interaction with learning resources, 2) students’ interaction with gamification elements, and 3) students’ interaction with learning resources and gamification elements. As such, the researchers conducted a mixed-method study with 47 teachers to evaluate their perceived understanding, perceived usefulness, perceived behavioral change, and perceived decision-making support regarding the three dashboards. The results suggest teachers perceived that the dashboard with visualizations concerning students’ interaction with learning resources and gamification elements provide better support to them in the decision-making process. Teachers also perceived the third dashboard has a more significant potential to impact behavioral changes than the other two dashboards. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Adaptive learning systems; Data visualization; Gamification analytics; Learning analytics; Pedagogical decision-making; Teachers},
	keywords = {Data visualization; Learning systems; Students; Visualization; Adaptive learning systems; Decisions makings; Gamification; Gamification analytic; Learning analytic; Learning resource; Mixed method; Pedagogical decision-making; Student interactions; Teachers'; Decision making},
	correspondence_address = {K. Tenório; Computing Institute, Federal University of Alagoas, Maceió, 57072-900, Brazil; email: kktas@ic.ufal.br},
	editor = {Cristea A.I. and Troussas C.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303080420-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Xin2021838,
	author = {Xin, Ong Kiat and Singh, Dalbir},
	title = {Development of Learning Analytics Dashboard based on Moodle Learning Management System},
	year = {2021},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {12},
	number = {7},
	pages = {838 – 843},
	doi = {10.14569/IJACSA.2021.0120793},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112177608&doi=10.14569%2fIJACSA.2021.0120793&partnerID=40&md5=955652c83d27ed95cb43196d839954fa},
	affiliations = {Center for Software Technology and Management (SOFTAM), Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia Acronyms Acceptable, Bangi, Malaysia},
	abstract = {Digitalization catalyzes drastic changes to a particular subject or area. Digitalization is an operational structure transformation process, such as in the educational domain. Digitalization in the academic field has brought the classroom to the users’ fingertips with the prevalence of e-learning applications, learning management systems, etc. However, with the increasing number of digital learning platform users, educators find it hard to monitor their students’ progress. Analytics that analyze data generated from the usage pattern of the users contribute to giving the educators an insight regarding the performance of their students. With that, they can apply early intervention and modification of their delivery method to suit the students’ needs and, at the same time, increase the quality of the content. This study illustrates the development of a learning analytics dashboard that can improve learning outcomes for educators and students. © 2021. All Rights Reserved.},
	author_keywords = {Learning analytics; learning management system; moodle},
	keywords = {E-learning; Learning systems; Academic fields; Catalyse; Digital-learning; e-Learning application; Learning analytic; Learning management system; Moodle; Operational structure; Structure transformations; Transformation process; Students},
	publisher = {Science and Information Organization},
	issn = {2158107X},
	language = {English},
	abbrev_source_title = {Intl. J. Adv.  Comput. Sci. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access}
}

@ARTICLE{Kokoç2021161,
	author = {Kokoç, Mehmet and Altun, Arif},
	title = {Effects of learner interaction with learning dashboards on academic performance in an e-learning environment},
	year = {2021},
	journal = {Behaviour and Information Technology},
	volume = {40},
	number = {2},
	pages = {161 – 175},
	doi = {10.1080/0144929X.2019.1680731},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074915342&doi=10.1080%2f0144929X.2019.1680731&partnerID=40&md5=bf29a0c7e6c444fb7cdd00eed9ef59a7},
	affiliations = {Department of Computer Education and Instructional Technology, Fatih Faculty of Education, Trabzon University, Trabzon, Turkey; Department of Computer Education and Instructional Technology, College of Education, Hacettepe University, Ankara, Turkey},
	abstract = {This study aims to investigate learners’ interaction with the learning dashboards as a predictor outcome of an online learning experience and, to what extent this interaction data could be used to predict and/or provide guidance through their academic performance. For this purpose, a prescriptive learning dashboard integrated into an e-learning environment was developed as a learning analytics tool. The participants consisted of 126 higher education students enrolled in the 12-week Computer Networks and Communication course. Data gathered through logs and academic performances of learners were analysed with data mining techniques. The result of cluster analysis, based on interaction with the prescriptive learning dashboard, showed that learners were separated into four groups according to their behavioural patterns. A similar pattern appears when the related clusters are profiled based on the academic performances. At predictive analysis, the study indicates that the interaction with prescriptive learning dashboard had certain effects on academic performance of learners significantly and artificial neural networks algorithm yielded the best performance for predicting academic performance. The results support that the usage prescriptive learning dashboards can be applied in online courses as an instructional aid to improve performance of learners and learning design in e-learning environments. © 2019 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {data visualisation; educational data mining; Learning analytics; learning dashboards; online interaction behaviour},
	keywords = {Cluster analysis; Computer aided instruction; Curricula; Data mining; Data visualization; Predictive analytics; Communication course; E-learning environment; Educational data mining; Higher education students; Learning analytics; learning dashboards; On-line interactions; Predicting academic performance; adult; algorithm; article; artificial neural network; cluster analysis; data mining; data visualization; education; female; human; human experiment; learning environment; major clinical study; male; E-learning},
	correspondence_address = {M. Kokoç; Department of Computer Education and Instructional Technology, Fatih Faculty of Education, Trabzon University, Trabzon, F-306, Akçaabat, 61300, Turkey; email: kokoc@trabzon.edu.tr},
	publisher = {Taylor and Francis Ltd.},
	issn = {0144929X},
	coden = {BEITD},
	language = {English},
	abbrev_source_title = {Behav Inf Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 58}
}

@ARTICLE{Zotov202146,
	author = {Zotov, Vladimir and Ibrahim, Iman and Petunina, Irina and Lazareva, Yuliya},
	title = {Engagement of Students in Data Visualization for the Purpose of E-Learning Improvement},
	year = {2021},
	journal = {International Journal of Emerging Technologies in Learning},
	volume = {16},
	number = {2},
	pages = {46 – 63},
	doi = {10.3991/ijet.v16i02.18745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101106306&doi=10.3991%2fijet.v16i02.18745&partnerID=40&md5=c07ba0c045893b3b2c71634a166104b8},
	affiliations = {State University of Management, Moscow, Russian Federation; University of Sharjah, Sharjah, United Arab Emirates; “Kuban State Agrarian University named after I.T. Trubilin”, Krasnodar, Russian Federation; I.M. Sechenov First Moscow State Medical University (Sechenov University), Moscow, Russian Federation},
	abstract = {The study describes an approach to e-learning based on the Moodle platform that is used to visualize participation in the learning community and is proposed to be used to inform students and teachers about their involvement in the social learning environment. The experiment involved 5 teachers and 3 experts who determined the most significant visualization indicators for the virtual learning environment dashboards. There were 42 students aged 21 to 23. The virtual learning environment is based on the Moodle and Blackboard platforms that are commonly used in universities. SocialWall allowed participants to perform actions in the social environment that are visualized in graphs under the specified criteria. A Wiki repository plugin was also added in order to accumulate student knowledge in shared structured documents stored in a shared repository. The relational database management system MySQL allows creation of additional relations, database design and administration. The visualization activities described in the study are based on modified state transition networks to analyze and visualize the student learning path. Student trajectory networks show the interaction of individual learners or groups with the course structure and material. © 2020. All Rights Reserved.},
	author_keywords = {E-learning; information visualization; learning analytics; social learning environment; visualization tools},
	keywords = {Computer aided instruction; Data visualization; Relational database systems; Students; Visualization; Learning community; Relational database management systems; Shared repositories; Social environment; State transitions; Structured document; Student knowledge; Virtual learning environments; E-learning},
	correspondence_address = {V. Zotov; State University of Management, Moscow, Russian Federation; email: zotovvla36@rambler.ru},
	publisher = {Kassel University Press GmbH},
	issn = {18688799},
	language = {English},
	abbrev_source_title = {Int. J. Emerg. Technol. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{2021,
	title = {NLASI 2021 - Proceedings of the Nordic Learning Analytics (Summer) Institute},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118228389&partnerID=40&md5=d363cc230a60bbf88112b39e1cc9b721},
	abstract = {The proceedings contain 8 papers. The topics discussed include: the development of computational thinking concepts in course participants’ programming solutions; students’ information privacy concerns in learning analytics: towards model development; Finnish education professionals’ thoughts on adaptive learning technologies; gamified learning analytics: an initial outline of design concept synergies from two fields; how deployment processes affect the adoption of learning analytics in higher education institutions: improving potential for impact with better deployment practices; AI driven competency development at the threshold of working life; and CADA: a learning analytics dashboard to support teachers with visualizations about students’ participation and discourse in online discussions.},
	editor = {Viberg O. and Glassey R. and Spikol D. and Balter O.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tegos2021693,
	author = {Tegos, Stergios and Tsiatsos, Thrasyvoulos and Psathas, Georgios and Demetriadis, Stavros},
	title = {Towards a Learning Analytics Dashboard for Collaborative Conversational Agent Activities in MOOCs},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1192 AISC},
	pages = {693 – 704},
	doi = {10.1007/978-3-030-49932-7_65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091477920&doi=10.1007%2f978-3-030-49932-7_65&partnerID=40&md5=4853e2bbf489ee7e28fe91f0d3de3965},
	affiliations = {Aristotle University of Thessaloniki, Thessaloniki, Greece},
	abstract = {This paper presents the design of a learning analytics dashboard, utilizing learning traces that emerge from conversational MOOC activities. These chat-based activities encourage students to collaborate in dyads, with the support of a conversational agent, in order to answer open-ended questions, set by the course instructor. Taking into account the dynamic and context-sensitive nature of the agent-based support provided during this kind of online activities, we aspire to share a series of variables, metrics and use cases, which can be valuable for practitioners and researchers looking forward to initiate the development of a learning analytics dashboard that encompasses aspects of both peer-to-peer and human-to-bot conversational interactions. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Computer-supported collaborative learning; Conversational agents; Learning analytics; Massive Open Online Courses},
	keywords = {Computer programming; Computer science; Agent based; Context sensitive; Conversational agents; Conversational interaction; Online activities; Open-ended questions; Peer to peer; Mobile telecommunication systems},
	correspondence_address = {S. Tegos; Aristotle University of Thessaloniki, Thessaloniki, Greece; email: stegos@csd.auth.gr},
	editor = {Auer M.E. and Tsiatsos T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21945357},
	isbn = {978-303049931-0},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Vaidya2021105,
	author = {Vaidya, Anagha and Saini, Jatinderkumar R.},
	title = {A Framework for Implementation of Learning Analytics and Educational Data Mining in Traditional Learning Environment},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {154},
	pages = {105 – 114},
	doi = {10.1007/978-981-15-8354-4_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098139010&doi=10.1007%2f978-981-15-8354-4_11&partnerID=40&md5=b8bbf082b7f163f7fcc4eea90cc65399},
	affiliations = {Symbiosis Institute of Computer Studies and Research, Symbiosis International Deemed University, Pune, India},
	abstract = {The use of the learning analytics (LA) and educational data mining (EDM) is going on from the last two decades. LA is a human-lead process which predicts learners’ performance as well as identifying potential problematic issues of the learner as the EDM translates the data into meaningful actions to support and empower the learning. In literature, these practices are used for online learning platform. In face-to-face teaching, these practices are rarely applied. The academic analytic systems are used for collecting the student, teacher and course data, but unable to create actionable and perceptive reports to the educational stakeholders. This paper designed a model for implementation of LA and EDM practices in face-to-face teaching environment. The model used the data about student’s continuous evaluation marks, the question paper or learning events used for the assessment. The different processes are generating the reports from it. The system is implemented by R. Shiny. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Academic analytics; Educational data mining (EDM); Learning analytics (LA); Learning dashboard (LD); Predictive analysis; Prescriptive analysis},
	correspondence_address = {A. Vaidya; Symbiosis Institute of Computer Studies and Research, Symbiosis International Deemed University, Pune, India; email: anaghavv@gmail.com},
	editor = {Fong S. and Dey N. and Joshi A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-981158353-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Olney202145,
	author = {Olney, Tom and Walker, Steve and Wood, Carlton and Clarke, Anactoria},
	title = {Are We Living in LA (P)LA Land? Reporting on the Practice of 30 STEM Tutors in Their Use of a Learning Analytics Implementation at The Open University},
	year = {2021},
	journal = {Journal of Learning Analytics},
	volume = {8},
	number = {3},
	pages = {45 – 59},
	doi = {10.18608/jla.2021.7261},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122219737&doi=10.18608%2fjla.2021.7261&partnerID=40&md5=049eeb763dca6c3f2cf454484cb4db43},
	affiliations = {Faculty of STEM, The Open University, Walton Hall, Milton Keynes, MK67AA, United Kingdom; Faculty of Arts & Social Sciences, The Open University, Walton Hall, Milton Keynes, MK67AA, United Kingdom},
	abstract = {Most higher education institutions view their increasing use of learning analytics as having significant potential to improve student academic achievement, retention outcomes, and learning and teaching practice but the realization of this potential remains stubbornly elusive. While there is an abundance of published research on the creation of visualizations, dashboards, and predictive models, there has been little work done to explore the impact of learning analytics on the actual practice of teachers. Through the lens of social informatics (an approach that views the users of technologies as active social actors whose technological practices constitute a wider socio-technical system) this qualitative study reports on an investigation into the practice of 30 tutors in the STEM faculty at Europe’s largest distance learning organization, The Open University UK (OU). When asked to incorporate learning analytics (including predictive learning analytics) contained in the Early Alert Indicator (EAI) dashboard during the 2017–2018 academic year into their practice, we found that tutors interacted with this dashboard in certain unanticipated ways and developed three identifiable “shadow practices”. © 2021, UTS ePRESS. All rights reserved.},
	author_keywords = {Learning analytics implementation; Shadow practice; Social informatics; Tutor practice},
	correspondence_address = {T. Olney; Faculty of STEM, The Open University, Milton Keynes, Walton Hall, MK67AA, United Kingdom; email: tom.olney@open.ac.uk},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Owatari2020523,
	author = {Owatari, Takuro and Shimada, Atsushi and Minematsu, Tsubasa and Hori, Maiya and Taniguchi, Rin-Ichiro},
	title = {Real-time learning analytics dashboard for students in online classes},
	year = {2020},
	journal = {Proceedings of 2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2020},
	pages = {523 – 529},
	doi = {10.1109/TALE48869.2020.9368340},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102970196&doi=10.1109%2fTALE48869.2020.9368340&partnerID=40&md5=ffab14fcda16d29ca6f3aaeaa752628a},
	affiliations = {Kyushu University, Graduate School of Information Science and Electrical Engineering, Fukuoka, Japan; Kyushu University, Platform of Inter/Transdisciplinary Energy Research, Fukuoka, Japan; Kyushu University, Faculty of Information Science and Electrical Engineering, Fukuoka, Japan},
	abstract = {In recent years, online classes have been increasingly conducted in various situations. However, in these classes, especially non-face-to-face and large-scale ones, it is more difficult for teachers and students to understand the status of the class during a lecture. To address this issue, we propose a real-time learning analytics dashboard that provides summarized information on teachers' instruction and students' learning activities during lectures. In this article, we introduce the real-time learning analytics dashboard and report its effectiveness through experiments in an online class at our university. © 2020 IEEE.},
	author_keywords = {Learning behavior; Online lecture; Real-time analytics; Real-time system},
	keywords = {Students; Face to face; Learning Activity; Online class; Real-time learning; Teachers'; E-learning},
	editor = {Mitsuhara H. and Goda Y. and Ohashi Y. and Rodrigo Ma.M.T. and Shen J. and Venkatarayalu N. and Wong G. and Yamada M. and Chi-Un Lei L.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816942-2},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Conf. Teach., Assess., Learn. Eng., TALE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Abu-Raya2021,
	author = {Abu-Raya, Kholod and Olsher, Shai},
	title = {Learning analytics based formative assessment: Gaining insights through interactive dashboard components in mathematics teaching},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121650055&partnerID=40&md5=89badb548b119f95e2b31ecc6a12dc44},
	affiliations = {University of Haifa, 199 Abba Hushi Blvd., Haifa, Israel},
	abstract = {Conducting a student centered discussion in a mathematics classroom is not a trivial task. A teacher must follow their students work, and then use the relevant information in order to conduct a meaningful discussion. This challenge is greater when digital environments are involved, or when the students work remotely and only submit their work online. One possible solution for this challenge could be in the form of accessible learning analytics that could assist the teacher to gain insight about their student's work. We report on a formative assessment platform that automatically analyzes student submissions and characterizes them according to preset conditions that are topic specific. These characterizations are then used in several interactive reports that form a teacher's dashboard that is designed to enable multiple levels of analysis by the teachers in planning a classroom discussion. We describe the different components and demonstrate their use in mathematics classrooms in Israel.  © 2021 Copyright for this paper by its authors.},
	author_keywords = {Online formative assessment; Teacher dashboard; Topic specific learning analytics},
	keywords = {E-learning; Digital environment; Formative assessment; Gaining insights; Mathematics teachings; Online formative assessment; Specific learning; Student-centred; Teacher dashboard; Teachers'; Topic specific learning analytic; Students},
	editor = {Yacobson E. and Weizmann Institute of Science, 234 Herzl St., Rehovot and Nazaretsky T. and Weizmann Institute of Science, 234 Herzl St., Rehovot and Toda A.M. and Durham University, Stockton Road, Durham and Cristea A.I. and Durham University, Stockton Road, Durham and Alexandron G. and Weizmann Institute of Science, 234 Herzl St., Rehovot},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sedrakyan2020,
	author = {Sedrakyan, Gayane and Malmberg, Jonna and Verbert, Katrien and Järvelä, Sanna and Kirschner, Paul A.},
	title = {Linking learning behavior analytics and learning science concepts: Designing a learning analytics dashboard for feedback to support learning regulation},
	year = {2020},
	journal = {Computers in Human Behavior},
	volume = {107},
	doi = {10.1016/j.chb.2018.05.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082548467&doi=10.1016%2fj.chb.2018.05.004&partnerID=40&md5=a91e5f5e2ad0a7e4265af7802a1ca2bb},
	affiliations = {KU Leuven, Department of Computer Science, Augment/HCI Research Group, Celestijnenlaan 200a, Leuven, 3001, Belgium; University of Ghent, IMEC / IDLab - Smart Applications, Faculty of Engineering and Architecture, AA Tower, Technologiepark 19, Zwijnaarde, 9052, Belgium; Oulu University, Faculty of Education, LET - Learning & Educational Technology Research Unit, University of Oulu, P.O.Box 2000, Snellmania, Yliopistokatu 9, Oulu, 90014, Finland; Open Universiteit Nederland, Welten Institute (Research Centre for Learning, Teaching and Technology), Valkenburgerweg 177, Heerlen, 6419AT, Netherlands},
	abstract = {Technological advancements have generated a strong interest in exploring learner behavior data through learning analytics to provide both learner and instructor with process-oriented feedback in the form of dashboards. However, little is known about the typology of dashboard feedback relevant for different learning goals, learners and teachers. While most dashboards and the feedback that they give are based only on learner performance indicators, research shows that effective feedback needs also to be grounded in the regulatory mechanisms underlying learning processes and an awareness of the learner's learning goals. The design artefact presented in this article uses a conceptual model that visualizes the relationships between dashboard design and the learning sciences to provide cognitive and behavioral process-oriented feedback to learners and teachers to support regulation of learning. A practical case example is given that demonstrates how the ideas presented in the paper can be deployed in the context of a learning dashboard. The case example uses several analytics/visualization techniques based on empirical evidence from earlier research that successfully tested these techniques in various learning contexts. © 2018 Elsevier Ltd},
	author_keywords = {Behavior analytics; Feedback automation; Learning analytics dashboards; Learning process analytics; Process-oriented feedback; Regulation of learning},
	keywords = {Behavioral research; Human computer interaction; Behavior analytics; Learning analytics dashboards; Learning process; Process-oriented; Regulation of learning; article; artifact; automation; awareness; conceptual model; human; human experiment; learning; regulatory mechanism; teacher; Learning systems},
	correspondence_address = {G. Sedrakyan; KU Leuven, Department of Computer Science, Augment/HCI Research Group, Leuven, Celestijnenlaan 200a, 3001, Belgium; email: gayane.sedrakyan@kuleuven.be},
	publisher = {Elsevier Ltd},
	issn = {07475632},
	coden = {CHBEE},
	language = {English},
	abbrev_source_title = {Comput. Hum. Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 191; All Open Access, Green Open Access}
}

@CONFERENCE{2021,
	title = {AIBL 2021 - AI for Blended-Learning: Empowering Teachers in Real Classrooms, co-located with 16th European Conference on Technology Enhanced Learning, ECTEL 2021},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121613037&partnerID=40&md5=111180e5d7c76c06d763933f7cf948dd},
	abstract = {The proceedings contain 5 papers. The topics discussed include: learning analytics based formative assessment: gaining insights through interactive dashboard components in mathematics teaching; classification in math class: using convolutional neural networks to categorize student cognitive demand; participatory design of feedback mechanism in a physics blended-learning environment; confirmation bias and trust: human factors that influence teachers' adoption of AI-based educational technology; and towards continuity of personalization in a large blended cours.},
	editor = {Yacobson E. and Weizmann Institute of Science, 234 Herzl St., Rehovot and Nazaretsky T. and Weizmann Institute of Science, 234 Herzl St., Rehovot and Toda A.M. and Durham University, Stockton Road, Durham and Cristea A.I. and Durham University, Stockton Road, Durham and Alexandron G. and Weizmann Institute of Science, 234 Herzl St., Rehovot},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Brown2020384,
	author = {Brown, Michael},
	title = {Seeing students at scale: how faculty in large lecture courses act upon learning analytics dashboard data},
	year = {2020},
	journal = {Teaching in Higher Education},
	volume = {25},
	number = {4},
	pages = {384 – 400},
	doi = {10.1080/13562517.2019.1698540},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084342594&doi=10.1080%2f13562517.2019.1698540&partnerID=40&md5=396db7c8678982ca27db888376d3002b},
	affiliations = {School of Education, College of Human Sciences, Iowa State University, Ames, IA, United States},
	abstract = {Despite their increasingly widespread adoption in post-secondary education, scholars and practitioners know very little about the impact of digital data displays on instructors’ sense-making and academic planning. In this manuscript, I report the results of comparative case studies of five different introductory physics instructors at three institutions who used data dashboards as part of an active learning approach called ‘Peer Instruction’. Instructors expressed frustration with the ways that data displays undermined their existing pedagogical strategies. They were stymied by a lack of clarity on how data is assembled and imbued with meaning, which limited their own sensemaking about the data. They also expressed concerns about how the dashboards facilitated data collection about their instructional planning and decision-making. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {academic planning; datafication; Learning analytics dashboards; peer instruction},
	correspondence_address = {M. Brown; School of Education, College of Human Sciences, Iowa State University, Ames, United States; email: brownm@iastate.edu},
	publisher = {Routledge},
	issn = {13562517},
	language = {English},
	abbrev_source_title = {Teach. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42}
}

@ARTICLE{Khulbe202114,
	author = {Khulbe, Manisha and Tammets, Kairit},
	title = {Scaffolding Teacher Learning During Professional Development with Theory-Driven Learning Analytics},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13103 LNCS},
	pages = {14 – 27},
	doi = {10.1007/978-3-030-90785-3_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119845467&doi=10.1007%2f978-3-030-90785-3_2&partnerID=40&md5=27575102bed6046d9284c3dfedfa9b30},
	affiliations = {Tallinn University, Tallinn, Estonia},
	abstract = {It is claimed that the innovative use of educational technology combined with appropriate pedagogical strategies can lead to improved student outcomes. However, teachers face difficulties in adopting educational technology and novel pedagogical methods as this involves acquiring complex new knowledge. Combined with training, Learning Analytics dashboards – artifacts which mediate teachers’ learning in technology-enhanced environments – can aid them in this task. Using student engagement as an example, we present the prototype of a theory-driven dashboard that can help teachers to better understand and implement new instructional methods in technology-enhanced learning environments. We describe here our needs analysis, design, and evaluation process and outcomes, reflecting upon how teachers can benefit from using thoughtfully-designed LA dashboards in professional development scenarios. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Learning Analytics dashboard; Teacher Professional Development; Teacher-facing dashboard; Theory-driven dashboard},
	keywords = {Computer aided instruction; Personnel training; Professional aspects; Scaffolds; Students; Learning analytic dashboard; Pedagogical method; Pedagogical strategies; Professional development; Student outcomes; Teacher learning; Teacher professional development; Teacher-facing dashboard; Teachers'; Theory-driven dashboard; Educational technology},
	correspondence_address = {M. Khulbe; Tallinn University, Tallinn, Estonia; email: manisha.khulbe@tlu.ee},
	editor = {Zhou W. and Mu Y.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303090784-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Mohseni2021,
	author = {Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
	title = {SBGTool: Similarity-Based Grouping Tool for Students' Learning Outcomes},
	year = {2021},
	journal = {Proceedings of the 2021 Swedish Workshop on Data Science, SweDS 2021},
	doi = {10.1109/SweDS53855.2021.9638263},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123845236&doi=10.1109%2fSweDS53855.2021.9638263&partnerID=40&md5=b4a68868b27a7db00beaba5915d4f4c9},
	affiliations = {Linnaeus University, Department of Computer Science and Media Technology, Växjö, Sweden},
	abstract = {With the help of Visual Learning Analytics (VLA) tools, teachers can construct meaningful groups of students that can, for example, collaborate and be engaged in productive discussions. However, finding similar samples in large educational databases requires effective similarity measures that capture the teacher's intent. In this paper we propose a web-based VLA tool called Similarity-Based Grouping (SBGTool), to assist teachers in categorizing students into different groups based on their similar learning outcomes and activities. By using SBGTool, teachers may compare individual students by considering the number of answers (correct and incorrect) in different question categories and time ranges, find the most difficult question categories considering the percentage of similarity to the correct answers, determine the degree of similarity and dissimilarity across students, and find the relationship between students' activity and success. To demonstrate the tool's efficacy, we used 10,000 random samples from the EdNet dataset, a large-scale hierarchical educational dataset consisting of student-system interactions from multiple platforms, at university level, collected over a period of two years. The results point to the conclusion that the tool is efficient, can be adapted to different learning domains, and has the potential to assist teachers in maximizing the collaborative learning potential in their classrooms.  © 2021 IEEE.},
	author_keywords = {Data Visualization; EdNet; Educational Data; Learning Analytics Dashboard; Similarity-Based Grouping; Visual Learning Analytics},
	keywords = {Data visualization; Large dataset; Analytic tools; Ednet; Educational data; Learning analytic dashboard; Question categories; Similarity-based grouping; Student learning outcomes; Teachers'; Visual learning; Visual learning analytic; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541830-0},
	language = {English},
	abbrev_source_title = {Proc. Swed. Workshop Data Sci., SweDS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Guerra2020973,
	author = {Guerra, Julio and Ortiz-Rojas, Margarita and Zúñiga-Prieto, Miguel Angel and Scheihing, Eliana and Jiménez, Alberto and Broos, Tom and De Laet, Tinne and Verbert, Katrien},
	title = {Adaptation and evaluation of a learning analytics dashboard to improve academic support at three Latin American universities},
	year = {2020},
	journal = {British Journal of Educational Technology},
	volume = {51},
	number = {4},
	pages = {973 – 1001},
	doi = {10.1111/bjet.12950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085748337&doi=10.1111%2fbjet.12950&partnerID=40&md5=eddd01aa8aa7617660b3a25d28babf1b},
	affiliations = {Universidad Austral de Chile, Chile; Ghent University, Belgium; Polytechnic University of Valencia, Spain; Institute of Informatics of the Austral University of Chile, Chile; Carlos III of Madrid University, Spain; Leuven Engineering and Science Education Centre (LESEC) and Augment HCI research group, Department of Computer Science at KU Leuven, Belgium; Faculty of Engineering Science, KU Leuven, Belgium; HCI research group of KU Leuven, Belgium},
	abstract = {Despite the success of academic advising dashboards in several higher educational institutions (HEI), these dashboards are still under-explored in Latin American HEI's. To close this gap, three different Latin American universities adapted an existing advising dashboard, originally deployed at the KU Leuven to their own context. In all three cases, the context was the main ruling factor to these adaptations. In this paper, we describe these adaptions using a framework that focuses on four different elements of the context: Objectives, Stakeholders, Key moment and Interactions. Evaluation of the adapted dashboards in the three different Latin American universities is conducted through pilots. This evaluation shows the value of the dashboard approach in different contexts in terms of satisfaction, usefulness and impact in academic decision-making and advising tasks. The main contribution of this paper is the systematic reporting of the adaptations to an academic advising dashboard and showing the value of an academic advising dashboard on academic decision-making and advising tasks. © 2020 British Educational Research Association},
	keywords = {Education; Educational technology; Academic advising; Academic supports; Educational institutions; Latin americans; Decision making},
	correspondence_address = {J. Guerra; Universidad Austral de Chile, Chile; email: jguerra@inf.uach.cl},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Green Open Access}
}

@ARTICLE{Afzaal202137,
	author = {Afzaal, Muhammad and Nouri, Jalal and Zia, Aayesha and Papapetrou, Panagiotis and Fors, Uno and Wu, Yongchao and Li, Xiu and Weegar, Rebecka},
	title = {Generation of Automatic Data-Driven Feedback to Students Using Explainable Machine Learning},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12749 LNAI},
	pages = {37 – 42},
	doi = {10.1007/978-3-030-78270-2_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126779857&doi=10.1007%2f978-3-030-78270-2_6&partnerID=40&md5=50d36b59d9cbd771c8f6f8b50176b7d7},
	affiliations = {Stockholm University, Stockholm, Sweden},
	abstract = {This paper proposes a novel approach that employs learning analytics techniques combined with explainable machine learning to provide automatic and intelligent actionable feedback that supports students self-regulation of learning in a data-driven manner. Prior studies within the field of learning analytics predict students’ performance and use the prediction status as feedback without explaining the reasons behind the prediction. Our proposed method, which has been developed based on LMS data from a university course, extends this approach by explaining the root causes of the predictions and automatically provides data-driven recommendations for action. The underlying predictive model effectiveness of the proposed approach is evaluated, with the results demonstrating 90 per cent accuracy. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Explainable machine learning; Feedback provision; Learning analytics; Recommendations generation},
	keywords = {Machine learning; Predictive analytics; Students; Analytic technique; Dashboard; Data driven; Explainable machine learning; Feedback provision; Feedback to students; Learning analytic; Machine-learning; Recommendation generation; Self regulation; Forecasting},
	correspondence_address = {M. Afzaal; Stockholm University, Stockholm, Sweden; email: muhammad.afzaal@dsv.su.se},
	editor = {Roll I. and McNamara D. and Sosnovsky S. and Luckin R. and Dimitrova V.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303078269-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Cechinel2021130,
	author = {Cechinel, Cristian and De Freitas Dos Santos, Mateus and Barrozo, Caio and Schardosim, Jesiel Emerim and Vila, Eduardo De and Ramos, Vinicius and Primo, Tiago and Munoz, Roberto and Queiroga, Emanuel Marques},
	title = {A Learning Analytics Dashboard for Moodle: Implementing Machine Learning Techniques to Early Detect Students at Risk of Failure},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	pages = {130 – 136},
	doi = {10.1109/LACLO54177.2021.00019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127141378&doi=10.1109%2fLACLO54177.2021.00019&partnerID=40&md5=3f544bef33c3324ce5315cd677f5a37d},
	affiliations = {Universidade Federal De Santa Catarina, Centro De Ciências, Tecnologiás E Saúde, Araranguá, Brazil; Universidade Federal De Pelotas, Centro De Engenharias, Pelotas, Brazil; Universidad De Valparaíso, Escuela De Ingenieriá Informática, Chile; Instituto Federal Sul-rio-grandense, Brazil},
	abstract = {Learning Analytics Dashboards are important tools that help professors to follow and understand students behavior inside Learning Management Systems. Moodle is one of the most popular and used Learning Management Systems available nowadays, and a number of initiatives have been conducted to offer Learning Analytics features inside it. The present paper describes MAD2, a Learning Analytics Dashboard developed for Moodle that offers different visualizations about students interactions inside the environment, and that uses machine learning techniques to early predict students at-risk of failure. The paper describes the predictive approach implemented inside the tool together with the most important visualization features available to the users. The offering of a tool to early predict students at-risk of failure inside Moodle is an important step to help professors and managers to better assist students during their courses.  © 2021 IEEE.},
	author_keywords = {At-risk students.; Dashboard; Educational Data Mining; Learning Analytics; Machine Learning},
	keywords = {Data mining; Learning algorithms; Machine learning; Visualization; At-risk student.; Dashboard; Educational data mining; Learning analytic; Learning management system; Machine learning techniques; Machine-learning; Risk of failure; Student interactions; Students' behaviors; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {English},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Pan2020393,
	author = {Pan, Zilong and Li, Chenglu and Liu, Min},
	title = {Learning Analytics Dashboard for Problem-based Learning},
	year = {2020},
	journal = {L@S 2020 - Proceedings of the 7th ACM Conference on Learning @ Scale},
	pages = {393 – 396},
	doi = {10.1145/3386527.3406751},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094927275&doi=10.1145%2f3386527.3406751&partnerID=40&md5=dcd1a18301da342dc7e688f4eaa10f88},
	affiliations = {University of Texas at Austin, Austin, United States},
	abstract = {This study examined two machine learning models for de-signing a learning analytics dashboard to assist teachers in facilitating problem-based learning. Specifically, we used BERT to automatically process a large amount of textual data to understand students' scientific argumentation. We then used Hidden Markov Model (HMM) to find students' cognitive state transition with time-series data. Preliminary results showed the models achieved high accuracy and were coherent with related theories, indicating the models can provide teachers with interpretable information to identify in-need students. © 2020 ACM.},
	author_keywords = {artificial intelligence; learning analytics dashboard; machine learning; problem-based learning (pbl)},
	keywords = {Students; Cognitive state; High-accuracy; Large amounts; Problem based learning; Textual data; Time-series data; Two machines; Hidden Markov models},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037951-9},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Valle20211405,
	author = {Valle, Natercia and Antonenko, Pavlo and Valle, Denis and Sommer, Max and Huggins-Manley, Anne Corinne and Dawson, Kara and Kim, Dongho and Baiser, Benjamin},
	title = {Predict or describe? How learning analytics dashboard design influences motivation and statistics anxiety in an online statistics course},
	year = {2021},
	journal = {Educational Technology Research and Development},
	volume = {69},
	number = {3},
	pages = {1405 – 1431},
	doi = {10.1007/s11423-021-09998-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106533501&doi=10.1007%2fs11423-021-09998-z&partnerID=40&md5=9a210f41ff0d1ac673ace25a60e419d9},
	affiliations = {University of Florida, Gainesville, FL, United States; Sungkyunkwan University, Seoul, South Korea},
	abstract = {Based on the achievement goal theory, this experimental study explored the influence of predictive and descriptive learning analytics dashboards on graduate students’ motivation and statistics anxiety in an online graduate-level statistics course. Participants were randomly assigned into one of three groups: (a) predictive dashboard, (b) descriptive dashboard, or (c) control (i.e., no dashboard). Measures of motivation and statistical anxiety were collected in the beginning and the end of the semester via the Motivated Strategies for Learning Questionnaire and Statistical Anxiety Rating Scale. Individual semi-structured interviews were used to understand learners’ perceptions of the course and whether the use of the dashboards influenced the meaning of their learning experiences. Results indicate that, compared to the control group, the predictive dashboard significantly reduced learners’ interpretation anxiety and had an effect on intrinsic goal orientation that depended on learners’ lower or higher initial levels of intrinsic goal orientation. In comparison to the control group, both predictive and descriptive dashboards reduced worth of anxiety (negative attitudes towards statistics) for learners who started the course with higher levels of worth anxiety. Thematic analysis revealed that learners who adopted a more performance-avoidance goal orientation approach demonstrated higher levels of anxiety regardless of the dashboard used. © 2021, Association for Educational Communications and Technology.},
	author_keywords = {Achievement goal theory; Learning analytics dashboards; Motivation; Online learning; Statistics anxiety},
	correspondence_address = {N. Valle; University of Florida, Gainesville, United States; email: naterciavalle@gmail.com},
	publisher = {Springer},
	issn = {10421629},
	language = {English},
	abbrev_source_title = {Educ. Technol. Res. Dev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Green Open Access}
}

@CONFERENCE{Alonso-Fernandez20211546,
	author = {Alonso-Fernandez, Cristina and Calvo-Morata, Antonio and Freire, Manuel and Martinez-Ortiz, Ivan and Manjon, Baltasar Fernandez},
	title = {Data science meets standardized game learning analytics},
	year = {2021},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2021-April},
	pages = {1546 – 1552},
	doi = {10.1109/EDUCON46332.2021.9454134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112457992&doi=10.1109%2fEDUCON46332.2021.9454134&partnerID=40&md5=0ac52162411ed8212024477d9c11ad49},
	affiliations = {Complutense University of Madrid, Dept. of Software Engineering and Artificial Intelligence, Madrid, Spain},
	abstract = {Data science applications in education are quickly proliferating, partially due to the use of LMSs and MOOCs. However, the application of data science techniques in the validation and deployment of serious games is still scarce. Among other reasons, obtaining and communicating useful information from the varied interaction data captured from serious games requires specific data analysis and visualization techniques that are out of reach of most non-experts. To mitigate this lack of application of data science techniques in the field of serious games, we present T-Mon, a monitor of traces for the xAPI-SG standard. T-Mon offers a default set of analysis and visualizations for serious game interaction data that follows this standard, with no other configuration required. The information reported by T-Mon provides an overview of the game interaction data collected, bringing analysis and visualizations closer to non-experts and simplifying the application of serious games. © 2021 IEEE.},
	author_keywords = {Dashboards; Data science; Learning analytics; Serious games; Visual analytics; XAPI},
	keywords = {Data Science; Data visualization; Engineering education; Visualization; Science applications; Visualization technique; Serious games},
	editor = {Klinger T. and Kollmitzer C. and Pester A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-172818478-4},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Avila-Pesantez2021536,
	author = {Avila-Pesantez, Diego and Usca, Brandon Alexander Tubon and Angamarca, Bryan Gagnay and Miriam Avila, L.},
	title = {Improving the Serious Game design using Game Learning Analytics and Eye-tracking: A pilot study},
	year = {2021},
	journal = {2021 IEEE URUCON, URUCON 2021},
	pages = {536 – 540},
	doi = {10.1109/URUCON53396.2021.9647058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124364067&doi=10.1109%2fURUCON53396.2021.9647058&partnerID=40&md5=d19a4d8a5a4b60c541738564777b752f},
	affiliations = {Escuela Superior Politécnica de Chimborazo, Facultad de Informática y Electrónica, Riobamba, Ecuador; Unidad Educatica Salesianos Star, Riobamba, Ecuador; Escuela Superior Politécnica de Chimborazo, Facultad de Mecánica, Riobamba, Ecuador},
	abstract = {It is necessary to consider metrics that integrate Game Learning Analytics (GLA) and technologies that improve user interfaces through the eye tracker to get better the Serious Games design. In this work, the Math4Fun game was developed using the ADDE methodology to support basic math operations for 7-year-old children, which allowed efficient communication to define the game's critical elements. The GLA metrics were implemented with eXperience API (xAPI) standard and visualized through a real-time dashboard, while Eye-tracking technology working with fixation time analysis on the game's interfaces improves gameplay and design. The results established that combining the GLA indicators with the user interface components obtained from the evaluation with eye-tracking allows redefining concepts in the design and programming inside SG in search of constant improvement. © 2021 IEEE.},
	author_keywords = {Eye-tracking; game learning analytics; MATH4FUN; serious game design},
	keywords = {Game design; Serious games; User interfaces; Critical elements; Efficient communications; Eye trackers; Eye tracking technologies; Eye-tracking; Game learning analytic; MATH4FUN; Pilot studies; Real-time dashboards; Serious games designs; Eye tracking},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542443-1},
	language = {English},
	abbrev_source_title = {IEEE URUCON, URUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Pelánek202193,
	author = {Pelánek, Radek},
	title = {Analyzing and visualizing learning data: A system designer’s perspective},
	year = {2021},
	journal = {Journal of Learning Analytics},
	volume = {8},
	number = {2},
	pages = {93 – 104},
	doi = {10.18608/JLA.2021.7345},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116004203&doi=10.18608%2fJLA.2021.7345&partnerID=40&md5=957b191e73e87ce7c4ff00ac0bc6a094},
	abstract = {In this work, we consider learning analytics for primary and secondary schools from the perspective of the designer of a learning system. We provide an overview of practically useful analytics techniques with descriptions of their applications and specific illustrations. We highlight data biases and caveats that complicate the analysis and its interpretation. Although we intentionally focus on techniques for internal use by designers, many of these techniques may inspire the development of dashboards for teachers or students. We also identify the consequences and challenges for research. © 2021, UTS ePRESS. All rights reserved.},
	author_keywords = {Biases; Cheating; Difficulty; Response time; Similarity; Temporal patterns},
	correspondence_address = {R. Pelánek; Faculty of Informatics, Masaryk University, Brno, Botanická 68a, 602 00, Czech Republic; email: pelanek@fi.muni.cz},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Guillain2021533,
	author = {Guillain, Léonore V. and Schneider, Bertrand},
	title = {Facilitators first: Building a tool with facilitators to foster a more collaborative makerspace community through movement traces},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {533 – 539},
	doi = {10.1145/3448139.3448194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103884214&doi=10.1145%2f3448139.3448194&partnerID=40&md5=45c60398f5a4c146c237c1815fb9cc3f},
	affiliations = {EPFL, Lausanne, Switzerland; Harvard University, Cambridge, United States},
	abstract = {Research indicates that makerspaces equip students with the practical skills needed to build their own projects and thrive in the twenty-first-century workforce. While the appeal of makerspaces lies in their spirit of tinkering and community-driven ethos, these same attributes make it difficult to monitor and facilitate learning. Makerspaces also attract students from diverse backgrounds and skills, further challenging facilitators to accommodate the needs of each student and their self-directed projects. We propose a dashboard interface that visualizes Kinect sensor data to aid facilitators in monitoring student collaboration. The tool was designed with an iterative and participatory approach. Five facilitators were involved at each phase of the design process, from need-finding to prototyping to implementation and evaluation. Insights derived from interviews were used to inform the design decisions of the final interface. The final evaluation suggests that the use of normalized summary scores and an interactive network graph can successfully support facilitators in tasks related to improving collaboration. Moreover, the use of a red-green color scheme and the inclusion of student photos improved the usability for facilitators, but issues of trustworthiness need to be further examined. © 2021 ACM.},
	author_keywords = {Human-computer interaction; Learning analytics dashboards; Physical learning analytics},
	keywords = {Image enhancement; Design decisions; Design process; Kinect sensors; Need findings; Participatory approach; Practical skill; Self-directed; Student collaboration; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038935-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Franzoni20201,
	author = {Franzoni, Valentina and Milani, Alfredo and Mengoni, Paolo and Piccinato, Fabrizio},
	title = {Artificial intelligence visual metaphors in e-learning interfaces for learning analytics},
	year = {2020},
	journal = {Applied Sciences (Switzerland)},
	volume = {10},
	number = {20},
	pages = {1 – 25},
	doi = {10.3390/app10207195},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092781596&doi=10.3390%2fapp10207195&partnerID=40&md5=ca128efbb6f09648608249a2c98312cc},
	affiliations = {Department of Mathematics and Computer Science, University of Perugia, Perugia, 6100, Italy; Department of Journalism, Hong Kong Baptist University, Hong Kong},
	abstract = {This work proposes an innovative visual tool for real-time continuous learners analytics. The purpose of the work is to improve the design, functionality, and usability of learning management systems to monitor user activity to allow educators to make informed decisions on e-learning design, usually limited to dashboards graphs, tables, and low-usability user logs. The standard visualisation is currently scarce, and often inadequate to inform educators about the design quality and students engagement on their learning objects. The same low usability can be found in learning analytics tools, which mostly focus on post-course analysis, demanding specific skills to be effectively used, e.g., for statistical analysis and database queries. We propose a tool for student analytics embedded in a Learning Management System, based on the innovative visual metaphor of interface morphing. Artificial intelligence provides in remote learning immediate feedback, crucial in a face-to-face setting, highlighting the students’ engagement in each single learning object. A visual metaphor is the representation of a person, group, learning object, or concept through a visual image that suggests a particular association or point of similarity. The basic idea is that elements of the application interface, e.g., learning objects’ icons and student avatars, can be modified in colour and dimension to reflect key performance indicators of learner’s activities. The goal is to provide high-affordance information on the student engagement and usage of learning objects, where aggregation functions on subsets of users allow a dynamic evaluation of cohorts with different granularity. The proposed visual metaphors (i.e., thermometer bar, dimensional morphing, and tag cloud morphing) have been implemented and experimented within academic-level courses. Experimental results have been evaluated with a comparative analysis of user logs and a subjective usability survey, which show that the tool obtains quantitative, measurable effectiveness and the qualitative appreciation of educators. Among metaphors, the highest success is obtained by Dimensional morphing and Tag cloud transformation. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Arttificial Intelligence–based visual interface; Course evaluation; Information visualization; Learner continuous monitoring; Teachers self-evaluation; Usability},
	correspondence_address = {V. Franzoni; Department of Mathematics and Computer Science, University of Perugia, Perugia, 6100, Italy; email: valentina.franzoni@dmi.unipg.it; A. Milani; Department of Mathematics and Computer Science, University of Perugia, Perugia, 6100, Italy; email: alfredo.milani@unipg.it},
	publisher = {MDPI AG},
	issn = {20763417},
	language = {English},
	abbrev_source_title = {Appl. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Eradze202128,
	author = {Eradze, Maka and Dipace, Anna and Fazlagic, Bojan and Di Pietro, Anastasia},
	title = {Semi-automated Student Feedback and Theory-Driven Video-Analytics: An Exploratory Study on Educational Value of Videos},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1344},
	pages = {28 – 39},
	doi = {10.1007/978-3-030-67435-9_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101497875&doi=10.1007%2f978-3-030-67435-9_3&partnerID=40&md5=9320a286df8ad38f21e572999e8401f6},
	affiliations = {Department of Education and Human Sciences, University of Modena and Reggio Emilia, Viale Antonio Allegri, 9, Reggio Emilia, 42121, Italy; University of Foggia, Via Antonio Gramsci, 89, Foggia, 71122, Italy},
	abstract = {Learning Analytics (LA) is a relatively novel method for automated data collection and analysis with promising opportunities to improve teaching and learning processes, widely used in educational research and practice. Moreover, with the elevated use of videos in teaching and learning processes the importance of the analysis of video data increases. In turn, video analytics presents us with opportunities as well as challenges. However, to make full use of its potential often additional data is needed from multiple other sources. On the other hand, existing data also requires context and design-awareness for the analysis. Based on the existing landscape in LA, namely in video-analytics, this article presents a proof-of-concept study connecting cognitive theory-driven analysis of videos and semi-automated student feedback to enable further inclusion of interaction data and learning outcomes to inform video design but also to build teacher dashboards. This paper is an exploratory study analysing relationship between semi-automated student feedback (on several scales on the perceived educational value of videos), video engagement, video duration and theory-driven video annotations. Results did not indicate a significant relationship between different video designs and student feedback; however, findings show some correlation between the number of visualisations and video designs. The results can design implications as well as inform the researchers and practitioners in the field. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Learning analytics; Student feedback; Video-analytics},
	keywords = {Automation; Distance education; Learning systems; Teaching; Automated data collection and analysis; Cognitive theory; Educational research; Exploratory studies; Learning outcome; Proof of concept; Teaching and learning; Video annotations; Students},
	correspondence_address = {M. Eradze; Department of Education and Human Sciences, University of Modena and Reggio Emilia, Reggio Emilia, Viale Antonio Allegri, 9, 42121, Italy; email: maka.eradze@unimore.it},
	editor = {Agrati L.S. and Burgos D. and Ducange P. and Limone P. and Perla L. and Picerno P. and Raviolo P. and Stracke C.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303067434-2},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Ruiperez-Valiente202183467,
	author = {Ruiperez-Valiente, Jose A. and Gomez, Manuel J. and Martinez, Pedro A. and Kim, Yoon Jeon},
	title = {Ideating and Developing a Visualization Dashboard to Support Teachers Using Educational Games in the Classroom},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {83467 – 83481},
	doi = {10.1109/ACCESS.2021.3086703},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107362990&doi=10.1109%2fACCESS.2021.3086703&partnerID=40&md5=c8b250267fa5ed7f9799b32b0c4d57a2},
	affiliations = {Faculty of Computer Science, University of Murcia, Murcia, 30100, Spain; Playful Journey Lab, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States},
	abstract = {Technology has become an integral part of our everyday life, and its use in educational environments keeps growing. Additionally, video games are one of the most popular mediums across cultures and ages. There is ample evidence that supports the benefits of using games for learning and assessment, and educators are mainly supportive of using games in classrooms. However, we do not usually find educational games within the classroom activities. One of the main problems is that teachers report difficulties to actually know how their students are using the game so that they can analyze properly the effect of the activity and the interaction of students. To support teachers, educational games should incorporate learning analytics to transform data generated by students when playing useful information in a friendly and understandable way. For this work, we build upon Shadowspect, a 3D geometry puzzle game that has been used by teachers in a group of schools in the US. We use learning analytics techniques to generate a set of metrics implemented in a live dashboard that aims to facilitate that teachers can understand students' interaction with Shadowspect. We depict the multidisciplinary design process that we have followed to generate the metrics and the dashboard with great detail. Finally, we also provide uses cases that exemplify how teachers can use the dashboard to understand the global progress of their class and each of their students at an individual level, in order to intervene, adapt their classes and provide personalize feedback when appropriate. © 2013 IEEE.},
	author_keywords = {Educational games; game-based assessment; learning analytics; technology-enhanced learning; visualization dashboard},
	keywords = {Human computer interaction; Technology transfer; Classroom activity; Educational environment; Educational game; Games for learning; Individual levels; Integral part; Multi-disciplinary designs; Puzzle games; Students},
	correspondence_address = {J.A. Ruiperez-Valiente; Faculty of Computer Science, University of Murcia, Murcia, 30100, Spain; email: jruiperez@um.es},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access}
}

@ARTICLE{Amarasinghe2020662,
	author = {Amarasinghe, Ishari and Hernandez-Leo, Davinia and Michos, Konstantinos and Vujovic, Milica},
	title = {An Actionable Orchestration Dashboard to Enhance Collaboration in the Classroom},
	year = {2020},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {13},
	number = {4},
	pages = {662 – 675},
	doi = {10.1109/TLT.2020.3028597},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092503160&doi=10.1109%2fTLT.2020.3028597&partnerID=40&md5=202a05653a9b0b86a49cbf2a70442521},
	affiliations = {Interactive and Distributed Technologies Research Group, Universitat Pompeu Fabra, Barcelona, 08018, Spain},
	abstract = {The orchestration of collaborative learning activities in technology-enhanced classrooms has become a nontrivial endeavor for educators. Depending on the behaviors and needs of students that emerge in real educational situations, educators may need to orchestrate activity adaptations on the fly. These adaptations may range from the provision of additional scaffolding by the educator (e.g., the educator's participation in a group discussion) to a change in the planned pedagogical scenario (e.g., the duration). This article aims to contribute to the orchestration of technology-mediated collaborative learning sessions in a classroom context. We present the design, implementation, and evaluation of a teacher-facing dashboard that supports teachers in orchestrating scripted collaboration. Evaluation studies were conducted in 16 classroom sessions. The findings indicate that teachers found the information on the dashboard to be actionable and help facilitate just in time support to student groups.  © 2008-2011 IEEE.},
	author_keywords = {Collaborative learning; dashboards; learning analytics (LA); learning technologies; orchestration; scripts.},
	keywords = {E-learning; Engineering; Collaborative learning; Collaborative learning activities; Evaluation study; Group discussions; Just in time; Pedagogical scenarios; Student groups; Technology enhanced classrooms; Scaffolds},
	correspondence_address = {I. Amarasinghe; Interactive and Distributed Technologies Research Group, Universitat Pompeu Fabra, Barcelona, 08018, Spain; email: ishari.amarasinghe@upf.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Green Open Access}
}

@CONFERENCE{Sigua2020,
	author = {Sigua, Edisson and Aguilar, Bryan and Pesantez-Cabrera, Paola and Maldonado-Mahauad, Jorge},
	title = {Proposal for the Design and Evaluation of a Dashboard for the Analysis of Learner Behavior and Dropout Prediction in Moodle},
	year = {2020},
	journal = {Proceedings of the 15th Latin American Conference on Learning Technologies, LACLO 2020},
	doi = {10.1109/LACLO50806.2020.9381148},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103742002&doi=10.1109%2fLACLO50806.2020.9381148&partnerID=40&md5=11116d1ae33922fb86806186bc6c13ed},
	affiliations = {Universidad de Cuenca, Departamento de Ciencias de la Computacion, Cuenca, Ecuador},
	abstract = {The rapid development of technology has meant that over the past two decades Information and Communications Technologies (ICT) become increasingly involved in the teaching process and seek to change traditional learning models. With the support of modern technology, virtual platforms that encourage the adoption of a new learning paradigm in which geographical/temporal limitations no longer pose a difficulty have been developed and refined. These virtual learning platforms, also known as Learning Management Systems (LMS), store student and teacher interactions with course resources, and these interactions are stored in database engines. However, all the information generated by LMS has not been processed in a way that is helpful for the use of teachers and students, mainly because in most cases, students' interactions with these systems focus on downloading class material, delivering assignments, and reading announcements, leaving aside indicators that can be presented in the form of visualizations that allow actions to be taken during the development of the learning process. Thus, this study proposes the design, implementation, and evaluation of a dashboard for the analysis of learner behavior and prediction of dropout on the Moodle platform. The proposed tool will help students to manage their learning process, easily and effectively monitor their progress in an online course, and teachers to know what students do before, during and after a virtual class. The latter for the purpose of being able to detect early students at risk of dropping out. © 2020 IEEE.},
	author_keywords = {Dashboard; Dropout; Learning Analytics; Moodle; Prediction},
	keywords = {Curricula; Engineering education; Learning systems; Students; Teaching; Design and evaluations; Information and communications technology; Learning management system; Learning paradigms; Learning process; Modern technologies; Teaching process; Traditional learning; E-learning},
	editor = {Piedra N. and Romero Pelaez A. and Cadme Samaniego E. and Chacon Rivas M. and Sprock A.S. and Frango Silveira I.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172819268-0},
	language = {Spanish},
	abbrev_source_title = {Proc. Lat. Am. Conf. Learn. Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{2021,
	title = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127131129&partnerID=40&md5=ec64ebefb9873aac187f8ca9cf50d9eb},
	abstract = {The proceedings contain 99 papers. The topics discussed include: predicting student performance using feature selection algorithms for deep learning models; ‘prediction’ in educational research: a bibliographic mapping of academic production over time; tools, resources and techniques for active learning at COVID-19 - a look at the private Brazilian higher education network; teaching computational thinking and introduction to programming through robotics amid the COVID-19 pandemic - an experience report; constraints, effectiveness and solutions in using google classroom as a learning management system during COVID-19 pandemic: a systematic literature review; online collaborative learning: analysis of the current state; meaningful learning: towards a meta-regulated learning model in hybrid education; and systematic mapping of Moodle dashboards focused on learning analytics tasks.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {English},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Majumdar2020127,
	author = {Majumdar, Rwitajit and Bakilapadavu, Geetha and Majumder, Reek and Chen, Mei-Rong Alice and Flanagan, Brendan and Ogata, Hiroaki},
	title = {Learning analytics of critical reading activity: Reading Hayavadana during lockdown},
	year = {2020},
	journal = {ICCE 2020 - 28th International Conference on Computers in Education, Proceedings},
	volume = {1},
	pages = {127 – 136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099436637&partnerID=40&md5=15a4c13b870a3eee51962e30a0d7f047},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Japan; Department of Humanities and Social Science, BITS Pilani Goa Campus, India; School of Computing, Clemson University, United States},
	abstract = {Investigating learning behaviors in a humanities course using learning analytics techniques is underrepresented in literature. A Critical Analysis of Literature and Cinema course was selected as a context. The course was offered for more than 10 years by the instructor in a face-to-face classroom mode. However, this time the context was unique as the classroom-based interactive activities were rapidly migrated to online sessions due to the COVID-19 pandemic related lockdown. Under such a circumstance, BookRoll, a learning analytics enhanced eBook platform supported the critical reading activity online. Students (n=22 out of the 50 registered) accessed Hayavadana, an Indian play titled Hayavadana uploaded on BookRoll and attempted to identify performative elements and cultural references in the text and highlight them. In this study, we analyze learner's reading logs gathered in the learning record store linked to BookRoll during that activity. Based on learner's online reading engagement from their clickstream interactions and time spent for them, four readers' profiles were defined; Effortful, Strategic, Wanderers and Check-out. We illustrate the content navigation and annotation behavior of each of those profiles. This study aims to initiate further discussion related to the application of learning analytics in humanities courses both to enhance the teaching and learning experiences by the use of interactive learning dashboards that was used to probe into the learning behaviors of the students. © ICCE 2020 - 28th International Conference on Computers in Education, Proceedings. All rights reserved.},
	author_keywords = {BookRoll; Critical Reading Activity; Hayavadana; Humanities Course; Learning Analytics; Process Mining},
	keywords = {Students; Critical analysis; Humanities course; Interactive activities; Interactive learning; Learning behavior; Learning record; Reading activities; Teaching and learning; Teaching},
	correspondence_address = {R. Majumdar; Academic Center for Computing and Media Studies, Kyoto University, Japan; email: dr.rwito@gmail.com},
	editor = {So H.-J. and Rodrigo Ma.M. and Mason J. and Mitrovic A. and Bodemer D. and Chen W. and Chen Z.-H. and Flanagan B. and Jansen M. and Nkambou R. and Wu L.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972145-5},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Scheers202152,
	author = {Scheers, Hanne and De Laet, Tinne},
	title = {Interactive and Explainable Advising Dashboard Opens the Black Box of Student Success Prediction},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12884 LNCS},
	pages = {52 – 66},
	doi = {10.1007/978-3-030-86436-1_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115448502&doi=10.1007%2f978-3-030-86436-1_5&partnerID=40&md5=ec6c1153f1369fcf753aadbf28da203f},
	affiliations = {Leuven Engineering and Science Education Center (LESEC), KU Leuven, Leuven, Belgium},
	abstract = {This paper presents exploratory research regarding the design and evaluation of a dashboard supporting the advising of aspiring university students incorporating a black-box predictive model for student success. While black-box predictive models can provide accurate predictions, incorporating them in dashboards is challenging as the black-box nature can threaten the interpretability and negatively impact trust of end-users. Explainable Learning Analytics aims to provide insights to black-box predictions by for instance explaining how the input features impact the prediction made. Two dashboards were designed to visualize the prediction and the outcome of the explainer. The dashboards supplemented the explainer with an interactive visualisation allowing to simulate how changes in the student’s features impact the prediction. Both dashboards were evaluated in user tests with 13 participants. The results show the potential of explainable AI techniques to bring predictive models to advising practice. We found that the combination of the explainer with the simulation helped users to compare the predictive model with their mental models of student success, challenging understanding of users and influencing trust in the predictive model. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Information visualization; Learning dashboards; Student advising},
	keywords = {Forecasting; Information systems; Visualization; Accurate prediction; Black boxes; Design and evaluations; Exploratory research; Information visualization; Learning dashboard; Predictive models; Student advising; Student success; University students; Students},
	correspondence_address = {T. De Laet; Leuven Engineering and Science Education Center (LESEC), KU Leuven, Leuven, Belgium; email: tinne.delaet@kuleuven.be},
	editor = {De Laet T. and Klemke R. and Alario-Hoyos C. and Hilliger I. and Ortega-Arranz A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303086435-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Broos2020855,
	author = {Broos, Tom and Pinxten, Maarten and Delporte, Margaux and Verbert, Katrien and De Laet, Tinne},
	title = {Learning dashboards at scale: early warning and overall first year experience},
	year = {2020},
	journal = {Assessment and Evaluation in Higher Education},
	volume = {45},
	number = {6},
	pages = {855 – 874},
	doi = {10.1080/02602938.2019.1689546},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075720857&doi=10.1080%2f02602938.2019.1689546&partnerID=40&md5=7b7e53084af05d64395d5a4b1141d034},
	affiliations = {Department of Computer Science, KU Leuven, Leuven, Belgium; Faculty of Engineering Science, KU Leuven, Leuven, Belgium; Faculty of Engineering Technology, KU Leuven, Leuven, Belgium; Leuven Statistics Research Centre, KU Leuven, Leuven, Belgium},
	abstract = {In this study, we present a case study involving two self-service dashboards providing feedback on learning and study skills and on academic achievement. These dashboards were offered to first-year university students in several study programmes in Flanders, Belgium. Data for this study were collected using usage tracking (N = 2875) and a survey taken at the beginning of the second year before (N = 484) and after (N = 538) the introduction of the dashboards. We found that early dashboard usage is related to academic achievement later in the academic year and that students’ review of the feedback received in the first year improved. Although these results are modest in comparison to how high the bar is sometimes set for learning analytics applications, we argue that low-cost deployments of self-service dashboards are an interesting approach to start building experience with similar tools and to start paving the way for future developments. © 2019 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {feedback; first-year experience; Learning analytics; learning and study skills; student dashboards},
	correspondence_address = {T. Broos; Department of Computer Science, KU Leuven, Leuven, Belgium; email: tom.broos@kuleuven.be},
	publisher = {Routledge},
	issn = {02602938},
	language = {English},
	abbrev_source_title = {Assess. Eval. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{Bao2021287,
	author = {Bao, Haogang and Li, Yanyan and Su, You and Xing, Shuang and Chen, Nian-Shing and Rosé, Carolyn Penstein},
	title = {The effects of a learning analytics dashboard on teachers’ diagnosis and intervention in computer-supported collaborative learning},
	year = {2021},
	journal = {Technology, Pedagogy and Education},
	volume = {30},
	number = {2},
	pages = {287 – 303},
	doi = {10.1080/1475939X.2021.1902383},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103603664&doi=10.1080%2f1475939X.2021.1902383&partnerID=40&md5=0836b13cbe97802cf7c4ea6ed87b2f3c},
	affiliations = {Faculty of Education, Beijing Normal University, Beijing, China; Center for Research on Technology-Enhanced Language Education, Beijing University of Posts and Telecommunications, Beijing, China; Teaching Affairs Department, Shenzhen Longhua Experimental School, Shenzhen, China; Department of Applied Foreign Languages, National Yunlin University of Science and Technology, Taiwan; Language Technologies Institute and Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {The learning analytics dashboard (LAD) has been recognised as a useful tool to facilitate teachers’ diagnosis and intervention in collaborative learning. However, little empirical evidence has been reported concerning the effects of LAD on teachers in computer-supported collaborative learning (CSCL). The purpose of this study was to evaluate the effectiveness of a LAD system called the Knowledge-Behavior-Social Dashboard (KBSD) for supporting teachers’ diagnosis and intervention of CSCL activities. Thirty-five pre-service teachers participated in the experiment. The results indicated that teachers using KBSD used more ‘cross-group’ strategies to diagnose students’ learning problems. Teachers in the experimental group also performed more interventions involving ‘cognitive guidance’, ‘scaffold instructing’, ‘positive evaluation’ and ‘individual facilitating’. Moreover, the analysis of the interview revealed that the KBSD tool has the potential to assist teachers in detecting learning problems in a group in an easy and convenient manner. Pedagogical implications and future research are also addressed. © 2021 Technology, Pedagogy and Education Association.},
	author_keywords = {CSCL; dashboard; learning analytics; teachers’ diagnosis; teachers’ intervention},
	correspondence_address = {Y. Li; School of Educational Technology, Beijing Normal University, Beijing, Xinjiekouwai Street, Haidian Disrict, 100875, China; email: liyy@bnu.edu.cn},
	publisher = {Routledge},
	issn = {1475939X},
	language = {English},
	abbrev_source_title = {Technol. Pedagog. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Mohseni2021,
	author = {Mohseni, Zeynab and Martins, Rafael M. and Masiello, Italo},
	title = {SAVis: A learning analytics dashboard with interactive visualization and machine learning},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118207858&partnerID=40&md5=751b3ab39097143f0cfdf4ea03b842ee},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Sweden},
	abstract = {A dashboard that provides a central location to monitor and analyze data is an efficient way to track multiple data sources. In the educational community, for example, using dashboards can be a straightforward introduction into the concepts of visual learning analytics. In this paper, the design and implementation of Student Activity Visualization (SAVis), a new Learning Analytics Dashboard (LAD) using interactive visualization and Machine Learning (ML) is presented and discussed. The design of the dashboard was directed towards answering a set of 22 pedagogical questions that teachers might want to investigate in an educational dataset. We evaluate SAVis with an educational dataset containing more than two million samples, including the learning behaviors of 6,423 students who used a web-based learning platform for one year. We show how SAVis can deliver relevant information to teachers and support them to interact with and analyze the students’ data to gain a better overview of students’ activities in terms of, for example, their performance in number of correct/incorrect answers per each topic. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Educational dataset; Learning analytics dashboard; Machine learning; SAVis; Visual learning analytics; Visualization},
	keywords = {Computer aided instruction; E-learning; Machine learning; Students; Central locations; Educational community; Educational dataset; Interactive visualizations; Learning analytic dashboard; Multiple data sources; Student activity visualization; Teachers'; Visual learning; Visual learning analytic; Visualization},
	editor = {Viberg O. and Glassey R. and Spikol D. and Balter O.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Person2021524,
	author = {Person, Joël and Vidal-Gomel, Christine and Cottier, Philippe and Lecomte, Coline},
	title = {Co-design of a Learning Analytics Tool by Computer Scientists and Teachers: The Difficult Emergence of a Common World},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {219 LNNS},
	pages = {524 – 533},
	doi = {10.1007/978-3-030-74602-5_73},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106447581&doi=10.1007%2f978-3-030-74602-5_73&partnerID=40&md5=c5f9db619037b4b7e4700f175585d1b4},
	affiliations = {CREN (Centre de Recherche en Education de Nantes), Université de Nantes, Nantes, France},
	abstract = {We present here the first part of an ongoing study conducted at a French high school, about the co-design of tools exploiting Learning Analytics by teachers and Computer Sciences researchers. The device implemented by the IT specialists hardly meets the conditions that would allow for an effective participation of stakeholders in the design process. The object planned to be designed turns out to be disconnected from the real activity of teachers. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Co-design; Learning Analytics; Learning dashboards; Participatory design; Teaching learning activity},
	correspondence_address = {J. Person; CREN (Centre de Recherche en Education de Nantes), Université de Nantes, Nantes, France; email: joel.person@univ-nantes.fr},
	editor = {Black N.L. and Neumann W.P. and Noy I.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303074601-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kokoç202116,
	author = {Kokoç, Mehmet and Kara, Mehmet},
	title = {A Multiple Study Investigation of the Evaluation Framework for Learning Analytics: Instrument Validation and the Impact on Learner Performance},
	year = {2021},
	journal = {Educational Technology and Society},
	volume = {24},
	number = {1},
	pages = {16 – 28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102832727&partnerID=40&md5=77c3675bd59de7ba35dfd3049d9f4de0},
	affiliations = {School of Applied Sciences, Trabzon University, Turkey; Vocational School of Design, Amasya University, Turkey},
	abstract = {The purposes of the two studies reported in this research are to adapt and validate the instrument of the Evaluation Framework for Learning Analytics (EFLA) for learners into the Turkish context, and to examine how metacognitive and behavioral factors predict learner performance. Study 1 was conducted with 83 online learners enrolled in a 16-week course delivered through the Moodle learning management system. The findings from the confirmatory factor analysis indicated that a three-factor model of the EFLA for learners provided the best model fit for the collected data. The model is consistent with the factorial structure of the original instrument developed based on the data from the European learners. Study 2 aimed to reveal how the metacognitive and behavioral factors pertaining to the learning analytics dashboard predict learners’ academic performance. A total of 63 online learners enrolled in a 14-week online computing course participated in this study. The results from the logistic regression analysis indicated that online learners more frequently interacted with the learning analytics dashboard demonstrated greater academic performance. Furthermore, the dimensions of the EFLA, together with the interaction with the dashboard, significantly predicted learners’ academic performance. This multiple-study investigation contributes to the generalizability of the EFLA for learners and highlights the importance of metacognitive and behavioral factors for the impact of learning analytics dashboards on learner performance. © 2021, Educational Technology and Society. All Rights Reserved.},
	author_keywords = {Evaluation; Learning analytics; Learning analytics dashboards; Learning performance; Validation},
	correspondence_address = {M. Kokoç; School of Applied Sciences, Trabzon University, Turkey; email: kokoc@trabzon.edu.tr},
	publisher = {International Forum of Educational Technology,National Taiwan Normal Universityand Society,},
	issn = {11763647},
	language = {English},
	abbrev_source_title = {Educational Technology and Society},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Oliver-Quelennec202163,
	author = {Oliver-Quelennec, Katia and Bouchet, François and Carron, Thibault and Pinçon, Claire},
	title = {CAN A LEARNING ANALYTICS DASHBOARD PARTICIPATIVE DESIGN APPROACH BE TRANSPOSED TO AN ONLINE-ONLY CONTEXT?},
	year = {2021},
	journal = {18th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2021},
	pages = {63 – 70},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124080706&partnerID=40&md5=bd75f6d3ab2a8539e6a9b022cbe108a8},
	affiliations = {Sorbonne Université, CNRS, LIP6, Paris, F-75005, France; Univ. Lille, CHU Lille, ULR 2694, METRICS: Évaluation des Technologies de Santé et des Pratiques Médicales, Lille, F-59000, France; Univ. Lille, GIVRE, DIP, France},
	abstract = {In-person sessions of participative design are commonly used in the field of Learning Analytics, but to reach students not always available on-site (e.g. during a pandemic), they have to be adapted to online-only context. Card-based tools are a common co-design method to collect users' needs, but this tangible format limits data collection and usage. We propose here two steps: first to use an existing co-design card deck-based method for our university context and next to adapt this new method called PADDLE (PArticipative Design of Dashboard for Learning in Education) for an online use. This article presents key factors and points of attention identified in adapting a card-based co-design method into a digital version for designing learning dashboards. This digital adaptation and the associated tool, ePADDLE, were tested with first year university students divided into 18 groups (N = 58). All groups have successfully designed a dashboard, and using the original evaluation scales, users have evaluated ePADDLE as almost as suitable as the original method. Thanks to the traces provided by the online version, we rely on speech acts to identify favorable conditions for successful collaboration. © 2021 Virtual Simulation Innovation Workshop, SIW 2021. All rights reserved.},
	author_keywords = {Cards; Co-Design; Learning analytics dashboard; Participatory design},
	keywords = {E-learning; Learning systems; Card; Co-designs; Codesign method; Data collection; Data usage; Design approaches; Learning analytic dashboard; Participative designs; Participatory design; User need; Design},
	publisher = {IADIS Press},
	isbn = {978-989870433-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Cuadros2021524,
	author = {Cuadros, Jordi and Serrano, Vanessa and Lluch, Francesc and Garcia-Zubia, Javier and Hernandez-Jayo, Unai},
	title = {Mapping VISIR Circuits for Computer-assisted Assessment},
	year = {2021},
	journal = {Proceedings of 2021 World Engineering Education Forum/Global Engineering Deans Council, WEEF/GEDC 2021},
	pages = {524 – 527},
	doi = {10.1109/WEEF/GEDC53299.2021.9657349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124807681&doi=10.1109%2fWEEF%2fGEDC53299.2021.9657349&partnerID=40&md5=5338b1119a257e2e37db8a3873d3b313},
	affiliations = {Iqs Universitat Ramon Llull, Barcelona, Spain; University of Deusto, Faculty of Engineering, Bilbao, Spain},
	abstract = {Virtual Instrument Systems in Reality (VISIR) is a remote laboratory for electrical circuits currently used worldwide. Work is in progress to develop a functional learning analytics tool, the VISIR dashboard (VISIR-DB), that may be useful to instructors and researchers. Explaining what a VISIR circuit is and how to map different circuits that share the same experimental goal is therefore key. This paper presents the issue of circuit identification in VISIR and proposes some algorithms to organize the different experiments users can perform.  © 2021 IEEE.},
	author_keywords = {assessment; learning analytics; remote lab; VISIR},
	keywords = {Computer aided instruction; E-learning; Analytic tools; Assessment; Circuit identification; Computer-assisted assessments; Electrical circuit; Learning analytic; Remote laboratories; Remote labs; Virtual instrument system in reality; Virtual instrument systems; Timing circuits},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542488-2},
	language = {English},
	abbrev_source_title = {Proc. World Eng. Educ. Forum/Glob. Eng. Deans Counc., WEEF/GEDC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Vázquez-Ingelmo2021,
	author = {Vázquez-Ingelmo, Andrea and García-Peñalvo, Francisco José and Therón, Roberto},
	title = {Towards a technological ecosystem to provide information dashboards as a service: A dynamic proposal for supplying dashboards adapted to specific scenarios},
	year = {2021},
	journal = {Applied Sciences (Switzerland)},
	volume = {11},
	number = {7},
	doi = {10.3390/app11073249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104088989&doi=10.3390%2fapp11073249&partnerID=40&md5=0581e32a0b99691e697c28139ca07310},
	affiliations = {GRIAL Research Group, Computer Science Department, University of Salamanca, Salamanca, 37008, Spain; VisUSAL, Computer Science Department, University of Salamanca, Salamanca, 37008, Spain},
	abstract = {Abstract: Data are crucial to improve decision-making and obtain greater benefits in any type of activity. However, the large amount of information generated by new technologies has made data analysis and knowledge generation a complex task. Numerous tools have emerged to facilitate this generation of knowledge, such as dashboards. Although dashboards are useful tools, their effectiveness can be affected by poor design or by not taking into account the context in which they are placed. Therefore, it is necessary to design and create custom dashboards according to the audience and data domain. This paper presents an application of the software product line paradigm and the integration of this approach into a web service to allow users to request source code for customized information dashboards. The main goal is to introduce the idea of creating a holistic ecosystem of different services to craft and integrate information visualizations in a variety of contexts. One of the contexts that can be especially favored by this approach is the educational context, where learning analytics, data analysis of student performance, and didactic tools are becoming very relevant. Three different use cases of this approach are presented to illustrate the benefits of the developed generative service. © 2021 by the authors.},
	author_keywords = {Code generation; Dashboard ecosystem; Data visualization; Information dashboards; Metamodeling; Visualization goals; Visualization tasks},
	correspondence_address = {A. Vázquez-Ingelmo; GRIAL Research Group, Computer Science Department, University of Salamanca, Salamanca, 37008, Spain; email: andreavazquez@usal.es},
	publisher = {MDPI AG},
	issn = {20763417},
	language = {English},
	abbrev_source_title = {Appl. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Joseph-Richard2021243,
	author = {Joseph-Richard, Paul and Uhomoibhi, James and Jaffrey, Andrew},
	title = {Predictive learning analytics and the creation of emotionally adaptive learning environments in higher education institutions: a study of students' affect responses},
	year = {2021},
	journal = {International Journal of Information and Learning Technology},
	volume = {38},
	number = {2},
	pages = {243 – 257},
	doi = {10.1108/IJILT-05-2020-0077},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102182640&doi=10.1108%2fIJILT-05-2020-0077&partnerID=40&md5=badb6e8041ff4bf4bfbc7a5aaf4360f6},
	affiliations = {Department of Management, Leadership and Marketing, Ulster University Business School, Newtownabbey, United Kingdom; Faculty of Computing and Engineering, University of Ulster, Newtownabbey, United Kingdom; Centre for Digital Learning, Ulster University – Jordanstown Campus, Newtownabbey, United Kingdom},
	abstract = {Purpose: The aims of this study are to examine affective responses of university students when viewing their own predictive learning analytics (PLA) dashboards, and to analyse how those responses are perceived to affect their self-regulated learning behaviour. Design/methodology/approach: A total of 42 Northern Irish students were shown their own predicted status of academic achievement on a dashboard. A list of emotions along with definitions was provided and the respondents were instructed to verbalise them during the experience. Post-hoc walk-through conversations with participants further clarified their responses. Content analysis methods were used to categorise response patterns. Findings: There is a significant variation in ways students respond to the predictions: they were curious and motivated, comforted and sceptical, confused and fearful and not interested and doubting the accuracy of predictions. The authors show that not all PLA-triggered affective states motivate students to act in desirable and productive ways. Research limitations/implications: This small-scale exploratory study was conducted in one higher education institution with a relatively small sample of students in one discipline. In addition to the many different categories of students included in the study, specific efforts were made to include “at-risk” students. However, none responded. A larger sample from a multi-disciplinary background that includes those who are categorised as “at-risk” could further enhance the understanding. Practical implications: The authors provide mixed evidence for students' openness to learn from predictive learning analytics scores. The implications of our study are not straightforward, except to proceed with caution, valuing benefits while ensuring that students' emotional well-being is protected through a mindful implementation of PLA systems. Social implications: Understanding students' affect responses contributes to the quality of student support in higher education institutions. In the current era on online learning and increasing adaptation to living and learning online, the findings allow for the development of appropriate strategies for implementing affect-aware predictive learning analytics (PLA) systems. Originality/value: The current study is unique in its research context, and in its examination of immediate affective states experienced by students who viewed their predicted scores, based on their own dynamic learning data, in their home institution. It brings out the complexities involved in implementing student-facing PLA dashboards in higher education institutions. © 2021, Emerald Publishing Limited.},
	author_keywords = {Affect responses; Emotional learning analytics; Emotions; Predictive learning analytics},
	correspondence_address = {P. Joseph-Richard; Department of Management, Leadership and Marketing, Ulster University Business School, Newtownabbey, United Kingdom; email: p.joseph-richard@ulster.ac.uk},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {20564880},
	language = {English},
	abbrev_source_title = {Int. J. Inf. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}@ARTICLE{2020,
	title = {21st International Conference on Artificial Intelligence in Education, AIED 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12163 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089503148&partnerID=40&md5=c1630a5696cc4b257fc0acc860144128},
	abstract = {The proceedings contain 123 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: Modeling the relationships between basic and achievement emotions in computer-based learning environments; Analysis of task difficulty sequences in a simulation-based POE environment; affective sequences and student actions within reasoning mind; Helping teachers help their students: A human-AI hybrid approach; comprehensive views of math learners: A case for modeling and supporting non-math factors in adaptive math software; exploring the impact of simple explanations and agency on batch deep reinforcement learning induced pedagogical policies; recommending insightful drill-downs based on learning processes for learning analytics dashboards; introducing a framework to assess newly created questions with natural language processing; using thinkalouds to understand rule learning and cognitive control mechanisms within an intelligent tutoring system; remember the facts? Investigating answer-aware neural question generation for text comprehension; raising teachers empowerment in gamification design of adaptive learning systems: A qualitative research; far from success – Far from feedback acceptance? The influence of game performance on young students’ willingness to accept critical constructive feedback during play; robust neural automated essay scoring using item response theory; supporting teacher assessment in Chinese language learning using textual and tonal features; Early detection of wheel-spinning in ASSISTments; investigating differential error types between human and simulated learners; studying the interactions between science, engineering, and computational thinking in a learning-by-modeling environment; exploring automated question answering methods for teaching assistance; detecting off-task behavior from student dialogue in game-based collaborative learning; preface; student dropout prediction.},
	editor = {Bittencourt I.I. and Cukurova M. and Luckin R. and Muldner K. and Millán E.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303052236-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Fleur2020411,
	author = {Fleur, Damien S. and van den Bos, Wouter and Bredeweg, Bert},
	title = {Learning analytics dashboard for motivation and performance},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12149 LNCS},
	pages = {411 – 419},
	doi = {10.1007/978-3-030-49663-0_51},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086265178&doi=10.1007%2f978-3-030-49663-0_51&partnerID=40&md5=88edecfa788ea828a11e97b641ed157a},
	affiliations = {Informatics Institute, University of Amsterdam, Amsterdam, Netherlands; Department of Psychology, University of Amsterdam, Amsterdam, Netherlands; Center for Adaptive Rationality, Max Planck Institute for Human Development, Berlin, Germany; Amsterdam University of Applied Sciences, Amsterdam, Netherlands},
	abstract = {Deploying Learning Analytics that significantly improve learning outcomes remains a challenge. Motivation has been found to be related to academic achievement and is argued to play an essential role in efficient learning. We developed a Learning Analytics dashboard and designed an intervention that relies on goal orientation and social comparison. Subjects can see a prediction of their final grade in a course as well as how they perform in comparison to classmates with similar goal grades. Those with access to the dashboard ended up more motivated than those without access, outperformed their peers as the course progressed and achieved higher final grades. Our results indicate that learner-oriented dashboards are technically feasible and may have tangible benefits for learners. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Goal orientation; Learning Analytics; Motivation; Social comparison},
	keywords = {Computer aided instruction; Motivation; Academic achievements; Efficient learning; Goal orientations; Learning outcome; Motivation and performance; Intelligent vehicle highway systems},
	correspondence_address = {D.S. Fleur; Informatics Institute, University of Amsterdam, Amsterdam, Netherlands; email: d.s.fleur@uva.nl},
	editor = {Kumar V. and Troussas C.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303049662-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@BOOK{Kokoç201955,
	author = {Kokoç, Mehmet and Altun, Arif},
	title = {Building a Learning Experience: What Do Learners’ Online Interaction Data Imply?},
	year = {2019},
	journal = {Learning Technologies for Transforming Large-Scale Teaching, Learning, and Assessment},
	pages = {55 – 70},
	doi = {10.1007/978-3-030-15130-0_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098569583&doi=10.1007%2f978-3-030-15130-0_4&partnerID=40&md5=79ca56b8c336de4809e9b0addecce595},
	affiliations = {Department of Computer Education and Instructional Technologies, Fatih Faculty of Education, Trabzon University, Trabzon, Turkey; Department of Computer Education and Instructional Technologies, College of Education, Hacettepe University, Ankara, Turkey},
	abstract = {It is still under debate whether learners’ interaction data within e-learning and/or open learning environments could be considered as reflections of their learning experiences to be effective or not. Therefore, it is meaningful to explore the nature of these interactions and to make meaningful conclusions. The purpose of this study is to model learners’ learning experiences based on their interaction data in an LMS. The study was designed to understand the nature of interactions and to observe whether interaction types display an observable meaningful pattern. For this purpose, a course titled Computer Networks and Communication was designed and taught in a learning management system, where learners could receive real-time responses and monitor their process through dashboards as recommendations for their learning process. Thirty-one metrics were gathered from database records, which yielded a common factor with six subfactors, where the highest correlation was between learners-learning dashboards interactions and learners-learning objects. In addition, this factorial structure could be considered a holistic view of a learning experience based on the interaction data within a learning management system. Another finding of this study indicated that learners’ interaction with learning dashboards had been a meaningful dimension of their overall learning experiences. The results of this study present instructional design cues and pedagogical outcomes. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Interaction; Interaction data; Learning analytics; Online learning behaviors; Online learning experience},
	correspondence_address = {M. Kokoç; Department of Computer Education and Instructional Technologies, Fatih Faculty of Education, Trabzon University, Trabzon, Turkey; email: kokoc@trabzon.edu.tr},
	publisher = {Springer International Publishing},
	isbn = {978-303015130-0; 978-303015129-4},
	language = {English},
	abbrev_source_title = {Learning Technologies for Transforming Large-Scale Teach., Learning, and Assess.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Lim2019250,
	author = {Lim, Lisa and Joksimović, Srećko and Dawson, Shane and Gašević, Dragan},
	title = {Exploring students' sensemaking of learning analytics dashboards: Does frame of reference make a difference?},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {250 – 259},
	doi = {10.1145/3303772.3303804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062768674&doi=10.1145%2f3303772.3303804&partnerID=40&md5=7ee8a64f56aa710516104cd393fd05d0},
	affiliations = {School of Education, University of South Australia, Australia; School of Education and Teaching Innovation Unit, University of South Australia, Australia; Teaching Innovation Unit, University of South Australia, Australia; Faculty of Education, Monash University, Melbourne, VIC, Australia; School of Informatics, University of Edinburgh Edinburgh, United Kingdom},
	abstract = {Learning Analytics Dashboards (LAD) are becoming an increasingly popular way to provide students with personalised feedback. Despite the number of LADs being developed, significant research gaps exist around the student perspective, especially how students make sense of graphics provided in LADs, and how they intend to act on the feedback provided therein. This study employed a randomized-controlled trial to examine students' sense-making of LADs showing four different frames of reference, and to what extent the impact of LADs was mediated by baseline self-regulation. Using a mix of quantitative and qualitative data analysis, the results revealed rather distinct patterns in students' sense-making across the four LADs. These patterns involved the intersection of visual salience and planned learning actions. However, collectively, across all four LADs a consistent theme emerged around students planned learning actions. This theme was classified as time and study environment management. A key finding of the study is that the use of LADs as a primary feedback process should be personalized and include training and support to aid student sensemaking. © 2019 Association for Computing Machinery.},
	author_keywords = {Epistemic network analysis; Learning dashboards; Sensemaking; Social comparison},
	keywords = {Feedback; Environment management; Frames of reference; Learning dashboards; Qualitative data analysis; Randomized controlled trial; Sensemaking; Social comparison; Student perspectives; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036256-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@CONFERENCE{Er2020113,
	author = {Er, Erkan},
	title = {Self and peer monitoring during peer feedback: The instructor perspective},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2671},
	pages = {113 – 120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092053490&partnerID=40&md5=eb9b8c9874dc2b83d847c2f71a9dcda7},
	affiliations = {School of Telecommunication Engineering, Universidad de Valladolid, Spain},
	abstract = {Monitoring is a crucial skill that can trigger regulation of learning for achieving better learning outcomes. While monitoring the self can enhance selfregulation, monitoring peers in collaborative activities can support co-regulation. Student-facing dashboards have been often used to support monitoring. These dashboards intend to provide students with timely feedback on how well they are doing, which then is expected to be used by the students to evaluate their progress and update their learning strategies as needed. This study investigates instructors' perspective about self and peer monitoring enabled via a student-facing dashboard in the specific context of peer reviews, which is an underexplored area of research. The findings suggest that although instructors consider that the proposed approach to monitoring can hold potential to enhance students' (both self- and co-) regulation of learning, they acknowledge that the activation of regulation in real-world practice might be a challenge. Implications for the activity design and learning analytics support are discussed. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Peer feedback; Peer-monitoring; Regulation of learning; Self-monitoring; Student-facing dashboards},
	keywords = {Facings; Students; Co-regulation; Collaborative activities; Learning outcome; Learning strategy; Peer feedback; Peer monitoring; Real-world practice; Timely feedback; Monitoring},
	correspondence_address = {E. Er; School of Telecommunication Engineering, Universidad de Valladolid, Spain; email: erkan@gsic.uva.es},
	editor = {Martinez-Mones A. and Universidad de Valladolid, Department of Computer Science, Campus Miguel Delibes, Valladolid and Alvarez A. and Universidad del Pais Vasco UPV/EHU, Department of Computer Languages and Systems, Paseo Manuel Lardizabal 1, Donostia, Gipuzkoa and Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Dimitriadis Y. and Universidad de Valladolid, Department of Theory of Signal and Communications and Telematics Engineering, Campus Miguel Delibes, Valladolid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Matcha2020226,
	author = {Matcha, Wannisa and Uzir, Noraayu Ahmad and Gasevic, Dragan and Pardo, Abelardo},
	title = {A Systematic Review of Empirical Studies on Learning Analytics Dashboards: A Self-Regulated Learning Perspective},
	year = {2020},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {13},
	number = {2},
	pages = {226 – 245},
	doi = {10.1109/TLT.2019.2916802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087489008&doi=10.1109%2fTLT.2019.2916802&partnerID=40&md5=e91f2bdafed292e0e2e4b13ee98f6e2f},
	affiliations = {School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; Faculty of Information Technology, Monash University, Clayton, 3800, VIC, Australia; Division of Information Technology Engineering and Environment, University of South Australia, Adelaide, 5000, SA, Australia},
	abstract = {This paper presents a systematic literature review of learning analytics dashboards (LADs) research that reports empirical findings to assess the impact on learning and teaching. Several previous literature reviews identified self-regulated learning as a primary focus of LADs. However, there has been much less understanding how learning analytics are grounded in the literature on self-regulated learning and how self-regulated learning is supported. To address this limitation, this review analyzed the existing empirical studies on LADs based on the well-known model of self-regulated learning proposed by Winne and Hadwin. The results show that existing LADs are rarely grounded in learning theory, cannot be suggested to support metacognition, do not offer any information about effective learning tactics and strategies, and have significant limitations in how their evaluation is conducted and reported. Based on the findings of the study and through the synthesis of the literature, the paper proposes that future research and development should not make any a priori design decisions about representation of data and analytic results in learning analytics systems such as LADs. To formalize this proposal, the paper defines the model for user-centered learning analytics systems (MULAS). The MULAS consists of the four dimensions that are cyclically and recursively interconnected including: theory, design, feedback, and evaluation. © 2008-2011 IEEE.},
	author_keywords = {Dashboards; empirical research; feedback; information visualization; learning analytics; self-regulated learning},
	keywords = {E-learning; Engineering; Effective learning; Empirical findings; Empirical studies; Learning and teachings; Literature reviews; Research and development; Self-regulated learning; Systematic literature review; Learning systems},
	correspondence_address = {D. Gasevic; Faculty of Information Technology, Monash University, Clayton, 3800, Australia; email: dragan.gasevic@monash.edu},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 267}
}

@CONFERENCE{Pastushenko201947,
	author = {Pastushenko, Olena},
	title = {Gamification in assignments: Using dynamic difficulty adjustment and learning analytics to enhance education},
	year = {2019},
	journal = {CHI PLAY 2019 - Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play},
	pages = {47 – 53},
	doi = {10.1145/3341215.3356335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074809535&doi=10.1145%2f3341215.3356335&partnerID=40&md5=bf764f14b7cbb211b4df239a41302161},
	affiliations = {Brno University of Technology, IT4Innovations Centre of Excellence, Brno, 61266, Czech Republic},
	abstract = {This paper discusses the opportunities for gamification and dynamic difficulty adjustment based on multimodal learning analytics in assignments. Altogether this covers a broader term of personalized education, which is getting more attention among the researchers in recent years. The difference of this work from other similar researches is that it suggests combining several domains to achieve better results: gamification (in order to improve student’s motivation and involvements), and dynamic difficulty adjustment. All this is made possible by applying multimodal learning analytics and creating useful learning dashboards for the teachers. Copyright held by the owner/author(s).},
	author_keywords = {Dynamic difficulty adjustment; Gamification; Multimodal learning analytics; Personalized learning},
	keywords = {Interactive computer systems; Gamification; Multi-modal learning; Personalized learning; Human computer interaction},
	correspondence_address = {O. Pastushenko; Brno University of Technology, IT4Innovations Centre of Excellence, Brno, 61266, Czech Republic; email: ipastushenko@fit.vut.cz},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036871-1},
	language = {English},
	abbrev_source_title = {CHI PLAY - Ext. Abstr. Annu. Symp. Comput.-Hum. Interact. Play},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Macarini2020166,
	author = {Macarini, Luiz Antonio and Lemos dos Santos, Henrique and Cechinel, Cristian and Ochoa, Xavier and Rodés, Virgínia and Pérez Casas, Alén and Lucas, Pedro Pablo and Maya, Ricardo and Alonso, Guillermo Ettlin and Díaz, Patricia},
	title = {Towards the implementation of a countrywide K-12 learning analytics initiative in Uruguay},
	year = {2020},
	journal = {Interactive Learning Environments},
	volume = {28},
	number = {2},
	pages = {166 – 190},
	doi = {10.1080/10494820.2019.1636082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068677488&doi=10.1080%2f10494820.2019.1636082&partnerID=40&md5=eaac2be2951b721d8e8ff50c3e551e58},
	affiliations = {Coordenadoria Especial Interdisciplinar de Tecnologias da Informação e Comunicação, Universidade Federal de Santa Catarina, Araranguá, Brazil; Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil; New York University Steinhardt School of Culture Education and Human Development, New York, NY, United States; Programa de Entornos Virtuales de Aprendizaje, Comisión Sectorial de Enseñanza, Universidad de la Republica, Montevideo, Uruguay; Escuela Superior Politecnica del Litoral, Guayaquil, Ecuador; Departamento de Tecnologías Digitales, Consejo de Formación en Educación, Administracion Nacional de Educacion Publica, Montevideo, Uruguay},
	abstract = {The present work describes the challenges faced during the development of a countrywide Learning Analytics study and tool focused on tracking and understanding the trajectories of Uruguayan students during their first three years of secondary education. Due to the large scale of the project, which covers an entire national educational system, several challenges and constraints were faced during its conception and development. Examples of key challenges were: to understand the different nuances of the educational system, to satisfy ethical and legal requirements without narrowing down the scope and potential novelty of the initiative and to deal with integration and inconsistencies in the databases. This paper presents the design decisions and solutions found to address or mitigate the problems found as a contribution to facilitate similar large-scale projects. Three main experiments using data mining were conducted and their results are also described, pointing out the feasibility of finding meaningful patterns that can be used by educational authorities to improve their decision making and foster public educational policies. Finally, the paper describes the use of the data and the findings of the study to create an interactive visual tool to explore the relationship between student variables, performance and persistence in the system. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Academic trajectory; dashboard; educational data mining; learning analytics; secondary education; visualization},
	correspondence_address = {L.A. Macarini; Coordenadoria Especial Interdisciplinar de Tecnologias da Informação e Comunicação, Universidade Federal de Santa Catarina, Araranguá, Brazil; email: luiz.buschetto@posgrad.ufsc.br},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Jayashanka201969,
	author = {Jayashanka, Rangana and Hewagamage, K.P. and Hettiarachchi, E.},
	title = {An intelligent interactive visualizer to improve blended learning in higher education},
	year = {2019},
	journal = {Proceedings - 2019 12th International Conference on Ubi-Media Computing, Ubi-Media 2019},
	pages = {69 – 73},
	doi = {10.1109/Ubi-Media.2019.00022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083462514&doi=10.1109%2fUbi-Media.2019.00022&partnerID=40&md5=7a9dd514a47e65d690bd138e2e781772},
	affiliations = {University of Colombo, School of Computing, Colombo, 07, Sri Lanka},
	abstract = {Universities tend to design, create and evaluate new learning activities to enhance the learning environment for both students and teachers. Furthermore, higher educational institutes are finding solutions to create more personalized learning environments. There is an opportunity to improve the learning environment by applying Learning Analytics to educational data generated by learners interacting with Virtual Learning Environments (VLEs) and other digital learning tools. More personalized learning environments can be implemented by applying Learning Analytics on Learning Designs. Students' learning progress can be captured through Learning Dashboards in real-time by applying Learning Analytics during the course run-time. We can improve Blended Learning through the synergy between Learning Analytics and Learning Design. This paper provides an outline of a research project which aims to link Learning Design with Learning Analytics in order to enhance the learning environments and improve both teachers and student satisfaction. The paper provides the proposed framework of a Digital Learning Tool (Intelligent Interactive Visualizer) and sets out the program of research and development. The expected outcomes of the research project also discussed. © 2019 IEEE.},
	author_keywords = {Higher education; Learning analytics; Learning design; Technology enhanced learning},
	keywords = {Computer aided instruction; Students; Educational Institutes; Finding solutions; Learning environments; Learning progress; Personalized learning environments; Research and development; Student satisfaction; Virtual learning environments (VLEs); E-learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172812820-7},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Ubi-Media Comput., Ubi-Media},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Cao2019372,
	author = {Cao, Jiaxin and Song, Yanjie},
	title = {Beyond just following data: How does visualization strategy facilitate learning analytics design?},
	year = {2019},
	journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
	volume = {1},
	pages = {372 – 374},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077716570&partnerID=40&md5=d10b1ec6b2ec785e2b374f2a2b46504c},
	affiliations = {Department of Mathematics and Information Technology, Education University of Hong Kong, Hong Kong},
	abstract = {In this poster, we reviewed 38 articles on learning analytics research, focusing on the data visualization interface designs. After examining the original ideas their interface design, a new visualization strategy was proposed to categorize and characterize them premised on their principles and approaches in four types, namely, (1) directly-presented, (2) outcome-oriented, (3) process-oriented, and (4) theory-oriented. Then, how these types of the visualization strategy could help facilitate learning analytics design and make data interpretable by users was presented. © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
	author_keywords = {Design principle; Learning analytics; Learning dashboard; Visualization strategy},
	keywords = {Visualization; Design Principles; Interface designs; Learning analytics; Learning dashboard; Process-oriented; Data visualization},
	correspondence_address = {J. Cao; Department of Mathematics and Information Technology, Education University of Hong Kong, Hong Kong; email: jxcao@s.eduhk.hk},
	editor = {Chang M. and So H.-J. and Wong L.-H. and Yu F.-Y. and Shih J.-L. and Boticki I. and Chen M.-P. and Dewan A. and Haklev S. and Koh E. and Kojiri T. and Li K.-C. and Sun D. and Wen Y.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972143-1},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Martinez-Maldonado2019413,
	author = {Martinez-Maldonado, Roberto},
	title = {Correction to: A handheld classroom dashboard: teachers’ perspectives on the use of real-time collaborative learning analytics (International Journal of Computer-Supported Collaborative Learning, (2019), 14, 3, (383-411), 10.1007/s11412-019-09308-z)},
	year = {2019},
	journal = {International Journal of Computer-Supported Collaborative Learning},
	volume = {14},
	number = {3},
	pages = {413 – 414},
	doi = {10.1007/s11412-019-09314-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076026001&doi=10.1007%2fs11412-019-09314-1&partnerID=40&md5=8c192d7f462049db9471eaf8d11c4293},
	affiliations = {Faculty of Information Technologies, Monash University, Melbourne, VIC, Australia},
	abstract = {The original version of this article unfortunately contained duplicate images for Figs. 4 and 6. The correct images are hereby published. © 2019, International Society of the Learning Sciences, Inc.},
	correspondence_address = {R. Martinez-Maldonado; Faculty of Information Technologies, Monash University, Melbourne, Australia; email: Roberto.MartinezMaldonado@Monash.edu},
	publisher = {Springer},
	issn = {15561607},
	language = {English},
	abbrev_source_title = {Int. J. Comput.-Supported Collab. Learn.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20201689,
	author = {Chen, Yuxin and Saleh, Asmalina and Hmelo-Silver, Cindy E. and Glazewski, Krista and Mott, Bradford W. and Lester, James C.},
	title = {Supporting collaboration: From learning analytics to teacher dashboards},
	year = {2020},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {3},
	pages = {1689 – 1692},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102920178&partnerID=40&md5=d718fa66efdd86c48b60ba27dd9f910b},
	affiliations = {Indiana University, United States; North Carolina State University, United States},
	abstract = {Designing embedded teacher-support structures within computer-supported collaborative learning environments is key to successful facilitation of group collaboration. Previous work has designed and examined various orchestration tools for teachers facilitating groups of learners, including the integration of a data visualization dashboard for teachers to simultaneously monitor multiple classroom groups. However, few studies have investigated to what extent and which supports are needed to monitor groups while students engage in a game-based collaborative learning environment. This paper proposes a theory-driven design framework for building teacher dashboards and examines the specific functions and design features needed. © ISLS.},
	author_keywords = {Collaborative inquiry; Game-based learning; Learning analytics; Teacher dashboard},
	keywords = {Data visualization; Computer supported collaborative learning environments; Design features; Design frameworks; Game-based collaborative learning; Group collaboration; Support structures; Computer aided instruction},
	editor = {Gresalfi M. and Horn I.S.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-173246727-9},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2020,
	title = {7th International Conference on Learning and Collaboration Technologies, LCT 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12205 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089160143&partnerID=40&md5=0b4403462778b0052a8720eb0ddf2c06},
	abstract = {The proceedings contain 86 papers. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Reflective Journaling: A Theoretical Model and Digital Prototype for Developing Resilience and Creativity; prototyping a Touch-Optimized Modeling Tool for Co-located and Inverted Classroom Group Modeling Scenarios; evaluating Portable Touch Projectors in the Context of Digital Education; STEAM-X: An Exploratory Study Adding Interactive Physical Activity to the STEAM Model; usability Testing of a Digital Competence Assessment and Certification System; designing ‘Embodied’ Science Learning Experiences for Young Children; impact of Constant Work on the Students’ Academic Performance; Learning Analytics and MOOCs; on the Design of a Teachers’ Dashboard: Requirements and Insights; evaluation of the Virtual Mobility Learning Hub; mudpoint: Evaluating Instructor Perception on a Continuous and Non-specific Feedback System; characterization of Learners from Their Learning Activities on a Smart Learning Platform; AI-Driven Assessment of Students: Current Uses and Research Trends; generating Dashboards Using Fine-Grained Components: A Case Study for a PhD Programme; learning Analytics and Spelling Acquisition in German – The Path to Individualization in Learning; Building Student Interactions Outside the Classroom: Utilizing a Web-Based Application in a University Flipped Learning Course for EFL Learners; the Impact of Corpus Linguistics on Language Teaching in Russia’s Educational Context: Systematic Literature Review; framework of Manga Application for Teaching Japanese Language; Individualized Differentiated Spelling with Blogs - Implementing and Individualizing (IDeRBlog ii): An Example of a Learning Analytics Platform for the Text-Based Acquisition of Spelling Skills of Students in German.},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050512-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ramaswami2019,
	author = {Ramaswami, Gomathy Suganya and Susnjak, Teo and Mathrani, Anuradha},
	title = {Capitalizing on Learning Analytics Dashboard for Maximizing Student Outcomes},
	year = {2019},
	journal = {2019 IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2019},
	doi = {10.1109/CSDE48274.2019.9162357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094644634&doi=10.1109%2fCSDE48274.2019.9162357&partnerID=40&md5=53292291666f2d1ff6b31cbb48ca41dc},
	affiliations = {School of Natural and Computational Studies, Massey University, Auckland, New Zealand},
	abstract = {With ongoing advancements in technology enabled learning, an opportunity has risen for educators to enhance student learning with use of Learning Analytics. Educational institutions are using Learning Analytics Dashboards (LAD) to provide students with timely and personalized feedback in visual format. LAD use advanced analytical capabilities that capitalize on online learner activities that are extracted from log files. They provide data-driven insights on current learning contexts and inform management on any learning intervention strategies that may be needed to support students in achieving their learning outcomes. Besides students, the perspective of instructors too is considered. Using easy-to-read graphical reporting formats (e.g., line graphs, scatter plot, bar charts, etc.), the LAD reveals a consolidated view of how online learning is taking place. In this manner, a snapshot depicting details of student learning patterns can enable instructors to monitor their students' learning strategies. At the same time, the LAD assists students too by providing them with a personalized environment to help them engage better with the learning outcomes. Therefore, LAD is increasingly used as a pedagogical approach to motivate students and help build their self-learning capacity. In this study, we propose to develop a real-time dashboard that pulls online student data from various sources including a learning management system (Moodle), University's library and from the student management system (SMS) that is used by the staff.  © 2019 IEEE.},
	author_keywords = {dashboard; feedback; learning dashboard; student feedback system; visualization tool},
	keywords = {Advanced Analytics; Graph theory; Human resource management; Information management; Learning systems; Students; Educational institutions; Intervention strategy; Learning management system; Pedagogical approach; Personalized feedback; Real-time dashboards; Student management; Technology-enabled learning; Engineering education},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816303-1},
	language = {English},
	abbrev_source_title = {IEEE Asia-Pacific Conf. Comput. Sci. Data Eng., CSDE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{de Laet2020316,
	author = {de Laet, Tinne and Broos, Tom and Pinxten, Maarten and van Soom, Carolien and Langie, Greet},
	title = {Closing the feedback loop in the transition from secondary to higher education},
	year = {2020},
	journal = {SEFI 47th Annual Conference: Varietas Delectat... Complexity is the New Normality, Proceedings},
	pages = {316 – 327},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077820275&partnerID=40&md5=c95b42532e63f1d48284aecc7dac4693},
	affiliations = {Leuven Engineering and Science Education Center (LESEC), KU Leuven, Leuven, Belgium; Department of Computer Science and LESEC, KU Leuven, Leuven, Belgium; Faculty Engineering Technology and LESEC, KU Leuven, Leuven, Belgium},
	abstract = {Against the background of the increasing need for skilled scientists and engineers, any hurdle in the study career of engineering students is undesired. One of the most important hurdles is the transition from secondary to higher education. The situation at faculty of Engineering Science at KU Leuven, the largest Flemish (Dutch-speaking part of Belgium) University, is not different. Even more, due to regional regulations, Flemish universities have to accept any student with a secondary education diploma into in the engineering bachelor program, even if the secondary education program does not provide the student with the required knowledge and competencies. The resulting heterogeneous inflow of students creates an additional challenge. During the last six years, researchers, educational staff and study advisors of the engineering science program of KU Leuven have collaborated to tackle this challenge. The concept paper will present the overarching ideas around the work that has been performed and provide pointers to the different supporting publications. Hereby, it will offer the unique opportunity for highlighting the connections between the work of our research team and the vision that underlies this work. This paper seeks to inspire practitioners and researcher in the engineering education field who focus on the transition from secondary to higher education. More specifically, the paper aims to share the underlying vision and shows how a close collaboration between practitioners and researchers can create an added value and impact on the engineering education field. © 2020 SEFI 47th Annual Conference: Varietas Delectat... Complexity is the New Normality, Proceedings. All rights reserved.},
	author_keywords = {Engineering education; Feedback; Learning analytics; Learning dashboards; Predictive models; Student success; Transition from secondary to higher education},
	keywords = {Education computing; Engineering education; Engineering research; Feedback; Predictive analytics; Professional aspects; Higher education; Learning analytics; Learning dashboards; Predictive models; Student success; Students},
	correspondence_address = {T. de Laet; Leuven Engineering and Science Education Center (LESEC), KU Leuven, Leuven, Belgium; email: tinne.delaet@kuleuven.be},
	editor = {Nagy B.V. and Murphy M. and Jarvinen H.-M. and Kalman A.},
	publisher = {European Society for Engineering Education (SEFI)},
	isbn = {978-287352018-2},
	language = {English},
	abbrev_source_title = {SEFI Annu. Conf.: Var. Delect.... Complex. New Norm., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shabaninejad202041,
	author = {Shabaninejad, Shiva and Khosravi, Hassan and Indulska, Marta and Bakharia, Aneesha and Isaias, Pedro},
	title = {Automated insightful drill-down recommendations for learning analytics dashboards},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {41 – 46},
	doi = {10.1145/3375462.3375539},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082402088&doi=10.1145%2f3375462.3375539&partnerID=40&md5=abdcc9181ac99cb521ba3e22758ee5af},
	affiliations = {University of Queensland, Brisbane, Australia},
	abstract = {The big data revolution is an exciting opportunity for universities, which typically have rich and complex digital data on their learners. It has motivated many universities around the world to invest in the development and implementation of learning analytics dashboards (LADs). These dashboards commonly make use of interactive visualisation widgets to assist educators in understanding and making informed decisions about the learning process.Acommon operation in analytical dashboards is a 'drill-down', which in an educational setting allows users to explore the behaviour of sub-populations of learners by progressively adding filters. Nevertheless, drill-down challenges exist, which hamper the most effective use of the data, especially by users without a formal background in data analysis. Accordingly, in this paper, we address this problem by proposing an approach that recommends insightful drill-downs to LAD users. We present results from an application of our proposed approach using an existing LAD. A set of insightful drill-down criteria from a course with 875 students are explored and discussed. © 2020 Copyright held by the owner/author(s).},
	author_keywords = {Decision trees; Drill-down analysis; Exploratory data analysis; Learning analytics dashboards},
	keywords = {Data handling; Decision trees; Infill drilling; Information analysis; Trees (mathematics); Digital datas; Drill-down; Educational settings; Exploratory data analysis; Informed decision; Interactive visualisation; Learning analytics dashboards; Sub-populations; Drills},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037712-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Anderson2019506,
	author = {Anderson, Khalil and Dubiel, Theodore and Tanaka, Kenji and Worsley, Marcelo},
	title = {Chemistry pods: A mutlimodal real time and retrospective tool for the classroom},
	year = {2019},
	journal = {ICMI 2019 - Proceedings of the 2019 International Conference on Multimodal Interaction},
	pages = {506 – 507},
	doi = {10.1145/3340555.3358662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074937982&doi=10.1145%2f3340555.3358662&partnerID=40&md5=16625ae6adac9643e05fcc45e7e5c033},
	affiliations = {Northwestern University, Evanston, IL, United States; Sony},
	abstract = {Instructors are often multitasking in the classroom. This makes it increasingly difficult for them to pay attention to each individual's engagement especially during activities where students are working in groups. In this paper, we describe a system that aids instructors in supporting group collaboration by utilizing a centralized, easy-to-navigate dashboard connected to multiple pods dispersed among groups of students in a classroom or laboratory. This allows instructors to check multiple qualities of the discussion such as: the usage of instructor specified keywords, relative participation of each individual, the speech acts students are using and different emotional characteristics of group language. © 2019 Copyright held by the owner/author(s).},
	author_keywords = {Audio processing; Collaboration; Learning analytics},
	keywords = {Interactive computer systems; Audio processing; Collaboration; Group collaboration; Learning analytics; Multiple quality; Real time; Speech acts; Students},
	editor = {Gao W. and Ling Meng H.M. and Turk M. and Fussell S.R. and Schuller B. and Schuller B. and Song Y. and Yu K.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036860-5},
	language = {English},
	abbrev_source_title = {ICMI - Proc. Int. Conf. Multimodal Interact.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Herodotou20193064,
	author = {Herodotou, Christothea and Hlosta, Martin and Boroowa, Avinash and Rienties, Bart and Zdrahal, Zdenek and Mangafa, Chrysoula},
	title = {Empowering online teachers through predictive learning analytics},
	year = {2019},
	journal = {British Journal of Educational Technology},
	volume = {50},
	number = {6},
	pages = {3064 – 3079},
	doi = {10.1111/bjet.12853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068837301&doi=10.1111%2fbjet.12853&partnerID=40&md5=15b72ae1bb272b1ccf9295c032106b69},
	affiliations = {Institute of Educational Technology, The Open University, United Kingdom; Knowledge Media Lab, The Open University, United Kingdom; Institute of Educational Technology, The Open University, United Kingdom; Knowledge Media Lab, The Open University, United Kingdom; Institute of Educational Technology, The Open University, United Kingdom},
	abstract = {This study presents an advanced predictive learning analytics system, OU Analyse (OUA), and evidence from its evaluation with online teachers at a distance learning university. OUA is a predictive system that uses machine learning methods for the early identification of students at risk of not submitting (or failing) their next assignment. Teachers have access, via interactive dashboards, to weekly predictions of risk of failing for each of their students. In this study, we examined how the degree of OUA usage by 559 teachers, of which 189 were given access to OUA, related to student learning outcomes of more than 14 000 students in 15 undergraduate courses. Teachers who made “average” use of OUA, that is accessed OUA throughout the life cycle of a course presentation, and in particular between 10% and 40% of the weeks a course was running, and intervened with students flagged as at risk were found to benefit their students the most; after controlling for differences in academic performance, these students were found to have significantly better performance than their peers in the previous year's course presentation during which the same teachers made no use of predictive learning analytics. Predictive learning analytics is an innovative student's support approach in online pedagogy that, as shown in this study, can empower online teachers in effectively monitoring and intervening with their students, over and above other approaches, and result in improved learning outcomes. Practitioner Notes What is already known about this topic Pedagogical and personal support to students is a significant responsibility of online teachers. Student's support is a challenging activity due to the lack of face-to-face interactions. Predictive learning analytics (PLA) can identify students at risk of failing their studies. What this paper adds One of the few large-scale studies is available for examining the impact of analytics on student's performance. Teachers' usage of PLA was significantly related to better learning outcomes. Online teachers had students with better learning outcomes when accessing PLA data rather than when they had no access. Implications for practice and/or policy PLA can empower online teachers and complement the teaching practice. PLA can help in the identification and proactive intervention of students at risk of failing their studies. Actions should be taken to motivate and engage online teachers with PLA. © 2019 British Educational Research Association},
	keywords = {E-learning; Learning systems; Life cycle; Predictive analytics; Teaching; Academic performance; Analytics systems; Learning outcome; Machine learning methods; Online pedagogy; Predictive systems; Student learning outcomes; Undergraduate Courses; Students},
	correspondence_address = {C. Herodotou; Institute of Educational Technology, The Open University, United Kingdom; email: Christothea.herodotou@open.ac.uk},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 77; All Open Access, Green Open Access}
}

@CONFERENCE{Cobos202061,
	author = {Cobos, Ruth and Soberón, Juan},
	title = {A proposal for monitoring the intervention strategy on the learning of MOOC learners},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2671},
	pages = {61 – 72},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092064681&partnerID=40&md5=3729f798a52cc650063d1dcafa7523db},
	affiliations = {Computer Science Department, Universidad Autónoma de Madrid, Spain},
	abstract = {Insufficient feedback and lack of interaction among instructors and learners affect negatively learner retention and engagement in MOOCs. These factors, paired with the feeling of isolation, have a high influence on learners who do not complete the course in which they have enrolled. To overcome this situation, we propose a system to provide periodically MOOC learners with visual information on a Web-based Learner Dashboard, showing them their progress and engagement in the MOOC. This provided information is part of an Intervention Strategy on the learning of these learners. The system offers MOOC instructors to access to a Web-based Instructor Dashboard that shows the interest in this service by the learners and, therefore, facilitates evaluating the success or failure of the Intervention Strategy. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Engagement; Feedback; Intervention; Learning Analytics; Learning Strategy; Massive Open Online Course; Web-based Technology},
	keywords = {Websites; Intervention strategy; Visual information; Web based; Learning systems},
	editor = {Martinez-Mones A. and Universidad de Valladolid, Department of Computer Science, Campus Miguel Delibes, Valladolid and Alvarez A. and Universidad del Pais Vasco UPV/EHU, Department of Computer Languages and Systems, Paseo Manuel Lardizabal 1, Donostia, Gipuzkoa and Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Dimitriadis Y. and Universidad de Valladolid, Department of Theory of Signal and Communications and Telematics Engineering, Campus Miguel Delibes, Valladolid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Park20191639,
	author = {Park, Yeonjeong and Jo, Il-Hyun},
	title = {Correction to: Factors that affect the success of learning analytics dashboards (Educational Technology Research and Development, (2019), 67, 6, (1547-1571), 10.1007/s11423-019-09693-0)},
	year = {2019},
	journal = {Educational Technology Research and Development},
	volume = {67},
	number = {6},
	pages = {1639},
	doi = {10.1007/s11423-019-09703-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070675117&doi=10.1007%2fs11423-019-09703-1&partnerID=40&md5=0aaca7943f4fbde395db7cc3f83e002e},
	affiliations = {Department of Early Childhood Education, College of Humanities and Social Sciences, Honam University, Gwangju, South Korea; Department of Educational Technology, College of Education, Ewha Womans University, Seoul, South Korea},
	abstract = {The Funding information provided in this article as published stands in need of correction. The correct information is: “This study was supported by research fund from Honam University, 2017”. Also note the current correct affiliation for author Yeonjeong Park: Department of Early Childhood Education, College of Humanities and Social Sciences, Honam University, Gwangju, South Korea. © 2019, Association for Educational Communications and Technology.},
	correspondence_address = {I.-H. Jo; Department of Educational Technology, College of Education, Ewha Womans University, Seoul, South Korea; email: ijo@ewha.ac.kr},
	publisher = {Springer},
	issn = {10421629},
	language = {English},
	abbrev_source_title = {Educ. Technol. Res. Dev.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Lu2020569,
	author = {Lu, Min and Chen, Li and Goda, Yoshiko and Shimada, Atsushi and Yamada, Masanori},
	title = {Visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12203 LNCS},
	pages = {569 – 580},
	doi = {10.1007/978-3-030-50344-4_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088742555&doi=10.1007%2f978-3-030-50344-4_41&partnerID=40&md5=66abab512436628e17055b7bceea2fb1},
	affiliations = {Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Kumamoto University, 2-39-1, Kurokami, Chuo-ku, Kumamoto, 8600862, Japan},
	abstract = {The existing researches and developments of dashboard visualizing results from learning analytics mainly serve the instructors instead of learners in a direct manner. Effective visualizations extracted from learning log data can help the students to reflect and compare studying activities and access their metacognition to improve their self-regulated learning. For such purposes, we designed a reading path graph for visualizing the studying activities on slide pages used as teaching materials in classes intuitively, as one of the key functions of the learning dashboard. By providing the comparisons between the user’s own situation and the class overview, the visualization is expected to motivate the further actions of using other tools of the learning dashboard and reflecting studies. This paper introduces our exploration of the data process flows of extracting necessary data from a large number of operational logs for the visualization, and the techniques and strategies applied for rendering the graphics effectively. We implemented the data processing module with Python3 and the web-based visualization module of the reading path graph with JavaScript based on D3.js considering the extensibilities. The issues engaged in the development of prototypes are discussed, which will lead to the improvement of future prototypes and better designs of user experiments for formative evaluations as the next step of this research. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Learning analytics; Learning dashboard; Self-regulated learning; Visualization},
	keywords = {Data handling; Data mining; Graph theory; Human computer interaction; Visualization; Formative evaluation; Meta cognitions; Metacognition; Processing modules; Self-regulated learning; Teaching materials; User experiments; Web-based visualization; Data visualization},
	correspondence_address = {M. Lu; Kyushu University, Fukuoka, 744, Motooka, Nishi-ku, 819-0395, Japan; email: lu@artsci.kyushu-u.ac.jp},
	editor = {Streitz N. and Konomi S.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050343-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Naranjo2019,
	author = {Naranjo, Diana M. and Prieto, José R. and Moltó, Germán and Calatrava, Amanda},
	title = {A visual dashboard to track learning analytics for educational cloud computing},
	year = {2019},
	journal = {Sensors (Switzerland)},
	volume = {19},
	number = {13},
	doi = {10.3390/s19132952},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069268181&doi=10.3390%2fs19132952&partnerID=40&md5=5767b929ff2201290f46cdec00f39d96},
	affiliations = {Instituto de Instrumentación para Imagen Molecular (I3M), Centro Mixto CSIC—Universitat Politècnica de València, Camino de Vera s/n, Valencia, 46022, Spain},
	abstract = {Cloud providers such as Amazon Web Services (AWS) stand out as useful platforms to teach distributed computing concepts as well as the development of Cloud-native scalable application architectures on real-world infrastructures. Instructors can benefit from high-level tools to track the progress of students during their learning paths on the Cloud, and this information can be disclosed via educational dashboards for students to understand their progress through the practical activities. To this aim, this paper introduces CloudTrail-Tracker, an open-source platform to obtain enhanced usage analytics from a shared AWS account. The tool provides the instructor with a visual dashboard that depicts the aggregated usage of resources by all the students during a certain time frame and the specific use of AWS for a specific student. To facilitate self-regulation of students, the dashboard also depicts the percentage of progress for each lab session and the pending actions by the student. The dashboard has been integrated in four Cloud subjects that use different learning methodologies (from face-to-face to online learning) and the students positively highlight the usefulness of the tool for Cloud instruction in AWS. This automated procurement of evidences of student activity on the Cloud results in close to real-time learning analytics useful both for semi-automated assessment and student self-awareness of their own training progress. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Cloud computing; Learning analytics; Learning dashboards; Visual learning analytics},
	keywords = {Automation; Cloud computing; Web services; Amazon web services; Application architecture; Automated assessment; Learning analytics; Learning dashboards; Open source platforms; Real-time learning; Visual learning; adult; article; autoregulation; awareness; case report; clinical article; cloud computing; female; human; human experiment; male; spatial learning; student; Students},
	correspondence_address = {D.M. Naranjo; Instituto de Instrumentación para Imagen Molecular (I3M), Centro Mixto CSIC—Universitat Politècnica de València, Valencia, Camino de Vera s/n, 46022, Spain; email: dnaranjo@i3m.upv.es},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {31277463},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Kia2020340,
	author = {Kia, Fatemeh Salehian and Teasley, Stephanie D. and Hatala, Marek and Karabenick, Stuart A. and Kay, Matthew},
	title = {How patterns of students dashboard use are related to their achievement and self-regulatory engagement},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {340 – 349},
	doi = {10.1145/3375462.3375472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082384274&doi=10.1145%2f3375462.3375472&partnerID=40&md5=423ef3db18de7286f04fecca099e432c},
	affiliations = {Simon Fraser University, University of Michigan, United States},
	abstract = {The aim of student-facing dashboards is to support learning by providing students with actionable information and promoting selfregulated learning. We created a new dashboard design aligned with SRL theory, called MyLA, to better understand how students use a learning analytics tool. We conducted sequence analysis on students' interactions with three different visualizations in the dashboard, implemented in a LMS, for a large number of students (860) in ten courses representing different disciplines. To evaluate different students' experiences with the dashboard, we computed chi-squared tests of independence on dashboard users (52%) to find frequent patterns that discriminate students by their differences in academic achievement and self-regulated learning behaviors. The results revealed discriminating patterns in dashboard use among different levels of academic achievement and self-regulated learning, particularly for low achieving students and high self-regulated learners. Our findings highlight the importance of differences in students' experience with a student-facing dashboard, and emphasize that one size does not fit all in the design of learning analytics tools. © 2020 Copyright held by the owner/author(s).},
	author_keywords = {Academic achievement; Self-regulated learning; Sequential pattern mining; Student-facing dashboard},
	keywords = {Facings; Academic achievements; Chi-Squared test; Low-achieving students; Self-regulated learning; Self-regulated learning behaviors; Sequence analysis; Sequential-pattern mining; Support learning; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037712-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34}
}

@ARTICLE{Dipace201929,
	author = {Dipace, Anna and Fazlagic, Bojan and Minerva, Tommaso},
	title = {The design of a learning analytics dashboard: Eduopen mooc platform redefinition procedures},
	year = {2019},
	journal = {Journal of E-Learning and Knowledge Society},
	volume = {15},
	number = {3},
	pages = {29 – 47},
	doi = {10.20368/1971-8829/1135044},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073722989&doi=10.20368%2f1971-8829%2f1135044&partnerID=40&md5=64c1b8d2e7edf69a019b16080e89326e},
	affiliations = {University of Modena and Reggio, Italy},
	abstract = {The current EduOpen dashboard is not capable of monitoring performances and trends over the medium to long term both for the students as for the instructors; summarising and synthesising the adequate information; allowing implementation of any sort of predictive actions and functions (learning prediction). The article aims to expose the process of innovation and redefinition of a learning analytics dashboard in the EduOpen MOOC platform in order to define a model to design it accurately in terms of productivity for all users (teachers and students above all). From the literature analysis, main MOOC platform comparisons and the insights from the round tables a time spent variable is identified as at the basis of the entire user experience in online training paths. A concrete experimentation, through the design of a learning timeline and a constructive feedback system of an upcoming course in the EduOpen catalogue, is designed and explained relaying on the hypothesis of the existence of a correlation between the “time spent” (time value) and the final performance of the student. © 2019, Italian e-Learning Association. All rights reserved.},
	author_keywords = {Dashboard design; Learning analytics; Mooc dashboard; Time spent},
	publisher = {Italian e-Learning Association},
	issn = {18266223},
	language = {English},
	abbrev_source_title = {J. E-learn. Knowl. Soc..},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{2020,
	title = {8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12203 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088805510&partnerID=40&md5=516462f552de8a6a63bb65179826560d},
	abstract = {The proceedings contain 50 papers. The special focus in this conference is on Distributed, Ambient and Pervasive Interactions. The topics include: Designing an Interactive Platform for Intangible Cultural Heritage Knowledge of Taoyuan Woodcarving Craft; circuit Game: A Craft-Based Electronic Building Practice; going Beyond Computer-Assisted Vocabulary Learning: Research Synthesis and Frameworks; Returning to Nature: VR Mediated States of Enhanced Wellness; visualization and Analysis for Supporting Teachers Using Clickstream Data and Eye Movement Data; visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students; applying Deep Learning in Creative Re-creation of Changsha Kiln Cultural Relics; rethinking User Interaction with Smart Environments—A Comparative Study of Four Interaction Modalities; Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard; smart Learning in the Community: Supporting Citizen Digital Skills and Literacies; tele Echo Tube for Historic House Tojo-Tei in Matsudo International Science Art Festival 2018; motivating Physical Exercise in the Elderly with Mixed Reality Experiences; computer Vision on Wheelchairs: Detecting Sleeping Behavior of People with Intellectual Disabilities; factors Influencing the Acceptance and Usage of Smart City Services: A Systematic Review and Meta-analysis; civic Crowdsensing Through Location-Aware Virtual Monsters; participatory Governance in Smart Cities: Future Scenarios and Opportunities; Adaptability and Attuning in Smart Cities: Exploring the HCI Grand Challenge of Learning and Creativity; investigating Users Attitudes and Perceptions Towards the Usage of Smart City Apps; accessibility in Pervasive Systems: An Exploratory Study; digitally Enhancing Society Through Structuralism: Virtualizing Collective Human Eyesight and Hearing Capabilities as a Case Study; foreword.},
	editor = {Streitz N. and Konomi S.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050343-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{van Leeuwen2019261,
	author = {van Leeuwen, Anouschka and Rummel, Nikol and van Gog, Tamara},
	title = {What information should CSCL teacher dashboards provide to help teachers interpret CSCL situations?},
	year = {2019},
	journal = {International Journal of Computer-Supported Collaborative Learning},
	volume = {14},
	number = {3},
	pages = {261 – 289},
	doi = {10.1007/s11412-019-09299-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066241869&doi=10.1007%2fs11412-019-09299-x&partnerID=40&md5=8ca1ef22b1c3a8c25f9e5dd16dcc8258},
	affiliations = {Department of Education, Utrecht University, Heidelberglaan 1, 3584CS, Utrecht, Netherlands; Pädagogische Psychologie, Institut für Erziehungswissenschaft, Ruhr-Universität Bochum, Universitätsstraße 150, D - 44801, Bochum, Germany},
	abstract = {Teachers play a major role during CSCL by monitoring and stimulating the types of interactions between students that are conducive to learning. Teacher dashboards are increasingly being developed to aid teachers in monitoring students’ collaborative activities, thereby constituting a form of indirect support for CSCL in the classroom. However, the process of how teachers find and interpret relevant information from dashboards, and which help they need during this process, remains largely unexamined. We first describe how we arrived at the design of a prototype teacher dashboard in the context of primary school fraction assignments, based on teacher interviews. We then report an experimental study (n = 53) to investigate the effect of the type of support a teacher dashboard offers (mirroring, alerting, or advising) on teachers’ detection and interpretation of potentially problematic situations where intervention might be needed. The results showed that the type of support did not influence detection of events, but did influence teachers’ interpretation of a CSCL situation. © 2019, The Author(s).},
	author_keywords = {Collaborative learning; Dashboard; Learning analytics; Teacher support},
	correspondence_address = {A. van Leeuwen; Department of Education, Utrecht University, Utrecht, Heidelberglaan 1, 3584CS, Netherlands; email: A.vanLeeuwen@uu.nl},
	publisher = {Springer},
	issn = {15561607},
	language = {English},
	abbrev_source_title = {Int. J. Comput.-Supported Collab. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 88; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Wang2019706,
	author = {Wang, Hsiu-Feng and Lin, Chia-Hsiung},
	title = {An investigation into visual complexity and aesthetic preference to facilitate the creation of more appropriate learning analytics systems for children},
	year = {2019},
	journal = {Computers in Human Behavior},
	volume = {92},
	pages = {706 – 715},
	doi = {10.1016/j.chb.2018.05.032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048252025&doi=10.1016%2fj.chb.2018.05.032&partnerID=40&md5=f8ddb80f190eb23ec852909743a22a48},
	affiliations = {Department of e-Learning Design and Management, National Chiayi University, 85, Wenlong, Mingsuin, Chiayi Hsien, 621, Taiwan; Division of Rehabilitation Medicine, Physical Therapy Department, Ditmanson Medical Foundation, Chiayi Christian Hospital, 539, Zhongxiao Road, East District, Chiayi City, 600, Taiwan},
	abstract = {The purpose of learning analytics is to optimise learning and the environment in which it occurs. However, while much research has been conducted into how to measure, collect and analyse learner data, little has been conducted into how to aesthetically display information to learners in dashboards and educational materials online to maximise its appeal. This experiment examined the relationship between children's age and their aesthetic preferences towards visual complexity in e-learning web pages designed for them. It applied Berlyne's theory of aesthetic preference: a theory that suggests that people prefer a medium level of stimuli to a low or high level of stimuli. It asked 180 Taiwanese primary school children to indicate their aesthetic preferences towards web pages of high, medium and low visual complexity. The children were divided into three groups: 7-8 year-olds, 9-10 year-olds and 11-12 year-olds. When the ratings of the three age groups were looked at together, they revealed that the children preferred e-learning web pages that had a medium level of visual complexity to those that had a high or low level of visual complexity. As such, the results supported Berlyne's theory. However, when the ratings of the age groups were looked at separately with respect to aesthetic factors, differences were found. In particular, it was found that the 7-8 year-olds preferred e-learning web pages that had a high level of colourfulness while the 9-12 year-olds did not. © 2018 Elsevier Ltd},
	keywords = {Websites; Aesthetic preference; Age groups; E-learning web pages; Educational materials; Learning analytics; Primary school children; Visual complexity; article; child; female; groups by age; human; learning; major clinical study; male; primary school; stimulus; E-learning},
	correspondence_address = {C.-H. Lin; Division of Rehabilitation Medicine, Physical Therapy Department, Ditmanson Medical Foundation, Chiayi Christian Hospital, Chiayi City, 539, Zhongxiao Road, East District, 600, Taiwan; email: 02853@cych.org.tw},
	publisher = {Elsevier Ltd},
	issn = {07475632},
	coden = {CHBEE},
	language = {English},
	abbrev_source_title = {Comput. Hum. Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Gruzd20202708,
	author = {Gruzd, Anatoliy and Conroy, Nadia},
	title = {Learning analytics dashboard for teaching with twitter},
	year = {2020},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2020-January},
	pages = {2708 – 2717},
	doi = {10.24251/hicss.2020.330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097325996&doi=10.24251%2fhicss.2020.330&partnerID=40&md5=99ffeac7f0e64954bd5881baf28fcbdc},
	affiliations = {Ted Rogers School, Management Social Media Lab, Ryerson University, Toronto, Canada},
	abstract = {As social media takes root in our society, more University instructors are incorporating platforms like Twitter into their classroom. However, few of the current Learning Analytics (LA) systems process social media data for instructional interventions and evaluation. As a result, instructors who are using social media cannot easily assess their students' learning progress or use the data to adjust their lessons in real time. We surveyed 54 university instructors to better understand how they use social media in the classroom; we then used these results to design and evaluate our own Twitter-centric LA dashboard. The overarching goals for this project were to 1) assist instructors in determining whether their particular use of Twitter met their teaching objectives, and 2) help system designers navigate the nuance of designing LA dashboards for social media platforms. © 2020 IEEE Computer Society. All rights reserved.},
	keywords = {'current; Analytics systems; Instructional interventions; Learning progress; Real- time; Social media; Social media datum; Student learning; System process; Teaching objectives},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813313-3},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2020,
	title = {LAK 2020 Conference Proceedings - Celebrating 10 years of LAK: Shaping the Future of the Field - 10th International Conference on Learning Analytics and Knowledge},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123040141&partnerID=40&md5=e217981da9f107c034139639a286c2b6},
	abstract = {The proceedings contain 80 papers. The topics discussed include: analyzing the consistency in within-activity learning patterns in blended learning; evaluating teachers perceptions of students questions organization; predicting student success in a blended learning environment; comparing teachers use of mirroring and advising dashboards; learning analytics dashboards: the past, the present and the future; automated insightful drill-down recommendations for learning analytics dashboards; trace data from student solutions to genetics problems reveals variance in the processes related to different course outcomes; how working memory capacity limits success in self-directed learning: a cognitive model of search and concept formation; inspiration cards workshops with teachers in early co-design stages of learning analytics; and fostering and supporting empirical research on evaluative judgment via a crowdsourced adaptive learning system.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037712-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hilliger2020117,
	author = {Hilliger, Isabel and De Laet, Tinne and Henríquez, Valeria and Guerra, Julio and Ortiz-Rojas, Margarita and Zuñiga, Miguel Ángel and Baier, Jorge and Pérez-Sanagustín, Mar},
	title = {For learners, with learners: Identifying indicators for an academic advising dashboard for students},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12315 LNCS},
	pages = {117 – 130},
	doi = {10.1007/978-3-030-57717-9_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091147185&doi=10.1007%2f978-3-030-57717-9_9&partnerID=40&md5=e233322b7957e82117e22424c59a1289},
	affiliations = {Pontificia Universidad Católica de Chile, Santiago, Chile; Katholieke Universiteit Leuven, Louvain, Belgium; Universidad Austral de Chile, Valdivia, Chile; Escuela Superior Politécnica del Litoral, Guayaquil, Ecuador; Universidad de Cuenca, Cuenca, Ecuador; Université Toulouse III Paul Sabatier, Toulouse, France},
	abstract = {Learning Analytics (LA) dashboards aggregate indicators about student performance and demographics to support academic advising. The majority of existing dashboards are targeted at advisors and professors, but not much attention has been put into students’ need for information for their own academic decision-making. In this study, we identify relevant indicators from a student perspective using a mixed methods approach. Qualitative data was obtained from an open-ended online questionnaire answered by 31 student representatives, and quantitative data was collected from a closed-ended online questionnaire answered by 652 students from different cohorts. Findings point out relevant indicators to help students choose what courses to take in an upcoming academic period. Since this study is part of a large research project that has motivated the adoption of academic advising dashboards in different Latin American universities, these findings were also contrasted with indicators of these advising dashboards, informing future developments targeting students. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Academic advising; Higher education; Learning analytics; Learning dashboards},
	keywords = {Decision making; Surveys; Academic advising; Latin americans; Mixed method; Online questionnaire; Qualitative data; Quantitative data; Student performance; Student perspectives; Students},
	correspondence_address = {I. Hilliger; Pontificia Universidad Católica de Chile, Santiago, Chile; email: ihillige@ing.puc.cl},
	editor = {Alario-Hoyos C. and Rodríguez-Triana M.J. and Scheffel M. and Arnedillo-Sánchez I. and Dennerlein S.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303057716-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{Guitart Hormigo2020109,
	author = {Guitart Hormigo, Isabel and Rodríguez, M. Elena and Baró, Xavier},
	title = {Design and implementation of dashboards to support teachers decision-making process in e-assessment systems},
	year = {2020},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {34},
	pages = {109 – 132},
	doi = {10.1007/978-3-030-29326-0_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083640494&doi=10.1007%2f978-3-030-29326-0_6&partnerID=40&md5=e06ce6d64a3708d9acd36aecc50a6198},
	affiliations = {Universitat Oberta de Catalunya, Rambla del Poblenou, 156, Barcelona, 08018, Spain},
	abstract = {The growing number of universities adopting some form of e-learning in recent years has raised some concerns about how to ensure students’ authentication, and the authorship of the assessment activities they deliver. There are several strategies and market tools that can help teachers in these tasks. While the usage of plagiarism detection tools for checking authorship is common practice (above all in fully online universities), the use of biometric instruments for ensuring students’ identity is less extended. Although all these tools collect a large amount and variety of data, there is a lack of software systems that can integrate such data, and show the information that may be extracted from these data in a visual and meaningful way that fits the teachers’ needs. Precisely, the objective of this chapter is to present a set of dashboards that integrate data collected by different kinds of authentication and authorship instruments, oriented to assist the decision-making process of teachers, above all in case of suspicion of students’ dishonest academic behavior. Although these dashboards have been designed and implemented in the context of TeSLA project, the experience and conclusions provided here are of interest to researchers and practitioners aiming to develop dashboards with learning analytics purposes at higher education. For this reason, this chapter also provides a discussion and review of the most prominent analytical efforts in universities. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Audit data; Authentication; Authorship; Dashboards; Decision-making; e-assessment systems; Key performance indicator; Learning analytics},
	keywords = {Authentication; Electronic assessment; Students; Analytical efforts; Assessment activities; Assessment system; Decision making process; Design and implementations; Higher education; Plagiarism detection; Software systems; Decision making},
	correspondence_address = {I. Guitart Hormigo; Universitat Oberta de Catalunya, Barcelona, Rambla del Poblenou, 156, 08018, Spain; email: iguitarth@uoc.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23674512},
	language = {English},
	abbrev_source_title = {Lecture. Notes. Data Eng. Commun. Tech.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Aslan2019,
	author = {Aslan, Sinem and Alyuz, Nese and Tanriover, Cagri and Mete, Sinem E. and Okur, Eda and D’Mello, Sidney K. and Esme, Asli Arslan},
	title = {Investigating the Impact of a Real-time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms},
	year = {2019},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3290605.3300534},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067593130&doi=10.1145%2f3290605.3300534&partnerID=40&md5=b7b60554e52ed0cca1ebbddfac1ec993},
	affiliations = {Intel Corporation, Hillsboro, OR, United States; Bahcesehir University, Istanbul, Turkey; University of Colorado Boulder, Boulder, CO, United States},
	abstract = {We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher’s classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers’ role of being a coach in technology-mediated learning environments. © 2019 Association for Computing Machinery.},
	author_keywords = {Affective computing; Dashboards; Learning analytics; Real-time; Student engagement},
	keywords = {Computer aided instruction; Engineering education; Environmental technology; Human computer interaction; Human engineering; Scaffolds; Affective Computing; Dashboards; Learning analytics; Real time; Student engagement; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145035970-2},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 73}
}

@CONFERENCE{Rubio-Fernández20209,
	author = {Rubio-Fernández, Aarón and Moreno-Marcos, Pedro Manuel and Muñoz-Merino, Pedro J. and Kloos, Carlos Delgado},
	title = {An initial analysis of prediction techniques as a support for the flipped classroom},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2671},
	pages = {9 – 16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092029646&partnerID=40&md5=637dd93fc412da462018e5d0f876ff73},
	affiliations = {Universidad Carlos III de Madrid, Spain},
	abstract = {With the increasing use of active learning methodologies such as the Flipped Classroom (FC), many approaches have been taken to enhance the students' learning in such contexts. Prediction techniques can be used in combination with Learning Analytics (LA) dashboards for the improvement of the FC model. In this direction, we analyze some theoretical cases in which this approach can provide academic benefits (e.g. providing additional resources or re-designing the class). Furthermore, we present several initial ideas on how to combine two existing software tools, one which provides LA dashboards and the other that implements prediction techniques, that can be used successfully in such scenarios for the FC. This is a preliminary work for the joint use of prediction techniques and LA dashboards in FC contexts. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Course Design; Flipped Classroom; Learning Analytics; Orchestration; Prediction; Visualizations},
	keywords = {Forecasting; Students; Academic benefit; Active Learning; Prediction techniques; Re-designing; Learning systems},
	editor = {Martinez-Mones A. and Universidad de Valladolid, Department of Computer Science, Campus Miguel Delibes, Valladolid and Alvarez A. and Universidad del Pais Vasco UPV/EHU, Department of Computer Languages and Systems, Paseo Manuel Lardizabal 1, Donostia, Gipuzkoa and Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Dimitriadis Y. and Universidad de Valladolid, Department of Theory of Signal and Communications and Telematics Engineering, Campus Miguel Delibes, Valladolid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Verbert202035,
	author = {Verbert, Katrien and Ochoa, Xavier and De Croon, Robin and Dourado, Raphael A. and De Laet, Tinne},
	title = {Learning analytics dashboards: The past, the present and the future},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {35 – 40},
	doi = {10.1145/3375462.3375504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082395570&doi=10.1145%2f3375462.3375504&partnerID=40&md5=b39ad0a7f92cb1fd9c54ace83adec328},
	affiliations = {KU Leuven, Leuven, Belgium; New York University, New York, United States; Universidade Federal de Pernambuco, Recife, Brazil},
	abstract = {Learning analytics dashboards are at the core of the LAK vision to involve the human into the decision-making process. The key focus of these dashboards is to support better human sense-making and decision-making by visualising data about learners to a variety of stakeholders. Early research on learning analytics dashboards focused on the use of visualisation and prediction techniques and demonstrates the rich potential of dashboards in a variety of learning settings. Present research increasingly uses participatory design methods to tailor dashboards to the needs of stakeholders, employs multimodal data acquisition techniques, and starts to research theoretical underpinnings of dashboards. In this paper, we present these past and present research efforts as well as the results of the VISLA19 workshop on "Visual approaches to Learning Analytics" that was held at LAK19 with experts in the domain to identify and articulate common practices and challenges for the domain. Based on an analysis of the results, we present a research agenda to help shape the future of learning analytics dashboards. © 2020 Association for Computing Machinery.},
	author_keywords = {Evaluation; Interaction; Learning analytics dashboards; Visualisation},
	keywords = {Data acquisition; Visualization; Approaches to learning; Decision making process; Evaluation; Interaction; Learning analytics dashboards; Learning settings; Participatory design; Prediction techniques; Decision making},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037712-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 109; All Open Access, Green Open Access}
}

@CONFERENCE{Vázquez-Ingelmo202047,
	author = {Vázquez-Ingelmo, Andrea and García-Peñalvo, Francisco J. and Therón, Roberto and García-Holgado, Alicia},
	title = {Specifying information dashboards' interactive features through meta-model instantiation},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2671},
	pages = {47 – 59},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092017661&partnerID=40&md5=ee0738ccbebcb46d8cf052fa2eb615d3},
	affiliations = {GRIAL Research Group, Computer Sciences Department, Research Institute for Educational Sciences, University of Salamanca, Salamanca, Spain; VisUSAL Research Group, University of Salamanca, Salamanca, Spain},
	abstract = {Information dashboards can be leveraged to make informed decisions with the goal of improving policies, processes, and results in different contexts. However, the design process of these tools can be convoluted, given the variety of profiles that can be involved in decision-making processes. The educative context is one of the contexts that can benefit from the use of information dashboards, but given the diversity of actors within this area (teachers, managers, students, researchers, etc.), it is necessary to take into account different factors to deliver useful and effective tools. This work describes an approach to generate information dashboards with interactivity capabilities in different contexts through meta-modeling. Having the possibility of specifying interaction patterns within the generative workflow makes the personalization process more fine-grained, allowing to match very specific requirements from the user. An example of application within the context of Learning Analytics is presented to demonstrate the viability of this approach. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Information Dashboards; Information Visualization; Interactions; MDA; Meta-model; SPL},
	keywords = {Decision making process; Design process; Effective tool; Informed decision; Interaction pattern; Interactive features; Interactivity; Personalizations; Decision making},
	editor = {Martinez-Mones A. and Universidad de Valladolid, Department of Computer Science, Campus Miguel Delibes, Valladolid and Alvarez A. and Universidad del Pais Vasco UPV/EHU, Department of Computer Languages and Systems, Paseo Manuel Lardizabal 1, Donostia, Gipuzkoa and Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Dimitriadis Y. and Universidad de Valladolid, Department of Theory of Signal and Communications and Telematics Engineering, Campus Miguel Delibes, Valladolid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Chou201993,
	author = {Chou, Chih-Yueh and Chih, Wen-Chieh and Tseng, Shu-Fen and Chen, Zhi-Hong},
	title = {Simulatable open learner models of core competencies for setting goals for course performance},
	year = {2019},
	journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
	volume = {1},
	pages = {93 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077708658&partnerID=40&md5=17297ea506290ba7e2e34b0049a91e1f},
	affiliations = {Department of Computer Science and Engineering, Yuan Ze University, Taiwan; Department of Information Management, Yuan Ze University, Taiwan; Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taiwan},
	abstract = {A competency-based curriculum involves courses for cultivating core competencies required for specific professions to enable students to take courses to cultivate their core competencies. This paper presents a curriculum level and competency-based learning analytics dashboard system with simulatable open learner models (OLMs) of core competencies for assisting students in setting goals for course performance. At first, the system provides students with their OLMs of core competencies based on their taken courses and grades. After that, students are asked to set their goals for course grades of all their courses during the current semester. The system displays the simulation of students’ future OLMs if they achieve their goals for course grades this semester. Students can re-set their goals and conduct the simulation of OLMs again until they satisfy the simulation results. The system also enables students to set detailed goals for attendance, assignment hand-in rate, midterm exam, and final exam in order to achieve their goals for course grade. A preliminary evaluation was conducted. Most students agreed that the simulatable OLMs assisted them in understanding the influence of their goals for course grades on core competencies and in setting goals for course grades. Most students also stated that setting detailed course goals prompted them to achieve the goal for course grade. © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
	author_keywords = {Competency-based curriculum; Core competencies; Goal setting; Learning analytics dashboard system; Open learner models},
	keywords = {Curricula; Education computing; Learning systems; Strategic planning; Core competencies; Course performance; Goal setting; Learning analytics dashboard system; Open learner models; System displays; Students},
	correspondence_address = {C.-Y. Chou; Department of Computer Science and Engineering, Yuan Ze University, Taiwan; email: cychou@saturn.yzu.edu.tw},
	editor = {Chang M. and So H.-J. and Wong L.-H. and Yu F.-Y. and Shih J.-L. and Boticki I. and Chen M.-P. and Dewan A. and Haklev S. and Koh E. and Kojiri T. and Li K.-C. and Sun D. and Wen Y.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972143-1},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Vázquez-Ingelmo2019815,
	author = {Vázquez-Ingelmo, Andrea and García-Pẽalvo, Francisco J. and Therón, Roberto},
	title = {Capturing high-level requirements of information dashboards' components through meta-modeling},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {815 – 821},
	doi = {10.1145/3362789.3362837},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075414934&doi=10.1145%2f3362789.3362837&partnerID=40&md5=d2470c06b81cfef33d5630aefd9148bd},
	affiliations = {GRIAL Research Group, Department of Computer Science, Research Institute for Educational Sciences, University of Salamanca, Paseo de Canalejas 169, Salamanca, 37008, Spain},
	abstract = {Information dashboards are increasing their sophistication to match new necessities and adapt to the high quantities of generated data nowadays. These tools support visual analysis, knowledge generation, and thus, are crucial systems to assist decision-making processes. However, the design and development processes are complex, because several perspectives and components can be involved. Tailoring capabilities are focused on providing individualized dashboards without affecting the time-to-market through the decrease of the development processes' time. Among the methods used to configure these tools, the software product lines paradigm and model-driven development can be found. These paradigms benefit from the study of the target domain and the abstraction of features, obtaining high-level models that can be instantiated into concrete models. This paper presents a dashboard meta-model that aims to be applicable to any dashboard. Through domain engineering, different features of these tools are identified and arranged into abstract structures and relationships to gain a better understanding of the domain. The goal of the meta-model is to obtain a framework for instantiating any dashboard to adapt them to different contexts and user profiles. One of the contexts in which dashboards are gaining relevance is Learning Analytics, as learning dashboards are powerful tools for assisting teachers and students in their learning activities. To illustrate the instantiation process of the presented meta-model, a small example within this relevant context (Learning Analytics) is also provided. © 2019 ACM.},
	author_keywords = {Domain engineering; High-level requirements; Information Dashboards; Meta-modeling},
	keywords = {Ecosystems; Decision making process; Design and development process; Domain engineering; High-level requirements; Information Dashboards; Meta model; Model driven development; Software Product Line; Decision making},
	editor = {Conde-Gonzalez M.A. and Rodriguez-Sedano F.J. and Fernandez-Llamas C. and Garcia-Penalvo F.J.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037191-9},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{Perez-Berenguer202036350,
	author = {Perez-Berenguer, Daniel and Kessler, Mathieu and Garcia-Molina, Jesus},
	title = {A customizable and incremental processing approach for learning analytics},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {36350 – 36362},
	doi = {10.1109/ACCESS.2020.2975384},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081660382&doi=10.1109%2fACCESS.2020.2975384&partnerID=40&md5=682820e62de95712fbd00c8fdd293bd6},
	affiliations = {Centro de Producción de Contenidos Digitales, Universidad Politécnica de Cartagena, Murcia, 30202, Spain; Departamento de Informática y Sistemas, Universidad de Murcia, Murcia, 30003, Spain},
	abstract = {The ability of learning analytics to improve the learning/teaching processes is widely recognized. In this paper, the learning analytics architecture developed at the Digital Content Production Center of the Technical University of Cartagena (Spain) is presented. This architecture contributes to the field of learning analytics in two aspects: it allows for dashboard customization and improves the efficiency of the analysis of learners' interaction data. Events resulting from learners' interaction are captured and stored in Caliper standard format, to be further processed incrementally to allow dashboards to be shown without delay to teachers. Customization is considered a mandatory requirement for learning analytics tools, however, although some proposals have recently been made, a greater research effort in this topic is necessary. In the present work, this requirement is addressed by defining a domain-specific language (DSL) that allows teachers to customize dashboards. This language allows to express indicators (logical expressions) that classify students into different groups depending on their performance level. The paper also shows how our learning analytics approach was evaluated with a course that applies a flipped classroom method, and how it compares to the most relevant related works that have been published. © 2013 IEEE.},
	author_keywords = {Caliper; Custom dashboard; DSL; Incremental event processing; Learning analytics; Model-driven development; R~language},
	keywords = {Digital subscriber lines; DSL; Modems; Problem oriented languages; Caliper; Custom dashboard; Event Processing; Learning analytics; Model driven development; R~language; Learning systems},
	correspondence_address = {D. Perez-Berenguer; Centro de Producción de Contenidos Digitales, Universidad Politécnica de Cartagena, Murcia, 30202, Spain; email: daniel.perez@upct.es},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{Teasley201959,
	author = {Teasley, Stephanie Danell},
	title = {Learning analytics: where information science and the learning sciences meet},
	year = {2019},
	journal = {Information and Learning Science},
	volume = {120},
	number = {1-2},
	pages = {59 – 73},
	doi = {10.1108/ILS-06-2018-0045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056758885&doi=10.1108%2fILS-06-2018-0045&partnerID=40&md5=84ee4bcc7c9639624025b2f2c7e74c24},
	affiliations = {School of Information, University of Michigan, Ann Arbor, MI, United States},
	abstract = {Purpose: The explosive growth in the number of digital tools utilized in everyday learning activities generates data at an unprecedented scale, providing exciting challenges that cross scholarly communities. This paper aims to provide an overview of learning analytics (LA) with the aim of helping members of the information and learning sciences communities understand how educational Big Data is relevant to their research agendas and how they can contribute to this growing new field. Design/methodology/approach: Highlighting shared values and issues illustrates why LA is the perfect meeting ground for information and the learning sciences, and suggests how by working together effective LA tools can be designed to innovate education. Findings: Analytics-driven performance dashboards are offered as a specific example of one research area where information and learning scientists can make a significant contribution to LA research. Recent reviews of existing dashboard studies point to a dearth of evaluation with regard to either theory or outcomes. Here, the relevant expertise from researchers in both the learning sciences and information science is offered as an important opportunity to improve the design and evaluation of student-facing dashboards. Originality/value: This paper outlines important ties between three scholarly communities to illustrate how their combined research expertise is crucial to advancing how we understand learning and for developing LA-based interventions that meet the values that we all share. © 2018, Emerald Publishing Limited.},
	author_keywords = {Dashboards; Education; Educational technology; Learning; Learning analytics; Student data privacy},
	correspondence_address = {S.D. Teasley; School of Information, University of Michigan, Ann Arbor, United States; email: steasley@umich.edu},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {23985348},
	language = {English},
	abbrev_source_title = {inform.Learn.Sci},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25}
}

@ARTICLE{Aljohani2019679,
	author = {Aljohani, Naif Radi and Daud, Ali and Abbasi, Rabeeh Ayaz and Alowibdi, Jalal S. and Basheri, Mohammad and Aslam, Muhammad Ahtisham},
	title = {An integrated framework for course adapted student learning analytics dashboard},
	year = {2019},
	journal = {Computers in Human Behavior},
	volume = {92},
	pages = {679 – 690},
	doi = {10.1016/j.chb.2018.03.035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055977462&doi=10.1016%2fj.chb.2018.03.035&partnerID=40&md5=9aa41b25ba90355d91807b7b0d7522e7},
	affiliations = {Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Faculty of Computing and Information Technology, University of Jeddah, Jeddah, Saudi Arabia},
	abstract = {The advanced learning analytics research of the last years converges with the industry demand to enhance famous learning management systems with learning analytics capabilities promoting the efficiency of higher education. The exploitation of big volume learning data, is a critical challenge for the design of personalized curricula and learning experiences. The purpose of this research paper is to communicate a framework for Learning Analytics aiming to support the integrated management of end-to-end learning data. We present the research foundations of a research prototype for the integration of a Learning Analytics Dashboard: The AMBA Prototype with famous Learning Management Systems. Finally, we present the main findings of an empirical study that proves the capacity of learning analytics to enhance the learners' ecosystem with value adding learning services. The proposed framework exploits cognitive computing for the enhancement of decision making in education by proving the capacity of Learning Analytics to reveal hidden patterns of learners’ behaviour and attitude. © 2018},
	author_keywords = {Blackboard; Cognitive computing; Learning analytics; Learning framework; Learning management systems},
	keywords = {Advanced Analytics; Cognitive systems; Decision making; Blackboard; Cognitive Computing; Learning analytics; Learning frameworks; Learning management system; article; decision making; ecosystem; education; empiricism; human; human experiment; learning; student; Learning systems},
	correspondence_address = {N.R. Aljohani; Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; email: nraljohani@kau.edu.sa},
	publisher = {Elsevier Ltd},
	issn = {07475632},
	coden = {CHBEE},
	language = {English},
	abbrev_source_title = {Comput. Hum. Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 71}
}

@CONFERENCE{Ajanovski202057,
	author = {Ajanovski, Vangel V.},
	title = {What to study next? Visual guidance in knowledge acquisition},
	year = {2020},
	journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	pages = {57 – 58},
	doi = {10.1145/3379336.3381454},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082172309&doi=10.1145%2f3379336.3381454&partnerID=40&md5=4c035496c35b227f9673e4881c7cc558},
	affiliations = {Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, North Macedonia},
	abstract = {This is a demo of a virtual academic adviser that enables student selfguidance and counters the unavailability of true academic advisers. The adviser integrates four visual tools: flexible and personalized planning of future terms and courses, body of knowledge acquisition mapping tool for easier finding of courses that are aligned to personal interests in terms of the acquired knowledge and abilities, and study program switch exploration tool to ease student mobility. © 2020 International Conference on Intelligent User Interfaces, Proceedings IUI. All rights reserved.},
	author_keywords = {Curriculum mapping; Educational recommender systems; Learning analytics dashboards; Student progress tracking},
	keywords = {Curricula; Knowledge acquisition; Mapping; Students; Exploration tools; Learning analytics dashboards; Mapping tools; Self guidances; Student mobilities; Student progress; Visual guidance; Visual tools; User interfaces},
	correspondence_address = {V.V. Ajanovski; Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, North Macedonia; email: vangel.ajanovski@finki.ukim.mk},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037513-9},
	language = {English},
	abbrev_source_title = {Int Conf Intell User Interfaces Proc IUI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Martínez-Ortiz20191108,
	author = {Martínez-Ortiz, Iván and Pérez-Colado, Iván and Rotaru, Dan Cristian and Freire, Manuel and Fernández-Manjón, Baltasar},
	title = {From heterogeneous activities to unified analytics dashboards},
	year = {2019},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {April-2019},
	pages = {1108 – 1113},
	doi = {10.1109/EDUCON.2019.8725222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067439975&doi=10.1109%2fEDUCON.2019.8725222&partnerID=40&md5=fbe95a5716c9386969f5466052de9536},
	affiliations = {Dept. of Software Eng. and Artificial Int., Universidad Complutense de Madrid, Madrid, Spain},
	abstract = {Teachers often wish to integrate activities from disparate sources into their courses. For example, gamified activities, mediated through technology, can promote the type of active learning required to develop higher-level engagement by students. However, unless the activities have been designed to facilitate it, integrating their analytics into a single dashboard can require significant development effort. A general solution to such heterogeneous analytics integration can be of great value, by presenting a single view of student actions throughout the different parts of a course. We describe the problems presented when integrating the analytics of three heterogeneous stand-alone activities, in the context of a EU project to improve software engineering teaching. The idea is to increase student engagement via gamification, and explore the design space of possible solutions for providing integrated analytics over the heterogeneous activities. We then describe the design of a proof-of-concept implementation, based on the use of both xAPI trackers and simple CSV files for information exchange, single sign-on, a minimal class management web application, and updates to the analytics platform to allow dynamic changes in the multi-level analysis. The resulting approach can be readily applied to similar heterogeneous scenarios. © 2019 IEEE.},
	author_keywords = {Analytics; Learning analytics; Serious games},
	keywords = {Curricula; Electronic document exchange; Engineering education; Serious games; Software engineering; Teaching; Analytics; Dynamic changes; General solutions; Information exchanges; Learning analytics; Multi-level analysis; Proof of concept; Student engagement; Students},
	editor = {Schreiter S. and Ashmawy A.K.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-153869506-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Jones2019,
	author = {Jones, Kyle M. L.},
	title = {Learning analytics and higher education: a proposed model for establishing informed consent mechanisms to promote student privacy and autonomy},
	year = {2019},
	journal = {International Journal of Educational Technology in Higher Education},
	volume = {16},
	number = {1},
	doi = {10.1186/s41239-019-0155-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068625122&doi=10.1186%2fs41239-019-0155-0&partnerID=40&md5=76f652f8f26bcac77ddb9f16ebff4f6a},
	affiliations = {Department of Library and Information Science, School of Informatics and Computing, Indiana University–Indianapolis (IUPUI), Indianapolis, IN, United States},
	abstract = {By tracking, aggregating, and analyzing student profiles along with students’ digital and analog behaviors captured in information systems, universities are beginning to open the black box of education using learning analytics technologies. However, the increase in and usage of sensitive and personal student data present unique privacy concerns. I argue that privacy-as-control of personal information is autonomy promoting, and that students should be informed about these information flows and to what ends their institution is using them. Informed consent is one mechanism by which to accomplish these goals, but Big Data practices challenge the efficacy of this strategy. To ensure the usefulness of informed consent, I argue for the development of Platform for Privacy Preferences (P3P) technology and assert that privacy dashboards will enable student control and consent mechanisms, while providing an opportunity for institutions to justify their practices according to existing norms and values. © 2019, The Author(s).},
	author_keywords = {Autonomy; Higher education; Informed consent; Learning analytics; Student privacy},
	correspondence_address = {K.M.L. Jones; Department of Library and Information Science, School of Informatics and Computing, Indiana University–Indianapolis (IUPUI), Indianapolis, United States; email: kmlj@iupui.edu},
	publisher = {Springer Netherlands},
	issn = {23659440},
	language = {English},
	abbrev_source_title = {Int. j. educ. technol. high. educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 101; All Open Access, Gold Open Access}
}

@ARTICLE{Wise201953,
	author = {Wise, Alyssa Friend and Jung, Yeonji},
	title = {Teaching with analytics: Towards a situated model of instructional decision-making},
	year = {2019},
	journal = {Journal of Learning Analytics},
	volume = {6},
	number = {2},
	pages = {53 – 69},
	doi = {10.18608/jla.2019.62.4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073369264&doi=10.18608%2fjla.2019.62.4&partnerID=40&md5=c197ed25865d98f74e009b995d01290e},
	affiliations = {NYU-Learning Analytics Research Network (NYU-LEARN), New York University, New York, 10003, NY, United States},
	abstract = {The process of using analytic data to inform instructional decision-making is acknowledged to be complex; however, details of how it occurs in authentic teaching contexts have not been fully unpacked. This study investigated five university instructors’ use of a learning analytics dashboard to inform their teaching. The existing literature was synthesized to create a template for inquiry that guided interviews, and inductive qualitative analysis was used to identify salient emergent themes in how instructors 1) asked questions, 2) interpreted data, 3) took action, and 4) checked impact. Findings showed that instructors did not always come to analytics use with specific questions, but rather with general areas of curiosity. Questions additionally emerged and were refined through interaction with the analytics. Data interpretation involved two distinct activities, often along with affective reactions to data: reading data to identify noteworthy patterns and explaining their importance in the course using contextual knowledge. Pedagogical responses to the analytics included whole-class scaffolding, targeted scaffolding, and revising course design, as well two new non-action responses: adopting a wait-and-see posture and engaging in deep reflection on pedagogy. Findings were synthesized into a model of instructor analytics use that offers useful categories of activities for future study and support. © 2019, UTS ePRESS. All rights reserved.},
	author_keywords = {Analytics use; Data-informed decision-making; Instructional dashboards; Instructional improvement; Learning analytics; Learning analytics design; Learning analytics implementation; Pedagogical support; Teaching analytics},
	correspondence_address = {A.F. Wise; NYU-Learning Analytics Research Network (NYU-LEARN), New York University, New York, 10003, United States; email: alyssa.wise@nyu.edu},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 137; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Calvo-Morata20191507,
	author = {Calvo-Morata, Antonio and Alonso-Fernández, Cristina and Pérez-Colado, Iván J. and Freire, Manuel and Martínez-Ortiz, Iván and Fernández-Manjón, Baltasar},
	title = {Improving teacher game learning analytics dashboards through ad-hoc development},
	year = {2019},
	journal = {Journal of Universal Computer Science},
	volume = {25},
	number = {12},
	pages = {1507 – 1530},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079134164&partnerID=40&md5=04872c867c2c4311121628250e348b19},
	affiliations = {Complutense University of Madrid, Madrid, Spain},
	abstract = {Using games for education can increase the motivation and engagement of students and provide a more authentic learning environment where students can learn, test and apply new knowledge. However, the actual (serious) game application in schools is still limited, partly because teachers consider their use as a complex process. To increase game adoption, the integration of Game Learning Analytics (GLA) can provide teachers a thorough insight into the knowledge acquired by their students and usually presented through a visual dashboard. Although it is possible to provide a useful general metrics and a prefab dashboard, it may not fully cover teachers’ expectations. In this paper, we study the ad-hoc adaptation of generic dashboards to increase their effectiveness through three case-studies. In these experiences, we adapt dashboards for teachers to include detailed information for more-focused analysis. With the positive results obtained from these scenarios, we have identified a methodological process to create ad-hoc GLA dashboards and extracted some lessons learned for dashboard development: Simple but useful dashboards can provide a higher added value for stakeholders compared with more complex dashboards; teachers and game developers should be involved in dashboard design for better results; and, if possible, ad-hoc developed dashboards should be used as they have proved to be more effective than generic dashboards. © J.UCS.},
	author_keywords = {Dashboards; Game-Based Learning; Learning Analytics; Serious Games; xAPI},
	publisher = {IICM},
	issn = {0948695X},
	language = {English},
	abbrev_source_title = {J. Univers. Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Koné202088,
	author = {Koné, Malik and May, Madeth and Iksal, Sébastien and Oumtanaga, Souleymane},
	title = {A Collective Dynamic Indicator for Discussion Forums in Learning Management Systems},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1220},
	pages = {88 – 110},
	doi = {10.1007/978-3-030-58459-7_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097366266&doi=10.1007%2f978-3-030-58459-7_5&partnerID=40&md5=e1ec7773c3e31f65e4e39cd54a209443},
	affiliations = {LIUM, Le Mans Université, Le Mans, France; LARIT, INP-HB, Yamoussoukro, Cote d'Ivoire},
	abstract = {In today’s successful Learning Management System (LMS), gathering thousands of students, emergent collective dynamics drive innovative learning experiences where learners help each other in online forums. The benefits of those behaviors were theorized in Vygotsky’s socio-constructivism theory where he insists that the knowledge development of not so formal peer exchanges is beneficial to all participants. Observing and understanding how those dynamics occur could improve course design and help tutors intervene to sustain collective learning. But, although the scientific community acknowledges the importance of theses dynamics, few works have yet been able to grasp and display them in a format tailored to the Massive Open Online Courses (MOOCs)’ instructors. Indeed, only recently have researches been able to articulate the required continuous Natural Language Processing (NLP) and Social Network Analysis (SNA). In this research, we propose an innovative model to compute a collective activity indicator to answer the problem of detecting and visualizing the collective dynamics from the MOOCs’s forums interactions. We also present datasets collected from several LMSs and used to illustrate the portability, scalability, interactivity of our first visualizations. Our approach should help develop indicators and Learning Dashboard (LDB) of collective actions for MOOCs. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Collective; Discussion; Learning analytics; Social network models; Visualization},
	keywords = {Curricula; Dynamics; Education computing; Learning systems; Natural language processing systems; Collective dynamics; Constructivism theories; Innovative learning; Knowledge development; Learning management system; Massive open online course; NAtural language processing; Scientific community; E-learning},
	correspondence_address = {M. Koné; LIUM, Le Mans Université, Le Mans, France; email: malik.kone.etu@univ-lemans.fr},
	editor = {Lane H.C. and Zvacek S. and Uhomoibhi J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303058458-0},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mena201951,
	author = {Mena, Miguel Alonso Canizares and Isaias, Pedro Teixeira},
	title = {Gathering researchers’ requirements to develop a learning technologies dashboard},
	year = {2019},
	journal = {Proceedings of the 12th IADIS International Conference Information Systems 2019, IS 2019},
	pages = {51 – 59},
	doi = {10.33965/is2019_201905l007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073894506&doi=10.33965%2fis2019_201905l007&partnerID=40&md5=337c7462425cd37028f8d676da09c678},
	affiliations = {University of Queensland, St Lucia, QLD, Australia},
	abstract = {The learning technologies area has expanded incredibly fast due to the growing and acceptance of technology in the classrooms. As a result, the data produced by students is vast and is growing in each of the learning technologies used, leading to a possibility of discovering patterns that can help to enhance the student experience. However, a clear research regarding the adoption of learning technologies and how to spread this research is limited and almost inexistent. Most of the research revolves around students or teachers disregarding the researcher’s standpoint. All the tools and artefacts such as dashboards that have helped to improve both students and teachers’ knowledge are absent for researchers. Hence, this paper is aimed on finding and defining the most common learning technologies platforms and tools as well as the user requirements to build a dashboard to display this information considering the researchers’ objectives. In this regard, an online survey was created and sent to both researchers interested in the learning technology area and learning technologies designers. The responses were analysed with quantitative tools such as exploratory factor analysis, analysis of variance, t-tests and graphical means. The results led to the user requirements for developing a dashboard. © 2019 IADIS Press. All rights reserved.},
	author_keywords = {Dashboard Design; Learning Analytics; Learning Technologies; Quantitative Research},
	keywords = {Factor analysis; Information systems; Information use; Students; Acceptance of technologies; Exploratory factor analysis; Learning Analytics; Learning technology; Quantitative research; Quantitative tool; Student experiences; User requirements; Engineering education},
	editor = {Nunes M.B. and Isaias P. and Powell P. and Ravesteijn P. and Ongena G. and Rodrigues L.},
	publisher = {IADIS Press},
	isbn = {978-989853387-6},
	language = {English},
	abbrev_source_title = {Proc. IADIS Int. Conf. Inf. Syst., IS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Beile2020435,
	author = {Beile, Penny and Choudhury, Kanak and Mulvihill, Rachel and Wang, Morgan},
	title = {Aligning library assessment with institutional priorities: A study of student academic performance and use of five library services},
	year = {2020},
	journal = {College and Research Libraries},
	volume = {81},
	number = {3},
	pages = {435 – 458},
	doi = {10.5860/crl.81.3.435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083314655&doi=10.5860%2fcrl.81.3.435&partnerID=40&md5=e7b8e14814e98e8aee192d7a349b2cba},
	affiliations = {University of Central Florida, United States; Department of Statistics, Iowa State University, United States; UCF Downtown Library, University of Central Florida, United States},
	abstract = {This large-scale study was conducted for the purposes of determining how representa-tive library users are compared to the whole student population, to explore how library services contribute to student success, and to position the library to be included in the institution’s learning analytics landscape. To that end, data were collected as students at University of Central Florida (n = 25,336) interacted with five library service points over four semesters. Analysis revealed a positive association between students who used one or more library services and higher end-of-semester GPAs. The article empha-sizes how results were disseminated and ongoing work to build an interactive learning analytics library dashboard that complements existing institutional dashboards. © 2020, Association of College and Research Libraries. All rights reserved.},
	correspondence_address = {M. Wang; University of Central Florida, United States; email: Chung-ching.wang@ucf.edu},
	publisher = {Association of College and Research Libraries},
	issn = {00100870},
	language = {English},
	abbrev_source_title = {Coll. Res. Libr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Kiat2019628,
	author = {Kiat, Cheong Hee and Chye, Koh Hian and Chong, Sylvia and Ying, Lim Wei and Rebekah},
	title = {Learning analytics in SUSS: Vision, action, implementation, translation and collaboration},
	year = {2019},
	journal = {ASCILITE 2019 - Conference Proceedings - 36th International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Personalised Learning. Diverse Goals. One Heart.},
	pages = {628 – 629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088541417&partnerID=40&md5=c998c41a004ceec44eb55ce11036ccd6},
	affiliations = {Singapore University of Social Sciences, Singapore},
	abstract = {Universities invest substantial resources into supporting learners to enhance their academic success. As universities become more inclusive and accessible, the range of learner ability increases, making learner-support more critical. For the Singapore University of Social Sciences (SUSS), an added impetus stems from large enrolment of adult learners. These include learners who balance family, work and study, and learners who left formal study for several years. For many, the learner-support is a critical component of their learning experience and academic success. SUSS’s learner-support is implemented primarily by academic units interacting with the learners. This is facilitated by the Business Intelligence & Analytics (BI&A) department and Teaching & Learning Centre (TLC). BI&A implements learning analytics projects and dashboards to deploy the analytics findings, while TLC translates the findings to enhance learner support. This data-driven support facilitates “personalised learning” for effective teaching and learning experiences. Adopting top-down strategies and bottom-up initiatives, the SUSS learning analytics eco-system comes together to provide support that enhances the learners’ learning and academic success. The panel discussion of 4 presentations will share how stakeholders collaborate to increase academic success. The significance of this session is the institutional-wide application and implementation, which is unique in the current educational landscape. © ASCILITE 2019 Singapore University of Social Sciences. All Rights Reserved.},
	author_keywords = {Institutional analytics; Learning analytics; Teaching and learning support},
	keywords = {Adult learners; Critical component; Data driven; Effective teaching; Formal studies; Learning experiences; Panel discussions; Personalised learning; Educational technology},
	editor = {Wei S.C.Y. and Mun C.K. and Alphonso A.},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	language = {English},
	abbrev_source_title = {ASCILITE - Conf. Proc. - Int. Conf. Innov., Pract. Res. Use Educ. Technol. Tert. Educ.: Pers. Learn. Diverse Goals One Heart},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hardebolle20201622,
	author = {Hardebolle, C. and Jermann, P. and Pinto, F. and Tormey, R.},
	title = {Impact of a learning analytics dashboard on the practice of students and teachers},
	year = {2020},
	journal = {SEFI 47th Annual Conference: Varietas Delectat... Complexity is the New Normality, Proceedings},
	pages = {1622 – 1632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077813668&partnerID=40&md5=fb748f8c7c4608661e6738e76ef536b9},
	affiliations = {Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland},
	abstract = {This paper reports results of the deployment of a learning analytics dashboard in the context of introductory Maths, Physics and Chemistry courses in the first year of the Engineering bachelor of a Swiss technical university. Informed by research on self-regulated learning, learning analytics dashboards and the social practice of learning in Higher Education, the tool includes a learning diary feature where students report their progress and the difficulties encountered in solving the course exercises. Both students and teachers have access to a dashboard showing an overview of the class progress and difficulties, the student view including personalized feedback. We present usage and survey data, and show how these help to identify key intervention principles to maximize the impact of learning analytics dashboards on the practice of students and teachers. © 2020 SEFI 47th Annual Conference: Varietas Delectat... Complexity is the New Normality, Proceedings. All rights reserved.},
	author_keywords = {Learning; Learning analytics dashboards; Problem solving; Self-regulated learning; Social practice of teaching},
	keywords = {Problem solving; Students; Teaching; Higher education; Learning; Learning analytics dashboards; Learning diaries; Personalized feedback; Self-regulated learning; Social practices; Technical universities; Chemical analysis},
	correspondence_address = {C. Hardebolle; Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; email: cecile.hardebolle@epfl.ch},
	editor = {Nagy B.V. and Murphy M. and Jarvinen H.-M. and Kalman A.},
	publisher = {European Society for Engineering Education (SEFI)},
	isbn = {978-287352018-2},
	language = {English},
	abbrev_source_title = {SEFI Annu. Conf.: Var. Delect.... Complex. New Norm., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Shabaninejad2020486,
	author = {Shabaninejad, Shiva and Khosravi, Hassan and Leemans, Sander J. J. and Sadiq, Shazia and Indulska, Marta},
	title = {Recommending insightful drill-downs based on learning processes for learning analytics dashboards},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12163 LNAI},
	pages = {486 – 499},
	doi = {10.1007/978-3-030-52237-7_39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089612623&doi=10.1007%2f978-3-030-52237-7_39&partnerID=40&md5=0aa9dcf7b1be0a2a3009f15e6f89ea78},
	affiliations = {The University of Queensland, Brisbane, Australia; Queensland University of Technology, Brisbane, Australia},
	abstract = {Learning Analytics Dashboards (LADs) make use of rich and complex data about students and their learning activities to assist educators in understanding and making informed decisions about student learning and the design and improvement of learning processes. With the increase in the volume, velocity, variety and veracity of data on students, manual navigation and sense-making of such multi-dimensional data have become challenging. This paper proposes an analytical approach to assist LAD users with navigating the large set of possible drill-down actions to identify insights about learning behaviours of the sub-cohorts. A distinctive feature of the proposed approach is that it takes a process mining lens to examine and compare students’ learning behaviours. The process oriented approach considers the flow and frequency of the sequences of performed learning activities, which is increasingly recognised as essential for understanding and optimising learning. We present results from an application of our approach in an existing LAD using a course with 875 students, with high demographic and educational diversity. We demonstrate the insights the approach enables, exploring how the learning behaviour of an identified sub-cohort differs from the remaining students and how the derived insights can be used by instructors. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Drill down analysis; Intelligent dashboards; Learning analytics dashboards; Process mining in education},
	keywords = {Air navigation; Artificial intelligence; Drills; Infill drilling; Analytical approach; Informed decision; Learning Activity; Learning process; Multidimensional data; Process mining; Process-oriented approaches; Student learning; Students},
	correspondence_address = {S. Shabaninejad; The University of Queensland, Brisbane, Australia; email: shiva.shabani@gmail.com},
	editor = {Bittencourt I.I. and Cukurova M. and Luckin R. and Muldner K. and Millán E.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303052236-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{2020,
	title = {LASI-SPAIN 2020 - Learning Analytics Summer Institute Spain 2020: Learning Analytics. Time for Adoption?},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2671},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092061518&partnerID=40&md5=defdeb40dcb99171df3bb6aa586e0f04},
	abstract = {The proceedings contain 15 papers. The topics discussed include: an initial analysis of prediction techniques as a support for the flipped classroom; looking for a dropout predictor based on the instructional design of online courses; combining clustering and sequential pattern mining to detect behavioral differences in log data: conceptualization and case study; early prediction of students' efficiency during online assessments using a long-short term memory architecture; specifying information dashboards’ interactive features through meta-model instantiation; conceptual framework for process-oriented feedback through learning analytics dashboards; towards rewards-based gamification in collaborative learning flow patterns based on learning analytics; and visualizing educational game data: a case study of visualizations to support teachers.},
	editor = {Martinez-Mones A. and Universidad de Valladolid, Department of Computer Science, Campus Miguel Delibes, Valladolid and Alvarez A. and Universidad del Pais Vasco UPV/EHU, Department of Computer Languages and Systems, Paseo Manuel Lardizabal 1, Donostia, Gipuzkoa and Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Dimitriadis Y. and Universidad de Valladolid, Department of Theory of Signal and Communications and Telematics Engineering, Campus Miguel Delibes, Valladolid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Winstone2019225,
	author = {Winstone, Naomi},
	title = {Facilitating students’ use of feedback: Capturing and tracking impact using digital tools},
	year = {2019},
	journal = {The Impact of Feedback in Higher Education: Improving Assessment Outcomes for Learners},
	pages = {225 – 242},
	doi = {10.1007/978-3-030-25112-3_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084852515&doi=10.1007%2f978-3-030-25112-3_13&partnerID=40&md5=828ffc00e18ec8acab7c33d755b6bd1c},
	affiliations = {University of Surrey, Guildford, United Kingdom},
	abstract = {This chapter explores the potential for digital tools to capture and track the impact of feedback. Advocating a shift from transmission-focused to learning-focused feedback processes, the chapter surfaces challenges inherent to visualising the impact of feedback processes and then reviews uses of learning analytics to illuminate students’ responses to feedback. The potential to capture the digital footprint of students’ interactions with feedback is discussed with reference to an e-portfolio system with a learning analytics dashboard. In this example, students were able to synthesise multiple feedback exchanges, visualise their key strengths and areas for development, and record and monitor actions on the basis of feedback information. Winstone argues that it is important for feedback impact to be visible to students as well as educators. © Te Editor(s) (if applicable) and Te Author(s), under exclusive licence to Springer Nature Switzerland AG 2019.},
	correspondence_address = {N. Winstone; University of Surrey, Guildford, United Kingdom; email: n.winstone@surrey.ac.uk},
	publisher = {Palgrave Macmillan},
	isbn = {978-303025112-3; 978-303025111-6},
	language = {English},
	abbrev_source_title = {The Impact of Feedback in High. Education: Improving Assess. Outcomes for Learners},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@ARTICLE{Prinsloo20192810,
	author = {Prinsloo, Paul},
	title = {A social cartography of analytics in education as performative politics},
	year = {2019},
	journal = {British Journal of Educational Technology},
	volume = {50},
	number = {6},
	pages = {2810 – 2823},
	doi = {10.1111/bjet.12872},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069924872&doi=10.1111%2fbjet.12872&partnerID=40&md5=4d8b49c55287c146a8cc969b2fd49ef8},
	affiliations = {College of Economic and Management Sciences, University of South Africa (Unisa), South Africa},
	abstract = {Data—their collection, analysis and use—have always been part of education, used to inform policy, strategy, operations, resource allocation, and, in the past, teaching and learning. Recently, with the emergence of learning analytics, the collection, measurement, analysis and use of student data have become an increasingly important research focus and practice. With (higher) education having access to more student data, greater variety and nuanced/granularity of data, as well as collecting and using real-time data, it is crucial to consider the data imaginary in higher education, and, specifically, analytics as performative politics. Data and data analyses are often presented as representing “reality” and, as such, are seminal in institutional “truth-making,” whether in the context of operational or student learning data. In the broader context of critical data studies (CDS), this social cartography examines and maps the “data frontier” and the “data gaze” within the context of the dominant narrative of evidence-based management and the data imaginary in higher education. Following an analysis of the main assumptions in evidence-based management and the power of metrics, this paper presents a social cartography of data analytics not only as representational, but as actant, and as performative politics. Practitioner Notes What is already known about this topic Student data in higher education are increasingly used not only to inform operational and strategic planning, but to inform and shape curricula, pedagogy and student learning. The collection, measurement, analysis and use of student data are informed by a particular data imaginary in service of evidence-based management. Data and analytics are seen as objective, neutral representations of reality and used as basis for informing policy, operational planning, resource allocation, and, increasingly, learning analytics and student facing dashboards. What this paper adds Critically examines data analytics in higher education as “truth-making” and never neutral, and always as provisional snapshots of “reality” serving particular, often undeclared, assumptions and interests. Situates learning analytics as the collection, measurement, analysis and use of student data in the broader context of the data imaginary and student data as “data frontier”. Provides evidence that data analytics is not only representational, but, increasingly, performative and political. Implications for practice and/or policy Makes explicit some of the theoretical, political, epistemological and ontological assumptions underpinning and sustaining the data imaginary in higher education. Foregrounds the need for more critical approaches to our expectations, collections, analyses and use of student data. Argues the need for policy and practitioners to recognise the inherent political and performative nature of data and data analysis, and the need for transparency, accountability and care. © 2019 British Educational Research Association},
	keywords = {Data Analytics; Maps; Resource allocation; Critical approach; Evidence-based managements; Higher education; Neutral representations; Operational planning; Research focus; Student learning; Teaching and learning; Students},
	correspondence_address = {P. Prinsloo; College of Economic and Management Sciences, University of South Africa (Unisa), South Africa; email: prinsp@unisa.ac.za},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@ARTICLE{Ahn201970,
	author = {Ahn, June and Campos, Fabio and Hays, Maria and Digiacomo, Daniela},
	title = {Designing in context: Reaching beyond usability in learning analytics dashboard design},
	year = {2019},
	journal = {Journal of Learning Analytics},
	volume = {6},
	number = {2},
	pages = {70 – 85},
	doi = {10.18608/jla.2019.62.5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073365701&doi=10.18608%2fjla.2019.62.5&partnerID=40&md5=490fd58cee006273b10ec0705326d98c},
	affiliations = {University of California, Irvine, School of Education, 3200 Education, Irvine, 92697, CA, United States; New York University, Steinhardt School of Culture, Education and Human Development, 82 Washington Square East, New York, 10003, NY, United States; University of Washington, Seattle, College of Education, 2012 Skagit Lane, Miller Hall, Seattle, 98105, WA, United States; University of Kentucky, School of Information Science, 320 Little Fine Arts Library, Lexington, 40506, KY, United States},
	abstract = {Researchers and developers of learning analytics (LA) systems are increasingly adopting human-centred design (HCD) approaches, with growing need to understand how to apply design practice in different educational settings. In this paper, we present a design narrative of our experience developing dashboards to support middle school mathematics teachers’ pedagogical practices, in a multi-university, multi-school district, improvement science initiative in the United States. Through documentation of our design experience, we offer ways to adapt common HCD methods — contextual design and design tensions — when developing visual analytics systems for educators. We also illuminate how adopting these design methods within the context of improvement science and research– practice partnerships fundamentally influences the design choices we make and the focal questions we undertake. The results of this design process flow naturally from the appropriation and repurposing of tools by district partners and directly inform improvement goals. © 2019, UTS ePRESS. All rights reserved.},
	author_keywords = {Computer interaction; Data sensemaking; Design narratives; Human; Human-centred design; Improvement science; Learning dashboards; Learning sciences},
	correspondence_address = {J. Ahn; University of California, Irvine, School of Education, 3200 Education, Irvine, 92697, United States; email: junea@uci.edu},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 94; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Aguilar2019280,
	author = {Aguilar, Stephen J. and Baek, Clare},
	title = {Motivated information seeking and graph comprehension among college students},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {280 – 289},
	doi = {10.1145/3303772.3303805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062787433&doi=10.1145%2f3303772.3303805&partnerID=40&md5=c3e619c2c3fc0cea4499b41cecc63eb0},
	affiliations = {University of Southern California, Rossier School of Education, Los Angeles, CA, United States},
	abstract = {Learning Analytics Dashboards (LADs) are predicated on the notion that access to more academic information can help students regulate their academic behaviors, but what is the association between information seeking preferences and help-seeking practices among college students? If given access to more information, what might college students do with it? We investigated these questions in a series of two studies. Study 1 validates a measure of information-seeking preferences-the Motivated Information-Seeking Questionnaire (MISQ)-using a college student sample drawn from across the country (n = 551). In a second study, we used the MISQ to measure college students' (n=210) performance-avoid (i.e., avoiding seeming incompetent in relation to one's peers) and performance-approach (i.e., wishing to outperform one's peers) information seeking preferences, their help-seeking behaviors, and their ability to comprehend line graphs and bar graphs-two common graphs types for LADs. Results point to a negative relationship between graph comprehension and help-seeking strategies, such as attending office hours, emailing one's professor for help, or visiting a study center-even after controlling for academic performance and demographic characteristics. This suggests that students more capable of readings graphs might not seek help when needed. Further results suggest a positive relationship between performance-approach information-seeking preferences, and how often students compare themselves to their peers. This study contributes to our understanding of the motivational implications of academic data visualizations in academic settings, and increases our knowledge of the way students interpret visualizations. It uncovers tensions between what students want to see, versus what it might be more motivationally appropriate for them to see. Importantly, the MISQ and graph comprehension measure can be used in future studies to better understand the role of students' information seeking tendencies with regard to their interpretation of various kinds of feedback present in LADs. © 2019 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.},
	author_keywords = {Higher education; Instrument validation; Motivation; Non-cognitive factors; Visualizations},
	keywords = {Graph theory; Information use; Motivation; Visualization; Academic performance; Cognitive factors; Demographic characteristics; Graph comprehensions; Higher education; Instrument validation; Measure of information; Performance approach; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036256-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Bennett202015,
	author = {Bennett, Liz and Folley, Sue},
	title = {Four design principles for learner dashboards that support student agency and empowerment},
	year = {2020},
	journal = {Journal of Applied Research in Higher Education},
	volume = {12},
	number = {1},
	pages = {15 – 26},
	doi = {10.1108/JARHE-11-2018-0251},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067005027&doi=10.1108%2fJARHE-11-2018-0251&partnerID=40&md5=fb0e1ea219d0e005fca01ba55cc2a76f},
	affiliations = {School of Education and Professional Development, University of Huddersfield, Huddersfield, United Kingdom},
	abstract = {Purpose: The purpose of this paper is to take a student-centred perspective to understanding the range of ways that students respond to receiving information about their learning behaviours presented on a dashboard. It identifies four principles to inform the design of dashboards which support learner agency and empowerment, features which Prinsloo and Slade (2016) suggest are central to ethical adoption of learning analytics. Design/methodology/approach: The study involved semi-structured interviews with 24 final-year undergraduates to explore the students’ response to receiving dashboards that showed the students’ achievement and other learning behaviours. Findings: The paper identifies four principles that should be used when designing and adopting learner dashboards to support student agency and empowerment. Research limitations/implications: The study was based on a small sample of undergraduate students from the final year from one academic school. The data are based on students’ self-reporting. Practical implications: The paper suggests that these four principles are guiding tenets for the design and implementation of learner dashboards in higher education. The four principles are: designs that are customisable by students; foregrounds students sense making; enables students to identify actionable insights; and dashboards are embedded into educational processes. Originality/value: The paper’s originality is that it illuminates student-centred principles of learner dashboard design and adoption. © 2019, Emerald Publishing Limited.},
	author_keywords = {Dashboards; Design; Learning analytics; Student agency},
	correspondence_address = {L. Bennett; School of Education and Professional Development, University of Huddersfield, Huddersfield, United Kingdom; email: e.bennett@hud.ac.uk},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {20507003},
	language = {English},
	abbrev_source_title = {J. Appl. Res. High. Edu.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Green Open Access}
}

@CONFERENCE{2020,
	title = {CrossMMLA 2020 - Proceedings of CrossMMLA in Practice: Collecting, Annotating and Analyzing Multimodal Data across Spaces, co-located with 10th International Learning and Analytics Conference, LAK 2020},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089108728&partnerID=40&md5=365a45bfa5d15fdfcdc4d954d7364086},
	abstract = {The proceedings contain 12 papers. The topics discussed include: context-aware multimodal learning analytics taxonomy; towards teacher orchestration load-aware teacher-facing dashboards; MMLA approach to track participation behavior in collaboration in collocated blended settings; physiology-aware learning analytic using pedagogical agents; designing and implementing multimodal data collection in classroom to capture metacognition in collaborative learning; multimodal temporal network analysis to improve learner support and teaching; using multimodal learning analytics to explore how children experience educational motion-based touchless games; the challenge of interaction assignment for learning analytics on large digital tabletop displays; and facilitating self-regulated learning with personalized scaffolds on student’s own regulation activities.},
	editor = {Giannakos M. and Spikol D. and Molenaar I. and Di Mitri D. and Sharma K. and Ochoa X. and Hammad R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ahmad2020467,
	author = {Ahmad, Atezaz and Schneider, Jan and Drachsler, Hendrik},
	title = {Openlair an open learning analytics indicator repository dashboard},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12315 LNCS},
	pages = {467 – 471},
	doi = {10.1007/978-3-030-57717-9_46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091157335&doi=10.1007%2f978-3-030-57717-9_46&partnerID=40&md5=380b77f72afdf447d84aa21409210a04},
	affiliations = {DIPF—Leibniz Institute for Research and Information in Education, Frankfurt, Germany},
	abstract = {In this demo paper we present a tool that provides an overview of learning analytics indicators, metrics, and learning design activities in the field of learning analytics over the past decade. The system is based on our literature review from a total of 123 scientific publications, where we fetched 132 indicators and their metrics, 40 learning activities, and eight learning events (i.e., create, explore, practice, imitate, receive, debate, meta-learn, and experiment). Therefore, we proposed a system that will provide indicators and metrics based on learning activities and learning events selected by the stakeholders. The aim is to help the stakeholders in the application of learning analytics. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Dashboards; Indicators; Learning activities; Learning analytics; Learning design; Learning events; Metrics},
	keywords = {Artificial intelligence; Computer science; Computers; Indicators and metrics; Learning Activity; Learning designs; Literature reviews; Open learning; Scientific publications; Learning systems},
	correspondence_address = {A. Ahmad; DIPF—Leibniz Institute for Research and Information in Education, Frankfurt, Germany; email: ahmad@dipf.com},
	editor = {Alario-Hoyos C. and Rodríguez-Triana M.J. and Scheffel M. and Arnedillo-Sánchez I. and Dennerlein S.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303057716-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Clauss2019,
	author = {Clauss, Alexander and Lenk, Florian and Schoop, Eric},
	title = {Enhancing international virtual collaborative learning with social learning analytics},
	year = {2019},
	journal = {2019 2nd International Conference on New Trends in Computing Sciences, ICTCS 2019 - Proceedings},
	doi = {10.1109/ICTCS.2019.8923106},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077011300&doi=10.1109%2fICTCS.2019.8923106&partnerID=40&md5=4973fb94c0db39a0f625db2c3aa1b3e8},
	affiliations = {Wirtschaftsinformatik Esp, Information Management TU Dresden, Dresden, Germany},
	abstract = {The ability to work collaboratively in intercultural virtual teams, is constantly gaining importance for the labour market. Virtual Mobility enables students to acquire the necessary intercultural teamwork skills while remaining locally integrated into their regular studies. But still, international virtual collaborative learning scenarios demand much time and effort for planning and coordination which binds resources. The support concepts for such collaborative virtual learning groups are also resource-intensive, because learners should be accompanied by qualified e-Tutors to optimise learning results both at individual and group level. Classical summative tests and exams are rather unsuitable for the assessment of collaboration as expected learning outcome. These arrangements also need new formative assessment forms, as participants need active and ongoing feedback. A meaningful assessment of learning processes and outcomes should not only be based on the observation of 'soft' factors but should also be complemented by 'hard', fixed, automatically measurable, quantitative indicators. To gain these hard indicators the research project ISLA-Indicator-based Social Learning Analytics was launched. This paper presents the procedure for implementation as well as virtual presence, content creation and relationships within the community as first derived indicators and their prototypical visualisation in a Learning Analytics Dashboard. © 2019 IEEE.},
	author_keywords = {Collaborative Learning; Learning Analytics Dashboard; Social Learning Analytics; Virtual Mobility},
	keywords = {Employment; Students; Collaborative learning; Collaborative virtual learning; Expected learning outcomes; Learning Analytics Dashboard; Quantitative indicators; Social learning; Virtual collaborative learning; Virtual mobility; E-learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172812882-5},
	language = {English},
	abbrev_source_title = {Int. Conf. New Trends Comput. Sci., ICTCS - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Droit2020100,
	author = {Droit, Alena and Rieger, Bodo},
	title = {Learning analytics in the flipped classroom - Learning dashboards from the students' perspective},
	year = {2020},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2020-January},
	pages = {100 – 107},
	doi = {10.24251/hicss.2020.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108179220&doi=10.24251%2fhicss.2020.013&partnerID=40&md5=ca506cc52b1a4e8601755944801a0f03},
	affiliations = {Osnabrück University, Germany},
	abstract = {Blended learning courses offer the opportunity to collect large amounts of learning data that can help students to improve their performance. The presentation of learning data often takes place in the form of Learning Analytics dashboards, which are already in use at some universities. Students, who are the primary data providers and at the same time the main users, should be involved in the process of developing Learning Analytics dashboards from the beginning. Since there are only a few guidelines for designing these dashboards in literature, we conducted a study with 139 business and information systems students who, in addition to answering a questionnaire, also designed their dashboards with the help of a case study. The dashboard analysis provides detailed insights into the design of the functional and information scope, as well as the presentation of the data for Learning Analytics dashboards. © 2020 IEEE Computer Society. All rights reserved.},
	keywords = {Blended learning; Case-studies; Classroom learning; Large amounts; Learning course; Learning data; Performance; Primary data; Student perspectives; Students},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813313-3},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Watanabe202067,
	author = {Watanabe, Hiroyuki and Chen, Li and Geng, Xuewang and Goda, Yoshiko and Shimada, Atsushi},
	title = {Design of the time management skills acquisition system using learning analytics},
	year = {2020},
	journal = {17th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2020},
	pages = {67 – 73},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099558905&partnerID=40&md5=8651a6225a49622aa3e69d7635e992a1},
	affiliations = {Faculty of Arts and Science, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Graduate School of Human-Environment Studies, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Research Center for Instructional Systems, Kumamoto University, 2-39-1, Kurokami, Chuo-ku, Kumamoto, 860-0862, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan},
	abstract = {Learning skills include abilities, habits, understanding, and attitudes which are utilized to achieve learning. Students will not achieve good grades unless they properly manage their limited study time. However, it is not easy for them to organize their own study time and learn how to use it efficiently. Notably, learning analytics has not been used in previous research for time management. Learning analytics provides students with accurate data that they can use to manage their study time. Therefore, in this study, we designed a system based on a learning analytics approach with functions that allow students to make their own learning schedules and reflect on their learning behaviors. The system has visualization, calendars, and reflection functions, which are used by both students and their instructors. © 2020 17th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2020. All rights reserved.},
	author_keywords = {Learning Analytics; Learning Analytics Dashboard; Learning Skills; Time Management Skills},
	keywords = {E-learning; Learning systems; Acquisition systems; Analytic approach; Learn+; Learning analytic; Learning analytic dashboard; Learning schedule; Learning skills; Management skills; Skills acquisition; Time management skill; Students},
	publisher = {IADIS Press},
	isbn = {978-989870422-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Rohloff2019,
	author = {Rohloff, Tobias and Sauer, Dominic and Meinel, Christoph},
	title = {Student Perception of a Learner Dashboard in MOOCs to Encourage Self-Regulated Learning},
	year = {2019},
	journal = {TALE 2019 - 2019 IEEE International Conference on Engineering, Technology and Education},
	doi = {10.1109/TALE48000.2019.9225939},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094873626&doi=10.1109%2fTALE48000.2019.9225939&partnerID=40&md5=55746084fceda94d281eb92cb4bf799c},
	affiliations = {Hasso Plattner Institute, Potsdam, Germany},
	abstract = {In online learning environments like Massive Open Online Courses (MOOCs), where teachers cannot provide individual support and guidance for thousands of students, self-regulated learning (SRL) is a critical metacognitive skillset for students' achievement. However, not every student intuitively self-regulates its learning and therefore technical solutions can help to apply SRL strategies. Learner dashboards with visualizations about the learner's progress and behavior are able to create awareness, encourage self-reflection, and perhaps motivate students to plan and adjust their learning behavior to achieve their learning objectives. Hence, such Learning Analytics tools can support the SRL strategies self-evaluation and strategic planning. To examine this potential, a learner dashboard was integrated into the HPI MOOC platform. This work presents the design process, the concept, and an evaluation of the first dashboard iteration. The perceived usefulness and usability are investigated, and in addition, the question will be considered whether the dashboard encourages students to apply self-regulated learning. The positive results pave the way for future research and a next iteration of the learner dashboard. © 2019 IEEE.},
	author_keywords = {Learner Dashboard; Learning Analytics; MOOCs; Self-Regulated Learning; Technology-Enhanced Learning},
	keywords = {Computer aided instruction; E-learning; Engineering education; Learning behavior; Learning objectives; Massive open online course; Online learning environment; Perceived usefulness; Self-regulated learning; Student perceptions; Technical solutions; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172812665-4},
	language = {English},
	abbrev_source_title = {TALE - IEEE Int. Conf. Eng., Technol. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Garcia-Zubia201942,
	author = {Garcia-Zubia, Javier and Cuadros, Jordi and Serrano, Vanessa and Hernandez-Jayo, Unai and Angulo-Martinez, Ignacio and Villar, Aitor and Orduna, Pablo and Alves, Gustavo},
	title = {Dashboard for the VISIR remote lab},
	year = {2019},
	journal = {Proceedings of the 2019 5th Experiment at International Conference, exp.at 2019},
	pages = {42 – 46},
	doi = {10.1109/EXPAT.2019.8876527},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074355668&doi=10.1109%2fEXPAT.2019.8876527&partnerID=40&md5=c7df6ce81469729e28098928de5731fc},
	affiliations = {Facultad de Ingeniería, University of Deusto, Bilbao, Spain; IQS, University Ramón Llull, Barcelona, Spain; LabsLand S.L, Bilbao, Spain; Inst. Sup. Engenehria de Porto, Inst. Politecnico de Porto, Porto, Portugal},
	abstract = {The VISIR dashboard (VISIR-DB) is a learning analytics tool connected with the VISIR remote lab. In VISIR, every action performed by a student from the interface over the remote laboratory and back is logged and recorded. VISIR-DB helps visualizing, in a fast and deep way, the recorded logs from this communication. Using this tool, a teacher can analyze and understand better how the students are using the remote lab during their learning process on analog electronics. With this information, the VISIR platform can be improved and the use of remote labs can be better understood. © 2019 IEEE.},
	author_keywords = {dashboard; learning analytics; remote laboratory},
	keywords = {Analog electronics; Analytics tools; dashboard; learning analytics; Learning process; Remote laboratories; Remote-labs; Laboratories},
	editor = {Cardoso A. and Restivo M.T.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172813637-0},
	language = {English},
	abbrev_source_title = {Proc. Exp. Int. Conf., exp.at},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Changhao2019744,
	author = {Changhao, Liang and Botički, Ivica and Ogata, Hiroaki},
	title = {Supporting teachers in group work formation and analytics for in-class group activities},
	year = {2019},
	journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
	volume = {1},
	pages = {744 – 749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077676315&partnerID=40&md5=4ce387d721dbf74ce9516ada5c42c4b0},
	affiliations = {Kyoto University, Japan; Faculty of Electrical Engineering and Computing, Zagreb, Croatia},
	abstract = {This paper introduces a system for collaborative learning which is designed to assist teachers in forming and grading groups for in-class group activities. The system is implemented as an extension of a learning analytics dashboard system and uses log data from a learning management system for operation. It consists of a group formation parameter console and the results console where formed groups are visualized and can be graded. The system supports teachers by using algorithms based on reliable learning evidence thereby simplifying the group formation process. All the group formation and grading data is logged thereby cyclically providing an infrastructure for subsequent collaborative learning activities. © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
	author_keywords = {Collaborative Learning; CSCL; Group Formation; Learning Analytics},
	keywords = {Grading; Information management; Class group; Collaborative learning; Collaborative learning activities; CSCL; Group formations; Learning Analytics; Learning management system; System supports; Learning systems},
	correspondence_address = {L. Changhao; Kyoto University, Japan; email: liang.changhao.84c@st.kyoto-u.ac.jp},
	editor = {Chang M. and So H.-J. and Wong L.-H. and Yu F.-Y. and Shih J.-L. and Boticki I. and Chen M.-P. and Dewan A. and Haklev S. and Koh E. and Kojiri T. and Li K.-C. and Sun D. and Wen Y.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972143-1},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Rohloff2019296,
	author = {Rohloff, Tobias and Oldag, Sören and Renz, Jan and Meinel, Christoph},
	title = {Utilizing web analytics in the context of learning analytics for large-scale online learning},
	year = {2019},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {April-2019},
	pages = {296 – 305},
	doi = {10.1109/EDUCON.2019.8725118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065914969&doi=10.1109%2fEDUCON.2019.8725118&partnerID=40&md5=71f5fbc3d0aa85563d6786aea78cf2fa},
	affiliations = {Hasso Plattner Institute, Potsdam, Germany},
	abstract = {Today, Web Analytics (WA) is commonly used to obtain key information about users and their behavior on websites. Besides, with the rise of online learning, Learning Analytics (LA) emerged as a separate research field for collecting and analyzing learners' interactions on online learning platforms. Although the foundation of both methods is similar, WA has not been profoundly used for LA purposes. However, especially large-scale online learning environments may benefit from WA as it is more sophisticated and well-established in comparison to LA. Therefore, this paper aims to examine to what extent WA can be utilized in this context, without compromising the learners' data privacy. For this purpose, Google Analytics was integrated into the Massive Open Online Course platform of the Hasso Plattner Institute as a proof of concept. It was tested with two deployments of the platform: openHPI and openSAP, where thousands of learners gain academic and industry knowledge about engineering education. Besides capturing behavioral data, the platforms' existing LA dashboards were extended by WA metrics. The evaluation of the integration showed that WA covers a large part of the relevant metrics and is particularly suitable for obtaining an overview of the platform's global activity, but reaches its limitations when it comes to learner-specific metrics. © 2019 IEEE.},
	author_keywords = {Learning analytics; Learning dashboards; Moocs; Online learning environments; Web analytics},
	keywords = {Computer aided instruction; Data privacy; Engineering education; Learning analytics; Learning dashboards; Moocs; Online learning environment; Web analytics; E-learning},
	editor = {Schreiter S. and Ashmawy A.K.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-153869506-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Paredes2020500,
	author = {Paredes, Yancy Vance and Siegle, Robert F. and Hsiao, I-Han and Craig, Scotty D.},
	title = {Educational Data Mining and Learning Analytics for Improving Online Learning Environments},
	year = {2020},
	journal = {Proceedings of the Human Factors and Ergonomics Society},
	volume = {64},
	number = {1},
	pages = {500 – 504},
	doi = {10.1177/1071181320641113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127329602&doi=10.1177%2f1071181320641113&partnerID=40&md5=d107b661f7fc26db9ace0f182491b374},
	affiliations = {Arizona State University, Mesa, AZ, United States},
	abstract = {The proliferation of educational technology systems has led to the advent of a large number of datasets related to learner interaction. New fields have emerged which aim to use this data to identify interventions that could help the learners become efficient and effective in their learning. However, these systems have to follow user-centered design principles to ensure that the system is usable and the data is of high quality. Human factors literature is limited on the topics regarding Educational Data Mining (EDM) and Learning Analytics (LA). To develop improved educational systems, it is important for human factors engineers to be exposed to these data-oriented fields. This paper aims to provide a brief introduction to the fields of EDM and LA, discuss data visualization and dashboards that are used to convey results to learners, and finally to identify where human factors can aid other fields. © 2020 by Human Factors and Ergonomics Society. All rights reserved.},
	keywords = {Computer aided instruction; Data visualization; E-learning; Ergonomics; Large datasets; Learning systems; User centered design; Design Principles; Educational systems; Educational technology systems; Exposed to; High quality; Learner interaction; Online learning environment; Data mining},
	publisher = {SAGE Publications Inc.},
	issn = {10711813},
	coden = {PHFSD},
	language = {English},
	abbrev_source_title = {Proc Hum Factors Ergon Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Conijn202030,
	author = {Conijn, Rianne and Van Waes, Luuk and van Zaanen, Menno},
	title = {Human-centered design of a dashboard on students’ revisions during writing},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12315 LNCS},
	pages = {30 – 44},
	doi = {10.1007/978-3-030-57717-9_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091137829&doi=10.1007%2f978-3-030-57717-9_3&partnerID=40&md5=2046a87e6330c9dda214ee2ae1afac25},
	affiliations = {Department of Cognitive Science and Artificial Intelligence, Tilburg University, Tilburg, Netherlands; Human-Technology Interaction Group, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Management, University of Antwerp, Antwerp, Belgium; South African Centre for Digital Language Resources, Potchefstroom, South Africa},
	abstract = {Learning dashboards are often used to provide teachers with insight into students’ learning processes. However, simply providing teachers with data on students’ learning processes is not necessarily beneficial for improving learning and teaching; the data need to be actionable. Recently, human-centered learning analytics has been suggested as a solution to realize more effective and actionable dashboards. Accordingly, this study aims to identify how these human-centered approaches could be used to design an interpretable and actionable learning dashboard on students’ writing processes. The design consists of three iterative steps. First, visualizations on students’ revision process, created from keystroke data, were evaluated with writing researchers. Second, the updated visualizations were used to co-design a paper prototype of the dashboard within a focus group session with writing teachers. Finally, the paper prototype was transformed into a digital prototype and evaluated by teachers in individual user test interviews. The results showed that this approach was useful for designing an interpretable dashboard with envisioned actions, which could be further tested in classroom settings. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Human-centered design; Keystroke logging; LATUX; Writing analytics; Writing process},
	keywords = {Digital devices; Students; Visualization; Classroom settings; Digital prototype; Focus groups; Human-centered designs; Improving learning; Learning process; Paper prototypes; Writing process; Design},
	correspondence_address = {R. Conijn; Human-Technology Interaction Group, Eindhoven University of Technology, Eindhoven, Netherlands; email: m.a.conijn@tue.nl},
	editor = {Alario-Hoyos C. and Rodríguez-Triana M.J. and Scheffel M. and Arnedillo-Sánchez I. and Dennerlein S.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303057716-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Williamson20192794,
	author = {Williamson, Ben},
	title = {Policy networks, performance metrics and platform markets: Charting the expanding data infrastructure of higher education},
	year = {2019},
	journal = {British Journal of Educational Technology},
	volume = {50},
	number = {6},
	pages = {2794 – 2809},
	doi = {10.1111/bjet.12849},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068698021&doi=10.1111%2fbjet.12849&partnerID=40&md5=9c15c56fe81f05af713a8dbfb4f63827},
	affiliations = {Centre for Research in Digital Education, University of Edinburgh, United Kingdom},
	abstract = {Digital data are transforming higher education (HE) to be more student-focused and metrics-centred. In the UK, capturing detailed data about students has become a government priority, with an emphasis on using student data to measure, compare and assess university performance. The purpose of this paper is to examine the governmental and commercial drivers of current large-scale technological efforts to collect and analyse student data in UK HE. The result is an expanding data infrastructure which includes large-scale and longitudinal datasets, learning analytics services, student apps, data dashboards and digital learning platforms powered by artificial intelligence (AI). Education data scientists have built positive pedagogic cases for student data analysis, learning analytics and AI. The politicization and commercialization of the wider HE data infrastructure is translating them into performance metrics in an increasingly market-driven sector, raising the need for policy frameworks for ethical, pedagogically valuable uses of student data in HE. Practitioner Notes What is already known about this topic Learning analytics, education data science and artificial intelligence are opening up new ways of collecting and analysing student data in higher education. UK government policies emphasize the use of student data for improvements to teaching and learning. What this paper adds A conceptual framework from “infrastructure studies” demonstrates how political objectives and commercial aims are fused to HE data systems, with data infrastructure becoming a key tool of government reform. A critical infrastructure analysis shows that student data processing technologies are being developed and deployed to measure university performance through student data. Implications for practice and/or policy Educators and managers in universities need to prepare robust institutional frameworks to govern their use of student data. Learning analytics practitioners, data scientists, learning scientists and social science researchers need to collaborate with the policy community and education technology developers on new policy frameworks to challenge narrow uses of student data as performance metrics. © 2019 British Educational Research Association},
	keywords = {Artificial intelligence; Binary alloys; Commerce; Data handling; E-learning; Large dataset; Metadata; Public policy; Social sciences computing; Conceptual frameworks; Data infrastructure; Data processing technologies; Education technology; Institutional framework; Performance metrics; Teaching and learning; Technological effort; Students},
	correspondence_address = {B. Williamson; Centre for Research in Digital Education, University of Edinburgh, United Kingdom; email: ben.williamson@ed.ac.uk},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 106; All Open Access, Green Open Access}
}

@ARTICLE{Yoo20201,
	author = {Yoo, Mina and Jin, Sung-Hee},
	title = {Development and evaluation of learning analytics dashboards to support online discussion activities},
	year = {2020},
	journal = {Educational Technology and Society},
	volume = {23},
	number = {2},
	pages = {1 – 18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088649017&partnerID=40&md5=90180cb897f2412ace977a1b364058ab},
	affiliations = {Kyungil University, South Korea; Hanbat National University, South Korea},
	abstract = {Online discussion plays an increasingly significant role in asynchronous online learning environments. While previous attempts have been made to develop learning analytics dashboards to facilitate such discussions, most of these dashboards have been designed without reference to data or visualization techniques that have been proven to make online discussions more effective. This study identified the difficulties and inconveniences experienced by learners in online discussion activities and generated a set of visual design guidelines for overcoming them. Applying these guidelines, a set of learning analytics dashboards were developed and evaluated. The study was conducted according to prototyping methodology, which yielded five prototype dashboards that display information on participation, interaction, discussion content keywords, discussion message types, and the distribution of debate opinions, respectively. The developed dashboards were then revised and refined in a three-step process: (1) expert validation to verify that the dashboards complied with the visual guidelines and provided learners with the information they needed; (2) tests to identify usability problems, collect qualitative and quantitative data, and determine participant satisfaction; and (3) user experience evaluations to determine how learners and instructors perceived their interactions with the dashboards. Practical and empirical discussions are provided based on the results, which offer a valuable base of user experience data that can be used in future studies. © 2020 National Taiwan Normal University.},
	author_keywords = {Learning analytics; Online discussion; Prototype development; Prototyping methodology; Visual dashboard},
	correspondence_address = {S.-H. Jin; Hanbat National University, South Korea; email: shjin@hanbat.ac.kr},
	publisher = {National Taiwan Normal University},
	issn = {11763647},
	language = {English},
	abbrev_source_title = {Educational Technology and Society},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@ARTICLE{Cha20192799,
	author = {Cha, Hyun-Jin and Park, Taejung},
	title = {Applying and evaluating visualization design guidelines for a MOOC dashboard to facilitate self-regulated learning based on learning analytics},
	year = {2019},
	journal = {KSII Transactions on Internet and Information Systems},
	volume = {13},
	number = {6},
	pages = {2799 – 2823},
	doi = {10.3837/tiis.2019.06.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070974062&doi=10.3837%2ftiis.2019.06.002&partnerID=40&md5=3be085e40058f7c99ec6eee42ef1a995},
	affiliations = {School of General Education, Dankook University, 119, Dandae-ro, Dongnam-gu, Cheonan-si, 31116, Chungnam, South Korea; College of Liberal Arts and Interdisciplinary Studies, Kyonggi University, 154-42, Gwanggyosan-ro, Yeongtong-gu, Suwon-si, 16227, Gyeonggi-do, South Korea},
	abstract = {With the help of learning analytics, MOOCs have wider potential to succeed in learning through promoting self-regulated learning (SRL). The current study aims to apply and validate visualization design guidelines for a MOOC dashboard to enhance such SRL capabilities based on learning analytics. To achieve the research objective, a MOOC dashboard prototype, LM-Dashboard, was designed and developed, reflecting the visualization design guidelines to promote SRL. Then, both expert and learner participants evaluated LM-Dashboard through iterations to validate the visualization design guidelines and perceived SRL effectiveness. The results of expert and learner evaluations indicated that most of the visualization design guidelines on LM-Dashboard were valid and some perceived SRL aspects such as monitoring a student’s learning progress and assessing their achievements with time management were beneficial. However, some features on LM-Dashboard should be improved to enhance SRL aspects related to achieving their learning goals with persistence. The findings suggest that it is necessary to offer appropriate feedback or tips as well as to visualize learner behaviors and activities in an intuitive and efficient way for the successful cycle of SRL. Consequently, this study contributes to establishing a basis for the visual design of a MOOC dashboard for optimizing each learner’s SRL. © 2019 KSII.},
	author_keywords = {Design guidelines; Learning analytics; MOOCs; Self-regulated learning},
	keywords = {Visualization; Learning analytics; Learning goals; Learning progress; MOOCs; Research objectives; Self-regulated learning; Time management; Visualization designs; Design},
	correspondence_address = {T. Park; College of Liberal Arts and Interdisciplinary Studies, Kyonggi University, Suwon-si, 154-42, Gwanggyosan-ro, Yeongtong-gu, 16227, South Korea; email: edutech@kyonggi.ac.kr},
	publisher = {Korean Society for Internet Information},
	issn = {19767277},
	language = {English},
	abbrev_source_title = {KSII Trans. Internet Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access}
}

@ARTICLE{Sedrakyan2020443,
	author = {Sedrakyan, Gayane and Dannerlein, Sebastian and Pammer-Schindler, Viktoria and Lindstaedt, Stefanie},
	title = {Measuring learning progress for serving immediate feedback needs: Learning process quantification framework (lpqf)},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12315 LNCS},
	pages = {443 – 448},
	doi = {10.1007/978-3-030-57717-9_42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091137956&doi=10.1007%2f978-3-030-57717-9_42&partnerID=40&md5=97620b0537cba22327b31742cbb074c0},
	affiliations = {Department of Industrial Engineering and Business Information Systems, University of Twente, Enschede, Netherlands; Institute of Interactive Systems and Data Science, Technical University of Graz, Graz, Austria; Know-Center, Graz, Austria},
	abstract = {Our earlier research attempts to close the gap between learning behavior analytics based dashboard feedback and learning theories by grounding the idea of dashboard feedback onto learning science concepts such as feedback, learning goals, (socio-/meta-) cognitive mechanisms underlying learning processes. This work extends the earlier research by proposing mechanisms for making those concepts and relationships measurable. The outcome is a complementary framework that allows identifying feedback needs and timing for their provision in a generic context that can be applied to a certain subject in a given LMS. The research serves as general guidelines for educators in designing educational dashboards, as well as a starting research platform in the direction of systematically matching learning sciences concepts with data and analytics concepts. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Dashboards; Feedback automation; Learning analytics; Measuring learning progress; Process-oriented feedback},
	keywords = {Artificial intelligence; Computer science; Computers; Cognitive mechanisms; Generic contexts; Immediate feedbacks; Learning behavior; Learning process; Learning progress; Learning science; Research platforms; Learning systems},
	correspondence_address = {G. Sedrakyan; Department of Industrial Engineering and Business Information Systems, University of Twente, Enschede, Netherlands; email: g.sedrakyan@utwente.nl},
	editor = {Alario-Hoyos C. and Rodríguez-Triana M.J. and Scheffel M. and Arnedillo-Sánchez I. and Dennerlein S.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303057716-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Cukurova2020270,
	author = {Cukurova, Mutlu and Zhou, Qi and Spikol, Daniel and Landolfi, Lorenzo},
	title = {Modelling collaborative problem-solving competence with transparent learning analytics: Is video data enough?},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {270 – 275},
	doi = {10.1145/3375462.3375484},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082397681&doi=10.1145%2f3375462.3375484&partnerID=40&md5=6b46d1917ea724e13c4bbd72e78a6ad1},
	affiliations = {University College London, United Kingdom; Malmo University, Sweden; Scuola Superiore sant'Anna, Italy},
	abstract = {In this study, we describe the results of our research to model collaborative problem-solving (CPS) competence based on analytics generated from video data. We have collected ~500 mins video data from 15 groups of 3 students working to solve design problems collaboratively. Initially, with the help of OpenPose, we automatically generated frequency metrics such as the number of the face-in-the-screen; and distance metrics such as the distance between bodies. Based on these metrics, we built decision trees to predict students' listening, watching, making, and speaking behaviours as well as predicting the students' CPS competence. Our results provide useful decision rules mined from analytics of video data which can be used to inform teacher dashboards. Although, the accuracy and recall values of the models built are inferior to previous machine learning work that utilizes multimodal data, the transparent nature of the decision trees provides opportunities for explainable analytics for teachers and learners. This can lead to more agency of teachers and learners, therefore can lead to easier adoption. We conclude the paper with a discussion on the value and limitations of our approach. © 2020 Association for Computing Machinery.},
	author_keywords = {Collaborative problem-solving; Decision trees; Multimodal learning analytics; Physical learning analytics; Video analytics},
	keywords = {Decision trees; Forestry; Problem solving; Students; Trees (mathematics); Video recording; Automatically generated; Collaborative problem solving; Design problems; Distance metrics; Multi-modal data; Multi-modal learning; Physical learning analytics; Video analytics; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037712-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@CONFERENCE{Mokhtar2019,
	author = {Mokhtar, Salimah and Alshboul, Jawad A. Q. and Shahin, Ghassan O. A.},
	title = {Towards Data-driven Education with Learning Analytics for Educator 4.0},
	year = {2019},
	journal = {Journal of Physics: Conference Series},
	volume = {1339},
	number = {1},
	doi = {10.1088/1742-6596/1339/1/012079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077818153&doi=10.1088%2f1742-6596%2f1339%2f1%2f012079&partnerID=40&md5=cb66e156da7df898e50968f65800b7ef},
	affiliations = {Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia; Department of Information Systems and Multimedia, Palestine Polytechnic University, Hebron, Palestine},
	abstract = {Learning analytics has not been extensively used yet as necessary tools in the management and operation of public universities in Malaysia. Massive amount of data been created and collected on students at the faculty but mostly remain dark and unexplored. Generating many reports, having lots of alerts or dashboards does not make a faculty data-driven. To be smart, a faculty must utilize technology to enable and support better planning and decision-making, and to be data-driven, a faculty must have analytics to drive actions for value. This paper intends to explore the impact of IR 4.0 in the field of education and research into the possibility on how a university or a faculty can adapt to IR 4.0 and function in the big data environment. It will present the concept of Education 4.0, data-driven education and learning analytics. To transform, universities must rethink the current teaching practices and then redesign learning to suit future demand. This is discuss next. Finally, it summarizes the roles that educators 4.0 should play in Education 4.0. © Published under licence by IOP Publishing Ltd.},
	keywords = {Decision making; Digital storage; Data driven; Data environment; Education and researches; Malaysia; Public universities; Teaching practices; Engineering education},
	editor = {Rahim R. and Dharma R. and Hendrik B. and Muhammad A.},
	publisher = {Institute of Physics Publishing},
	issn = {17426588},
	language = {English},
	abbrev_source_title = {J. Phys. Conf. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Ajanovski2019,
	author = {Ajanovski, Vangel V.},
	title = {Body of knowledge explorer: Long-term student guidance across the computer-science domain},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3364510.3364531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076797422&doi=10.1145%2f3364510.3364531&partnerID=40&md5=d6b488062ce96efa6311abda532d442c},
	affiliations = {Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, North Macedonia},
	abstract = {A visual domain exploration tool is introduced that offers several viewpoints as parts of a personalized student advice and guidance solution: explanation of the personal progress over a reference body of knowledge areas, within the field of study; mapping of the actual courses in relation to the field of study where the taught topics belong; guidance in choosing courses aligned towards personal interests and abilities in respective areas. The student can visualize areas that are successfully covered by past courses, areas that are a probable point of risk, mandating greater focus and determination, and out-of-topic areas where the student is predicted to perform with greater success. The student can view the past trends of personal progress, and experiment with future tracks. © 2019 ACM.},
	author_keywords = {Curriculum mapping; Educational recommender systems; Learning analytics dashboards; Student progress tracking},
	keywords = {Curricula; Mapping; Risk management; Body of knowledge; Domain exploration; Learning analytics dashboards; Student guidance; Student progress; Topic areas; Students},
	correspondence_address = {V.V. Ajanovski; Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, North Macedonia; email: vangel.ajanovski@finki.ukim.mk},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037715-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Ulfa201949,
	author = {Ulfa, Saida and Fattawi, Izzull and Surahman, Ence and Yusuke, Hayashi},
	title = {Investigating Learners' Perception of Learning Analytics Dashboard to Improve Learning Interaction in Online Learning System},
	year = {2019},
	journal = {2019 5th International Conference on Education and Technology, ICET 2019},
	pages = {49 – 54},
	doi = {10.1109/ICET48172.2019.8987229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081044361&doi=10.1109%2fICET48172.2019.8987229&partnerID=40&md5=8801047c08065e35c57c5a6b49822060},
	affiliations = {Educational Technology PUI-PT, State University of Malang, Malang, Indonesia; Islamic Education Institut Agama Islam Nurul Hakim, Lombok, Indonesia; Educational Technology Universitas Negeri Malang, Malang, Indonesia; Graduate School of Engineering Hiroshima University, Hiroshima, Japan},
	abstract = {Big data has changed the approach in designing an e-Learning. When students interact with e-Learning content, automatically generating data, we can collect and trace their learning tracks. The data is processed and analyzed, then used to understand the behavioral characteristics of the user or student to enable a personalized learning experience. In this study, learning analytics dashboard was used to improve learning interaction which impacts the learning successfulness. Tests were conducted on 67 students in the Educational Technology Department of the State University of Malang and distributed questionnaires and then analyzed using descriptive methods. The result is that most of the students who take online learning using the learning analytics dashboard find it helpful to carry out self-evaluations of their interaction hence they can manage their learning. The results of the study showed that most participants agreed that LAD could provide information to them regarding their interactions with learning content (M = 4.15, SD = 0.557), learning environment (M = 4.13, SD = 0.457), as well as the participants could conduct problem identification during their learning process (M = 3.88, SD = 0.477). © 2019 IEEE.},
	author_keywords = {learner's perception; learning analytics; learning interaction},
	keywords = {Computer aided instruction; Learning systems; Students; Surveys; Behavioral characteristics; Learners' perceptions; learning analytics; Learning environments; Learning interactions; On-line learning systems; Personalized learning; Problem identification; E-learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172814908-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Educ. Technol., ICET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Piety20201023,
	author = {Piety, Philip J.},
	title = {Expanding the frame: Designing a learning analytics system using a theory of learning},
	year = {2020},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {2},
	pages = {1023 – 1030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102872649&partnerID=40&md5=1127af3d6c88cf6fa58f3a839849c2d8},
	affiliations = {University of Maryland, College Park, United States},
	abstract = {This essay presents the case of designing a learning analytics system using a theory of learning. Learning analytics systems are often institutional artifacts using data collected from and to support educational practice and practitioners including learning, teachers, and administrators. There is a substantial and growing body of work under the learning analytics banner. Much of it framed technically around data harvested from digital tools and presentation mechanisms called dashboards. Using a specific case involving a collaborative game-based education research project, this paper provides a broad, sociotechnical design perspective through three frame expanding sections: the educational game’s learning theory-driven approach, the information architecture of the learning analytics system, and the activity system that the information from learning analytics information are used within. This paper illustrates a portion of the conceptual landscape that can guide the design, development, and research for these data systems that are potentially consequential for students and educators. © ISLS.},
	keywords = {Digital devices; Activity Systems; Analytics systems; Collaborative games; Education research; Educational game; Information architectures; Socio-technical designs; Theory of learning; Learning systems},
	correspondence_address = {P.J. Piety; University of Maryland, College Park, United States; email: ppiety@umd.edu},
	editor = {Gresalfi M. and Horn I.S.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-173246726-2},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Isaias2020255,
	author = {Isaias, Pedro and Backx Noronha Viana, Adriana},
	title = {On the Design of a Teachers’ Dashboard: Requirements and Insights},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12205 LNCS},
	pages = {255 – 269},
	doi = {10.1007/978-3-030-50513-4_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089165080&doi=10.1007%2f978-3-030-50513-4_19&partnerID=40&md5=a35cfe83e7c05b853bfd89a887d84795},
	affiliations = {University of New South Wales (UNSW – Sydney), Room 2117, Quadrangle Building, Sydney, 2052, Australia; Business School, University of São Paulo, Av. Prof. Luciano Gualberto, 908 - Butantã, São Paulo, 05508-010, SP, Brazil},
	abstract = {The value that data has in the information society is undeniable. However data per se has limited significance, as it requires structure and it needs to be adequately conveyed to the user. Education is no exception to all the sectors currently harnessing the power of the data that stems from the interaction with their various stakeholders. Learning analytics can assist educators to understand how their students are learning, how successful they are at the accomplishment of certain tasks and to identify if they are at risk of failing. A fundamental part of learning analytics is visualisation, which is responsible for the communication of the data that is collected and becomes central in determining the teacher intervention in the learning process. In this paper the authors will present the results of semi-structured interviews that were conducted with lecturers at UNIV faculties and schools, in order to collect their insights regarding what aspects should be considered when design a teachers dashboard. Main requirements as well as major concerns are compiled and discussed. This is specifically useful to guide the future design of a teacher dashboard at UNIV and other universities. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Dashboard design; Learning analytics; Teacher dashboards},
	keywords = {Artificial intelligence; Computer science; Computers; Future designs; Information society; Learning process; Semi structured interviews; Human computer interaction},
	correspondence_address = {P. Isaias; University of New South Wales (UNSW – Sydney), Sydney, Room 2117, Quadrangle Building, 2052, Australia; email: pedro.isaias@unsw.edu.au},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050512-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Daniel201943,
	author = {Daniel, Ben Kei},
	title = {Improving the pedagogy of research methodology through learning analytics},
	year = {2019},
	journal = {Electronic Journal of Business Research Methods},
	volume = {17},
	number = {1},
	pages = {43 – 53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081663181&partnerID=40&md5=c130b7cad03aa156e88c27264b796087},
	affiliations = {University of Otago, Dunedin, New Zealand},
	abstract = {Teaching research methodology is complicated because students often come from a wide range of disciplines, with different prior knowledge, diverse interests and expectations, as such, employing a pedagogical approach that appeals to all students is difficult to achieve. Subsequently, students experience many challenges when learning research methods, to the extent that courses on research methods are increasingly becoming unpopular. The current article presents the design, development and testing of iMethod; a digital learning environment for students to access various forms of online resources (e.g. text, video and audio) on research methods. iMethod tracks and captures student learning analytics, and present the teacher with a dashboard on students' learning trajectories, to enable teachers to identify challenges students face in learning research methods. The learning analytics harvested from iMethod were used to inform the design of a pedagogical programme-analytics and research methods (ARM) that brings together a variety of workshops to support student learning. The article contributes to the growing need to improve the quality of teaching research methods courses. © ACPIL.},
	author_keywords = {Dashboards; Imethod; Learning analytics; Research methodology pedagogy; Teaching research methods},
	correspondence_address = {B.K. Daniel; University of Otago, Dunedin, New Zealand; email: ben.daniel@otago.ac.nz},
	publisher = {Academic Publishing Limited},
	issn = {14777029},
	language = {English},
	abbrev_source_title = {Electron. J. Bus. Res. Methods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Pecori201996,
	author = {Pecori, Riccardo and Suraci, Vincenzo and Ducange, Pietro},
	title = {Efficient computation of key performance indicators in a distance learning university},
	year = {2019},
	journal = {Information Discovery and Delivery},
	volume = {47},
	number = {2},
	pages = {96 – 105},
	doi = {10.1108/IDD-09-2018-0050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062468115&doi=10.1108%2fIDD-09-2018-0050&partnerID=40&md5=8e1a448aefea0f88fe845827da6b194d},
	affiliations = {SMARTEST Research Centre, eCampus University, Novedrate, CO, Italy},
	abstract = {Purpose: Managing efficiently educational Big Data, produced by Virtual Learning Environments, is becoming a compelling necessity, especially for those universities providing distance learning. This paper aims to propose a possible framework to compute efficiently key performance indicators, summarizing the trends of students’ academic careers, by using educational Big Data. Design/methodology/approach: The framework is designed and implemented in a distributed fashion. The parallel computation of the indicators through Map and Reduce nodes is carefully described, together with the workflow of data, from the educational sources to a NoSQL database and to the learning analytics engine. Findings: This framework was tested at eCampus University, an Italian distance learning institution, and it was able to significantly reduce the amount of time needed to compute key performance indicators. Moreover, by implementing a proper data representation dashboard, it resulted in a useful help and support for educational decisions and performance analyses and for revealing possible criticalities. Originality/value: The framework proposed integrates for the first time, to the best of the authors’ knowledge, a set of modules, designed and implemented in a distributed fashion, to compute key performance indicators for distance learning institutions. It can be used to analyze the dropouts and the outcomes of students and, therefore, to evaluate the performances of universities, which can, in turn, propose effective improvements toward enhancing the overall e-learning scenario. © 2019, Emerald Publishing Limited.},
	author_keywords = {E-Learning; Educational big data; Key performance indicators; Learning analytics; MapReduce; Virtual learning environment},
	correspondence_address = {R. Pecori; SMARTEST Research Centre, eCampus University, Novedrate, Italy; email: riccardo.pecori@uniecampus.it},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {23986247},
	language = {English},
	abbrev_source_title = {Information Discov. Deliv.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Liu2020157,
	author = {Liu, Arita L. and Nesbit, John C.},
	title = {Dashboards for computer-supported collaborative learning},
	year = {2020},
	journal = {Intelligent Systems Reference Library},
	volume = {158},
	pages = {157 – 182},
	doi = {10.1007/978-3-030-13743-4_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063719816&doi=10.1007%2f978-3-030-13743-4_9&partnerID=40&md5=4d820315a544ca9f0e9ffd2c41e5472c},
	affiliations = {Simon Fraser University, Burnaby, Canada},
	abstract = {In the field of learning analytics, dashboards are visual displays that help instructors and students monitor performance, track goals and modify learning-related activities and plans. Student-facing dashboards provide visualizations of the data students need to take responsibility for their own learning, while instructor-facing dashboards help instructors guide and orchestrate student learning. After summarizing the spectrum of learning analytics research on dashboards, we critically review dashboards designed to support collaborative learning and examine research on student-facing and instructor-facing dashboards for problem-based learning, project-based learning, collaborative argumentation, and various team-based learning activities. We explain key concepts such as group awareness, shared mental models, and group cognition, and review tools including shared mirroring systems, ambient displays, and learning dashboards. We then identify opportunities and challenges in the burgeoning field of learning analytics dashboards for computer-supported collaborative learning and argue that learning dashboards can be a useful aid in facilitating collaborative learning but only when designed with a clear pedagogical purpose informed by research and theory will learning dashboards be able to foster effective teaching and learning strategies. © 2020, Springer Nature Switzerland AG.},
	correspondence_address = {A.L. Liu; Simon Fraser University, Burnaby, Canada; email: arita_liu@sfu.ca},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684394},
	language = {English},
	abbrev_source_title = {Intell. Syst. Ref. Libr.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25}
}

@CONFERENCE{Thiruppugal202048,
	author = {Thiruppugal, Mithila},
	title = {An Investigation into the Design of Learning Analytic Dashboards (LAD) for the Enhancement of Motivation, Engagement and Achievements in an E-Learning Environment},
	year = {2020},
	journal = {Proceedings of the 33rd International BCS Human Computer Interaction Conference, BCS HCI 2020},
	pages = {48 – 50},
	doi = {10.14236/ewic/HCI20DC.11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124572389&doi=10.14236%2fewic%2fHCI20DC.11&partnerID=40&md5=5b35425ff8abff2302d73003cd018eca},
	affiliations = {Middlesex University, United Kingdom},
	abstract = {The current scenario of higher education reflects an increased permeation of digital technology, with this integration has influenced both learning and teaching practices. One of the main impacts has been in the advancement of Learning Management Systems (LMS). By facilitating synchronous and asynchronous communication and interactions linked to a virtual environment, LMSs have become integral to higher education. Learning Analytic Dashboards (LAD) are the digital platforms used by educational institutions for collecting, measuring, analysing and reporting data concerning learners and their activities and achievements. Related to that, as an area of research and development, learning Analytics is a rapidly growing field of LMS and of particular significance to LAD design. Many universities are utilising LADs, but guidelines to support effective design underpinned by research are limited. This study aims to assess the role of LAD design in optimising learning by influencing factors such as student motivation, engagement and achievement. The significance of this study is that it will offer novel insights on principles that should be adopted while designing LADs capable of leading students towards better learning experience and performance. Based on implications from previous studies as well as an empirical investigation on the need for such tools, this study will develop a prototype of a LAD that befits with student-facing demands. © Thiruppugal. Published by BCS Learning and Development Ltd.},
	author_keywords = {Information visualisation; Learning analytics dashboard; Learning management system},
	keywords = {Computer aided instruction; E-learning; Information management; Learning systems; Motivation; Virtual reality; 'current; Digital technologies; E-learning environment; High educations; Information visualization; Learning analytic dashboard; Learning and teachings; Learning management system; Synchronous and asynchronous communications; Teaching practices; Students},
	publisher = {BCS Learning and Development Ltd.},
	language = {English},
	abbrev_source_title = {Proc. Int. BCS Hum. Comput. Interact. Conf., BCS HCI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Olalde202073,
	author = {Olalde, Iñigo Arriaran and Larrañaga, Nagore Ipiña},
	title = {Conceptual framework for process-oriented feedback through learning analytics dashboards},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2671},
	pages = {73 – 80},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092023977&partnerID=40&md5=f07fd0eec91836642d5831add0117ce0},
	affiliations = {Mondragon Unibertsitatea, Spain},
	abstract = {The number of students enrolled in online higher education courses is increasing, and as a result, more data on their learning process is being generated. By exploring this student behavior data through learning analytics, both student and teacher can be provided with process-oriented feedback in the form of dashboards. However, little is known about the typology of relevant feedback in the dashboard to different learning objectives, students and teachers. Although most dashboards and the feedback they provide are based solely on student performance indicators, research shows that such feedback is not sufficient. This article attempts to define a conceptual model that visualizes the relationships between the design of a Learning Analytics Dashboard (LAD) and the concepts of learning science in order to provide process-oriented feedback that supports the regulation of learning. The aim of the work is not to propose a specific design of the LAD to provide feedback, but rather a conceptual framework for the choice of concepts for that design, and therefore to help understand future data needs as a basis for the educational feedback of the dashboards. As a conclusion of our research, we can say that having LADs adapted to any profile (student, teacher, etc.) can improve decision-making processes by showing each user the information that interests them most in the way that best enables them to understand it. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Learning analytics dashboards; Learning sciences; Process-oriented feedback},
	keywords = {Decision making; Education computing; Learning systems; Students; Conceptual frameworks; Decision making process; Higher education; Learning objectives; Learning science; Relevant feedback; Student behavior; Student performance; E-learning},
	editor = {Martinez-Mones A. and Universidad de Valladolid, Department of Computer Science, Campus Miguel Delibes, Valladolid and Alvarez A. and Universidad del Pais Vasco UPV/EHU, Department of Computer Languages and Systems, Paseo Manuel Lardizabal 1, Donostia, Gipuzkoa and Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Dimitriadis Y. and Universidad de Valladolid, Department of Theory of Signal and Communications and Telematics Engineering, Campus Miguel Delibes, Valladolid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen2020295,
	author = {Chen, Li and Lu, Min and Goda, Yoshiko and Shimada, Atsushi and Yamada, Masanori},
	title = {Factors of the use of learning analytics dashboard that affect metacognition},
	year = {2020},
	journal = {17th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2020},
	pages = {295 – 302},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099576427&partnerID=40&md5=cf95f68c814a0f54f42445b303a036f0},
	affiliations = {Graduate School of Human-Environment Studies, Kyushu University 1, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Faculty of Arts and Science, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Research Center for Instructional Systems, Kumamoto University, 2-39-1, Kurokami, Chuo-ku, Kumamoto, 8600862, Japan; Faculty of Information Science and Electrical Engineering, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan},
	abstract = {In this study, we used a learning analytics dashboard (LAD) in a higher education course to support students' metacognition and evaluated the effects of its use. The LAD displays students' reading path and specific behaviors when viewing digital learning materials. The study was conducted on 53 university students to identify the factors that affected metacognition changes in terms of their awareness and behavior dimensions when using the LAD. In terms of results, first, the students' perception of visual attraction for the LAD, and behaviors related to reflection such as deleting annotations they had previously added, positively affected the changes in the knowledge of cognition dimension of metacognition. Second, students' perception of behavioral changes by using the LAD had positive effects on the regulation of cognition dimension of metacognition. However, the behaviors of using some cognitive tools, negatively affected knowledge of cognition, which indicated the necessity to provide more guidance or feedback to students. © 2020 17th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2020. All rights reserved.},
	author_keywords = {Learning Analytics Dashboard; Learning Behaviors; Metacognition; Self-Regulated Learning},
	keywords = {E-learning; Students; Awareness and behaviors; Digital learning materials; Education course; High educations; Learning analytic dashboard; Learning behavior; Metacognition; Self-regulated learning; Student perceptions; University students; Cognitive systems},
	publisher = {IADIS Press},
	isbn = {978-989870422-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Chen2019237,
	author = {Chen, Qing and Li, Zhen and Pong, Ting-Chuen and Qu, Huamin},
	title = {Designing narrative slideshows for learning analytics},
	year = {2019},
	journal = {IEEE Pacific Visualization Symposium},
	volume = {2019-April},
	pages = {237 – 246},
	doi = {10.1109/PacificVis.2019.00036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070680793&doi=10.1109%2fPacificVis.2019.00036&partnerID=40&md5=9d801db5e761891ff078da7b0a698938},
	affiliations = {Hong Kong University of Science and Technology, Hong Kong},
	abstract = {The practical power of data visualization is currently attracting much attention in the e-learning domain. A growing number of studies have been conducted in recent years to help instructors better analyze learner behavior and reflect on their teaching. However, current elearning dashboards and visualization systems usually require a lot of time and effort into the exploration process. Moreover, the lack of communication power of existing systems constrains users from organizing the narrative of information pieces into a compelling data story. In this paper, we have proposed a narrative visualization approach with an interactive slideshow that helps instructors and education experts explore potential learning patterns and convey data stories. This approach contains three key components: guided-tour concept, drill-down path, and dig-in exploration dimension. The use cases further demonstrate the potential of employing this visual narrative approach in the e-learning context. © 2019 IEEE.},
	author_keywords = {Human-centered-computing; Information-Visualization; Visualization; Visualization-application-domains},
	keywords = {E-learning; Flow visualization; Information systems; Visualization; Education experts; Existing systems; Exploration process; Human-centered computing; Information visualization; Learning patterns; Visualization application; Visualization system; Data visualization},
	publisher = {IEEE Computer Society},
	issn = {21658765},
	isbn = {978-153869226-4},
	language = {English},
	abbrev_source_title = {IEEE Pacific Visual. Symp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@CONFERENCE{Majumdar2019351,
	author = {Majumdar, Rwitajit and Warriem, Jayakrishnan M. and Kuromiya, Hiroyuki and Akç Apinar, Gökhan and Flanagan, Brendan and Ogata, Hiroaki},
	title = {Learning evidence Analytics Framework (LEAF) in practice: A2I2 based Teacher Adoption Approach},
	year = {2019},
	journal = {ICCE 2019 - 27th International Conference on Computers in Education, Proceedings},
	volume = {1},
	pages = {351 – 353},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077708690&partnerID=40&md5=7e8e6ad8e1e5c1f8aa703e2d396ebf99},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Japan; NPTEL, Indian Institute of Technology Madras, Chennai, India; Computer Education and Instructional Tech, Hacettepe University, Turkey},
	abstract = {Learning Analytics (LA) platforms can gather data from the teaching-learning interactions during a course. While there have been previous discussions regarding the individual tools, limited scholarship describes the utility of a LA framework for supporting evidence-based teaching-learning practices. We have proposed LEAF, a framework to bridge that gap. We implement the framework in a platform by integrating LMS, learning behaviour sensors such as an ebook reader, learning analytics dashboard and an evidence portal through Learning Tools Interoperability (LTI). The platform was then made available to teachers from different colleges in India to orchestrate their course offering for one semester. This paper describes the design of the teacher training module for the adoption of the platform based on the A2I2 model as its theoretical basis. The A2I2 model explicitly focuses on encouraging scholarship of learning and teaching among participating teachers and thus is an ideal candidate for utilizing an evidence-based framework. © 2019 International Conference on Computers in Education, Proceedings.All right reserved.},
	author_keywords = {A2I2; Evidence-based Education and Learning; LEAF; TEEL},
	keywords = {Personnel training; A2I2; Evidence-based; LEAF; Learning and teachings; Learning tool; Teacher training; Teaching-learning; TEEL; Teaching},
	correspondence_address = {R. Majumdar; Academic Center for Computing and Media Studies, Kyoto University, Japan; email: dr.rwito@gmail.com},
	editor = {Chang M. and So H.-J. and Wong L.-H. and Yu F.-Y. and Shih J.-L. and Boticki I. and Chen M.-P. and Dewan A. and Haklev S. and Koh E. and Kojiri T. and Li K.-C. and Sun D. and Wen Y.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972143-1},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Molenaar2019347,
	author = {Molenaar, I. and Knoop-Van Campen, C.A.N.},
	title = {How Teachers Make Dashboard Information Actionable},
	year = {2019},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {12},
	number = {3},
	pages = {347 – 355},
	doi = {10.1109/TLT.2018.2851585},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049302650&doi=10.1109%2fTLT.2018.2851585&partnerID=40&md5=1f70c1a9fb6b52e72882e95a24af4502},
	affiliations = {Radboud University, Nijmegen, Netherlands},
	abstract = {This study investigates how teachers use dashboards in primary school classrooms. While learners practice on a tablet real-time data indicating learner progress and performance is displayed on teacher dashboards. This study examines how teachers use the dashboards, applying Verberts' learning analytics process model. Teacher dashboard consultations and resulting pedagogical actions were observed in 38 mathematics lessons. In stimulated recall interviews, the 38 teachers were asked to elaborate on how they reflect on and make sense of the information on the dashboard. The results showed that teachers consulted the dashboard on average 8.3 times per lesson. Teachers activated existing knowledge about students and the class to interpret dashboard information. Task and process feedback were the pedagogical actions most often used following dashboard consultation. Additionally, teachers who consulted the dashboard more often activated more and more diverse pedagogical knowledge to interpret the data and, consequently, gave more and more diverse feedback. These results indicated that teacher dashboards were indeed influencing teachers' pedagogical actions in their daily classroom activities. This study provided the first evidence that dashboards progressively impact teaching practice and initiate more profound behavioral changes as teachers become more proficient in using them. © 2008-2011 IEEE.},
	author_keywords = {Adaptive learning technologies; dashboards; learning analytics; technology enhanced learning.},
	keywords = {Analytical models; Education; Education computing; Engineering education; Instruments; Interactive computer systems; Job analysis; Mathematical techniques; Real time systems; Reflection; Adaptive learning; dashboards; Learning analytics; Task analysis; Technology enhanced learning; Teaching},
	correspondence_address = {I. Molenaar; Radboud University, Nijmegen, Netherlands; email: i.molenaar@pwo.ru.nl},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 83; All Open Access, Green Open Access}
}

@ARTICLE{Liu2020548,
	author = {Liu, Songran and Mouri, Kousuke and Ogata, Hiroaki},
	title = {Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12203 LNCS},
	pages = {548 – 557},
	doi = {10.1007/978-3-030-50344-4_39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088743656&doi=10.1007%2f978-3-030-50344-4_39&partnerID=40&md5=6880e6e31fb1b6558739c6055fe87a72},
	affiliations = {BiiiiiT, Inc., Tokyo, Japan; Tokyo University of Agriculture and Technology, Fuchu, Japan; Kyoto University, Kyoto, Japan},
	abstract = {In this paper, we describe about a kind of data flow design that between ubiquitous learning log system called SCROLL and learning analytics and visualizing system called Learning Analytics Dashboard (LAD). SCROLL is a ubiquitous learning system what is logging students’ learning behaviors data in database, and SCROLL can provide students suitable learning method and location to learn efficiently. Lots of paper show that it is appreciate to share the learning data in SCROLL to the other learning analytics system like LTI, Bookroll, Moodle and so on. Learning Analytics Dashboard (LAD) is also a learning data analytics and visualizing system. So share students’ learning data from SCROLL to LAD to show and help students to know their students’ learning situation is the proposal of this paper. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Learning Analytics Dashboard; SCROLL; Ubiquitous learning; xAPI},
	keywords = {Data Analytics; Data transfer; Human computer interaction; Students; Analytics systems; Data-flow design; Learning behavior; Learning data; Learning methods; Learning situation; Ubiquitous learning; Ubiquitous learning logs; Learning systems},
	correspondence_address = {S. Liu; BiiiiiT, Inc., Tokyo, Japan; email: liu.songran@biiiiit.com},
	editor = {Streitz N. and Konomi S.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050343-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Martinez-Maldonado2019383,
	author = {Martinez-Maldonado, Roberto},
	title = {A handheld classroom dashboard: Teachers’ perspectives on the use of real-time collaborative learning analytics},
	year = {2019},
	journal = {International Journal of Computer-Supported Collaborative Learning},
	volume = {14},
	number = {3},
	pages = {383 – 411},
	doi = {10.1007/s11412-019-09308-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075419983&doi=10.1007%2fs11412-019-09308-z&partnerID=40&md5=cb7e212c470772622b0e64e604e2c946},
	affiliations = {Faculty of Information Technologies, Monash University, Melbourne, VIC, Australia},
	abstract = {In Computer-Supported Collaborative Learning (CSCL) classrooms it may be challenging for teachers to keep awareness of certain aspects of the learning process of each small group or assess whether the enactment of the class script deviates from the original plan. Orchestration tools, aimed at supporting the management of the increasing uncertainty and complexity of CSCL classrooms, have been emerging in response. Similarly, learning analytics innovations hold the promise of empowering teachers by making certain aspects of the classroom visible and by providing information that can prompt actionable responses. However, the active role that data may play in teachers’ decision-making and orchestration processes is still not well understood. This paper investigates the perspectives of teachers who used a real-time analytics tool to support the orchestration of a CSCL classroom. A longitudinal study was conducted with a handheld dashboard deployed in a multi-display collaborative classroom during one full academic term. The dashboard showed real-time information about group participation and task progress; the current state of the CSCL script; and a set of text notifications informing teachers of potential students’ misconceptions automatically detected. The study involved four teachers conducting 72 classroom sessions during 10 weeks with a total of 150 students. The teachers’ perspectives discussed in this paper portray the promises and challenges of introducing new technologies aimed at enhancing orchestration and awareness in a CSCL classroom. © 2019, International Society of the Learning Sciences, Inc.},
	author_keywords = {Classroom ecologies; Dashboard; Data visualisation; Learning analytics; Learning design; Multi-display; Small group collaboration; Tabletops},
	correspondence_address = {R. Martinez-Maldonado; Faculty of Information Technologies, Monash University, Melbourne, Australia; email: Roberto.MartinezMaldonado@Monash.edu},
	publisher = {Springer},
	issn = {15561607},
	language = {English},
	abbrev_source_title = {Int. J. Comput.-Supported Collab. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55}
}

@ARTICLE{Brun2019299,
	author = {Brun, Armelle and Bonnin, Geoffray and Castagnos, Sylvain and Roussanaly, Azim and Boyer, Anne},
	title = {Learning analytics made in France: the METAL project},
	year = {2019},
	journal = {International Journal of Information and Learning Technology},
	volume = {36},
	number = {4},
	pages = {299 – 313},
	doi = {10.1108/IJILT-02-2019-0022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069897118&doi=10.1108%2fIJILT-02-2019-0022&partnerID=40&md5=57e7fa43e6be95132c0356edf150ee30},
	affiliations = {LORIA – KIWI, Université de Lorraine, Nancy, France},
	abstract = {Purpose: The purpose of this paper is to present the METAL project, a French open learning analytics (LA) project for secondary school, that aims at improving the quality of teaching. The originality of METAL is that it relies on research through exploratory activities and focuses on all the aspects of a learning analytics environment. Design/methodology/approach: This work introduces the different concerns of the project: collection and storage of multi-source data owned by a variety of stakeholders, selection and promotion of standards, design of an open-source LRS, conception of dashboards with their final users, trust, usability, design of explainable multi-source data-mining algorithms. Findings: All the dimensions of METAL are presented, as well as the way they are approached: data sources, data storage, through the implementation of an LRS, design of dashboards for secondary school, based on co-design sessions data mining algorithms and experiments, in line with privacy and ethics concerns. Originality/value: The issue of a global dissemination of LA at an institution level or at a broader level such as a territory or a study level is still a hot topic in the literature, and is one of the focus and originality of this paper, associated with the large spectrum of different concerns. © 2019, Emerald Publishing Limited.},
	author_keywords = {Data collection and storage; Data mining; Educational data; Multi-source data; Teacher and learner dashboards},
	correspondence_address = {A. Brun; LORIA – KIWI, Université de Lorraine, Nancy, France; email: armelle.brun@loria.fr},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {20564880},
	language = {English},
	abbrev_source_title = {Int. J. Inf. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{Park20191547,
	author = {Park, Yeonjeong and Jo, Il-Hyun},
	title = {Factors that affect the success of learning analytics dashboards},
	year = {2019},
	journal = {Educational Technology Research and Development},
	volume = {67},
	number = {6},
	pages = {1547 – 1571},
	doi = {10.1007/s11423-019-09693-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069188675&doi=10.1007%2fs11423-019-09693-0&partnerID=40&md5=592b79c6bfd1eff3522a24eed5baeda8},
	affiliations = {Center for Teaching and Learning, Honam University, Kwangju, South Korea; Department of Educational Technology, College of Education, Ewha Womans University, Seoul, South Korea},
	abstract = {A learning analytics dashboard enables teachers and students to monitor and reflect on their online teaching and learning patterns. This study was a review of prior studies on learning analytics dashboards to show the need to develop an instrument for measuring dashboard success. An early version of the instrument based on the framework of Kirkpatrick’s four levels of evaluation was revised through expert reviews and exploratory factor analysis. The instrument contains five criteria: visual attraction, usability, level of understanding, perceived usefulness, and behavioral changes. The validity of the instrument was subsequently tested with factor analysis. A total of 271 samples from students who utilized a learning analytics dashboard for one semester were collected and analyzed using structural equation modeling. In the model with fair fit, the visual attraction and usability of the dashboard significantly affected the level of understanding, and level of understanding affected perceived usefulness, which in turn significantly affected potential behavior changes. The findings of this study have implications for designers who want to develop successful learning analytics dashboards, and further research is suggested related to measuring the cross validity of the evaluation instrument to broaden its usage. © 2019, Association for Educational Communications and Technology.},
	author_keywords = {Dashboard; Factor analysis; Learning analytics; Structural equation modeling},
	correspondence_address = {I.-H. Jo; Department of Educational Technology, College of Education, Ewha Womans University, Seoul, South Korea; email: ijo@ewha.ac.kr},
	publisher = {Springer},
	issn = {10421629},
	language = {English},
	abbrev_source_title = {Educ. Technol. Res. Dev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 53}
}

@CONFERENCE{Herodotou20201737,
	author = {Herodotou, Christothea and Boroowa, Avinash and Hlosta, Martin and Rienties, Bart},
	title = {What do distance learning students need from student analytics?},
	year = {2020},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {3},
	pages = {1737 – 1738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102939611&partnerID=40&md5=b8c56c9f2de0baf5165082f0d1f7fb64},
	affiliations = {The Open University, United Kingdom},
	abstract = {This study explores the perspectives of distance learners about student-facing learning analytics. Nineteen middle-aged, white, online students answered eight forum questions about a hypothetical scenario of a student who struggles to balance work and study and who was given access to a learning analytics dashboard. The dashboard presented comparative performance and engagement information and personalised study recommendations. Findings showed that study recommendations were highly favoured by students whereas peer comparisons were mostly viewed as not useful and demotivating. © ISLS.},
	keywords = {Distance education; Comparative performance; Distance learners; Students},
	editor = {Gresalfi M. and Horn I.S.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-173246727-9},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{2020,
	title = {15th European Conference on Technology Enhanced Learning, EC-TEL 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12315 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091133891&partnerID=40&md5=4e72a25fe963ee492918e47939524684},
	abstract = {The proceedings contain 49 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Knowledge-driven wikipedia article recommendation for electronic textbooks; infobits: A mobile application to foster digital competencies of senior citizens; human-centered design of a dashboard on students’ revisions during writing; student awareness and privacy perception of learning analytics in higher education; user assistance for serious games using hidden markov model; guiding socio-technical reflection of ethical principles in tel software development: The srep framework; git4school: A dashboard for supporting teacher interventions in software engineering courses; exploring the design and impact of online exercises for teacher training about dynamic models in mathematics; interactive concept cartoons: Exploring an instrument for developing scientific literacy; quality evaluation of open educational resources; designing digital activities to screen locomotor skills in developing children; towards adaptive social comparison for education; simulation based assessment of epistemological beliefs about science; an operational framework for evaluating the performance of learning record stores; an approach to support interactive activities in live stream lectures; educational escape games for mixed reality; measuring learning progress for serving immediate feedback needs: Learning process quantification framework (lpqf); data-driven game design: The case of difficulty in educational games; extracting topics from open educational resources; supporting gamification with an interactive gamification analytics tool (igat); openlair an open learning analytics indicator repository dashboard; casuallearn: A smart application to learn history of art; applying instructional design principles on augmented reality cards for computer science education; what teachers need for orchestrating robotic classrooms; preface.},
	editor = {Alario-Hoyos C. and Rodríguez-Triana M.J. and Scheffel M. and Arnedillo-Sánchez I. and Dennerlein S.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303057716-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ullmann201941,
	author = {Ullmann, Thomas Daniel and De Liddo, Anna and Bachler, Michelle},
	title = {A Visualisation Dashboard for Contested Collective Intelligence. Learning Analytics to Improve Sensemaking of Group Discussion; [Un panel de visualización para la Inteligencia Colectiva Controvertida. Analíticas de aprendizaje para la mejora de creación de ideas en grupos de discusión]},
	year = {2019},
	journal = {RIED-Revista Iberoamericana de Educacion a Distancia},
	volume = {22},
	number = {1},
	pages = {41 – 80},
	doi = {10.5944/ried.22.1.22294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085100800&doi=10.5944%2fried.22.1.22294&partnerID=40&md5=3c99c89f53ebf5dbf0145c54ff7c6edf},
	affiliations = {The Open University, United Kingdom},
	abstract = {The skill to take part in and to contribute to debates is important for informal and formal learning. Especially when addressing highly complex issues, it can be difficult to support learners participating in effective group discussion, and to stay abreast of all the information collectively generated during the discussion. Technology can help with the engagement and sensemaking of such large debates, for example, it can monitor how healthy a debate is and provide indicators of participation’s distribution. A special framework that aims at harnessing the intelligence of small to very large groups with the support of structured discourse and argumentation tools is Contested Collective Intelligence (CCI). CCI tools provide a rich source of semantic data that, if appropriately processed, can generate powerful analytics of the online discourse. This study presents a visualisation dashboard with several visual analytics that show important aspects of online debates that have been facilitated by CCI discussion tools. The dashboard was designed to improve sensemaking and participation in online debates and has been evaluated with two studies, a lab experiment and a field study in the context of two Higher Education institutes. The paper reports findings of a usability evaluation of the visualisation dashboard. The descriptive findings suggest that participants with little experience in using analytics visualisations were able to perform well on given tasks. This constitutes a promising result for the application of such visualisation technologies as discourse-centric learning analytics interfaces can help to support learners’ engagement and sensemaking of complex online debates. © 2019, Ibero-American Association for Distance Higher Education (AIESAD). All rights reserved.},
	author_keywords = {argumentation; collective intelligence; dashboard; information visualisations; learning analytics; learning analytics; online deliberation; online discussion; sensemaking},
	publisher = {Ibero-American Association for Distance Higher Education (AIESAD)},
	issn = {11382783},
	language = {English},
	abbrev_source_title = {RIED Rev. Iberoam. Educ. Distancia.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Caeiro-Rodriguez2019265,
	author = {Caeiro-Rodriguez, Manuel},
	title = {Making teaching and learning visible: How can learning designs be represented?},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {265 – 274},
	doi = {10.1145/3362789.3362839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075446311&doi=10.1145%2f3362789.3362839&partnerID=40&md5=b530322c9537821ad45cedc803ff2dd1},
	affiliations = {Departmento de Enxẽaría Telemática, Universidade de Vigo, Vigo, Spain},
	abstract = {This work is situated in the context of the Learning Design research area. It reviews different forms in which learning designs can be represented both in textual or in a graphical way. The different forms have been gathered from the options used by teachers in current practice and from proposals of the research community. The following categories have been defined to classify the several representation types into a clear and concise classification: Narrative Text; Forms/Templates; Table Representations/Matrices; Concept Maps, Mind Maps and Tree-based Representations; Flow Diagrams; Sequential Diagrams; and Ad-hoc Diagrams. For each type of representation specific examples and uses are provided, showing the benefits and contexts in which they are used. Text-based representations are common in the real teachers' practice, while graphical representations have been taken from research initiatives. The goal of the paper is to attract attention to the fact that no type of representation for learning designs has been adopted as a mainstream, yet. A common language in this domain would be desirable and could offer great benefits related to the communication and sharing of teaching and learning results. This could be very useful for the representation of learning designs and teaching practices in learning analytics dashboards. © 2019 ACM.},
	author_keywords = {Diagrams; Learning design; Making teaching and learning visible; Representation types},
	keywords = {Ecosystems; Graphic methods; Text processing; Diagrams; Graphical representations; Learning designs; Representation type; Research communities; Research initiatives; Teaching and learning; Teaching practices; Teaching},
	correspondence_address = {M. Caeiro-Rodriguez; Departmento de Enxẽaría Telemática, Universidade de Vigo, Vigo, Spain; email: Manuel.Caeiro@det.uvigo.es},
	editor = {Conde-Gonzalez M.A. and Rodriguez-Sedano F.J. and Fernandez-Llamas C. and Garcia-Penalvo F.J.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037191-9},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Sun2019,
	author = {Sun, Kaiwen and Mhaidli, Abraham H. and Watel, Sonakshi and Brooks, Christopher A. and Schaub, Florian},
	title = {It’s my data! Tensions among stakeholders of a learning analytics dashboard},
	year = {2019},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3290605.3300824},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067604894&doi=10.1145%2f3290605.3300824&partnerID=40&md5=749bada0c083ed2d69d0c568a2bbc48a},
	affiliations = {School of Information, University of Michigan, Ann Arbor, MI, United States},
	abstract = {Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system’s developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system’s benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings’ implications for the ethical design and deployment of learning analytics applications in higher education. © 2019 Copyright held by the owner/author(s).},
	author_keywords = {Early warning dashboards; Ethics; Higher education; Learning analytics; Privacy; Student data},
	keywords = {Data privacy; Human computer interaction; Human engineering; Philosophical aspects; Early warning; Ethics; Higher education; Learning analytics; Multi-stakeholder analysis; Semi structured interviews; Stakeholder groups; University of Michigan; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145035970-2},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 56}
}

@CONFERENCE{Chen2019175,
	author = {Chen, Li and Lu, Min and Goda, Yoshiko and Yamada, Masanori},
	title = {Design of learning analytics dashboard supporting metacognition},
	year = {2019},
	journal = {16th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2019},
	pages = {175 – 182},
	doi = {10.33965/celda2019_201911l022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078980422&doi=10.33965%2fcelda2019_201911l022&partnerID=40&md5=a7875dd13052a803f09e85a35f7f1880},
	affiliations = {Graduate School of Human-Environment Studies, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Faculty of Arts and Science, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan; Research Center for Instructional Systems, Kumamoto University, 2-39-1, Kurokami, Chuo-ku, Kumamoto, 8600862, Japan},
	abstract = {Metacognition is an aspect in self-regulated learning and is necessary to achieve such learning in an effective and efficient manner. However, it is not always easy and accurate for learners to monitor or assess their own metacognition. In this study, we designed a learning analytics dashboard to improve self-regulated learning in online environments through the collection and analysis of learning log data. There are two separate dashboards used in our system: a knowledge monitoring dashboard and a strategy use dashboard. The knowledge monitoring dashboard is designed to support the knowledge monitoring skills of learners, allowing them to monitor their prior knowledge, whereas the strategy use dashboard is designed to help learners develop metacognitive skills of planning, monitoring, and regulation. © 2019 16th International Conference on Cognition and Exploratory Learning in Digital Age, CELDA 2019. All rights reserved.},
	author_keywords = {Dashboard; Learning Analytics; Metacognition; Self-Regulated Learning},
	keywords = {Cognitive systems; Dashboard; Knowledge monitoring; Learning Analytics; Metacognition; Metacognitive skills; Online environments; Prior knowledge; Self-regulated learning; E-learning},
	publisher = {IADIS Press},
	isbn = {978-989853393-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access}
}

@CONFERENCE{De Quincey2019353,
	author = {De Quincey, Ed and Kyriacou, Theocharis and Briggs, Chris and Waller, Richard},
	title = {Student centred design of a learning analytics system},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {353 – 362},
	doi = {10.1145/3303772.3303793},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062779861&doi=10.1145%2f3303772.3303793&partnerID=40&md5=c0670484433499f1cb54969ea00e6b47},
	affiliations = {Keele University, Staffordshire, United Kingdom},
	abstract = {Current Learning Analytics (LA) systems are primarily designed with University staff members as the target audience; very few are aimed at students, with almost none being developed with direct student involvement and undertaking a comprehensive evaluation. This paper describes a HEFCE funded project that has employed a variety of methods to engage students in the design, development and evaluation of a student facing LA dashboard. LA was integrated into the delivery of 4 undergraduate modules with 169 student sign-ups. The design of the dashboard uses a novel approach of trying to understand the reasons why students want to study at university and maps their engagement and predicted outcomes to these motivations, with weekly personalised notifications and feedback. Students are also given the choice of how to visualise the data either via a chart-based view or to be represented as themselves. A mixed-methods evaluation has shown that students' feelings of dependability and trust of the underlying analytics and data is variable. However, students were mostly positive about the usability and interface design of the system and almost all students once signed-up did interact with their LA. The majority of students could see how the LA system could support their learning and said that it would influence their behaviour. In some cases, this has had a direct impact on their levels of engagement. The main contribution of this paper is the transparent documentation of a User Centred Design approach that has produced forms of LA representation, recommendation and interaction design that go beyond those used in current similar systems and have been shown to motivate students and impact their learning behaviour. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Laddering; Learning analytics; Usability; User centred design; User experience; Visualisation},
	keywords = {Learning systems; User centered design; User experience; User interfaces; Visualization; Analytics systems; Comprehensive evaluation; Interaction design; Interface designs; Laddering; Learning analytics; Student involvements; Usability; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036256-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42}
}

@ARTICLE{Smith202038,
	author = {Smith, Paula},
	title = {Engaging online students through peer-comparison progress dashboards},
	year = {2020},
	journal = {Journal of Applied Research in Higher Education},
	volume = {12},
	number = {1},
	pages = {38 – 56},
	doi = {10.1108/JARHE-11-2018-0249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065792903&doi=10.1108%2fJARHE-11-2018-0249&partnerID=40&md5=13952f45a06f5418a353c850bf687c74},
	affiliations = {Department of Clinical Surgery, University of Edinburgh, Edinburgh, United Kingdom},
	abstract = {Purpose: Students studying exclusively online face the challenge of gauging their progress in relation to that of their disparate peers. The purpose of this paper is to describe the creation of a student progress “dashboard” in an online Masters programme, and the perceived effectiveness of the tool for engaging students. Design/methodology/approach: Tableau® visualisation software was used to create a dashboard displaying cohort comparison data comprising metrics relating to the continuous assessment components of the Masters programme. An anonymous questionnaire gauged students’ perceptions of the dashboard. Findings: Feedback from students (n=137) suggests the dashboard improved their motivation, incentivising change in study behaviours, and sense of belonging to an online community of learners. It also acted as a conversation catalyst between staff and students, whereby students more readily engaged in dialogue with their personal tutor. Practical implications: Distance learners are more likely to feel isolated and can become demotivated, which contributes to typically higher levels of withdrawal from online programmes vs those delivered on-campus. Tutors may consider communicating progress data as dashboards to enable online students to monitor their academic progress alongside that of their peers, as a motivational tool in an otherwise disparate group of learners, and to reduce feelings of isolation by reminding distance learners that they are part of a larger online community. Originality/value: This paper shares student and tutor perspectives on the use of dashboards to increase online students’ motivation, and examines whether the benefits of a peer-comparison dashboard are reserved for high-achieving students. © 2019, Emerald Publishing Limited.},
	author_keywords = {Dashboard; Learning analytics visualizations; Online students},
	correspondence_address = {P. Smith; Department of Clinical Surgery, University of Edinburgh, Edinburgh, United Kingdom; email: paula.smith@ed.ac.uk},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {20507003},
	language = {English},
	abbrev_source_title = {J. Appl. Res. High. Edu.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@CONFERENCE{Sebastien2019,
	author = {Sebastien, Veronique and Sebastien, Didier and Timol, Ilias and Gay, Dominique and Cucchi, Alain and Porlier, Christophe},
	title = {Moodleboard: Dynamic and Interactive Indicators for Teachers and Pedagogical Engineers},
	year = {2019},
	journal = {2nd International Conference on Next Generation Computing Applications 2019, NextComp 2019 - Proceedings},
	doi = {10.1109/NEXTCOMP.2019.8883651},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074985482&doi=10.1109%2fNEXTCOMP.2019.8883651&partnerID=40&md5=64af878769bbbd928541d2185e992b00},
	affiliations = {Institut Indianocéanique du Numérique, University of Reunion Island, Saint-Denis, Reunion, France; Direction des Usages du Numérique, University of Reunion Island, Saint-Denis, Reunion, France; Laboratoire d'Informatique et de Mathématiques, University of Reunion Island, Saint-Denis, Reunion, France},
	abstract = {In this article, we present Moodleboard, a dynamic and interactive dashboard which can be used as a decision support tool by pedagogical engineers and Moodle platforms administrators. These users can explore various indicators in an interactive way in order to obtain statistics about online courses with different granularity levels, but also detect remarkable courses and their types, classify courses, detect misuses or innovations implemented by teaching or administrative teams in the organization. This work also aims at proposing models for digital courses in Moodle, in order to facilitate their adaptation to full-online distance learning. © 2019 IEEE.},
	author_keywords = {clustering; dashboard; decision support; learning analytics; pedagogical platform},
	keywords = {Decision support systems; Teaching; clustering; dashboard; Decision supports; learning analytics; pedagogical platform; E-learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172811460-6},
	language = {English},
	abbrev_source_title = {Int. Conf. Next Gener. Comput. Appl,, NextComp - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}@ARTICLE{2019,
	title = {10th International Conference on Computer Supported Education, CSEDU 2018},
	year = {2019},
	journal = {Communications in Computer and Information Science},
	volume = {1022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068317446&partnerID=40&md5=c8eb050f7ebb291e01d24acfe1c76e2c},
	abstract = {The proceedings contain 27 papers. The special focus in this conference is on Computer Supported Education. The topics include: Improving STEM Learning Experience in Primary School by Using NEWTON Project Innovative Technologies; Pathways to Successful Online Testing: eExams with the “Secure Exam Environment” (SEE); A Space-Efficient Technique of Policy Trees for an Intelligent Tutoring System on POMDP; a Learning Analytics Dashboard to Analyse Learning Activities in Interpreter Training Courses; how to Apply Problem-Based Learning in a Managed Way? A Case in Computing Education; practical Software Engineering Capstone Course – Framework for Large, Open-Ended Projects to Graduate Student Teams; a Systematic Mapping Study on Game Elements and Serious Games for Learning Programming; algorithms and Logic as Programming Primers; an Evaluation of the Reliability, Validity and Sensitivity of Three Human Mental Workload Measures Under Different Instructional Conditions in Third-Level Education; Using Spinoza Log Data to Enhance CS1 Pedagogy; an Exercise in Reverse Engineering for Safety-Critical Systems: An Experience for the Classroom; digital Media and Informal Learning: Alteration Mechanism and Captured Episodes; as One Size Doesn’t Fit All, Personalized Massive Open Online Courses Are Required; intermediaries in eHealth Education; detecting and Addressing Design Smells in Novice Processing Programs; investigating Embodied Music Expression Through the Leap Motion: Experimentations in Educational and Clinical Contexts; intuitive Reasoning in Formalized Mathematics with Elfe; automatic Evaluation of Students’ Discussion Skill Based on their Heart Rate; improving Student Learning Experience by the Full Integration of Classroom Response Systems into Lectures; a Layered Approach to Automatic Essay Evaluation Using Word-Embedding.},
	editor = {McLaren B.M. and Zvacek S. and Reilly R. and Uhomoibhi J.},
	publisher = {Springer Verlag},
	issn = {18650929},
	isbn = {978-303021150-9},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Zapata-Rivera20181,
	author = {Zapata-Rivera, Diego},
	title = {Introduction: Why Is Score Reporting Relevant?},
	year = {2018},
	journal = {Score Reporting Research and Applications},
	pages = {1 – 8},
	doi = {10.4324/9781351136501-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143465010&doi=10.4324%2f9781351136501-1&partnerID=40&md5=727b6e1ca4fb33a436c2029885ad9af5},
	affiliations = {Cognitive and Technology Sciences Center, Educational Testing Service, Princeton, NJ, United States},
	abstract = {The chapters in this volume provide a balance of research and practice in the field of score reporting. The first section includes foundational work on validity issues related the use and interpretation of test scores, design principles drawn from areas such as cognitive science, human-computer interaction and information visualization, and research on communicating assessment information to various audiences. The second section provides a select compilation of practical applications in real settings: large-scale assessment programs in K-12, credentialing and admissions tests in higher education, using reports to support formative assessment in K-12, applying learning analytics to provide teachers with class- and individual-level performance, and evaluating students interpretation of dashboard data. These chapters highlight the importance of clearly communicating assessment results to the intended audience to support appropriate decisions based on the original purposes of the assessment. As more technology-rich, highly interactive assessment systems become available, the more important it is to keep in mind that the information provided by these systems should support appropriate decision making by a variety of stakeholders. Many opportunities for research and development involving the participation of interdisciplinary groups of researchers and practitioners lie ahead in this exciting field. © 2019 Taylor & Francis},
	publisher = {Taylor and Francis},
	isbn = {978-135113649-5; 978-081535339-3},
	language = {English},
	abbrev_source_title = {Score Reporting Research and Applications},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Pérez-álvarez20181090,
	author = {Pérez-álvarez, Ronald and Maldonado-Mahauad, Jorge and Pérez-Sanagustín, Mar},
	title = {Design of a tool to support self-regulated learning strategies in MOOCs},
	year = {2018},
	journal = {Journal of Universal Computer Science},
	volume = {24},
	number = {8},
	pages = {1090 – 1109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055246444&partnerID=40&md5=57eaad206db867c9cc807f514be6e26d},
	affiliations = {Pontificia Universidad Católica, Santiago de Chile, Chile; Universidad de Costa Rica, Puntarenas, Costa Rica; Universidad de Cuenca, Cuenca, Ecuador; Université Tolouse III Paul Sabatier, Tolouse, France},
	abstract = {The massive and open nature of MOOCs contribute to attracting a great diversity of learners. However, the learners who enroll in these types of courses have trouble achieving their course objectives. One reason for this is that they do not adequately self-regulate their learning. In this context, there are few tools to support these strategies in online learning environment. Also, the lack of metrics to evaluate the impact of the proposed tools makes it difficult to identify the key features of this type of tools. In this paper, we present the process for designing NoteMyProgress, a web application that complements a MOOC platform and supports self-regulated learning strategies. For designing NoteMyProgress we followed the Design Based Research methodology. For the evaluation of the tool, we conducted two case studies using a beta version of NoteMyProgress over three MOOCs offered in Coursera. The findings of these two case studies are presented as a set of lessons learned that inform about: (1) a list of requirements to inform the design of a second version of the tool; (2) a list of requirements that could serve as a reference for other developers to design new tools that support self-regulated learning in MOOCs. © J.UCS.},
	author_keywords = {Dashboard; Learning analytics; Massive open online courses; Mooc; Self-regulated learning; Srl; Tool},
	publisher = {IICM},
	issn = {0948695X},
	language = {English},
	abbrev_source_title = {J. Univers. Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32}
}

@CONFERENCE{Sun201771,
	author = {Sun, Bo and Lai, Song and Xu, Congcong and Xiao, Rong and Wei, Yungang and Xiao, Yongkang},
	title = {Differences of online learning behaviors and eye-movement between students having different personality traits},
	year = {2017},
	journal = {MIE 2017 - Proceedings of the 1st ACM SIGCHI International Workshop on Multimodal Interaction for Education, Co-located with ICMI 2017},
	volume = {2017-November},
	pages = {71 – 75},
	doi = {10.1145/3139513.3139527},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046550936&doi=10.1145%2f3139513.3139527&partnerID=40&md5=9a6e72b97ae469e9af1ebfa64324c1da},
	affiliations = {Beijing Normal University, Beijing, China},
	abstract = {The information technologies are integrated into education so that mass data is available reflecting each action of students in online environments. Numerous studies have exploited these data to do the learning analytics. In this paper, we aim at achieving the show of personalized indicators for students per personality trait on the learning analytics dashboard (LAD) and present the preliminary results. First, we employ learning behavior engagement (LBE) to describe students' learning behaviors, exploited to analyze the significant differences among students having different personality traits. In experiments, fifteen behavioral indicators are tested. The experimental results show that there are significant differences about some behavioral indicators among personality traits. Second, some of these behavioral indicators are presented on the LAD and distributed in each area of interest (AOI). Hence, students can visualize their behavioral data that they care about in AOIs anytime in the learning process. Through the analysis of eye-movement including the fixation duration, fixation count, heat map and track map, we have found that there are significant differences about some visual indicators in AOIs. This is partly consistent with the results of behavioral indicators. © 2017 Association for Computing Machinery.},
	author_keywords = {Eye-movement; Learning analytics; Learning behavior engagement; Personality traits},
	keywords = {E-learning; Eye movements; Interactive computer systems; Area of interest; Behavioral indicators; Fixation duration; Learning analytics; Learning behavior; Online environments; Personality traits; Visual indicators; Students},
	editor = {Bianchi-Berthouze N. and Baud-Bovy G. and Volta E. and Volpe G. and Gori M. and Alborno P.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035557-5},
	language = {English},
	abbrev_source_title = {MIE - Proc. ACM SIGCHI Int. Workshop Multimodal Interact. Educ., Co-located ICMI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{2019,
	title = {CEUR Workshop Proceedings},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071473110&partnerID=40&md5=60d53aa0a952cdae9caef8fb9f9a5876},
	abstract = {The proceedings contain 9 papers. The topics discussed include: application of learning analytics techniques on blended learning environments for university students; using Simva to evaluate serious games and collect game learning analytics data; extending a dashboard metamodel to account for users' characteristics and goals for enhancing personalization; predicting student performance over time. a case study for a blended-learning engineering course; analyzing students’ persistence using an event-based model; a data value chain to support the processing of multimodal evidence in authentic learning scenarios; and predictors and early warning systems in higher education a systematic literature review.},
	editor = {Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Munoz-Merino P.J. and Universidad Carlos III de Madrid, Department of Telematics Engineering, Av. Universidad 30, Leganes, Madrid and Hernandez-Garcia A. and Universidad Politecnica de Madrid, Departamento de Ingenieria de Organizacion, Administracion de Empresas y Estadistica, Escuela Tecnica Superior de Ingenieros de Telecomunicacion, Av. Complutense 30, Madrid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vázquez-Ingelmo201935,
	author = {Vázquez-Ingelmo, Andrea and García-Peñalvo, Francisco José and Therón, Roberto and Conde, Miguel Ángel},
	title = {Extending a dashboard meta-model to account for users’ characteristics and goals for enhancing personalization},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2415},
	pages = {35 – 42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071468563&partnerID=40&md5=4cfdcf07b3aba338beb40f2df5580272},
	affiliations = {GRIAL Research Group, Computer Sciences Department, Research Institute for Educational Sciences, University of Salamanca, Salamanca, Spain; VisUSAL Research Group, University of Salamanca, Salamanca, Spain; Department of Mechanics, Computer Science and Aerospace Engineering, University of León, León, Spain},
	abstract = {Information dashboards are useful tools for exploiting datasets and support decision-making processes. However, these tools are not trivial to design and build. Information dashboards not only involve a set of visualizations and handlers to manage the presented data, but also a set of users that will potentially benefit from the knowledge generated by interacting with the data. It is important to know and understand the requirements of the final users of a dashboard because they will influence the design processes. But several user profiles can be involved, making these processes even more complicated. This paper identifies and discusses why it is essential to include the final users when modeling a dashboard. Through meta-modeling, different characteristics of potential users are structured, thus obtaining a meta-model that dissects not only technical and functional features of a dashboard (from an abstract point of view) but also the different aspects of the final users that will make use of it. By identifying these user characteristics and by arranging them into a meta-model, software engineering paradigms such as model-driven development or software product lines can employ it as an input for generating concrete dashboard products. This approach could be useful for generating Learning Analytics dashboards that take into account the users' motivations, beliefs, and knowledge. Copyright © 2019 for the individual papers by the papers' authors.},
	author_keywords = {Information dashboards; Information visualization; MDA; Meta-model; User model},
	keywords = {Concrete products; Decision making; Information systems; Visualization; Decision making process; Information dashboards; Information visualization; Meta model; Model driven development; Software engineering paradigm; Technical and functional features; User Modeling; Software architecture},
	editor = {Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Hernandez-Garcia A. and Universidad Politecnica de Madrid, Departamento de Ingenieria de Organizacion, Administracion de Empresas y Estadistica, Escuela Tecnica Superior de Ingenieros de Telecomunicacion, Av. Complutense 30, Madrid and Munoz-Merino P.J. and Universidad Carlos III de Madrid, Department of Telematics Engineering, Av. Universidad 30, Leganes, Madrid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Gibson2017528,
	author = {Gibson, Andrew and Martinez-Maldonado, Roberto},
	title = {That dashboard looks nice, but what does it mean? towards making meaning explicit in learning analytics design},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {528 – 532},
	doi = {10.1145/3152771.3156171},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044236703&doi=10.1145%2f3152771.3156171&partnerID=40&md5=f36bb5c5afda8dd1e478f16b0dd0f546},
	affiliations = {University of Technology Sydney, 2007, NSW, Australia},
	abstract = {As learning analytics (LA) systems become more common, teachers and students are often required to not only make sense of the user interface (UI) elements of a system, but also to make meaning that is pedagogically appropriate to the learning context. However, we suggest that the dominant way of thinking about the relationship between representation and meaning results in an overemphasis on the UI, and that re-thinking this relationship is necessary to create systems that can facilitate deeper meaning making. We propose a conceptual view as a basis for discussion among the LA and HCI communities around a different way of thinking about meaning making, specifically that it should be explicit in the design process, provoking greater consideration of system level elements such as algorithms, data structures and information flow. We illustrate the application of the conceptualisation with two cases of LA design in the areas of Writing Analytics and Multi-modal Dashboards. © 2017 Association for Computing Machinery. All rights reserved.},
	author_keywords = {Embodied cognition; Information systems; Learning analytics; Meaning making; User interface design},
	keywords = {Design; Human computer interaction; Information systems; Interactive computer systems; Teaching; Conceptual views; Design process; Embodied cognition; Information flows; Learning analytics; Learning context; Meaning makings; User interface designs; User interfaces},
	editor = {Brereton M. and Vyas D. and Soro A. and Ploderer B. and Waycott J. and Morrison A.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145035379-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access}
}

@CONFERENCE{Van Der Stappen201815,
	author = {Van Der Stappen, Esther},
	title = {Workplace learning analytics in higher engineering education},
	year = {2018},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2018-April},
	pages = {15 – 20},
	doi = {10.1109/EDUCON.2018.8363102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048142985&doi=10.1109%2fEDUCON.2018.8363102&partnerID=40&md5=d60995ee05ad3a5d61996e07f595bc0d},
	affiliations = {Institute for ICT, HU University of Applied Sciences Utrecht, Utrecht, Netherlands},
	abstract = {Learning in the workplace is crucial in higher engineering education, since it allows students to transfer knowledge and skills from university to professional engineering practice. Learning analytics endeavors in higher education have primarily focused on classroom-based learning. Recently, workplace learning analytics has become an emergent research area, with target users being workers, students and trainers. We propose technology for workplace learning analytics that allows program managers of higher engineering education programs to get insight into the workplace learning of their students, while ensuring privacy of students' personal data by design. Using a design-based agile methodology, we designed and developed a customizable workplace learning dashboard. From the evaluation with program managers in the computing domain, we can conclude that such technology is feasible and promising. The proposed technology was designed to be generalizable to other (engineering) domains. A next logical step would be to evaluate and improve the proposed technology within other engineering domains. © 2018 IEEE.},
	author_keywords = {Data-Driven Curriculum Improvement; Learning Analytics; Workplace Learning},
	keywords = {Data privacy; Managers; Students; Agile Methodologies; Classroom based learning; Curriculum improvement; Engineering domains; Higher engineering educations; Learning analytics; Professional engineerings; Workplace learning; Engineering education},
	correspondence_address = {E. Van Der Stappen; Institute for ICT, HU University of Applied Sciences Utrecht, Utrecht, Netherlands; email: esther.vanderstappen@hu.nl},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-153862957-4},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Oliva-Córdova201969,
	author = {Oliva-Córdova, Luis Magdiel and Amado-Salvatierra, Héctor R. and Monterroso, Leonel and Bojórquez-Roque, Maylin Suleny and Villalba-Condori, Klinge},
	title = {A learning analytics experience using interaction visualization dashboards to support virtual tutoring; [Una experiencia de analíticas de aprendizaje utilizando tableros de visualización de interacciones como soporte a la tutoría virtual]},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2425},
	pages = {69 – 78},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070873734&partnerID=40&md5=061ba4053124f05c8d800004de156a01},
	affiliations = {Universidad de San Carlos de Guatemala, Arequipa, Peru; Universidad Galileo, Arequipa, Peru; Secretaría Nacional de Ciencia y Tecnología -Guatemala, Arequipa, Peru; Universidad de San Carlos de Guatemala, Arequipa, Peru; Universidad Continental, Arequipa, Peru},
	abstract = {We live in the digital age of data, and the technologies we use allow us to store different records that can serve as inputs for decision making in any learning environment. This work was developed in a virtual university context, applying learning analytics based on interaction visualization boards. The study was based on the question: how to support tutoring in a virtual course through the use of visualization boards of student activity? The research method used was formulated under a quasi-experimental cross-sectional design, with a mixed approach, developed through an introductory course on mobile technologies and virtual platforms for learning. The study involved 55 students who had no previous experience of training in virtual environments. The total number of participants was divided into groups and moderated by 5 virtual tutors at the beginner level. The results present an experience of Learning Analytics (LA) using visualization dashboards to support the work of the virtual tutor, highlighting that through graphics, it is easier to identify the most active students within a group, verify access to tasks and URL resources, visualize the number of submissions of an activity, establish percentages of dedication, evaluate performance through qualifications and intervene in a didactic and pedagogical way when necessary. © 2019 CEUR-WS. All rights reserved.},
	keywords = {Computer aided instruction; Curricula; Decision making; Students; Virtual reality; Visualization; Cross-sectional design; Introductory course; Learning environments; Mixed approach; Mobile Technology; research methods; Virtual platform; Virtual university; E-learning},
	editor = {Scheihing E. and Guerra J. and Henriquez V. and Olivares C. and Munoz-Merino P.J.},
	publisher = {CEUR-WS},
	issn = {16130073},
	isbn = {978-841682938-5},
	language = {Spanish},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bernoth2019333,
	author = {Bernoth, Jan and Kiy, Alexander and Lucke, Ulrike},
	title = {Analytics dashboard for teaching, research and transfer; [Analytics-Dashboard für Lehre, Forschung und Transfer]},
	year = {2019},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {P-297},
	pages = {333 – 334},
	doi = {10.18420/delfi2019_354},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072122902&doi=10.18420%2fdelfi2019_354&partnerID=40&md5=1f95f4e5ed7786eabd2166eadb8bdf70},
	affiliations = {Universität Potsdam, Institut für Informatik and Computational Science, August-Bebel-Str. 89, Potsdam, 14482, Germany},
	author_keywords = {Analytics; Dashboard; Data Visualisation; Learning Analytics},
	editor = {Pinkwart N. and Humboldt-Universitat zu Berlin, Unter den Linden 6, Berlin and Konert J. and Beuth Hochschule fur Technik, Luxemburger Strasse, Berlin},
	publisher = {Gesellschaft fur Informatik (GI)},
	issn = {16175468},
	isbn = {978-388579691-6},
	language = {German},
	abbrev_source_title = {Lect. Notes Informatics (LNI), Proc. - Series Ges. Inform. (GI)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yoo2019291,
	author = {Yoo, Mina and Jin, Sung-Hee and Han, Yujie},
	title = {Development and usability testing of online debate dashboard based on learning analytics approach},
	year = {2019},
	journal = {International Journal of Innovative Technology and Exploring Engineering},
	volume = {8},
	number = {3},
	pages = {291 – 295},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064638402&partnerID=40&md5=a8bba4fbfe0a914490f724c6fb48a89c},
	affiliations = {Research and Information Center for Innovative Engineering Education, Inha University, Incheon, South Korea; Division of Humanities and Liberal Arts, Hanbat National University, Daejeon, South Korea; Department of Education, College of Education, Seoul National University, Seoul, South Korea},
	abstract = {Background/Objectives: The purpose of this study is to develop Debate Dashboard to promote learners’ online debate activities and provide suggestions that could be adopted to improve the online debate dashboard. Methods/Statistical analysis: Debate dashboard was developed by computer scientists, and usability test and user experience evaluation were conducted to identify and usability problems and determine the participants’ satisfaction with the dashboard. The usability questionnaires were 9 items and 35 students and 6 instructors were participated. User experience evaluation was performed to determine how users perceived when experiencing the dashboard, the questionnaires were 26 items and 34 students and 6 instructors were participated. Findings: Based on the characteristics of the learning analysis, the debate dashboard was developed by applying the visualization guidelines such as comparability, implicity, and overview-detail. The usability test and user experience evaluation were conducted for students and instructors. The results of the usability test showed that the average score of ease of learning and ease of use was high. As a result of user experience evaluation, perspicuity and efficiency were found to be the highest among students and instructors. These findings show that Debate Dashboard seemed useful to both learners and instructors in identifying debate status. This study sought to support learners debate activities by visualizing debate status on Debate Dashboard by applying comparability, which is a unique characteristic of learning analysis, rather than programming or visualization techniques. The results of this study will help to develop a dashboard to support various learning situations in the future.Improvements/Applications: It is necessary to investigate the effect of Debate Dashboard on learner participation in debate activities and provide intervention by analyzing quality of the debate contents. © BEIESP.},
	author_keywords = {Debate dashboard; Learning analysis; Usability test; User experience; Visual dashboard},
	publisher = {Blue Eyes Intelligence Engineering and Sciences Publication},
	issn = {22783075},
	language = {English},
	abbrev_source_title = {Int. J. Innov. Technol. Explor. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Boscardin2018855,
	author = {Boscardin, Christy and Fergus, Kirkpatrick B. and Hellevig, Bonnie and Hauer, Karen E.},
	title = {Twelve tips to promote successful development of a learner performance dashboard within a medical education program},
	year = {2018},
	journal = {Medical Teacher},
	volume = {40},
	number = {8},
	pages = {855 – 861},
	doi = {10.1080/0142159X.2017.1396306},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033667791&doi=10.1080%2f0142159X.2017.1396306&partnerID=40&md5=9ac0e3ddbf5e5156339070025bf6a717},
	affiliations = {UCSF–Medicine, San Francisco, CA, United States},
	abstract = {Easily accessible and interpretable performance data constitute critical feedback for learners that facilitate informed self-assessment and learning planning. To provide this feedback, there has been a proliferation of educational dashboards in recent years. An educational (learner) dashboard systematically delivers timely and continuous feedback on performance and can provide easily visualized and interpreted performance data. In this paper, we provide practical tips for developing a functional, user-friendly individual learner performance dashboard and literature review of dashboard development, assessment theory, and users’ perspectives. Considering key design principles and maximizing current technological advances in data visualization techniques can increase dashboard utility and enhance the user experience. By bridging current technology with assessment strategies that support learning, educators can continue to improve the field of learning analytics and design of information management tools such as dashboards in support of improved learning outcomes. © 2017, © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
	keywords = {Benchmarking; Competency-Based Education; Education, Medical; Educational Measurement; Formative Feedback; Humans; Information Management; Interprofessional Relations; Learning; Program Development; Self-Assessment; User-Computer Interface; human; human experiment; information system; learning; medical education; outcome assessment; benchmarking; computer interface; constructive feedback; curriculum; education; medical education; procedures; program development; public relations; self evaluation},
	correspondence_address = {C. Boscardin; Department of Medicine, UCSF Office of Medical Education, San Francisco, Box 0710, 533 Parnassus Avenue, Suite U-80, 94143, United States; email: christy.boscardin@ucsf.edu},
	publisher = {Taylor and Francis Ltd},
	issn = {0142159X},
	coden = {MEDTD},
	pmid = {29117744},
	language = {English},
	abbrev_source_title = {Med. Teach.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36}
}

@CONFERENCE{2018,
	title = {CEUR Workshop Proceedings},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2224},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055588413&partnerID=40&md5=dc8a57028e0e2e08c854be15ebbbd25b},
	abstract = {The proceedings contain 12 papers. The topics discussed include: MOOC-maker: three years building MOOC management capacities in Latin America; learning analytics dashboard to work the flipped classroom methodology through the reuse of MOOCs; how to map learning activities through URLs? the case of coursera platform; LOAC: a new model in the post-MOOC era; the effectiveness of the use of simulators for knowledge building in a MOOC context; proposal for the inclusion of gamification elements in object-oriented programming through the use of MOOCs; proposal for a code book to evaluate the moderators of the MOOC videos provided by Latin American universities; experiences from the MOOC: flipped learning for teacher education; and learning with MOOCs in face-to-face classes. Pilot study in a programming course.},
	editor = {Rizzardini R.H. and Universidad Galileo, 4A Calle 7a. Avenida, calle Dr. Eduardo Suger Cofino, Ciudad de Guatemala and Gutl C. and Graz University of Technology, Rechbauerstrasse 12, Graz and Jerez O. and Universidad de Chile, Facultad de Economia y Negocios, Periodista Jose Carrasco Tapia No 75, Santiago and Roman M. and Universidad Panamericana, Diagonal 34, 3143 Zona 16, Ciudad de Guatemala and Ramirez-Gonzalez G. and Luna T. and Catolica del Norte Fundacion Universitaria, Calle 52 No 47 - 42, Edificio Coltejer, Piso 5, Medellin and Universidad Carlos III de Madrid, Departmento de Ingenieria Telematica, Avda de la Universidad 30, Leganes and Alario-Hoyos C. and Teixeira A.M. and Universidade Aberta, Rua da Escola Politecnica, Lisboa and Kloos C.D. and Universidad Carlos III de Madrid, Departmento de Ingenieria Telematica, Avda de la Universidad 30, Leganes and Mira J.F. and Catolica del Norte Fundacion Universitaria, Calle 52 No 47 - 42, Edificio Coltejer, Piso 5, Medellin},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {Spanish},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Volaric2017,
	author = {Volaric, Tomislav and Ljubic, Hrvoje},
	title = {Learner and course dashboards for intelligent learning management systems},
	year = {2017},
	journal = {2017 25th International Conference on Software, Telecommunications and Computer Networks, SoftCOM 2017},
	doi = {10.23919/SOFTCOM.2017.8115555},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041304574&doi=10.23919%2fSOFTCOM.2017.8115555&partnerID=40&md5=620917c9df95838d4f28d322729a74d4},
	affiliations = {University of Mostar, Faculty of Science and Education, University of Mostar, Mostar, Bosnia and Herzegovina},
	abstract = {Visualization of data in learning management systems became essential for easier analysis of learner's behavior and interpretation of results on such system. In this paper, we presented design and development process of dashboard for the prototype of program support-CM Tutor. After analysis of various approaches of designing a learning analytics dashboard, we selected most important items for display on the dashboard, and we created our own. We have designed and built a dashboard for intelligent learning management systems. The dashboard is intended for both students and teachers. The teacher has access to all the functionalities of dashboard, while student approach is limited. © 2017 University of Split, FESB.},
	author_keywords = {Dashboard; Intelligent learning management systems; Learning analytics; Learning Analytics Dashboards; Visualization},
	keywords = {Computer networks; Data visualization; Flow visualization; Information management; Learning systems; Teaching; Visualization; Analysis of various; Dashboard; Design and development process; Intelligent learning management systems; Learning analytics; Learning Analytics Dashboards; Learning management system; Program support; Education},
	editor = {Begusic D. and Saric M. and Radic J. and Rozic N.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-953290078-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Softw., Telecommun. Comput. Networks, SoftCOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Vaclavek2018575,
	author = {Vaclavek, Jonas and Kuzilek, Jakub and Skocilas, Jan and Zdrahal, Zdenek and Fuglik, Viktor},
	title = {Learning Analytics Dashboard Analysing First-Year Engineering Students},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11082 LNCS},
	pages = {575 – 578},
	doi = {10.1007/978-3-319-98572-5_48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053189497&doi=10.1007%2f978-3-319-98572-5_48&partnerID=40&md5=460a5f0f4c87332896f10031f15d4677},
	affiliations = {CTU in Prague, CIIRC, Jugoslavskych Partyzanu 1580/3, Prague 6, 166 00, Czech Republic; CTU in Prague, FME, Technicka 4, Prague 6, 166 07, Czech Republic; Faculty of Education, Charles University, Magdaleny Rettigove 4, Prague 1, 116 39, Czech Republic},
	abstract = {Nowadays, the higher education institutions experience the problem of the student drop-out. In response to this problem, universities started employing analytical dashboards and educational data mining methods such as machine learning, to detect students at risk of failing their studies. In this paper, we present interactive web-based Learning Analytics dashboard - Analyst, which has been successfully deployed at Faculty of Mechanical Engineering (FME), Czech Technical University in Prague. The dashboard provides academic teaching staff with the opportunity to analyse student-related data from various sources in multiple ways to identify those, who might have difficulties to complete their degree. For this purpose, multiple analytical dashboard views have been implemented. It includes summary statistic, study progression graph, and credit completion probabilities graph. In addition, users have the option to export all analysis related graphs for the future use. Based on the outcomes provided by the Analyst, the university successfully ran the interventions on the selected at-risk students and significantly increased the retention rate in the first study year. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Analytical dashboard; Data visualisation; Educational data mining; Student retention},
	keywords = {Computer aided instruction; Data mining; Data visualization; E-learning; Engineering education; Learning systems; Teaching; Analytical dashboard; Completion probability; Educational data mining; Faculty of mechanical engineerings; First-year engineering; Higher education institutions; Student retention; Technical universities; Students},
	correspondence_address = {J. Vaclavek; CTU in Prague, CIIRC, Prague 6, Jugoslavskych Partyzanu 1580/3, 166 00, Czech Republic; email: jonas.vaclavek@cvut.cz},
	editor = {Elferink R. and Drachsler H. and Pammer-Schindler V. and Perez-Sanagustin M. and Scheffel M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331998571-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Herbert2019387,
	author = {Herbert, Katherine and Holder, Ian},
	title = {How learning analytics becomes a bridge for non-expert data miners: Impact on higher education online teaching},
	year = {2019},
	journal = {Communications in Computer and Information Science},
	volume = {996},
	pages = {387 – 395},
	doi = {10.1007/978-981-13-6661-1_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063473922&doi=10.1007%2f978-981-13-6661-1_30&partnerID=40&md5=85cebfbb24a59112b7ef1f3932d4a542},
	affiliations = {Charles Sturt University, Wagga Wagga, 2650, NSW, Australia},
	abstract = {This paper builds on the current studies on data mining’s potential benefits to online learning environments. Many Teaching Academics who are non-experts in data mining techniques however are not able to take advantage of these potential benefits. The objective of this paper is to illustrate how learning analytics is bridging the gap between data mined from Learning Management Systems and teaching practice development in higher education, specifically for Teaching Academics who recently transitioned into online teaching. The authors suggest that bridging this gap is an essential step in the development of online teaching practices and online courses. A customised Dashboard that curates data mined from a university’s LMS is discussed, showcasing the impact on the practices of Teaching Academics. The results from the preliminary exploration suggest that learning analytics can bridge the gap between expert and non-experts of data mining techniques and can become a valuable tool for teaching practice development. © Springer Nature Singapore Pte Ltd. 2019.},
	author_keywords = {Data mining visualisation; Learning analytics; Learning and teaching; Professional learning},
	keywords = {Computer aided instruction; Data mining; Information management; Online systems; Higher education; Learning analytics; Learning and teachings; Learning management system; Online learning environment; Potential benefits; Professional learning; Teaching practices; E-learning},
	correspondence_address = {K. Herbert; Charles Sturt University, Wagga Wagga, 2650, Australia; email: kherbert@csu.edu.au},
	editor = {Zhao Y. and Koh Y.S. and Li C.-T. and Islam Z. and Stirling D. and Warwick G. and Islam R.},
	publisher = {Springer Verlag},
	issn = {18650929},
	isbn = {978-981136660-4},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liaqat2019266,
	author = {Liaqat, Amna and Akcayir, Gokce and Demmans Epp, Carrie and Munteanu, Cosmin},
	title = {Mature ELLs’ Perceptions Towards Automated and Peer Writing Feedback},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11722 LNCS},
	pages = {266 – 279},
	doi = {10.1007/978-3-030-29736-7_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072988968&doi=10.1007%2f978-3-030-29736-7_20&partnerID=40&md5=8c3f80087a38c6e7884ad989e19ca300},
	affiliations = {Department of Computer Science, University of Toronto, Toronto, Canada; EdTeKLA Research Group, Department of Computing Science, University of Alberta, Edmonton, Canada; Institute for Communication, Culture, Information, and Technology, University of Toronto Mississauga, Toronto, Canada},
	abstract = {Mature English Language Learners (ELLs) learning to write in informal environments have little access to instructor feedback and must rely on other sources to support their writing development. While it is known that mature ELLs trust instructor feedback, their perceptions towards feedback from non-expert sources may be mixed. We report on mature ELLs’ perceptions and interpretations of peer and automated feedback when using dashboard visualizations of their writing skills derived from several metrics and sources of feedback. These perceptions and interpretations were collected through a short-term deployment of the dashboard within a writing app with 16 mature ELLs, followed by interviews with the learners. From analyses of these interviews, we suggest three design guidelines (DG) related to learning analytics dashboard design for mature ELLs in informal learning contexts. First, analytics-based feedback should contextualize ELLs’ learning progress by providing temporal information about learner performance. Second, justifications should accompany feedback to avoid criticism arising from ELLs’ prior beliefs. Third, learner autonomy should be fostered by offering explicit mechanisms for reflecting on feedback that is inconsistent with learner beliefs since learners are willing to question automated feedback. We discuss how these three guidelines can be used to benefit learners when an instructor is not present. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Adult learners; Dashboards; Learning analytics; Migrants; Writing},
	keywords = {Automation; Technical writing; Adult learners; Automated feedback; Dashboards; Learner autonomies; Learning analytics; Migrants; Temporal information; Writing feedbacks; Engineering education},
	correspondence_address = {A. Liaqat; Department of Computer Science, University of Toronto, Toronto, Canada; email: a.liaqat@mail.utoronto.ca},
	editor = {Scheffel M. and Broisin J. and Pammer-Schindler V. and Ioannou A. and Schneider J.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303029735-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Tlili2018476,
	author = {Tlili, Ahmed and Essalmi, Fathi and Jemni, Mohamed and Chang, Maiga and Kinshuk},
	title = {iMoodle: An intelligent moodle based on learning analytics},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10858 LNCS},
	pages = {476 – 479},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048346614&partnerID=40&md5=f464c212ff7192bb970b8110aa762799},
	affiliations = {Research Laboratory of Technologies of Information and Communication & Electrical Engineering (LaTICE), Tunis Higher School of Engineering (ENSIT), University of Tunis, Tunis, Tunisia; School of Computing and Information Systems, Athabasca University, Athabasca, Canada; University of North Texas, 3940 N. Elm Street, G 150, Denton, 76207, TX, United States},
	abstract = {Online learning is gaining an increasing attention by researchers and educators, since it makes students learn without being limited in time or space like traditional classrooms. However, this type of learning faces several challenges include the difficulties for teachers to control the learning process and keep track of their students’ learning progress. Therefore, this paper presents an ongoing project which is an intelligent Moodle (iMoodle) that uses learning analytics to provide dashboard for teachers to control the learning process and make decisions. It also aims to increase the students’ success rate with an early warning system for identifying at-risk students as well as providing real time interventions of supportive learning content as notifications. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {At-risk students; Learning analytics; Moodle; Online learning intelligent tutoring systems},
	keywords = {Computer aided instruction; Intelligent vehicle highway systems; Learning systems; Online systems; Process control; Students; Teaching; Early Warning System; Intelligent tutoring system; Learning analytics; Learning contents; Learning process; Learning progress; Moodle; Online learning; E-learning},
	correspondence_address = {A. Tlili; Research Laboratory of Technologies of Information and Communication & Electrical Engineering (LaTICE), Tunis Higher School of Engineering (ENSIT), University of Tunis, Tunis, Tunisia; email: ahmed.tlili23@yahoo.com},
	editor = {Vassileva J. and Nkambou R. and Azevedo R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331991463-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Bodily2017405,
	author = {Bodily, Robert and Verbert, Katrien},
	title = {Review of research on student-facing learning analytics dashboards and educational recommender systems},
	year = {2017},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {10},
	number = {4},
	pages = {405 – 418},
	doi = {10.1109/TLT.2017.2740172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028474352&doi=10.1109%2fTLT.2017.2740172&partnerID=40&md5=a392b98af03b6fdd2ce1ece3fcc47929},
	affiliations = {Instructional Psychology and Technology Department, Brigham Young University, 150 MCKB, Provo, 84604, UT, United States; Human and Computer Interaction Group, Department of Computer Science, KU Leuven, Celestijnenlaan 200A, Heverlee, B-3001, Belgium},
	abstract = {This article is a comprehensive literature review of student-facing learning analytics reporting systems that track learning analytics data and report it directly to students. This literature review builds on four previously conducted literature reviews in similar domains. Out of the 945 articles retrieved from databases and journals, 93 articles were included in the analysis. Articles were coded based on the following five categories: functionality, data sources, design analysis, student perceptions, and measured effects. Based on this review, we need research on learning analytics reporting systems that targets the design and development process of reporting systems, not only the final products. This design and development process includes needs analyses, visual design analyses, information selection justifications, and student perception surveys. In addition, experiments to determine the effect of these systems on student behavior, achievement, and skills are needed to add to the small existing body of evidence. Furthermore, experimental studies should include usability tests and methodologies to examine student use of these systems, as these factors may affect experimental findings. Finally, observational study methods, such as propensity score matching, should be used to increase student access to these systems but still rigorously measure experimental effects. © 2016 IEEE.},
	author_keywords = {Adaptive and intelligent educational systems; Data and knowledge visualization; Data mining; Homework support systems; Literature review; Self-assessment technologies},
	keywords = {Bibliographies; Computer science; Data mining; Data visualization; Database systems; Education; Facings; Flow visualization; Product design; Recommender systems; Visualization; Conferences; Data and knowledge visualizations; Intelligent educational systems; Literature reviews; Self assessment; Support systems; Students},
	correspondence_address = {R. Bodily; Instructional Psychology and Technology Department, Brigham Young University, 150 MCKB, Provo, 84604, United States; email: bodilyrobert@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 246; All Open Access, Green Open Access}
}

@ARTICLE{Tsivitanidou2019600,
	author = {Tsivitanidou, Olia and Ioannou, Andri},
	title = {What Do Educational Data, Generated by an Online Platform, Tell Us About Reciprocal Web-Based Peer Assessment?},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11722 LNCS},
	pages = {600 – 603},
	doi = {10.1007/978-3-030-29736-7_48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072973908&doi=10.1007%2f978-3-030-29736-7_48&partnerID=40&md5=f1fb703d0ffee954705b17e19dfbe180},
	affiliations = {Research Center on Interactive Media, Smart Systems and Emerging Technologies (RISE), Nicosia, Cyprus; Cyprus Interaction Lab, Cyprus University of Technology, Limassol, Cyprus},
	abstract = {Peer Assessment (PA) is a promising evaluation strategy in the educational context, not only due to its effectiveness to reduce instructor’s evaluation loading, but mainly due to its benefit towards student development e.g., teamwork, in-depth thinking. In this exploratory study we sought to explore how do educational data, as generated by an online platform (i.e., Peergrade) and displayed in teacher’s and students’ Learning Analytics Dashboard (LAD), can potentially inform us of the PA process and the peer interactions, as they take place. Participants in the study were 21 undergraduate teacher-students who attended a science course (electrical circuits topic) following the inquiry-based approach. Students were asked to reciprocally and individually assess the responses of a peer in a given task. The findings of this study have implications towards the establishment of new theoretical frameworks and developments for bridging educational theory, design process and data science, in the field of assessment. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Online assessment; Peer feedback; Science education; Science learning; Web-based peer assessment},
	keywords = {E-learning; Engineering education; Websites; On-line assessment; Peer assessment; Peer feedback; Science education; Science learning; Students},
	correspondence_address = {O. Tsivitanidou; Research Center on Interactive Media, Smart Systems and Emerging Technologies (RISE), Nicosia, Cyprus; email: o.tsivitanidou@rise.org.cy},
	editor = {Scheffel M. and Broisin J. and Pammer-Schindler V. and Ioannou A. and Schneider J.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303029735-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Schumacher2018,
	author = {Schumacher, Clara and Ifenthaler, Dirk},
	title = {Students' perceptions of privacy in learning analytics; [Einstellung Studierender zu Datenschutz in Learning Analytics]},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2092},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048084250&partnerID=40&md5=9c6a7a3ad0ba1ecdca4aa029977762dc},
	affiliations = {Universität Mannheim, Wirtschaftspädagogik, Technologiebasiertes, Instruktionsdesign, L4, 1, Mannheim, 68161, Germany; Deakin University, Burwood Campus, Melbourne, 3000, VIC, Australia},
	abstract = {The purpose of this study is to investigate students' privacy perceptions in relation to learning analytics. Privacy in learning analytics refers to collecting and storing personal data including the analyses on the data and presenting results to the different stakeholders. In total 330 university students participated in an exploratory study confronting them with different learning analytics systems. In addition, their perceived control over data and their willingness to reveal personal data were investigated. Results indicated that students prefer learning analytics systems providing detailed, adaptive and personalized dashboards. Furthermore, students are rather restrained in sharing personal data with learning analytics systems. Due to the relation of acceptance and anticipated benefits of learning analytics with privacy principles interests of all relevant stakeholders should already be considered when implementing learning analytics. Upcoming research should further investigate the conditions under which students are willing to reveal relevant data for learning analytics systems. © 2018 CEUR-WS. All rights reserved.},
	author_keywords = {Datenkontrolle; Datenschutz; Hochschulbildung; Learning Analytics; Transparenz},
	keywords = {E-learning; Students; Datenkontrolle; Datenschutz; Hochschulbildung; Learning analytics; Transparenz; Data privacy},
	editor = {Ullrich C. and Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI GmbH), Educational Technology Lab (EdTec), Alt-Moabit 91c, Berlin and Wessner M. and Hochschule Darmstadt, Department of Media, Max-Planck-Strasse 2, Dieburg},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {German},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tan2018706,
	author = {Tan, Jennifer Pei-Ling and Koh, Elizabeth and Mohamed Ariffin, Noriff Elyn and Teo, Ee Zi and Tay, Siu Hua and Singh, Shyam},
	title = {A collaborative video annotation and analytics environment (CoVAA) intervention: User experiences and reflections of teacher-practitioners},
	year = {2018},
	journal = {ICCE 2018 - 26th International Conference on Computers in Education, Main Conference Proceedings},
	pages = {706 – 714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060056346&partnerID=40&md5=85a652a4710eeb46289465dba2ead998},
	affiliations = {National Institute of Education, Nanyang Technological University, Singapore, Singapore; Ministry of Education, Singapore, Singapore},
	abstract = {This paper foregrounds teacher practitioners' implementation experiences and reflections of a web-based Collaborative Video Annotation and Learning Analytics (CoVAA) intervention aimed at enhancing video-based teaching and learning in schools, with a view to foster secondary students' conceptual understanding, social knowledge construction, and self-regulated learning dispositions. We first briefly outline the key learning principles that underpin the design of CoVAA, namely social dialogic learning, assessment for learning, and computer-supported collaborative learning. Next, we explain its two key learning affordances: (i) timepoint-based collaborative video annotation supplemented by a live interactive chatboard, and (ii) rapid digital formative feedback in the form of teacher and learner dashboards. We then illustrate how teachers implement these in their classrooms. Teachers' sense-making of the learning and teaching gains, challenges and pathways forward for leveraging on these contemporary digital social learning affordances to enhance video-based classroom practices are presented and discussed. © 2018 Asia-Pacific Society for Computers in Education. All rights reserved.},
	author_keywords = {Assessment for learning; Computer-supported collaborative learning; Dialogic learning; Learner dashboards; Learning analytics; Teacher dashboards; Video-based learning},
	keywords = {Computer graphics; Learning systems; Assessment for learning; Computer Supported Collaborative Learning; Dialogic learning; Learner dashboards; Learning analytics; Teacher dashboards; Video-based learning; E-learning},
	editor = {Rodrigo M.M.T. and Yang J.-C. and Wong L.-H. and Chang M.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986940128-9},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Youngs2018206,
	author = {Youngs, Bonnie L. and Prakash, Akhil and Nugent, Rebecca},
	title = {Statistically-driven visualizations of student interactions with a French online course video},
	year = {2018},
	journal = {Computer Assisted Language Learning},
	volume = {31},
	number = {3},
	pages = {206 – 225},
	doi = {10.1080/09588221.2017.1367311},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029701947&doi=10.1080%2f09588221.2017.1367311&partnerID=40&md5=519d10219f1e16e318dae047a882bf46},
	affiliations = {Department of Modern Languages, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Statistics, Stanford University, Stanford, CA, United States; Department of Statistics, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Logged tracking data for online courses are generally not available to instructors, students, and course designers and developers, and even if these data were available, most content-oriented instructors do not have the skill set to analyze them. Learning analytics, mined from logged course data and usually presented in the form of learning dashboards, can inform instructors and students about how students are doing in a course, for example, questions answered correctly or incorrectly, pages visited, exercises completed, and assessment scores. However, these dashboards do not provide data on what students are doing when interacting with course materials. This dearth of information severely limits the amount of feedback that online course instructors can give to students on how to best maximize their time online to meet their learning outcomes. Using logged data from an online French course, the research presented here offers a sample of preliminary statistical visualizations created using data from students interacting with a course video and its attendant questions. By developing a methodology that can be applied to other similar datasets, these types of visualizations could be automatically generated for all stakeholders to obtain a fuller picture of how students behave in online courses. © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {course; French; learning analytics; Online; statistics; video; visualizations},
	correspondence_address = {B.L. Youngs; Department of Modern Languages, Carnegie Mellon University, Pittsburgh, United States; email: byoungs@cmu.edu},
	publisher = {Routledge},
	issn = {09588221},
	coden = {CALLE},
	language = {English},
	abbrev_source_title = {Comput. Assisted Lang. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Fu2017280,
	author = {Fu, Xinyu and Shimada, Atsushi and Ogata, Hiroaki and Taniguchi, Yuta and Suehiro, Daiki},
	title = {Real-time learning analytics for C programming language courses},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {280 – 288},
	doi = {10.1145/3027385.3027407},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016511580&doi=10.1145%2f3027385.3027407&partnerID=40&md5=d88eadbe327ae9ece98b0ee84118817d},
	affiliations = {Graduate School of Information Science and Electrical Engineering, Kyushu University, Japan; Faculty of Arts and Science, Kyushu University, Japan},
	abstract = {Many universities choose the C programming language (C) as the first one they teach their students, early on in their program. However, students often consider programming courses difficult, and these courses often have among the highest dropout rates of computer science courses offered. It is therefore critical to provide more effective instruction to help students understand the syntax of C and prevent them losing interest in programming. In addition, homework and paper-based exams are still the main assessment methods in the majority of classrooms. It is difficult for teachers to grasp students' learning situation due to the large amount of evaluation work. To facilitate teaching and learning of C, in this article we propose a system-LAPLE (Learning Analytics in Programming Language Education)-that provides a learning dashboard to capture the behavior of students in the classroom and identify the different difficulties faced by different students looking at different knowledge. With LAPLE, teachers may better grasp students' learning situation in real time and better improve educational materials using analysis results. For their part, novice undergraduate programmers may use LAPLE to locate syntax errors in C and get recommendations from educational materials on how to fix them. © 2017 ACM.},
	author_keywords = {C programming; Information visualization; Learning Analytics; Learning dashboard; Programming education},
	keywords = {Ada (programming language); Computer programming; Computer programming languages; Education; Information systems; Students; Syntactics; Teaching; C programming; Information visualization; Learning Analytics; Learning dashboard; Programming education; C (programming language)},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 53}
}

@CONFERENCE{Dazo20172504,
	author = {Dazo, Suzanne L. and Stepanek, Nicholas R. and Chauhan, Aarjav and Dorn, Brian},
	title = {Examining instructor use of learning analytics},
	year = {2017},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	volume = {Part F127655},
	pages = {2504 – 2510},
	doi = {10.1145/3027063.3053256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019635944&doi=10.1145%2f3027063.3053256&partnerID=40&md5=df6b724600fd2b08d61d14c43ba1a469},
	affiliations = {University of Nebraska Omaha, Omaha, 68182, NE, United States},
	abstract = {This study takes an instructor-centric approach to Learning Analytic (LA) research by analyzing instructor use of the LA within an educational streaming video platform called TrACE. The goal of this study is to understand how instructors naturally interact with analytic dashboards through an empirical analysis. To accomplish this, data of 14 instructors from three institutions that used TrACE from Spring 2015 to Spring 2016 was collected. Data was analyzed to identify frequency of analytic visits, duration of analytic use, differences in analytic use, and differences in use between semesters. Instructors demonstrated preferences for some analytics over others, but the majority of teachers generate short sessions that may not allow for in-depth exploration in analytics. Finally, instructor activity is not always consistent between semesters. Focus groups were conducted to explore motivations behind these findings and future work includes developing LA that address discovered issues. Copyright © 2017 by the Association for Computing Machinery, Inc. (ACM).},
	author_keywords = {Analytics usage trends; Instructor support},
	keywords = {Human engineering; Teaching; Analytics usage trends; Empirical analysis; Focus groups; Streaming videos; Education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034656-6},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access}
}

@ARTICLE{Putra2018171,
	author = {Putra, Faisal A.T. and Santoso, Harry B. and Aji, Rizal F.},
	title = {Evaluation of learning analytics metrics and dashboard in a software engineering project course},
	year = {2018},
	journal = {Global Journal of Engineering Education},
	volume = {20},
	number = {3},
	pages = {171 – 180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056753527&partnerID=40&md5=b1cb167d42df5f9d624bfccf8a1ff5b2},
	affiliations = {Universitas Indonesia Depok, Jawa Barat, Indonesia},
	abstract = {Learning analytics is a technique to monitor a learning activity using metrics. The aim of this research was to find the impact of data filtering on metric quality, the learning analytics dashboard usability in a software development course project, and to compare a correlation-based dashboard with a randomly arranged dashboard. A quantitative method was applied, with the metric correlation set to lecturer scores; the system usability scale (SUS) was a tool for evaluating dashboards; and the Fisher-Irwin test and t-test were applied to compare dashboards. A qualitative method was applied to evaluate dashboard usability, with usability testing through lost our lease. A simple data filtering technique can improve metric quality except for code review metrics. As for usability, the learning analytics dashboard has a relatively good and acceptable SUS score of 70.75. Findings from the research reveal a significant difference between correlation-based and randomly arranged dashboards, whereas two other indicators suggest no significant differences are present. © WIETE 2018.},
	author_keywords = {Dashboard; Learning analytics; Metric},
	publisher = {World Institute for Engineering and Technology Education},
	issn = {13283154},
	language = {English},
	abbrev_source_title = {Glob. J. Eng. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Biedermann2018,
	author = {Biedermann, Daniel and Schneider, Jan and Drachsler, Hendrik},
	title = {Implementation and evaluation of a trusted learning analytics dashboard},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060085567&partnerID=40&md5=c385c3622735b90a9abaa62b5706edd6},
	affiliations = {German Institute for International Educational Research, Germany; Open Universiteit, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; Goethe University Frankfurt, Frankfurt am Main, Germany},
	abstract = {The research described in this article covers the user-facing components of a learning analytics environment which is developed with the premise of trust as an essential factor for the adoption of learning analytics. It investigates the influence of privacy settings and personalization on the acceptance and adoption of learning analytics. By ensuring compliance with data protection legislation, and by providing transparency in the means and results of data collection, we aim to reduce doubts and fears in the learning analytics process. By respecting the needs of individuals, we hope to create an environment where learning analytics is perceived as something positive. © 2018 CEUR-WS. All Rights Reserved.},
	keywords = {Data collection; Learning analytics; Personalizations; Privacy Settings},
	editor = {Dirckinck-Holmfeld L. and Glahn C.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Calvo-Morata2018112,
	author = {Calvo-Morata, Antonio and Alonso-Fernández, Cristina and Freire, Manuel and Martínez-Ortiz, Iván and Fernández-Manjón, Baltasar},
	title = {Making Understandable Game Learning Analytics for Teachers},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11007 LNCS},
	pages = {112 – 121},
	doi = {10.1007/978-3-319-96565-9_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052679173&doi=10.1007%2f978-3-319-96565-9_11&partnerID=40&md5=84752de4dea52cb91640353a0fec2716},
	affiliations = {Facultad de Informática, Complutense University of Madrid, C/Profesor José García Santesmases 9, Madrid, 28040, Spain},
	abstract = {When used for education, games can increase students’ motivation and engagement and provide a more authentic learning environment where they can apply knowledge, making them especially suited to schools. However, actual application of such (serious) games in schools is still limited. Teachers still consider that using games is a complex process that they do not fully master and that requires extra effort from them. We consider that simplifying teachers’ tasks when deploying games is crucial to promote their use. In classroom scenarios, teachers can greatly benefit from knowing what is happening as a serious game is being played. Game learning analytics (GLA) is the process of collecting, analyzing and displaying student interaction data with the games to improve the educational experience. GLA can be used both at real-time, providing teachers with information while their students are still playing, and offline, inspecting already-finished game sessions. In both cases, analytics is only useful when it manages to bridge the gap between large collections of interaction data and pedagogically sound insight. Analytics dashboards should therefore provide not only complete but meaningful and easy-to-understand information, considering that teachers will most probably not know all the details of the analyses performed underneath. In this paper, we review our experiences on game learning analytics dashboards for teachers, and describe some of the steps we have taken to improve our dashboards. © 2018, Springer International Publishing AG, part of Springer Nature.},
	author_keywords = {Dashboards; Game-based learning; Learning analytics; Serious games; xAPI},
	keywords = {Computer aided instruction; E-learning; Serious games; Students; Websites; Authentic learning environment; Dashboards; Educational experiences; Game-based Learning; Learning analytics; Motivation and engagements; Student interactions; xAPI; Teaching},
	correspondence_address = {C. Alonso-Fernández; Facultad de Informática, Complutense University of Madrid, Madrid, C/Profesor José García Santesmases 9, 28040, Spain; email: crisal03@ucm.es},
	editor = {Klamma R. and Spaniol M. and Hancke G. and Osathanunkul K. and Unankard S.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331996564-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{McDonald2017306,
	author = {McDonald, J. and Bird, R.J. and Zouaq, A. and Moskal, A.C.M.},
	title = {Short answers to deep questions: supporting teachers in large-class settings},
	year = {2017},
	journal = {Journal of Computer Assisted Learning},
	volume = {33},
	number = {4},
	pages = {306 – 319},
	doi = {10.1111/jcal.12178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013500968&doi=10.1111%2fjcal.12178&partnerID=40&md5=2849af9b3ecbba3714bcf54a97bc948e},
	affiliations = {Centre for Learning and Research in Higher Education, University of Auckland, New Zealand; Department of Anatomy, University of Otago, New Zealand; School of Electrical Engineering and Computer Science, University of Ottawa, Canada; College of Enterprise and Development, Otago Polytechnic, New Zealand},
	abstract = {In large class settings, individualized student–teacher interaction is difficult. However, teaching interactions (e.g., formative feedback) are central to encouraging deep approaches to learning. While there has been progress in automatic short-answer grading, analysing student responses to support formative feedback at scale is arguably some way from being widely applied in practice. However, analysing student written responses can provide insights into student conceptions, thus directly informing teacher actions. Indeed, we argue that analysing student responses to provide feedback directly to teachers is as worthy a goal as providing individualized feedback to students and is achievable given the current state-of-the-art in natural language processing. In this paper, we analyse student written responses to short-answer questions posed in the context of a large first year health sciences course. Each question was designed to elicit deep responses. Our qualitative analysis illustrates the variability in student responses and reveals multiple relationships between these responses, course materials and the questions posed. Such information can be invaluable for teacher praxis. We conclude with a conceptual ‘dashboard’ that categorizes student responses and reveals relationships between responses, course resources and the questions. Such a dashboard could provide timely, actionable insights for teachers and help foster deep learning approaches for students. © 2017 John Wiley & Sons Ltd},
	author_keywords = {formative feedback; higher education; learning analytics},
	correspondence_address = {J. McDonald; Centre for Learning and Research in Higher Education, University of Auckland, New Zealand; email: j.mcdonald@auckland.ac.nz},
	publisher = {Blackwell Publishing Ltd},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Amo2018990,
	author = {Amo, Daniel and Alier, Marc and Casan, Maria José},
	title = {The student’s progress snapshot a hybrid text and visual learning analytics dashboard},
	year = {2018},
	journal = {International Journal of Engineering Education},
	volume = {34},
	number = {3},
	pages = {990 – 1000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047522817&partnerID=40&md5=72034aaa2c8af666fb509cc6ed650672},
	affiliations = {La Salle, Universitat Ramon Llull, Barcelona, Catalonia, 08022, Spain; Universitat Politècnica de Catalunya, UPC Campus Nord, Ed. Omega, Jordi Girona 1-3, Barcelona, 08034, Spain},
	abstract = {In recent years, virtual learning environments, laptops, tablets and mobile devices have been introduced in the classroom. These technologies start a snowball effect: the old tools teachers used to fathom the students’ learning progress, since so much happens online, are not enough. Thus, the need for new tools to analyse the students’ activity on the online learning environments arises. The field of learning analytics can provide some of these tools. In this paper, we introduce the Student’s Progress Snapshot (SPS), a Learning Analytics Dashboard that allows teachers to analyse the activity of their students on Moodle courses. The SPS running as software as a service, includes both charts and automatically generated explanatory texts of these charts. During the academic course 2015–2016 a pilot was conducted to validate the SPS. © 2018 TEMPUS Publications.},
	author_keywords = {Learning analytics; Learning management systems; Moodle; Student interactions; Virtual learning environments},
	keywords = {Computer aided instruction; Software as a service (SaaS); Students; Teaching; Active learning; Adversarial machine learning; Collaborative learning; Federated learning; Transfer learning; Virtual environments; Visual analytics; Learning analytics; Learning management system; Moodle; Student interactions; Virtual learning environments; Learning analytic; Learning progress; Online learning environment; Student learning; Teachers'; Visual learning; E-learning; Contrastive Learning},
	publisher = {Tempus Publications},
	issn = {0949149X},
	language = {English},
	abbrev_source_title = {Int. J. Eng. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Jivet201831,
	author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
	title = {License to evaluate: Preparing learning analytics dashboards for educational practice},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {31 – 40},
	doi = {10.1145/3170358.3170421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045910955&doi=10.1145%2f3170358.3170421&partnerID=40&md5=f74d0c71750252e72c17a38c5dc42ad8},
	affiliations = {Open University of the Netherlands, Heerlen, Netherlands; Goethe University Frankfurt/DIPF Germany, Open University of the Netherlands, Heerlen, Netherlands},
	abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners. © 2018 Copyright held by the owner/author(s).},
	author_keywords = {Competition; Evaluation; Learning analytics; Learning dashboards; Learning science; Learning theory; Social comparison; Systematic review},
	keywords = {Competition; Computer aided instruction; Teaching; Evaluation; Learning analytics; Learning dashboards; Learning science; Learning Theory; Social comparison; Systematic Review; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 233; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Suarez2017,
	author = {Suarez, Angel and Ternier, Stefaan and Helbig, René and Specht, Marcus},
	title = {DojoAnalytics: A Learning Analytics interoperable component for DojoIBL},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3136907.3136939},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041435734&doi=10.1145%2f3136907.3136939&partnerID=40&md5=0064f932803da822b3f676c5203efa9d},
	affiliations = {Welten Institute, Open Universiteit, Netherlands; Informatik, Kommunikation und Wirtschaft, HTW Berlin, Germany},
	abstract = {DojoIBL1 is a cloud based platform that provides flexible support for collaborative inquiry-based learning processes. It expands the learning process beyond the classroom walls and brings it to an online setting. Such transition requires teachers and learners to have more means to track and to follow up their progress. Learning Analytics dashboards provide such functionality in form of meaningful visualizations. In this paper we present the DojoAnalytics, a new module of DojoIBL that enables connections with third party Learning Analytics dashboards. In order to demonstrate interoperability with the external dashboards, two use case implementations will be described. © 2017 Association for Computing Machinery.},
	author_keywords = {Inquiry-based learning; Interoperability; Learners' performance; Learning analytics},
	keywords = {Interoperability; Learning systems; Teaching; Cloud based platforms; Flexible supports; Inquiry-based learning; Learners' performance; Learning analytics; Learning process; On-line setting; Third parties; Education},
	editor = {Souleles N. and Papadopoulos G. and Loizides F.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145035255-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Azcona2018,
	author = {Azcona, David and Hsiao, I-Han and Smeaton, Alan F.},
	title = {Personalizing computer science education by leveraging multimodal learning analytics},
	year = {2018},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	volume = {2018-October},
	doi = {10.1109/FIE.2018.8658596},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063442297&doi=10.1109%2fFIE.2018.8658596&partnerID=40&md5=9aff9aae2ef692d444b3f1ea6b2b2810},
	affiliations = {Insight Centre for Data Analytics, Dublin City University, Dublin, Ireland; School of Computing, Informatics Decision Systems Engineering, Arizona State University, Tempe, AZ, United States},
	abstract = {This Research Full Paper implements a framework that harness sources of programming learning analytics on three computer programming courses a Higher Education Institution. The platform, called PredictCS, automatically detects lower-performing or 'at-risk' students in programming courses and automatically and adaptively sends them feedback. This system has been progressively adopted at the classroom level to improve personalized learning. A visual analytics dashboard is developed and accessible to Faculty. This contains information about the models deployed and insights extracted from student's data. By leveraging historical student data we built predictive models using student characteristics, prior academic history, logged interactions between students and online resources, and students' progress in programming laboratory work. Predictions were generated every week during the semester's classes. In addition, during the second half of the semester, students who opted-in received pseudo real-time personalised feedback. Notifications were personalised based on students' predicted performance on the course and included a programming suggestion from a top-student in the class if any programs submitted had failed to meet the specified criteria. As a result, this helped students who corrected their programs to learn more and reduced the gap between lower and higher-performing students. © 2018 IEEE.},
	author_keywords = {Computer Science Education; Educational Data Mining; Learning Analytics; Machine Learning; Peer Learning; Predictive Modelling},
	keywords = {Computer programming; Data mining; Education computing; Learning systems; Machine learning; Predictive analytics; Computer programming course; Computer Science Education; Educational data mining; Higher education institutions; Learning analytic; Machine-learning; Multi-modal learning; Peer learning; Predictive models; Programming learning; Students},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {978-153861173-9},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Green Open Access}
}

@CONFERENCE{Bae2019947,
	author = {Bae, Haesol and Glazewski, Krista and Hmelo-Silver, Cindy E. and Lester, James and Mott, Bradford W. and Rowe, Jonathan},
	title = {Intelligent cognitive assistants to support orchestration in cscl},
	year = {2019},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {2},
	pages = {947 – 948},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073320738&partnerID=40&md5=787de99342f7268cb65c0eda32daf301},
	affiliations = {Indiana University, United States; North Carolina State University, United States},
	abstract = {This design paper proposes an intelligent cognitive assistant framework that utilizes AI-based multimodal learning analytics for developing a teacher dashboard. Using six data streams, we suggest this design can extend teacher’s instructional capacity in technology-rich collaborative inquiry-focused science classrooms. We discuss how this tool can support teacher’s orchestration in relation to relevant learning practices in complex problem-solving activities in a CSCL environment. © ISLS.},
	keywords = {Computer science; Computers; Complex problem solving; Data stream; Multi-modal learning; Science classroom; E-learning},
	editor = {Lund K. and Niccolai G.P. and Lavoue E. and Hmelo-Silver C. and Gweon G. and Baker M.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-173246724-8},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Gruzd2018,
	author = {Gruzd, Anatoliy and Conroy, Nadia},
	title = {Designing a learning analytics dashboard for twitter-facilitated teaching},
	year = {2018},
	journal = {Proceedings of the 5th Annual ACM Conference on Learning at Scale, L at S 2018},
	doi = {10.1145/3231644.3231704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051519898&doi=10.1145%2f3231644.3231704&partnerID=40&md5=0d1348851638cea0deae6d22a0c235a6},
	affiliations = {Ryerson University, Toronto, Canada},
	abstract = {Social media sites are increasingly being adopted to support teaching practice in higher education. Learning Analytics (LA) dashboards can be used to reveal how students engage with course material and others in the class. However, research on the best practices of designing, developing, and evaluating such dashboards to support teaching and learning with social media has been limited. Considering the increasing use of Twitter for both formal and informal learning processes, this paper presents our design process and a LA prototype dashboard developed based on a comprehensive literature review and an online survey among 54 higher education instructors who have used Twitter in their teaching. © 2017 Association for Computing Machinery. All rights reserved.},
	author_keywords = {Dashboards; Learning Analytics; Survey; Teaching},
	keywords = {Design; Social networking (online); Surveying; Surveys; Course material; Dashboards; Higher education; Informal learning; Learning analytics; Literature reviews; Teaching and learning; Teaching practices; Teaching},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035886-6},
	language = {English},
	abbrev_source_title = {Proc. Annu. ACM Conf. Learn. Scale, L at S},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{2018124,
	title = {CEUR Workshop Proceedings},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2188},
	pages = {124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053069347&partnerID=40&md5=8dad574a5836c5399628ecc60c15c0b5},
	abstract = {The proceedings contain 12 papers. The topics discussed include: supporting competence-based learning in blended learning environments; learning analytics to improve the effectiveness of continuous assessment; learning analytics and recommender systems toward remote experimentation; validating performance of group formation based on homogeneous engagement criteria in MOOCs; SPEET: visual data analysis of engineering students performance from academic data; design of an extraction, transform and load process for calculation of teamwork indicators in Moodle; learning analytics to assess students' behavior with scratch through clickstream; towards a methodology and a toolkit to analyse data for novices in computer programming; visualization index for educational resources by learning analytics; model for evaluating student performance through their interaction with version control systems; and generation of customized dashboards through software product line paradigms to analyse university employment and employability data.},
	editor = {Fernandez-Llamas C. and University of Leon, Department of Mechanical, Computer Science and Aerospace Engineering, Campus de Vegazana S/N, Leon and Garcia-Penalvo F.J. and University of Salamanca, Computer Science Department, Science Education Research Institute (IUCE), GRIAL Research Group, Paseo de Canalejas, Salamanca and Conde M.A. and University of Leon, Department of Mechanical, Computer Science and Aerospace Engineering, Campus de Vegazana S/N, Leon and Hernandez-Garcia A. and Universidad Politecnica de Madrid, Departamento de Ingenieria de Organizacion Administracion de Empresas y Estadistica, Escuela Tecnica Superior de Ingenieros de Telecomunicacion, Av. Complutense 30, Madrid and Guerrero-Higueras A.M. and University of Leon, Department of Mechanical, Computer Science and Aerospace Engineering, Campus de Vegazana S/N, Leon and Rodriguez-Sedano F.J. and University of Leon, Department of Mechanical, Computer Science and Aerospace Engineering, Campus de Vegazana S/N, Leon},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Molenaar2017614,
	author = {Molenaar, Inge and Knoop-Van Campen, Carolien A. N. and Hasselman, Fred},
	title = {The effects of a learning analytics empowered technology on students' arithmetic skill development},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {614 – 615},
	doi = {10.1145/3027385.3029488},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016489611&doi=10.1145%2f3027385.3029488&partnerID=40&md5=63d381f86694c3c500ee5abf25b78b8e},
	affiliations = {Radboud University, Montessorilaan 3, Nijmegen, Netherlands},
	abstract = {Learning analytics empowered educational technologies (LA-ET) in primary classrooms allow for blended learning scenarios with teacher-lead instructions, class-paced and individually-paced practice. This quasi-experimental study investigates the effects of a LA-ET on the development of students' arithmetic skills over one schoolyear. Children learning in a traditional paper & pencil condition were compared to learners using a LA-ET on tablet computers in grade 4. The educational technology combined teacher dashboards (extracted analytics) and class and individually paced assignments (embedded analytics). The results indicated that children in the LA-ET condition made significantly more progress on arithmetic skills in one schoolyear compared to children in the paper & pencil condition. © 2017 ACM.},
	author_keywords = {Ability levels; Arithmetic's; Educational technologies; Primary education},
	keywords = {Educational technology; Students; Teaching; Ability levels; Blended learning; Children learning; Primary education; Skill development; Tablet computer; Education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@CONFERENCE{Dichev201870,
	author = {Dichev, Christo and Dicheva, Darina and Irwin, Keith},
	title = {Gamification driven learning analytics},
	year = {2018},
	journal = {Proceedings of the International Conference on e-Learning, ICEL},
	volume = {2018-July},
	pages = {70 – 76},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050796779&partnerID=40&md5=840612ca9c7518d728c05ffc556f1299},
	affiliations = {Computer Science Department, Winston Salem State University, Winston Salem, United States},
	abstract = {In this paper we introduce our approach towards learning analytics and associated visualizations implemented in a gamified learning platform. Driven by the goal to better encourage learners to reflect on and monitor their learning activities, we aim at bridging the gap between learning analytics and educational gamification research. We discuss the principles and the learning analytics support incorporated in the form of learning dashboards into the course gamification platform OneUp Learning. The focus of the paper is on leveraging the potential of combining learning analytics and gamification, on the feedback capabilities and mechanisms of OneUp dashboards, and on utilizing their motivational effect in a learning context. The paper presents the design strategy, the visualization approach of the dashboards, and the provided support for learners and teachers. © Academic Conferences Limited. All rights reserved.},
	author_keywords = {Dashboard; Feedback; Gamification; Learning analytics; Motivation; Self-regulation; Visualization},
	keywords = {E-learning; Feedback; Flow visualization; Motivation; Teaching; Dashboard; Design strategies; Feedback capabilities; Gamification; Learning Activity; Learning analytics; Learning platform; Self regulation; Visualization},
	editor = {Ivala E.},
	publisher = {Academic Conferences Limited},
	issn = {20488882},
	isbn = {978-191121890-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. e-Lear., ICEL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{2018,
	title = {ACM International Conference Proceeding Series},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046059060&partnerID=40&md5=b7007878f235d6ad9c378551de76bf7a},
	abstract = {The proceedings contain 60 papers. The topics discussed include: the half-life of MOOC knowledge: a randomized trial evaluating knowledge retention and retrieval practice in MOOCs; graph-based visual topic dependency models: supporting assessment design and delivery at scale; data-driven generation of rubric criteria from an educational programming environment; supporting teacher's intervention in students' virtual collaboration using a network based model; correlating affect and behavior in reasoning mind with state test achievement; license to evaluate: preparing learning analytics dashboards for educational practice; open learner models and learning analytics dashboards: a systematic review; multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in Flanders; a qualitative evaluation of a learning dashboard to support advisor-student dialogues; the classrooom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers; an application of participatory action research in advising-focused learning analytics; profiling students from their questions in a blended learning environment; recurrence quantification analysis as a method for studying text comprehension dynamics; towards a writing analytics framework for adult English language learners; epistemic network analysis of students' longer written assignments as formative/summative evaluation; and the influence of student's cognitive and motivational characteristics on student's use of a 4C/ID-based online learning environment and their learning gain.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Perez-Colado2018,
	author = {Perez-Colado, Ivan J. and Rotaru, Dan Cristian and Freire-Moran, Manuel and Martinez-Ortiz, Ivan and Fernandez-Manjon, Baltasar},
	title = {Multi-level game learning analytics for serious games},
	year = {2018},
	journal = {2018 10th International Conference on Virtual Worlds and Games for Serious Applications, VS-Games 2018 - Proceedings},
	doi = {10.1109/VS-Games.2018.8493435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057309151&doi=10.1109%2fVS-Games.2018.8493435&partnerID=40&md5=ca60be4c3e83ae87f09d4ebabb3887a6},
	affiliations = {Dept. of Software Engineering and AI, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain},
	abstract = {Serious games are usually used or deployed in an educational setting as an isolated or individual activity, disconnected from other curricular activities. However, to really increase the adoption of serious games in different educational scenarios, the combination and integration of games into the educational flow should be simplified. We envision Serious Games as new type of educational activity that can be combined as parts of other games (e.g. minigames integrated in larger games), integrated into other online activities, or even mixed with both game and non-game activities. In addition, if we want to make the most from serious games, a learning analytics system must be in place to harvest and analyze interactions, providing metrics and insights to instructors regarding the gameplay sessions. Moreover, if a course-level learning analytics strategy is designed, it must be aligned with the game learning analytics. This approach requires communication between games and educational activities used during the educational experience. From a game learning analytics standpoint, gaining insights from these integrated experiences introduces new requirements within potentially complex multi-level or hierarchical activities. Moreover, the analysis required to generate these metrics should be both efficient and provide insight in an understandable way and for different stakeholders. This paper describes an approach to multilevel game learning analytics from the perspectives of data model, implementation architecture, and result visualization in teacher-oriented dashboards © 2018 IEEE.},
	author_keywords = {Game learning analytics; Learning analytics models; Location-based games; Multi-level games; Serious games; Teacheroriented dashboards; xAPI},
	keywords = {Data visualization; Interactive computer graphics; Virtual reality; Learning analytics; Location based games; Multilevels; Teacheroriented dashboards; xAPI; Serious games},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153867123-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Virtual Worlds Games Serious Appl., VS-Games - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@ARTICLE{Albó2019541,
	author = {Albó, Laia and Barria-Pineda, Jordan and Brusilovsky, Peter and Hernández-Leo, Davinia},
	title = {Concept-Level Design Analytics for Blended Courses},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11722 LNCS},
	pages = {541 – 554},
	doi = {10.1007/978-3-030-29736-7_40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072975165&doi=10.1007%2f978-3-030-29736-7_40&partnerID=40&md5=05edc0b339f8160dd0ec8dad449d2e5b},
	affiliations = {Universitat Pompeu Fabra, Barcelona, Spain; University of Pittsburgh, Pittsburgh, PA, United States},
	abstract = {Although many efforts are being made to provide educators with dashboards and tools to understand student behaviors within specific technological environments (learning analytics), there is a lack of work in supporting educators in making data-informed design decisions when designing a blended course and planning learning activities. In this paper, we introduce concept-level design analytics, a knowledge-based visualization, which uncovers facets of the learning activities that are being authored. The visualization is integrated into a (blended) learning design authoring tool, edCrumble. This new approach is explored in the context of a higher education programming course, where teaching assistants design labs and home practice sessions with online smart learning content on a weekly basis. We performed a within-subjects user study to compare the use of the design tool both with and without the visualization. We studied the differences in terms of cognitive load, design outcomes and user actions within the system to compare both conditions to the objective of evaluating the impact of using design analytics during the decision-making phase of course design. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Authoring tool; Blended learning; Concept-level visualization; Design analytics; Learning design; Smart learning content},
	keywords = {Decision making; Engineering education; Knowledge based systems; Visualization; Authoring tool; Blended learning; Concept levels; Learning contents; Learning designs; Curricula},
	correspondence_address = {L. Albó; Universitat Pompeu Fabra, Barcelona, Spain; email: laia.albo@upf.edu},
	editor = {Scheffel M. and Broisin J. and Pammer-Schindler V. and Ioannou A. and Schneider J.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303029735-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Kiy2018,
	author = {Kiy, Alexander and Sass, Kristin and Lucke, Ulrike},
	title = {Facing the general data privacy regulation: What data is being collected about me and how can I get access?; [Der EU-Datenschutz-Grundverordnung begegnen: Welche Daten sind über mich erhoben und wie komme ich da ran?]},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2250},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060065904&partnerID=40&md5=11b6044e92fb7d1df12e424b6dd26260},
	affiliations = {Universität Potsdam, Institut für Informatik and Computational Science, August-Bebel-Str. 89, Potsdam, 14482, Germany},
	abstract = {With the General Data Privacy Regulation (GDPR) coming into force, users get new and advanced privileges in dealing with their personal data. Especially in virtual learning environments, where manifold data is aggregated and processed, the transparency about which data is gathered, and saved is lost quickly. When the number of applications increases, it gets even more confusing for the users to keep track of their data. In addition, at worst case it entails several manual steps by the service providers to exercise the data subject rights. This article presents a self-information dashboard, by which the users achieve an overview about their personal data. The implementation of the use cases is based on the GDPR fundamental data subject rights and is automated as far possible. Therefore, users can exercise most of their rights without manual intervention of service providers. The article closes with a discussion about current limitations and future challenges. © 2018 CEUR-WS. All rights reserved.},
	author_keywords = {DSGVO; GDPR; Learning Analytics; PLE; Self Service},
	keywords = {Computer aided instruction; E-learning; Current limitation; DSGVO; GDPR; Learning analytics; Manual intervention; Privacy regulation; Self Service; Virtual learning environments; Data privacy},
	correspondence_address = {A. Kiy; Universität Potsdam, Institut für Informatik and Computational Science, Potsdam, August-Bebel-Str. 89, 14482, Germany; email: vorname.nachname@uni-potsdam.de},
	editor = {Schiffner D. and Goethe Universitat, Studiumdigitale, Institut fur Informatik, Robert-Mayer-Strasse 10, Frankfurt am Main},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {German},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Van Horne201821,
	author = {Van Horne, Sam and Curran, Maura and Smith, Anna and VanBuren, John and Zahrieh, David and Larsen, Russell and Miller, Ross},
	title = {Facilitating Student Success in Introductory Chemistry with Feedback in an Online Platform},
	year = {2018},
	journal = {Technology, Knowledge and Learning},
	volume = {23},
	number = {1},
	pages = {21 – 40},
	doi = {10.1007/s10758-017-9341-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035084698&doi=10.1007%2fs10758-017-9341-0&partnerID=40&md5=3b331d4520eb73448a61dc4f1c6deeb1},
	affiliations = {The Office of Teaching, Learning and Technology & The Office of Assessment, The University of Iowa, Iowa City, IA, United States; Department of Communication Sciences and Disorders, The University of Iowa, Iowa City, IA, United States; The Office of Teaching, Learning and Technology, The University of Iowa, Iowa City, IA, United States; Department of Biostatistics, The University of Iowa, Iowa City, IA, United States; Department of Chemistry, The University of Iowa, Iowa City, IA, United States; ITS Administrative Information Systems, The University of Iowa, Iowa City, IA, United States; Office of Institutional Research and Effectiveness, University of Delaware, 332 Hullihen Hall, Newark, DE, United States; Division of Pediatric Critical Care, University of Utah School of Medicine, Salt Lake City, UT, United States; Division of Biomedical Statistics and Informatics, Mayo Clinic, Rochester, MN, United States},
	abstract = {Instructional technologists and faculty in post-secondary institutions have increasingly adopted learning analytics interventions such as dashboards that provide real-time feedback to students to support student’ ability to regulate their learning. But analyses of the effectiveness of such interventions can be confounded by measures of students’ prior learning as well as their baseline level of self-regulated learning. For this research study, we sought to examine whether the frequency of accessing a dashboard was associated with learning outcomes after matching subjects on confounding variables. And because prior research has suggested that measures of prior learning are associated with students’ likelihood to use learning analytics interventions, we sought to adequately control for learners’ likelihood to access the feedback by using a propensity score matching with a non-binary treatment variable. We administered the Motivated Strategies for Learning Questionnaire and also collected demographic information for a propensity score matching process. Users’ frequency of accessing the intervention was categorized as High, Moderate, or Low/No usage. After matching users on characteristics associated with dashboard usage (gender, high school GPA, and the “Test Anxiety” and “Self Efficacy” factors) we found that both the “High” and “Moderate” users achieved significantly higher course grades than the “Low/No” users. The results suggest learners benefited from regularly accessing the feedback, but extreme amounts of usage were not necessary to achieve a positive effect. We discuss the implications for recommending how students use learning analytics interventions without excessively accessing feedback. © 2017, Springer Science+Business Media B.V., part of Springer Nature.},
	author_keywords = {Feedback; Learning analytics; Motivation; Propensity score matching; Self-regulated learners},
	keywords = {Feedback; Learning systems; Motivation; Students; Teaching; Demographic information; Introductory chemistry; Learning analytics; Post-secondary institutions; Propensity score matching; Real-time feedback; Self-regulated learners; Self-regulated learning; Education},
	correspondence_address = {S. Van Horne; Office of Institutional Research and Effectiveness, University of Delaware, Newark, 332 Hullihen Hall, United States; email: vanhorne@udel.edu},
	publisher = {Springer Netherlands},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@ARTICLE{Chaudy2018209,
	author = {Chaudy, Yaëlle and Connolly, Thomas},
	title = {Specification and evaluation of an assessment engine for educational games: Empowering educators with an assessment editor and a learning analytics dashboard},
	year = {2018},
	journal = {Entertainment Computing},
	volume = {27},
	pages = {209 – 224},
	doi = {10.1016/j.entcom.2018.07.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050375803&doi=10.1016%2fj.entcom.2018.07.003&partnerID=40&md5=7a59c7a916dd35663d20eb5ab15f2b9a},
	affiliations = {University of the West of Scotland, Paisley, United Kingdom},
	abstract = {Assessment is a crucial aspect of any teaching and learning process. Educational games offer promising advantages for assessment; personalised feedback to students and automated assessment process. However, while many teachers agree that educational games increase motivation, learning and retention, few of them are ready to fully trust them as an assessment tool. We believe there are two main reasons for this lack of trust: educators are not given sufficient information about the gameplays, and many educational games are distributed as black-boxes, unmodifiable by teachers. This paper presents an assessment engine designed to separate a game and its assessment. It allows teachers to modify a game's assessment after distribution and visualise gameplay data via a learning analytics dashboard. The engine was evaluated quantitatively by 31 educators. Findings were overall very positive: both the assessment editor and the learning analytics dashboard were rated useful and easy to use. The evaluation also indicates that, having access to EngAGe, educators would be more likely to trust a game's assessment. This paper concludes that EngAGe can be used by educators effectively to modify educational games’ assessment and visualise gameplay data, and that it contributes to increasing their trust in educational games as an assessment tool. © 2018 Elsevier B.V.},
	author_keywords = {Assessment; Assessment editor; Assessment engine; Educational games; Learning analytics},
	keywords = {Engines; Assessment; Assessment editor; Assessment tool; Automated assessment; Educational game; Feedback to students; Learning analytics; Teaching and learning; Teaching},
	correspondence_address = {Y. Chaudy; University of the West of Scotland, Paisley, United Kingdom; email: yaelle.chaudy@uws.ac.uk},
	publisher = {Elsevier B.V.},
	issn = {18759521},
	language = {English},
	abbrev_source_title = {Entertain. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Koné201967,
	author = {Koné, Malik and May, Madeth and Iksal, Sébastien and Oumtanaga, Souleyman},
	title = {Towards visual explorations of forums’ collective dynamics in learning management systems},
	year = {2019},
	journal = {CSEDU 2019 - Proceedings of the 11th International Conference on Computer Supported Education},
	volume = {2},
	pages = {67 – 78},
	doi = {10.5220/0007716000670078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067094203&doi=10.5220%2f0007716000670078&partnerID=40&md5=ac775c8ad1b0555bec22314db6e8532f},
	affiliations = {LIUM, Le Mans Université, Le Mans, France; LARIT, INP-HB, Yamoussoukro, Cote d'Ivoire},
	abstract = {Discussion and exchange among peers have being hailed as an essential part of learning since at least, Vygotsky’s socio-constructivist theory. There, learning is presented as a subtle and dynamical collective process. Hence, despite numerous efforts to understand how learners engage and maintain inspiring discussions, researchers continue to question how to effectively reinforce the collective actions. In Learning Management Systems (LMSs) they propose Learning Dashboards (LDBs) to learners, tutors, and managers to help them monitor various learning indicators. But only recently have they employed Natural Language Processings (NLPs) and Social Network Analysis (SNA) techniques to display temporal indicators incorporating the forums’ content analysis and the learners’ behavioral patterns. In this study, we present our design efforts to model a scalable and portable indicator of collective actions. We aim to support tutors’ monitoring of forums’ activities through explorable visualizations. We review previous researches about visual explorations of Forums’ content and online collaboration’s measures. We expose in progress visualizations built from three different datasets and propose directions towards further development of indicators to monitor collective actions. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Forum; Learning analytics; Social network; Visualization},
	keywords = {E-learning; Flow visualization; Natural language processing systems; Social networking (online); Visualization; Behavioral patterns; Collective dynamics; Collective process; Forum; Learning analytics; Learning management system; NAtural language processing; On-line collaborations; Learning systems},
	editor = {Lane H. and Zvacek S. and Uhomoibhi J.},
	publisher = {SciTePress},
	isbn = {978-989758367-4},
	language = {English},
	abbrev_source_title = {CSEDU - Proc. Int. Conf. Comput. Support. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Charleer2018389,
	author = {Charleer, Sven and Moere, Andrew Vande and Klerkx, Joris and Verbert, Katrien and De Laet, Tinne},
	title = {Learning Analytics Dashboards to Support Adviser-Student Dialogue},
	year = {2018},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {11},
	number = {3},
	pages = {389 – 399},
	doi = {10.1109/TLT.2017.2720670},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023780081&doi=10.1109%2fTLT.2017.2720670&partnerID=40&md5=8f22e20f880c201c0bd5b509dca872b8},
	affiliations = {Department of Computer Science, KU Leuven, Leuven, 3001, Belgium; Department of Architecture, KU Leuven, Leuven, 3001, Belgium; Tutorial Services of Engineering Science, KU Leuven, Leuven, 3001, Belgium},
	abstract = {This paper presents LISSA ("Learning dashboard for Insights and Support during Study Advice"), a learning analytics dashboard designed, developed, and evaluated in collaboration with study advisers. The overall objective is to facilitate communication between study advisers and students by visualizing grade data that is commonly available in any institution. More specifically, the dashboard attempts to support the dialogue between adviser and student through an overview of study progress, peer comparison, and by triggering insights based on facts as a starting point for discussion and argumentation. We report on the iterative design process and evaluation results of a deployment in 97 advising sessions. We have found that the dashboard supports the current adviser-student dialogue, helps them motivate students, triggers conversation, and provides tools to add personalization, depth, and nuance to the advising session. It provides insights at a factual, interpretative, and reflective level and allows both adviser and student to take an active role during the session. © 2018 IEEE.},
	author_keywords = {Information visualization; learning technologies},
	keywords = {Data visualization; Electronic mail; Information systems; Recommender systems; Visualization; Context; Information visualization; Interviews; Learning technology; Tutorials; Students},
	correspondence_address = {S. Charleer; Department of Computer Science, KU Leuven, Leuven, 3001, Belgium; email: sven.charleer@kuleuven.be},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 74}
}

@ARTICLE{Rienties2018187,
	author = {Rienties, Bart and Herodotou, Christothea and Olney, Tom and Schencks, Mat and Boroowa, Avi},
	title = {Making sense of learning analytics dashboards: A technology acceptance perspective of 95 teachers},
	year = {2018},
	journal = {International Review of Research in Open and Distributed Learning},
	volume = {19},
	number = {5},
	pages = {187 – 202},
	doi = {10.19173/irrodl.v19i5.3493},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057353510&doi=10.19173%2firrodl.v19i5.3493&partnerID=40&md5=5867f14dfd77155badf3d2815a157ae3},
	affiliations = {Open University, Learning and Teaching Innovation, United Kingdom},
	abstract = {The importance of teachers in online learning is widely acknowledged to effectively support and stimulate learners. With the increasing availability of learning analytics data, online teachers might be able to use learning analytics dashboards to facilitate learners with different learning needs. However, deployment of learning analytics visualisations by teachers also requires buy-in from teachers. Using the principles of technology acceptance model, in this embedded case-study, we explored teachers' readiness for learning analytics visualisations amongst 95 experienced teaching staff at one of the largest distance learning universities by using an innovative training method called Analytics4Action Workshop. The findings indicated that participants appreciated the interactive and hands-on approach, but at the same time were skeptical about the perceived ease of use of learning analytics tools they were offered. Most teachers indicated a need for additional training and follow-up support for working with learning analytics tools. Our results highlight a need for institutions to provide effective professional development opportunities for learning analytics. © 2018, Athabasca University.},
	author_keywords = {Distance education; Information visualisation; Learning analytics; Learning dashboards},
	issn = {14923831},
	language = {English},
	abbrev_source_title = {Int. Rev. Res. Open Distributed Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 80; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2018,
	title = {CEUR Workshop Proceedings},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2250},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060038440&partnerID=40&md5=0960deb559491aa0985866361cfa4a34},
	abstract = {The proceedings contain 29 papers. The topics discussed include: design patterns for digital competency credentials based on open badges in the context of virtual mobility; facing the general data privacy regulation: what data is being collected about me and how can i get access?; heart rate, electrodermal activity and skin conductance as new sources for learning analytics; detecting academic emotions from learners’ skin conductance and heart rate: data-driven approach using fuzzy logic; branched learning paths for the recommendation of personalized sequences of course items; on the emergence of typical behaviors in LMS; education 4.0 for tall thin engineer competencies blended learning 4.0 process with learning analytics cockpit; and evidence-based implementation of a learning analytics dashboard into an existing learning management system.},
	editor = {Schiffner D. and Goethe Universitat, Studiumdigitale, Institut fur Informatik, Robert-Mayer-Strasse 10, Frankfurt am Main},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Meluso2018176,
	author = {Meluso, Floriana and Avogadro, Paolo and Calegari, Silvia and Dominoni, Matteo},
	title = {Utilization measures in a learning management system},
	year = {2018},
	journal = {Communications in Computer and Information Science},
	volume = {814},
	pages = {176 – 196},
	doi = {10.1007/978-3-319-94809-6_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049691199&doi=10.1007%2f978-3-319-94809-6_9&partnerID=40&md5=3233d1d1654af958d909ecefc0440a99},
	affiliations = {Università degli Studi di Milano-Bicocca, Milan, 22104, Italy},
	abstract = {Learning Management Systems (LMSs) are becoming more and more popular and incorporate many different functionalities. For this reason, an evaluation of the quantitative utilization of all the parts of a LMS is essential. In this research we propose indicators and techniques which allow to understand in detail how a functionality is accessed by the users. These analytic tools are useful in particular for the administrators of the LMS which are in charge of allocating resources according to the workload and importance of the functionalities. We tested the proposed indicators with the data obtained from the LMS of Università degli Studi di Milano-Bicocca (Milan, Italy) about the messaging functionality. Although the students’ messages can potentially be a source of big data, in the present case it is observed that the utilization is limited. With this analysis it has been possible to notice a similarity between the utilization of the message system and the empirical Zipf law. We also introduced the description of the structure of a dashboard which allows to access to the indicators and goes towards the definition of a global tool for students, teachers and administrators. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {Indicator; Learning analytics; LMS; Message system; Zipf},
	keywords = {Indicators (instruments); Information management; Teaching; Analytic tools; Learning analytics; Learning management system; Message systems; Milan , Italy; Zipf; Zipf Law; Big data},
	correspondence_address = {P. Avogadro; Università degli Studi di Milano-Bicocca, Milan, 22104, Italy; email: paolo.avogadro@unimib.it},
	editor = {Quix C. and Bernardino J. and Filipe J.},
	publisher = {Springer Verlag},
	issn = {18650929},
	isbn = {978-331994808-9},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bodily201841,
	author = {Bodily, Robert and Kay, Judy and Aleven, Vincent and Jivet, Ioana and Davis, Dan and Xhakaj, Franceska and Verbert, Katrien},
	title = {Open learner models and learning analytics dashboards: A systematic review},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {41 – 50},
	doi = {10.1145/3170358.3170409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045874117&doi=10.1145%2f3170358.3170409&partnerID=40&md5=e6a71082257743b6aa99cedba60c86a5},
	affiliations = {Brigham Young University, United States; University of Sydney, Australia; Carnegie Mellon University, United States; Open University of the Netherlands, Netherlands; Delft University of Technology, Netherlands; University of Leuven, Belgium},
	abstract = {This paper aims to link student facing Learning Analytics Dashboards (LADs) to the corpus of research on Open Learner Models (OLMs), as both have similar goals. We conducted a systematic review of literature on OLMs and compared the results with a previously conducted review of LADs for learners in terms of (i) data use and modelling, (ii) key publication venues, (iii) authors and articles, (iv) key themes, and (v) system evaluation. We highlight the similarities and differences between the research on LADs and OLMs. Our key contribution is a bridge between these two areas as a foundation for building upon the strengths of each. We report the following key results from the review: in reports of new OLMs, almost 60% are based on a single type of data; 33% use behavioral metrics; 39% support input from the user; 37% have complex models; and just 6% involve multiple applications. Key associated themes include intelligent tutoring systems, learning analytics, and self-regulated learning. Notably, compared with LADs, OLM research is more likely to be interactive (81% of papers compared with 31% for LADs), report evaluations (76% versus 59%), use assessment data (100% versus 37%), provide a comparison standard for students (52% versus 38%), but less likely to use behavioral metrics, or resource use data (33% against 75% for LADs). In OLM work, there was a heightened focus on learner control and access to their own data. © 2018 Association for Computing Machinery.},
	author_keywords = {Learning analytics dashboards; Literature review; Open learner models; Open student models},
	keywords = {Access control; Computer aided instruction; Students; Comparison standard; Intelligent tutoring system; Learning analytics; Literature reviews; Multiple applications; Open learner models; Open student models; Self-regulated learning; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 126; All Open Access, Green Open Access}
}

@CONFERENCE{Lopez2017181,
	author = {Lopez, Glenn and Seaton, Daniel T. and Ang, Andrew and Tingley, Dustin and Chuang, Isaac},
	title = {Google BigQuery for education: Framework for parsing and analyzing edX MOOC data},
	year = {2017},
	journal = {L@S 2017 - Proceedings of the 4th (2017) ACM Conference on Learning at Scale},
	pages = {181 – 184},
	doi = {10.1145/3051457.3053980},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018405542&doi=10.1145%2f3051457.3053980&partnerID=40&md5=a9d6e642567b44bce17eeee1476910cf},
	affiliations = {Harvard, Cambridge, MA, United States; MIT, Cambridge, MA, United States},
	abstract = {The size and complexity of MOOC data present overwhelming challenges to many institutions. This paper details the functionality of edx2bigquery -An open source Python package developed by Harvard and MIT to ingest and report on hundreds of MITx and HarvardX course datasets from edX, making use of Google BigQuery to handle multiple terabytes of learner data. For this application, we find that Google BigQuery provides ease of use in loading the multi-faceted MOOC datasets and near real-Time interactive querying of data, including large clickstream datasets; moreover, we are able to provide flexible research and reporting dashboards, visualizing and aggregating data, by interfacing services associated with BigQuery. This framework makes it feasible for edx2bigquery to be open source, following standards which emphasize the importance of data products that transcend a particular data science platform and allow teams with diverse backgrounds to interact with data. edx2bigquery is being adopted by other institutions with an aim toward future collaboration. © 2017 ACM.},
	author_keywords = {Big data; BigQuery; Educational data mining; Learning analytics; MOOC},
	keywords = {Data mining; BigQuery; Clickstreams; Data products; Educational data mining; Interactive querying; Learning analytics; MOOC; Near-real time; Big data},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145034450-0},
	language = {English},
	abbrev_source_title = {L@S - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Green Open Access}
}

@ARTICLE{Holstein2018169,
	author = {Holstein, Kenneth and Yu, Zac and Sewall, Jonathan and Popescu, Octav and McLaren, Bruce M. and Aleven, Vincent},
	title = {Opening up an intelligent tutoring system development environment for extensible student modeling},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10947 LNAI},
	pages = {169 – 183},
	doi = {10.1007/978-3-319-93843-1_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049364721&doi=10.1007%2f978-3-319-93843-1_13&partnerID=40&md5=e154696d05fc808c96e67e433791d3ac},
	affiliations = {Carnegie Mellon University, Pittsburgh, 15213, PA, United States},
	abstract = {ITS authoring tools make creating intelligent tutoring systems more cost effective, but few authoring tools make it easy to flexibly incorporate an open-ended range of student modeling methods and learning analytics tools. To support a cumulative science of student modeling and enhance the impact of real-world tutoring systems, it is critical to extend ITS authoring tools so they easily accommodate novel student modeling methods. We report on extensions to the CTAT/Tutorshop architecture to support a plug-in approach to extensible student modeling, which gives an author full control over the content of the student model. The extensions enhance the range of adaptive tutoring behaviors that can be authored and support building external, student- or teacher-facing real-time analytics tools. The contributions of this work are: (1) an open architecture to support the plugging in, sharing, re-mixing, and use of advanced student modeling techniques, ITSs, and dashboards; and (2) case studies illustrating diverse ways authors have used the architecture. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {Architectures; Authoring tools; Closing the loop; Intelligent tutoring systems; Learning analytics; Student modeling},
	keywords = {Architecture; Artificial intelligence; Computer aided instruction; Cost effectiveness; Education computing; Intelligent vehicle highway systems; Teaching; Authoring tool; Closing the loop; Intelligent tutoring system; Learning analytics; Student Modeling; Students},
	correspondence_address = {K. Holstein; Carnegie Mellon University, Pittsburgh, 15213, United States; email: kjholste@cs.cmu.edu},
	editor = {Mavrikis M. and Penstein Rosé C. and McLaren B. and Hoppe H.U. and Luckin R. and Porayska-Pomsta K. and du Boulay B. and Martinez-Maldonado R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331993842-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Taibi2018145,
	author = {Taibi, Davide and Bianchi, Francesca and Kemkes, Philipp and Marenzi, Ivana},
	title = {Learning analytics for interpreting},
	year = {2018},
	journal = {CSEDU 2018 - Proceedings of the 10th International Conference on Computer Supported Education},
	volume = {1},
	pages = {145 – 154},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047604017&partnerID=40&md5=8ee181b07ed5b3f099594135864f851e},
	affiliations = {Institute for Educational Technology, National Research Council of Italy, Palermo, Italy; University of Salento, Lecce, Italy; L3S Research Center, Hannover, Germany},
	abstract = {An important activity in the life of interpreters is terminology work. A primary method for learning technical vocabulary is the creation of personal glossaries. The current paper describes the design and creation of a system that guides the students in autonomous vocabulary work, supports the students' learning progress, and helps the teacher in monitoring the student commitment to and achievements in the creation of personal glossaries. The system includes a tool for the creation of glossaries, a tracking system that records the students' actions and the websites they visit while searching the Web for linguistic and content information, and a learning analytics dashboard. The system was tested on a class of 34 university students training in interpreting and the paper reports some preliminary results. Copyright © 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Glossary; Learning Analytics Dashboard; Technical Vocabulary for Interpreting},
	keywords = {E-learning; Glossaries; Search engines; Teaching; Content information; Learning analytics; Learning progress; Searching the Web; Technical Vocabulary for Interpreting; Tracking system; University students; Students},
	editor = {Zvacek S. and Uhomoibhi J. and McLaren B.M. and Reilly R.},
	publisher = {SciTePress},
	isbn = {978-989758291-2},
	language = {English},
	abbrev_source_title = {CSEDU - Proc. Int. Conf. Comput. Supported Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Ternier2018177,
	author = {Ternier, Stefaan and Scheffel, Maren and Drachsler, Hendrik},
	title = {Towards a cloud-based big data infrastructure for higher education institutions},
	year = {2018},
	journal = {Lecture Notes in Educational Technology},
	pages = {177 – 194},
	doi = {10.1007/978-981-13-0650-1_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056188800&doi=10.1007%2f978-981-13-0650-1_10&partnerID=40&md5=c1396c8c0c83a5c9e1e84cda61cf000c},
	affiliations = {Welten Institute, Open University of the Netherlands, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; German Institute of International Educational Research (DIPF), Goethe University Frankfurt, Schloßstraße 29, Frankfurt Am Main, 60486, Germany},
	abstract = {This chapter reports about experiences gained in developing a learning analytics infrastructure for an ecosystem of different MOOC providers in Europe. These efforts originated in the European project ECO that aimed to develop a single-entry portal for various MOOC providers by developing shared technologies for these providers and distributing these technologies to the individual MOOC platforms of the project partners. The chapter presents a big data infrastructure that is able to handle learning activities from various sources and shows how the work in ECO led to a standardised approach for capturing learning analytics data according to the xAPI specification and storing them into cloud-based big data storage. The chapter begins with a definition of big data in higher education and thereafter describes the practical experiences gained from developing the learning analytics infrastructure. © Springer Nature Singapore Pte Ltd. 2018.},
	author_keywords = {Cloud storage; Dashboard; Learning analytics; Real time feedback; Visualisation; xAPI interfaces},
	correspondence_address = {S. Ternier; Welten Institute, Open University of the Netherlands, Heerlen, Valkenburgerweg 177, 6419 AT, Netherlands; email: stefaan.ternier@ou.nl},
	publisher = {Springer International Publishing},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Seaton2018229,
	author = {Seaton, Jennifer and Graf, Sabine and Chang, Maiga and Farhmand, Arta},
	title = {Incorporating learning analytics in an educational game to provide players with information about how to improve their performance},
	year = {2018},
	journal = {Proceedings - IEEE 18th International Conference on Advanced Learning Technologies, ICALT 2018},
	pages = {229 – 230},
	doi = {10.1109/ICALT.2018.00121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052536908&doi=10.1109%2fICALT.2018.00121&partnerID=40&md5=f9d7090299b02221cd89068aee88e324},
	affiliations = {School of Computing and Information Systems, Athabasca University, Edmonton, Canada},
	abstract = {Educational games aim to balance learning and playing. However, for people to benefit from an educational game, they must be encouraged to play the game often. Providing players with information about how to improve their performance could help in achieving this goal. This paper examines how a learning analytics dashboard can be incorporated into an educational game to encourage players to play more often and continuously. The proposed dashboard provides players with a variety of information such as how their performance and skills change over time. Such information allows players to see their performance and play habits, and find strategies on how to improve their performance, and therefore their learning, in the game. © 2018 IEEE.},
	author_keywords = {Dashboard; Educational game; Learning analytics; Metacognitive skill},
	keywords = {Dashboard; Educational game; Learning analytics; Metacognitive skills},
	editor = {Chen N.-S. and Chang M. and Huang R. and Kinshuk K. and Moudgalya K. and Murthy S. and Sampson D.G.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153866049-2},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Praharaj2018187,
	author = {Praharaj, Sambit and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus},
	title = {Multimodal Analytics for Real-Time Feedback in Co-located Collaboration},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11082 LNCS},
	pages = {187 – 201},
	doi = {10.1007/978-3-319-98572-5_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053193328&doi=10.1007%2f978-3-319-98572-5_15&partnerID=40&md5=20f2922aa977422878b32248451dd33f},
	affiliations = {Open Universiteit, Valkenburgerweg 177, Heerlen, 6419AT, Netherlands; DIPF, Schloßstr. 29, Frankfurt am Main, 60486, Germany; Goethe Universität, Robert-Mayer-Str. 11-15, Frankfurt am Main, 60629, Germany},
	abstract = {Collaboration is an important 21st century skill; it can take place in a remote or co-located setting. Co-located collaboration (CC) is a very complex process which involves subtle human interactions that can be described with multimodal indicators (MI) like gaze, speech and social skills. In this paper, we first give an overview of related work that has identified indicators during CC. Then, we look into the state-of-the-art studies on feedback during CC which also make use of MI. Finally, we describe a Wizard of Oz (WOz) study where we design a privacy-preserving research prototype with the aim to facilitate real-time collaboration in-the-wild during three co-located group PhD meetings (of 3–7 members). Here, human observers stationed in another room act as a substitute for sensors to track different speech-based cues (like speaking time and turn taking); this drives a real-time visualization dashboard on a public shared display. With this research prototype, we want to pave way for design-based research to track other multimodal indicators of CC by extending this prototype design using both humans and sensors. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Collaboration; CSCL; Feedback; Intervention; Multimodal indicators; Multimodal learning analytics},
	keywords = {Data privacy; Feedback; Collaboration; CSCL; Intervention; Multi-modal; Multi-modal learning; Engineering education},
	correspondence_address = {S. Praharaj; Open Universiteit, Heerlen, Valkenburgerweg 177, 6419AT, Netherlands; email: sambit.praharaj@ou.nl},
	editor = {Elferink R. and Drachsler H. and Pammer-Schindler V. and Perez-Sanagustin M. and Scheffel M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331998571-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33}
}

@ARTICLE{Pérez-Álvarez201816,
	author = {Pérez-Álvarez, Ronald and Maldonado-Mahauad, Jorge and Pérez-Sanagustín, Mar},
	title = {Tools to Support Self-Regulated Learning in Online Environments: Literature Review},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11082 LNCS},
	pages = {16 – 30},
	doi = {10.1007/978-3-319-98572-5_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053175970&doi=10.1007%2f978-3-319-98572-5_2&partnerID=40&md5=78564dd16be2591661e019ed0b1938e7},
	affiliations = {Department of Computer Science, Pontificia Universidad Católica de Chile, Santiago, Chile; University of Costa Rica, Sede Regional del Pacífico, Puntarenas, Costa Rica; Department of Computer Science, University of Cuenca, Cuenca, Ecuador; Université Toulouse III Paul Sabatier, Toulouse, France},
	abstract = {Self-regulated learning (SRL) skills are especially important in Massive Open Online Courses (MOOCs), where teacher guidance is scarce, and learners must engage in their learning process trying to succeed and achieve their learning goals. However, developing SRL strategies is difficult for learners given the autonomy that is required in this kind of courses. In order to support learners on this process, researchers have proposed a variety of tools designed to support certain aspects of self-regulation in online learning environments. Nevertheless, there is a lack of study to understand what the commonalities and differences in terms of design are, what the results in terms of the effect on learners’ self-regulation are and which of them could be applied in MOOCs. Those are the questions that should be further explored. In this paper we present a systematic literature review where 22 tools designed to support SRL in online environments were analyzed. Our findings indicate that: (1) most of the studies do not evaluate the effect on learners’ SRL strategies; (2) the use of interactive visualizations has a positive effect on learners’ motivation; (3) the use of the social comparison component has a positive effect on engagement and time management; and (4) there is a lack of models to match learners’ activity with the tools with SRL strategies. Finally, we present the lessons learned for guiding the community in the implementation of tools to support SRL strategies in MOOCs. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Learning analytics; Literature review; Massive Open Online Courses; MOOC; Online; Self-Regulated Learning; System; Tools},
	keywords = {Computer aided instruction; Curricula; Deregulation; Engineering education; Learning systems; Teaching; Tools; Visualization; Dashboard; Learning analytics; Literature reviews; Massive open online course; MOOC; Online; Self-regulated learning; System; E-learning},
	correspondence_address = {R. Pérez-Álvarez; Department of Computer Science, Pontificia Universidad Católica de Chile, Santiago, Chile; email: raperez13@uc.cl},
	editor = {Elferink R. and Drachsler H. and Pammer-Schindler V. and Perez-Sanagustin M. and Scheffel M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331998571-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 62}
}

@CONFERENCE{Ogata2018493,
	author = {Ogata, Hiroaki and Majumdar, Rwitajit and Akçapinar, Gökhan and Hasnine, Mohammad Nehal and Flanagan, Brendan},
	title = {Beyond learning analytics: Framework for technology-enhanced evidence-based education and learning},
	year = {2018},
	journal = {ICCE 2018 - 26th International Conference on Computers in Education, Workshop Proceedings},
	pages = {493 – 496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060055841&partnerID=40&md5=57920ec5a30c76489d06ec891fb874b6},
	affiliations = {Academic Center for Computing and Media Studies, Kyoto University, Japan; Department of Computer Education and Instructional Technology, Hacettepe University, Turkey},
	abstract = {Currently eLearning infrastructure across various institutions often includes a Learning Management System (LMS), various ubiquitous and classroom learning tools, Learning Record Stores (LRS) and Learning Analytics Dashboards (LAD). Such an infrastructure can apply Learning Analytics (LA) methods to process log data and support various stakeholders. Teachers can refine their instructional practices, learners can enhance learning experiences and researchers can study the dynamics of the teaching-learning process with it. While LA platforms gathers and analyses the data, there is a lack of specific design framework to capture the technology-enhanced teaching-learning practices. This position paper focuses the research agenda on evidence in a data-driven educational scenario. We propose the Learning Evidence Analytics Framework (LEAF) and present the research challenges involved. © 2018 Asia-Pacific Society for Computers in Education..All Rights Reserved.},
	author_keywords = {Evidence Analytics; Evidence Based Education; Learning Evidence Analytics Framework},
	keywords = {Classroom learning; Evidence Analytics; Evidence-based; Instructional practices; Learning Evidence Analytics Framework; Learning management system; Research challenges; Teaching-learning process; Learning systems},
	correspondence_address = {H. Ogata; Academic Center for Computing and Media Studies, Kyoto University, Japan; email: ogata.hiroaki.3e@kyoto-u.ac.jp},
	editor = {Wong L.-H. and Banawan M. and Srisawasdi N. and Yang J.-C. and Rodrigo M.M.T. and Chang M. and Wu Y.-T.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986972142-4},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ., Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@CONFERENCE{Hu2017604,
	author = {Hu, Xiao and Hou, Xiangyu and Lei, Chi-Un and Yang, Chengrui and Ng, Jeremy},
	title = {An outcome-based dashboard for Moodle and Open edX},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {604 – 605},
	doi = {10.1145/3027385.3029483},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016480941&doi=10.1145%2f3027385.3029483&partnerID=40&md5=595be3bbb8197bd1a0b78578a724e38d},
	affiliations = {Faculty of Education, University of Hong, Pokfulam, Hong Kong; Technology-Enriched Learning Initiative, University of Hong, Pokfulam, Hong Kong; Deparment of Computer Science, University of Hong, Pokfulam, Hong Kong},
	abstract = {This poster presents a cross-platform learning analytics dashboard on Moodle and Open edX for monitoring outcome-based learning progress. The dashboard visualizes students' interactions with the platforms in near real-time, aiming to help teachers and students monitor students' learning progress. The dashboard has been used in four large-size general education courses in a comprehensive university in Hong Kong, undergoing evaluation and improvement. © 2017 ACM.},
	author_keywords = {Dashboard; Moodle; Open edX, outcome-based learning},
	keywords = {Students; Teaching; Cross-platform; Dashboard; Evaluation and improvement; General education; Learning progress; Moodle; Near-real time; Open edX, outcome-based learning; Education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Schumacher2018,
	author = {Schumacher, Clara and Klasen, Daniel and Ifenthaler, Dirk},
	title = {Evidence-based implementation of a learning analytics dashboard into an existing learning management system; [Evidenzbasierte Implementation eines Learning Analytics Dashboards in ein bestehendes Lernmanagementsystem]},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2250},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060036655&partnerID=40&md5=9e526ffc84dc19574ba6d471b0d1c4dd},
	affiliations = {Universität Mannheim, Technologiebasiertes Instruktionsdesign,, L4 1, Mannheim, 68161, Germany; Universität Mannheim, Technologiebasiertes Instruktionsdesign,, L4 1, Mannheim, 68161, Germany; Universität Mannheim, Technologiebasiertes Instruktionsdesign,, L4 1, Mannheim, 68161, Germany; Curtin University, Australia},
	abstract = {The interaction between learning analytics (LA) systems and students is usually realized via LA-dashboards. The LA-system LeAP is a Plug-In for the learning management platform ILIAS and was designed under consideration of pedagogical, information technological and data privacy perspectives. The featured LA-dashboard offers students an overview about their utilization of the course’s resources, the results of self-assessment tests, the option to decide about the usage of their data and a transparent insight into the stored personal information. A qualitative interview study showed that students particularly perceive the overview about learning objectives and progress, as well as self-assessments as supportive for their learning. The study also showed, that besides transparent data privacy, students request that their progress and behaviour within the learning environment must not influence their final grading. Future research and implementations will be on data analysis, implementing automatic prompts and how students interact with the feedback provided. © 2018 CEUR-WS. All rights reserved.},
	keywords = {Data privacy; E-learning; Grading; Information management; Students; Learning analytics; Learning environments; Learning management system; Learning managements; Learning objectives; Personal information; Qualitative interviews; Self assessment; Computer aided instruction},
	editor = {Schiffner D. and Goethe Universitat, Studiumdigitale, Institut fur Informatik, Robert-Mayer-Strasse 10, Frankfurt am Main},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{De Laet20191454,
	author = {De Laet, Tinne and Broos, Tom and Van Staalduinen, J.P. and Ebner, M.},
	title = {Learning dashboard for supporting students: From first-year engineering to MOOC students},
	year = {2019},
	journal = {Proceedings of the 46th SEFI Annual Conference 2018: Creativity, Innovation and Entrepreneurship for Engineering Education Excellence},
	pages = {1454 – 1456},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073002862&partnerID=40&md5=bbaeceb81fac1b714c3dc4ddb1e83019},
	affiliations = {Tutorial Services Engineering Science, Leuven Engineering and Science Education Center (LESEC), KU Leuven, Leuven, Belgium; Online Labs, TU Delft Online Learning, Delft, Netherlands; Lehr und Lerntechnologien Technische Universität Graz, Graz, Austria},
	author_keywords = {First-year experience; Learning analytics; Learning dashboards; Machine learning; Retention; Student success},
	editor = {Clark R. and Hussmann P.M. and Jarvinen H.-M. and Murphy M. and Vigild M.E.},
	publisher = {European Society for Engineering Education (SEFI)},
	isbn = {978-287352016-8},
	language = {English},
	abbrev_source_title = {Proc. SEFI Annu. Conf.: Creativity, Innov. Entrep. Eng. Educ. Excell.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{He2018361,
	author = {He, Lingjun and Levine, Richard A. and Bohonak, Andrew J. and Fan, Juanjuan and Stronach, Jeanne},
	title = {Predictive Analytics Machinery for STEM Student Success Studies},
	year = {2018},
	journal = {Applied Artificial Intelligence},
	volume = {32},
	number = {4},
	pages = {361 – 387},
	doi = {10.1080/08839514.2018.1483121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048207425&doi=10.1080%2f08839514.2018.1483121&partnerID=40&md5=153e1cf47fa34bbcd3fd8efb7134a555},
	affiliations = {Analytics Studies and Institutional Research, San Diego State University, San Diego, United States; Department of Biology, San Diego State University, United States; Department of Mathematics and Statistics, San Diego State University, United States},
	abstract = {Statistical predictive models play an important role in learning analytics. In this work, we seek to harness the power of predictive modeling methodology for the development of an analytics framework in STEM student success efficacy studies. We develop novel predictive analytics tools to provide stakeholders automated and timely information to assess student performance toward a student success outcome, and to inform pedagogical decisions or intervention strategies. In particular, we take advantage of the random forest machine learning algorithm, proposing a number of innovations to identify key input thresholds, quantify the impact of inputs on student success, evaluate student success at benchmarks in a program of study, and obtain a student success score. The proposed machinery can also tailor information for advisers to identify the risk levels of individual students in efforts to enhance STEM persistence and STEM graduation success. We additionally present our predictive analytics pipeline, motivated by and illustrated in a particular STEM student success study at San Diego State University. We highlight the process of designing, implementing, validating, and deploying analytical tools or dashboards, and emphasize the advantage of leveraging the utilities of both statistical analyses and business intelligence tools in order to maximize functionality and computational capacity. © 2018, © 2018 Taylor & Francis.},
	keywords = {Decision trees; Learning algorithms; Machine learning; Predictive analytics; Students; Analytic tools; Decision strategy; Forest machines; Intervention strategy; Modeling methodology; Power; Predictive models; Random forests; Student performance; Student success; Machinery},
	correspondence_address = {R.A. Levine; Analytics Studies and Institutional Research, San Diego State University, San Diego, United States; email: rlevine@mail.sdsu.edu},
	publisher = {Bellwether Publishing, Ltd.},
	issn = {08839514},
	coden = {AAINE},
	language = {English},
	abbrev_source_title = {Appl Artif Intell},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@ARTICLE{Teasley2017377,
	author = {Teasley, Stephanie D.},
	title = {Student Facing Dashboards: One Size Fits All?},
	year = {2017},
	journal = {Technology, Knowledge and Learning},
	volume = {22},
	number = {3},
	pages = {377 – 384},
	doi = {10.1007/s10758-017-9314-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018330175&doi=10.1007%2fs10758-017-9314-3&partnerID=40&md5=6b5fccb8bee2abdbd161c5f455f498d7},
	affiliations = {School of Information, University of Michigan, Ann Arbor, MI, United States},
	abstract = {This emerging technology report reviews a new development in educational technology, student-facing dashboards, which provide comparative performance feedback to students calculated by Learning Analytics-based algorithms on data generated from university students’ use of educational technology. Instructor- and advisor-facing dashboards emerged as one of the first direct applications of Learning Analytics, but the results from early implementations of these displays for students provide mixed results about the effects of their use. In particular, the “one-size-fits-all” design of many existing systems is questioned based on findings in related research on performance feedback and student motivation which has shown that various internal and external student-level factors affect the impact of feedback interventions, especially those using social comparisons. Integrating data from student information systems into underlying algorithms to produce personalized dashboards may mediate the possible negative effects of feedback, especially comparative feedback, and support more consistent benefits from the use of such systems. © 2017, Springer Science+Business Media Dordrecht.},
	author_keywords = {Dashboards; Higher education; Learning Analytics; Motivation; Performance feedback; Social comparison},
	keywords = {Education; Educational technology; Engineering education; Facings; Motivation; Dashboards; Higher education; Learning Analytics; Performance feedback; Social comparison; Students},
	correspondence_address = {S.D. Teasley; School of Information, University of Michigan, Ann Arbor, United States; email: steasley@umich.edu},
	publisher = {Springer Netherlands},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 115}
}

@ARTICLE{Huang2018442,
	author = {Huang, Lingyun and Bodnar, Stephen and Zheng, Juan and Kazemitabar, Maedeh Assadat and Chen, Yuxin and Birk, Gurpreet and Hmelo-Silver, Cindy E. and Lajoie, Susanne P.},
	title = {The design of a learning analytics pedagogical dashboard to enhance instructors’ facilitation in an online asynchronous problem-based learning environment},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10858 LNCS},
	pages = {442 – 445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048339422&partnerID=40&md5=e02de26797b330324278451bb7b2e76c},
	affiliations = {McGill University, Montreal, H3A 1Y2, Canada; Indiana University Bloomington, Bloomington, 47405-1006, IN, United States},
	abstract = {Problem-based learning (PBL) refers to small group collaborative learning situations where students solve complex problems with the assistance of teachers who serve as facilitators. Scaling PBL using technology requires specific tools since online asynchronous PBL can increase the number of small groups that engage in the curriculum but poses challenges to PBL teachers who must attend to multiple groups. To address the problem, we have been researching how technology can be used to develop specific tools to extend expert teachers’ instructional capacities. Building on previous work, we present the most recent design of a pedagogical dashboard used in an online asynchronous PBL environment. We illustrate how the new pedagogical dashboard visualizations can support PBL instructors observing individual student learning activities, diagnosing group dynamics and intervening when necessary. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {Learning analytics; Pedagogical dashboard; Visualizations Online asynchronous PBL},
	keywords = {Computer aided instruction; Curricula; E-learning; Intelligent vehicle highway systems; Problem solving; Visualization; Collaborative learning; Complex problems; Group dynamics; Learning analytics; Multiple-group; Pedagogical dashboard; Problem based learning; Student learning; Teaching},
	correspondence_address = {L. Huang; McGill University, Montreal, H3A 1Y2, Canada; email: lingyun.huang@mail.mcgill.ca},
	editor = {Vassileva J. and Nkambou R. and Azevedo R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331991463-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Avila2017183,
	author = {Avila, Cecilia and Fabregat, Ramon and Baldiris, Silvia and Graf, Sabine},
	title = {ATCE - An analytics tool to trace the creation and evaluation of inclusive and accessible open educational resources},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {183 – 187},
	doi = {10.1145/3027385.3027413},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016515727&doi=10.1145%2f3027385.3027413&partnerID=40&md5=f340f0ae05825c56e7fe46b937b09301},
	affiliations = {Institute of Informatics and Applications, University of Girona, Spain; Innovation and Social Projection, Fundación Universitaria Tecnológico Comfenalco, Colombia; School of Computing and Information Systems, Athabasca University, Canada},
	abstract = {The creation of Inclusive and Accessible Open Educational Resources (IA-OERs) is a challenge for teachers because they have to invest time and effort to create learning contents considering students' learning needs and preferences. An IA-OER is characterized by its alignment with the Universal Design Learning (UDL) principles, the quality on its contents and the web accessibility as a way to address the diversity of students. Creating an IA-OER with these characteristics is not a straightforward task, especially when teachers do not have enough information/feedback to make decisions on how to improve the learning contents. In this paper we introduce ATCE - an Analytics Tool to Trace the Creation and Evaluation of IA-OERs. This tool focuses in particular on the accessibility and quality of the IA-OERs. ATCE was developed as a module within the ATutor Learning Management System (LMS). An analytics dashboard with visualizations related to the teachers' competences in the creation and evaluation of IA-OERs was included as part of the tool. This paper also presents a use case of the visualizations obtained from the creation and evaluation of one IA-OER after using our analytics tool. © 2017 ACM.},
	author_keywords = {Competences; Learning analytics; Open Educational Resources; Quality; Teachers; Web accessibility},
	keywords = {Image quality; Students; Teaching; Transportation; Visualization; Web crawler; Websites; Competences; Learning analytics; Open educational resources; Teachers; Web accessibility; Education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Peña2019,
	author = {Peña, M. and Bravo, F. and Illescas-Peña, L.},
	title = {Learning analytics, dashboard for academic trajectory; [Analítica del aprendizaje, visualización de trayectoria académica]},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2425},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070859460&partnerID=40&md5=d757afbd177a3dbb32168d9392d597f7},
	affiliations = {Universidad de Cuenca, Facultad de Ciencias Químicas, Ecuador; Universidad de Cuenca, Facultad de Filosofía, Ecuador},
	abstract = {In the context of university academic management, several proposals have been developed for the study of analysis and visualization of learning trajectories. Bearing in mind that the educational trajectory is the trajectory of the student traveled at a given time from entry to the end of the stay, it can be considered that the use of technology could extract or highlight relevant information that is not seen directly with the tools traditional The visualization of data in educational environments has become a challenge due to the large amounts of information available. The responsibilities of educational administrators require a clear visual proposal adapted to queries based on an academic context. Therefore, it was proposed to generate a tool that generates dashboard based on relevant variables of the students. To do this, the proposal began with a review of the literature that helped analyze the different ways of visualizing the data of academic trajectories. Subsequently, a dynamic visualization was formulated to explain the teachers and authorities through the learning analysis panel, based on the use of parallel coordinates that present multidimensional data over time. The sample was constituted by records of 1975 students of an Ecuadorian university, of the cohort that began in March 2013, distributed by faculties and careers. The technique used allowed us to discover trends and relationships between dimensions, improving the understanding of the trajectory patterns of students, the trends of school dropout, either increase or decrease performance, among other relationships. The consultations allowed to filter data by variables such as: faculties, careers, students and intervals of scores. Finally, the validation of the proposal was made based on the relevance of the dashboard, in response to the inquiries of the academic manager. © 2019 CEUR-WS. All rights reserved.},
	keywords = {Data visualization; Mica; Trajectories; Visualization; Academic managements; Dynamic visualization; Educational administrators; Educational environment; Learning trajectories; Multidimensional data; Parallel coordinates; Trajectory pattern; Students},
	editor = {Scheihing E. and Guerra J. and Henriquez V. and Olivares C. and Munoz-Merino P.J.},
	publisher = {CEUR-WS},
	issn = {16130073},
	isbn = {978-841682938-5},
	language = {Spanish},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chalvatza2019339,
	author = {Chalvatza, Filothei and Karkalas, Sokratis and Mavrikis, Manolis},
	title = {Communicating learning analytics: Stakeholder participation and early stage requirement analysis},
	year = {2019},
	journal = {CSEDU 2019 - Proceedings of the 11th International Conference on Computer Supported Education},
	volume = {2},
	pages = {339 – 346},
	doi = {10.5220/0007716503390346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067109887&doi=10.5220%2f0007716503390346&partnerID=40&md5=314eecebb7bf2a6bb9215fb552cd7da6},
	affiliations = {Technology, Research and Experimentation Ltd, Hertfordshire, United Kingdom; UCL Knowledge Lab, London, United Kingdom},
	abstract = {This paper reflects on a user-centered design methodology for requirements elicitation at early stages of a design process for Learning Analytics tools. This methodology may be used as a domain specific instrument to elicit user perspectives about the communicational aspects of learning analytics dashboards. The focus of this work is identifying ways to communicate the data analysis findings in a way that is easily perceptible and facilitates actionable decision making. We present the structure as well as the logic behind the design of this instrument. As a case study, the paper describes an implementation of this methodology in the context of school-wide analytics communicating to stakeholders quality indicators through summarising and visualising data collected through student and parent surveys. We provide high-level and transferable recommendations derived from the analysis of the workshop with key stakeholders and identify future improvements in our methodology. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Educational stakeholders; Learning analytics dashboard design; Requirements elicitation},
	keywords = {Decision making; Learning systems; Requirements engineering; User centered design; Domain specific; Educational stakeholders; Future improvements; Quality indicators; Requirement analysis; Requirements elicitation; Stakeholder participation; User perspectives; E-learning},
	editor = {Lane H. and Zvacek S. and Uhomoibhi J.},
	publisher = {SciTePress},
	isbn = {978-989758367-4},
	language = {English},
	abbrev_source_title = {CSEDU - Proc. Int. Conf. Comput. Support. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Manolis201733,
	author = {Manolis, Mavrikis and Karkalas, Sokratis},
	title = {Reflective analytics for interactive e-books},
	year = {2017},
	journal = {Interaction Design and Architecture(s)},
	number = {33},
	pages = {33 – 53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033796765&partnerID=40&md5=ebe601837596b1898add1d9b57f0a12e},
	affiliations = {UCL Knowledge Lab University College London, United Kingdom},
	abstract = {This paper presents an analytics platform that has been developed for designers and teachers who build and use interactive e-books for learning. The analytics dashboard aims to increase awareness of the use of the e-books so that designers (and teachers in their role as designers) can make informed decisions on how to redesign and improve them taking into account both the overall learning design and the data from their usage. This paper presents architectural and design decisions on key features of the dashboard, and the evaluation of a high-fidelity prototype. We discuss findings related to use of the dashboard for exploratory data analysis and inquiry and how these generalise and can be taken into account by our future work or that of others.},
	author_keywords = {Analytics for designers; Constructionist data analytics; Learning analytics architecture},
	correspondence_address = {M. Manolis; UCL Knowledge Lab University College London, United Kingdom; email: m.mavrikis@ucl.ac.uk},
	publisher = {Scuola Iad},
	issn = {18269745},
	language = {English},
	abbrev_source_title = {Interact. Des. Architecture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Le2018239,
	author = {Le, Christopher V. and Pardos, Zachary A. and Meyer, Samuel D. and Thorp, Rachel},
	title = {Communication at scale in a MOOC using predictive engagement analytics},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10947 LNAI},
	pages = {239 – 252},
	doi = {10.1007/978-3-319-93843-1_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049379391&doi=10.1007%2f978-3-319-93843-1_18&partnerID=40&md5=293dea39062d0a6479476175ee620047},
	affiliations = {University of California at Berkeley, Berkeley, 94720, CA, United States},
	abstract = {When teaching at scale in the physical classroom or online classroom of a MOOC, the scarce resource of personal instructor communication becomes a differentiating factor between the quality of learning experience available in smaller classrooms. In this paper, through real-time predictive modeling of engagement analytics, we augment a MOOC platform with personalized communication affordances, allowing the instructional staff to direct communication to learners based on individual predictions of three engagement analytics. The three model analytics are the current probability of earning a certificate, of submitting enough materials to pass the class, and of leaving the class and not returning. We engineer an interactive analytics interface in edX which is populated with real-time predictive analytics from a backend API service. The instructor can target messages to, for example, all learners who are predicted to complete all materials but not pass the class. Our approach utilizes the state-of-the-art in recurrent neural network classification, evaluated on a MOOC dataset of 20 courses and deployed in one. We provide evaluation of these courses, comparing a manual feature engineering approach to an automatic feature learning approach using neural networks. Our provided code for the front-end and back-end allows any instructional team to add this personalized communication dashboard to their edX course granted they have access to the historical clickstream data from a previous offering of the course, their course’s daily provided log data, and an external machine to run the model service API. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {Drop-out prediction; edX; Engagement; Instructor communication; Learning analytics; MOOCs; Representation learning; User-interface},
	keywords = {Application programming interfaces (API); Classification (of information); Energy dispersive spectroscopy; Recurrent neural networks; Teaching; User interfaces; Drop-out; Engagement; Learning analytics; MOOCs; Representation learning; Predictive analytics},
	correspondence_address = {Z.A. Pardos; University of California at Berkeley, Berkeley, 94720, United States; email: zp@berkeley.edu},
	editor = {Mavrikis M. and Penstein Rosé C. and McLaren B. and Hoppe H.U. and Luckin R. and Porayska-Pomsta K. and du Boulay B. and Martinez-Maldonado R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331993842-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Millecamp201856,
	author = {Millecamp, Martijn and Gutiérrez, Francisco and Charleer, Sven and Verbert, Katrien and De Laet, Tinne},
	title = {A qualitative evaluation of a learning dashboard to support advisor-Student dialogues},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {56 – 60},
	doi = {10.1145/3170358.3170417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045909036&doi=10.1145%2f3170358.3170417&partnerID=40&md5=f334d33ad1dd3f466caf7fdbf30d64fc},
	affiliations = {KU Leuven, Department of Computer Science, Leuven, Belgium; KU Leuven Tutorial services, Faculty of Engineering Science, Leuven, Belgium},
	abstract = {This paper presents an evaluation of a learning dashboard that supports the dialogue between a student and a study advisor. The dashboard was designed, developed, and evaluated in collaboration with study advisers. To ensure scalability to other contexts, the dashboard uses data that is commonly available at any higher education institute. It visualizes the grades of the student, an overview of the progress through the year, his/her position in comparison with peers, sliders to plan the next years and a prediction of the length of the bachelor program for this student in years based on historic data. The dashboard was deployed at KU Leuven, Belgium and used in September 2017 to support 224 sessions between students and study advisers. We observed twenty of these conversations. We also collected feedback from 101 students with questionnaires. Results of our observations indicate that the dashboard primarily triggers insights at the beginning of a conversation. The number of insights and the level of these insights (factual, interpretative and reflective) depends on the context of the conversation. Most insights were triggered in conversations with students doubting to continue the program, indicating that our dashboard is useful to support difficult decision-making processes. © 2018 Association for Computing Machinery.},
	author_keywords = {Information visualization; Insights; Learning analytics dashboards; Learning technologies},
	keywords = {Decision making; Information systems; Surveys; Bachelor programs; Decision making process; Higher education; Information visualization; Insights; Learning analytics; Learning technology; Qualitative evaluations; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Green Open Access}
}

@ARTICLE{Rienties2017279,
	author = {Rienties, Bart and Cross, Simon and Marsh, Vicky and Ullmann, Thomas},
	title = {Making sense of learner and learning Big Data: reviewing five years of Data Wrangling at the Open University UK},
	year = {2017},
	journal = {Open Learning},
	volume = {32},
	number = {3},
	pages = {279 – 293},
	doi = {10.1080/02680513.2017.1348291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025162576&doi=10.1080%2f02680513.2017.1348291&partnerID=40&md5=0b61f9be3a9c1862691fd2d0893a7b40},
	affiliations = {Institute of Educational Technology, Open University UK, Milton Keynes, United Kingdom},
	abstract = {Most distance learning institutions collect vast amounts of learning data. Making sense of this ‘Big Data’ can be a challenge, in particular when data are stored at different data warehouses and require advanced statistical skills to interpret complex patterns of data. As a leading institute on learning analytics, the Open University UK instigated in 2012 a Data Wrangling initiative. This provided every Faculty with a dedicated academic with expertise data analysis and whose task is to provide strategic, pedagogical and sense-making advice to staff and senior management. Given substantial changes within the OU (e.g. new Faculty structure, real-time dashboards, two large-scale adoptions of predictive analytics approaches, increased reliance on analytics), this embedded case study provides an in-depth review of lessons learned of five years of data wrangling. We will elaborate on the design of the new structure, its strengths and potential weaknesses, and affordances to be adopted by other institutions. © 2017 The Open University.},
	author_keywords = {Big Data; data wranglers; Learning analytics; qualitative research},
	correspondence_address = {B. Rienties; Institute of Educational Technology, Open University UK, Milton Keynes, United Kingdom; email: bart.rienties@open.ac.uk},
	publisher = {Routledge},
	issn = {02680513},
	language = {English},
	abbrev_source_title = {Open Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Rodrigues201952,
	author = {Rodrigues, Rodrigo Lins and Ramos, Jorge Luis Cavalcanti and Silva, João Carlos Sedraz and Dourado, Raphael A. and Gomes, Alex Sandro},
	title = {Forecasting students' performance through self-regulated learning behavioral analysis},
	year = {2019},
	journal = {International Journal of Distance Education Technologies},
	volume = {17},
	number = {3},
	pages = {52 – 74},
	doi = {10.4018/IJDET.2019070104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065707989&doi=10.4018%2fIJDET.2019070104&partnerID=40&md5=e4ad9efef74685fdd2bc25a4bdd026c9},
	affiliations = {Universidade Federal Rural de Pernambuco, Recife, Brazil; Universidade Federal Do Vale Do São Francisco, Petrolina, Brazil; Universidade Federal de Pernambuco, Recife, Brazil},
	abstract = {The increasing use of the Learning Management Systems (LMSs) is making available an ever-growing, volume of data from interactions between teachers and students. This study aimed to develop a model capable of predicting students' academic performance based on indicators of their self-regulated behavior in LMSs. To accomplish this goal, the authors analyzed behavioral data from an LMS platform used in a public University for distance learning courses, collected during a period of seven years. With this data, they developed, evaluated, and compared predictive models using four algorithms: Decision Tree (CART), Logistic Regression, SVM, and Naïve Bayes. The Logistic Regression model yielded the best results in predicting students' academic performance, being able to do so with an accuracy rate of 0.893 and an area under the ROC curve of 0.9574. Finally, they conceived and implemented a dashboard-like interface intended to present the predictions in a user-friendly way to tutors and teachers, so they could use it as a tool to help monitor their students' learning process. Copyright © 2019, IGI Global.},
	author_keywords = {Educational Data Mining; Learning Analytics; Learning Management Systems; Learning Systems; Self-regulated Learning},
	keywords = {Data mining; Decision trees; Distance education; Forecasting; Learning systems; Regression analysis; Students; Trees (mathematics); Area under the ROC curve; Distance learning course; Educational data mining; Learning Analytics; Learning management system; Logistic Regression modeling; Logistic regressions; Self-regulated learning; Information management},
	publisher = {IGI Global},
	issn = {15393100},
	language = {English},
	abbrev_source_title = {Int. J. Distance Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Bodily2017309,
	author = {Bodily, Robert and Verbert, Katrien},
	title = {Trends and issues in student-facing learning analytics reporting systems research},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {309 – 318},
	doi = {10.1145/3027385.3027403},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016515187&doi=10.1145%2f3027385.3027403&partnerID=40&md5=f20ccbdbdaaf2c699f01125869e8c4ec},
	affiliations = {Brigham Young University, United States; University of Leuven, Belgium},
	abstract = {We conducted a literature review on systems that track learning analytics data (e.g., resource use, time spent, assessment data, etc.) and provide a report back to students in the form of visualizations, feedback, or recommendations. This review included a rigorous article search process; 945 articles were identified in the initial search. After filtering out articles that did not meet the inclusion criteria, 94 articles were included in the final analysis. Articles were coded on five categories chosen based on previous work done in this area: functionality, data sources, design analysis, perceived effects, and actual effects. The purpose of this review is to identify trends in the current studentfacing learning analytics reporting system literature and provide recommendations for learning analytics researchers and practitioners for future work. © 2017 ACM.},
	author_keywords = {Educational recommender systems; Learning analytics; Learning analytics dashboards; Literature review; Student-facing systems},
	keywords = {Facings; Data-sources; Design Analysis; Learning analytics; Literature reviews; Reporting systems; Resource use; Search process; Time spent; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 121; All Open Access, Green Open Access}
}

@CONFERENCE{Narendranath2018,
	author = {Narendranath, Aneet Dharmavaram},
	title = {Raspberry Pi based learning center usage tracking system for optimal resource allocation},
	year = {2018},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	volume = {2018-October},
	doi = {10.1109/FIE.2018.8659225},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063490769&doi=10.1109%2fFIE.2018.8659225&partnerID=40&md5=c6c235d518fdac31f8f5f50541063bea},
	affiliations = {Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, United States},
	abstract = {The objective of this 'work-in-progress' paper is to describe a Raspberry Pi based learning center management system that assists in deciding resource allocation for a peer-instruction driven engineering tutoring center. Data gathered from the usage of the engineering tutoring center allows for cost-effective staffing through recognition of the center's usage trends. The data collected may be structured per the center administrator's requirements and presented real-time on dashboards. The flexibility of this Raspberry Pi system allows for it to be developed into a full fledged learning management system with integrated analytics as required for a particular curriculum. This system is highly cost-effective as compared a commercial web-based system. This prototype has saved approximately 12 hours a month of time, for data retrieval and analysis as compared to a previously used commercial web-based system. At the moment, this Raspberry Pi data tracking system has been installed only in a single tutoring center on-campus. Deployment of this across a university campus would allow accumulated usage trends to be examined through data analysis operations such as seasonality and trend decomposition. © 2018 IEEE.},
	author_keywords = {Discipline Specific Issues: Data Science and/or Data Engineering; Discipline Specific Issues: Information Technology; Primary Topics: Computer-Based Learning and Courseware Technologies. Secondary Topics: Learning Analytics},
	keywords = {Cost effectiveness; Cost engineering; E-learning; Engineering education; Learning systems; Resource allocation; Websites; Computer-based learning; Courseware; Data engineering; Discipline specific issue: data science and/or data engineering; Discipline specific issue: information technology; Learning center; Primary topic: computer-based learning and courseware technology.; Science and engineering; Science-data; Secondary topic: learning analytic; Search engines},
	correspondence_address = {A.D. Narendranath; Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, United States; email: dnaneet@mtu.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {978-153861173-9},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Broos201851,
	author = {Broos, Tom and Verbert, Katrien and Langie, Greet and Van Soom, Carolien and De Laet, Tinne},
	title = {Multi-Institutional positioning test feedback dashboard for aspiring students lessons learnt from a case study in flanders},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {51 – 55},
	doi = {10.1145/3170358.3170419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045918416&doi=10.1145%2f3170358.3170419&partnerID=40&md5=46a2f8e102a0761d88daf3f8bd4418d8},
	affiliations = {KU Leuven, Department of Computer Science, Leuven, Belgium; KU Leuven, Leuven Engineering and Science Education Centre, Leuven, Belgium},
	abstract = {Our work focuses on a multi-institutional implementation and evaluation of a Learning Analytics Dashboards (LAD) at scale, providing feedback to N=337 aspiring STEM (science, technology, engineering and mathematics) students participating in a region-wide positioning test before entering the study program. Study advisors were closely involved in the design and evaluation of the dashboard. The multi-institutional context of our case study requires careful consideration of external stakeholders and data ownership and portability issues, which gives shape to the technical design of the LAD. Our approach confirms students as active agents with data ownership, using an anonymous feedback code to access the LAD and to enable students to share their data with institutions at their discretion. Other distinguishing features of the LAD are the support for active content contribution by study advisors and LATEX typesetting of question item feedback to enhance visual recognizability. We present our lessons learnt from a first iteration in production. © 2018 Association for Computing Machinery.},
	author_keywords = {Case study; Feedback; Higher education; Learning analytics; Positioning test; Student dashboard},
	keywords = {Feedback; Software testing; Students; Active content; Data ownership; Design and evaluations; External stakeholders; Higher education; Institutional contexts; Learning analytics; Technical design; Engineering education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@CONFERENCE{Villarroel2018,
	author = {Villarroel, Rodolfo and Villalobos, Cristian and Merino, Erick and Barcelos, Thiago and Munoz, Roberto},
	title = {Developing a Dashboard to Support the Analysis of Multimodal Educational Data},
	year = {2018},
	journal = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
	volume = {2018-November},
	doi = {10.1109/SCCC.2018.8705240},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065748334&doi=10.1109%2fSCCC.2018.8705240&partnerID=40&md5=868c3be1b8df5bfaf95ff757aaf7baff},
	affiliations = {Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile; Escuela de Ingeniería Civil Informática, Universidad de Valparaíso, Valparaíso, Chile; Laboratório de Computação Aplicada, Instituto Federal de Educação, Ciência e Tecnologia de São Paulo, Brazil},
	abstract = {Learning analytics consists of gathering and analyzing data from students in order to understand complex aspects of the learning process and promote its improvement. Currently, there is a lack of tools that allow the visualization of multimodal data. In this paper, we present a visualizer that allows analyzing the data provided by a multimodal learning analytics software. The multimodal data visualizer, in addition to allowing to visualize 10 body postures, permits applying clustering techniques, such as k-means. As validation, we analyze the data provided of 43 engineering student presentations. © 2018 IEEE.},
	author_keywords = {dashboard; kinect; multimodal learning analytics; oral presentations},
	keywords = {Data visualization; K-means clustering; Body postures; Clustering techniques; dashboard; kinect; Learning process; Multi-modal data; Multi-modal learning; Oral presentations; Modal analysis},
	publisher = {IEEE Computer Society},
	issn = {15224902},
	isbn = {978-153869233-2},
	language = {Spanish},
	abbrev_source_title = {Proc. Int. Conf. Chilean Comput. Sci. Soc. SCCC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Collado-Gómez201815,
	author = {Collado-Gómez, Cristina and Alario-Hoyos, Carlos and Santín-Cristóbal, David and Cruz-Argudo, Francisco and Kloos, Carlos Delgado},
	title = {Learning Analytics dashboard to work the Flipped Classroom methodology through the reuse of MOOCs; [Tablero Learning Analytics para trabajar la metodologia Flipped Classroom mediante la reutilización de MOOCs]},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2224},
	pages = {15 – 24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055490406&partnerID=40&md5=f6d67160213383cd2df4cf651ea4ae71},
	affiliations = {Servicio de Informática y Comunicaciones, Spain; Departamento de Ingenieriá Telemática, Universidad Carlos III de Madrid, Av. Universidad, 30, Leganés, 28911, Spain},
	abstract = {That a student can be aware, in real time, of his/her performance is essential to promote participation in a course and the implementation of flipped classroom strategies. This work presents a preliminary work on the development of a Learning Analytics dashboard for the Open edX platform to support MOOCs (Massive Open Online Courses) and SPOCs (Small Private Online Courses) at Universidad Carlos III de Madrid. The new design tries to motivate students, showing them information about the results and statistics they are obtaining in a course. In addition, the student gets information about his/her progress with respect to the peers. After asking users their opinion on the new Learning Analytics dashboard, the answers received are mostly positive, also receiving suggestions and opinions on possible improvements that the system could have in the future. © 2018 CEUR-WS. All rights reserved.},
	keywords = {Curricula; Students; Teaching; Flipped classrooms; Learning analytics; Massive open online course; Online course; Real time; E-learning},
	editor = {Rizzardini R.H. and Universidad Galileo, 4A Calle 7a. Avenida, calle Dr. Eduardo Suger Cofino, Ciudad de Guatemala and Gutl C. and Graz University of Technology, Rechbauerstrasse 12, Graz and Jerez O. and Universidad de Chile, Facultad de Economia y Negocios, Periodista Jose Carrasco Tapia No 75, Santiago and Roman M. and Universidad Panamericana, Diagonal 34, 3143 Zona 16, Ciudad de Guatemala and Ramirez-Gonzalez G. and Luna T. and Catolica del Norte Fundacion Universitaria, Calle 52 No 47 - 42, Edificio Coltejer, Piso 5, Medellin and Universidad Carlos III de Madrid, Departmento de Ingenieria Telematica, Avda de la Universidad 30, Leganes and Alario-Hoyos C. and Teixeira A.M. and Universidade Aberta, Rua da Escola Politecnica, Lisboa and Kloos C.D. and Universidad Carlos III de Madrid, Departmento de Ingenieria Telematica, Avda de la Universidad 30, Leganes and Mira J.F. and Catolica del Norte Fundacion Universitaria, Calle 52 No 47 - 42, Edificio Coltejer, Piso 5, Medellin},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {Spanish},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Alonso-Fernandez20171111,
	author = {Alonso-Fernandez, Cristina and Calvo, Antonio and Freire, Manuel and Martinez-Ortiz, Ivan and Fernandez-Manjon, Baltasar},
	title = {Systematizing game learning analytics for serious games},
	year = {2017},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	pages = {1111 – 1118},
	doi = {10.1109/EDUCON.2017.7942988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023601917&doi=10.1109%2fEDUCON.2017.7942988&partnerID=40&md5=d1416c81d75874a274bc49aaed22d1c7},
	affiliations = {Dept. Software Engineering and Artificial Intelligence, Universidad Complutense de Madrid, Facultad de Informática, C/Profesor JoseGarciaSantesmases, 9, Madrid, 28040, Spain},
	abstract = {Applying games in education provides multiple benefits clearly visible in entertainment games: their engaging, goal-oriented nature encourages students to improve while they play. Educational games, also known as Serious Games (SGs) are video games designed with a main purpose other than pure entertainment; their main purpose may be to teach, to change an attitude or behavior, or to create awareness of a certain issue. As educators and game developers, the validity and effectiveness of these games towards their defined educational purposes needs to be both measurable and measured. Fortunately, the highly interactive nature of games makes the application of Learning Analytics (LA) perfect to capture students' interaction data with the purpose of better understanding or improving the learning process. However, there is a lack of widely adopted standards to communicate information between games and their tracking modules. Game Learning Analytics (GLA) combines the educational goals of LA with technologies that are commonplace in Game Analytics (GA), and also suffers from a lack of standards adoption that would facilitate its use across different SGs. In this paper, we describe two key steps towards the systematization of GLA: 1), the use of a newly-proposed standard tracking model to exchange information between the SG and the analytics platform, allowing reusable tracker components to be developed for each game engine or development platform; and 2), the use of standardized analysis and visualization assets to provide general but useful information for any SG that sends its data in the aforementioned format. These analysis and visualizations can be further customized and adapted for particular games when needed. We examine the use of this complete standard model in the GLA system currently under development for use in two EU H2020 SG projects. © 2017 IEEE.},
	author_keywords = {Dashboard; E-learning; Game analytics; Serious games; XAPI},
	keywords = {Computer software reusability; Data visualization; E-learning; Education; Education computing; Engineering education; Human computer interaction; Standardization; Students; Visualization; Dashboard; Development platform; Educational game; Educational goals; Game analytics; Learning process; Standards adoptions; XAPI; Serious games},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-150905467-1},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 56; All Open Access, Green Open Access}
}

@CONFERENCE{Mouaici2018,
	author = {Mouaici, Mohamed and Vignollet, Laurence and Galez, Christine and Etienne, Mael},
	title = {Learning analytics dashboards for professional training - Challenges and proposal},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060116824&partnerID=40&md5=81c1c98ebcf19b5f69ddb9fb3fdc61c6},
	affiliations = {Savoie Mont Blanc University, France; Logipro company, France},
	abstract = {Exploiting the large quantities of traces left by learners in Virtual Learning Environments (VLE) allows educators, learners and administrators to gain new insights into the learning process. Learning Analytics (LA) aims to leverage data collection, measurement, analysis and reporting data which can help users to improve the learning process. This paper presents the first results of the work we are conducting in a professional learning context to design an effective learning analytics dashboard. We show the particularities and explain the different challenges of our context that have led us to propose models to tackle it. We discuss how these models meet the requirements of our domain, and we finally give an example of indicators, measures and visualization built with educators to help them better understand the learner’s behavior. © 2018 CEUR-WS. All Rights Reserved.},
	author_keywords = {Challenges; Indicators; Information Visualization; Learning Analytics; Measures; Models; Professional Training},
	keywords = {Computer aided instruction; Indicators (instruments); Information systems; Models; Personnel training; Professional aspects; Visualization; Challenges; Information visualization; Learning analytics; Measures; Professional training; Learning systems},
	editor = {Dirckinck-Holmfeld L. and Glahn C.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Fessl2018,
	author = {Fessl, Angela and Kowald, Dominik and Sola, Susana López and Moreno, Ana and Maturana, Ricardo Alonso and Thalmann, Stefan},
	title = {Analytics for everyday learning from two perspectives: Knowledge workers and teachers},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2209},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055709477&partnerID=40&md5=ba633b3497d028fcd3e9dc1287d8f3b9},
	affiliations = {Know-Center, Inffeldgasse 13, Graz, 8010, Austria; Institute of Interactive Systems and Data Science, Graz University of Technology, Austria; GNOSS - Riamintelearning Lab S.L., Piqueras 3-4th Floor, Logroño-LaRioja, 26006, Spain},
	abstract = {Learning analytics deals with tools and methods for analyzing and detecting patterns in order to support learners while learning in formal as well as informal learning settings. In this work, we present the results of two focus groups in which the effects of a learning resource recommender system and a dashboard based on analytics for everyday learning were discussed from two perspectives: (1) knowledge workers as self-regulated everyday learners (i.e., informal learning) and (2) teachers who serve as instructors for learners (i.e., formal learning). Our findings show that the advantages of analytics for everyday learning are three-fold: (1) it can enhance the motivation to learn, (2) it can make learning easier and broadens the scope of learning, and (3) it helps to organize and to systematize everyday learning. © 2018 CEUR-WS. All rights reserved.},
	author_keywords = {Focus group; Formal learning; Informal learning; Learning analytics; Recommender systems},
	keywords = {Knowledge management; Recommender systems; Teaching; Focus groups; Formal learning; Informal learning; Knowledge workers; Learning analytics; Learning resource; Three folds; Tools and methods; Learning systems},
	editor = {Fessl A. and Thalmann S. and d'Aquin M. and Holtz P. and Dietze S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gelan2018294,
	author = {Gelan, Anouk and Fastré, Greet and Verjans, Martine and Martin, Niels and Janssenswillen, Gert and Creemers, Mathijs and Lieben, Jonas and Depaire, Benoît and Thomas, Michael},
	title = {Affordances and limitations of learning analytics for computer-assisted language learning: a case study of the VITAL project},
	year = {2018},
	journal = {Computer Assisted Language Learning},
	volume = {31},
	number = {3},
	pages = {294 – 319},
	doi = {10.1080/09588221.2017.1418382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040966621&doi=10.1080%2f09588221.2017.1418382&partnerID=40&md5=43571bb0b1a7dde0662a6f681a9765c8},
	affiliations = {Hasselt University–Center Applied Linguistics, Hasselt, Belgium; Hasselt University–Specific Teacher Education, Hasselt, Belgium; Hasselt University–Business Informatics, Hasselt, Belgium; School of Language and Global Studies, University of Central Lancashire, Preston, United Kingdom},
	abstract = {Learning analytics (LA) has emerged as a field that offers promising new ways to prevent drop-out and aid retention. However, other research suggests that large datasets of learner activity can be used to understand online learning behaviour and improve pedagogy. While the use of LA in language learning has received little attention to date, available research suggests that LA could provide valuable insights into task design for instructors and materials designers, as well as help students with effective learning strategies and personalised learning pathways. This paper first discusses previous CALL research based on learner tracking and specific affordances of LA for CALL, as well as its inherent limitations and challenges. The second part of the paper analyses data arising from the VITAL project that implemented LA in different blended or distance learning settings. Statistical and process-mining techniques were applied to data from 285 undergraduate students on a Business French course. Results suggested that most students planned their self-study sessions in accordance with the flipped classroom design. Other metrics measuring active online engagement indicated significant differences between successful and non-successful students’ learner patterns. The research implied that valuable insights can be acquired through LA and the use of visualisation and process-mining tools. © 2018 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Blended learning; flipped learning; learning analytics; learning dashboards; learning patterns; self-regulated learning; tracking data},
	correspondence_address = {A. Gelan; Hasselt University–Center Applied Linguistics, Hasselt, Belgium; email: anouk.gelan@uhasselt.be},
	publisher = {Routledge},
	issn = {09588221},
	coden = {CALLE},
	language = {English},
	abbrev_source_title = {Comput. Assisted Lang. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42; All Open Access, Green Open Access}
}

@CONFERENCE{Haro-Valle2018,
	author = {Haro-Valle, Valeria and Benlloch-Dualde, José-V. and Lemus-Zúñiga, Lenin Y Maldonado-Mahauad and Jorge, J.},
	title = {Designing dashboards for students and instructors in a Sakai supported face-To-face learning environment},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055445702&partnerID=40&md5=9463653d053e4debc6d5a43d847b5503},
	affiliations = {Universitat Politècnica de València, Valencia, 46022, Spain; Universidad de Cuenca, Ecuador, Colombia},
	abstract = {A very recent review of the literature in the field of Visual Learning Analytics states that the use of these techniques is quite frequent in blended learning or online learning environments, including MOOCs. However, this is not the case in classroom learning environments. In this context, the paper aims at studying how using Visual Learning Analytics can contribute to a better understanding of the educational processes in face-To-face educational contexts, supported by a Sakai-based Virtual Learning Environment. Considering that the institutional platform reports are only available for teachers, the main objective is the design and implementation of a learning dashboard that could help students in their learning process. To accomplish that, it should integrate data from different sources, generating easy to understand visual representations. Additionally, the same data sources will be used to develop a dashboard for instructors that could help them to provide formative feedback to their students, or to improve the teaching materials they use. In order to create the dashboards, visualization tools such as Tableau and QlikSense have been initially employed. However, it was decided to use the Java script library D3.js, as it allows us to create any imaginable visualization and because of the interactivity it offers. To conclude, some preliminary results are discussed, and further research is outlined. © 2018 CEUR-WS. All rights reserved.},
	author_keywords = {Face-To-Face Learning Environment; Learning Dashboard; Sakai.; Visual Learning Analytics},
	keywords = {E-learning; Students; Teaching; Visualization; Design and implementations; Face-to-face learning; Learning Dashboard; Online learning environment; Sakai; Virtual learning environments; Visual learning; Visual representations; Computer aided instruction},
	editor = {del Mar Perez Sanagustin M. and Ochoa X.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {Spanish},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Viswanathan2019327,
	author = {Viswanathan, Sree Aurovindh and Vanlehn, Kurt},
	title = {Detection of collaboration: Relationship between log and speech-based classification},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11626 LNAI},
	pages = {327 – 331},
	doi = {10.1007/978-3-030-23207-8_60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068325563&doi=10.1007%2f978-3-030-23207-8_60&partnerID=40&md5=d67361acc67043315cace5e165258799},
	affiliations = {Arizona State University, AZ, United States},
	abstract = {Research in the field of collaboration shows that students do not spontaneously collaborate with each other. A system that can measure collaboration in real time could be useful by, for example, helping the teacher locate a group requiring guidance. To address this challenge, my research focuses on building and comparing collaboration detectors for different types of classroom problem solving activities, such as card sorting and hand writing. I am also studying transfer: how collaboration detectors for one task can be used with a new task. Finally, we attempt to build a teachers dashboard that can describe reasoning behind the triggered alerts thereby helping the teachers with insights to aid the collaborative activity. Data for building such detectors were collected in the form of verbal interaction and user action logs from students’ tablets. Three qualitative levels of interactivity was distinguished: Collaboration, Cooperation and Asymmetric Contribution. Machine learning was used to induce a classifier that can assign a code for every episode based on the set of features. Our preliminary results indicate that machine learned classifiers were reliable. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Collaborative learning; Learning analytics; Machine learning},
	keywords = {Learning systems; Machine learning; Students; Card-sorting; Collaborative activities; Collaborative learning; Hand writing; Interactivity; Learning analytics; Research focus; Verbal interaction; Problem solving},
	correspondence_address = {S.A. Viswanathan; Arizona State University, United States; email: sviswa10@asu.edu},
	editor = {Isotani S. and Millán E. and Ogan A. and McLaren B. and Hastings P. and Luckin R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303023206-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Howell20188,
	author = {Howell, Joel A. and Roberts, Lynne D. and Mancini, Vincent O.},
	title = {Learning analytics messages: Impact of grade, sender, comparative information and message style on student affect and academic resilience},
	year = {2018},
	journal = {Computers in Human Behavior},
	volume = {89},
	pages = {8 – 15},
	doi = {10.1016/j.chb.2018.07.021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053082842&doi=10.1016%2fj.chb.2018.07.021&partnerID=40&md5=95e1fdd8cb0e9044b595ed613d3ca733},
	affiliations = {School of Psychology, Curtin University, Perth, WA, Australia},
	abstract = {Learning analytics enable automated feedback to students through dashboards, reports and alerts. The underlying untested assumption is that providing analytics will be sufficient to improve self-regulated learning. Working within a feedback recipience framework, we begin to test this assumption by examining the impact of learning analytics messages on student affect and academic resilience. Three hundred and twenty undergraduate students completed an online survey and were exposed to three randomly assigned learning analytics alerts (High Distinction, Pass, and Fail grades). Multivariate analyses of variance indicated significant differences between grade levels (large effects), with higher positive affect and lower resilience in response to High Distinction alerts than Pass or Fail alerts. Within each hypothetical grade level, there were no differences in student affect and academic resilience. Based upon systematic changes in feedback sender, message style or whether comparative peer achievement was included or not. These findings indicate that grade level has the largest impact on both affect and academic resilience. The failure of message and sender characteristics to impact on activities that promote self-regulated learning suggests we need to look beyond these characteristics of individual messages to identify drivers of engaging students in self-regulated learning. © 2018 Elsevier Ltd},
	author_keywords = {Academic resilience; Educational technology; Feedback; Feedback recipience; Learning analytics},
	keywords = {Educational technology; Feedback; Multivariant analysis; Academic resilience; Automated feedback; Engaging students; Learning analytics; Multi variate analysis; Self-regulated learning; Systematic changes; Undergraduate students; achievement; article; controlled study; driver; educational technology; human; human experiment; learning; major clinical study; multivariate analysis of variance; randomized controlled trial; undergraduate student; Students},
	correspondence_address = {J.A. Howell; School of Psychology, Curtin University, Perth, GPO Box U1987, 6845, Australia; email: joel.howell@curtin.edu.au},
	publisher = {Elsevier Ltd},
	issn = {07475632},
	coden = {CHBEE},
	language = {English},
	abbrev_source_title = {Comput. Hum. Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37}
}

@ARTICLE{Alonso-Fernández2019287,
	author = {Alonso-Fernández, Cristina and Pérez-Colado, Iván and Freire, Manuel and Martínez-Ortiz, Iván and Fernández-Manjón, Baltasar},
	title = {Improving serious games analyzing learning analytics data: Lessons learned},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11385 LNCS},
	pages = {287 – 296},
	doi = {10.1007/978-3-030-11548-7_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061359934&doi=10.1007%2f978-3-030-11548-7_27&partnerID=40&md5=6b51427a409d077fb97c98f004a3b111},
	affiliations = {Facultad de Informática, Complutense University of Madrid, C/Profesor José García Santesmases 9, Madrid, 28040, Spain},
	abstract = {Serious games adoption is increasing, although their penetration in formal education is still surprisingly low. To improve their outcomes and increase their adoption in this domain, we propose new ways in which serious games can leverage the information extracted from player interactions, beyond the usual post-activity analysis. We focus on the use of: (1) open data which can be shared for research purposes, (2) real-time feedback for teachers that apply games in schools, to maintain awareness and control of their classroom, and (3) once enough data is gathered, data mining to improve game design, evaluation and deployment; and allow teachers and students to benefit from enhanced feedback or stealth assessment. Having developed and tested a game learning analytics platform throughout multiple experiments, we describe the lessons that we have learnt when analyzing learning analytics data in the previous contexts to improve serious games. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Dashboards; Game-based learning; Learning analytics; Serious games; Stealth assessment},
	keywords = {Data mining; Feedback; Open Data; Students; Activity analysis; Dashboards; Formal education; Game-based Learning; Learning analytics; Real-time feedback; Research purpose; Stealth assessment; Serious games},
	correspondence_address = {C. Alonso-Fernández; Facultad de Informática, Complutense University of Madrid, Madrid, C/Profesor José García Santesmases 9, 28040, Spain; email: crisal03@ucm.es},
	editor = {Söbke H. and Gentile M. and Allegra M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303011547-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{2018,
	title = {CEUR Workshop Proceedings},
	year = {2018},
	journal = {CEUR Workshop Proceedings},
	volume = {2294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062754173&partnerID=40&md5=8e6c527c9817409e2b93130e9f595515},
	abstract = {The proceedings contain 11 papers. The topics discussed include: a data mining framework for analyzing students' feedback of assessment; MULTIFOCUS: multimodal learning analytics for co-located collaboration understanding and support; implementation and evaluation of a trusted learning analytics dashboard; learning analytics dashboards for professional training - challenges and proposal; identification of role models in online communities of practice; application of participatory design in designing infrastructures for learning in resource limiting environments; inferring knowledge acquisition through web navigation behaviors; and contextualized instruction in data science and its effect on transfer of learning.},
	editor = {Dirckinck-Holmfeld L. and Glahn C.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Broos2018399,
	author = {Broos, Tom and Verbert, Katrien and Langie, Greet and Van Soom, Carolien and De Laet, Tinne},
	title = {Low-Investment, Realistic-Return Business Cases for Learning Analytics Dashboards: Leveraging Usage Data and Microinteractions},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11082 LNCS},
	pages = {399 – 405},
	doi = {10.1007/978-3-319-98572-5_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053203702&doi=10.1007%2f978-3-319-98572-5_30&partnerID=40&md5=98fdfc85b9010946be07a1199abc6f83},
	affiliations = {Catholic University of Leuven, Leuven, Belgium},
	abstract = {In recent years, Learning Analytics (LA) is finding more and more practical adoption, alongside of continued research interest. However, questions about the impact of LA applications and their underpinning in educational science are still being raised, impeding viability of some LA projects at larger scale. Within this paper we describe two examples using student-facing LA dashboards (LAD) deployed at scale at a relatively low cost. Leveraging data collected by the dashboards themselves, usage data (N = 4070 students) and in-dashboard microinteractions (N = 367 students), we try to put the impact question in perspective. We suggest that when investment is kept limited, a business case with modest but realistic expatiations of returns may be feasible. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Business case; Learning analytics; Learning analytics dashboards; Microinteractions; Realistics expectations; Usage data},
	keywords = {Students; Business case; Learning analytics; Microinteractions; Realistics expectations; Usage data; Engineering education},
	correspondence_address = {T. Broos; Catholic University of Leuven, Leuven, Belgium; email: tom.broos@kuleuven.be},
	editor = {Elferink R. and Drachsler H. and Pammer-Schindler V. and Perez-Sanagustin M. and Scheffel M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331998571-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lumbantoruan20174472,
	author = {Lumbantoruan, Rosni and Sitorus, Ridho and Siagian, Niko and Elsa, Corry},
	title = {Formative assessment and learning analytics in informatics diploma program},
	year = {2017},
	journal = {Advanced Science Letters},
	volume = {23},
	number = {5},
	pages = {4472 – 4477},
	doi = {10.1166/asl.2017.8859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023745577&doi=10.1166%2fasl.2017.8859&partnerID=40&md5=acc86bb42657f9ff162c89d131aedbd4},
	affiliations = {Del Institute of Technology, Information System Faculty, Toba Samosir, Indonesia},
	abstract = {Learning analytics is a process to analyze the learners and teachers which improves the educational performance such as ameliorating educational practices and techniques. Analyzes are performed to formative assessment data of learning process. This paper provides models for formative assessment of Informatics Engineering Institute which delivers both practical and theory session. The assessment models is based on current research activities in an existing Informatics Diploma program and aims to track each student’s performance during study and support for decision making for both students and teachers for preventive action for risky not performed students or for learning improvement. To help decision making, the analysis result of the assessment will be displayed in dashboard of learning management system. © 2017 American Scientific Publishers All rights reserved.},
	author_keywords = {Dashboard; Formative assessment; Informatics diploma program; Learning analytics},
	publisher = {American Scientific Publishers},
	issn = {19366612},
	language = {English},
	abbrev_source_title = {Adv. Sci. Lett.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Schumacher2018397,
	author = {Schumacher, Clara and Ifenthaler, Dirk},
	title = {Features students really expect from learning analytics},
	year = {2018},
	journal = {Computers in Human Behavior},
	volume = {78},
	pages = {397 – 407},
	doi = {10.1016/j.chb.2017.06.030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023619557&doi=10.1016%2fj.chb.2017.06.030&partnerID=40&md5=89c268c75461353f365ff40b8983bde0},
	affiliations = {University of Mannheim, L4, 1, Mannheim, 68131, Germany; University of Mannheim and Curtin University, L4, 1, Mannheim, 68131, Germany},
	abstract = {More and more learning in higher education settings is being facilitated through online learning environments. Students' ability to self-regulate their learning is considered a key factor for success in higher education. Learning analytics offer a promising approach to better support and understand students' learning processes. The purpose of this study is to investigate students' expectations towards features of learning analytics systems and their willingness to use these features for learning. A total of 20 university students participated in an initial qualitative exploratory study. They were interviewed about their expectations of learning analytics features. The findings of the qualitative study were complemented by a quantitative study with 216 participating students. The findings show that students expect learning analytics features to support their planning and organization of learning processes, provide self-assessments, deliver adaptive recommendations, and produce personalized analyses of their learning activities. © 2017 Elsevier Ltd},
	author_keywords = {Dashboard; Feature; Learning analytics; Self-regulated learning},
	keywords = {Computer aided instruction; Students; Dashboard; Exploratory studies; Feature; Learning analytics; Online learning environment; Quantitative study; Self-regulated learning; University students; expectation; exploratory research; human; learning; major clinical study; qualitative research; quantitative study; self evaluation; university student; Education},
	correspondence_address = {C. Schumacher; University of Mannheim, Mannheim, L4, 1, 68131, Germany; email: clara.schumacher@bwl.uni-mannheim.de},
	publisher = {Elsevier Ltd},
	issn = {07475632},
	coden = {CHBEE},
	language = {English},
	abbrev_source_title = {Comput. Hum. Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 230}
}

@ARTICLE{Roberts2017317,
	author = {Roberts, Lynne D. and Howell, Joel A. and Seaman, Kristen},
	title = {Give Me a Customizable Dashboard: Personalized Learning Analytics Dashboards in Higher Education},
	year = {2017},
	journal = {Technology, Knowledge and Learning},
	volume = {22},
	number = {3},
	pages = {317 – 333},
	doi = {10.1007/s10758-017-9316-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020708155&doi=10.1007%2fs10758-017-9316-1&partnerID=40&md5=c40241e82a0306b71ecd8b09aa5dc11c},
	affiliations = {School of Psychology and Speech Pathology, Curtin University, GPO Box U1987, Perth, 6845, WA, Australia; Faculty of Health Sciences, Curtin University, Perth, WA, Australia},
	abstract = {With the increased capability of learning analytics in higher education, more institutions are developing or implementing student dashboards. Despite the emergence of dashboards as an easy way to present data to students, students have had limited involvement in the dashboard development process. As part of a larger program of research examining student and academic perceptions of learning analytics, we report here on work in progress exploring student perceptions of dashboards and student preferences for dashboard features. First, we present findings on higher education students’ attitudes towards learning analytic dashboards resulting from four focus groups (N = 41). Thematic analysis of the focus group transcripts identified five key themes relating to dashboards: ‘provide everyone with the same learning opportunities’, ‘to compare or not to compare’, ‘dashboard privacy’, ‘automate alerts’ and ‘make it meaningful—give me a customizable dashboard’. Next we present findings from a content analysis of students’ drawings of dashboards demonstrating that students are interested in features that support learning opportunities, provide comparisons to peers and are meaningful to the student. Finally, we present preliminary findings from a survey of higher education students, reinforcing students’ desire to choose whether to have a dashboard and to be able to customize their dashboards. These findings highlight the potential for providing students with some level of control over learning analytics as a means to increasing self-regulated learning and academic achievement. Future research directions aimed at better understanding students emotional and behavioral responses to learning analytics feedback on dashboards and alerts are outlined. © 2017, Springer Science+Business Media B.V.},
	author_keywords = {Big data; Higher education; Learning analytics; Student attitudes; Student dashboards},
	keywords = {Big data; Education; Academic achievements; Future research directions; Higher education; Higher education students; Learning analytics; Personalized learning; Self-regulated learning; Student attitudes; Students},
	correspondence_address = {L.D. Roberts; School of Psychology and Speech Pathology, Curtin University, Perth, GPO Box U1987, 6845, Australia; email: Lynne.Roberts@curtin.edu.au},
	publisher = {Springer Netherlands},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 106}
}

@CONFERENCE{Nguyen201835,
	author = {Nguyen, Viet Anh and Nguyen, Quang Bach and Nguyen, Vuong Thinh},
	title = {A model to forecast learning outcomes for students in blended learning courses based on learning analytics},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {35 – 41},
	doi = {10.1145/3268808.3268827},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056736938&doi=10.1145%2f3268808.3268827&partnerID=40&md5=354a7e1de994f0d232d8babf7938e96c},
	affiliations = {VNU University of Engineering and Technology, E3, 144 Xuan Thuy, Cau Giay, Hanoi, Viet Nam; Vietnam Maritime University, 484 LachTray, NgoQuyen, Haiphong, China},
	abstract = {One of the difficulties experienced by online learners is the lack of regular supervision as well as the need to provide instructions to support the learning process more effectively. The analysis of the learning data in the online courses is not only becoming increasingly important in forecasting learning outcomes but also providing effective instructional strategies for learners to help them get the best results. In this paper, we propose a forecast learning outcomes model based on learners' interaction with online learning systems by providing learning analytics dashboard for both learners and teachers to monitor and orient online learners. This approach is mainly based on some machine learning and data mining techniques. This research aims to answer two research questions: (1) Is it possible to accurately predict learners' learning outcomes based on their interactive activities? (2) How to monitor and guide learners in an effective online learning environment? To answer these two questions, our model has been developed and tested by learners participating in the Moodle LMS system. The results show that 75% of students have outcomes close to the predicted results with an accuracy of over 50%. These positive results, though done on a small scale, can also be considered as suggestions for studies of using learning analytics in predicting learning outcomes of learners through learning activities. © 2018 Association for Computing Machinery.},
	author_keywords = {Forecast model; Learning activities; Learning analytics; Learning outcomes; Predictive modeling},
	keywords = {Computer aided instruction; Data mining; E-learning; Education computing; Forecasting; Online systems; Predictive analytics; Students; FORECAST model; Learning Activity; Learning analytics; Learning outcome; Predictive modeling; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036528-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@CONFERENCE{Gilliot2018119,
	author = {Gilliot, Jean-Marie and Iksal, Sébastien and Medou, Daniel Magloire and Dabbebi, Inès},
	title = {Participatory design of learning analytics dashboards; [Conception participative de tableaux de bord d'apprentissage]},
	year = {2018},
	journal = {IHM 2018 - Actes de la 30ieme Conference Francophone sur l''Interaction Homme-Machine},
	pages = {119 – 127},
	doi = {10.1145/3286689.3286693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062060475&doi=10.1145%2f3286689.3286693&partnerID=40&md5=5ad1d041cff15a63e8ad6f4096ea8028},
	affiliations = {Lab-STICC UMR 6285, IMT Atlantique Technopôle Brest-Iroise CS, Brest, 83818 29238, France; Le Mans Université, LIUM, Avenue Messiaen 72085, Le Mans, EA 4023, France},
	abstract = {While the field of Learning Analytics is in full development, potential users are just discovering the opportunities offered by these tools. One of the major difficulties consists in proposing a visual data representation which makes sense to the users. After refining our method to identify user needs in terms of visualization, and to define the main dimensions of a learning dashboard, we propose a tool to support participatory design. This tool is based on a canvas and cards to help dashboards' creation using Learning Analytics. It allows users to support creativity around decision making, characterize their context, and draw a dashboard's mockup using existing content. © 2018 Copyright held by the owner/author(s).},
	author_keywords = {Canvas; Dashboard; Learning Analytics; Participatory design},
	keywords = {Canvas; Dashboard; Learning Analytics; Participatory design; Potential users; User need; Visual data representation; Decision making},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035109-6},
	language = {French},
	abbrev_source_title = {IHM - Actes Conf. Francoph. Interact. Homme-Mach.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Cassano2019156,
	author = {Cassano, Fabio and Piccinno, Antonio and Roselli, Teresa and Rossano, Veronica},
	title = {Gamification and learning analytics to improve engagement in university courses},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {804},
	pages = {156 – 163},
	doi = {10.1007/978-3-319-98872-6_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057297090&doi=10.1007%2f978-3-319-98872-6_19&partnerID=40&md5=2e49ca8db70b68c8794e80cee7558b6a},
	affiliations = {Department of Computer Science, University of Bari, Bari, Italy},
	abstract = {Gamification is one of the most used techniques to improve active participation and engagement in different kinds of contexts. The use of game techniques is effective in pushing subjects to be involved in an activity. Since the early childhood, indeed, the promises of rewards are useful to affect specific behaviors. On the other hands, the learning analytics have been largely implemented in education in order to improve the assessment and the self-assessment of students, above all in e-learning settings. The research presented in this work aims at combining gamification techniques and learning analytics to improve the engagement in University courses. The paper describes a model of gamification and a learning dashboard defined based on data in Moodle e-learning platform. A pilot test of an app android in which both the solutions have been implemented pointed out promising results. © Springer Nature Switzerland AG 2019.},
	author_keywords = {E-learning engagement; Gamification; Learning analytics; Learning dashboard},
	keywords = {Education computing; Intelligent systems; E-learning platforms; Early childhoods; Gamification; Learning analytics; Learning dashboard; Pilot tests; Self assessment; University course; E-learning},
	correspondence_address = {F. Cassano; Department of Computer Science, University of Bari, Bari, Italy; email: fabio.cassano1@uniba.it},
	editor = {Vittorini P. and De la Prieta F. and Rodríguez S. and Popescu E. and Lancia L. and Gennari R. and Di Mascio T. and Silveira R.A. and Temperini M.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331998871-9},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Diana2017272,
	author = {Diana, Nicholas and Grover, Shuchi and Eagle, Michael and Bienkowski, Marie and Stamper, John and Basu, Satabdi},
	title = {An instructor dashboard for real-time analytics in interactive programming assignments},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {272 – 279},
	doi = {10.1145/3027385.3027441},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016475395&doi=10.1145%2f3027385.3027441&partnerID=40&md5=cfe41e65c873a67c9a7ecf257fb8dd0e},
	affiliations = {Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, 15213, PA, United States; SRI International, 333 Ravenswood Avenue, Menlo Park, 94025, CA, United States},
	abstract = {Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well. © 2017 ACM.},
	author_keywords = {Dashboards; Introductory programming; Learning analytics; Machine learning; Peer tutors},
	keywords = {Learning systems; Teaching; Dashboards; Introductory programming; Learning analytics; Peer tutors; Predictive models; Programming assignments; Real-time analytics; Student outcomes; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 51; All Open Access, Bronze Open Access}
}

@ARTICLE{Kuhnel2018332,
	author = {Kuhnel, Matthias and Seiler, Luisa and Honal, Andrea and Ifenthaler, Dirk},
	title = {Mobile learning analytics in higher education: usability testing and evaluation of an app prototype},
	year = {2018},
	journal = {Interactive Technology and Smart Education},
	volume = {15},
	number = {4},
	pages = {332 – 347},
	doi = {10.1108/ITSE-04-2018-0024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056486042&doi=10.1108%2fITSE-04-2018-0024&partnerID=40&md5=9360d791dde3ccfe268207697c09b345},
	affiliations = {Learning, Design and Technology, University of Mannheim, Mannheim, Germany; Cooperative State University Mannheim, Mannheim, Germany; UNESCO Deputy Chair of Data Science in Higher Education Learning and Teaching, Curtin University, Bentley, WA, Australia},
	abstract = {Purpose: The purpose of the study was to test the usability of the MyLA app prototype by its potential users. Furthermore, the Web app will be introduced in the framework of “Mobile Learning Analytics”, a cooperation project between the Cooperative State University Mannheim and University of Mannheim. The participating universities focus on the support of personalized and self-regulated learning. MyLA collects data such as learning behavior, as well as personality traits. Last but not least, the paper will contribute to the topic of learning analytics and mobile learning in higher education. Design/methodology: For the empirical investigation, a mixed-method design was chosen. While 105 participants took part in the conducted online survey, after testing the app prototype, seven students joined an additional eye tracking study. For the quantitative part, a selected question pool from HIMATT (highly integrated model assessment technology and tools) instrument was chosen. The eye tracking investigation consisted of three tasks the participants had to solve. Findings: The findings showed that the students assessed the idea of the app, as well as the navigation positively. Only the color scheme of the prototype was not very attractive to a noticeable amount of the participants. So, it requires slight modifications concerning the app design. For the eye tracking study, it can be stated that the students viewed the relevant parts, and they basically had no difficulties to solve the tasks. Originality/value: Due to the empirical testing of the app prototype, the project team was able to adjust the application and to add further features. Furthermore, the backend was programmed and an additional tool (MyLA dashboard) was developed for lecturers. A mutual understanding of the targets, privacy issue and relevant features are indispensable for further development of the project. © 2018, Matthias Kuhnel, Luisa Seiler, Andrea Honal and Dirk Ifenthaler.},
	author_keywords = {Electronic media; Higher education; Learning methods; Online applications; Research; User studies},
	correspondence_address = {M. Kuhnel; Learning, Design and Technology, University of Mannheim, Mannheim, Germany; email: kuhnel@bwl.uni-mannheim.de},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {17415659},
	language = {English},
	abbrev_source_title = {Interact. Technol. Smart Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Green Open Access}
}

@CONFERENCE{Bektik2018,
	author = {Bektik, Duygu},
	title = {XIPIt: Updating the XIP dashboard to support educators in essay marking at higher education},
	year = {2018},
	journal = {Proceedings of the 5th Annual ACM Conference on Learning at Scale, L at S 2018},
	doi = {10.1145/3231644.3231696},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051556449&doi=10.1145%2f3231644.3231696&partnerID=40&md5=f6290b0efd35f9fa3fc1ff5d0553c76c},
	affiliations = {Institute of Educational Technology, Open University, Milton Keynes, United Kingdom},
	abstract = {Effective written communication is an essential skill which promotes educational success for undergraduates. However, undergraduate students, especially those in their first year at university, are unused to this form of writing. After their long experience with the schoolroom essay, for most undergraduates academic writing development is painstakingly slow. Thus, especially those with poor writing abilities, should write more to be better writers. Yet, the biggest impediment to more writing is that overburdened tutors would ask limited number of drafts from their students. Today, there exist powerful computational language technologies that could evaluate student writing, saving time and providing timely, speedy, reliable feedback which can support educators marking process. This paper motivates an updated visual analytics dashboard, XIPIt, to introduce a set of visual and writing analytics features embedded in a marking environment built on XIP output. © 2017 Association for Computing Machinery. All rights reserved.},
	author_keywords = {Learning Analytics; Marking Interface; Undergraduate Writing.; Visual Dashboards; Writing Learning Analytics},
	keywords = {Academic writings; Computational languages; Learning analytics; Undergraduate students; Visual analytics; Visual Dashboards; Writing abilities; Written communications; Students},
	correspondence_address = {D. Bektik; Institute of Educational Technology, Open University, Milton Keynes, United Kingdom; email: duygu.bektik@open.ac.uk},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035886-6},
	language = {English},
	abbrev_source_title = {Proc. Annu. ACM Conf. Learn. Scale, L at S},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bodily2018572,
	author = {Bodily, Robert and Ikahihifo, Tarah K. and Mackley, Benjamin and Graham, Charles R.},
	title = {The design, development, and implementation of student-facing learning analytics dashboards},
	year = {2018},
	journal = {Journal of Computing in Higher Education},
	volume = {30},
	number = {3},
	pages = {572 – 598},
	doi = {10.1007/s12528-018-9186-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055318010&doi=10.1007%2fs12528-018-9186-0&partnerID=40&md5=e41a001727674aead048b1bde10b113e},
	affiliations = {Brigham Young University, 150 MCKB, Provo, 84602, UT, United States},
	abstract = {We have designed, developed, and implemented a student-facing learning analytics dashboard in order to support students as they learn in online environments. There are two separate dashboards in our system: a content recommender dashboard and a skills recommender dashboard. The content recommender helps students identify gaps in their content knowledge; the skills recommender helps students improve their metacognitive strategies. We discuss the technical requirements needed to develop a real-time student dashboard as well as report our inquiry into the functionality students want in a dashboard. The dashboards were evaluated with focus groups and a perceptions survey. Students were positive in their perceptions of the dashboards and 79% of the students that used the dashboards found them user-friendly, engaging, useful, and informative. One challenge encountered was low student use of the dashboard. Only 25% of students used the dashboard multiple times, despite favorable student perceptions of the dashboard. Additional research should examine how to motivate and support students to engage with dashboard feedback in online environments. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Dashboard; Data visualization; Iterative design; Learning analytics; Learning dashboards; Student reporting tools},
	correspondence_address = {R. Bodily; Brigham Young University, Provo, 150 MCKB, 84602, United States; email: bodilyrobert@gmail.com},
	publisher = {Springer Science and Business Media, LLC},
	issn = {10421726},
	language = {English},
	abbrev_source_title = {J. Comput. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 57}
}

@ARTICLE{Ndukwe20181,
	author = {Ndukwe, Ifeanyi G. and Daniel, Ben K. and Butson, Russell J.},
	title = {Data science approach for simulating educational data: Towards the development of teaching outcome model (TOM)},
	year = {2018},
	journal = {Big Data and Cognitive Computing},
	volume = {2},
	number = {3},
	pages = {1 – 18},
	doi = {10.3390/bdcc2030024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061971423&doi=10.3390%2fbdcc2030024&partnerID=40&md5=fa365aff1d9e4d537f5f5ffa6581739f},
	affiliations = {Educational Technology, Higher Education Development Centre, University of Otago, Dunedin, 9016, New Zealand},
	abstract = {The increasing availability of educational data provides the educational researcher with numerous opportunities to use analytics to extract useful knowledge to enhance teaching and learning. While learning analytics focuses on the collection and analysis of data about students and their learning contexts, teaching analytics focuses on the analysis of the design of the teaching environment and the quality of learning activities provided to students. In this article, we propose a data science approach that incorporates the analysis and delivery of data-driven solution to explore the role of teaching analytics, without compromising issues of privacy, by creating pseudocode that simulates data to help develop test cases of teaching activities. The outcome of this approach is intended to inform the development of a teaching outcome model (TOM), that can be used to inspire and inspect quality of teaching. The simulated approach reported in the research was accomplished through Splunk. Splunk is a Big Data platform designed to collect and analyse high volumes of machine-generated data and render results on a dashboard in real-time. We present the results as a series of visual dashboards illustrating patterns, trends and results in teaching performance. Our research aims to contribute to the development of an educational data science approach to support the culture of data-informed decision making in higher education. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Big data; Big data education; Dashboards; Data science; Student evaluation of teaching; Teaching analytics; Teaching output model; Teaching practice},
	keywords = {Data Science; Decision making; Education computing; Quality control; Students; Analysis of data; Big data education; Dashboard; Learning context; Student evaluation of teaching; Students' evaluations; Teaching analytics; Teaching and learning; Teaching output model; Teaching practices; Big data},
	correspondence_address = {I.G. Ndukwe; Educational Technology, Higher Education Development Centre, University of Otago, Dunedin, 9016, New Zealand; email: ifeanyigloryndukwe@gmail.com},
	publisher = {MDPI},
	issn = {25042289},
	language = {English},
	abbrev_source_title = {Big Data Cogn. Computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ines2019260,
	author = {Ines, Dabbebi and Jean-Marie, Gilliot and Sebastien, Iksal},
	title = {User centered approach for learning analytics dashboard generation},
	year = {2019},
	journal = {CSEDU 2019 - Proceedings of the 11th International Conference on Computer Supported Education},
	volume = {2},
	pages = {260 – 267},
	doi = {10.5220/0007693102600267},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067090846&doi=10.5220%2f0007693102600267&partnerID=40&md5=a8796f192a910e8f6b0227cddb86a0de},
	affiliations = {UBL, Le Mans University, LIUM Laboratory, Laval-LeMans, France; UBL, IMT Atlantique, Lab-STICC Laboratory, Brest, France},
	abstract = {The use of learning dashboards with analytics might help users to gain insight into their learning process and then to make decision. However, designing meaningful Learning Analytics dashboard (LAD) is still a complex process that requires an explicit understanding of the user needs. For this reason, we carried out a user-centered design (UCD) approach with the aim to provide users with adapted LADs to support their decision-making. Hence, we develop a UCD process composed of 4 steps: (i) we propose a participatory-based design tool for capturing contextualized needs (ii) these identified needs will be described using an independent formalism and LAD models in order to capitalize on them (iii) to automate these models, we propose a LAD generation process (iv) finally, we carried out an evaluation phase with the aim to review and refine our models. During our process development, an iterative user needs refinement confirmed that decision is considered as a centered element for LAD generations. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Business intelligence; Dashboard; Decision making; Generation process; Learning analytics},
	keywords = {Competitive intelligence; Decision making; User centered design; Complex Processes; Dashboard; Evaluation phase; Generation process; Learning analytics; Process development; User Centered Design(UCD); User-centered approach; E-learning},
	editor = {Lane H. and Zvacek S. and Uhomoibhi J.},
	publisher = {SciTePress},
	isbn = {978-989758367-4},
	language = {English},
	abbrev_source_title = {CSEDU - Proc. Int. Conf. Comput. Support. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Taibi2019268,
	author = {Taibi, Davide and Bianchi, Francesca and Kemkes, Philipp and Marenzi, Ivana},
	title = {A Learning Analytics Dashboard to Analyse Learning Activities in Interpreter Training Courses},
	year = {2019},
	journal = {Communications in Computer and Information Science},
	volume = {1022},
	pages = {268 – 286},
	doi = {10.1007/978-3-030-21151-6_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068333852&doi=10.1007%2f978-3-030-21151-6_14&partnerID=40&md5=942c8a41d901cb8178da9d841c80babb},
	affiliations = {Institute for Educational Technology, National Research Council of Italy, Palermo, Italy; University of Salento, Lecce, Italy; L3S Research Center, Hannover, Germany},
	abstract = {Learning analytics dashboards constitute an effective tool for monitoring learning activities that take place in online learning environments. Thanks to dashboards, teachers can promptly detect low levels of student engagement in given tasks, incorrect usage of a system, and other types of pedagogically relevant information, which helps them to better support students in achieving their learning objectives. This study describes the integration of a dashboard in an online learning system. The system includes a tool that guides students in the creation of highly informative bilingual glossaries, a service that traces student searches on the web for reference material, and a service that tracks student interactions with the glossary. The data thus collected are selectively displayed in the newly developed dashboard. The dashboard was specifically designed to allow teachers to monitor the students’ approaches to glossary building and to provide individual remedial feedback, if necessary. It was also intended to spur students to keep on a par with the rest of the class, by seeing their status compared to the rest of the class. The system was tested with two groups of university students specializing in interpreting, and two different teachers. The results of the experiments suggest that this integrated system manages to achieve its goals and provides students and teachers of interpreting with an innovative online tool that concretely fosters and supports vocabulary building. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Interpreting; Learning analytics dashboard; Tracking systems},
	keywords = {Computer aided instruction; Glossaries; Learning systems; Students; Interpreting; Learning analytics dashboard; Learning objectives; On-line learning systems; Online learning environment; Student interactions; Tracking system; Vocabulary building; E-learning},
	correspondence_address = {I. Marenzi; L3S Research Center, Hannover, Germany; email: marenzi@L3S.de},
	editor = {McLaren B.M. and Reilly R. and Zvacek S. and Uhomoibhi J.},
	publisher = {Springer Verlag},
	issn = {18650929},
	isbn = {978-303021150-9},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}@ARTICLE{Xhakaj2017315,
	author = {Xhakaj, Françeska and Aleven, Vincent and McLaren, Bruce M.},
	title = {Effects of a teacher dashboard for an intelligent tutoring system on teacher knowledge, lesson planning, lessons and student learning},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {315 – 329},
	doi = {10.1007/978-3-319-66610-5_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029579076&doi=10.1007%2f978-3-319-66610-5_23&partnerID=40&md5=2c3f0473295833ef4ba1ac0c177ff4e4},
	affiliations = {Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Intelligent Tutoring Systems (ITSs) help students learn but often are not designed to support teachers and their practices. A dashboard with analytics about students’ learning processes might help in this regard. However, little research has investigated how dashboards influence teacher practices in the classroom and whether they can help improve student learning. In this paper, we explore how Luna, a dashboard prototype designed for an ITS and used with real data, affects teachers and students. Results from a quasi-experimental classroom study with 5 middle school teachers and 17 classes show that Luna influences what teachers know about their students’ learning in the ITS and that the teachers’ updated knowledge affects the lesson plan they prepare, which in turn guides what they cover in a class session. Results did not confirm that Luna increased student learning. In summary, even though teachers generally know their classes well, a dashboard with analytics from an ITS can still enhance their knowledge about their students and support their classroom practices. The teachers tended to focus primarily on dashboard information about the challenges their students were experiencing. To the best of our knowledge, this is the first study that demonstrates that a dashboard for an ITS can affect teacher knowledge, decision-making and actions in the classroom. © Springer International Publishing AG 2017.},
	author_keywords = {Dashboard; Data-driven instruction; Intelligent tutoring systems; Learning analytics; Teachers’ use of data},
	keywords = {Computer aided instruction; Decision making; Education computing; Intelligent vehicle highway systems; Planning; Students; Teaching; Classroom practices; Dashboard; Data driven; Intelligent tutoring system; Intelligent tutoring system (ITSs); Learning analytics; Learning process; Teacher practices; Education},
	correspondence_address = {F. Xhakaj; Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, United States; email: francesx@cs.cmu.edu},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55}
}

@CONFERENCE{Jaakonmäki2017572,
	author = {Jaakonmäki, Roope and Dietze, Stefan and Drachsler, Hendrik and Fortenbacher, Albrecht and Kickmeier-Rust, Michael and Marenzi, Ivana},
	title = {Cooking with learning analytics recipes},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {572 – 573},
	doi = {10.1145/3027385.3029465},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016465866&doi=10.1145%2f3027385.3029465&partnerID=40&md5=17cf99943d3823d45e44075992a90490},
	affiliations = {University of Liechtenstein, Liechtenstein; University of Hannover, Germany; Open University of the Netherlands, Netherlands; HTW Berlin, Germany; TU Graz, Austria},
	abstract = {Learning Analytics is a melting pot for a multitude of research fields and origin of many developments about learning and its environment. There is a serious hype over the concepts of learning analytics, however, concrete solutions and applications are comparably scarce. Of course, data rich environments, such as MOOCs, come with statistical analytics dashboards, although the educational value is often limited. Practical solutions for scenarios in data-lean environments or for small-scale organizations are rarely adopted. The LA4S project is dedicated to gather practical solutions, provide a tool box for practitioners, and publish a cook book with concrete learning analytics recipes for everyone. © 2017 ACM.},
	author_keywords = {Applications; Cookbook; Learning Analytics; Recipes; Solutions},
	keywords = {Applications; Concretes; Solutions; Cookbook; Lean environments; Learning Analytics; Practical solutions; Recipes; Research fields; Small scale; Cooking},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Ifenthaler2016923,
	author = {Ifenthaler, Dirk and Schumacher, Clara},
	title = {Student perceptions of privacy principles for learning analytics},
	year = {2016},
	journal = {Educational Technology Research and Development},
	volume = {64},
	number = {5},
	pages = {923 – 938},
	doi = {10.1007/s11423-016-9477-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982290347&doi=10.1007%2fs11423-016-9477-y&partnerID=40&md5=546ca2b77d973144d90539d9b15f7f44},
	affiliations = {University of Mannheim, Mannheim, Baden-Württemberg, Germany; Deakin University, Melbourne, VIC, Australia},
	abstract = {The purpose of this study was to examine student perceptions of privacy principles related to learning analytics. Privacy issues for learning analytics include how personal data are collected and stored as well as how they are analyzed and presented to different stakeholders. A total of 330 university students participated in an exploratory study confronting them with learning analytics systems and associated issues of control over data and sharing of information. Findings indicate that students expect learning analytics systems to include elaborate adaptive and personalized dashboards. Further, students are rather conservative in sharing data for learning analytics systems. On the basis of the relationship between the acceptance and use of learning analytics systems and privacy principles, we conclude that all stakeholders need to be equally involved when learning analytics systems are implemented at higher education institutions. Further empirical research is needed to elucidate the conditions under which students are willing to share relevant data for learning analytics systems. © 2016, Association for Educational Communications and Technology.},
	author_keywords = {Control over data; Higher education; Learning analytics; Privacy; Transparency},
	correspondence_address = {D. Ifenthaler; University of Mannheim, Mannheim, Germany; email: dirk@ifenthaler.info},
	publisher = {Springer New York LLC},
	issn = {10421629},
	language = {English},
	abbrev_source_title = {Educ. Technol. Res. Dev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 169}
}

@ARTICLE{Zapparolli2017587,
	author = {Zapparolli, Luciana Silva and Stiubiener, Itana},
	title = {FAG - A management support tool with BI techniques to assist teachers in the virtual learning environment Moodle},
	year = {2017},
	journal = {Advances in Science, Technology and Engineering Systems},
	volume = {2},
	number = {3},
	pages = {587 – 597},
	doi = {10.25046/aj020375},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046095132&doi=10.25046%2faj020375&partnerID=40&md5=5d571ce2686c9b5c3b68bbc92198d96c},
	affiliations = {Faculdade de Tecnologia, Informática, Fatec Mauá e Zona sul, Brazil; Universidade Federal Do ABC, Centro de Matemática Computação e Cognição, UFABC, Brazil},
	abstract = {One of the great challenges in distance-learning is to follow the actions of the teachers/tutors and also the actions of students during the process of teaching and learning. This article presents the FAG Tool integrated with the LMS Moodle was developed to help managers of the Distance Education environment to monitor the actions of teachers/tutors and also teachers/tutors in the follow-up of student actions. Through the techniques of Business Intelligence (BI) and Learning Analytics (LA), the tool generates analytical reports and dashboards, presenting a holistic and transversal view, being this vision the differential of this tool. The use of FAG allows teachers/tutors to monitor the participation of all their students in all virtual rooms under their responsibility and thus take corrective measures in the teaching and learning process, such as reducing the risk of avoidance. For the managers, it can be considered as a support tool for decision making regarding the faculty, maintaining or not the teacher/tutor in the process of teaching and learning or even be a base to enlarge or reduce their classes depending on their performance in the virtual environment. Through the use of the FAG, this decision-making can happen during the teaching and learning process and not only after the end, as is usual, because the reports are easy to understand and present accurate information in time to ensure the success of the teaching and learning process. © 2017 ASTES Publishers. All rights reserved.},
	author_keywords = {Business Intelligence; Learning Analytics; Monitoring in virtual environments},
	correspondence_address = {L.S. Zapparolli; Fatec de Mauá e Zona Sul, Informática, Brazil; email: luciana.zapparolli@fatec.sp.gov.br},
	publisher = {ASTES Publishers},
	issn = {24156698},
	language = {English},
	abbrev_source_title = {Adv.  Sci., Technol.  Eng.  Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{Kim201613,
	author = {Kim, Jeonghyun and Jo, Il-Hyun and Park, Yeonjeong},
	title = {Effects of learning analytics dashboard: analyzing the relations among dashboard utilization, satisfaction, and learning achievement},
	year = {2016},
	journal = {Asia Pacific Education Review},
	volume = {17},
	number = {1},
	pages = {13 – 24},
	doi = {10.1007/s12564-015-9403-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959110982&doi=10.1007%2fs12564-015-9403-8&partnerID=40&md5=26941f4d7f9d341aaf93b863d3378a69},
	affiliations = {Ewha Womans University, Seoul, South Korea},
	abstract = {The learning analytics dashboard (LAD) is a newly developed learning support tool for virtual classrooms that is believed to allow students to review their online learning behavior patterns intuitively through the provision of visual information. The purpose of this study was to empirically validate the effects of LAD. An experimental study was conducted with a dashboard treatment group and a control group. The researchers developed a LAD and evaluated its effectiveness on the sample of 151 college students at a private university located in Korea, who were taking the online course titled “Management Statistics” in the first semester of 2014. The following results were obtained. First, the students who received dashboard treatment presented higher final score than those who did not. Second, the dashboard usage frequency, as measured by the number of times the dashboard was opened, did not have a significant impact on learning achievement. However, a slightly positive correlation between satisfaction with LAD and learning achievement was observed. Further analysis indicated that learners who used the dashboard only a few times showed relatively high satisfaction with LAD. On the other hand, high academic achievers who opened LAD relatively frequently showed lower satisfaction with dashboard. The results guide that LAD should be revised in a way to motivate learners consistently and support learners who have different academic achievement levels. The study discusses the further research tasks in terms of LAD development as an effective and personalized feedback tool to improve learners’ academic achievement. © 2015, Education Research Institute, Seoul National University, Seoul, Korea.},
	author_keywords = {Dashboard; Learning achievement; Learning analytics; Satisfaction},
	correspondence_address = {I.-H. Jo; Ewha Womans University, Seoul, South Korea; email: ijo@ewha.ac.kr},
	publisher = {Springer Netherlands},
	issn = {15981037},
	language = {English},
	abbrev_source_title = {Asia Pac. Educ. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 112}
}

@CONFERENCE{Pardos2015103,
	author = {Pardos, Zachary A. and Kao, Kevin},
	title = {MoocRP: An open-source analytics platform},
	year = {2015},
	journal = {L@S 2015 - 2nd ACM Conference on Learning at Scale},
	pages = {103 – 110},
	doi = {10.1145/2724660.2724683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928016588&doi=10.1145%2f2724660.2724683&partnerID=40&md5=af012908521b2bf0d5c328b566540740},
	affiliations = {School of Information/ School of Education, UC Berkeley, United States; EECS, UC Berkeley, United States},
	abstract = {In this paper, we address issues of transparency, modularity, and privacy with the introduction of an open source, web-based data repository and analysis tool tailored to the Massive Open Online Course community. The tool integrates data request/authorization and distribution workflows as well as a simple analytics module upload format to enable reuse and replication of analytics results among instructors and researchers. We survey the evolving landscape of competing data models, all of which can be accommodated in the platform. Data model descriptions are provided to analytics authors who choose, much like with smartphone app stores, to write for any number of data models depending on their needs and the proliferation of the particular data model. Two case study examples of analytics and interactive visualizations are described in the paper. The result is a simple but effective approach to learning analytics immediately applicable to X consortium institutions and beyond. Copyright © 2015 ACM.},
	author_keywords = {Dashboards; EdX; Modularization; MOOC; Open learning analytics; Reproducible research; Visualizations},
	keywords = {Energy dispersive spectroscopy; Modular construction; Dashboards; Modularizations; MOOC; Open learning; Reproducible research; Visualization},
	publisher = {Association for Computing Machinery},
	isbn = {978-145033411-2},
	language = {English},
	abbrev_source_title = {L@S - ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@CONFERENCE{Héctor201664,
	author = {Héctor, J. Pijeira-Díaz and Drachsler, Hendrik and Järvelä, Sanna and Kirschner, Paul A.},
	title = {Investigating collaborative learning success with physiological coupling indices based on electrodermal activity},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {64 – 73},
	doi = {10.1145/2883851.2883897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976477347&doi=10.1145%2f2883851.2883897&partnerID=40&md5=ab7ff4aeeeb6f339d449386ac98aacb3},
	affiliations = {University of Oulu Oulu, Finland; Welten Institute Heerlen, Netherlands},
	abstract = {Collaborative learning is considered a critical 21st century skill. Much is known about its contribution to learning, but still investigating a process of collaboration remains a challenge. This paper approaches the investigation on collaborative learning from a psychophysiological perspective. An experiment was set up to explore whether biosensors can play a role in analysing collaborative learning. On the one hand, we identified five physiological coupling indices (PCIs) found in the literature: 1) Signal Matching (SM), 2) Instantaneous Derivative Matching (IDM), 3) Directional Agreement (DA), 4) Pearson's correlation coeficient (PCC) and the 5) Fisher's z-transform (FZT) of the PCC. On the other hand, three collaborative learning measurements were used: 1) collaborative will (CW), 2) collaborative learning product (CLP) and 3) dual learning gain (DLG). Regression analyses showed that out of the five PCIs, IDM related the most to CW and was the best predictor of the CLP. Meanwhile, DA predicted DLG the best. These results play a role in determining informative collaboration measures for designing a learning analytics, biofeedback dashboard.},
	author_keywords = {Biosensors; Collaborative learning; Electrodermal activity; Learning analytics; Physiological coupling indices},
	keywords = {Biofeedback; Biosensors; Correlation methods; Electric fault currents; Electrodes; Regression analysis; Z transforms; Collaborative learning; Correlation coeficient; Coupling indices; Electrodermal activity; Learning analytics; Learning gain; Signal matching; Physiology},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 63}
}

@CONFERENCE{Corrigan2015165,
	author = {Corrigan, Owen and Glynn, Mark and McKenna, Aisling and Smeaton, Alan and Smyth, Sinead},
	title = {Student data: Data is knowledge: Putting the knowledge back in the students' hands},
	year = {2015},
	journal = {Proceedings of the European Conference on e-Learning, ECEL},
	pages = {165 – 172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977123234&partnerID=40&md5=025f10167cdb97865979a201f304136a},
	affiliations = {Dublin City University, Ireland},
	abstract = {Learning Management Systems are integral technologies within higher education institutions. These tools automatically amass large amounts of log data relating to student activities. The field of learning analytics uses data from learning management systems (LMSs) and student information systems to track student progress and predict future performance in order to enhance learning environments (Siemens, 2011). The aim of this paper is to describe a project where we utilized a system developed in Dublin City University to use information about student engagement with our LMS, Moodle, to create a model predicting pass or failure in certain modules. The project is divided into three distinct phases. An initial investigation was completed analyzing Moodle activity for the last six years. The purpose of this exercise was to determine automatically if "trends" could be identified linking Moodle engagement with student attainment. This was done by training a machine learning classifier to map student online behaviour, against outcomes. Once the classifier was trained, several modules were identified as suitable for building a predictor of student exam success.Ten modules were identified for semester 1 with a further seven identified for semester 2. The second phase involved analyzing current students' engagement with these modules and sending students information about the predictions of their attainment for the module, based on their Moodle engagement. At this stage concerns were raised within the university that the data that we share with the students could actually have the opposite effect to what we are after, i.e. the student may look at the data and think that there is no point in putting in more effort as 'I'm too far behind already'. Dietz-Uhler and Hurn refer to this as "instead of being a constructive tool, feedback becomes a prophet of failure" (Dietz-Uhler, 2013). This contention was addressed by conducting an online survey with students in an effort to explore their experiences of being provided with feedback regarding their engagement with the LMS. The third and final phase of this project was the development of a dashboard for lecturers to enable monitoring of their students' engagement with their module on Moodle. This enables lecturers to have an overview of how students are engaging with their course on Moodle and quickly identify students who are not engaging with the LMS and who are potentially at risk of failure or non-completion. There are numerous examples of the use of learning analytics in higher education. This study focuses on the provision of data obtained through learning analytics to the student and qualitative analysis that was conducted in relation to this data. This research adds to the existing research into learning analytics being used for student retention.},
	author_keywords = {Data-mining; Learner; Learning analytics; Student-retention; VLE},
	keywords = {Artificial intelligence; Computer aided instruction; Data mining; E-learning; Education; Education computing; Information management; Learning systems; Teaching; Dublin City University; Higher education institutions; Integral technologies; Learner; Learning analytics; Learning management system; Student retention; Students' engagements; Students},
	editor = {Cubric M. and Jefferies A.},
	publisher = {Academic Conferences Limited},
	issn = {20488637},
	isbn = {978-191081071-2; 978-191081072-9},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. e-Learn., ECEL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Jonathan2017457,
	author = {Jonathan, Christin and Tan, Jennifer Pei-Ling and Koh, Elizabeth and Caleon, Imelda and Tay, Siu Hua},
	title = {Enhancing students' critical reading fluency, engagement and self-efficacy using self-referenced learning analytics dashboard visualizations},
	year = {2017},
	journal = {Proceedings of the 25th International Conference on Computers in Education, ICCE 2017 - Main Conference Proceedings},
	pages = {457 – 462},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053887611&partnerID=40&md5=e1deb4a6798c3467820822dcc13ac875},
	affiliations = {National Institute of Education, Nanyang Technological University, Singapore; Educational Technology Division, Ministry of Education, Singapore},
	abstract = {Although learning analytics (LA) dashboard visualizations are increasingly being used to provide feedback to students, literature on the effectiveness of LA dashboards has been inconclusive. To address this, a LA student dashboard visualizing students' latest data against their own data from previous weeks (i.e., self-referenced data) was designed - informed by Fredrickson's (2004) broaden-and-build theory, as well as studies highlighting personal best goals (Martin & Elliot, 2016) and the negative effects of peer comparisons (Corrin & de Barba, 2014). The self-referenced LA student dashboard was implemented and evaluated in a Singapore Secondary school as part of a larger study, WiREAD. This paper reports on the quantitative impact of the WiREAD self-referenced LA dashboard visualizations on 15-year-old students' critical reading fluency, cognitive reading engagement, and English language (EL) self-efficacy, as well as students' qualitative feedback on the usefulness and shortcomings of the LA dashboard. © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.},
	author_keywords = {Critical reading skills; English language; Learning Analytics; Student dashboards},
	keywords = {Visualization; English languages; Feedback to students; Learning analytics; Qualitative feedback; Reading skills; Secondary schools; Self efficacy; Self-referenced; Students},
	editor = {Mohd Ayub A.F. and Mitrovic A. and Yang J.-C. and Wong S.L. and Chen W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986940126-5},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Comput. Educ., ICCE - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Roberto2016124,
	author = {Roberto, Martinez-Maldonado and Schneider, Bertrand and Charleer, Sven and Shum, Simon Buckingham and Klerkx, Joris and Duval, Erik},
	title = {Interactive surfaces and learning analytics: Data, orchestration aspects, pedagogical uses and challenges},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {124 – 133},
	doi = {10.1145/2883851.2883873},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976499259&doi=10.1145%2f2883851.2883873&partnerID=40&md5=0edc2356fec5702f573e09119b06b354},
	affiliations = {University of Technology, Sydney, Australia; Stanford University, United States; KU Leuven, Belgium},
	abstract = {The proliferation of varied types of multi-user interactive surfaces (such as digital whiteboards, tabletops and tangible interfaces) is opening a new range of applications in face-to-face (f2f) contexts. They offer unique opportunities for Learning Analytics (LA) by facilitating multi-user sensemaking of automatically captured digital footprints of students' f2f interactions. This paper presents an analysis of current research exploring learning analytics associated with the use of surface devices. We use a framework to analyse our first-hand experiences, and the small number of related deployments according to four dimensions: The orchestration aspects involved; the phases of the pedagogical practice that are supported; the target actors; and the levels of iteration of the LA process. The contribution of the paper is twofold: 1) a synthesis of conclusions that identify the degree of maturity, challenges and pedagogical opportunities of the existing applications of learning analytics and interactive surfaces; and 2) an analysis framework that can be used to characterise the design space of similar areas and LA applications. © 2016 ACM.},
	author_keywords = {Awareness; Dashboard; Design; Design; Face-to-face; Groupware; Studies in the wild; Visualisations},
	keywords = {Design; Groupware; Visualization; Analysis frameworks; Awareness; Dashboard; Face to face; Interactive surfaces; Pedagogical practices; Studies in the wild; Tangible interfaces; Education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Green Open Access}
}

@CONFERENCE{Holstein201614,
	author = {Holstein, Kenneth and Xhakaj, Franceska and Aleven, Vincent and McLaren, Bruce},
	title = {Luna: A dashboard for teachers using Intelligent Tutoring Systems},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1738},
	pages = {14 – 18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006324109&partnerID=40&md5=d56fbb1eb6c220b87acbddadbd507fc0},
	affiliations = {Human-Computer Interaction Institute, Carnegie Mellon University, United States},
	abstract = {Intelligent Tutoring Systems (ITS) generate a wealth of finegrained student interaction data. Although it seems likely that teachers could benefit from access to advanced analytics generated from these data, ITSs do not typically come with dashboards designed for teachers' needs. In this project, we follow a user-centered design approach to create a dashboard for teachers using ITSs.},
	author_keywords = {Blended learning; Dashboards; Intelligent Tutoring Systems; Learning analytics; Student modeling; User-centered design},
	keywords = {Computer aided instruction; Education; Intelligent vehicle highway systems; User centered design; Blended learning; Dashboards; Intelligent tutoring system; Learning analytics; Student Modeling; Teaching},
	editor = {Bull S. and Ginon B. and Vatrapu R. and Kickmeier-Rust M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vigentini201720,
	author = {Vigentini, Lorenzo and Clayphan, Andrew and Chitsaz, Mahsa},
	title = {Dynamic dashboard for educators and students in FutureLearn MOOCs: Experiences and insights},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1967},
	pages = {20 – 35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034963101&partnerID=40&md5=b3b389c284b0dd35d0665d17c096d6cd},
	affiliations = {UNSW Sydney Australia, Office of Pro-Vice Chancellor (Education), Australia; UNSW Sydney Australia, School of Education, Australia; School of Computer Science and Engineering, Australia},
	abstract = {One of the differentiating aspects of the FutureLearn platform, compared with other MOOC providers such as Coursera and EdX, is the approach to data sharing with partners. This is grounded on the release of a small set of relatively simple source files, which can be downloaded and used as required by end users (e.g. educators, researchers and so on). This approach has both advantages and disadvantages. The major advantage is the simplicity; the most important drawback is the lack of an 'out-of-the-box' set of analytical representations which the end-user can use and digest to obtain immediate insights regarding their online course. In this paper, we discuss these aspects in more detail and document the approach adopted at UNSW Sydney, to use the data as released, and how we produced a set of analytical dashboards for educators and students. The architecture underpinning the dashboards built is explained with a link to a GitHub repository with more detailed information. Copyright © 2017 for the individual papers by the papers' authors.},
	author_keywords = {FutureLearn; Learning analytics; MOOCs; Visualization dashboard},
	keywords = {Data Sharing; End users; FutureLearn; Learning analytics; MOOCs; Online course; Source files; Education},
	correspondence_address = {L. Vigentini; UNSW Sydney Australia, Office of Pro-Vice Chancellor (Education), Australia; email: l.vigentini@unsw.edu.au},
	editor = {Vigentini L. and Urrutia M.L. and Wang Y. and Paquette L.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Hsiao201648,
	author = {Hsiao, I-Han and Govindarajan, Sesha Kumar Pandhalkudi and Lin, Yi-Ling},
	title = {Semantic visual analytics for today's programming courses},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {48 – 53},
	doi = {10.1145/2883851.2883915},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976464319&doi=10.1145%2f2883851.2883915&partnerID=40&md5=f6265d626307b56e12c28537f4622412},
	affiliations = {School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, United States; Department of Information Management National, Sun Yat-Sen University, No. 70 Lienhai Rd., Kaohsiung, 80424, Taiwan},
	abstract = {We designed and studied an innovative semantic visual learning analytics for orchestrating today's programming classes. The visual analytics integrates sources of learning activities by their content semantics. It automatically processs paper-based exams by associating sets of concepts to the exam questions. Results indicated the automatic concept extraction from exams were promising and could be a potential technological solution to address a real world issue. We also discovered that indexing effectiveness was especially prevalent for complex content by covering more comprehensive semantics. Subjective evaluation revealed that the dynamic concept indexing provided teachers with immediate feedback on producing more balanced exams. © 2016 ACM.},
	author_keywords = {Auto grading; Dashboard; Intelligent authoring; Orchestration technology; Programming; Semantic analytics; Visual analytics},
	keywords = {Grading; Indexing (of information); Mathematical programming; Teaching; Visualization; Automatic concept extractions; Dashboard; Immediate feedbacks; Intelligent authoring; Semantic-analytics; Subjective evaluations; Technological solution; Visual analytics; Semantics},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Aleven201615,
	author = {Aleven, Vincent and Xhakaj, Franceska and Holstein, Kenneth and McLaren, Bruce M.},
	title = {Developing a teacher dashboard for use with intelligent tutoring systems},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1738},
	pages = {15 – 23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006251600&partnerID=40&md5=34dcc89b2921156d1b879a3f715ee623},
	affiliations = {Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Many dashboards display analytics generated by educational technologies, but few of them work with intelligent tutoring systems (ITSs). We are creating a teacher dashboard for use with ITSs built and used within our CTAT/Tutorshop infrastructure: an environment for authoring and deploying ITSs. The dashboard will take advantage of the fine-grained interaction data and derived analytics that CTAT-built ITSs produce. We are taking a user-centered design approach in which we target two usage scenarios for the dashboard. In one scenario, a teacher uses the dashboard while helping a class of students working with the tutoring software in the school's computer lab. In the other, the teacher uses the dashboard to prepare for an upcoming class session. So far, we have completed a Contextual Inquiry, ideation, Speed Dating sessions in which teachers evaluated story boards, usability testing, and a classroom study with a mocked up version of the dashboard with real data from the teacher's current classes and students. We are currently analyzing the data produced in these activities, iterating on the design of the dashboard, and implementing a full version of the dashboard. Unique characteristics of this dashboard may be that it leverages finegrained interaction data produced by an ITS and that it will be fully integrated with an ITS development and deployment environment, and therefore available for use with many ITSs.},
	author_keywords = {Blended learning; Dashboards; Intelligent tutoring systems; Learning analytics; Student modeling; User-centered design},
	keywords = {Computer aided instruction; Education; Intelligent vehicle highway systems; Students; User centered design; Blended learning; Dashboards; Intelligent tutoring system; Learning analytics; Student Modeling; Teaching},
	editor = {Bull S. and Ginon B. and Vatrapu R. and Kickmeier-Rust M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Lin2017422,
	author = {Lin, Chan-Hsien and Hu, Shih-Shin and Lai, Horng-Yih and Chiang, Chieh-Feng and Tseng, Hsiao-Chien and Cheng, Yuan-Che},
	title = {VisCa: A dashboard system to visualize learning activities from e-learning platforms},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10108 LNCS},
	pages = {422 – 427},
	doi = {10.1007/978-3-319-52836-6_44},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014283658&doi=10.1007%2f978-3-319-52836-6_44&partnerID=40&md5=f4ee1119c2a55baa9e74e3cf56275550},
	affiliations = {Institute for Information Industry, Digital Education Institute, Taipei, Taiwan},
	abstract = {With the advance of ICT technology, the e-learning platform from higher education to K12 becomes increasingly prevalent in recent years. Furthermore, as the emerging trend of data science, several educational platforms have introduced learning analytics and data-driven learning in their system, leading to more adaptive and personalized learning services. Therefore, it is crucial time to develop a mechanism to manage and visualize the data of learning experience. To achieve this goal, we created a web-based dashboard system called VisCa to track, store, and show learning experience from e-learning platforms. The data model is based on the standard of Experience API (xAPI) to communicate with third-party platforms. The whole system brings a general framework for the data flow of learning experience, as well as supports the students and teachers to understand their leaning status. The development of this study will provide an infrastructure to collect the data of learning activities, which can be used for further learning analytics or data-driven learning in the future. © Springer International Publishing AG 2017.},
	author_keywords = {Data visualization; Experience API; Learning analytics; Learning record store},
	keywords = {E-learning; Education; Education computing; Teaching; E-learning platforms; Educational platforms; Experience API; Learning Activity; Learning analytics; Learning experiences; Learning record; Personalized learning; Data visualization},
	correspondence_address = {C.-H. Lin; Institute for Information Industry, Digital Education Institute, Taipei, Taiwan; email: chanhsienlin@iii.org.tw},
	editor = {Gennari R. and Cao Y. and Huang Y.-M. and Wu T.-T. and Xie H.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331952835-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Jivet201782,
	author = {Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus},
	title = {Awareness is not enough: Pitfalls of learning analytics dashboards in the educational practice},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {82 – 96},
	doi = {10.1007/978-3-319-66610-5_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029587668&doi=10.1007%2f978-3-319-66610-5_7&partnerID=40&md5=520f0178139e3ade3fff9a41e75465d7},
	affiliations = {Open Universiteit, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; Goethe University Frankfurt, Frankfurt, Germany; German Institute for International Educational Research (DIPF), Frankfurt, Germany},
	abstract = {It has been long argued that learning analytics has the potential to act as a “middle space” between the learning sciences and data analytics, creating technical possibilities for exploring the vast amount of data generated in online learning environments. One common learning analytics intervention is the learning dashboard, a support tool for teachers and learners alike that allows them to gain insight into the learning process. Although several related works have scrutinised the state-of-the-art in the field of learning dashboards, none have addressed the theoretical foundation that should inform the design of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our critical examination reveals the most common educational concepts and the context in which they have been applied. We find evidence that current designs foster competition between learners rather than knowledge mastery, offering misguided frames of reference for comparison. © Springer International Publishing AG 2017.},
	author_keywords = {Competition; Learning analytics; Learning dashboards; Learning science; Learning theory; Social comparison; Systematic review},
	keywords = {Competition; Computer aided instruction; E-learning; Learning systems; Teaching; Learning analytics; Learning dashboards; Learning science; Learning Theory; Social comparison; Systematic Review; Education},
	correspondence_address = {I. Jivet; Open Universiteit, Heerlen, Valkenburgerweg 177, 6419 AT, Netherlands; email: ioana.jivet@ou.nl},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 168}
}

@CONFERENCE{Beheshitha201654,
	author = {Beheshitha, Sanam Shirazi and Hatala, Marek and Gaševic, Dragan and Joksimovic, Srećko},
	title = {The role of achievement goal orientations when studying effect of learning analytics visualizations},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {54 – 63},
	doi = {10.1145/2883851.2883904},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976516195&doi=10.1145%2f2883851.2883904&partnerID=40&md5=8e3dde9e200bec57364e2cef180d9801},
	affiliations = {School of Interactive Arts and Technology, Simon Fraser University, Surrey, Canada; Schools of Education and Informatics, University of Edinburgh, Edinburgh, United Kingdom},
	abstract = {When designing learning analytics tools for use by learners we have an opportunity to provide tools that consider a particular learner's situation and the learner herself. To afford actual impact on learning, such tools have to be informed by theories of education. Particularly, educational research shows that individual differences play a significant role in explaining students' learning process. However, limited empirical research in learning analytics has investigated the role of theoretical constructs, such as motivational factors, that are underlying the observed differences between individuals. In this work, we conducted a field experiment to examine the effect of three designed learning analytics visualizations on students' participation in online discussions in authentic course settings. Using hierarchical linear mixed models, our results revealed that effects of visualizations on the quantity and quality of messages posted by students with differences in achievement goal orientations could either be positive or negative. Our findings highlight the methodological importance of considering individual differences and pose important implications for future design and research of learning analytics visualizations. © 2016 ACM.},
	author_keywords = {Achievement goal orientation; Dashboards; Learning analytics; Online discussions; Visualizations},
	keywords = {Education; Education computing; Social networking (online); Students; Visualization; Dashboards; Educational research; Goal orientations; Implications for futures; Individual Differences; Learning analytics; Linear mixed models; Online discussions; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 53}
}

@CONFERENCE{Chen2017857,
	author = {Chen, Yuxin and Birk, Gurpreet and Hmelo-Silver, Cindy E. and Kazemitabar, Maedeh and Bodnar, Stephen and Lajoie, Susanne P.},
	title = {Visualizations to support facilitation: The instructors’ view},
	year = {2017},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {2},
	pages = {857 – 858},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073379124&partnerID=40&md5=036b5e5f411cb87f959dfd08dcb7ce70},
	affiliations = {Indiana University, United States; McGill University, Canada},
	abstract = {Dashboards with visualization techniques have the potential to support instructors in facilitating multiple asynchronous small groups by tracing learning activities and making interventions with the use of synthesized real-time information. However, few studies address how instructors use these visualizations in an online problem-based learning environment. This poster presents the results of a study that examined instructors’ use of a teacher dashboard in an online PBL environment using a think-aloud protocol. © ISLS.},
	author_keywords = {Dashboard; Learning analytics; Online learning; Problem-based learning; Visualizations},
	keywords = {Computer aided instruction; Visualization; Dashboard; Learning Activity; Learning analytics; Online learning; Problem based learning; Real-time information; Think-aloud protocol; Visualization technique; E-learning},
	editor = {Smith null and Borge M. and Mercier E. and Lim K.Y.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-099035502-1},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2016,
	title = {CEUR Workshop Proceedings},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006297731&partnerID=40&md5=4224eda373501857fab4d6cb4536e36e},
	abstract = {The proceedings contain 8 papers. The topics discussed include: towards understanding the potential of teaching analytics within educational communities; analysis of human-to-human tutorial dialogues: insights for teaching analytics; Luna: a dashboard for teachers using intelligent tutoring systems; developing a teacher dashboard for use with intelligent tutoring systems; an open learner model used by teachers to monitor speed reading learners; modelling the relationship between learner autonomy and cognitive abilities worth the effort?; support teachers' predictions of learning success by structural competence modelling; and improving personalized feedback at the workplace with a learning analytics enhanced e-portfolio.},
	editor = {Bull S. and Ginon B. and Vatrapu R. and Kickmeier-Rust M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pesare2015252,
	author = {Pesare, Enrica and Roselli, Teresa and Rossano, Veronica and Di Bitonto, Pierpaolo},
	title = {Digitally enhanced assessment in virtual learning environments},
	year = {2015},
	journal = {Journal of Visual Languages and Computing},
	volume = {31},
	pages = {252 – 259},
	doi = {10.1016/j.jvlc.2015.10.021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949539746&doi=10.1016%2fj.jvlc.2015.10.021&partnerID=40&md5=78e33c5e3eefc05c7d619f4f34e11507},
	affiliations = {Department of Computer Science, University of Bari, Via Orabona, 4 - Bari, Italy},
	abstract = {One of the main challenges in teaching and learning activities is the assessment: it allows teachers and learners to improve the future activities on the basis of the previous ones. It allows a deep analysis and understanding of the whole learning process. This is particularly difficult in virtual learning environments where a general overview is not always available. In the latest years, Learning Analytics are becoming the most popular methods to analyze the data collected in the learning environments in order to support teachers and learners in the complex process of learning. If they are properly integrated in learning activities, indeed, they can supply useful information to adapt the activities on the basis of student's needs. In this context, the paper presents a solution for the digitally enhanced assessment. Two different Learning Dashboards have been designed in order to represent the most interesting Learning Analytics aiming at providing teachers and learners with easy understandable view of learning data in virtual learning environments. © 2015 Elsevier Ltd.},
	author_keywords = {Assessment; Learning Analytics; Learning dashboard; Virtual learning environments},
	correspondence_address = {E. Pesare; Department of Computer Science, University of Bari, 4 - Bari, Via Orabona, Italy; email: enrica.pesare@uniba.it},
	publisher = {Academic Press},
	issn = {1045926X},
	coden = {JVLCE},
	language = {English},
	abbrev_source_title = {J. Vis. Lang. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access}
}

@CONFERENCE{Davis201617,
	author = {Davis, Dan and Chen, Guanliang and Jivet, Ioana and Hauff, Claudia and Houben, Geert-Jan},
	title = {Encouraging metacognition and Self-regulation in MOOCs through increased learner feedback},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1596},
	pages = {17 – 22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978194482&partnerID=40&md5=9b19f7a355745d2132614cb005be21e1},
	affiliations = {Delft University of Technology, Delft, Netherlands; Extension School, Delft University of Technology, Netherlands},
	abstract = {Learning analytics for learners has the ability to greatly improve learners' self-regulation. Current learner dashboards are mostly providing learners with an isolated view of their learning behavior, while we believe learners will gain more from a comparison of their own behavior with that of successful peer learners. In this work-in-progress demonstration we describe our design of a Learning Tracker widget that provides MOOC learners with timely and goal-oriented (i.e. towards passing the course) feedback in a manner that encourages reection and self-regulation. We also present some preliminary findings which show how exposure to feedback can significantly increase student success and engagement. Copyright © 2016 for the individual papers by the papers' authors.},
	author_keywords = {Learner feedback; Learning analytics; Self-regulated learning; Study planning},
	keywords = {Curricula; Deregulation; Learner feedbacks; Learning analytics; Learning behavior; Metacognition; Self regulation; Self-regulated learning; Student success; Work in progress; Learning systems},
	editor = {Bull S. and Ginon B.M. and Kay J. and Kickmeier-Rust M.D. and Johnson M.D.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 48}
}

@ARTICLE{20171,
	title = {4th International Conference on HCI in Business, Government and Organizations, HCIBGO 2017, held as part of the 19th International Conference on Human-Computer Interaction , HCI 2017},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10296 LNCS},
	pages = {1 – 498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025141015&partnerID=40&md5=161a08b4e91a46fc4f139083b1691772},
	abstract = {The proceedings contain 75 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Using augmented reality interactive system to support digital electronics learning; an AI system for coaching novice programmers; affective walkthroughs and heuristics; a creative engineering experience; manipulation of mathematical expressions in collaborative environments; designing tools that allows children in the early childhood to program robots; decision making for interactive systems; preschool learning with a fingertip; augmentative and alternative communication in the literacy teaching for deaf children; a model for collaboration in virtual worlds bringing together cultures in conflict; challenges of integrating non-traditional students in higher education and how electronic learning can support inclusion; training socially responsible engineers by developing accessible video games; the use of a new visual language as a supporting resource for people with intellectual disabilities; dashboard for actionable feedback on learning skills; learning analytics and spelling acquisition in German; data analysis of coaching and advising in undergraduate students; learning analytics and its paternalistic influences; development of a dashboard for learning analytics in higher education; mixing and matching learning design and learning analytics; a guidance and evaluation approach for mhealth  education applications; collaborative hybrid agent provision of learner needs using ontology based semantic technology and designing a peer feedback mobile application as a professional development tool.},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331958514-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Di Bitonto2015148,
	author = {Di Bitonto, Pierpaolo and Pesare, Enrica and Roselli, Teresa and Rossano, Veronica},
	title = {Digitally enhanced assessment in virtual learning environments},
	year = {2015},
	journal = {Proceedings - DMS 2015: 21st International Conference on Distributed Multimedia Systems},
	pages = {148 – 154},
	doi = {10.18293/DMS2015-34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969820461&doi=10.18293%2fDMS2015-34&partnerID=40&md5=3df9c567541ec5cbf669b9199f4f3db8},
	affiliations = {Department of Computer Science, University of Bari, Via Orabona, 4, Bari, Italy},
	abstract = {One of the main challenges in teaching and learning activities is the assessment: it allows teachers and learners to improve the future activities on the basis of the previous ones. It allows a deep analysis and understanding of the whole learning process. This is particularly difficult in virtual learning environments where a general overview is not always available. In the latest years, Learning Analytics are becoming the most popular methods to analyze the data collected in the learning environments in order to support teachers and learners in the complex process of learning. If they are properly integrated in learning activities, indeed, they can supply useful information to adapt the activities on the basis of student's needs. In this context, the paper presents a solution for the digitally enhanced assessment. Two different Learning Dashboards have been designed in order to represent the most interesting Learning Analytics aiming at providing teachers and learners with easy understandable view of learning data in virtual learning environments.},
	author_keywords = {Assessment; Learning Analytics; Learning Dashboard; Virtual learning environments},
	keywords = {Computer aided instruction; E-learning; Multimedia systems; Teaching; Assessment; Complex Processes; Learning Activity; Learning Analytics; Learning Dashboard; Learning environments; Teaching and learning; Virtual learning environments; Learning systems},
	publisher = {Knowledge Systems Institute Graduate School},
	isbn = {1891706381; 978-189170638-7},
	language = {English},
	abbrev_source_title = {Proc. - DMS: Int. Conf. Distrib. Multimed. Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Tan2016430,
	author = {Tan, Jennifer Pei-Ling and Yang, Simon and Koh, Elizabeth and Jonathan, Christin},
	title = {Fostering 21st century literacies through a collaborative critical reading and learning analytics environment: Userperceived benefits and problematic},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {430 – 434},
	doi = {10.1145/2883851.2883965},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976508445&doi=10.1145%2f2883851.2883965&partnerID=40&md5=2da699fe779f99f2623fbb25b4a8cbc2},
	affiliations = {National Institute of Education, Nanyang Technological University, Singapore},
	abstract = {The affordances of learning analytics (LA) are being increasingly harnessed to enhance 21st century (21C) pedagogy and learning. Relatively rare, however, are use cases and empirically based understandings of students' actual experiences with LA tools and environments at fostering 21C literacies, especially in secondary schooling and Asian education contexts. This paper addresses this knowledge gap by 1) presenting a first iteration design of a computer-supported collaborative critical reading and LA environment and its 16-week implementation in a Singapore high school; and 2) foregrounding students' quantitative and qualitative accounts of the benefits and problematics associated with this learning innovation. We focus the analytic lens on the LA dashboard components that provided visualizations of students' reading achievement, 21C learning dispositions, critical literacy competencies and social learning network positioning within the class. The paper aims to provide insights into the potentialities, paradoxes and pathways forward for designing LA that take into consideration the voices of learners as critical stakeholders. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {21st century skills; Critical literacy; CSCL; Learning analytics},
	keywords = {Students; 21st century skills; Affordances; Critical literacy; CSCL; High school; Knowledge gaps; Learning analytics; Social learning; Education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@CONFERENCE{Bull2016496,
	author = {Bull, S. and Ginon, B. and Kay, J. and Kickmeier-Rust, M. and Johnson, M.D.},
	title = {LAL workshop: Learning analytics for learners},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {496 – 497},
	doi = {10.1145/2883851.2883852},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976476941&doi=10.1145%2f2883851.2883852&partnerID=40&md5=5dbd8372756c2a88a6c921689eada1e9},
	affiliations = {University College London, United Kingdom; University of Birmingham, United Kingdom; University of Sydney, Australia; Technische Universität Graz, Austria},
	abstract = {With the arrival of 'big data' in education, the potential was recognised for learning analytics to track students' learning, to reveal patterns in their learning, or to identify at-risk students, in addition to guiding reform and supporting educators in improving teaching and learning processes [1]. Learning Analytics dashboards have been used at all levels, including institutional, regional and national level [2]. In classroom use, while learning visualisations are often based on counts of activity data or interaction patterns, there is increasing recognition that learning analytics relate to learning, and should therefore provide pedagogically useful information [3]. While increasing numbers of technology-enhanced learning applications are embracing the potential of learning analytics at the classroom level, often these are aimed at teachers. However, learners can also benefit from learning analytics data (e.g. [4][5]). © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Dashboards; Learning analytics for learners; Learning data for learners; Open learner models; Visual learning analytics},
	keywords = {Big data; Education; Education computing; Teaching; Dashboards; Learning analytics for learners; Learning data; Open learner models; Visual learning; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{20171,
	title = {12th European Conference on Technology Enhanced Learning, EC-TEL 2017},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {1 – 617},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029597189&partnerID=40&md5=12217cf6ee24725c8d9bfe00ee47d1dc},
	abstract = {The proceedings contain 75 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Machine and human observable differences in groups’ collaborative problem-solving behaviours; equality and intra-individual variability of physical interactivity; towards automatic assessment of argumentation in theses justifications; contextualizing the co-creation of artefacts within the nested social structure of a collaborative MOOC; pitfalls of learning analytics dashboards in the educational practice; examining interaction modality effects toward engagement in an interactive learning environment; using embodied learning technology to advance motor performance of children with special educational needs and motor impairments; usage and impact; a multi-aspect generic adaptation model for learning environments; automatic assessment of programming assignments using image recognition; learning analytics for professional and workplace learning; examining validity and reliability of the evaluation framework for learning analytics; opportunities and challenges in using learning analytics in learning design; evaluating student-facing learning dashboards of affective states; a strong concept in technology enhanced learning; a new theoretical framework for curiosity for learning in social contexts; studying multimodal behavioral dynamics to design social scaffolding of curiosity; using sequential pattern mining to explore learners’ behaviors and evaluate their correlation with performance in inquiry-based learning; a multi-system classifier; effects of a teacher dashboard for an intelligent tutoring system on teacher knowledge, lesson planning, lessons and student learning; identifying game elements suitable for MOOCs and an approach for the analysis of perceptual and gestural performance during critical situations.},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Aljohani2016139,
	author = {Aljohani, Naif R. and Davis, Hugh C. and Ally, Mohamed and Jalal, Syed Asim},
	title = {Student-centred learning analytics dashboards to empower students to take responsibility for their learning},
	year = {2016},
	journal = {Transforming Education in the Gulf Region: Emerging Learning Technologies and Innovative Pedagogy for the 21st Century},
	pages = {139 – 149},
	doi = {10.4324/9781315621586},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020344658&doi=10.4324%2f9781315621586&partnerID=40&md5=22586a2506559f6e0d87bf7a1b775c93},
	affiliations = {Faculty of Computing and Information Technology, King Abdul Aziz University, Jeddah, Saudi Arabia; Web and Internet Science Research Group (WAIS), University of Southampton, United Kingdom; Institute for Learning Innovation and Development (ILIaD), United Kingdom; Technology Enhanced Knowledge Research Institute (TEKRI), Athabasca University, Canada; University of Peshawar, Pakistan},
	publisher = {Taylor and Francis},
	isbn = {978-131722039-8; 978-113865700-7},
	language = {English},
	abbrev_source_title = {Transforming Education in the Gulf Region: Emerg. Learning Technologies and Innovative Pedagogy for the 21st Century},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Derick2017107,
	author = {Derick, Leony and Sedrakyan, Gayane and Munoz-Merino, Pedro J. and Delgado Kloos, Carlos and Verbert, Katrien},
	title = {Evaluating emotion visualizations using AffectVis, an affect-aware dashboard for students},
	year = {2017},
	journal = {Journal of Research in Innovative Teaching and Learning},
	volume = {10},
	number = {2},
	pages = {107 – 125},
	doi = {10.1108/JRIT-05-2017-0011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045919661&doi=10.1108%2fJRIT-05-2017-0011&partnerID=40&md5=9046b633c37463c880d9db6488dd6b1f},
	affiliations = {Department of Telematic Engineering, Universidad Carlos III de Madrid, Madrid, Spain; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium},
	abstract = {Purpose: The purpose of this paper is to evaluate four visualizations that represent affective states of students. Design/methodology/approach: An empirical-experimental study approach was used to assess the usability of affective state visualizations in a learning context. The first study was conducted with students who had knowledge of visualization techniques (n=10). The insights from this pilot study were used to improve the interpretability and ease of use of the visualizations. The second study was conducted with the improved visualizations with students who had no or limited knowledge of visualization techniques (n=105). Findings: The results indicate that usability, measured by perceived usefulness and insight, is overall acceptable. However, the findings also suggest that interpretability of some visualizations, in terms of the capability to support emotional awareness, still needs to be improved. The level of students’ awareness of their emotions during learning activities based on the visualization interpretation varied depending on previous knowledge of information visualization techniques. Awareness was found to be high for the most frequently experienced emotions and activities that were the most frustrating, but lower for more complex insights such as interpreting differences with peers. Furthermore, simpler visualizations resulted in better outcomes than more complex techniques. Originality/value: Detection of affective states of students and visualizations of these states in computer-based learning environments have been proposed to support student awareness and improve learning. However, the evaluation of visualizations of these affective states with students to support awareness in real life settings is an open issue. © 2017, Leony Derick, Gayane Sedrakyan, Pedro J. Munoz-Merino, Carlos Delgado Kloos and Katrien Verbert.},
	author_keywords = {Human-computer interface; Interactive learning environments; Learning analytics; Visualization evaluation},
	correspondence_address = {G. Sedrakyan; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; email: gsedrakyan@gmail.com},
	publisher = {Emerald Publishing},
	issn = {23977604},
	language = {English},
	abbrev_source_title = {J. Res. Innov. Teach. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Avogadro2016470,
	author = {Avogadro, Paolo and Calegari, Silvia and Dominoni, Matteo},
	title = {Analyzing social learning management systems for educational environments},
	year = {2016},
	journal = {Communications in Computer and Information Science},
	volume = {631},
	pages = {470 – 491},
	doi = {10.1007/978-3-319-52758-1_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011360896&doi=10.1007%2f978-3-319-52758-1_25&partnerID=40&md5=90a2c8d0e81c14b89b3b30458d0f3572},
	affiliations = {University of Milano-Bicocca, v.le Sarca 336/14, Milano, 20126, Italy},
	abstract = {A Social Learning Management System (Social LMS) is an instantiation of an LMS where there is an inclusion and strong emphasis of the social aspects mediated via the ICT. The amount of data produced within the social educational network (since all the students are potential creators of material) outnumbers the information of a normal LMS and calls for novel analysis methods. At the beginning, we introduce the architecture of the social learning analytics required to manage the knowledge of a Social LMS. At this point, we adapt the Kirkpatrcik-Phillips model for scholastic environments in order to provide assessment and control tools for a Social LMS. This requires the definition of new metrics which clarify aspects related to the single student but also provide global views of the network as a whole. In order to manage and visualize these metrics we suggest to use modular dashboards which accommodate for the different roles present in a learning institution. © Springer International Publishing AG 2016.},
	author_keywords = {Dashboard; E-Learning platform; Key performance indicators; KirckPatrick-phillips model; Social learning analytics; Social learning management system},
	keywords = {Benchmarking; E-learning; Knowledge engineering; Knowledge management; Social aspects; Dashboard; E-learning platforms; Key performance indicators; Phillips; Social learning; Students},
	correspondence_address = {P. Avogadro; University of Milano-Bicocca, Milano, v.le Sarca 336/14, 20126, Italy; email: paolo.avogadro@disco.unimib.it},
	editor = {Filipe J. and Fred A. and Dietz J.L.G. and Liu K. and Aveiro D.},
	publisher = {Springer Verlag},
	issn = {18650929},
	isbn = {978-331952757-4},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Vigentini2017512,
	author = {Vigentini, Lorenzo and Urrutia, Manuel León and Fields, Ben},
	title = {FutureLearn data: What we currently have, what we are Learning and how it is demonstrating learning in MOOCs},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {512 – 513},
	doi = {10.1145/3027385.3029433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016458656&doi=10.1145%2f3027385.3029433&partnerID=40&md5=993fa2d92b05b84c99b14dd2c2b88482},
	affiliations = {UNSW, Australia; University of Southampton, United Kingdom; FutureLearn, China},
	abstract = {Compared to other platforms such as Coursera and EdX, FutureLearn is a relatively new player in the MOOC arena and received limited coverage in the Learning Analytics and Educational Data Mining research. Founded by a partnership between the Open University in the UK, the BBC, The British Library and (originally) 12 universities in the UK, FutureLearn has two distinctive features relevant to the way their data is displayed and analyzed:1) it was designed with a specific educational philosophy in mind which focuses on the social dimension of learning and 2) every learning activity provide opportunities for formal discussion and commenting. This workshop provides an opportunity to invite contributions and connect individual and groups to share their research activities on an international stage. As the first of its kind, this workshop will bring in a number of scholars and practitioners, as well as data scientists and analyst involved in the reporting, researching and developments emerging from the data offered by the platform. © 2017 ACM.},
	author_keywords = {Learning analytics; MOOCs; Visualization dashboard},
	keywords = {Computer applications; Computer programming; Educational data mining; Educational philosophies; Learning Activity; Learning analytics; MOOCs; Open universities; Research activities; Social dimensions; Data mining},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zapparolli2016,
	author = {Zapparolli, Luciana Silva and Stiubiener, Itana},
	title = {Management support tool in virtual learning environments using moodle as a case study},
	year = {2016},
	journal = {Proceedings - 2016 11th Latin American Conference on Learning Objects and Technology, LACLO 2016},
	doi = {10.1109/LACLO.2016.7751756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006942646&doi=10.1109%2fLACLO.2016.7751756&partnerID=40&md5=04418512f621ec6aa13c83b6b5f477b7},
	affiliations = {Centro de Matemática, Computação e Cognição, Universidade Federal Do ABC e Fatec Mauá, Santo André, Brazil; Centro de Matemática, Computação e Cognição, Universidade Federal Do ABC, Santo André, Brazil},
	abstract = {This paper presents a tool that uses techniques of Business Intelligence (BI) and Learning Analytics (LA) to assist the Distance Education managers (EAD) in monitoring the actions of both students and teachers/tutors in the Virtual Learning Environment (VLE) Moodle. The tool provides analytical and consolidated reports on all the responsibility rooms of a certain teacher/tutor, and dashboards, with the vision of the students and the teacher/tutor, thus allowing a better management in virtual learning environments as AVA Moodle Learning Analytics offers some features, however, the views refer to rooms, resources or specific participants, making it difficult to interpret, making it laborious process management. The use of this tool by EaD managers allows faults to be corrected during the process of teaching and learning and helps the decisions to be taken concerning the people related to the process in reference to teachers, tutors that should be reliable and assertive, as they are an integral and very important part of this process of teaching and learning. © 2016 IEEE.},
	author_keywords = {Business Intelligence; Distance Education Management; Learning Analytics; Monitoring in virtual environments},
	keywords = {Competitive intelligence; Computer aided instruction; Distance education; Education; Engineering education; Environmental management; Information analysis; Management science; Managers; Students; Teaching; Virtual reality; Education management; Learning Analytics; Management support tools; Process management; Teaching and learning; Virtual learning environments; E-learning},
	editor = {Chacon I.A. and Rivas M.C. and Cechinel C. and Alfaro A.F.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150906149-5},
	language = {Portuguese},
	abbrev_source_title = {Proceedings - Lat. Am. Conf. Learn. Objects Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hayit201635,
	author = {Hayit, Darya and Hölterhof, Tobias and Rehm, Martin and Carl, Oskar and Kerres, Michael},
	title = {Visualizing online (social) learning processes - Designing a Dashboard to support reflection},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1736},
	pages = {35 – 40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006086148&partnerID=40&md5=71ea9d11ad93dbcb8df963d523c4e39e},
	affiliations = {University of Duisburg-Essen, Essen, Germany},
	abstract = {Learning analytics, as a means to visualize learning, has been repeatedly suggested to enhance learners' and teachers' self-reflection in online learning processes. Departing from this notion, we propose a combination of this visual approach to learning analytics with the concept of social presence, thereby acknowledging social aspects of online learning processes that are often overlooked. More specifically, we present the considerations and design of a dedicated dashboard that supports self-reflection by visualizing (social) online learning processes. The approach is based on our belief that visualizing learning by itself does not automatically lead to self-reflection and awareness among students and teachers. Instead, organizers and instructors of learning activities need to be conscious about the social aspects of learning.},
	author_keywords = {Awareness; Dashboard; Learning analytics; Online learning; Reflection; Social learning; Social presence; Visualization},
	keywords = {Engineering education; Flow visualization; Reflection; Social aspects; Teaching; Awareness; Dashboard; Learning analytics; Online learning; Social learning; Social presence; E-learning},
	editor = {Pammer V. and Graz University of Technology, Knowledge Technologies Institute, Inffeldgasse 21A, Graz and Kravcik M. and RWTH Aachen University, Advanced Community Information Systems (ACIS), Ahornstr. 55, Aachen and Prilla M. and Clausthal University of Technology, Human Centered Information Systems, Julius-Albert-Str. 4, Clausthal and Ullmann T.D. and The Open University, Institute of Educational Technology, Walton Hall, Milton Keynes and Mikroyannidis A. and The Open University, Knowledge Media Institute, Walton Hall, Milton Keynes},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Scheffel2017194,
	author = {Scheffel, Maren and Drachsler, Hendrik and Toisoul, Christian and Ternier, Stefaan and Specht, Marcus},
	title = {The proof of the pudding: Examining validity and reliability of the evaluation framework for learning analytics},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {194 – 208},
	doi = {10.1007/978-3-319-66610-5_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029598272&doi=10.1007%2f978-3-319-66610-5_15&partnerID=40&md5=fe8a325a903dd9dcf239c92ba6d0e42a},
	affiliations = {Open Universiteit, Valkenburgerweg 177, Heerlen, 6419AT, Netherlands; Goethe University Frankfurt, Frankfurt, Germany; German Institute for International Educational Research (DIPF), Frankfurt, Germany},
	abstract = {While learning analytics (LA) is maturing from being a trend to being part of the institutional toolbox, the need for more empirical evidences about the effects for LA on the actual stakeholders, i.e. learners and teachers, is increasing. Within this paper we report about a further evaluation iteration of the Evaluation Framework for Learning Analytics (EFLA) that provides an efficient and effective measure to get insights into the application of LA in educational institutes. For this empirical study we have thus developed and implemented several LA widgets into a MOOC platform’s dashboard and evaluated these widgets using the EFLA as well as the framework itself using principal component and reliability analysis. The results show that the EFLA is able to measure differences between widget versions. Furthermore, they indicate that the framework is highly reliable after slightly adapting its dimensions. © Springer International Publishing AG 2017.},
	author_keywords = {Evaluation; Learning analytics; Reliability; Validity},
	keywords = {Network function virtualization; Principal component analysis; Reliability; Reliability analysis; Teaching; Educational Institutes; Effective measures; Empirical studies; Evaluation; Evaluation framework; Learning analytics; Principal Components; Validity; Education},
	correspondence_address = {M. Scheffel; Open Universiteit, Heerlen, Valkenburgerweg 177, 6419AT, Netherlands; email: maren.scheffel@ou.nl},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Demmans Epp2015242,
	author = {Demmans Epp, Carrie and Bull, Susan},
	title = {Uncertainty Representation in Visualizations of Learning Analytics for Learners: Current Approaches and Opportunities},
	year = {2015},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {8},
	number = {3},
	pages = {242 – 260},
	doi = {10.1109/TLT.2015.2411604},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961794709&doi=10.1109%2fTLT.2015.2411604&partnerID=40&md5=f95ad397d900dcb391087cd428e38ab4},
	affiliations = {Department of Computer Science, University of Toronto, 3302-10 King's College Road, Toronto, ON, Canada; School of Electronic, Electrical and Systems Engineering, University of Birmingham, Birmingham, West Midlands, B15 2TT, United Kingdom},
	abstract = {Adding uncertainty information to visualizations is becoming increasingly common across domains since its addition helps ensure that informed decisions are made. This work has shown the difficulty that is inherent to representing uncertainty. Moreover, the representation of uncertainty has yet to be thoroughly explored in educational domains even though visualizations are often used in educational reporting. We analyzed 50 uncertainty-augmented visualizations from various disciplines to map out how uncertainty has been represented. We then analyzed 106 visualizations from educational reporting systems where the learner can see the visualization; these visualizations provide learners with information about several factors including their knowledge, performance, and abilities. This analysis mapped the design space that has been employed to communicate a learner's abilities, knowledge, and interests. It also revealed several opportunities for the inclusion of uncertainty information within visualizations of educational data. We describe how uncertainty information can be added to visualizations of educational data and illustrate these opportunities by augmenting several of the types of visualizations that are found in existing learning analytics reports. The definition of this design space, based on a survey of the literature, will enable the systematic exploration of how different design decisions affect learner trust, understanding, and decision making. © 2008-2011 IEEE.},
	author_keywords = {educational reporting; learning analytics; learning dashboards; open learner models; uncertainty; visual analytics},
	keywords = {Decision making; Education; Learning systems; Visualization; educational reporting; learning analytics; learning dashboards; Open learner models; uncertainty; Visual analytics; Uncertainty analysis},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44; All Open Access, Green Open Access}
}

@CONFERENCE{Kitto2016548,
	author = {Kitto, Kirsty and Bakharia, Aneesha and Lupton, Mandy and Mallet, Dann and Banks, John and Bruza, Peter and Pardo, Abelardo and Shum, Simon Buckingham and Dawsony, Shane and Gaševícy, Dragan and Siemensg, George and Lynch, Grace},
	title = {The connected learning analytics toolkit},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {548 – 549},
	doi = {10.1145/2883851.2883881},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976506613&doi=10.1145%2f2883851.2883881&partnerID=40&md5=23482c8eb4e58ffdcb173c0eee2277d5},
	affiliations = {Queensland University of Technology (QUT), Australia; University of Sydney, Australia; University of Technology Sydney, Australia; University of South Australia, Australia; University of Edinburgh, United Kingdom; University of Texas (Arlington), United States; Royal Melbourne Institute of Technology (RMIT), Australia},
	abstract = {This demonstration introduces the Connected Learning An- Alytics (CLA) Toolkit. The CLA toolkit harvests data about student participation in specified learning activities across standard social media environments, and presents information about the nature and quality of the learning interactions. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Dashboards; Sensemaking; Social learning analytics},
	keywords = {Computer programming; Dashboards; Learning Activity; Learning interactions; Sensemaking; Social learning; Social media; Student participation; Computer applications},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Xhakaj2017582,
	author = {Xhakaj, Françeska and Aleven, Vincent and McLaren, Bruce M.},
	title = {Effects of a dashboard for an intelligent tutoring system on teacher knowledge, lesson plans and class sessions},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10331 LNAI},
	pages = {582 – 585},
	doi = {10.1007/978-3-319-61425-0_69},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022206650&doi=10.1007%2f978-3-319-61425-0_69&partnerID=40&md5=3e7013afbc89b28d4ae6f18ccb20dad6},
	affiliations = {Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Even though Intelligent Tutoring Systems (ITS) have been shown to help students learn, little research has investigated how a dashboard could help teachers help their students. In this paper, we explore how a dashboard prototype designed for an ITS affects teachers’ knowledge about their students, their classroom lesson plans and class sessions. We conducted a quasi-experimental classroom study with 5 middle school teachers and 8 classes. We found that the dashboard influences what teachers know about their students, which in turn influences the lesson plans they prepare, which then guides what teachers cover in a class session. We believe this is the first study that explores how a dashboard for an ITS affects teacher’s knowledge, decision-making and actions in the classroom. © Springer International Publishing AG 2017.},
	author_keywords = {Dashboard; Data-driven instruction; Intelligent Tutoring Systems; Learning analytics; Teachers' use of data},
	keywords = {Artificial intelligence; Computer aided instruction; Decision making; Education computing; Intelligent vehicle highway systems; Planning; Students; Dashboard; Data driven; Intelligent tutoring system; Learning analytics; Teachers'; Teaching},
	correspondence_address = {F. Xhakaj; Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, United States; email: francesx@cs.cmu.edu},
	editor = {Andre E. and Hu X. and Rodrigo M.M.T. and du Boulay B. and Baker R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331961424-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Martinez-Maldonado20151,
	author = {Martinez-Maldonado, Roberto and Pardo, Abelardo and Mirriahi, Negin and Yacef, Kalina and Kay, Judy and Clayphan, Andrew},
	title = {The LATUX workflow: Designing and deploying awareness tools in technology-enabled learning settings},
	year = {2015},
	journal = {ACM International Conference Proceeding Series},
	volume = {16-20-March-2015},
	pages = {1 – 10},
	doi = {10.1145/2723576.2723583},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955566903&doi=10.1145%2f2723576.2723583&partnerID=40&md5=50057efa7dd044986be3585c9e56c0f3},
	affiliations = {Faculty of Education and Social Work, University of Sydney, 2006, Australia; School of Electrical and Information Engineering, University of Sydney, 2006, Australia; School of Information Technologies, University of Sydney, 2006, Australia; School of Education and Learning and Teaching Unit, University of New South Wales, 2052, Australia},
	abstract = {Designing, deploying and validating learning analytics tools for instructors or students is a challenge requiring techniques and methods from different disciplines, such as software engineering, human-computer interaction, educational design and psychology. Whilst each of these disciplines has consolidated design methodologies, there is a need for more specific methodological frameworks within the cross-disciplinary space defined by learning analytics. In particular there is no systematic workflow for producing learning analytics tools that are both technologically feasible and truly underpin the learning experience. In this paper, we present the LATUX workflow, a five-stage workflow to design, deploy and validate awareness tools in technology-enabled learning environments. LATUX is grounded on a well-established design process for creating, testing and re-designing user interfaces. We extend this process by integrating the pedagogical requirements to generate visual analytics to inform instructors' pedagogical decisions or intervention strategies. The workflow is illustrated with a case study in which collaborative activities were deployed in a real classroom.},
	author_keywords = {Awareness; Dashboard; Design; Design; Groupware; Visualisations},
	keywords = {Computer aided instruction; Design; Education; Groupware; Human computer interaction; Software engineering; Teaching; User interfaces; Visualization; Awareness; Collaborative activities; Cross-disciplinary; Dashboard; Intervention strategy; Learning experiences; Methodological frameworks; Technology-enabled learning; Engineering education},
	publisher = {Association for Computing Machinery},
	isbn = {978-145033417-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49}
}

@ARTICLE{Roberts2016257,
	author = {Roberts, Jeremy D. and Chung, Gregory K. W. K. and Parks, Charles B.},
	title = {Supporting children’s progress through the PBS KIDS learning analytics platform},
	year = {2016},
	journal = {Journal of Children and Media},
	volume = {10},
	number = {2},
	pages = {257 – 266},
	doi = {10.1080/17482798.2016.1140489},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963553658&doi=10.1080%2f17482798.2016.1140489&partnerID=40&md5=3d48ea37d013c10716b9cdb30ede32f9},
	affiliations = {The Incredible Pear, Alexandria, VA, United States; University of California, Los Angeles (UCLA) National Center for Research on Evaluation, Standards, and Student Testing (CRESST), Los Angeles, CA, United States},
	abstract = {A 2010–2015 Ready to Learn grant from the US Department of Education supported the research, development, and dissemination of PBS KIDS math and literacy content for kids aged 2–8, and new ways to measure and report on children’s learning. PBS KIDS, in collaboration with UCLA CRESST, developed a prototype learning analytics platform (LAP) to analyze back-end data from children’s interactions with PBS KIDS transmedia content, and provide custom reports to parents that enable them to better identify and support their child’s individual learning needs. Evidence suggests that the PBS KIDS prototype LAP demonstrates potential for assessment and prediction of mathematics performance, including on the TEMA-3 standardized assessment for early mathematics. Similarly, early research findings suggest that the reporting applications developed to provide LAP information are viewed favorably by parents and promote interest in learning more about, monitoring, and engaging with their kids around learning. Implications for the future are discussed. © 2016 Taylor & Francis.},
	author_keywords = {Analytics; Data dashboard; Early learning; Game-based-learning; Machine learning; Transmedia},
	correspondence_address = {J.D. Roberts; The Incredible Pear, Alexandria, United States; email: jer@incrediblepear.com},
	publisher = {Routledge},
	issn = {17482798},
	language = {English},
	abbrev_source_title = {J. Child. Media},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@CONFERENCE{Ramos-Soto2015260,
	author = {Ramos-Soto, A. and Lama, M. and Vazquez-Barreiros, B. and Bugarin, A. and Mucientes, M. and Barro, S.},
	title = {Towards textual reporting in learning analytics dashboards},
	year = {2015},
	journal = {Proceedings - IEEE 15th International Conference on Advanced Learning Technologies: Advanced Technologies for Supporting Open Access to Formal and Informal Learning, ICALT 2015},
	pages = {260 – 264},
	doi = {10.1109/ICALT.2015.96},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961724116&doi=10.1109%2fICALT.2015.96&partnerID=40&md5=8c56d56a49d244d7ebeca12e260d3edd},
	affiliations = {Research Center on Information Technologies (CiTIUS), University of Santiago de Compostela, Spain},
	abstract = {In this paper we present the Soft Learn Activity Reporter (SLAR) service which automatically generates textual short-term reports about learners' behavior in virtual learning environments. Through this approach, we show how textual reporting is a coherent way of providing information that can complement (and even enhance) visual statistics and help teachers to understand in a comprehensible manner the behavior of their students during the course. This solution extracts relevant information from the students' activity and encodes it into intermediate descriptions using linguistic variables and temporal references, which are subsequently translated into texts in natural language. The examples of application on real data from an undergraduate course supported by the Soft Learn platform show that automatic textual reporting is a valuable complementary tool for explaining teachers and learners the information comprised in a Learning Analytics Dashboard. © 2015 IEEE.},
	author_keywords = {Learning Analytics Dashboard; Linguistic Descriptions of Data; Natural Language Generation},
	keywords = {Computational linguistics; Computer aided instruction; Education; Learning systems; Linguistics; Natural language processing systems; Teaching; Complementary tools; Learning Analytics Dashboard; Linguistic descriptions; Linguistic variable; Natural language generation; Natural languages; Undergraduate Courses; Virtual learning environments; Engineering education},
	editor = {Chen N.-S. and Liu T.-C. and Kinshuk null and Huang R. and Hwang G.-J. and Sampson D.G. and Tsai C.-C.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-146737333-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol.: Adv. Technol. Support. Open Access Formal Informal Learn., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Kitto2016338,
	author = {Kitto, Kirsty and Lupton, Mandy and Davis, Kate and Waters, Zak},
	title = {Incorporating student-facing learning analytics into pedagogical practice},
	year = {2016},
	journal = {ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
	pages = {338 – 347},
	doi = {10.14742/apubs.2016.810},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032626176&doi=10.14742%2fapubs.2016.810&partnerID=40&md5=bd2e38f3fca4b5497602eaa9182d3730},
	affiliations = {Science and Engineering Faculty, Queensland University of Technology, Australia; Faculty of Education, Queensland University of Technology, Australia},
	abstract = {Despite a narrative that sees Learning Analytics (LA) as a field that enhances student learning, few student-facing solutions have been developed. A lack of tools enables a sophisticated student focus, and it is difficult for educators to imagine how data can be used in authentic practice. This is unfortunate, as LA has the potential to be a powerful tool for encouraging metacognition and reflection. We propose a series of learning design patterns that will help people to incorporate LA into their teaching protocols: do-analyse-change-reflect, active learning squared, and group contribution. We discuss these learning design patterns with reference to a case study provided by the Connected Learning Analytics (CLA) toolkit, demonstrating that student-facing learning analytics is not just a future possibility, but an area that is ripe for further development. © 2016 Deakin University. All Rights Reserved.},
	author_keywords = {CLA toolkit; Dashboards; Learning analytics; Learning design patterns; Pedagogy},
	keywords = {Educational technology; Facings; Connected learning analytic toolkit; Dashboard; Design Patterns; Learning analytic; Learning design pattern; Learning designs; Metacognition; Pedagogical practices; Pedagogy; Student learning; Students},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	language = {English},
	abbrev_source_title = {ASCILITE - Conf. Proc. - Int. Conf. Innov., Pract. Res. Use Educ. Technol. Tert. Educ.: Show Me Learn.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Broos2017229,
	author = {Broos, Tom and Peeters, Laurie and Verbert, Katrien and Van Soom, Carolien and Langie, Greet and De Laet, Tinne},
	title = {Dashboard for actionable feedback on learning skills: Scalability and usefulness},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10296 LNCS},
	pages = {229 – 241},
	doi = {10.1007/978-3-319-58515-4_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025158156&doi=10.1007%2f978-3-319-58515-4_18&partnerID=40&md5=7ef7695cae468234e76e1537cb39f001},
	affiliations = {Faculty of Engineering Science, KU Leuven, Leuven, Belgium; Leuven Statistics Research Centre, KU Leuven, Leuven, Belgium; Department of Computer Science, KU Leuven, Leuven, Belgium; Faculty of Science, KU Leuven, Leuven, Belgium; Faculty of Engineering Technology, KU Leuven, Leuven, Belgium; Leuven Engineering and Science Education Centre, KU Leuven, Leuven, Belgium},
	abstract = {In the transition from secondary to higher education, students are expected to develop a set of learning skills. This paper reports on a dashboard implemented and designed to support this development, hereby bridging the gap between Learning Analytics research and the daily practice of supporting students. To demonstrate the scalability and usefulness of the dashboard, this paper reports on an intervention with 1406 first-year students in 12 different programs. The results show that the dashboard is perceived as clear and useful.While students not accessing the dashboard have lower learning skills, they make more use of the extra remediation possibilities in the dashboard. © Springer International Publishing AG 2017.},
	author_keywords = {Higher education; Learning analytics; Learning skills; Scalable},
	keywords = {Engineering education; Human computer interaction; Scalability; Students; First year students; Higher education; Learning analytics; Learning skills; Scalable; Education},
	correspondence_address = {T. Broos; Faculty of Engineering Science, KU Leuven, Leuven, Belgium; email: tom.broos@kuleuven.be},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331958514-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@CONFERENCE{Kickmeier-Rust201536,
	author = {Kickmeier-Rust, Michael D. and Steiner, Christina M. and Albert, Dietrich},
	title = {Uncovering learning processes using competence-based knowledge structuring and hasse diagrams},
	year = {2015},
	journal = {CEUR Workshop Proceedings},
	volume = {1518},
	pages = {36 – 40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960970651&partnerID=40&md5=3d50983a88b4f73bb647a5845fc1b7c4},
	affiliations = {Graz University of Technology, Knowledge Technologies Institute, Graz, 8010, Austria},
	abstract = {Learning analytics means gathering a broad range of data, bringing the various sources together, and analyzing them. However, to draw educational insights from the results of the analyses, these results must be visualized and presented to the educators and learners. This task is often accomplished by using dashboards equipped with conventional and often simple visualizations such as bar charts or traffic lights. In this paper we want to introduce a method for utilizing the strengths of directed graphs, namely Hasse diagrams, and a competence-oriented approach of structuring knowledge and learning domains. After a brief theoretical introduction, this paper highlights and discusses potential advantages and gives an outlook to recent challenges for research.},
	author_keywords = {Competence-based Knowledge Space Theory; Data visualization; Hasse diagram; Learning analytics},
	keywords = {Data visualization; Directed graphs; Visualization; Bar chart; Hasse diagrams; Knowledge space theory; Knowledge structuring; Learning analytics; Learning process; Structuring knowledge; Traffic light; Graphic methods},
	editor = {Gillet D. and School of Engineering, EPFL, Station 9, Lausanne and Govaerts S. and School of Engineering, EPFL, Station 9, Lausanne and Parra D. and Wolpers M. and Ochoa X. and Escuela Superior Politecnica del Litoral, Campus Gustavo Galindo, Km. 30.5 Via Perimetral, Guayaquil and Klerkx J. and Duval E. and Verbert K. and Pardo A.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Perez-Colado201751,
	author = {Perez-Colado, Ivan J. and Perez-Colado, Victor M. and Freire-Moran, Manuel and Martinez-Ortiz, Ivan and Fernandez-Manjon, Baltasar},
	title = {Integrating learning analytics into a game authoring tool},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10473 LNCS},
	pages = {51 – 61},
	doi = {10.1007/978-3-319-66733-1_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030110159&doi=10.1007%2f978-3-319-66733-1_6&partnerID=40&md5=4f98d2f17e870a751a45884d3e64992a},
	affiliations = {Department of Software Engineering and Artificial Intelligence, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain},
	abstract = {Educational games can greatly benefit from integrating support for learning analytics. Game authoring tools that make this integration as easy as possible are therefore an important step towards improving adoption of educational games. We describe the process of integrating full support for game learning analytics into uAdventure, a serious game authoring tool. We argue that such integrations greatly systematize, simplify and reduce both the cost and the knowledge required to apply analytics to serious games. In uAdventure, we have used an analytics model for serious games and its supporting implementation as a xAPI application. We describe how player interactions are automatically traced, and provide an interaction-model-trace table with the general game traces that are generated by the editor. Also, we describe the custom editors that simplify the task of authoring game-dependant analytics. Thanks to these integrated analytics, games developed with uAdventure provide detailed tracking information that can be sent to a cloud analytics server, to be analyzed and visualized with dashboards that provide game developers and educators with insights into how games are being played. © 2017, Springer International Publishing AG.},
	author_keywords = {Analytics; Game learning analytics; Games authoring; Serious games; xAPI},
	keywords = {Computer aided instruction; E-learning; Education; Websites; Analytics; Educational game; Game authoring tool; Game learning analytics; Games authoring; Interaction model; xAPI; Serious games},
	correspondence_address = {B. Fernandez-Manjon; Department of Software Engineering and Artificial Intelligence, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain; email: balta@fdi.ucm.es},
	editor = {Manjon B.F. and Xie H. and Popescu E. and Hancke G.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966732-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Li2017908,
	author = {Li, Huiyong and Ogata, Hiroaki and Tsuchiya, Tomoyuki and Suzuki, Yubun and Uchida, Satoru and Ohashi, Hiroshi and Konomi, Shin'ichi},
	title = {Using learning analytics to support computer-assisted language learning},
	year = {2017},
	journal = {Proceedings of the 25th International Conference on Computers in Education, ICCE 2017 - Main Conference Proceedings},
	pages = {908 – 913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053895889&partnerID=40&md5=65c7c148b91e24d3ef644b08a44d9508},
	affiliations = {Graduate School of Information Science and Electrical Engineering, Kyushu University, Japan; Academic Center for Computing and Media Studies, Kyoto University, Japan; Faculty of Languages and Cultures, Kyushu University, Japan; Faculty of Arts and Science, Kyushu University, Japan},
	abstract = {Computer-assisted language learning (CALL) is often used as an approach to foreign language teaching and learning in higher education. The CALL course is offered at a national university in Japan to allow freshman students to perform self-regulated learning with e-learning materials for the purpose of developing language skills. However, as novice self-regulated learners, freshman students have low self-regulation skills and they are more likely to obtain lower achievement. In addition, it is difficult for instructors to grasp students' learning situation due to the large amount of evaluation work. Therefore, in this research, a total of 7,413,397 learning logs were analyzed, which were collected from 2,499 students' learning interactions in the CALL course. After that, a learning support system for freshman students is proposed. The system is provided for students and instructors through the learning dashboard. On the one hand, students can conduct self-monitoring and reflect their behaviors in a visual way. On the other hand, instructors can identify learning behavioral patterns and grasp individual learning situation to provide one-on-one instructions. © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.},
	author_keywords = {Computer-assisted language learning; Learning analytics; Self-regulated learning},
	keywords = {Computer aided instruction; Curricula; Linguistics; Students; Teaching; Computer assisted language learning; E-learning materials; Foreign language teaching; Individual learning; Learning analytics; Learning interactions; Learning support systems; Self-regulated learning; E-learning},
	editor = {Mohd Ayub A.F. and Mitrovic A. and Yang J.-C. and Wong S.L. and Chen W.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986940126-5},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Comput. Educ., ICCE - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Molinaro201636,
	author = {Molinaro, Marco and Li, Qiwei and Steinwachs, Matthew and Guzman-Alvarez, Alberto},
	title = {Promoting instructor and department action via simple, actionable tools and analyses},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1590},
	pages = {36 – 40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978285885&partnerID=40&md5=235327b6a2009a118a6d03235f9b6a5a},
	affiliations = {University of California, Davis, United States},
	abstract = {In this paper, we present some of our ongoing, as well as more recent work designing, implementing, and improving three tools to help university instructors and department leaders make evidence-based improvements to instruction. The first tool, Know Your Students, is a very early prototype that helps instructors tailor their instruction based on characteristics of the students they would not otherwise be aware of in their courses. The other two tools, the Departmental Diagnostic Dashboard and Ribbon Tool, help department chairs, curricular chairs, and/or advisors identify and make sense of student patterns they may be trying to minimize or enhance within individual courses, course series, and/or throughout their entire program. This paper illustrates examples of these tools and some of the actions they have inspired as a means of improving student outcomes.},
	author_keywords = {Departmental instructional dashboard; Learning analytics; Programmatic change; Ribbon tool; Visualization},
	keywords = {Curricula; Education; Flow visualization; Program diagnostics; Departmental instructional dashboard; Evidence-based; Learning analytics; Programmatic changes; Student outcomes; Students},
	editor = {McKay T. and Molinaro M. and Greer J. and Ochoa X.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Lkhagvasuren20161,
	author = {Lkhagvasuren, Erdenesaikhan and Matsuura, Kenji and Mouri, Kousuke and Ogata, Hiroaki},
	title = {Dashboard for analyzing ubiquitous learning log},
	year = {2016},
	journal = {International Journal of Distance Education Technologies},
	volume = {14},
	number = {3},
	pages = {1 – 20},
	doi = {10.4018/IJDET.2016070101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975078294&doi=10.4018%2fIJDET.2016070101&partnerID=40&md5=4bc80e4e33e78ca0840f47b5de310a3d},
	affiliations = {Department of Information Science and Intelligent Systems, Tokushima University, Tokushima, Japan; Centre for Administration of Information Technology, Tokushima University, Tokushima, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Faculty of Arts and Sciences, Kyushu University, Fukuoka, Japan},
	abstract = {Mobile and ubiquitous technologies have been applied to a wide range of learning fields such as science, social science, history and language learning. Many researchers have been investigating the development of ubiquitous learning environments; nevertheless, to date, there have not been enough research works related to the reflection, analysis and traces of learners' activities in the history of ubiquitous learning environment. Therefore this paper presents a research on the design and development of a dashboard function which proposes new opportunity for ubiquitous learning. The dashboard captures, analyzes and visualizes traces of learning activities in order to promote awareness and enables learners to reflect on their own activity and helps to recall what they have learned. An initial evaluation has been conducted with 14 international students. Results indicate that the dashboard is a useful tool for self-reflection on activities and recall what learners have learned by repeated quizzes. Copyright © 2016, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.},
	author_keywords = {Dashboard; Language learning; Learning analytics; Memory; Reflection; Ubiquitous learning},
	keywords = {Computational linguistics; Computer aided instruction; Data storage equipment; Reflection; Social sciences computing; Dashboard; Design and Development; International students; Language learning; Learning analytics; Ubiquitous learning; Ubiquitous learning environment; Ubiquitous learning logs; Learning systems},
	publisher = {IGI Global},
	issn = {15393100},
	language = {English},
	abbrev_source_title = {Int. J. Distance Educ. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@BOOK{Jantti2016267,
	author = {Jantti, Margie},
	title = {Libraries and big data: A new view on impact and affect},
	year = {2016},
	journal = {Quality and the Academic Library: Reviewing, Assessing and Enhancing Service Provision},
	pages = {267 – 273},
	doi = {10.1016/B978-0-12-802105-7.00026-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967361555&doi=10.1016%2fB978-0-12-802105-7.00026-9&partnerID=40&md5=aa4ab77bed0650932b81a0fae33b7c49},
	affiliations = {Library Services, University of Wollongong, Wollongong, NSW, Australia},
	abstract = {The increasing sophistication of data capture and warehousing capability within contemporary tertiary education institutions has offered new approaches for the examination of data generated from library systems and other university data sources. The University of Wollongong Library has, since 2010, sought to integrate Library usage data within enterprise reporting systems to better understand the value and impact for students using Library resources. The development of the Value Cube provided the evidence of positive correlations between use and student performance, i.e. their grades. Subsequent to the Value Cube, the Marketing Cube offers granular, near real-time usage data by a range of student dimensions, capturing patterns of behaviour and new insights into what information resources are being used and by which groups. The third milestone is the harvesting of Library usage data into the Learning Analytics dashboards and reports, creating a multifaceted view of student utilisation of critical learning systems, resources and services. © 2016 Jeremy Atkinson Published by Elsevier Ltd.},
	author_keywords = {Australia; Data warehousing; Learning analytics; Library impact; Library value; Wollongong University Library},
	publisher = {Elsevier Inc.},
	isbn = {978-012802105-7},
	language = {English},
	abbrev_source_title = {Qual. and the Acad. Libr.: Rev., Assess. and Enhanc. Serv. Provis.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@CONFERENCE{Khan2016249,
	author = {Khan, Imran and Pardo, Abelardo},
	title = {Data2U: Scalable real time student feedback in active learning environments},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {249 – 253},
	doi = {10.1145/2883851.2883911},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976520171&doi=10.1145%2f2883851.2883911&partnerID=40&md5=2567b805feb366436f61d7bd641d6f79},
	affiliations = {Faculty of Engineering and IT University of Sydney, 2006, NSW, Australia},
	abstract = {The majority of applications and products that use learning analytics to understand and improve learning experiences assume the creation of actionable items that will affect students through an intermediary. Much less focus is devoted to exploring how to provide insight directly to students. Furthermore, student engagement has always been a relevant aspect to increase the quality of a learning experience. Learning analytics techniques can be used to provide real-time insight tightly integrated with the learning outcomes directly to the students. This paper describes a case study deployed in a first year engineering course using a flipped learning strategy to explore the behavior of students interacting with a dashboard updated in real time providing indicators of their engagement with the course activities. The results show different patterns of use and their evolution throughout the experience and shed some light on how students perceived this resource. © 2016 ACM.},
	author_keywords = {Dashboard; Feedback; Learning analytics; Visualizations},
	keywords = {Artificial intelligence; Education; Feedback; Students; Visualization; Active learning environment; Dashboard; First year engineering course; Learning analytics; Learning experiences; Learning outcome; Learning strategy; Student engagement; Computer aided instruction},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 58}
}

@CONFERENCE{Corrin2015430,
	author = {Corrin, Linda and De Barba, Paula},
	title = {How do students interpret feedback delivered via dashboards?},
	year = {2015},
	journal = {ACM International Conference Proceeding Series},
	volume = {16-20-March-2015},
	pages = {430 – 431},
	doi = {10.1145/2723576.2723662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955562954&doi=10.1145%2f2723576.2723662&partnerID=40&md5=7b8f4f25f8d2ce4b0004c2eb09685994},
	affiliations = {Melbourne Centre for the Study of Higher Education, University of Melbourne, Melbourne, VIC, Australia},
	abstract = {Providing feedback directly to students on their engagement and performance in educational activities is important to supporting students' learning. However, questions have been raised whether such data representations are adequate to inform reflection, planning and monitoring of students' learning strategies. In this poster we present an investigation of how students interpret feedback delivered via learning analytics dashboards. The findings indicated that most students were able to articulate an interpretation of the feedback presented through the dashboard to identify gaps between their expected and actual performance to inform changes to their study strategies. However, there was also evidence of uncertain interpretation both in terms of the format of the visualization of the feedback and their inability to understand the connection between the feedback and their current strategies. The findings have been used to inform recommendations for ways to enhance the effectiveness of the delivery of feedback through dashboards to provide value to students in developing effective learning strategies to meet their educational goals. © Copyright 2015 ACM.},
	author_keywords = {Dashboards; Feedback; Learning Analytics; Self-Regulated Learning},
	keywords = {Education; Feedback; Learning systems; Dashboards; Data representations; Educational activities; Effective learning; Learning Analytics; Learning strategy; Planning and monitoring; Self-regulated learning; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145033417-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 62}
}

@CONFERENCE{Jeremic2017596,
	author = {Jeremic, Zoran and Kumar, Vive and Graf, Sabine},
	title = {MORPH: Supporting the integration of learning analytics at institutional level},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	pages = {596 – 597},
	doi = {10.1145/3027385.3029478},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016449251&doi=10.1145%2f3027385.3029478&partnerID=40&md5=b856996ce1f7cefefa9da8052ffa924c},
	affiliations = {School of Computing and Information Systems, Athabasca University, Canada},
	abstract = {While there is high potential in using learning analytics to provide educational institutions as well as teachers and learners with actionable information and improve learning experiences, currently only very few learning analytics tools are actually used in educational institutions. In this paper, we introduce MORPH, a platform that facilitates the integration of learning analytics modules and tools into institutional learning systems. MORPH provides a robust distributed architecture which combines batch, stream and real-time data processing using a parallel processing model to enable and support efficient processing of large amounts of data. Furthermore, it provides common management and administration features that enable the seamless integration of learning analytics research modules and tools into existing institutional learning systems. © 2017 ACM.},
	author_keywords = {Batch processing; Dashboards; Data streaming; Institutional learning environments; Learning analytics; Real-time processing},
	keywords = {Batch data processing; Computer aided instruction; Data handling; Deep neural networks; Integration; Societies and institutions; Teaching; Dashboards; Data streaming; Learning analytics; Learning environments; Realtime processing; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034870-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Brouwer2016363,
	author = {Brouwer, Natasa and Bredeweg, Bert and Latour, Sander and Berg, Alan and van der Huizen, Gerben},
	title = {Learning analytics pilot with coach2 - Searching for effective mirroring},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9891 LNCS},
	pages = {363 – 369},
	doi = {10.1007/978-3-319-45153-4_28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988521304&doi=10.1007%2f978-3-319-45153-4_28&partnerID=40&md5=14d10ab653ec2839eecec0b70d2a04f6},
	affiliations = {Education Service Center, University of Amsterdam, Amsterdam, Netherlands; Informatics Institute, University of Amsterdam, Amsterdam, Netherlands; ICT-Services, University of Amsterdam, Amsterdam, Netherlands; Perceptum B.V, Amsterdam, Netherlands},
	abstract = {Coach2 project investigated usability and effectiveness of Learning Analytics in a group of Bachelor courses in the area of Computer Science. An advanced architecture was developed and implemented, including a standalone Learning Record Store for data storage and easy access to miscellaneous data, Machine Learning techniques for determining relevant predictors, and a dashboard for informing learners. The overall approach was based on mirroring, the idea that learners see themselves operating in the context of their peers. The results were informative in terms of pro’s and con’s regarding the design and approach. The treatment showed tendencies, but finding statistical significant results turned out difficult. This paper reports on the Coach2 project. © Springer International Publishing Switzerland 2016.},
	author_keywords = {Higher education; Learning analytics; Mirroring; Usability and effectiveness},
	keywords = {Artificial intelligence; Digital storage; Engineering education; Online systems; Advanced architecture; Data storage; Higher education; Learning analytics; Learning record; Machine learning techniques; Mirroring; Usability and effectiveness; Learning systems},
	correspondence_address = {B. Bredeweg; Informatics Institute, University of Amsterdam, Amsterdam, Netherlands; email: B.Bredeweg@uva.nl},
	editor = {Verbert K. and Sharples M. and Klobučar T.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331945152-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{2017,
	title = {CEUR Workshop Proceedings},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035063533&partnerID=40&md5=a24ad7e019eab2ff8d0d8f5a04b47a7a},
	abstract = {The proceedings contain 11 papers. The topics discussed include: FutureLearn data: what we currently have, what we are learning and how it is demonstrating learning in MOOCs; the University of Southampton MOOC observatory dashboard; dynamic dashboard for educators and students in FutureLearn MOOCs: experiences and insights; discussion analytics: identifying conversations and social learners in FutureLearn MOOCs; data analytics informing MOOC continuous improvement; predicting attrition from massive open online courses in FutureLearn and edX; workshop on integrated learning analytics of MOOC post-course development; behavioral predictors of MOOC post-course development; habits of highly successful professional learners and the corresponding online curriculum; public participation in environmental stewardship after MOOCs; and engaging MOOC learners as lifelong collaborators.},
	editor = {Vigentini L. and Urrutia M.L. and Wang Y. and Paquette L.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Leitner2017293,
	author = {Leitner, Philipp and Ebner, Martin},
	title = {Development of a dashboard for learning analytics in higher education},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10296 LNCS},
	pages = {293 – 301},
	doi = {10.1007/978-3-319-58515-4_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025150783&doi=10.1007%2f978-3-319-58515-4_23&partnerID=40&md5=94b5b83a835db79544a7863fa67327e5},
	affiliations = {Institute of Interactive Systems and Data Science, Graz University of Technology, Graz, Austria; Department of Educational Technology, Graz University of Technology, Graz, Austria},
	abstract = {In this paper, we discuss the design, development, and implementation of a Learning Analytics (LA) dashboard in the area of Higher Education (HE). The dashboard meets the demands of the different stakeholders, maximizes the mainstreaming potential and transferability to other contexts, and is developed in the path of Open Source. The research concentrates on developing an appropriate concept to fulfil its objectives and finding a suitable technology stack. Therefore, we determine the capabilities and functionalities of the dashboard for the different stakeholders. This is of significant importance as it identifies which data can be collected, which feedback can be given, and which functionalities are provided. A key approach in the development of the dashboard is the modularity. This leads us to a design with three modules: the data collection, the search and information processing, and the data presentation. Based on these modules, we present the steps of finding a fitting Open Source technology stack for our concept and discuss pros and cons trough out the process. © Springer International Publishing AG 2017.},
	author_keywords = {e-Learning; Learning analytics; Learning dashboard; Open source; Technology enhanced learning},
	keywords = {E-learning; Engineering education; Human computer interaction; Data collection; Data presentation; Higher education; Learning analytics; Learning dashboard; Open sources; Open-source technology; Technology enhanced learning; Education},
	correspondence_address = {P. Leitner; Institute of Interactive Systems and Data Science, Graz University of Technology, Graz, Austria; email: philipp.leitner@tugraz.at},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331958514-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Einhardt2016,
	author = {Einhardt, Luan and Tavares, Tatiana Aires and Cechinel, Cristian},
	title = {Moodle analytics dashboard: A learning analytics tool to visualize users interactions in moodle},
	year = {2016},
	journal = {Proceedings - 2016 11th Latin American Conference on Learning Objects and Technology, LACLO 2016},
	doi = {10.1109/LACLO.2016.7751805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006868983&doi=10.1109%2fLACLO.2016.7751805&partnerID=40&md5=7100a9057cdf142aad99a1a2bc4b72ad},
	affiliations = {Technological Development Center (CDTec), Federal University of Pelotas (UFPel), Pelotas, RS, 96016-080, Brazil; Faculty of Education (FaE), Federal University of Pelotas (UFPel), Pelotas, RS, 96016-080, Brazil},
	abstract = {The present work describes the Moodle Analytics Dashboard (MAD), a tool developed to allow the visualization of students and professors logs in Moodle disciplines. MAD provides an easy way to obtain graphical visualization of several aspects related to students and professors accesses in virtual learning disciplines, thus helping professors to better follow teaching and learning process, as well as to visually identify potential at-risk students, or to better understand how the different educational resources are being used. The paper presents the theoretical foundations and the technologies used to develop MAD, together with the most important features of the tool and the first results obtained during the preliminary stages of validation. © 2016 IEEE.},
	author_keywords = {Dashboards; Interactions; Learning analytics; Logs; Moodle; Visualization},
	keywords = {Beam plasma interactions; Education; Flow visualization; Students; Visualization; Dashboards; Educational resource; Graphical visualization; Learning analytics; Logs; Moodle; Teaching and learning; Theoretical foundations; Engineering education},
	editor = {Chacon I.A. and Rivas M.C. and Cechinel C. and Alfaro A.F.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150906149-5},
	language = {Portuguese},
	abbrev_source_title = {Proceedings - Lat. Am. Conf. Learn. Objects Technol., LACLO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Vovides2016,
	author = {Vovides, Yianna and Inman, Sarah},
	title = {Elusive learning-Using learning analytics to support reflective sensemaking of ill-structured ethical problems: A learner-managed dashboard solution},
	year = {2016},
	journal = {Future Internet},
	volume = {8},
	number = {2},
	doi = {10.3390/fi8020026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006223175&doi=10.3390%2ffi8020026&partnerID=40&md5=9599ab17afaaab62bad0d9d1ba1a2e5d},
	affiliations = {Center for New Designs in Learning and Scholarship, Georgetown University, Washington, DC, 20007, United States; Learning Technology, Stevens Institute of Technology, Hoboken, 07030, NJ, United States},
	abstract = {Since the turn of the 21st century, we have seen a surge of studies on the state of U.S. education addressing issues such as cost, graduation rates, retention, achievement, engagement, and curricular outcomes. There is an expectation that graduates should be able to enter the workplace equipped to take on complex and "messy" or ill-structured problems as part of their professional and everyday life. In the context of online learning, we have identified two key issues that are elusive (hard to capture and make visible): learning with ill-structured problems and the interaction of social and individual learning. We believe that the intersection between learning and analytics has the potential, in the long-term, to minimize the elusiveness of deep learning. A proposed analytics model is described in this article that is meant to capture and also support further development of a learner's reflective sensemaking. © 2016 By The Authors.},
	author_keywords = {Deep learning; Learner-managed dashboard; Reflective sensemaking; Social concept mapping},
	keywords = {Internet; Deep learning; Ethical problems; Graduation rates; Ill-structured problems; Individual learning; Learner-managed dashboard; Sensemaking; Social concepts; Learning systems},
	correspondence_address = {Y. Vovides; Center for New Designs in Learning and Scholarship, Georgetown University, Washington, DC, 20007, United States; email: yv11@georgetown.edu},
	publisher = {MDPI AG},
	issn = {19995903},
	language = {English},
	abbrev_source_title = {Future Internet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Chou201732,
	author = {Chou, Chih-Yueh and Tseng, Shu-Fen and Chih, Wen-Chieh and Chen, Zhi-Hong and Chao, Po-Yao and Lai, K. Robert and Chan, Chien-Lung and Yu, Liang-Chih and Lin, Yi-Lung},
	title = {Open Student Models of Core Competencies at the Curriculum Level: Using Learning Analytics for Student Reflection},
	year = {2017},
	journal = {IEEE Transactions on Emerging Topics in Computing},
	volume = {5},
	number = {1},
	pages = {32 – 44},
	doi = {10.1109/TETC.2015.2501805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027675736&doi=10.1109%2fTETC.2015.2501805&partnerID=40&md5=08256373f8f6565b99548930c5e8a7a5},
	affiliations = {Dept. of Comput. Sci. and Eng., Yuan Ze Univ., Taoyuan, 320, Taiwan; Innovation Center for Big Data and Digital Convergence, Yuan Ze Univ., Taoyuan, 320, Taiwan; Department of Information Management, Yuan Ze University, Taoyuan, 320, Taiwan; Department of Information Communication, Yuan Ze University, Taoyuan, 320, Taiwan; Institute of Network Learning Technology, National Central University, Taoyuan, 320, Taiwan},
	abstract = {This paper proposes an approach for developing curriculum-level open student models. This approach entails evaluating student core competencies using the correspondence between courses and core competencies in a competency-based curriculum and students' taken courses and grades. On the basis of this approach, a curriculum-level, competency-based visualized analytic system, called visualized analytics of core competencies (VACCs), was implemented. Course-competency diagnostic tools, course work performance radar charts, and peer-based ranking tables were developed as part of the VACC analytic system for student reflection and to position their levels of core competencies. These curriculum-level open student models revealed multiple aspects of students' core competencies by monitoring the quantity and quality of courses taken by students, and evaluating students' ranks regarding core competencies compared with their classmates and graduates. VACC evaluation was conducted in this paper. The results showed that more than 70% of students reported that VACC helped in reflecting on their core competencies, assisting them in understanding the correspondence between their taken courses and core competencies, and helping them to set goals regarding taking additional courses. In addition, this paper discusses potential analytics and applications of open student models of core competencies. © 2013 IEEE.},
	author_keywords = {Computers and education; learning analytics; learning dashboards; learning technologies; open student model},
	keywords = {Curricula; Education; Planning; Radar reflection; Strategic planning; Students; Computers and education; learning analytics; learning dashboards; Learning technology; Open student models; Education computing},
	correspondence_address = {C.-Y. Chou; Dept. of Comput. Sci. and Eng., Yuan Ze Univ., Taoyuan, 320, Taiwan; email: cychou@saturn.yzu.edu.tw},
	publisher = {IEEE Computer Society},
	issn = {21686750},
	language = {English},
	abbrev_source_title = {IEEE Trans. Emerg. Top. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Vigentini20172,
	author = {Vigentini, Lorenzo and Urrutia, Manuel León and Fields, Ben},
	title = {FutureLearn data: What we currently have, what we are learning and how it is demonstrating learning in MOOCs},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1967},
	pages = {2 – 7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035052591&partnerID=40&md5=827a519e02ffb664b9ddad27b3ba0918},
	affiliations = {UNSW Sydney, Australia; University of Southampton, United Kingdom; FutureLearn, United Kingdom},
	abstract = {Compared to other platforms such as Coursera and EdX, Future-Learn is a relatively new player in the MOOC arena and received limited coverage in the Learning Analytics and Educational Data Mining research. Founded by a partnership between the Open University in the UK, the BBC, The British Library and (originally) 12 universities in the UK, FutureLearn has two distinctive features relevant to the way their data is displayed and analyzed: 1) it was designed with a specific educational philosophy in mind which focuses on the social dimension of learning and 2) every learning activity provide opportunities for formal discussion and commenting. This workshop provided an opportunity to invite contributions spanning several areas of investigation and development. The papers collated in this proceeding include: 1) the development of dashboards to support the analytical exploration of FutureLearn Data (León-Urrutia, and Vigentini), 2) the application of analytical methods to understand and improve learners' engagement and participation, especially understanding patterns of communication in FL (Chua, Tagg, Sharples and Rientes) and the comparison of FutureLearn and ED-X data to predict attrition (Cobos, Wilde and Zaluska) ; 3) an example of the use of analytics to support the future pedagogical development of FL MOOCs (Vulic, Chitsaz, Prusty and Ford). Copyright © 2017 for the individual papers by the papers' authors.},
	author_keywords = {Learning analytics; MOOCs; Visualization dashboard},
	keywords = {Binary alloys; Data mining; Teaching; Uranium alloys; Analytical method; Educational data mining; Educational philosophies; Learning analytics; MOOCs; Open universities; Patterns of communication; Social dimensions; Education},
	editor = {Vigentini L. and Urrutia M.L. and Wang Y. and Paquette L.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Guillot2016269,
	author = {Guillot, Claudia and Guillot, Rébecca and Kumar, Vive and Kinshuk},
	title = {MUSIX: Learning analytics in music teaching},
	year = {2016},
	journal = {Lecture Notes in Educational Technology},
	number = {9789812878663},
	pages = {269 – 273},
	doi = {10.1007/978-981-287-868-7_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032347901&doi=10.1007%2f978-981-287-868-7_31&partnerID=40&md5=fdee384cd3b170a7475ca7ed33a2c3e2},
	affiliations = {School of Computer Science, Athabasca University, Edmonton, Canada},
	abstract = {This chapter exposes MUSIX, an analytics tool about to be developed, that will enrich music learning and enhance the music teaching approach. MUSIX will collect data from music theory lessons, the playing of instrumental pieces, sight-singing, and vocal training, and subsequently teach and help each student through computerized analysis to better themselves. This software will offer precise instructions, exercises, games, and quizzes to fill in gaps and build a strong understanding using self-regulation and co-regulation techniques. Computer software, audio recording, and MIDI connection between the instrument and the computer are different means that will be used to track the results that will be analyzed and then displayed in a compelling dashboard. © 2016, Springer Science+Business Media Singapore.},
	author_keywords = {Audio software; E-learning; E-teaching; Human–computer interaction; Music analytics; Teaching approach},
	correspondence_address = {C. Guillot; School of Computer Science, Athabasca University, Edmonton, Canada; email: claudia.guillot@outlook.com},
	publisher = {Springer International Publishing},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Ramos-Soto2017177,
	author = {Ramos-Soto, Alejandro and Vazquez-Barreiros, Borja and Bugarín, Alberto and Gewerc, Adriana and Barro, Senen},
	title = {Evaluation of a Data-To-Text System for Verbalizing a Learning Analytics Dashboard},
	year = {2017},
	journal = {International Journal of Intelligent Systems},
	volume = {32},
	number = {2},
	pages = {177 – 193},
	doi = {10.1002/int.21835},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978141995&doi=10.1002%2fint.21835&partnerID=40&md5=082c388025ad74a7a1d446c9a83c422c},
	affiliations = {Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; Departamento de Didáctica e Organización Escolar, Universidade de Santiago de Compostela, Santiago de Compostela, Spain},
	abstract = {The SoftLearn Activity Reporter is a data-to-text service, which automatically generates textual reports about the activity developed by students within the SoftLearn virtual learning environment. In this paper, we describe the conception of the service, its architecture, and its subsequent evaluation by an expert pedagogue, where 20 full reports generated from real data from an undergraduate course supported by the SoftLearn platform were assessed. Results show that the automatically generated reports are a valuable complementary tool for explaining teachers and students the information comprised in a learning analytics dashboard. © 2016 Wiley Periodicals, Inc.},
	keywords = {Education; Teaching; Automatically generated; Complementary tools; ITS architecture; Undergraduate Courses; Virtual learning environments; Computer aided instruction},
	correspondence_address = {A. Ramos-Soto; Centro Singular de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; email: alejandro.ramos@usc.es},
	publisher = {John Wiley and Sons Ltd},
	issn = {08848173},
	coden = {IJISE},
	language = {English},
	abbrev_source_title = {Int J Intell Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@ARTICLE{Roberts2016,
	author = {Roberts, Lynne D. and Howell, Joel A. and Seaman, Kristen and Gibson, David C.},
	title = {Student attitudes toward learning analytics in higher education: "The fitbit version of the learning world"},
	year = {2016},
	journal = {Frontiers in Psychology},
	volume = {7},
	number = {DEC},
	doi = {10.3389/fpsyg.2016.01959},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009366101&doi=10.3389%2ffpsyg.2016.01959&partnerID=40&md5=f53d1ab2f26060cae209be861e67de0a},
	affiliations = {School of Psychology and Speech Pathology, Curtin University, Perth, WA, Australia; Faculty of Health Sciences, Curtin University, Perth, WA, Australia; Curtin Institute for Computation, UNESCO Chair of Data Science in Higher Education Learning and Teaching, Curtin University, Perth, WA, Australia},
	abstract = {Increasingly, higher education institutions are exploring the potential of learning analytics to predict student retention, understand learning behaviors, and improve student learning through providing personalized feedback and support. The technical development of learning analytics has outpaced consideration of ethical issues surrounding their use. Of particular concern is the absence of the student voice in decision-making about learning analytics. We explored higher education students' knowledge, attitudes, and concerns about big data and learning analytics through four focus groups (N = 41). Thematic analysis of the focus group transcripts identified six key themes. The first theme, "Uninformed and Uncertain," represents students' lack of knowledge about learning analytics prior to the focus groups. Following the provision of information, viewing of videos and discussion of learning analytics scenarios three further themes; "Help or Hindrance to Learning," "More than a Number," and "Impeding Independence" represented students' perceptions of the likely impact of learning analytics on their learning. "Driving Inequality" and "Where Will it Stop" represent ethical concerns raised by the students about the potential for inequity, bias and invasion of privacy and the need for informed consent. A key tension to emerge was how "personal" vs. "collective" purposes or principles can intersect with "uniform" vs. "autonomous" activity. The findings highlight the need the need to engage students in the decision making process about learning analytics. © 2016 Roberts, Howell, Seaman and Gibson.},
	author_keywords = {Big data; Dashboards; Higher education; Learning analytics; Student attitudes},
	correspondence_address = {L.D. Roberts; School of Psychology and Speech Pathology, Curtin University, Perth, Australia; email: lynne.roberts@curtin.edu.au},
	publisher = {Frontiers Research Foundation},
	issn = {16641078},
	language = {English},
	abbrev_source_title = {Front. Psychol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 109; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Molenaar2017125,
	author = {Molenaar, Inge and Knoop-van Campen, Carolien},
	title = {Teacher dashboards in practice: Usage and impact},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {125 – 138},
	doi = {10.1007/978-3-319-66610-5_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029595757&doi=10.1007%2f978-3-319-66610-5_10&partnerID=40&md5=5885c3a44d53afe0bc4fdb0ac86366d6},
	affiliations = {Behavioral Research Institute, Radboud University, Montessorilaan 3, Nijmegen, Netherlands},
	abstract = {Even though the recent influx of tablets in primary education goes together with the vision that educational technologies will revolutionize education, empirical results supporting this claim are scarce. The adaptive educational technology in this research is used daily in primary classrooms and includes teacher dashboards. While students practice on the tablet, the technology displays real-time data of learner progress and performance in teacher dashboards. This study examines how teachers use the dashboards during lessons applying the Verberts’ learning analytic process model. Teacher dashboard consultations and resulting pedagogical actions were observed in mathematics lessons. In a following stimulated recall interview, a teacher was asked to elaborate on the knowledge he/she activated and his/her reasoning in interpreting the dashboard. The results indicate that teachers consult the dashboard on average 8,3 times per lesson, but great variation among teachers was found. Teachers activate existing knowledge about the class and students to interpret dashboard data. The pedagogical actions teachers take after dashboard consultation are mainly providing individual feedback and additional instruction. The results show that pedagogical actions preformed at teachers’ own initiative are mostly directed to low ability students, whereas actions after consulting the dashboard are more directed at middle and high ability students. These results indicate that extracted learning analytics, in the form of teacher dashboards are indeed influencing teachers’ pedagogical actions in daily classroom activities and may initiate behavior changes in teaching practices. © Springer International Publishing AG 2017.},
	author_keywords = {Ability levels; Dashboards; Educational technologies; Primary education},
	keywords = {Education computing; Educational technology; Students; Teaching; Ability levels; Behavior change; Classroom activity; Dashboards; Primary education; Process Modeling; Real-time data; Teaching practices; Education},
	correspondence_address = {I. Molenaar; Behavioral Research Institute, Radboud University, Nijmegen, Montessorilaan 3, Netherlands; email: i.molenaar@pwo.ru.nl},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 52}
}

@ARTICLE{Boulanger2017221,
	author = {Boulanger, David and Seanosky, Jeremie and Guillot, Rebecca and Kumar, Vivekanandan Suresh and Kinshuk},
	title = {Breadth and depth of learning analytics},
	year = {2017},
	journal = {Lecture Notes in Educational Technology},
	number = {9789811024184},
	pages = {221 – 225},
	doi = {10.1007/978-981-10-2419-1_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032331164&doi=10.1007%2f978-981-10-2419-1_30&partnerID=40&md5=8000464f683df1d3e1de9dd4546d48ea},
	affiliations = {School of Computing and Information Systems, Athabasca University, Athabasca, Canada},
	abstract = {This paper presents a learning analytics system that has been extended to address multiple domains (writing and coding) for a breadthwise expansion. The system has also been infused with analytics solutions targeting competence, grade prediction and regulation traits, thus offering deeper insights. Our experiences in extending the breadth and depth of the analytics system have been discussed. The discussion includes elaboration on two types of sensors to track the writing and the coding experiences of students. The design of a dashboard for teachers to monitor the performance of their classrooms and advocate regulation activities is also included. The discussions lean more on the side of teachers, parents, and administrators, than on the side of students. © 2017, Springer Science+Business Media Singapore.},
	author_keywords = {Coding; Competences; Dashboard; Grade prediction; Learning analytics; Regulation; Rubrics; Sensors; Teacher; Writing},
	correspondence_address = {D. Boulanger; School of Computing and Information Systems, Athabasca University, Athabasca, Canada; email: david.boulanger@dbu.onmicrosoft.com},
	publisher = {Springer International Publishing},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Mejia201753,
	author = {Mejia, Carolina and Florian, Beatriz and Vatrapu, Ravi and Bull, Susan and Gomez, Sergio and Fabregat, Ramon},
	title = {A novel web-based approach for visualization and inspection of reading difficulties on university students},
	year = {2017},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {10},
	number = {1},
	pages = {53 – 67},
	doi = {10.1109/TLT.2016.2626292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017587714&doi=10.1109%2fTLT.2016.2626292&partnerID=40&md5=8700b804c949f77d7f23187ef07deb43},
	affiliations = {FEAV, Universidad EAN, Bogota, CO 110231, Colombia; EISC, Universidad del Valle, Cali, CO 76001000, Colombia; Center for Business Data Analytics, Copenhagen Business School, Denmark; WOACT, Frederiksberg, 2000, Norway; Institute of Education, University College London, London, WC1E 6BT, United Kingdom; UMB Virtual, Universidad Manuela Beltran, Cajica, CO 250247, Colombia; IIA, University of Girona, Girona, CO 17071, Spain},
	abstract = {Existing tools aim to detect university students with early diagnosis of dyslexia or reading difficulties, but there are not developed tools that let those students better understand some aspects of their difficulties. In this paper, a dashboard for visualizing and inspecting early detected reading difficulties and their characteristics, called PADA (acronym for the Spanish name Panel de Analíticas de Aprendizaje de Dislexia en Adultos), is presented. PADA is a web-based tool designed to facilitate the creation of descriptive visualizations required for a better understanding by students about their learner model. Through information visualization techniques, PADA shows students the knowledge in their learner models in order to help them to increase their awareness and to support reflection and self-regulation about their difficulties in reading. PADA provides different learning analytics on reading performance of students, so that they can self-identify their strengths and weaknesses and self-regulate their learning. This paper describes examples that cover a variety of visualizations (bar-charts, line-charts, and pie-charts) to show user model fragments as personal details, reading profiles, learning styles, and cognitive traits of the students. We tested PADA with 26 students (aged 21-53 years) of different academic programs and levels, dyslexic and non-dyslexic. The results show that PADA can assist students in creating awareness, and help them to understand their difficulties associated with the reading tasks, as well as facilitate reflection and self-regulation in the learning process. Implications for the design of learning analytics are discussed and directions for future work are outlined. © 2008-2011 IEEE.},
	author_keywords = {Dyslexia; learning analytics solutions; open learner modeling; reading difficulties; university students},
	keywords = {Deregulation; Diagnosis; Information systems; Learning systems; Students; Visualization; Web crawler; Websites; Dyslexia; Information visualization; Learning process; Open learner modeling; reading difficulties; Reading performance; University students; Web-based approach; Education},
	correspondence_address = {C. Mejia; FEAV, Universidad EAN, Bogota, CO 110231, Colombia; email: cmejiaco@ean.edu.co},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@CONFERENCE{Olivares2015271,
	author = {Olivares, Daniel},
	title = {Exploring learning analytics for computing education},
	year = {2015},
	journal = {ICER 2015 - Proceedings of the 2015 ACM Conference on International Computing Education Research},
	pages = {271 – 272},
	doi = {10.1145/2787622.2787746},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959312863&doi=10.1145%2f2787622.2787746&partnerID=40&md5=15cd3814799aced203a685b1cad748d1},
	affiliations = {Human-Centered Environments for Learning and Programming (HELP) Lab., School of Electrical Engineering and Computer Science, Washington State University, Pullman, 99164, WA, United States},
	abstract = {Student retention in STEM disciplines is a growing problem. The number of students receiving undergraduate STEM degrees will need to increase by about 34% annually in order to meet projected needs [6]. One way to address this problem is by leveraging the emerging field of learning analytics, a data-driven approach to designing learning interventions based on continuously-updated data on learning processes and outcomes. Through an iterative, user-centered, design approach, we propose to develop a learning dashboard tailored for computing courses. The dashboard will collect, analyze, and present learning process and outcome data to instructors and students, thus providing an empirical basis for automated, teacher-initiated, and learner-initiated interventions to positively influence learning outcomes and retention. Through a series of mixed-method empirical studies, we will determine what data should be made available to instructors, how that data can be best displayed, how effective teaching interventions can be fashioned from the data, and how such interventions affect student grades and persistence in introductory computing science courses.},
	author_keywords = {Computing education; Learning analytics; Learning dashboard; Social learning theory; Social programming},
	keywords = {Computation theory; Curricula; Education; Iterative methods; Learning systems; Online conferencing; Students; Teaching; User centered design; Computing education; Learning analytics; Learning dashboard; Social learning theory; Social programming; STEM (science, technology, engineering and mathematics)},
	correspondence_address = {D. Olivares; Human-Centered Environments for Learning and Programming (HELP) Lab., School of Electrical Engineering and Computer Science, Washington State University, Pullman, 99164, United States; email: daniel.olivares@wsu.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145033628-4},
	language = {English},
	abbrev_source_title = {ICER - Proc. ACM Conf. Int. Comput. Educ. Res.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Pardos201675,
	author = {Pardos, Zachary A. and Whyte, Anthony and Kao, Kevin},
	title = {moocRP: Enabling Open Learning Analytics with an Open Source Platform for Data Distribution, Analysis, and Visualization},
	year = {2016},
	journal = {Technology, Knowledge and Learning},
	volume = {21},
	number = {1},
	pages = {75 – 98},
	doi = {10.1007/s10758-015-9268-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961285707&doi=10.1007%2fs10758-015-9268-2&partnerID=40&md5=6a0cdc81b5f32c865036adb6bf0dcf45},
	affiliations = {University of California at Berkeley, Berkeley, 94720, CA, United States; University of Michigan, Ann Arbor, MI, United States},
	abstract = {In this paper, we address issues of transparency, modularity, and privacy with the introduction of an open source, web-based data repository and analysis tool tailored to the Massive Open Online Course community. The tool integrates data request/authorization and distribution workflow features as well as provides a simple analytics module upload format to enable reuse and replication of analytics results among instructors and researchers. We survey the evolving landscape of competing established and emerging data models, all of which are accommodated in the platform. Data model descriptions are provided to analytics authors who choose, much like with smartphone app stores, to write for any number of data models depending on their needs and the proliferation of the particular data model. Two case study examples of analytics and responsive visualizations based on different data models are described in the paper. The result is a simple but effective approach to learning analytics immediately applicable to X consortium MOOCs and beyond. © 2016, Springer Science+Business Media Dordrecht.},
	author_keywords = {Dashboards; Modularization; MOOC; Open learning analytics; Reproducible research; Visualizations},
	keywords = {Modular construction; Visualization; Dashboards; Modularizations; MOOC; Open learning; Reproducible research; Data visualization},
	correspondence_address = {Z.A. Pardos; University of California at Berkeley, Berkeley, 94720, United States; email: pardos@berkeley.edu},
	publisher = {Springer Netherlands},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access}
}

@CONFERENCE{Broos2017,
	author = {Broos, Tom and Peeters, Laurie and Verbert, Katrien and Van Soom, Carolien and Langie, Greet and De Laet, Tinne},
	title = {Dashboard for actionable feedback on learning skills: How learner profile affects use},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037036605&partnerID=40&md5=2defecf048e57e568e497c35349a82cc},
	affiliations = {KU Leuven, Leuven, Belgium},
	abstract = {Learning Analytics Dashboards (LAD) provide a means to leverage data to support learners, teachers, and counselors. This paper reports on an in-depth analysis of how learners interact with a LAD. N=1,406 first-year students in 12 different study programs were invited to use a LAD to support them in their transition from secondary to higher education. The LAD provides actionable feedback about five of the learning skills assessed by the Learning and Study Strategies Inventory (LASSI): concentration, anxiety, motivation, test strategies, and time management. We logged access to and behavior within the LAD and analyzed their relationship with these learning skills. While eight out of ten students accessed the LAD, students with lower time management scores tend to have a lower click-trough rate. Once within the LAD, students with lower scores for specific learning skills are accessing the corresponding information and remediation possibilities more often. Regardless of their scores for any of the other learning skills, learners with higher motivation scores are reading the remediation possibilities for the other four learning skills more often. Gender and study program have an influence on how learners use the LAD. Our findings may help both researchers and practitioners by creating awareness about how LAD use in itself may depend on the context and profile of the learner.},
	author_keywords = {First-year; Higher education; Learning analytics dashboard; Learning skills},
	keywords = {Engineering education; Learning systems; Motivation; Students; Teaching; First year; First year students; Higher education; In-depth analysis; Learner profiles; Learning analytics dashboard; Learning skills; Specific learning; Education},
	correspondence_address = {T. Broos; KU Leuven, Leuven, Belgium; email: tom.broos@kuleuven.be},
	editor = {Prilla M. and Mikroyannidis A. and Kravcik M. and Pammer-Schindler V.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Broos201794,
	author = {Broos, Tom and Verbert, Katrien and Langie, Greet and Van Soom, Carolien and De Laet, Tinne},
	title = {Small data as a conversation starter for learning analytics: Exam results dashboard for first-year students in higher education},
	year = {2017},
	journal = {Journal of Research in Innovative Teaching and Learning},
	volume = {10},
	number = {2},
	pages = {94 – 106},
	doi = {10.1108/JRIT-05-2017-0010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204682516&doi=10.1108%2fJRIT-05-2017-0010&partnerID=40&md5=f6b7e64159dd7156507f58453115e42c},
	affiliations = {Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Tutorial services, Faculty of Engineering Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Computer Science, Faculty of Engineering Science, Katholieke Universiteit Leuven, Leuven, Belgium; Faculty of Engineering Technology, Katholieke Universiteit Leuven, Leuven, Belgium; Faculty of Science, Katholieke Universiteit Leuven, Leuven, Belgium; Faculty of Engineering Science, Katholieke Universiteit Leuven, Leuven, Belgium},
	abstract = {Purpose: The purpose of this paper is to draw attention to the potential of “small data” to complement research in learning analytics (LA) and to share some of the insights learned from this approach. Design/methodology/approach: This study demonstrates an approach inspired by design science research, making a dashboard available to n=1,905 students in 11 study programs (used by n=887) to learn how it is being used and to gather student feedback. Findings: Students react positively to the LA dashboard, but usage and feedback differ depending on study success. Research limitations/implications: More research is needed to explore the expectations of a high-performing student with regards to LA dashboards. Originality/value: This publication demonstrates how a small data approach to LA contributes to building a better understanding. © 2017, Tom Broos, Katrien Verbert, Greet Langie, Carolien Van Soom and Tinne De Laet.},
	author_keywords = {Case study; Dashboard; First-year students; Higher education; Learning analytics; Small data},
	correspondence_address = {T. Broos; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; email: tom.broos@kuleuven.be},
	publisher = {Emerald Publishing},
	issn = {23977604},
	language = {English},
	abbrev_source_title = {J. Res. Innov. Teach. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Kickmeier-Rust201551,
	author = {Kickmeier-Rust, Michael D. and Albert, Dietrich},
	title = {Visualizing the structure of learning},
	year = {2015},
	journal = {CEUR Workshop Proceedings},
	volume = {1599},
	pages = {51 – 62},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977593178&partnerID=40&md5=ae7108d06fa762d5d6f101fa6370b1ed},
	affiliations = {Knowledge Technologies Institute, Graz University of Technology, Graz, 8010, Austria},
	abstract = {Learning analytics means gathering a broad range of data, bringing the various sources together, and analyzing them. However, to draw educational insights from the results of the analyses, these results must be visualized and presented to the educators and learners. This task is often accomplished by using dashboards equipped with conventional and often simple visualizations such as bar charts or traffic lights. In this paper we want to introduce a method for utilizing the strengths of directed graphs, namely Hasse diagrams, and a competence- oriented approach of structuring knowledge and learning domains. After a brief theoretical introduction, this paper highlights and discusses potential advantages and gives an outlook to recent challenges for research.},
	author_keywords = {Competencebased knowledge space theory; Data visualization; Hasse diagram; Learning analytics},
	keywords = {Directed graphs; Graphic methods; Visualization; Bar chart; Hasse diagrams; Knowledge space theory; Learning analytics; Structuring knowledge; Traffic light; Data visualization},
	editor = {Crespo-Garcia R.M. and Universidad Carlos III de Madrid, Department of Telematic Engineering, Avda de la Universidad, 30, Leganes and Munoz-Merino P.J. and Universidad Carlos III de Madrid, Department of Telematic Engineering, Avda de la Universidad, 30, Leganes and Kloos C.D. and Universidad Carlos III de Madrid, Department of Telematic Engineering, Avda de la Universidad, 30, Leganes and Alario-Hoyos C. and Universidad Carlos III de Madrid, Department of Telematic Engineering, Avda de la Universidad, 30, Leganes},
	publisher = {CEUR-WS},
	issn = {16130073},
	isbn = {978-848931596-9},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chitsaz2016116,
	author = {Chitsaz, Mahsa and Vigentini, Lorenzo and Clayphan, Andrew},
	title = {Toward the development of a dynamic dashboard for FutureLearn MOOCs: Insights and directions},
	year = {2016},
	journal = {ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
	pages = {116 – 121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035046985&partnerID=40&md5=20d1bc42fcac6767250d0696aaac5640},
	affiliations = {PVC (Education), UNSW, Australia},
	abstract = {In recent years, many higher education institutions have invested in the development of Massive Open Online Courses (MOOCs). With the increase of available MOOC data, there is an opportunity to provide insights to educators and developers into learners’ behaviors through learning analytics. Focusing on the FutureLearn platform (FL), standardized data files are offered to partner institutions. Additionally, a report is offered to stakeholders, but it is limited in a number of ways: it is static, it is limited in presenting relevant information and, most importantly, it does not provide ‘real-time’ access to data. This paper provides an overview of the rationale and the development process of a dynamic and near real-time dashboard. It explores the viability of different types of visualizations with the available data, lessons learned, comparisons with similar efforts, and future directions are discussed. © 2016 Deakin University. All Rights Reserved.},
	author_keywords = {Dashboards; FutureLearn MOOCs; Learning analytics; Sense-making; Visualizations},
	keywords = {Visualization; Dashboards; Development process; FutureLearn MOOCs; Higher education institutions; Learning analytics; Massive open online course; Partner institutions; Sense making; Educational technology},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	language = {English},
	abbrev_source_title = {ASCILITE - Conf. Proc. - Int. Conf. Innov., Pract. Res. Use Educ. Technol. Tert. Educ.: Show Me Learn.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Muñoz-Cristóbal201615,
	author = {Muñoz-Cristóbal, Juan A. and Rodríguez-Triana, María Jesús and Gallego-Lema, Vanesa and Arribas-Cubero, Higinio F. and Martínez-Monés, Alejandra and Asensio-Pérez, Juan I.},
	title = {Toward the integration of monitoring in the orchestration of across-spaces learning situations},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1601},
	pages = {15 – 21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977656728&partnerID=40&md5=b3b8b31cc9a7a8229dc24a126b307c88},
	affiliations = {Universidad de Valladolid, Spain; École Polytechnique Fédérale de Lausanne, Switzerland},
	abstract = {Technologies such as augmented Reality (AR), 3D Virtual Worlds (3DVWs) and mobile phones are extending education to other spaces beyond the classroom or the Virtual Learning Environments (VLEs). However, the richness of across-spaces learning situations that could be conducted in all these spaces is hampered by the difficulties (encompassed under the "orchestration" metaphor) that teachers face to carry them out. Monitoring can help in such orchestration, and it has been highly explored in face-to-face and blended learning. Nevertheless, in ubiquitous environments it is usually limited to activities taking place in a specific type of space (e.g., outdoors). In this paper we propose an orchestration system which supports the monitoring of learning situations that may involve web, AR-enabled physical and 3DVW spaces. The proposal was evaluated in three authentic studies, in which a prototype of the system provided monitoring through a web dashboard, an AR app, and a Virtual Globe. © Copyright 2016 for this paper by its authors.},
	author_keywords = {Across-spaces; Augmented Reality; Learning analytics; Monitoring; Virtual Worlds; VLE},
	keywords = {Augmented reality; Cellular telephone systems; Computer aided instruction; Monitoring; Teaching; Virtual reality; 3d virtual worlds; Across-spaces; Blended learning; Learning analytics; Learning situation; Ubiquitous environments; Virtual learning environments (VLEs); Virtual worlds; E-learning},
	editor = {Martinez-Maldonado R. and Hernandez-Leo D.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Ruiz-Calleja201679,
	author = {Ruiz-Calleja, Adolfo and Dennerlein, Sebastian and Ley, Tobias and Lex, Elisabeth},
	title = {Visualizing workplace learning data with the SSS dashboard},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1601},
	pages = {79 – 86},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977645430&partnerID=40&md5=7727fd9ca1a054108ef9b02795cf02a2},
	affiliations = {Tallinn University, Estonia; Graz University of Technology, Austria},
	abstract = {This paper reports the design and development of a visual Dashboard, called the SSS Dashboard, which visualizes data from informal workplace learning processes from different viewpoints. The SSS Dashboard retrieves its data from the Social Semantic Server (SSS), an infrastructure that integrates data from several workplace learning applications into a semantically-enriched Artifact-Actor Network. A first evaluation with end users in a course for professional teachers gave promising results. Both a trainer and a learner could understand the learning process from different perspectives using the SSS Dashboard. The results obtained will pave the way for the development of future Learning Analytics applications that exploit the data collected by the SSS. © Copyright 2016 for this paper by its authors.},
	author_keywords = {Data visualization; Social semantic data; Workplace learning analytics},
	keywords = {Data visualization; Semantics; Teaching; Actor-network; Design and Development; End users; ITS data; Learning process; Social semantics; Workplace learning; Learning systems},
	editor = {Martinez-Maldonado R. and Hernandez-Leo D.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{León-Urrutia20178,
	author = {León-Urrutia, Manuel and Tang, Darron},
	title = {The university of Southampton MOOC observatory dashboard},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1967},
	pages = {8 – 19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035062709&partnerID=40&md5=0fc846fc3b4093c53aef74d3cb800b8b},
	affiliations = {University of Southampton, University Road, SO172BJ, United Kingdom},
	abstract = {The University of Southampton MOOC Observatory Dashboard (UoSMOD) is an application that visualises near-to-real time data from Future-Learn courses. The intended end users of this tool are those who are involved in MOOC development and delivery such as mentors, educators, learning designers, researchers, programme leaders, and marketing officers. These different stakeholders (mentors, educators, learning designers, etc) are beneficiaries of different features of UoSMOD, who use them for different purposes. The tool downloads the data dumps that FutureLearn provides to their partners every 24 hours, and scrapes the courses metadata from the administration site of the platform. The data is managed in a MySQL database, and an R based environment called Shiny is used for its analysis and visualisation. These visualisations have been presented to mentors and learning designers. New features have been being added as a response to the feedback provided by its first users. Further iterations are in the pipeline, in this process of optimising a tool that exploits the data available in the most usable way as possible. Copyright © 2017 for the individual papers by the papers' authors.},
	author_keywords = {Dashboards; Learning analytics; MOOCs; Visualisation},
	keywords = {Curricula; Observatories; Visualization; Dashboards; End users; Learning analytics; MOOCs; MySQL database; Real-time data; University of Southampton; Education},
	editor = {Vigentini L. and Urrutia M.L. and Wang Y. and Paquette L.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{20161,
	title = {11th European Conference on Technology Enhanced Learning, EC-TEL 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9891 LNCS},
	pages = {1 – 685},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988468567&partnerID=40&md5=4e4dee742fede15f781bda93d39bb4cc},
	abstract = {The proceedings contain 90 papers. The special focus in this conference is on Adaptive and Adaptable Learning. The topics include: A semantic-driven model for ranking digital learning objects based on diversity in the user comments; social facilitation due to online inter-classrooms tournaments; creating effective learning analytics dashboards; retrieval practice and study planning in MOOCs; effects on performance, attitudes and perceptions in high school algebra; argumentation identification for academic support in undergraduate writings; mobile grading paper-based programming exams; discouraging gaming the system through interventions of an animated pedagogical agent; multi-device territoriality to support collaborative activities; implementation and findings from the E-learning domain; refinement of a Q-matrix with an ensemble technique based on multi-label classification algorithms; a peer evaluation tool of learning designs; learning in the context of manuskills; attracting youth to manufacturing through TEL; examining the effects of social media in co-located classrooms; a case study based on SpeakUp; inferring student attention with ASQ; chronicle of a scenario graph; assessing learner-constructed conceptual models and simulations of dynamic systems; exploring benefits of meaning making in a collaborative learning task at the workplace; improving usage of learning designs by teachers; scalable method enabling collaboration in the classroom; combining adaptive learning with learning analytics; evaluating the effectiveness of an affective tutoring agent in specialized education; requirements for Collaborative OER authoring tools in global settings and virtual reality for training doctors to break bad news.},
	editor = {Verbert K. and Sharples M. and Klobučar T.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331945152-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Schmitz2017209,
	author = {Schmitz, Marcel and van Limbeek, Evelien and Greller, Wolfgang and Sloep, Peter and Drachsler, Hendrik},
	title = {Opportunities and challenges in using learning analytics in learning design},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {209 – 223},
	doi = {10.1007/978-3-319-66610-5_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029573797&doi=10.1007%2f978-3-319-66610-5_16&partnerID=40&md5=466307a6eda9d951b25f147813417dd1},
	affiliations = {Zuyd University of Applied Sciences, Nieuw Eyckholt 300, Heerlen, 6419 AT, Netherlands; Vienna University of Education, Vienna, Austria; Open University, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; Goethe University, Frankfurt, Germany; German Institute for International Educational Research (DIPF), Frankfurt, Germany},
	abstract = {Educational institutions are designing, creating and evaluating courses to optimize learning outcomes for highly diverse student populations. Yet, most of the delivery is still monitored retrospectively with summative evaluation forms. Therefore, improvements to the course design are only implemented at the very end of a course, thus missing to benefit the current cohort. Teachers find it difficult to interpret and plan interventions just-in-time. In this context, Learning Analytics (LA) data streams gathered from ‘authentic’ student learning activities, may provide new opportunities to receive valuable information on the students’ learning behaviors and could be utilized to adjust the learning design already “on the fly” during runtime. We presume that Learning Analytics applied within Learning Design (LD) and presented in a learning dashboard provide opportunities that can lead to more personalized learning experiences, if implemented thoughtfully. In this paper, we describe opportunities and challenges for using LA in LD. We identify three key opportunities for using LA in LD: (O1) using on demand indicators for evidence based decisions on learning design; (O2) intervening during the run-time of a course; and, (O3) increasing student learning outcomes and satisfaction. In order to benefit from these opportunities, several challenges have to be overcome. Following a thorough literature review, we mapped the identified opportunities and challenges in a conceptual model that considers the interaction of LA in LD. © Springer International Publishing AG 2017.},
	author_keywords = {Feedback; Learning analytics; Learning dashboards; Learning design; Meta-cognitive competences; Reflection},
	keywords = {Curricula; Education computing; Embedded systems; Feedback; Reflection; Students; Teaching; Educational institutions; Evidence- based decisions; Learning analytics; Learning dashboards; Learning designs; Metacognitives; Personalized learning; Student learning outcomes; Education},
	correspondence_address = {M. Schmitz; Zuyd University of Applied Sciences, Heerlen, Nieuw Eyckholt 300, 6419 AT, Netherlands; email: marcel.schmitz@zuyd.nl},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36}
}

@CONFERENCE{Park2017326,
	author = {Park, Yun-Gon and Cho, Yong-Sang and Son, Jeong-Eun},
	title = {Design of a learning analytics dashboard based on digital textbooks and online learning},
	year = {2017},
	journal = {ICCE 2017 - 25th International Conference on Computers in Education: Technology and Innovation: Computer-Based Educational Systems for the 21st Century, Workshop Proceedings},
	pages = {326 – 334},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054180501&partnerID=40&md5=0227f7ef16783d805c3784b431b4b01d},
	affiliations = {Korea Education and Research Information Service, South Korea},
	abstract = {In general, online learning provides functions such as access to video and learning materials, assessments what learners have learned, and participation in community activities. However, it is difficult to provide a learning environment that meets the achievement level or needs for each learner by providing such a function, and it is especially limited to prescribe in a proper situation. Learning analytics, which has received much attention in recent years, provides a tool to collect and analyze learning activity data. Since the process of collecting and analyzing data is generally performed in the system, the information presented by the analysis results is very important as an interface that users meet. Therefore, research on how teachers and students design intuitively to understand results and messages from data analysis bas a great implication on the place of learning analytics. This study introduces the process of designing a dashboard on users' requirements to intuitively express the collected data based on digital textbooks and online learning. © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.},
	author_keywords = {Dashboard; Digital textbook; Learning analytics; Online learning; Visualization},
	keywords = {Computer aided instruction; Design; Educational technology; Engineering research; Flow visualization; Learning systems; Teaching; Textbooks; Community activities; Dashboard; Digital textbooks; Learning Activity; Learning analytics; Learning environments; Learning materials; Online learning; E-learning},
	correspondence_address = {J.-E. Son; Korea Education and Research Information Service, South Korea; email: sje2335@keris.or.kr},
	editor = {Hayashi Y. and Supnithi T. and Mathews M. and Wong S.L. and Mohd Ayub A.F. and Mitrovic A. and Chen W. and Yang J.-C.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-986940122-7},
	language = {English},
	abbrev_source_title = {ICCE - Int. Conf. Comput. Educ.: Technol. Innov.: Comput.-Based Educ. Syst. 21st Century, Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Lu2017106,
	author = {Lu, Owen H.T. and Huang, Anna Y.Q. and Huang, Jeff C.H. and Huang, Chester S.J. and Yang, Stephen J.H.},
	title = {Early-Stage Engagement: Applying Big Data Analytics on Collaborative Learning Environment for Measuring Learners' Engagement Rate},
	year = {2017},
	journal = {Proceedings - 5th International Conference on Educational Innovation through Technology, EITT 2016},
	pages = {106 – 110},
	doi = {10.1109/EITT.2016.28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015727632&doi=10.1109%2fEITT.2016.28&partnerID=40&md5=6d0b499003af6185fb1e023854c58053},
	affiliations = {Department of Computer Science and Information Engineering, National Central University, Taiwan; Department of Computer Science and Information Engineering, Hwa Hsia University of Technology, Taiwan},
	abstract = {Computer-supported Collaborative Learning (CSCL) is a pedagogical strategy associated with how learners construct knowledge with a group by computer-based learning system. In recent years, most of the computer-based learning systems record the interaction log of each learner when developing course assignments. However, the recorded data is facing a challenge to expose the learners behaviors during the course and to design a computer-supported collaborative learning activity. To address those challenges in this paper, a novel collaborative programming tool called Software Project Development and Insight Learning Environment (SPDI Learning Environment) is described. The SPDI Learning environment allows learners of computer science to develop course assignments collaboratively. Besides, it allows instructors to investigate the learners behaviors by associating a web-based integrated development environment (IDE) with Big Data analysis pipeline and Visualization Dashboard. In addition to collect real data from courses, we designed learning activities to help teachers to engage the field of CSCL and Learning Analytics. © 2016 IEEE.},
	author_keywords = {Big-Data Analysis; Clickstream Data; Collaborative Programming; Computer-supported Collaborative Learning; Learning Analytics},
	keywords = {Big data; Computer aided instruction; Computer programming; Computer supported cooperative work; Curricula; Data handling; Data visualization; Deep neural networks; Education; Engineering research; Information analysis; Learning systems; Teaching; Clickstream data; Collaborative learning environment; Collaborative programming; Computer Supported Collaborative Learning; Computer-based learning systems; Integrated development environment; Learning Analytics; Pedagogical strategies; E-learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150906138-9},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Educ. Innov. Technol., EITT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Schwendimann2016532,
	author = {Schwendimann, Beat A. and Rodríguez-Triana, María Jesús and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
	title = {Understanding learning at a glance: An overview of learning dashboard studies},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {532 – 533},
	doi = {10.1145/2883851.2883930},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976507952&doi=10.1145%2f2883851.2883930&partnerID=40&md5=e854df569b89228218dd94170219b420},
	affiliations = {CHILI Group, EPFL, Station 20, Lausanne, 1015, Switzerland; REACT Group, EPFL, Station 9, Lausanne, 1015, Switzerland},
	abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the fnal analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dash-board design options. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Dashboards; Educational data mining; Information VI- sualization; Learning analytics; Systematic reVIew},
	keywords = {Education; Enterprise resource planning; Dashboards; Educational data mining; Information VI- sualization; Learning analytics; Systematic Review; Data mining},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; All Open Access, Green Open Access}
}

@ARTICLE{Popescu201762,
	author = {Popescu, Paultefan and Mihăescu, Cristian and Popescu, Elvira and Mocanu, Mihai},
	title = {Generating Alerts for Drops in Student Activity Levels in a Social Learning Environment},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10473 LNCS},
	pages = {62 – 71},
	doi = {10.1007/978-3-319-66733-1_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030094772&doi=10.1007%2f978-3-319-66733-1_7&partnerID=40&md5=1c6fef26d533126643831ea9f5485548},
	affiliations = {Computers and Information Technology Department, University of Craiova, Craiova, Romania},
	abstract = {Monitoring students’ activity in a social learning environment is an important issue both for students and teachers. Providing learners with notifications whenever their activity level drops has the potential to increase their motivation and engagement. This paper tackles the issue of accurately pointing when a student has a drop or an increase in activity in the context of a social learning environment. We designed and implemented a data analysis framework which generates statistical dashboards based on aggregated student activity on three social media tools (blog, wiki and microblogging tool); alerts are subsequently issued in case of a significant decrease in activity. Experimental results obtained on student data collected over the course of five years reveal a pattern regarding the average number of generated alerts. Therefore our system can be successfully used by the instructor to easily configure the number of alerts issued to the students. © 2017, Springer International Publishing AG.},
	author_keywords = {Activity trend; Learner tracking; Learning analytics; Social media},
	keywords = {Computer aided instruction; Drops; E-learning; Social networking (online); Students; Teaching; Websites; Analysis frameworks; Learner tracking; Learning analytics; Motivation and engagements; Social learning; Social media; Social media tools; Statistical dashboards; Education},
	correspondence_address = {P. Popescu; Computers and Information Technology Department, University of Craiova, Craiova, Romania; email: spopescu@software.ucv.ro},
	editor = {Manjon B.F. and Xie H. and Popescu E. and Hancke G.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966732-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ha2015371,
	author = {Ha, Kunhee and Jo, Il-Hyun and Lim, Sohye and Park, Yeonjeong},
	title = {Tracking students’ eye-movements on visual dashboard presenting their online learning behavior patterns},
	year = {2015},
	journal = {Lecture Notes in Educational Technology},
	number = {9783662441879},
	pages = {371 – 376},
	doi = {10.1007/978-3-662-44188-6_51},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032363791&doi=10.1007%2f978-3-662-44188-6_51&partnerID=40&md5=6f9be40fedf38899f7ba28074975af93},
	affiliations = {College of Education, Ewha Womans University, Seoul, South Korea; College of Social Sciences, Ewha Womans University, Seoul, South Korea},
	abstract = {This study aims to investigate students’ reactions and perceptions to the Learning Analytics Dashboard (LAD). LAD was designed and developed by researchers to present students’ online learning activity in a visualized display. An eye tracking system was incorporated to measure students’ eye-movement, including eye fixation, saccade and their sub derivatives on LAD. The results are derived from the data-mining of what the eye-tracking system generates. This study is expected to support a smart learning environment, where students can effectively monitor their online behavior patterns in real-time using their mobile devices. Students can utilize such information to change their learning patterns, and improve performance. © 2015, Springer-Verlag Berlin Heidelberg.},
	author_keywords = {Dashboard; Eye-tracking; Learning analytics; Smart learning},
	correspondence_address = {Y. Park; College of Education, Ewha Womans University, Seoul, South Korea; email: ypark78@ewha.ac.kr},
	publisher = {Springer International Publishing},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Sahin2017255,
	author = {Sahin, Muhittin and Yurdugül, Halil},
	title = {The framework of intervention engine based on learning analytics},
	year = {2017},
	journal = {14th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2017},
	pages = {255 – 258},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055960817&partnerID=40&md5=3bffefa3cc3b9583b0e54a1005f0c9e5},
	affiliations = {Hacettepe University, Faculty of Education, Department of Computer Education and Instructional Technology, Ankara, Turkey},
	abstract = {Learning analytics primarily deals with the optimization of learning environments and the ultimate goal of learning analytics is to improve learning and teaching efficiency. Studies on learning analytics seem to have been made in the form of adaptation engine and intervention engine. Adaptation engine studies are quite widespread, but intervention engine work has been seen to studies very few. For the intervention engine studies, it was generally determined that interventions were made with feedback and dashboards. The aim of this study is to reveal an intervention engine framework which is based on learning analytics. Within this framework, a system design has been put forward which can provide instructional, supportive and motivational interventions to learners. These interventions are based on both the learning outputs of the learners and their learning experiences. Instructional interventions are planned to be based on learning outputs, supportive and motivational interventions are based on learning experiences. © 2017.},
	author_keywords = {Intervention engine; Learner experience; Learner output; Learning analytics},
	keywords = {Computer aided instruction; E-learning; Engines; Adaptation engines; Instructional interventions; Learner experience; Learner output; Learning analytics; Learning and teachings; Learning environments; Learning experiences; Learning systems},
	editor = {Spector J.M. and Ifenthaler D. and Ifenthaler D. and Sampson D.G. and Isaias P. and Rodrigues L.},
	publisher = {IADIS Press},
	isbn = {978-989853368-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Kloos2016,
	author = {Kloos, Carlos Delgado and Alario-Hoyos, Carlos and Fernández-Panadero, Carmen and Estévez-Ayres, Iria and Muñoz-Merino, Pedro J. and Cobos, Ruth and Moreno, Jaime and Tovar, Edmundo and Cabedo, Rosa and Piedra, Nelson and Chicaiza, Janneth and López, Jorge},
	title = {EMadrid project: MOOCs and learning analytics},
	year = {2016},
	journal = {2016 International Symposium on Computers in Education, SIIE 2016: Learning Analytics Technologies},
	doi = {10.1109/SIIE.2016.7751870},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006790066&doi=10.1109%2fSIIE.2016.7751870&partnerID=40&md5=87a8b1329e2278e7d55e4103ed8bd300},
	affiliations = {Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Spain; Departamento de Ingeniería Informática, Universidad Autónoma de Madrid, Spain; Escuela de Ingeniería Informática, Universidad Politécnica de Madrid, Spain; Universidad Técnica Particular de Loja, Ecuador},
	abstract = {Both, MOOCs and learning analytics, are two emergent topics in the field of educational technology. This paper shows the main contributions of the eMadrid network in these two topics during the last years (2014-2016), as well as the planned future works in the network. The contributions in the field of the MOOCs include the design and authoring of materials, the improvement of the peer review process or experiences about teaching these courses and institutional adoption. The contributions in the field of learning analytics include the inference of higher level information, the development of dashboards, the evaluation of the learning process, or the prediction and clustering. © 2016 IEEE.},
	author_keywords = {education; educational; learning analytics; MOOCs; technologies},
	keywords = {Curricula; Education; Educational technology; Teaching; Technology; educational; Higher-level information; learning analytics; Learning process; MOOCs; Peer-review process; Engineering education},
	editor = {Mendes A.J. and Garcia-Penalvo F.J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150904596-9},
	language = {English},
	abbrev_source_title = {Int. Symp. Comput. Educ., SIIE: Learn. Anal. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Atapattu2016276,
	author = {Atapattu, Thushari and Falkner, Katrina and Tarmazdi, Hamid},
	title = {Topic-wise classification of MOOC discussions: A visual analytics approach},
	year = {2016},
	journal = {Proceedings of the 9th International Conference on Educational Data Mining, EDM 2016},
	pages = {276 – 281},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013344309&partnerID=40&md5=a0541b65a9d1906402932290f9e3474a},
	affiliations = {School of Computer Science, University of Adelaide, Adelaide, Australia},
	abstract = {With a goal of better understanding the online discourse within the Massive Open Online Course (MOOC) context, this paper presents an open source visualisation dashboard developed to identify and classify emergent discussion topics (or themes). As an extension to the authors’ previous work in identifying key topics from MOOC discussion contents, this work visualises lecture-related discussions as a graph of relationships between topics and threads. We demonstrate the visualisation using three popular MOOCs offered during 2013. This work facilitates the course staff to locate and navigate the most influential topic clusters as well as the discussions that require intervention by connecting the topics with the corresponding weekly lectures. Further, we demonstrate how our interactive visualisation can be used to explore correlation between discussion topics and other variables such as views, posts, votes, and instructor intervention. © 2016 International Educational Data Mining Society. All rights reserved.},
	author_keywords = {Discussion forum; Learning analytics; MOOC; Online discourse; Topic model; Visualisation},
	keywords = {Visualization; Discussion forum; Learning analytics; MOOC; Online discourse; Topic Modeling; Data mining},
	editor = {Barnes T. and Chi M. and Feng M.},
	publisher = {International Educational Data Mining Society},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Educ. Data Min., EDM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28}
}

@CONFERENCE{De Freitas2017429,
	author = {De Freitas, Sara and Irving, Leah and Verbert, Katrien and Gibson, David and Star, Kam and Alvarez, Victor and Charleer, Sven},
	title = {How to use gamified dashboards and learning analytics for providing immediate student feedback and performance tracking in higher education},
	year = {2017},
	journal = {26th International World Wide Web Conference 2017, WWW 2017 Companion},
	pages = {429 – 434},
	doi = {10.1145/3041021.3054175},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037060334&doi=10.1145%2f3041021.3054175&partnerID=40&md5=5a245b0f76da0fdc67d2c6f1c5cb761a},
	affiliations = {Office of the Pro-Vice Chancellor, Learning and Teaching, Murdoch University, Perth, Australia; Office of Teaching and Learning, Curtin University, Perth, Australia; Department of Computer Science, KU Leuven, Belgium; Playgen, Gaminomics, London, United Kingdom},
	abstract = {With the wide use of the Internet and digital data sources, there has been a recent emergence of easy access to student data within learning management systems (LMS), grade data through student information systems (SIS) and broader sector data through benchmarking metrics and standards. Learning analytics on top of this data has introduced greater capabilities for improving student performance through immediate feedback. Current literature considers the role of dashboards for student performance and feedback, but few papers consider the efficacy of fast feedback to students or other ways that information can be fed back to learners. In this paper, we consider the work done by three leading groups addressing the impact of gamification in university education, with a specific focus on how data is presented to the learner, that is using elements such as points, levelling up, narrative and progression to scaffold learning. Results indicate increases in student motivation, engagement, satisfaction, retention and performance enhancements. © 2017 International World Wide Web Conference Committee (IW3C2), published under Creative Commons CC BY 4.0 License.},
	author_keywords = {Dashboards; Game-based learning; Higher education; Learning analytics; Serious games},
	keywords = {Gamification; Information management; Scaffolds; Serious games; World Wide Web; Dashboards; Game-based Learning; Higher education; Learning analytics; Learning management system; Performance enhancements; Performance tracking; University education; Students},
	publisher = {International World Wide Web Conferences Steering Committee},
	isbn = {978-145034914-7},
	language = {English},
	abbrev_source_title = {Int. World Wide Web Conf. , WWW Companion},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@CONFERENCE{Pesare201626,
	author = {Pesare, Enrica and Roselli, Teresa and Rossano, Veronica},
	title = {Visualizing student engagement in e-learning environment},
	year = {2016},
	journal = {Proceedings - DMS 2016: 22nd International Conference on Distributed Multimedia Systems},
	pages = {26 – 33},
	doi = {10.18293/DMS2016-028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014322881&doi=10.18293%2fDMS2016-028&partnerID=40&md5=a08c3ca2cc7ddcfcc2176ee3e1db6829},
	affiliations = {Dipartimento di Informatica, Università degli Studi di Bari Aldo Moro, Bari, Italy},
	abstract = {The learning assessment in e-learning contexts is one of the latest challenges for educational technology researchers. One of the main issues to be addressed is the definition of dimensions that should be used to measure the learning effectiveness. In this perspective, the research work aims at defining the engagement indicators useful to assess the active participation of students in social learning environments. Moreover, the paper presents the design and implementation of Learning Dashboards aimed at visualizing the student engagement in online communities where the engagement and involvement of students are the key factors for successful learning.},
	author_keywords = {Assessment; Engagement; Learning analytics; Learning Dashboard; Social learning environments},
	keywords = {E-learning; Multimedia systems; Online systems; Students; Assessment; Engagement; Learning analytics; Learning Dashboard; Social learning; Computer aided instruction},
	publisher = {Knowledge Systems Institute Graduate School},
	isbn = {1891706403; 978-189170640-0},
	language = {English},
	abbrev_source_title = {Proc. - DMS: Int. Conf. Distrib. Multimed. Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access}
}

@CONFERENCE{Leeuwen2017805,
	author = {Leeuwen, Anouschka Van},
	title = {Teacher regulation of collaborative learning: Research directions for learning analytics dashboards},
	year = {2017},
	journal = {Computer-Supported Collaborative Learning Conference, CSCL},
	volume = {2},
	pages = {805 – 806},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049140406&partnerID=40&md5=ad4bbbe3396b2640a2b2012e8d9b4e52},
	affiliations = {Ruhr-Universität Bochum, Germany},
	abstract = {Learning analytics, the measurement and reporting of data about learners, has been advocated as a support tool for teacher regulation of collaborative learning. More specifically, so called Teacher Dashboards are currently being developed to support teachers. The aim of this poster is to provide a theoretical framing of Teacher Dashboards and to discuss the state of the art in this field. As such, this poster also contributes to formulating an agenda for future research. © ISLS.},
	keywords = {Computer science; Computers; Collaborative learning; State of the art; Support tool; E-learning},
	editor = {Smith null and Borge M. and Mercier E. and Lim K.Y.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {15734552},
	isbn = {978-099035502-1},
	language = {English},
	abbrev_source_title = {Comput. -Supported Collab. Learn. Conf., CSCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Sedrakyan2017224,
	author = {Sedrakyan, Gayane and Leony, Derick and Muñoz-Merino, Pedro J. and Kloos, Carlos Delgado and Verbert, Katrien},
	title = {Evaluating student-facing learning dashboards of affective states},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {224 – 237},
	doi = {10.1007/978-3-319-66610-5_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029603402&doi=10.1007%2f978-3-319-66610-5_17&partnerID=40&md5=1f2a522bd296bc9efad3e766598fd1f8},
	affiliations = {Department of Computer Science, KU Leuven, Leuven, Belgium; Department of Telematics Engineering, Universidad Carlos III de Madrid, Madrid, Spain},
	abstract = {Detection and visualizations of affective states of students in computer based learning environments have been proposed to support student awareness and improve learning. However, the evaluation of such visualizations with students in real life settings is an open issue. This research reports on our experiences from the use of four different types of dashboard visualizations in two user studies (n = 115). Students who participated in the studies were bachelor and master level students from two different study programs at two universities. The results indicate that usability, measured by interpretability, perceived usefulness and insight, is overall acceptable. However, the findings also suggest that interpretability of some visualizations, in terms of the capability to support emotion awareness, still needs to be improved. The level of students awareness about their emotions during learning activities based on the visualization interpretation varied depending on previous knowledge on visualization techniques. Furthermore, simpler visualizations resulted in better outcomes than more complex techniques. © Springer International Publishing AG 2017.},
	author_keywords = {Emotion visualization; Human-computer interface; Interactive learning environments; Learning analytics; Learning dashboards; Visualization evaluation},
	keywords = {Computer aided instruction; E-learning; Human computer interaction; Students; Visualization; Computer-based learning environments; Human computer interfaces; Interactive learning environment; Learning analytics; Learning dashboards; Perceived usefulness; Students awareness; Visualization technique; Education},
	correspondence_address = {G. Sedrakyan; Department of Computer Science, KU Leuven, Leuven, Belgium; email: gayane.sedrakyan@kuleuven.be},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Matsuzawa2017619,
	author = {Matsuzawa, Yoshiaki and Tanaka, Yoshiki and Kitani, Tomoya and Sakai, Sanshiro},
	title = {A demonstration of evidence-based action research using information dashboard in introductory programming education},
	year = {2017},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {515},
	pages = {619 – 629},
	doi = {10.1007/978-3-319-74310-3_62},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041535459&doi=10.1007%2f978-3-319-74310-3_62&partnerID=40&md5=50cdfc4bb07419c3c398e8023e4a7cb6},
	affiliations = {Aoyama Gakuin University, Tokyo, Japan; Shizuoka University, Shizuoka, Japan},
	abstract = {In this paper, we demonstrated an evidence-based action research in an introductory programming class with the use of an information dashboard which provides coding metrics to visualize students’ engagement of their assignments. The information dashboard was designed for teachers to improve their classroom teaching using the same coding metrics which was verified in our previous research [9]. The system was equipped with a cross-filter functionality for exploring the entire classroom metrics. Accordingly, teachers can easily conduct a temporal analysis, an across-year comparison, and a cross metrics analysis. We examined the system for the improvement of the 5th year course using a dataset from the past four years from a non-CS introductory programming course at a university. Qualitative analysis was conducted using the discourse between teachers and teaching assistants with the proposed dashboard. The results showed that the system succeeded in promoting discourse, which included a clearer understanding of the class and its improvement, such as teaching method, assignments, or of students’ behavior. © 2017, IFIP International Federation for Information Processing.},
	author_keywords = {Action research; Information dashboard; Learning analytics; Programming education},
	keywords = {Information use; Students; Action research; Information dashboard; Introductory programming; Introductory programming course; Learning analytics; Programming education; Qualitative analysis; Teaching assistants; Teaching},
	correspondence_address = {Y. Matsuzawa; Aoyama Gakuin University, Tokyo, Japan; email: matsuzawa@si.aoyama.ac.jp},
	editor = {Webb M. and Tatnall A.},
	publisher = {Springer New York LLC},
	issn = {18684238},
	isbn = {978-331974309-7},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{20161,
	title = {3rd International Conference on Learning and Collaboration Technologies, LCT 2016 and 18th International Conference on Human-Computer Interaction, HCI International 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9753},
	pages = {1 – 742},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978790714&partnerID=40&md5=e80cf82f45c88e214b9c7e3e294edb16},
	abstract = {The proceedings contain 66 papers. The special focus in this conference is on Instructional Design, Interaction Techniques, Platforms for Learning, Learning Performance, Web-based, Mobile and Ubiquitous Learning. The topics include: Designing a new evaluation system based on scenario centered curriculum methodology; creating instructor dashboards to foster collaborative learning in on-line medical problem-based learning situations; increasing the quality of use case definition through a design thinking collaborative method and an alternative hybrid documentation style; reflections on e-learning storyboard for interaction design; constructive learning using flip-flop methodology; learning by making quizzes synchronized with video recording of lectures; an analysis of applying the short bridge method to digital education; a new approach for collaborative learning; software architectures supporting human-computer interaction analysis; pseudo-haptics presentation for promoting historical understanding; interactivity and multimodality in language learning; on the integration of tangible elements with multi-touch surfaces for the collaborative creation of concept maps; evaluation of the CTMTC methodology for assessment of teamwork competence development and acquisition in higher education; mixed method assessment for BIM implementation in the AEC curriculum; searching interactions and perceived learning; evaluating usability of m-learning application in the context of higher education institute; the design and implementation of a cross-platform teaching system; heuristic evaluation for serious immersive games and m-instruction; an analysis of social collaboration and networking tools in e-learning and learning analytics and spelling acquisition in German.},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331939482-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Charleer201642,
	author = {Charleer, Sven and Klerkx, Joris and Duval, Erik and De Laet, Tinne and Verbert, Katrien},
	title = {Creating effective learning analytics dashboards: Lessons learnt},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9891 LNCS},
	pages = {42 – 56},
	doi = {10.1007/978-3-319-45153-4_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988494817&doi=10.1007%2f978-3-319-45153-4_4&partnerID=40&md5=2c61640946094c697112caba93c0844b},
	affiliations = {Department of Computer Science, KU Leuven, Leuven, Belgium; Tutorial Services of Engineering Science, KU Leuven, Leuven, Belgium},
	abstract = {Learning Analytics (LA) dashboards help raise student and teacher awareness regarding learner activities. In blog-supported and inquiry-based learning courses, LA data is not limited to student activities, but also contains an abundance of digital learner artefacts, such as blog posts, hypotheses, and mind-maps. Exploring peer activities and artefacts can help students gain new insights and perspectives on learning efforts and outcomes, but requires effort. To help facilitate and promote this exploration, we present the lessons learnt during and guidelines derived from the design, deployment and evaluation of five dashboards. © Springer International Publishing Switzerland 2016.},
	author_keywords = {Collaboration; Guidelines; Information visualisation; Learning analytics; Learning dashboards},
	keywords = {Engineering education; Internet; Social networking (online); Students; Teaching; Collaboration; Guidelines; Information visualisation; Learning analytics; Learning dashboards; Learning systems},
	correspondence_address = {S. Charleer; Department of Computer Science, KU Leuven, Leuven, Belgium; email: Sven.Charleer@kuleuven.be},
	editor = {Verbert K. and Sharples M. and Klobučar T.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331945152-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39}
}

@CONFERENCE{Hatala20163,
	author = {Hatala, Marek and Beheshitha, Sanam Shirazi and Gaševic, Dragan},
	title = {Associations between students' approaches to learning and learning analytics visualizations},
	year = {2016},
	journal = {CEUR Workshop Proceedings},
	volume = {1596},
	pages = {3 – 10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978285962&partnerID=40&md5=4d2a1697bad8c1390a0a990409efbfc3},
	affiliations = {School of Interactive Arts and Technology, Simon Fraser University, Surrey, Canada; Schools of Education and Informatics, University of Edinburgh, Edinburgh, United Kingdom},
	abstract = {We investigated the connection between Students' Approaches to Learning and different information presented in learning analytics visualizations. Students' approaches to learning are a construct studied in educational psychology. They are context dependent and can be either surface or deep. In a field experiment, we discovered a significant interaction effect between learning analytics visualizations and students' approach to learning on the quality of messages posted by students. The associations were both positive and negative, depending on the combination of information presented in the visualizations and students' approach to learning. The paper contributes to the development of the body of research knowledge that aims to explain of how aptitude constructs from educational psychology interact with learning analytics visualizations. Copyright © 2016 for the individual papers by the papers' authors.},
	author_keywords = {Dashboards; Individual differences; Learning analytics; Online discussions; Students' approaches to learning; Visualizations},
	keywords = {Education; Learning systems; Visualization; Approaches to learning; Dashboards; Individual Differences; Learning analytics; Online discussions; Students},
	editor = {Bull S. and Ginon B.M. and Kay J. and Kickmeier-Rust M.D. and Johnson M.D.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Tarmazdi2015165,
	author = {Tarmazdi, Harmid and Vivian, Rebecca and Szabo, Claudia and Falkner, Katrina and Falkner, Nickolas},
	title = {Using learning analytics to visualise computer science teamwork},
	year = {2015},
	journal = {Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
	volume = {2015-June},
	pages = {165 – 170},
	doi = {10.1145/2729094.2742613},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951995042&doi=10.1145%2f2729094.2742613&partnerID=40&md5=8cac278cfc9fd2a748bbe73e669c3f97},
	affiliations = {School of Computer Science, University of Adelaide, 5005, SA, Australia},
	abstract = {Industry has called upon academia to better prepare Computer Science graduates for teamwork, especially in developing the soft skills necessary for collaborative work. However, the teaching and assessment of teamwork is not easy, with instructors being pressed for time and a lack of tools available to efficiently analyse student teamwork, where large cohorts are involved. We have developed a teamwork dashboard, founded on learning analytics, learning theory and teamwork models that analyses students' online teamwork discussion data and visualises the team mood, role distribution and emotional climate. This tool allows educators to easily monitor teams in real-time. Educators may use the tool to provide students with feedback about team interactions as well as to identify problematic teams. We present a case study, trialing the dashboard on one university Computer Science course and include reflections from the course lecturer to determine its utility in monitoring online student teamwork. Copyright 2015 ACM.},
	author_keywords = {Collaboration; Computer science education; Learning analytics},
	keywords = {Climate models; Education; Education computing; Engineering research; Students; Teaching; Collaboration; Collaborative Work; Computer Science course; Computer Science Education; Learning analytics; Monitoring on line; Teaching and assessments; Teamwork discussions; Engineering education},
	publisher = {Association for Computing Machinery},
	issn = {1942647X},
	isbn = {978-145033440-2},
	language = {English},
	abbrev_source_title = {Annu. Conf. Innov. Technol. Comput. Sci. Educ. ITiCSE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37}
}

@CONFERENCE{Cobos2016265,
	author = {Cobos, Ruth and Gil, Silvia and Lareo, Ángel and Vargas, Francisco A.},
	title = {Open-DLAs: An open dashboard for learning analytics},
	year = {2016},
	journal = {L@S 2016 - Proceedings of the 3rd 2016 ACM Conference on Learning at Scale},
	pages = {265 – 268},
	doi = {10.1145/2876034.2893430},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969972736&doi=10.1145%2f2876034.2893430&partnerID=40&md5=eaf630d12739564dfb8d2fbe32d4d55b},
	affiliations = {University Autónoma of Madrid, Spain},
	abstract = {In this paper a learning analytics dashboard for MOOCs is proposed. It visualises the progress of learners' activity taking into account navigation, social interactions and interaction with educational resources. This approach was tested with the MOOCs created by the University Autonóma of Madrid (Spain) in the edX platform. Nowadays, the dashboard is being improved taking into account the received feedback from MOOCs instructors and assistants. Finally, a new version is presented to work along with edX and Open edX. Copyright is held by the author/owner(s).},
	author_keywords = {Dashboard; Learning analytics; MOOCs},
	keywords = {Dashboard; Educational resource; Learning analytics; MOOCs; Social interactions},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145033726-7},
	language = {English},
	abbrev_source_title = {LS - Proc. ACM Conf. Learn. Scale},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@CONFERENCE{Charleer201532,
	author = {Charleer, Sven and Klerkx, Joris and Duval, Erik},
	title = {Exploring inquiry-based learning analytics through interactive surfaces},
	year = {2015},
	journal = {CEUR Workshop Proceedings},
	volume = {1518},
	pages = {32 – 35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960951315&partnerID=40&md5=9c64be51e9bf29fc05db53562ead23c5},
	affiliations = {Dept. of Computer Science, KU Leuven, Celestijnenlaan 200A, Leuven, 3001, Belgium},
	abstract = {Learning Analytics is about collecting traces that learners leave behind and using those traces to improve learning. Dashboard applications can visualize these traces to present learners and teachers with useful information. The work in this paper is based on traces from an inquiry-based learning (IBL) environment, where learners create hypotheses, discuss findings and collect data in the field using mobile devices. We present a work-in-progress that enables teachers and learners to gather around an interactive tabletop to explore the abundance of learning traces an IBL environment generates, and help collaboratively make sense of them, so as to facilitate insights.},
	author_keywords = {Awareness; Collaboration; Information visualization; Inquiry-based learning; Interactive surfaces; Learning analytics; Learning dashboards; Reection; Sense-making},
	keywords = {Information systems; Mobile devices; Teaching; Awareness; Collaboration; Information visualization; Inquiry-based learning; Interactive surfaces; Learning analytics; Learning dashboards; Reection; Sense making; Learning systems},
	editor = {Gillet D. and School of Engineering, EPFL, Station 9, Lausanne and Govaerts S. and School of Engineering, EPFL, Station 9, Lausanne and Parra D. and Wolpers M. and Ochoa X. and Escuela Superior Politecnica del Litoral, Campus Gustavo Galindo, Km. 30.5 Via Perimetral, Guayaquil and Klerkx J. and Duval E. and Verbert K. and Pardo A.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Schwendimann201730,
	author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
	title = {Perceiving learning at a glance: A systematic literature review of learning dashboard research},
	year = {2017},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {10},
	number = {1},
	pages = {30 – 41},
	doi = {10.1109/TLT.2016.2599522},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017624978&doi=10.1109%2fTLT.2016.2599522&partnerID=40&md5=9710190a28a5f0a2b673680e6f968c1c},
	affiliations = {CHILI Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland; REACT Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland},
	abstract = {This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining. Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes. Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs). The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis. Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation. As the research field is still relatively young, most studies are exploratory and proof-of-concept. The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards. There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs. © 2008-2011 IEEE.},
	author_keywords = {dashboards; educational data mining; information visualization; Learning analytics; systematic review},
	keywords = {Data visualization; Education; Enterprise resource planning; Information systems; Online systems; dashboards; Educational data mining; Information visualization; Learning analytics; Systematic Review; Data mining},
	correspondence_address = {B.A. Schwendimann; CHILI Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland; email: beat.schwendimann@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 396}
}

@CONFERENCE{Guenaga2015340,
	author = {Guenaga, Mariluz and Longarte, Jon Kepa and Rayon, Alex},
	title = {Standardized enriched rubrics to support competeney-assessment through the SCALA methodology and dashboard},
	year = {2015},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2015-April},
	pages = {340 – 347},
	doi = {10.1109/EDUCON.2015.7095994},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946028126&doi=10.1109%2fEDUCON.2015.7095994&partnerID=40&md5=42b2f63304add6d654b31cc63252a803},
	abstract = {Universities have increasingly emphasized competencies as central elements of students' development. However, the assessment of these competencies is not an easy task. The availability of data that learners generate in computer mediated learning offers great potential to study how learning takes place, and thus, to gather evidences for competency-assessment using enriched rubrics. These are the so-called electronic assessment instruments. Among them, the enriched rubrics arises as a tool to improve the assessment process. However, the lack of data interoperability and the decentralization of those educational applications set out a challenge to exploit trace data. To face these problems we have designed and developed SCALA (Supporting Competency-Assessment through a Learning Analytics approach), an analytics system that integrates usage -how the user interacts with resources- and social -how students and teachers interact among them- trace data to support competency assessment. After presenting the components of SCALA (process, model and platform), we evaluate them presenting six scenarios to know whether it is viable in terms of time, sustainability and quality assurance to normalize the heterogeneous data present in technology-rich learning environments. The results show and confirm the viability of the proposed solution and the possibility to offer real-time feedback to the teachers to assess students'. © 2015 IEEE.},
	author_keywords = {competency assessment; data workflow; knowledge discovery; learning analytics; teacher dashboard},
	keywords = {Computer aided instruction; Data mining; Education computing; Electronic assessment; Engineering education; Quality assurance; Students; Assessment instruments; Competency assessment; Computer-mediated learning; Data interoperability; data workflow; Educational Applications; learning analytics; teacher dashboard; Learning systems},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-147991908-6},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Molenaar2016538,
	author = {Molenaar, Inge and Campen, Carolien Knoop-Van},
	title = {Learning analytics in practice The effects of adaptive educational technology Snappet on students' arithmetic skills},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {538 – 539},
	doi = {10.1145/2883851.2883892},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976509236&doi=10.1145%2f2883851.2883892&partnerID=40&md5=6c463893ba6fb3ff0f2a6322323ed158},
	affiliations = {Radboud University, Nijmegen, Netherlands},
	abstract = {Even though the recent influx of tablets in primary education goes together with the vision that educational technology empowered with learning analytics will revolutionize education, empirical results supporting this claim are scares. Adaptive educational technology Snappet combines extracted and embedded learning analytics daily in classrooms. While students make exercises on the tablet this technology displays real-time data of learner performance in a teacher dashboard (extracted analytics). At the same time, learner performance is used to adaptively adjust exercises to students' progress (embedded analytics). This quasiexperimental study compares the development of students' arithmetic skills over one schoolyear (grade 2 and 4) in a traditional paper based setting to learning with the adaptive educational technology Snappet. The results indicate that students in the Snappet condition make significantly more progress on arithmetic skills in grade 4. Moreover, in this grade students with a high ability level, benefit the most from working with this adaptive educational technology. Overall the development pattern of students with different abilities was more divergent in the AET condition compared to the control condition. These results indicate that adaptive educational technologies combining extracted and embedded learning analytics are indeed creating new education scenarios that contribute to personalized learning in primary education. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Ability levels; Arithmetic's; Educational technologies; Primary education},
	keywords = {Education; Educational technology; Engineering education; Teaching; Ability levels; Development patterns; Embedded learning; Personalized learning; Primary education; Real-time data; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Green Open Access}
}

@CONFERENCE{Eradze2017193,
	author = {Eradze, Maka and Tammets, Kairit},
	title = {Learning analytics in MOOCs: EMMA case},
	year = {2017},
	journal = {Studies in Classification, Data Analysis, and Knowledge Organization},
	volume = {2},
	pages = {193 – 204},
	doi = {10.1007/978-3-319-55477-8_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045253072&doi=10.1007%2f978-3-319-55477-8_18&partnerID=40&md5=86af672d2d9a0fead5bbd2f370918a9f},
	affiliations = {Tallinn University, Narva rd. 25, Tallinn, 10120, Estonia},
	abstract = {The paper overviews the project—European Multiple MOOC Aggre-gator, EMMA for short, and its learning analytics system with the initial results. xAPI statements are used for designing learning analytics dashboards in order to provide instant feedback for learners and instructors. The paper presents dashboard visualizations and discusses the possibilities of use of EMMA learning analytics dashboard views for sensemaking and reflection of the MOOCs and MOOC experience. It investigates some of the MOOCs in EMMA platform as cases and analyzes the learning designs of those MOOCs. Recommendations of changes to learning designs based on learning analytics data are provided. © Springer International Publishing AG 2017.},
	keywords = {Learning analytics; Learning designs; Sensemaking},
	correspondence_address = {M. Eradze; Tallinn University, Tallinn, Narva rd. 25, 10120, Estonia; email: maka.eradze@tlu.ee},
	editor = {Carlo Lauro N. and Amaturo E. and Grassia M.G. and Aragona B. and Marino M.},
	publisher = {Springer Berlin Heidelberg},
	issn = {14318814},
	isbn = {978-331955476-1},
	language = {English},
	abbrev_source_title = {Stud. Classif., Data Anal., Knowl. Organ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Van Alphen20162334,
	author = {Van Alphen, Erik and Bakker, Saskia},
	title = {Lernanto: Using an ambient display during differentiated instruction},
	year = {2016},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	volume = {07-12-May-2016},
	pages = {2334 – 2340},
	doi = {10.1145/2851581.2892524},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014615391&doi=10.1145%2f2851581.2892524&partnerID=40&md5=6a71a68d5bb9eed581f1cb1c43e94434},
	affiliations = {Information Studies Department, University of Amsterdam, Amsterdam, Netherlands; Industrial Design Department, Eindhoven University of Technology, Eindhoven, Netherlands},
	abstract = {The emerging field of Learning Analytics (LA) promises to provide teachers with all types of data gathered realtime during lessons. This data could support teachers during differentiated instruction. A potential pitfall of providing teachers with such data on a screen-based dashboard, is information overload: comprehending the overload of information might decrease the valuable time available to attend to students. We present a pilot study in which data from Learning Analytics is provided to two secondary school teachers by means of an ambient display, called Lernanto. Semi-structured interviews, after a ten-week testing period, reveal that immediate access to learning analytics through an ambient display, next to using a LA dashboard, could result in teachers being able to distribute their attention more efficiently during lessons. © 2016 Authors.},
	author_keywords = {Ambient display; Classroom orchestration; Classroom technology; Peripheral interaction},
	keywords = {Display devices; Human computer interaction; Human engineering; Ambient displays; Classroom orchestration; Classroom technology; Information overloads; Peripheral interactions; Pilot studies; Real- time; School teachers; Secondary schools; Teachers'; Teaching},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034082-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@CONFERENCE{Grubišić2017513,
	author = {Grubišić, Ani and Stankov, Slavomir and Žitko, Branko and Šarić, Ines and Tomaš, Suzana and Brajković, Emil and Volarić, Tomislav and Vasić, Daniel and Dodaj, Arta},
	title = {Knowledge tracking variables in intelligent tutoring systems},
	year = {2017},
	journal = {CSEDU 2017 - Proceedings of the 9th International Conference on Computer Supported Education},
	volume = {1},
	pages = {513 – 518},
	doi = {10.5220/0006366905130518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023779055&doi=10.5220%2f0006366905130518&partnerID=40&md5=63da4bf01e5134b44241c351000de7be},
	affiliations = {Faculty of Science, University of Split, Split, Croatia; Croatia; Faculty of Humanities and Social Sciences, University of Split, Split, Croatia; Faculty of Science and Education, University of Mostar, Mostar, Bosnia and Herzegovina; Faculty of Philosophy, University of Mostar, Mostar, Bosnia and Herzegovina},
	abstract = {In this research we propose a comprehensive set of knowledge indicators aimed to enhance learners' selfreflection and awareness in the learning and testing process. Since examined intelligent tutoring systems do not include additional messaging features, the introduction of common set of knowledge indicators differentiates our approach from the previous studies. In order to investigate the relation between proposed knowledge indicators and learner performance, the correlation and regression analysis were performed for 3 different courses and each examined intelligent tutoring system. The results of correlation and regression analysis, as well as learners' feedback, guided us in discussion about the introduction of knowledge indicators in dashboard-like visualizations of integrated intelligent tutoring system. Copyright © 2017 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Intelligent tutoring systems; Learning analytics},
	keywords = {Computer aided instruction; E-learning; Education computing; Regression analysis; Correlation and regression analysis; Intelligent tutoring system; Learning analytics; Self reflection; Testing process; Learning systems},
	editor = {Escudeiro P. and Costagliola G. and Zvacek S. and Uhomoibhi J. and McLaren B.M.},
	publisher = {SciTePress},
	isbn = {978-989758239-4},
	language = {English},
	abbrev_source_title = {CSEDU - Proc. Int. Conf. Comput. Support. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Alhadad201620,
	author = {Alhadad, Sakinah S.J.},
	title = {Attentional and cognitive processing of analytics visualisations: Can design features affect interpretations and decisions about learning and teaching?},
	year = {2016},
	journal = {ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
	pages = {20 – 32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033796990&partnerID=40&md5=0aac0122800fc163aa00b3e1746b8013},
	affiliations = {Centre for Learning Futures, Griffith University, Australia},
	abstract = {There has been an increasing demand for course-level learning analytics to inform design improvements and interventions. While there has been an increasing research and development focus on dashboards to facilitate this, less has been done to investigate the impact of design features on optimising the interpretation process when translating learning analytics into actionable interventions and design changes. In this paper, I assess the effect of two prominent design features on the attentional and cognitive processes when using learning analytics at the course level. Emergent thematic analysis revealed response patterns suggesting systematic effects of three design features (course-only data, course-versus school-level data, course-only data with learning events marked) on the interpretive patterns, proposed actions, and consequential thinking of participants in the study. Implications for future designs of course-level learning analytics dashboards, as well as academic development are discussed. © 2016 Deakin University. All Rights Reserved.},
	author_keywords = {Attention; Dashboard designs; Data literacy; Learning analytics; Visualisations},
	keywords = {Educational technology; Visualization; Attention; Cognitive processing; Data literacy; Design improvements; Implications for futures; Learning analytics; Learning and teachings; Research and development; Curricula},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	language = {English},
	abbrev_source_title = {ASCILITE - Conf. Proc. - Int. Conf. Innov., Pract. Res. Use Educ. Technol. Tert. Educ.: Show Me Learn.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}@ARTICLE{Conde201550,
	author = {Conde, Miguel Ángel and Hérnandez-García, Ángel and García-Peñalvo, Francisco J. and Séin-Echaluce, María Luisa},
	title = {Exploring student interactions: Learning analytics tools for student tracking},
	year = {2015},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9192},
	pages = {50 – 61},
	doi = {10.1007/978-3-319-20609-7_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947080265&doi=10.1007%2f978-3-319-20609-7_6&partnerID=40&md5=605f83997d5f8677bc08e4632f33b306},
	affiliations = {Department of Mechanics, Computer Science and Aerospace Engineering, University of León, Campus de Vegazana S/N, León, 24071, Spain; Departamento de Ingeniería de Organización, Administración de Empresas y Estadística, Universidad Politécnica de Madrid, Av. Complutense 30, Madrid, 28040, Spain; Department of Computer Science, University of Salamanca, Plaza de los Caídos S/N, Salamanca, 37008, Spain; Department of Applied Mathematics, School of Engineering and Architecture, University of Zaragoza, María de Luna 3, Zaragoza, 50018, Spain},
	abstract = {This paper presents four categories of learning analytics tools: dashboards, ad hoc tools, tools for analysis of specific issues, and learning analytics frameworks, and details the characteristics of a selection of tools within each category: (1) Moodle Dashboard and Moodle default reporting tool; (2) Interactions and Teamwork Assessment Tool; (3) SNAPP, GraphFES and Moodle Engagement Analytics; and (4) VeLA and GISMO. The study investigates how these tools can be applied to the analysis of courses by using real data from a course that made intensive use of forums, wikis, web resources, videos, quizzes and assignments. The discussion that follows points out how the different tools complement each other, and suggests the implementation of basic dashboards in learning platforms and the use of external frameworks for learning analytics. © Springer International Publishing Switzerland 2015.},
	author_keywords = {Learning analytics; Moodle; Student tracking; User interactions},
	keywords = {Human computer interaction; Students; Learning analytics; Learning platform; Moodle; Reporting tools; Student interactions; Student tracking; Teamwork assessments; User interaction; Engineering education},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331920608-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35; All Open Access, Bronze Open Access}
}

@ARTICLE{Kapros2014282,
	author = {Kapros, Evangelos and Peirce, Neil},
	title = {Empowering L&D managers through customisation of inline learning analytics},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8523 LNCS},
	number = {PART 1},
	pages = {282 – 291},
	doi = {10.1007/978-3-319-07482-5_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903737477&doi=10.1007%2f978-3-319-07482-5_27&partnerID=40&md5=9df4a213e9ad7f7ec12b7eb38414429b},
	affiliations = {Learnovate Centre, Trinity Technology and Enterprise Campus, Dublin 2, Ireland},
	abstract = {Popular learning management systems (LMS) often feature dashboards displaying various analytics. This dashboard display might be suboptimal for some learning and development managers (L&D). Moreover, the analytics presented are often based on standardised quizzes or semesters, which might be unsuitable (e.g., informal learning, corporate education, etc.). Finally, each LMS has its bespoke reporting solution, thus making it difficult for L&D managers to monitor the situation across various LMSs. We propose an interactive system where an L&D manager can customise the data source, queries, filters, and visualisations of their LMSs, and display them inline. To this end, we have built EVADE, a system that allows L&D managers to capture data from various LMSs, analyse them, and embed related visualisations in each LMS. In this instance, we have integrated EVADE with a Moodle instance for corporate education, and Almanac, a tablet application for informal learning. In this paper we present EVADE and discuss how it can improve the L&D manager-LMS interaction. © 2014 Springer International Publishing.},
	author_keywords = {Corporate Learning; Learning Analytics; LMS; Visualisation},
	keywords = {Human computer interaction; Management; Managers; Visualization; Corporate Learning; Informal learning; Interactive system; Learning Analytics; Learning management system; LMS; Tablet applications; Visualisations; Engineering education},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331907481-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@CONFERENCE{Malhotra2014363,
	author = {Malhotra, Manav and Hsiao, I-Han and Chae, Hui Soo and Natriello, Gary},
	title = {Data depository: Business & learning analytics for educational web applications},
	year = {2014},
	journal = {Proceedings - IEEE 14th International Conference on Advanced Learning Technologies, ICALT 2014},
	pages = {363 – 364},
	doi = {10.1109/ICALT.2014.237},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910048829&doi=10.1109%2fICALT.2014.237&partnerID=40&md5=a01cfe262b496ed738556a152f1b0a7b},
	affiliations = {EdLab, Teachers College, Columbia University, 525 W. 120th Street, New York City, 10027, NY, United States},
	abstract = {Quantitative methods in education research have long been limited by the ability to collect detailed learner data in a consistent, scalable way. As education continues to move online we are presented with an unprecedented opportunity to study learner interactions within learning systems. However, doing so requires infrastructure to collect and store massive interaction data from which we can learn. In this paper we present Data Depository, a flexible, pluggable, data hub for tracking interaction data from any browser-based application, aiding the measurement of usage and effectiveness. © 2014 IEEE.},
	author_keywords = {dashboard; depository; learning analytics; measurement; tracking; user interaction},
	keywords = {Measurement; Online systems; Surface discharges; Browser-based application; dashboard; depository; Education research; Learner interaction; learning analytics; Quantitative method; User interaction; Learning systems},
	editor = {Sampson D.G. and Spector M.J. and Chen N.-S. and Huang R. and Kinshuk null},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-147994038-7},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Santos2012143,
	author = {Santos, Jose Luis and Govaerts, Sten and Verbert, Katrien and Duval, Erik},
	title = {Goal-oriented visualizations of activity tracking: A case study with engineering students},
	year = {2012},
	journal = {ACM International Conference Proceeding Series},
	pages = {143 – 152},
	doi = {10.1145/2330601.2330639},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864689444&doi=10.1145%2f2330601.2330639&partnerID=40&md5=06e63c5e7c525e066a9030e91d5a2ec2},
	affiliations = {Departement Computerwetenschappen, K.U.Leuven, B-3001 Leuven, Celestijnenlaan 200A, Belgium},
	abstract = {Increasing motivation of students and helping them to reflect on their learning processes is an important driver for learning analytics research. This paper presents our research on the development of a dashboard that enables self-reflection on activities and comparison with peers. We describe evaluation results of four iterations of a design based research methodology that assess the usability, use and usefulness of different visualizations. Lessons learned from the different evaluations performed during each iteration are described. In addition, these evaluations illustrate that the dashboard is a useful tool for students. However, further research is needed to assess the impact on the learning process. © 2012 ACM.},
	author_keywords = {learning analytics; reflection; visualization},
	keywords = {Flow visualization; Reflection; Students; Visualization; Design-based research; Evaluation results; Goal-oriented; learning analytics; Learning process; Self reflection; Research},
	correspondence_address = {J.L. Santos; Departement Computerwetenschappen, K.U.Leuven, B-3001 Leuven, Celestijnenlaan 200A, Belgium; email: joseluis.santos@cs.kuleuven.be},
	isbn = {978-145031111-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 100; All Open Access, Green Open Access}
}

@CONFERENCE{Schneider2014D3,
	author = {Schneider, Daniel K. and Class, Barbara and Benetos, Kalliopi and Da Costa, Julien and Follonier, Valérie},
	title = {Learning process analytics for a self-study class in a semantic mediawiki},
	year = {2014},
	journal = {Proceedings of the 10th International Symposium on Open Collaboration, OpenSym 2014},
	pages = {D3},
	doi = {10.1145/2641580.2641605},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908617859&doi=10.1145%2f2641580.2641605&partnerID=40&md5=6703533fdaf6e8de37ada6697d1cf2eb},
	affiliations = {University of Geneva, 40 bd. du Pont d'Arve, Genève, CH-1211, Switzerland},
	abstract = {We describe a framework and an implementation of learning process analytics for both learners and teachers to enhance a self-study class on psychological and educational theory. The environment is implemented in a Semantic MediaWiki using Semantic Forms and Semantic Result Formats. The design is in early development, but it is deployed and operational.},
	author_keywords = {Learning analytics; Learning cockpit; Learning dashboard; Online learning; Self-study course; Semantic Forms; Semantic MediaWiki; Semantic Result Formats},
	keywords = {Computer software; E-learning; Semantics; Teaching; Learning analytics; Learning dashboard; Online learning; Self-study course; Semantic mediawiki; Learning systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145033016-9},
	language = {English},
	abbrev_source_title = {Proc. Int. Symp. Open Collab., OpenSym},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Duval20119,
	author = {Duval, Erik},
	title = {Attention please! Learning analytics for visualization and recommendation},
	year = {2011},
	journal = {ACM International Conference Proceeding Series},
	pages = {9 – 17},
	doi = {10.1145/2090116.2090118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856339985&doi=10.1145%2f2090116.2090118&partnerID=40&md5=1ced842c13a38f381c3ef1d2cbfe0b54},
	affiliations = {Dept. Computer Science, Katholieke Universiteit Leuven, B3000 Leuven, Celestijnenlaan 200A, Belgium},
	abstract = {This paper will present the general goal of and inspiration for our work on learning analytics, that relies on attention metadata for visualization and recommendation. Through information visualization techniques, we can provide a dashboard for learners and teachers, so that they no longer need to "drive blind". Moreover, recommendation can help to deal with the "paradox of choice" and turn abundance from a problem into an asset for learning. © 2011 ACM.},
	author_keywords = {Learning analytics; Recommendation; Visualization},
	keywords = {Flow visualization; Information systems; Metadata; Information visualization; Learning analytics; Recommendation; Visualization},
	correspondence_address = {E. Duval; Dept. Computer Science, Katholieke Universiteit Leuven, B3000 Leuven, Celestijnenlaan 200A, Belgium; email: erik.duval@cs.kuleuven.be},
	isbn = {978-145031057-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 227; All Open Access, Green Open Access}
}

@CONFERENCE{Manske2014254,
	author = {Manske, Sven and Hecking, Tobias and Bollen, Lars and Gohnert, Tilman and Ramos, Alfredo and Hoppe, H. Ulrich},
	title = {A flexible framework for the authoring of reusable and portable learning analytics gadgets},
	year = {2014},
	journal = {Proceedings - IEEE 14th International Conference on Advanced Learning Technologies, ICALT 2014},
	pages = {254 – 258},
	doi = {10.1109/ICALT.2014.80},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910030084&doi=10.1109%2fICALT.2014.80&partnerID=40&md5=2d1c0d6af92ba70ca2dc94ac249f2eca},
	affiliations = {University of Duisburg-Essen, Faculty of Engineering, Duisburg, Germany; University of Twente, Department of Instructional Technology, Enschede, Netherlands},
	abstract = {Technology supported learning is nowadays often based on heterogeneous environments that encompass not only one application and also possibly involve different devices. This creates specific challenges for data analysis and thus for learning analytics. In this paper, we propose a framework to create reusable learning analytics components that are portable to different target platforms. In this approach, the logic of each analysis component is specified in a separate web-based visual environment (or 'workbench') from where it is later exported to the target environments form of a gadget-based dashboard. We demonstrate this mechanism in the context of the Go-Lab portal for accessing remote laboratories in STEM learning scenarios. An example shows how such analytics gadgets can be used to support collaboration inside the classroom. © 2014 IEEE.},
	author_keywords = {CSCL; Inquiry learning; learning analytics},
	keywords = {CSCL; Heterogeneous environments; Inquiry learning; learning analytics; Learning scenarios; Remote laboratories; Supported learning; Visual environments; Computer software reusability},
	editor = {Sampson D.G. and Spector M.J. and Chen N.-S. and Huang R. and Kinshuk null},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-147994038-7},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Charleer2014143,
	author = {Charleer, Sven and Santos, Jose Luis and Klerkx, Joris and Duval, Erik},
	title = {Improving teacher awareness through activity, Badge and content visualizations},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8699},
	pages = {143 – 152},
	doi = {10.1007/978-3-319-13296-9_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84917735562&doi=10.1007%2f978-3-319-13296-9_16&partnerID=40&md5=3e20813535b029a3af3d29694fdc2451},
	affiliations = {Department of Computer Science, KU Leuven, Leuven, Belgium},
	abstract = {This paper introduces LARAe (Learning Analytics Reflection & Awareness environment), a teacher-oriented dashboard that visualizes learning traces from students, badges and course content. We also present an evaluation of the dashboard in a course on Human-Computer Interaction. The LARAe teacher dashboard provides a detailed overview of group and individual activities, achievements and course outcomes. To help visualize the abundance of traces, badges are used to abstract essential aspects of the course such as course goals and social activity. This paper reports our work on LARAe, presents the course in which we evaluated our approach with students and teachers, and analyses our first results that indicate that such an environment can help with teacher awareness. © Springer International Publishing Switzerland 2014.},
	author_keywords = {Awareness; Collaboration; Information visualization; Learning analytics; Learning dashboards; Open badges; Reflection},
	keywords = {Administrative data processing; Computer aided instruction; Curricula; E-learning; Human computer interaction; Information systems; Knowledge management; Personal computing; Reflection; Social networking (online); Students; Visualization; Awareness; Collaboration; Information visualization; Learning analytics; Learning dashboards; Open badges; Teaching},
	editor = {Väljataga T. and Institute of Informatics, Tallinn University, Narva mnt 25, Tallinn, 10120 and Tang J.K.T. and Cao Y. and Laanpere M. and Institute of Informatics, Centre for Educational Technology, Tallinn University, Narva mnt. 29, Tallinn, 10120 and Leung J.K.T.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331913295-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Charleer201369,
	author = {Charleer, Sven and Klerkx, Joris and Santos, Jose Luis and Duval, Erik},
	title = {Improving awareness and reflection through collaborative, interactive visualizations of badges},
	year = {2013},
	journal = {CEUR Workshop Proceedings},
	volume = {1103},
	pages = {69 – 81},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922756687&partnerID=40&md5=c507aeaf3b8ef8b26167465301d8bb74},
	affiliations = {Dept. of Computer Science, KU Leuven, Celestijnenlaan 200A, Leuven, 3001, Belgium},
	abstract = {This paper introduces novel ways of improving awareness and reflection through visualizations of badges as an abstraction of learning analytics data. We report initial findings with both a personal dashboard approach, Navi Badgeboard, that provides details on student and class progress, and a collaborative, interactive tabletop visualization, Navi Surface, to promote group reflection. We evaluate both approaches to find improvements among students regarding awareness and reflec- tion on course activities. Our results indicate that Navi Badgeboard helps with awareness of personal activity while Navi Surface improves collaboration resulting in better reflection.},
	author_keywords = {Awareness; Badges; Collaboration; Learning analytics; Learning dashboards; Reflection; Visualization},
	keywords = {Flow visualization; Reflection; Visualization; Awareness; Badges; Collaboration; Learning analytics; Learning dashboards; Engineering education},
	editor = {Reinhardt W. and University of Paderborn, Department of Computer Science, Computer Science Education Group, Furstenallee 11, Paderborn and Prilla M. and Ruhr University of Bochum, Institute for Applied Work Science, Universitaetsstr. 150, Bochum and Pammer V. and Graz University of Technology, Know-Center, Knowledge Technologies Institute, Inffeldgasse 21A, Graz and Krogstie B. and Norwegian University of Science and Technology, Department of Computer and Information Science, Sem Saelands vei 7-9, Trondheim and Kravcik M. and RWTH Aachen University, Advanced Community Information Systems (ACIS), Ahornstr. 55, Aachen and Moore A. and Pannese L. and Imaginary Srl, Innovation Network Politecnico di Milano, Via Mauro Macchi, 50, Milano and Ullmann T.D.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}

@CONFERENCE{Corrin2014629,
	author = {Corrin, Linda and De Barba, Paula},
	title = {Exploring students' interpretation of feedback delivered through learning analytics dashboards},
	year = {2014},
	journal = {Proceedings of ASCILITE 2014 - Annual Conference of the Australian Society for Computers in Tertiary Education},
	pages = {629 – 633},
	doi = {10.14742/apubs.2014.1300},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955260027&doi=10.14742%2fapubs.2014.1300&partnerID=40&md5=89131ea4831a3bb087f5e3147c690871},
	affiliations = {Centre for the Study of Higher Education, University of Melbourne, Australia},
	abstract = {The delivery of feedback to students through learning analytics dashboards is becoming more common in higher education. However, it is not clear what ability students have to interpret this feedback in ways that will benefit their learning. This paper presents the preliminary results of a mixed methods study into students' interpretation of feedback delivered through learning analytics dashboards and the influence this feedback has on students' self-regulated learning. The findings from a preliminary analysis of the data from the first two phases will be discussed and the future phases of the research outlined. The outcomes of this research provide new insights into how dashboards can be designed to provide effective feedback in blended learning environments.},
	author_keywords = {Feedback; Learning analytics; Motivation; Self-regulated learning},
	keywords = {Computer aided instruction; Blended learning environments; Feedback to students; High educations; Learning analytic; Mixed method; Preliminary analysis; Self-regulated learning; Two phase; Students},
	correspondence_address = {L. Corrin; Centre for the Study of Higher Education, University of Melbourne, Australia; email: lcorrin@unimelb.edu.au},
	publisher = {Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
	language = {English},
	abbrev_source_title = {Proc. ASCILITE - Annu. Conf. Aust. Soc. Comput. ter. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 94; All Open Access, Green Open Access}
}

@CONFERENCE{Santos201314,
	author = {Santos, Jose Luis and Verbert, Katrien and Govaerts, Sten and Duval, Erik},
	title = {Addressing learner issues with StepUp!: An evaluation},
	year = {2013},
	journal = {ACM International Conference Proceeding Series},
	pages = {14 – 22},
	doi = {10.1145/2460296.2460301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876480347&doi=10.1145%2f2460296.2460301&partnerID=40&md5=0bddc50ff5d55ce8ea8e62d6165a61ec},
	affiliations = {Dept. of Computer Science, KU Leuven, B-3001 Leuven, Celestijnenlaan 200A, Belgium},
	abstract = {This paper reports on our research on the use of learning analytics dashboards to support awareness, self-reflection, sensemaking and impact for learners. So far, little research has been done to evaluate such dashboards with students and to assess their impact on learning. In this paper, we present the results of an evaluation study of our dashboard, called StepUp!, and the extent to which it addresses issues and needs of our students. Through brainstorming sessions with our students, we identified and prioritized learning issues and needs. In a second step, we deployed StepUp! during one month and we evaluated to which extent our dashboard addresses the issues and needs identified earlier in different courses. The results show that our tool has potentially higher impact for students working in groups and sharing a topic than students working individually on different topics. © 2013 ACM.},
	author_keywords = {design based research; evaluation; learning analytics; reflection; visualization},
	keywords = {Flow visualization; Reflection; Research; Brainstorming sessions; Design-based research; evaluation; Evaluation study; learning analytics; Self reflection; Sensemaking; Students},
	correspondence_address = {J.L. Santos; Dept. of Computer Science, KU Leuven, B-3001 Leuven, Celestijnenlaan 200A, Belgium; email: JoseLuis.Santos@cs.kuleuven.be},
	isbn = {978-145031785-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 77; All Open Access, Green Open Access}
}

@ARTICLE{Vázquez-Barreiros2015925,
	author = {Vázquez-Barreiros, Borja and Ramos-Soto, Alejandro and Lama, Manuel and Mucientes, Manuel and Bugarín, Alberto and Barro, Senén},
	title = {Soft computing for learner’s assessment in softlearn},
	year = {2015},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9112},
	pages = {925 – 926},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949033151&partnerID=40&md5=b543868cf735390135fa81a9925e88b9},
	affiliations = {Centro de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Spain},
	abstract = {This paper describes the contributions of the SoftLearn platform to key issues in learning analytics, as i) discovery of the learning path that students follow in a course and ii) provide interpretability of graphs in dashboards. © Springer International Publishing Switzerland 2015.},
	keywords = {Artificial intelligence; Interpretability; Key Issues; Learning paths; Soft computing},
	editor = {Conati C. and Heffernan N. and Mitrovic A. and Felisa Verdejo M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331919772-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Park2015110,
	author = {Park, Yeonjeong and Jo, Il-Hyun},
	title = {Development of the learning analytics dashboard to support students’ learning performance},
	year = {2015},
	journal = {Journal of Universal Computer Science},
	volume = {21},
	number = {1},
	pages = {110 – 133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933039245&partnerID=40&md5=555840a6c853cf053230214945750ff1},
	affiliations = {Ewha Womans University, Seoul, South Korea},
	abstract = {The Learning Analytics Dashboard (LAD) is an application to show students’ online behavior patterns in a virtual learning environment. This supporting tool works by tracking students’ log-files, mining massive amounts of data to find meaning, and visualizing the results so they can be comprehended at a glance. This paper reviews previously developed applications to analyze their features. Based on the implications from the review of previous studies as well as a preliminary investigation on the need for such tools, an early version of the LAD was designed and developed. Also, in order to improve the LAD, a usability test incorporating a stimulus recall interview was conducted with 38 college students in two blended learning classes. Evaluation of this tool was performed in an experimental research setting with a control group and additional surveys were conducted asking students’ about perceived usefulness, conformity, level of understanding of graphs, and their behavioral changes. The results indicated that this newly developed learning analytics tool did not significantly impact on their learning achievement. However, lessons learned from the usability and pilot tests support that visualized information impacts on students’ understanding level; and the overall satisfaction with dashboard plays as a covariant that impacts on both the degree of understanding and students’ perceived change of behavior. Taking in the results of the tests and students’ openended responses, a scaffolding strategy to help them understand the meaning of the information displayed was included in each sub section of the dashboard. Finally, this paper discusses future directions in regard to improving LAD so that it better supports students’ learning performance, which might be helpful for those who develop learning analytics applications for students. © J.UCS.},
	author_keywords = {Dashboard; Learning analytics; Learning management system; Perceived usefulness; Pilot test; Usability test; Visualization},
	publisher = {IICM},
	issn = {0948695X},
	language = {English},
	abbrev_source_title = {J. Univers. Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 190}
}

@CONFERENCE{Orduña2014299,
	author = {Orduña, Pablo and Almeida, Aitor and López-De-Ipiña, Diego and Garcia-Zubia, Javier},
	title = {Learning Analytics on federated remote laboratories: Tips and techniques},
	year = {2014},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	pages = {299 – 305},
	doi = {10.1109/EDUCON.2014.6826107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903451766&doi=10.1109%2fEDUCON.2014.6826107&partnerID=40&md5=8e7e1c6ace3fcc0e68f79e4a4cbbb862},
	affiliations = {DeustoTech - Deusto Institute of Technology, University of Deusto, Bilbao, Spain; Faculty of Engineering, University of Deusto Bilbao, Spain},
	abstract = {A remote laboratory is a software and hardware tool which enables students to use real equipment -located in an educational institution- through the Internet. This way, students can experiment as if they were using the laboratories with their own hands. And, depending on the design, instructors can later see the results of these students. During the last decade, federation protocols to share remote laboratories have emerged. The focus of these protocols is to be make remote laboratories of one institution available in other in an automated manner, through institutional contracts. And these federation protocols usually rely on existing Remote Laboratory Management Systems (RLMS), which usually provide APIs for tracking student usage. At the same time, the interest on Learning Analytics is increasing. Learning Analytics focuses on the measurement and analysis of data about learners in their context. In the particular context of federated remote laboratories, new challenges arise: on the one hand, remote laboratories must be prepared to track insightful information from the student session so as to extract patterns, and on the other hand, the usage of a federated environment requires different degrees of anonymity. This contribution describes the new Learning Analytics dashboard of WebLab-Deusto, detailing what information can be extracted and how the usage of a RLMS simplifies the development of such tools in a federated environment. © 2014 IEEE.},
	keywords = {Engineering education; Laboratories; Sustainable development; Educational institutions; Measurement and analysis; Remote laboratories; Software and hardwares; Students},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-147993191-0},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25}
}

@ARTICLE{Florian-Gaviria2013283,
	author = {Florian-Gaviria, Beatriz and Glahn, Christian and Fabregat Gesa, Ramon},
	title = {A software suite for efficient use of the European qualifications framework in online and blended courses},
	year = {2013},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {6},
	number = {3},
	pages = {283 – 296},
	doi = {10.1109/TLT.2013.18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884247875&doi=10.1109%2fTLT.2013.18&partnerID=40&md5=d95b9425aa1455b2a47bde3e958747d1},
	affiliations = {EISC, Universidad Del Valle, Edf. 331, Valle del Cauca 76001000, Calle 13 No 100-00, Colombia; International Relations and Security Network (ISN), Swiss Federal Institute of Technology Zurich, LEH 8092 Zurich, Leonhardshalde 21, Switzerland; Institute of Informatics and Applications, University of Girona, Campus Montilivi, Girona 17071, Edifici P-4, Av. Lluis Santaló, Spain},
	abstract = {Since introduction of the European qualifications framework (EQF) as one instrument to bridge from learning institutions to competence driven lifelong learning, it remains a challenge for instructors and teachers in higher education to make efficient use of this framework for designing, monitoring, and managing their lessons. This paper presents a software suite for enabling teachers to make better use of EQF in their teaching. The software suite extends course design based on well-defined learning outcomes, monitoring performance and competence acquisition according to the EQF levels, assessment using scoring rubrics of EQF levels and competences in a 360-degree feedback, as well as visualizations of learning analytics and open student models in dashboards for different social perspectives in social planes. This paper includes a case study with 20 teachers who used the software suite in all phases of the course lifecycle for three programming courses. The results show that integrated applications for adopting the EQF in teaching practice are strongly needed. These results also show that the suite can assist teachers in creating contextual awareness, kindling reflection, understanding students and course progress, and inferring patterns of success and failure in competences development. © 2008-2011 IEEE.},
	author_keywords = {360-degree feedback; EQF; Instructor interfaces; integration and modeling; learning analytics; personalized e-learning; social learning techniques; system architectures; systems specification methodology},
	keywords = {E-learning; Teaching; EQF; Integration and modeling; learning analytics; Personalized e-learning; Social learning; System architectures; Systems specification; Curricula},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Bronze Open Access}
}

@CONFERENCE{Vozniuk2013412,
	author = {Vozniuk, Andrii and Govaerts, Sten and Gillet, Denis},
	title = {Towards portable learning analytics dashboards},
	year = {2013},
	journal = {Proceedings - 2013 IEEE 13th International Conference on Advanced Learning Technologies, ICALT 2013},
	pages = {412 – 416},
	doi = {10.1109/ICALT.2013.126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885237483&doi=10.1109%2fICALT.2013.126&partnerID=40&md5=6c705c4ded5d0225c344310b88f72d9d},
	affiliations = {EPFL, Lausanne, Switzerland},
	abstract = {This paper proposes a novel approach to build and deploy learning analytics dashboards in multiple learning environments. Existing learning dashboards are barely portable: once deployed on a learning platform, it requires considerable effort to deploy the dashboard elsewhere. We suggest constructing dashboards from lightweight web applications, namely widgets. Our approach allows to port dashboards with no additional cost between learning environments that implement open specifications (Open Social and Activity Streams) for data access and use widget APIs. We propose to facilitate reuse by sharing the dashboards and widgets via a centralized analytics repository. © 2013 IEEE.},
	author_keywords = {ActivityStreams; dashboards; learning analytics; open standards; OpenSocial; portability; widget},
	keywords = {Computer software portability; Engineering education; ActivityStreams; dashboards; learning analytics; Open Standards; OpenSocial; widget; Computer aided instruction},
	isbn = {978-076955009-1},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Green Open Access}
}

@ARTICLE{Zheng201523,
	author = {Zheng, Lanqin and El-Bishouty, Moushir M. and Pinnell, Colin and Bell, Jason and Kumar, Vive and Kinshuk},
	title = {A framework to automatically analyze regulation},
	year = {2015},
	journal = {Lecture Notes in Educational Technology},
	number = {9783662441879},
	pages = {23 – 30},
	doi = {10.1007/978-3-662-44188-6_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925331799&doi=10.1007%2f978-3-662-44188-6_3&partnerID=40&md5=c23ea88e34b6d114f05c22b06b512955},
	affiliations = {School of Educational Technology, Faculty of Education, Beijing Normal University, Beijing, China; School of Computing and Information Systems, Athabasca University, Athabasca, Canada; City for Scientific Research and Technological Applications, New Borg El-Arab, Egypt},
	abstract = {Self-regulated learning has achieved prominence in recent years. Helping students to become self-regulated learners is becoming a favorite target of researchers and educational practitioners. This study proposes a novel framework that can automatically analyze online self-regulated learning processes and competencies. It presents an analytics dashboard that encourages students to initiate activities of self-regulation and guide them to reflect on their competencies. The architecture of the framework and an applied scenario are presented and discussed in detail. © 2015, Springer-Verlag Berlin Heidelberg.},
	author_keywords = {Competency; Dashboard; Learning analytics; Self-regulated learning},
	correspondence_address = {L. Zheng; School of Educational Technology, Faculty of Education, Beijing Normal University, Beijing, China; email: bnuzhenglq@bnu.edu.cn},
	publisher = {Springer International Publishing},
	issn = {21964963},
	language = {English},
	abbrev_source_title = {Lect. Notes Educ. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Charleer201485,
	author = {Charleer, Sven and Santos, Jose Luis and Klerkx, Joris and Duval, Erik},
	title = {LARAe: Learning analytics reflection & awareness environment},
	year = {2014},
	journal = {CEUR Workshop Proceedings},
	volume = {1238},
	pages = {85 – 87},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911894239&partnerID=40&md5=9ae8921695e3beff550dfd90c225cd17},
	affiliations = {Dept. of Computer Science, KU Leuven, Leuven, Belgium},
	abstract = {Exploring and managing the abundance of data that Learning Analytics generate is a challenge for both teachers and students. This paper introduces a Learning Dashboard that provides an overview, context and content of learner traces to help students with awareness of feedback and progress, and assist teachers with monitoring student effort and outcomes to intervene where needed.},
	author_keywords = {Awareness; Effort; Information visualization; Inquiry-based learning; Intervention; Learning analytics; Learning dashboards},
	keywords = {Information systems; Students; Awareness; Effort; Information visualization; Inquiry-based learning; Intervention; Learning analytics; Learning dashboards; Teaching},
	editor = {Kravcik M. and RWTH Aachen University, Advanced Community Information Systems (ACIS), Ahornstr. 55, Aachen and Mikroyannidis A. and Pammer V. and Graz University of Technology, Knowledge Technologies Institute, Know-Center, Inffeldgasse 21A, Graz and Prilla M. and Ruhr University of Bochum, Institute for Applied Work Science, Universitaetsstr. 150, Bochum and Wild F. and Ullmann T.D.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Knight2015,
	author = {Knight, David B. and Brozina, Cory and Stauffer, Eric M. and Frisina, Chris and Abel, Troy D.},
	title = {Developing a learning analytics dashboard for undergraduate engineering using participatory design},
	year = {2015},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	volume = {122nd ASEE Annual Conference and Exposition: Making Value for Society},
	number = {122nd ASEE Annual Conference and Exposition: Making Value for Society},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941995522&partnerID=40&md5=0ed2432e27c627c1983cf7d336685563},
	affiliations = {Virginia Tech., Department of Engineering Education, United States; Department of Visual Communication Design, Virginia Tech., United States},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Rayón2014,
	author = {Rayón, Alex and Guenaga, Mariluz and Núñez, Asier},
	title = {Integrating and visualizing learner and social data to elicit higher-order indicators in SCALA dashboard},
	year = {2014},
	journal = {ACM International Conference Proceeding Series},
	volume = {16-19-September-2014},
	doi = {10.1145/2637748.2638435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987984447&doi=10.1145%2f2637748.2638435&partnerID=40&md5=3de2fa2f67d62a21779b55a998e1bec1},
	affiliations = {DeustoTech Learning, Deusto Institute of Technology, University of Deusto, Avda. Universidades 24, Bilbao, 48007, Spain},
	abstract = {The assessment of competencies is a difficult task; on one hand due to its subjective nature, and, on the other one, because of the difficulties to make it scalable and simple. Since ICT are becoming increasingly important learning mediating tools, data stored in learning tools could yield a wealth of information that could serve as an indicator to measure students' progress and the development of competencies. However, the lack of data interoperability among different educational applications imposes a challenge to data mining and analytics that rely on diverse and distributed data. Besides, these educational technologies do neither usually provide a statistics module in which the teacher can obtain specific reports about students' performance, nor visualization tools to summarize student usage data. In response to this weakness, and based on the limitations encountered in existing tools, we have developed an integrated and extensible web tool called SCALA (Scalable Competency Assessment through a Learning Analytics approach) that not only shows but also mines using analytics techniques for the discovery of student patterns and metric relations in web-based educational systems. © Copyright 2014 ACM.},
	author_keywords = {Dashboard; Data integration; Information retrieval; Large-scale interoperability; Learning analytics; Visual analytics},
	keywords = {Data mining; Data visualization; Education; Information retrieval; Interoperability; Students; Teaching; Visualization; Competency assessment; Dashboard; Data interoperability; Educational Applications; Learning analytics; Visual analytics; Wealth of information; Web-based educational systems; Data integration},
	publisher = {Association for Computing Machinery},
	isbn = {978-145032769-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Reimers2015399,
	author = {Reimers, Gabriel and Neovesky, Anna},
	title = {Student focused dashboards: An analysis of current student dashboards and what students really want},
	year = {2015},
	journal = {CSEDU 2015 - 7th International Conference on Computer Supported Education, Proceedings},
	volume = {1},
	pages = {399 – 404},
	doi = {10.5220/0005475103990404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943394986&doi=10.5220%2f0005475103990404&partnerID=40&md5=4b93110e2f5bafdf22417de268e2a4e4},
	affiliations = {Quality and Usability Lab, Technische Universität Berlin, Ernst-Reuter-Platz 7, Berlin, 10587, Germany; Digital Academy, Academy of Sciences and Literature Mainz, Geschwister-Scholl-Str. 2, Mainz, 55131, Germany},
	abstract = {Online learning analytics dashboards are already available in various online learning platforms and are in use at schools and universities. In this paper we give an overview about several existing dashboard applications. Most of these dashboards are either targeted at teachers and tutors or focus on the presentation of research relevant learning analytics concepts. We present two surveys among school and university students asking them about their requirements on a learning dashboard. The results show that basic requirements of students are not addressed in current learning platforms and dashboards. We formulate several research questions that need to be answered to create dashboards that put students in the center of dashboard design processes and give an outline of our own efforts in that direction.},
	author_keywords = {Dashboards; Learning analytics; Self reflection; Visualisation},
	keywords = {E-learning; Visualization; Dashboards; Design process; Learning analytics; Learning platform; Online learning; Research questions; Self reflection; University students; Students},
	editor = {Helfert M. and Restivo M.T. and Zvacek S. and Uhomoibhi J.},
	publisher = {SciTePress},
	isbn = {978-989758107-6},
	language = {English},
	abbrev_source_title = {CSEDU - Int. Conf. Comput. Support. Educ., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Swenson2014246,
	author = {Swenson, Jenni},
	title = {Establishing an ethical literacy for learning analytics},
	year = {2014},
	journal = {ACM International Conference Proceeding Series},
	pages = {246 – 250},
	doi = {10.1145/2567574.2567613},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898780264&doi=10.1145%2f2567574.2567613&partnerID=40&md5=904ec1d0f9423eb4a69b810efc3216d1},
	affiliations = {Lake Superior College, Duluth, MN 55811, 2101 Trinity Road, United States},
	abstract = {This paper borrows multiple frameworks from the field of technical communication in order to review theory, research, practice, and ethics of the Learning Analytics and Knowledge (LAK) discipline. These frameworks also guide discussion on the ethics of learning analytics "artifacts" (data visualizations, dashboards, and methodology), and the ethical consequences of using learning analytics (classification, social power moves, and absence of voice). Finally, the author suggests a literacy for learning analytics that includes an ethical viewpoint. Copyright © 2014 by the Association for Computing Machinery, Inc.},
	author_keywords = {Ethics; Higher education; Learning analytics; Literacy},
	keywords = {Computer applications; Computer programming; Ethics; Higher education; Learning analytics; Literacy; Technical communications; Philosophical aspects},
	correspondence_address = {J. Swenson; Lake Superior College, Duluth, MN 55811, 2101 Trinity Road, United States; email: j.swenson@lsc.edu},
	publisher = {Association for Computing Machinery},
	isbn = {1595930361; 978-159593036-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@CONFERENCE{Rayon Jerez2014321,
	author = {Rayon Jerez, Alex and Guenaga, Mariluz and Núñez, Asier},
	title = {A web platform for the assessment of competences in Mobile Learning Contexts},
	year = {2014},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	pages = {321 – 329},
	doi = {10.1109/EDUCON.2014.6826111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903439403&doi=10.1109%2fEDUCON.2014.6826111&partnerID=40&md5=f103ac60ff37824b8b889b279c81c3ee},
	affiliations = {DeustoTech Learning, Deusto Institute of Technology, Universidad de Deusto, Bilbao, Avda. Universidades, 24, Spain},
	abstract = {Society demands new competences from professionals, who require having specific skills and abilities. Universities, accordingly, have changed from a content-based towards a competency-based educational model. However, the assessment of these competences is not a scalable task, has a subjective nature and must consider data from many different sources. This paper describes the model, architecture and objectives of an on-going research project aimed at developing a web platform called LACAMOLC, to provide teachers and students a dashboard which gathers usage and social data from different Knowledge and Learning Technologies such as Moodle, Google Apps for Education and MediaWiki to provide visual and learning analytics visualizations to support learning and assessment process. We select Pentaho as our analytics specific tool, based on its characteristics in order to effectively scale learning analytics systems and achieve long-term sustainability and scalability, and we design an experiment to carry out for teamwork competence. © 2014 IEEE.},
	author_keywords = {competence assessment; knowledge and learning technologies; learning analytics; mobile learning},
	keywords = {Education computing; Sustainable development; Assessment of competences; Assessment process; Competence assessments; Educational models; learning analytics; Learning technology; Long-term sustainability; Mobile Learning; Engineering education},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-147993191-0},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Verbert20141499,
	author = {Verbert, Katrien and Govaerts, Sten and Duval, Erik and Santos, Jose Luis and Van Assche, Frans and Parra, Gonzalo and Klerkx, Joris},
	title = {Learning dashboards: An overview and future research opportunities},
	year = {2014},
	journal = {Personal and Ubiquitous Computing},
	volume = {18},
	number = {6},
	pages = {1499 – 1514},
	doi = {10.1007/s00779-013-0751-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904805806&doi=10.1007%2fs00779-013-0751-2&partnerID=40&md5=d82f38994b821f8f9cc0b7a3c5f6b3c6},
	affiliations = {Department of Computer Science, KU Leuven, 3000 Leuven, Celestijnenlaan 200A, Belgium; Department of Computer Science, Eindhoven University of Technology, Eindhoven, Netherlands; School of Engineering, EPFL, Lausanne, Switzerland},
	abstract = {In this paper, we present work on learning analytics that aims to support learners and teachers through dashboard applications, ranging from small mobile applications to learnscapes on large public displays. Dashboards typically capture and visualize traces of learning activities, in order to promote awareness, reflection, and sense-making, and to enable learners to define goals and track progress toward these goals. Based on an analysis of our own work and a broad range of similar learning dashboards, we identify HCI issues for this exciting research area. © 2013 Springer-Verlag London.},
	author_keywords = {Dashboards; HCI; Information visualization; Learning analytics},
	keywords = {Human computer interaction; Information systems; Ubiquitous computing; Dashboards; Information visualization; Learning Activity; Learning analytics; Mobile applications; Public display; Research opportunities; Track progress; Learning systems},
	correspondence_address = {E. Duval; Department of Computer Science, KU Leuven, 3000 Leuven, Celestijnenlaan 200A, Belgium; email: erik.duval@cs.kuleuven.be},
	publisher = {Springer-Verlag London Ltd},
	issn = {16174909},
	language = {English},
	abbrev_source_title = {Pers. Ubiquitous Comp.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 319}
}

@ARTICLE{Kotsiantis2013133,
	author = {Kotsiantis, Sotiris and Tselios, Nikolaos and Filippidi, Andromahi and Komis, Vassilis},
	title = {Using learning analytics to identify successful learners in a blended learning course},
	year = {2013},
	journal = {International Journal of Technology Enhanced Learning},
	volume = {5},
	number = {2},
	pages = {133 – 150},
	doi = {10.1504/IJTEL.2013.059088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893517667&doi=10.1504%2fIJTEL.2013.059088&partnerID=40&md5=6eb082a42c5075854c05aa6435a46716},
	affiliations = {Department of Mathematics, University of Patras, 26500 Rio, Patras, Greece; Department of Educational Sciences and Early Childhood Education, ICT in Education Group, University of Patras, 26500 Rio, Patras, Greece},
	abstract = {In this paper, students' practices while using a Learning Content Management System in a blended learning environment were examined. This is a case study involving 337 students who attended an academic course based upon a blended learning approach over three years using Moodle. Eighteen variables depicting the students' perceptions of Moodle, as well as their interaction with it, were examined using four complementary data mining and statistical analysis approaches: visualisation, decision trees, class association rules and clustering. The analysis of the collected data shows that failure in the course was associated with negative attitudes and perceptions of the students towards Moodle. On the other hand excellent grades were associated with increased use of the LCMS. Requirements elicitation of a learning analytics dashboard, are also discussed.Copyright © 2013 Inderscience Enterprises Ltd.},
	author_keywords = {Blended learning; Case study; Higher education; Interaction data; Learning analytics; Learning content management systems; Moodle; Perceptions},
	correspondence_address = {N. Tselios; Department of Educational Sciences and Early Childhood Education, ICT in Education Group, University of Patras, 26500 Rio, Patras, Greece; email: nitse@ece.upatras.gr},
	publisher = {Inderscience Publishers},
	issn = {17535255},
	language = {English},
	abbrev_source_title = {Int. J. Technol. Enhanced Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42}
}

@CONFERENCE{Chaudy201458,
	author = {Chaudy, Yaëlle and Connolly, Thomas and Hainey, Thomas},
	title = {An assessment engine: Educators as editors of their serious games' assessment},
	year = {2014},
	journal = {Proceedings of the European Conference on Games-based Learning},
	volume = {1},
	pages = {58 – 67},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923568297&partnerID=40&md5=aa39d49d09c701ecc37f82be31dbc505},
	affiliations = {University of the West of Scotland, Paisley, Renfrewshire, United Kingdom},
	abstract = {Serious Games (SG) are increasingly used by educators to assist the teaching and learning process and offer many advantages over traditional education. They are highly engaging, motivating and they have the potential to adapt to each student quickly becoming an ideal supplementary tool for education. However, if the majority of teachers agree that using SGs increases the motivation, learning and retention of their students, very few of them are ready to trust their assessment to verify that the learning goals have been met. They would rather adopt a more conventional method such as a paperbased test. We believe two main reasons explain this attitude: a lack of ownership over the games used and the rigidness of the games, making them unmodifiable by the teacher. To overcome these issues, we have developed an assessment engine to be used by both SG developers and educators. The engine's design results in a separation of a game and its assessment, and the resulting modularity allows the teachers to modify the assessment of a game even after distribution. This paper focuses on the teacher interface of the assessment engine. After reviewing the literature associated with ingame assessment and learning analytics, the paper will provide a summary of the engine and its functionalities, present the Learning Analytics (LA) dashboard. We will then describe the visual language that allows teachers to edit a game's assessment system based on the LA reports. Thereafter, the authorisation and versioning mechanics of the engine will be detailed, showing how the system regulates the access to the games and stressing the fact that every teacher will have, after modification, a unique game customised to their students' needs. Finally, we will provide conclusions and state the remaining work to be undertaken. © The Authors, 2014.},
	author_keywords = {Assessment; Assessment engine; Authoring tool; Serious game; Visual editor},
	keywords = {Engines; Motivation; Students; Teaching; Visual languages; Assessment; Assessment system; Authoring tool; Conventional methods; Serious games; Teaching and learning; Traditional educations; Visual editors; Education},
	editor = {Busch C.},
	publisher = {Dechema e.V.},
	issn = {20490992},
	isbn = {978-191030955-1},
	language = {English},
	abbrev_source_title = {Proc. European Conf. Games-based Learn.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Ritsos201461,
	author = {Ritsos, Panagiotis D. and Roberts, Jonathan C.},
	title = {Towards more Visual Analytics in Learning Analytics},
	year = {2014},
	journal = {International Workshop on Visual Analytics},
	pages = {61 – 65},
	doi = {10.2312/eurova.20141147},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944531025&doi=10.2312%2feurova.20141147&partnerID=40&md5=c079fa5c51bc104a9ee35c83a352520d},
	affiliations = {School of Computer Science, Bangor University, United Kingdom},
	abstract = {Learning Analytics is the collection, management and analysis of students' learning. It is used to enable teachers to understand how their students are progressing and for learners to ascertain how well they are performing. Often the data is displayed through dashboards. However, there is a huge opportunity to include more comprehensive and interactive visualizations that provide visual depictions and analysis throughout the lifetime of the learner, monitoring their progress from novices to experts. We therefore encourage researchers to take a comprehensive approach and re-think how visual analytics can be applied to the learning environment, and develop more interactive and exploratory interfaces for the learner and teacher. © 2019 International Workshop on Visual Analytics. All rights reserved.},
	publisher = {Eurographics Association},
	issn = {26644487},
	isbn = {978-390567468-2},
	language = {English},
	abbrev_source_title = {Int. Workshop Vis. Anal.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Rayón2014584,
	author = {Rayón, Alex and Guenaga, Mariluz and Nuñez, Asier},
	title = {Heterogeneous educational data integration and knowledge discovery to supporting competency assessment in SCALA web tool},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8719 LNCS},
	pages = {584 – 585},
	doi = {10.1007/978-3-319-11200-8_81},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906351082&doi=10.1007%2f978-3-319-11200-8_81&partnerID=40&md5=731f73bd8d3eeb6ecf35fa17d6329bde},
	affiliations = {DeustoTech Learning, Deusto Institute of Technology, University of Deusto, 48007 Bilbao, Avda. Universidades 24, Spain},
	abstract = {The lack of data interoperability among different educational systems imposes a challenge to data analytics. To face these problems, we have developed SCALA (Scalable Competency Assessment web platform through a Learning Analytics approach), an integrated analytics system that employs Learning Analytics techniques to visualize in a single interface enriched indicators to teachers and learners, gaining insights into their habits and the impact of their learning activities. © 2014 Springer International Publishing Switzerland.},
	author_keywords = {competency-assessment; dashboard; learning analytics; learning metrics},
	keywords = {Education; Analytics systems; competency-assessment; dashboard; Data interoperability; Educational systems; Learning Activity; learning analytics; Learning metrics; Interoperability},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331911199-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rayón2014291,
	author = {Rayón, Alex and Guenaga, Mariluz and Núñez, Asier},
	title = {Supporting competency-assessment through a learning analytics approach using enriched rubrics},
	year = {2014},
	journal = {ACM International Conference Proceeding Series},
	pages = {291 – 298},
	doi = {10.1145/2669711.2669913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014832539&doi=10.1145%2f2669711.2669913&partnerID=40&md5=dea5a15f99c38b06638245a2ff8e1051},
	affiliations = {University of Deusto, Spain; Deusto Institute of Technology, University of Deusto, Spain; Deusto Tech Learning, Deusto Institute of Technology, Spain},
	abstract = {Universities have increasingly emphasized competencies as central elements of students' development. However, the assessment of these competencies is not an easy task. The availability of data that learners generate in computer mediated learning offers great potential to study how learning takes place, and thus, to gather evidences for competency-assessment using enriched rubrics. The lack of data interoperability and the decentralization of those educational applications set out a challenge to exploit trace data. To face these problems we have designed and developed SCALA (Scalable Competence Assessment through a Learning Analytics approach), an analytics system that integrates usage-how the user interacts with resources-and social-how students and teachers interact among them-trace data to support competency assessment. The case study of SCALA presents teachers a dashboard with enriched rubrics of blended datasets obtained from six assessment learning activities, performed with a group of 28 students working teamwork competency. In terms of knowledge discovery, we obtain results applying clustering and association rule mining algorithms. Thus, we provide a visual analytics tool ready to support competency-assessment.},
	author_keywords = {Data integration; Information retrieval; Large-scale interoperability; Learning analytics; Learning dashboard},
	keywords = {Data mining; Ecology; Ecosystems; Education; Information retrieval; Interoperability; Students; Teaching; Competence assessments; Competency assessment; Computer-mediated learning; Data interoperability; Educational Applications; Learning analytics; Learning dashboard; Rule mining algorithms; Data integration},
	editor = {Garcia-Penalvo F.J. and University of Salamanca, Research Institute for Educational Sciences (IUCE), Department of Computer Science and Automatics, Plaza de los Caidos s/n, Salamanca},
	publisher = {Association for Computing Machinery},
	isbn = {978-145032896-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Tobarra2014,
	author = {Tobarra, Llanos and Ros, Salvador and Hernández, Roberto and Robles-Gómez, Antonio and Caminero, Agustín C. and Pastor, Rafael},
	title = {Integrated Analytic dashboard for virtual evaluation laboratories and collaborative forums},
	year = {2014},
	journal = {Proceedings of XI Tecnologias Aplicadas a la Ensenanza de la Electronica (Technologies Applied to Electronics Teaching), TAEE 2014},
	doi = {10.1109/TAEE.2014.6900177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931441080&doi=10.1109%2fTAEE.2014.6900177&partnerID=40&md5=e9c504eb7d3bee0a7530ee480abdfc60},
	affiliations = {Control and Communication Systems Department, Spanish University for Distance Education, UNED, Spain},
	abstract = {This paper presents a new Learning Analytics dashboard which integrates all the information gathered by a virtual evaluation laboratory deployed at our institution and, also, the collaborative evaluation forums used by students in our courses. As an example, a subject focused on the configuration of network services has been chosen to implement our approach. Our proposal will be able to graphically show the students' progress both in an experimental and collaborative way at the same time. Therefore, lecturers can guide each student through the learning process based on his/her particular knowledge-level and grade her/him at the end of the term. Some specific techniques are needed by the system, in our case Learning Analytics techniques are used, in order to observe the students' behavior and their level of proficiency. In particular, a set of evaluation events for each activity, the students' social network, the students' timeline for their activities and some relevant metrics associated to them are given. © 2014 IEEE.},
	author_keywords = {Assessment and Evaluation Strategies; Collaborative Forums; Distance Education; Learning Analytics (LA); Virtual/Remote Laboratories},
	keywords = {Learning systems; Students; Collaborative evaluation; Collaborative Forums; Evaluation strategies; Knowledge level; Learning Analytics (LA); Learning process; Network services; Students' behaviors; Distance education},
	correspondence_address = {L. Tobarra; Control and Communication Systems Department, Spanish University for Distance Education, UNED, Spain; email: llanos@scc.uned.es},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-147996002-6},
	language = {English},
	abbrev_source_title = {Proc. Tecnol. Apl. Ensen. Electr. (Technol. Appl. Electr. Teach.), TAEE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Aljohani2013262,
	author = {Aljohani, Naif Radi and Davis, Hugh C.},
	title = {Learning analytics and formative assessment to provide immediate detailed feedback using a student centered mobile dashboard},
	year = {2013},
	journal = {International Conference on Next Generation Mobile Applications, Services, and Technologies},
	pages = {262 – 267},
	doi = {10.1109/NGMAST.2013.54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892768025&doi=10.1109%2fNGMAST.2013.54&partnerID=40&md5=951644947bbb3c9928a8d3835fcfa761},
	affiliations = {Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; School of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom},
	abstract = {The 'immediacy' of feedback on academic performance is a common characteristic shared by both Learning Analytics (LA) and Formative Assessment (FA), and such immediacy could be facilitated by supporting the mobility of learners. However, there is little literature that investigates the significance of combining these two techniques. Therefore, this paper will discuss the analytical application called Quiz My Class Understanding (QMCU) which was purposely developed to investigate the significance of the combination between LA and FA techniques in order to provide students with immediate detailed feedback. Furthermore, it reports on a case study which reflects the role QMCU students' centered mobile dashboard in increasing the students' engagement with the QMCU dashboard. © 2013 IEEE.},
	author_keywords = {Immediate Feedback; Learning Analytics; Mobile Formative Assessment; Mobile Learning Analytics Formative Assessment},
	keywords = {Mobile computing; Academic performance; Analytical applications; Detailed feedbacks; Formative assessment; Immediate feedbacks; Learning Analytics; Students' engagements; Students},
	issn = {21612897},
	isbn = {978-147992019-8},
	language = {English},
	abbrev_source_title = {Int. Conf.  Next Gener. Mob. Appli. Serv. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; All Open Access, Green Open Access}
}

@BOOK{Bienkowski20141,
	author = {Bienkowski, Marie and Feng, Mingyu and Means, Barbara},
	title = {Enhancing teaching and learning through educational data mining and learning analytics: An issue brief},
	year = {2014},
	journal = {Educational Improvement Through Data Mining and Analytics},
	pages = {1 – 60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958672748&partnerID=40&md5=dc8f2c223988dc08ea1d9ba0c305c26c},
	abstract = {In data mining and data analytics, tools and techniques once confined to research laboratories are being adopted by forward-looking industries to generate business intelligence for improving decision making. Higher education institutions are beginning to use analytics for improving the services they provide and for increasing student grades and retention. The U.S. Department of Education's National Education Technology Plan, as one part of its model for 21st-century learning powered by technology, envisions ways of using data from online learning systems to improve instruction. With analytics and data mining experiments in education starting to proliferate, sorting out fact from fiction and identifying research possibilitiesand practical applications are not easy. This issue brief is intended to help policymakers and administrators understand how analytics and data mining have been-and can be-applied for educational improvement. At present, educational data mining tends to focus on developing new tools for discovering patterns in data. These patterns are generally about the microconcepts involved in learning: one-digit multiplication, subtraction with carries, and so on. Learning analytics-at least as it is currently contrasted with data mining-focuses on applying tools and techniques at larger scales, such as in courses and at schools and postsecondary institutions. But both disciplines work with patterns and prediction: If we can discern the pattern in the data and make sense of what is happening, we can predict what should come next and take the appropriate action. Educational data mining and learning analytics are used to research and build models in several areas that can influence online learning systems. One area is user modeling, which encompasses what a learner knows, what a learner's behavior and motivation are, what the user experience is like, and how satisfied users are with online learning. At the simplest level, analytics can detect when a student in an online course is going astray and nudge him or her on to a course correction. At the most complex, they hold promise of detecting boredom from patterns of key clicks and redirecting the student's attention. Because these data are gathered in real time, there is a real possibility of continuous improvement via multiple feedback loops that operate at different time scales-immediate to the student for the next problem, daily to the teacher for the next day's teaching, monthly to the principal for judging progress, and annually to the district and state administrators for overall school improvement. The same kinds of data that inform user or learner models can be used to profile users. Profiling as used here means grouping similar users into categories using salient characteristics. These categories then can be used to offer experiences to groups of users or to make recommendations to the users and adaptations to how a system performs. User modeling and profiling are suggestive of real-time adaptations. In contrast, some applications of data mining and analytics are for more experimental purposes. Domain modeling is largely experimental with the goal of understanding how to present a topic and at what level of detail. The study of learning components and instructional principles also uses experimentation to understand what is effective at promoting learning. These examples suggest that the actions from data mining and analytics are always automatic, but that is less often the case. Visual data analyticsclosely involve humans to help make sense of data, from initial pattern detection and model building to sophisticated data dashboards that present data in a way that humans can act upon. K-12 schools and school districts are starting to adopt such institution-level analyses for detecting areas for instructional improvement, setting policies, and measuring results. Making visible students' learning and assessment activities opens up the possibility for students to develop skills in monitoring their own learning and to see directly how their effort improves their success. Teachers gain views into students' performance that help them adapt their teaching or initiate tutoring, tailored assignments, and the like. Robust applications of educational data mining and learning analytics techniques come with costs and challenges. Information technology (IT) departments will understand the costs associated with collecting and storing logged data, while algorithm developers will recognize the computational costs these techniques still require. Another technical challenge is that educational data systems are not interoperable, so bringing together administrative data and classroom-level data remains a challenge. Yet combining these data can give algorithms better predictive power. Combining data about student performance-online tracking, standardized tests, teachergenerated tests-to form one simplified picture of what a student knows can be difficult and must meet acceptable standards for validity. It also requires careful attention to student and teacher privacy and the ethical obligations associated with knowing and acting on student data. Educational data mining and learning analytics have the potential to make visible data that have heretofore gone unseen, unnoticed, and therefore unactionable. To help further the fields and gain value from their practical applications, the recommendations are that educators and administrators: • Develop a culture of using data for making instructional decisions. • Involve IT departments in planning for data collection and use. • Be smart data consumers who ask critical questions about commercial offerings and create demand for the most useful features and uses. • Start with focused areas where data will help, show success, and then expand to new areas. • Communicate with students and parents about where data come from and how the data are used. • Help align state policies with technical requirements for online learning systems.Researchers and software developers are encouraged to: • Conduct research on usability and effectiveness of data displays. • Help instructors be more effective in the classroom with more realtime and data-based decision support tools, including recommendation services. • Continue to research methods for using identified student information where it will help most, anonymizing data when required, and understanding how to align data across different systems. • Understand how to repurpose predictive models developed in one context to another. A final recommendation is to create and continue strong collaboration across research, commercial, and educational sectors. Commercial companies operate on fast development cycles and can produce data useful for research. Districts and schools want properly vetted learning environments. Effective partnerships can help these organizations codesign the best tools. © 2014 Nova Science Publishers, Inc.},
	publisher = {Nova Science Publishers, Inc.},
	isbn = {978-163321374-6; 978-163321358-6},
	language = {English},
	abbrev_source_title = {Educ. Improv. Through Data Min. and Anal.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Grann2014168,
	author = {Grann, Jeff and Bushway, Deborah},
	title = {Competency map: Visualizing student learning to promote student success},
	year = {2014},
	journal = {ACM International Conference Proceeding Series},
	pages = {168 – 172},
	doi = {10.1145/2567574.2567622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898807897&doi=10.1145%2f2567574.2567622&partnerID=40&md5=e524db8d3cbffc70bd6c640fb8efe21c},
	affiliations = {Capella University, Minneapolis, MN 55402, 225 South Sixth Street, United States},
	abstract = {Adult students often struggle to appreciate the relevance of their higher educational experiences to their careers. Capella University's competency map is a dashboard that visually indicates each student's status relative to specific assessed competencies. MBA students who utilize their competency map demonstrate competencies at slightly higher levels and persist in their program at greater rates, even after statistically controlling for powerful covariates, such as course engagement. Copyright © 2014 by the Association for Computing Machinery, Inc.},
	author_keywords = {Competency; Evaluation; Learning analytics; Visualization},
	keywords = {Computer applications; Computer programming; Flow visualization; Competency; Covariates; Educational experiences; Evaluation; Learning analytics; Student learning; Student success; Students},
	publisher = {Association for Computing Machinery},
	isbn = {1595930361; 978-159593036-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@ARTICLE{Softic201374,
	author = {Softic, Selver and Taraghi, Benham and Ebner, Martin and De Vocht, Laurens and Mannens, Erik and Van De Walle, Rik},
	title = {Monitoring learning activities in PLE using semantic modelling of learner behaviour},
	year = {2013},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {7946 LNCS},
	pages = {74 – 90},
	doi = {10.1007/978-3-642-39062-3_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879875492&doi=10.1007%2f978-3-642-39062-3_5&partnerID=40&md5=e0f07490cf4938aa68d089f00582a2e9},
	affiliations = {Graz University of Technology, Department for Social Learning, 8010 Graz, Muenzgrabenstr. 35A, Austria; Ghent University, iMinds, Multimedia Lab., 9000 Ghent, Gaston Crommelaan 8, Belgium},
	abstract = {We report on the reflection of learning activities and revealing hidden information based on tracked user behaviour in our widget based PLE (Personal Learning Environment) at Graz University of Technology. Our reference data set includes information of more then 4000 active learners for a period of around two years. We have modelled activity and usage traces using domain specific ontologies like Activity Ontology and Learning Context Ontology from the IntelLEO EU project. Generally we distinguish three different metrics: user centric, learning object (widget) centric and activity centric. We have used Semantic Web query languages like SPARQL and representation formats like RDF to implement a human and machine readable web service along with a learning analytics dashboard for metrics visualization. The results offer a quick overview of learning habits, preferred set-ups of learning objects (widgets) and overall reflection of usages and activity dynamics in the PLE platform over time. The architecture delivers insights for intervening and recommending as closure of a learning analytics cycle[1] to optimize confidence in the PLE. © 2013 Springer-Verlag.},
	author_keywords = {Learning Analytics; PLE; RDF; Reflection; Semantic Web; SPARQL},
	keywords = {Behavioral research; Human engineering; Information science; Query languages; Reflection; Semantic Web; Web services; Activity ontologies; Domain-specific ontologies; Learning Analytics; Personal learning environment; PLE; RDF; SPARQL; Web Query Languages; Computer aided instruction},
	issn = {16113349},
	isbn = {978-364239061-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Taibi2013,
	author = {Taibi, Davide and Sándor, Ágnes and Simsek, Duygu and Shum, Simon Buckingham and Deliddo, Anna and Ferguson, Rebecca},
	title = {Visualizing the LAK/EDM literature using combined concept and rhetorical sentence extraction},
	year = {2013},
	journal = {CEUR Workshop Proceedings},
	volume = {974},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922785658&partnerID=40&md5=1fb7a9d9a9a1ca3080f5ee1b51d05d3f},
	affiliations = {Institute for Educational Technologies, Italian National Research Council, via Ugo la Malfa 153, Palermo, 90146, Italy; Parsing and Semantics Group, Xerox Research Centre Europe, 6 Chemin de Maupertuis, Meylan, F-38240, France; Open University Knowledge Media Institute, Institute of Educational Technology Milton Keynes, MK7 6AA, United Kingdom},
	abstract = {Scientific communication demands more than the mere listing of empirical findings or assertion of beliefs. Arguments must be constructed to motivate problems, expose weaknesses, justify higher-order concepts, and support claims to be advancing the field. Researchers learn to signal clearly in their writing when they are making such moves, and the progress of natural language processing technology has made it possible to combine conventional concept extraction with rhetorical analysis that detects these moves. To demonstrate the potential of this technology, this short paper documents preliminary analyses of the dataset published by the Society for Learning Analytics, comprising the full texts from primary conferences and journals in Learning Analytics and Knowledge (LAK) and Educational Data Mining (EDM). We document the steps taken to analyse the papers thematically using Edge Betweenness Clustering, combined with sentence extraction using the Xerox Incremental Parser's rhetorical analysis, which detects the linguistic forms used by authors to signal argumentative discourse moves. Initial results indicate that the refined subset derived from more complex concept extraction and rhetorically significant sentences, yields additional relevant clusters. Finally, we illustrate how the results of this analysis can be rendered as a visual analytics dashboard.},
	author_keywords = {Corpus analysis; Learning analytics; Natural language processing; Network analysis; Scientific rhetoric; Visualization},
	keywords = {Complex networks; Computational linguistics; Data mining; Electric network analysis; Extraction; Flow visualization; Natural language processing systems; Syntactics; Visualization; Corpus analysis; Educational data minings (EDM); Learning analytics; NAtural language processing; Preliminary analysis; Scientific communication; Scientific rhetoric; Sentence extraction; Engineering education},
	editor = {Dietze S. and d'Aquin M. and Drachsler H. and Taibi D. and Herder E.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Verbert20131500,
	author = {Verbert, Katrien and Duval, Erik and Klerkx, Joris and Govaerts, Sten and Santos, José Luis},
	title = {Learning Analytics Dashboard Applications},
	year = {2013},
	journal = {American Behavioral Scientist},
	volume = {57},
	number = {10},
	pages = {1500 – 1509},
	doi = {10.1177/0002764213479363},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883400392&doi=10.1177%2f0002764213479363&partnerID=40&md5=900408eb0c6cbd0726dbde85c60b93e6},
	affiliations = {Department of Computer Science, KU Leuven, Leuven, Belgium; Department of Computer Science, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Computer Science, EPFL, Lausanne, Switzerland},
	abstract = {This article introduces learning analytics dashboards that visualize learning traces for learners and teachers. We present a conceptual framework that helps to analyze learning analytics applications for these kinds of users. We then present our own work in this area and compare with 15 related dashboard applications for learning. Most evaluations evaluate only part of our conceptual framework and do not assess whether dashboards contribute to behavior change or new understanding, probably also because such assessment requires longitudinal studies. © 2013 SAGE Publications.},
	author_keywords = {information visualization; learning analytics; learning dashboards},
	correspondence_address = {E. Duval; Departement Computerwetenschappen, KU Leuven, B-3001 Leuven, Celestijnenlaan 200A, Belgium; email: erik.duval@cs.kuleuven.be},
	issn = {15523381},
	language = {English},
	abbrev_source_title = {Am. Behav. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 504; All Open Access, Bronze Open Access, Green Open Access}
}