
@article{ WOS:000647887900001,
Author = {Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and
   Huggins-Manley, Anne Corinne},
Title = {Staying on target: A systematic literature review on learner-facing
   learning analytics dashboards},
Journal = {BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY},
Year = {2021},
Volume = {52},
Number = {4},
Pages = {1724-1748},
Month = {JUL},
Abstract = {The advances in technology to capture and process unprecedented amounts
   of educational data has boosted the interest in Learning Analytics
   Dashboard (LAD) applications as a way to provide meaningful visual
   information to administrators, parents, teachers and learners. Despite
   the frequent argument that LADs are useful to support target users and
   their goals to monitor and act upon the information provided, little is
   known about LADs' theoretical underpinnings and the alignment (or lack
   thereof) between LADs intended outcomes and the measures used to
   evaluate their implementation. However, this knowledge is necessary to
   illuminate more efficient approaches in the development and
   implementation of LAD tools. Guided by the self-regulated learning
   perspective and using the Preferred Reporting Items for Systematic
   Reviews and Meta-Analyses (PRISMA) framework, this systematic literature
   review addressed this gap by examining whether and how learner-facing
   LAD's target outcomes align with the domain measures used to evaluate
   their implementations. Out of the 1297 papers retrieved from 15
   databases, 28 were included in the final quantitative and qualitative
   analysis. Results suggested an intriguing lack of alignment between
   LADs' intended outcomes (mostly cognitive domain) and their evaluation
   (mostly affective measures). Based on these results and on the premise
   that LADs are designed to support learners, a critical recommendation
   from this study is that LADs' target outcomes should guide the selection
   of measures used to evaluate the efficacy of these tools. This alignment
   is critical to enable the construction of more robust guidelines to
   inform future endeavours in the field.
   Practitioner notes
   What is already known about this topic
   There has been an increased interest and investment in learning
   analytics dashboards to support learners as end-users.
   Learner-facing learning analytics dashboards are designed with different
   purposes, functionalities and types of data in an attempt to influence
   learners' behaviour, achievement and skills.
   What this paper adds
   This paper reports trends and opportunities regarding the design of
   learner-facing learning analytics dashboards, contexts of
   implementation, as well as types and features of learner-facing learning
   analytics dashboard studies.
   The paper discusses how affect and motivation have been largely
   overlooked as target outcomes in learner-facing learning analytics
   dashboards.
   Implications for practice and/or policy
   Based on the evidence gathered through the review, this paper makes
   recommendations for theory (eg, inclusion of motivation as an important
   target outcome).
   The paper makes recommendations related to the design, implementation
   and evaluation of learning analytics dashboards.
   The paper also highlights the need for further integration between
   learner-facing learning analytics dashboards and open learner models.},
DOI = {10.1111/bjet.13089},
EarlyAccessDate = {MAY 2021},
ISSN = {0007-1013},
EISSN = {1467-8535},
ResearcherID-Numbers = {Antonenko, Pavlo/GPK-6167-2022
   },
ORCID-Numbers = {Dawson, Kara/0000-0002-1855-0719
   Valle, Natercia/0000-0003-0345-9979},
Unique-ID = {WOS:000647887900001},
}

@article{ WOS:000396399600004,
Author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk,
   Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer,
   Adrian and Gillet, Denis and Dillenbourg, Pierre},
Title = {Perceiving Learning at a Glance: A Systematic Literature Review of
   Learning Dashboard Research},
Journal = {IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES},
Year = {2017},
Volume = {10},
Number = {1},
Pages = {30-41},
Month = {JAN-MAR},
Abstract = {This paper presents a systematic literature review of the
   state-of-the-art of research on learning dashboards in the fields of
   Learning Analytics and EducationalDataMining. Research on learning
   dashboards aims to identify what data ismeaningful to different
   stakeholders and how data can be presented to support sense-making
   processes. Learning dashboards are becoming popular due to the increased
   use of educational technologies, such as LearningManagement Systems
   (LMS) andMassive Open OnlineCourses (MOOCs). The initial search of
   fivemain academic databases and GScholar resulted in 346 papers out
   ofwhich 55 papers were included in the final analysis. Our review
   distinguishes different kinds of research studies aswell as various
   aspects of learning dashboards and theirmaturity regarding evaluation.
   As the research field is still relatively young, most studies are
   exploratory and proof-of-concept. The review concludes by offering a
   definition for learning dashboards and by outlining open issues and
   future lines ofwork in the area of learning dashboards. There is a need
   for longitudinal research in authentic settings and studies that
   systematically compare different dashboard designs.},
DOI = {10.1109/TLT.2016.2599522},
ISSN = {1939-1382},
ResearcherID-Numbers = {Schwendimann, Beat A/G-4849-2015
   Prieto, Luis P./K-4236-2015
   Prieto, Luis Enrique/HFZ-7903-2022
   Rodríguez-Triana, María Jesús/AHI-6443-2022
   },
ORCID-Numbers = {Schwendimann, Beat A/0000-0001-6526-1795
   Prieto, Luis P./0000-0002-0057-0682
   Rodríguez-Triana, María Jesús/0000-0001-8639-1257
   Holzer, Adrian/0000-0001-7946-1552},
Unique-ID = {WOS:000396399600004},
}

@article{ WOS:001018397000001,
Author = {Ley, Tobias and Tammets, Kairit and Pishtari, Gerti and Chejara, Pankaj
   and Kasepalu, Reet and Khalil, Mohammad and Saar, Merike and Tuvi, Iiris
   and Vaeljataga, Terje and Wasson, Barbara},
Title = {Towards a partnership of teachers and intelligent learning technology: A
   systematic literature review of model-based learning analytics},
Journal = {JOURNAL OF COMPUTER ASSISTED LEARNING},
Year = {2023},
Volume = {39},
Number = {5},
Pages = {1397-1417},
Month = {OCT},
Abstract = {BackgroundWith increased use of artificial intelligence in the
   classroom, there is now a need to better understand the complementarity
   of intelligent learning technology and teachers to produce effective
   instruction. ObjectiveThe paper reviews the current research on
   intelligent learning technology designed to make models of student
   learning and instruction transparent to teachers, an area we call
   model-based learning analytics. We intended to gain an insight into the
   coupling between the knowledge models that underpin the intelligent
   system and the knowledge used by teachers in their classroom decision
   making. MethodsUsing a systematic literature review methodology, we
   first identified 42 papers, mainly from the domain of intelligent
   tutoring systems and learning analytics dashboards that conformed to our
   selection criteria. We then qualitatively analysed the context in which
   the systems were applied, models they used and benefits reported for
   teachers and learners. Results and ConclusionsA majority of papers used
   either domain or learner models, suggesting that instructional decisions
   are mostly left to teachers. Compared to previous reviews, our set of
   papers appeared to have a stronger focus on providing teachers with
   theory-driven insights and instructional decisions. This suggests that
   model-based learning analytics can address some of the shortcomings of
   the field, like meaningfulness and actionability of learning analytics
   tools. However, impact in the classroom still needs further research, as
   in half of the cases the reported benefits were not backed with
   evidence. Future research should focus on the dynamic interaction
   between teachers and technology and how learning analytics has an impact
   on learning and decision making by teachers and students. We offer a
   taxonomy of knowledge models that can serve as a starting point for
   designing such interaction.},
DOI = {10.1111/jcal.12844},
EarlyAccessDate = {JUN 2023},
ISSN = {0266-4909},
EISSN = {1365-2729},
ResearcherID-Numbers = {Khalil, Mohammad/G-9275-2016
   Khalil, Mohammad/ABC-1628-2022
   },
ORCID-Numbers = {Khalil, Mohammad/0000-0002-6860-4404
   Khalil, Mohammad/0000-0002-6860-4404
   Wasson, Barbara/0000-0003-4897-1394},
Unique-ID = {WOS:001018397000001},
}

@inproceedings{ WOS:000694009400006,
Author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler,
   Hendrik},
Book-Group-Author = {ACM},
Title = {License to Evaluate: Preparing Learning Analytics Dashboards for
   Educational Practice},
Booktitle = {PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS \&
   KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS},
Year = {2018},
Pages = {31-40},
Note = {8th International Conference on Learning Analytics and Knowledge (LAK) -
   Towards User-Centred Learning Analytics, Sydney, AUSTRALIA, MAR 05-09,
   2018},
Abstract = {Learning analytics can bridge the gap between learning sciences and data
   analytics, leveraging the expertise of both fields in exploring the vast
   amount of data generated in online learning environments. A typical
   learning analytics intervention is the learning dashboard, a
   visualisation tool built with the purpose of empowering teachers and
   learners to make informed decisions about the learning process. Related
   work has investigated learning dashboards, yet none have explored the
   theoretical foundation that should inform the design and evaluation of
   such interventions. In this systematic literature review, we analyse the
   extent to which theories and models from learning sciences have been
   integrated into the development of learning dashboards aimed at
   learners. Our analysis revealed that very few dashboard evaluations take
   into account the educational concepts that were used as a theoretical
   foundation for their design. Furthermore, we report findings suggesting
   that comparison with peers, a common reference frame for contextualising
   information on learning analytics dashboards, was not perceived
   positively by all learners. We summarise the insights gathered through
   our literature review in a set of recommendations for the design and
   evaluation of learning analytics dashboards for learners.},
DOI = {10.1145/3170358.3170421},
ISBN = {978-1-4503-6400-3},
ResearcherID-Numbers = {Jivet, Ioana/AAW-7088-2021
   },
ORCID-Numbers = {Jivet, Ioana/0000-0002-8715-2642
   Drachsler, Hendrik/0000-0001-8407-5314
   Scheffel, Maren/0000-0003-4395-4819},
Unique-ID = {WOS:000694009400006},
}

@article{ WOS:000886313000002,
Author = {Banihashem, Seyyed Kazem and Noroozi, Omid and van Ginkel, Stan and
   Macfadyen, Leah P. and Biemans, Harm J. A.},
Title = {A systematic review of the role of learning analytics in enhancing
   feedback practices in higher education},
Journal = {EDUCATIONAL RESEARCH REVIEW},
Year = {2022},
Volume = {37},
Month = {NOV},
Abstract = {Learning analytics (LA) offers new opportunities to enrich feedback
   practices in higher education, but little is understood about the ways
   different LA can enhance feedback practices for educators and students.
   This systematic literature review maps the current state of
   implementation of LA to improve feedback practices in
   technology-mediated learning environments in higher education. We used
   strict inclusion criteria to select relevant studies that have
   investigated the role of LA on feedback practices. To identify common
   features of LA for feedback studies, we coded relevant publications
   using an analytical framework that identifies four key dimensions of LA
   systems: what (types of data), how (analytic methods), why (objectives),
   and how educators and students are served by LA (stakeholders). Based on
   findings, we propose a conceptual framework that can guide the
   implementation of LA for feedback systems and also suggest future
   empirical research in this area.},
DOI = {10.1016/j.edurev.2022.100489},
EarlyAccessDate = {NOV 2022},
Article-Number = {100489},
ISSN = {1747-938X},
EISSN = {1878-0385},
ORCID-Numbers = {Banihashem, Seyyed Kazem/0000-0002-9978-3783
   Biemans, Harm/0000-0003-2955-8211},
Unique-ID = {WOS:000886313000002},
}

@inproceedings{ WOS:000390844700088,
Author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk,
   Andrii and Prieto, Luis P. and Boroujenii, Mina Shirvani and Holzer,
   Adrian and Gillet, Denis and Dillenbourg, Pierre},
Book-Group-Author = {ACM},
Title = {Understanding learning at a glance: An overview of learning dashboard
   studies},
Booktitle = {LAK `16 CONFERENCE PROCEEDINGS: THE SIXTH INTERNATIONAL LEARNING
   ANALYTICS \& KNOWLEDGE CONFERENCE,},
Year = {2016},
Pages = {532-533},
Note = {6th International Conference on Learning Analytics and Knowledge (LAK),
   Univ Edinburgh, Edinburgh, SCOTLAND, APR 25-29, 2016},
Organization = {Soc Learning Analyt Res; ACM},
Abstract = {Research on learning dashboards aims to identify what data is meaningful
   to different stakeholders in education, and how data can be presented to
   support sense-making processes. This paper summarizes the main outcomes
   of a systematic literature review on learning dashboards, in the fields
   of Learning Analytics and Educational Data Mining The query was run in
   five main academic databases and enriched with papers coming from
   GScholar, resulting in 346 papers out of which 55 were included in the
   final analysis. Our review distinguishes different kinds of research
   studies as well as different aspects of learning dashboards and their
   maturity in terms of evaluation. As the research field is still
   relatively young, many of the studies are exploratory and
   proof-of-concept. Among the main open issues and future lines of work in
   the area of learning dashboards, we identify the need for longitudinal
   research in authentic settings, as well as studies that systematically
   compare different dashboard design options.},
DOI = {10.1145/2883851.2883930},
ISBN = {978-1-4503-4190-5},
ResearcherID-Numbers = {Schwendimann, Beat A/G-4849-2015
   Prieto, Luis Enrique/HFZ-7903-2022
   Rodríguez-Triana, María Jesús/AHI-6443-2022
   Prieto, Luis P./K-4236-2015
   Prieto, Luis P./HTQ-9993-2023
   Prieto, Luis P./V-5313-2019
   },
ORCID-Numbers = {Schwendimann, Beat A/0000-0001-6526-1795
   Rodríguez-Triana, María Jesús/0000-0001-8639-1257
   Prieto, Luis P./0000-0002-0057-0682
   Prieto, Luis P./0000-0002-0057-0682
   Prieto, Luis P./0000-0002-0057-0682
   Holzer, Adrian/0000-0001-7946-1552},
Unique-ID = {WOS:000390844700088},
}

@article{ WOS:000551439300001,
Author = {Ifenthaler, Dirk and Yau, Jane Yin-Kim},
Title = {Utilising learning analytics to support study success in higher
   education: a systematic review},
Journal = {ETR\&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT},
Year = {2020},
Volume = {68},
Number = {4, SI},
Pages = {1961-1990},
Month = {AUG},
Abstract = {Study success includes the successful completion of a first degree in
   higher education to the largest extent, and the successful completion of
   individual learning tasks to the smallest extent. Factors affecting
   study success range from individual dispositions (e.g., motivation,
   prior academic performance) to characteristics of the educational
   environment (e.g., attendance, active learning, social embeddedness).
   Recent developments in learning analytics, which are a socio-technical
   data mining and analytic practice in educational contexts, show promise
   in enhancing study success in higher education, through the collection
   and analysis of data from learners, learning processes, and learning
   environments in order to provide meaningful feedback and scaffolds when
   needed. This research reports a systematic review focusing on empirical
   evidence, demonstrating how learning analytics have been successful in
   facilitating study success in continuation and completion of students'
   university courses. Using standardised steps of conducting a systematic
   review, an initial set of 6220 articles was identified. The final sample
   includes 46 key publications. The findings obtained in this systematic
   review suggest that there are a considerable number of learning
   analytics approaches which utilise effective techniques in supporting
   study success and students at risk of dropping out. However, rigorous,
   large-scale evidence of the effectiveness of learning analytics in
   supporting study success is still lacking. The tested variables,
   algorithms, and methods collected in this systematic review can be used
   as a guide in helping researchers and educators to further improve the
   design and implementation of learning analytics systems.},
DOI = {10.1007/s11423-020-09788-z},
EarlyAccessDate = {JUN 2020},
ISSN = {1042-1629},
EISSN = {1556-6501},
ORCID-Numbers = {Ifenthaler, Dirk/0000-0002-2446-6548
   Yau, Jane Yin-Kim/0000-0001-6688-7079},
Unique-ID = {WOS:000551439300001},
}

@inproceedings{ WOS:000480393500007,
Author = {Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht,
   Marcus},
Editor = {Lavoue, E and Drachsler, H and Verbert, K and Broisin, J and PerezSanagustin, M},
Title = {Awareness Is Not Enough: Pitfalls of Learning Analytics Dashboards in
   the Educational Practice},
Booktitle = {DATA DRIVEN APPROACHES IN DIGITAL EDUCATION},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10474},
Pages = {82-96},
Note = {12th European Conference on Technology Enhanced Learning (EC-TEL), Univ
   Tallinn, Tallinn, ESTONIA, SEP 12-15, 2017},
Abstract = {It has been long argued that learning analytics has the potential to act
   as a ``middle space{''} between the learning sciences and data
   analytics, creating technical possibilities for exploring the vast
   amount of data generated in online learning environments. One common
   learning analytics intervention is the learning dashboard, a support
   tool for teachers and learners alike that allows them to gain insight
   into the learning process. Although several related works have
   scrutinised the state-of-the-art in the field of learning dashboards,
   none have addressed the theoretical foundation that should inform the
   design of such interventions. In this systematic literature review, we
   analyse the extent to which theories and models from learning sciences
   have been integrated into the development of learning dashboards aimed
   at learners. Our critical examination reveals the most common
   educational concepts and the context in which they have been applied. We
   find evidence that current designs foster competition between learners
   rather than knowledge mastery, offering misguided frames of reference
   for comparison.},
DOI = {10.1007/978-3-319-66610-5\_7},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-66610-5; 978-3-319-66609-9},
ResearcherID-Numbers = {Jivet, Ioana/AAW-7088-2021
   },
ORCID-Numbers = {Jivet, Ioana/0000-0002-8715-2642
   Scheffel, Maren/0000-0003-4395-4819
   Drachsler, Hendrik/0000-0001-8407-5314},
Unique-ID = {WOS:000480393500007},
}

@article{ WOS:000979503900001,
Author = {Kaliisa, Rogers and Jivet, Ioana and Prinsloo, Paul},
Title = {A checklist to guide the planning, designing, implementation, and
   evaluation of learning analytics dashboards},
Journal = {INTERNATIONAL JOURNAL OF EDUCATIONAL TECHNOLOGY IN HIGHER EDUCATION},
Year = {2023},
Volume = {20},
Number = {1},
Month = {MAY 3},
Abstract = {Higher education institutions are moving to design and implement
   teacher-facing learning analytics (LA) dashboards with the hope that
   instructors can extract deep insights about student learning and make
   informed decisions to improve their teaching. While much attention has
   been paid to developing teacher-facing dashboards, less is known about
   how they are designed, implemented and evaluated. This paper presents a
   systematic literature review of existing studies reporting on
   teacher-facing LA dashboards. Out of the 1968 articles retrieved from
   several databases, 50 articles were included in the final analysis.
   Guided by several frameworks, articles were coded based on the following
   dimensions: purpose, theoretical grounding, stakeholder involvement,
   ethics and privacy, design, implementation, and evaluation criteria. The
   findings show that most dashboards are designed to increase teachers'
   awareness but with limited actionable insights to allow intervention.
   Moreover, while teachers are involved in the design process, this is
   mainly at the exploratory/problem definition stage, with little input
   beyond this stage. Most dashboards were prescriptive, less customisable,
   and implicit about the theoretical constructs behind their designs. In
   addition, dashboards are deployed at prototype and pilot stages, and the
   evaluation is dominated by self-reports and users' reactions with
   limited focus on changes to teaching and learning. Besides, only one
   study considered privacy as a design requirement. Based on the findings
   of the study and synthesis of existing literature, we propose a
   four-dimensional checklist for planning, designing, implementing and
   evaluating LA dashboards.},
DOI = {10.1186/s41239-023-00394-6},
Article-Number = {28},
ISSN = {2365-9440},
ORCID-Numbers = {Kaliisa, Rogers/0000-0001-6528-8517},
Unique-ID = {WOS:000979503900001},
}

@article{ WOS:001007580400001,
Author = {Pishtari, Gerti and Ley, Tobias and Khalil, Mohammad and Kasepalu, Reet
   and Tuvi, Iiris},
Title = {Model-Based Learning Analytics for a Partnership of Teachers and
   Intelligent Systems: A Bibliometric Systematic Review},
Journal = {EDUCATION SCIENCES},
Year = {2023},
Volume = {13},
Number = {5},
Month = {MAY 15},
Abstract = {This paper presents a bibliometric systematic review on model-based
   learning analytics (MbLA), which enable coupling between teachers and
   intelligent systems to support the learning process. This is achieved
   through systems that make their models of student learning and
   instruction transparent to teachers. We use bibliometric network
   analysis and topic modelling to explore the synergies between the
   related research groups and the main research topics considered in the
   42 reviewed papers. Network analysis depicts an early stage community,
   made up of several research groups, mainly from the fields of learning
   analytics and intelligent tutoring systems, which have had little
   explicit and implicit collaboration but do share a common core
   literature. Th resulting topics from the topic modelling can be grouped
   into the ones related to teacher practices, such as awareness and
   reflection, learning orchestration, or assessment frameworks, and the
   ones related to the technology used to open up the models to teachers,
   such as dashboards or adaptive learning architectures. Moreover, results
   show that research in MbLA has taken an individualistic approach to
   student learning and instruction, neglecting social aspects and elements
   of collaborative learning. To advance research in MbLA, future research
   should focus on hybrid teacher-AI approaches that foster the partnership
   between teachers and technology to support the learning process, involve
   teachers in the development cycle from an early stage, and follow an
   interdisciplinary approach.},
DOI = {10.3390/educsci13050498},
Article-Number = {498},
EISSN = {2227-7102},
ResearcherID-Numbers = {Khalil, Mohammad/ABC-1628-2022
   Khalil, Mohammad/G-9275-2016
   Kasepalu, Reet/ABA-2059-2021
   },
ORCID-Numbers = {Khalil, Mohammad/0000-0002-6860-4404
   Khalil, Mohammad/0000-0002-6860-4404
   Kasepalu, Reet/0000-0003-3389-8673
   Tuvi, Iiris/0000-0002-8095-2620
   Pishtari, Gerti/0000-0001-9451-6881},
Unique-ID = {WOS:001007580400001},
}

@article{ WOS:000844908600001,
Author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha and Umer,
   Rahila},
Title = {Use of Predictive Analytics within Learning Analytics Dashboards: A
   Review of Case Studies},
Journal = {TECHNOLOGY KNOWLEDGE AND LEARNING},
Year = {2023},
Volume = {28},
Number = {3},
Pages = {959-980},
Month = {SEP},
Abstract = {Learning analytics dashboards (LADs) provide educators and students with
   a comprehensive snapshot of the learning domain. Visualizations
   showcasing student learning behavioral patterns can help students gain
   greater self-awareness of their learning progression, and at the same
   time assist educators in identifying those students who may be facing
   learning difficulties. While LADs have gained popularity, existing LADs
   are still far behind when it comes to employing predictive analytics
   into their designs. Our systematic literature review has revealed
   limitations in the utilization of predictive analytics tools among
   existing LADs. We find that studies leveraging predictive analytics only
   go as far as identifying the at-risk students and do not employ model
   interpretation or explainability capabilities. This limits the ability
   of LADs to offer data-driven prescriptive advice to students that can
   offer them guidance on appropriate learning adjustments. Further,
   published studies have mostly described LADs that are still at prototype
   stages; hence, robust evaluations of how LADs affect student outcomes
   have not yet been conducted. The evaluations until now are limited to
   LAD functionalities and usability rather than their effectiveness as a
   pedagogical treatment. We conclude by making recommendations for the
   design of advanced dashboards that more fully take advantage of machine
   learning technologies, while using suitable visualizations to project
   only relevant information. Finally, we stress the importance of
   developing dashboards that are ultimately evaluated for their
   effectiveness.},
DOI = {10.1007/s10758-022-09613-x},
EarlyAccessDate = {AUG 2022},
ISSN = {2211-1662},
EISSN = {2211-1670},
ResearcherID-Numbers = {Mathrani, Anuradha/R-7903-2018},
ORCID-Numbers = {Mathrani, Anuradha/0000-0002-9124-2536},
Unique-ID = {WOS:000844908600001},
}

@article{ WOS:000527381500001,
Author = {Pishtari, Gerti and Rodriguez-Triana, Maria J. and Sarmiento-Marquez,
   Edna M. and Perez-Sanagustin, Mar and Ruiz-Calleja, Adolfo and Santos,
   Patricia and Prieto, Luis P. and Serrano-Iglesias, Sergio and Valjataga,
   Terje},
Title = {Learning design and learning analytics in mobile and ubiquitous
   learning: A systematic review},
Journal = {BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY},
Year = {2020},
Volume = {51},
Number = {4},
Pages = {1078-1100},
Month = {JUL},
Abstract = {Mobile and Ubiquitous Learning (m/u-learning) are finding an increasing
   adoption in education. They are often distinguished by hybrid learning
   environments that encompass elements of formal and informal learning, in
   activities that happen in distributed settings (indoors and outdoors),
   across physical and virtual spaces. Despite their purported benefits,
   these environments imply additional complexity in the design, monitoring
   and evaluation of learning activities. The research literature on
   learning design (LD) and learning analytics (LA) has started to deal
   with these issues. This paper presents a systematic literature review of
   LD and LA, in m/u-learning. Apart from providing an overview of the
   current research in the field, this review elicits elements of common
   ground between both communities, as shown by the similar learning
   contexts and complementary research contributions, and based on the
   research gaps, proposes to: address m/u-learning beyond higher education
   settings, reinforce the connection between physical and virtual learning
   spaces, and more systematically align LD and LA processes.},
DOI = {10.1111/bjet.12944},
EarlyAccessDate = {APR 2020},
ISSN = {0007-1013},
EISSN = {1467-8535},
ResearcherID-Numbers = {Prieto, Luis Enrique/HFZ-7903-2022
   Rodríguez-Triana, María Jesús/AHI-6443-2022
   Santos, Patricia/HGB-1720-2022
   Prieto, Luis P./K-4236-2015
   Pérez-Sanangustín, Mar/G-8981-2015
   Perez-Sanagustin, Mar/K-7317-2014
   },
ORCID-Numbers = {Rodríguez-Triana, María Jesús/0000-0001-8639-1257
   Prieto, Luis P./0000-0002-0057-0682
   Perez-Sanagustin, Mar/0000-0001-9854-9963
   Valjataga, Terje/0000-0001-8109-0674},
Unique-ID = {WOS:000527381500001},
}

@inproceedings{ WOS:000552686200002,
Author = {Perez-Alvarez, Ronald and Maldonado-Mahauad, Jorge and Perez-Sanagustin,
   Mar},
Editor = {PammerSchindler, V and PerezSanagustin, M and Drachsler, H and Elferink, R and Scheffel, M},
Title = {Tools to Support Self-Regulated Learning in Online Environments:
   Literature Review},
Booktitle = {LIFELONG TECHNOLOGY-ENHANCED LEARNING, EC-TEL 2018},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {11082},
Pages = {16-30},
Note = {13th European Conference on Technology Enhanced Learning (EC-TEL), Univ
   Leeds, Leeds, ENGLAND, SEP 03-05, 2018},
Abstract = {Self-regulated learning (SRL) skills are especially important in Massive
   Open Online Courses (MOOCs), where teacher guidance is scarce, and
   learners must engage in their learning process trying to succeed and
   achieve their learning goals. However, developing SRL strategies is
   difficult for learners given the autonomy that is required in this kind
   of courses. In order to support learners on this process, researchers
   have proposed a variety of tools designed to support certain aspects of
   self-regulation in online learning environments. Nevertheless, there is
   a lack of study to understand what the commonalities and differences in
   terms of design are, what the results in terms of the effect on
   learners' self-regulation are and which of them could be applied in
   MOOCs. Those are the questions that should be further explored. In this
   paper we present a systematic literature review where 22 tools designed
   to support SRL in online environments were analyzed. Our findings
   indicate that: (1) most of the studies do not evaluate the effect on
   learners' SRL strategies; (2) the use of interactive visualizations has
   a positive effect on learners' motivation; (3) the use of the social
   comparison component has a positive effect on engagement and time
   management; and (4) there is a lack of models to match learners'
   activity with the tools with SRL strategies. Finally, we present the
   lessons learned for guiding the community in the implementation of tools
   to support SRL strategies in MOOCs.},
DOI = {10.1007/978-3-319-98572-5\_2},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-98572-5; 978-3-319-98571-8},
ResearcherID-Numbers = {Pérez-Sanangustín, Mar/G-8981-2015
   Perez-Sanagustin, Mar/K-7317-2014},
ORCID-Numbers = {Maldonado-Mahauad, Jorge/0000-0003-1953-390X
   Perez-Sanagustin, Mar/0000-0001-9854-9963},
Unique-ID = {WOS:000552686200002},
}
