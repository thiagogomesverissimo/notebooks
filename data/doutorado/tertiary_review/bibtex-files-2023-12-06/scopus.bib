Scopus
EXPORT DATE: 06 December 2023

@ARTICLE{Hooshyar2023,
	author = {Hooshyar, Danial and Tammets, Kairit and Ley, Tobias and Aus, Kati and Kollom, Kaire},
	title = {Learning Analytics in Supporting Student Agency: A Systematic Review},
	year = {2023},
	journal = {Sustainability (Switzerland)},
	volume = {15},
	number = {18},
	doi = {10.3390/su151813662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173036349&doi=10.3390%2fsu151813662&partnerID=40&md5=c6e67c3fdc5dcf81077ccd2bf6c01291},
	affiliations = {Centre for Educational Technology, Tallinn University, Tallinn, 10120, Estonia; Center for Digitalisation in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, 3500, Austria; School of Educational Sciences, Tallinn University, Tallinn, 10120, Estonia},
	abstract = {Student agency, or agency for learning, refers to an individual’s ability to act and cause changes during the learning process. Recently, learning analytics (LA) has demonstrated its potential in promoting agency, as it enables students to take an active role in their learning process and supports the development of their self-regulatory skills. Despite the growing interest and potential for supporting student agency, there have yet to be any studies reviewing the extant works dealing with the use of LA in supporting student agency. We systematically reviewed the existing related works in eight major international databases and identified 15 articles. Analysis of these articles revealed that most of the studies aimed to investigate student or educators’ agency experiences, propose design principles for LA, and to a lesser extent, develop LA methods/dashboards to support agency. Of those studies developing LA, none initially explored student agency experiences and then utilized their findings to develop evidence-based LA methods and dashboards for supporting student agency. Moreover, we found that the included articles largely rely on descriptive and diagnostic analytics, paying less attention to predictive analytics and completely overlooking the potential of prescriptive learning analytics in supporting agency. Our findings also shed light on nine key design elements for effective LA support of student agency, including customization, decision-making support, consideration of transparency and privacy, and facilitation of co-design. Surprisingly, we found that no studies have considered the use of LA to support student agency in K–12 education, while higher education has been the focal point of the LA community. Finally, we highlighted the fields of study and data visualization types that the studies mostly targeted and, more importantly, identified eight crucial challenges facing LA in its support of student agency. © 2023 by the authors.},
	author_keywords = {learning analytics; student agency; systematic review; technology-enhanced learning},
	keywords = {decision support system; facilitation; higher education; learning; student; visualization},
	correspondence_address = {D. Hooshyar; Centre for Educational Technology, Tallinn University, Tallinn, 10120, Estonia; email: danial@tlu.ee},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{2019,
	title = {CEUR Workshop Proceedings},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071473110&partnerID=40&md5=60d53aa0a952cdae9caef8fb9f9a5876},
	abstract = {The proceedings contain 9 papers. The topics discussed include: application of learning analytics techniques on blended learning environments for university students; using Simva to evaluate serious games and collect game learning analytics data; extending a dashboard metamodel to account for users' characteristics and goals for enhancing personalization; predicting student performance over time. a case study for a blended-learning engineering course; analyzing students’ persistence using an event-based model; a data value chain to support the processing of multimodal evidence in authentic learning scenarios; and predictors and early warning systems in higher education a systematic literature review.},
	editor = {Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Munoz-Merino P.J. and Universidad Carlos III de Madrid, Department of Telematics Engineering, Av. Universidad 30, Leganes, Madrid and Hernandez-Garcia A. and Universidad Politecnica de Madrid, Departamento de Ingenieria de Organizacion, Administracion de Empresas y Estadistica, Escuela Tecnica Superior de Ingenieros de Telecomunicacion, Av. Complutense 30, Madrid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jivet201831,
	author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
	title = {License to evaluate: Preparing learning analytics dashboards for educational practice},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {31 – 40},
	doi = {10.1145/3170358.3170421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045910955&doi=10.1145%2f3170358.3170421&partnerID=40&md5=f74d0c71750252e72c17a38c5dc42ad8},
	affiliations = {Open University of the Netherlands, Heerlen, Netherlands; Goethe University Frankfurt/DIPF Germany, Open University of the Netherlands, Heerlen, Netherlands},
	abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners. © 2018 Copyright held by the owner/author(s).},
	author_keywords = {Competition; Evaluation; Learning analytics; Learning dashboards; Learning science; Learning theory; Social comparison; Systematic review},
	keywords = {Competition; Computer aided instruction; Teaching; Evaluation; Learning analytics; Learning dashboards; Learning science; Learning Theory; Social comparison; Systematic Review; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 171; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Bodily201841,
	author = {Bodily, Robert and Kay, Judy and Aleven, Vincent and Jivet, Ioana and Davis, Dan and Xhakaj, Franceska and Verbert, Katrien},
	title = {Open learner models and learning analytics dashboards: A systematic review},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {41 – 50},
	doi = {10.1145/3170358.3170409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045874117&doi=10.1145%2f3170358.3170409&partnerID=40&md5=e6a71082257743b6aa99cedba60c86a5},
	affiliations = {Brigham Young University, United States; University of Sydney, Australia; Carnegie Mellon University, United States; Open University of the Netherlands, Netherlands; Delft University of Technology, Netherlands; University of Leuven, Belgium},
	abstract = {This paper aims to link student facing Learning Analytics Dashboards (LADs) to the corpus of research on Open Learner Models (OLMs), as both have similar goals. We conducted a systematic review of literature on OLMs and compared the results with a previously conducted review of LADs for learners in terms of (i) data use and modelling, (ii) key publication venues, (iii) authors and articles, (iv) key themes, and (v) system evaluation. We highlight the similarities and differences between the research on LADs and OLMs. Our key contribution is a bridge between these two areas as a foundation for building upon the strengths of each. We report the following key results from the review: in reports of new OLMs, almost 60% are based on a single type of data; 33% use behavioral metrics; 39% support input from the user; 37% have complex models; and just 6% involve multiple applications. Key associated themes include intelligent tutoring systems, learning analytics, and self-regulated learning. Notably, compared with LADs, OLM research is more likely to be interactive (81% of papers compared with 31% for LADs), report evaluations (76% versus 59%), use assessment data (100% versus 37%), provide a comparison standard for students (52% versus 38%), but less likely to use behavioral metrics, or resource use data (33% against 75% for LADs). In OLM work, there was a heightened focus on learner control and access to their own data. © 2018 Association for Computing Machinery.},
	author_keywords = {Learning analytics dashboards; Literature review; Open learner models; Open student models},
	keywords = {Access control; Computer aided instruction; Students; Comparison standard; Intelligent tutoring system; Learning analytics; Literature reviews; Multiple applications; Open learner models; Open student models; Self-regulated learning; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 100; All Open Access, Green Open Access}
}

@ARTICLE{2020,
	title = {8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12203 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088805510&partnerID=40&md5=516462f552de8a6a63bb65179826560d},
	abstract = {The proceedings contain 50 papers. The special focus in this conference is on Distributed, Ambient and Pervasive Interactions. The topics include: Designing an Interactive Platform for Intangible Cultural Heritage Knowledge of Taoyuan Woodcarving Craft; circuit Game: A Craft-Based Electronic Building Practice; going Beyond Computer-Assisted Vocabulary Learning: Research Synthesis and Frameworks; Returning to Nature: VR Mediated States of Enhanced Wellness; visualization and Analysis for Supporting Teachers Using Clickstream Data and Eye Movement Data; visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students; applying Deep Learning in Creative Re-creation of Changsha Kiln Cultural Relics; rethinking User Interaction with Smart Environments—A Comparative Study of Four Interaction Modalities; Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard; smart Learning in the Community: Supporting Citizen Digital Skills and Literacies; tele Echo Tube for Historic House Tojo-Tei in Matsudo International Science Art Festival 2018; motivating Physical Exercise in the Elderly with Mixed Reality Experiences; computer Vision on Wheelchairs: Detecting Sleeping Behavior of People with Intellectual Disabilities; factors Influencing the Acceptance and Usage of Smart City Services: A Systematic Review and Meta-analysis; civic Crowdsensing Through Location-Aware Virtual Monsters; participatory Governance in Smart Cities: Future Scenarios and Opportunities; Adaptability and Attuning in Smart Cities: Exploring the HCI Grand Challenge of Learning and Creativity; investigating Users Attitudes and Perceptions Towards the Usage of Smart City Apps; accessibility in Pervasive Systems: An Exploratory Study; digitally Enhancing Society Through Structuralism: Virtualizing Collective Human Eyesight and Hearing Capabilities as a Case Study; foreword.},
	editor = {Streitz N. and Konomi S.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050343-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pishtari2023,
	author = {Pishtari, Gerti and Ley, Tobias and Khalil, Mohammad and Kasepalu, Reet and Tuvi, Iiris},
	title = {Model-Based Learning Analytics for a Partnership of Teachers and Intelligent Systems: A Bibliometric Systematic Review},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {5},
	doi = {10.3390/educsci13050498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160032427&doi=10.3390%2feducsci13050498&partnerID=40&md5=45381239f920c885e6bdfa4a9d31beb9},
	affiliations = {Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems, Danube University Krems, Krems an der Donau, 3500, Austria; School of Educational Sciences, Tallinn University, Tallinn, 10120, Estonia; Centre for the Science of Learning & Technology (SLATE), Faculty of Psychology, University of Bergen, Bergen, 5007, Norway; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, 33100, Finland},
	abstract = {This paper presents a bibliometric systematic review on model-based learning analytics (MbLA), which enable coupling between teachers and intelligent systems to support the learning process. This is achieved through systems that make their models of student learning and instruction transparent to teachers. We use bibliometric network analysis and topic modelling to explore the synergies between the related research groups and the main research topics considered in the 42 reviewed papers. Network analysis depicts an early stage community, made up of several research groups, mainly from the fields of learning analytics and intelligent tutoring systems, which have had little explicit and implicit collaboration but do share a common core literature. Th resulting topics from the topic modelling can be grouped into the ones related to teacher practices, such as awareness and reflection, learning orchestration, or assessment frameworks, and the ones related to the technology used to open up the models to teachers, such as dashboards or adaptive learning architectures. Moreover, results show that research in MbLA has taken an individualistic approach to student learning and instruction, neglecting social aspects and elements of collaborative learning. To advance research in MbLA, future research should focus on hybrid teacher–AI approaches that foster the partnership between teachers and technology to support the learning process, involve teachers in the development cycle from an early stage, and follow an interdisciplinary approach. © 2023 by the authors.},
	author_keywords = {adaptive learning technology; bibliometric analysis; dashboards; intelligent tutoring systems; model-based learning analytics; topic modelling},
	correspondence_address = {G. Pishtari; Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems, Danube University Krems, Krems an der Donau, 3500, Austria; email: gerti.pishtari@donau-uni.ac.at},
	publisher = {MDPI},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@BOOK{Chaudy20211803,
	author = {Chaudy, Yaëlle and Connolly, Thomas M.},
	title = {Integrating assessment, feedback, and learning analytics in educational games: Literature review and design of an assessment engine},
	year = {2021},
	journal = {Research Anthology on Developments in Gamification and Game-Based Learning},
	volume = {4-4},
	pages = {1803 – 1846},
	doi = {10.4018/978-1-6684-3710-0.ch088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163656150&doi=10.4018%2f978-1-6684-3710-0.ch088&partnerID=40&md5=8cc5632e76753fcde156628adf17d03e},
	affiliations = {University of the West of Scotland, United Kingdom},
	abstract = {Assessment is a crucial aspect of any teaching and learning process. New tools such as educational games offer promising advantages: they can personalize feedback to students and save educators time by automating the assessment process. However, while many teachers agree that educational games increase motivation, learning, and retention, few are ready to fully trust them as an assessment tool. A likely reason behind this lack of trust is that educational games are distributed as black boxes, unmodifiable by educators and not providing enough insight about the gameplay. This chapter presents three systematic literature reviews looking into the integration of assessment, feedback, and learning analytics in educational games. It then proposes a framework and present a fully developed engine. The engine is used by both developers and educators. Designed to separate game and assessment, it allows teachers to modify the assessment after distribution and visualize gameplay data via a learning analytics dashboard. © 2022, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-166843711-7; 978-166843710-0},
	language = {English},
	abbrev_source_title = {Res. Anthol. on Dev. in Gamification and Game-Based Learn.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pérez-Álvarez201816,
	author = {Pérez-Álvarez, Ronald and Maldonado-Mahauad, Jorge and Pérez-Sanagustín, Mar},
	title = {Tools to Support Self-Regulated Learning in Online Environments: Literature Review},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11082 LNCS},
	pages = {16 – 30},
	doi = {10.1007/978-3-319-98572-5_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053175970&doi=10.1007%2f978-3-319-98572-5_2&partnerID=40&md5=78564dd16be2591661e019ed0b1938e7},
	affiliations = {Department of Computer Science, Pontificia Universidad Católica de Chile, Santiago, Chile; University of Costa Rica, Sede Regional del Pacífico, Puntarenas, Costa Rica; Department of Computer Science, University of Cuenca, Cuenca, Ecuador; Université Toulouse III Paul Sabatier, Toulouse, France},
	abstract = {Self-regulated learning (SRL) skills are especially important in Massive Open Online Courses (MOOCs), where teacher guidance is scarce, and learners must engage in their learning process trying to succeed and achieve their learning goals. However, developing SRL strategies is difficult for learners given the autonomy that is required in this kind of courses. In order to support learners on this process, researchers have proposed a variety of tools designed to support certain aspects of self-regulation in online learning environments. Nevertheless, there is a lack of study to understand what the commonalities and differences in terms of design are, what the results in terms of the effect on learners’ self-regulation are and which of them could be applied in MOOCs. Those are the questions that should be further explored. In this paper we present a systematic literature review where 22 tools designed to support SRL in online environments were analyzed. Our findings indicate that: (1) most of the studies do not evaluate the effect on learners’ SRL strategies; (2) the use of interactive visualizations has a positive effect on learners’ motivation; (3) the use of the social comparison component has a positive effect on engagement and time management; and (4) there is a lack of models to match learners’ activity with the tools with SRL strategies. Finally, we present the lessons learned for guiding the community in the implementation of tools to support SRL strategies in MOOCs. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Learning analytics; Literature review; Massive Open Online Courses; MOOC; Online; Self-Regulated Learning; System; Tools},
	keywords = {Computer aided instruction; Curricula; Deregulation; Engineering education; Learning systems; Teaching; Tools; Visualization; Dashboard; Learning analytics; Literature reviews; Massive open online course; MOOC; Online; Self-regulated learning; System; E-learning},
	correspondence_address = {R. Pérez-Álvarez; Department of Computer Science, Pontificia Universidad Católica de Chile, Santiago, Chile; email: raperez13@uc.cl},
	editor = {Elferink R. and Drachsler H. and Pammer-Schindler V. and Perez-Sanagustin M. and Scheffel M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331998571-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@ARTICLE{Valle20211724,
	author = {Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and Huggins-Manley, Anne Corinne},
	title = {Staying on target: A systematic literature review on learner-facing learning analytics dashboards},
	year = {2021},
	journal = {British Journal of Educational Technology},
	volume = {52},
	number = {4},
	pages = {1724 – 1748},
	doi = {10.1111/bjet.13089},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105201830&doi=10.1111%2fbjet.13089&partnerID=40&md5=52b5f2b1d1986f68fd04d2b9c868df6e},
	affiliations = {School of Teaching and Learning, University of Florida, Gainesville, FL, United States; School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, FL, United States},
	abstract = {The advances in technology to capture and process unprecedented amounts of educational data has boosted the interest in Learning Analytics Dashboard (LAD) applications as a way to provide meaningful visual information to administrators, parents, teachers and learners. Despite the frequent argument that LADs are useful to support target users and their goals to monitor and act upon the information provided, little is known about LADs’ theoretical underpinnings and the alignment (or lack thereof) between LADs intended outcomes and the measures used to evaluate their implementation. However, this knowledge is necessary to illuminate more efficient approaches in the development and implementation of LAD tools. Guided by the self-regulated learning perspective and using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, this systematic literature review addressed this gap by examining whether and how learner-facing LAD’s target outcomes align with the domain measures used to evaluate their implementations. Out of the 1297 papers retrieved from 15 databases, 28 were included in the final quantitative and qualitative analysis. Results suggested an intriguing lack of alignment between LADs’ intended outcomes (mostly cognitive domain) and their evaluation (mostly affective measures). Based on these results and on the premise that LADs are designed to support learners, a critical recommendation from this study is that LADs’ target outcomes should guide the selection of measures used to evaluate the efficacy of these tools. This alignment is critical to enable the construction of more robust guidelines to inform future endeavours in the field. Practitioner notes What is already known about this topic There has been an increased interest and investment in learning analytics dashboards to support learners as end-users. Learner-facing learning analytics dashboards are designed with different purposes, functionalities and types of data in an attempt to influence learners’ behaviour, achievement and skills. What this paper adds This paper reports trends and opportunities regarding the design of learner-facing learning analytics dashboards, contexts of implementation, as well as types and features of learner-facing learning analytics dashboard studies. The paper discusses how affect and motivation have been largely overlooked as target outcomes in learner-facing learning analytics dashboards. Implications for practice and/or policy Based on the evidence gathered through the review, this paper makes recommendations for theory (eg, inclusion of motivation as an important target outcome). The paper makes recommendations related to the design, implementation and evaluation of learning analytics dashboards. The paper also highlights the need for further integration between learner-facing learning analytics dashboards and open learner models. © 2021 British Educational Research Association.},
	author_keywords = {evaluation; learning analytics dashboards; systematic literature review; target outcomes},
	keywords = {Alignment; Facings; Motivation; Affective measures; Cognitive domain; Open learner models; Quantitative and qualitative analysis; Self-regulated learning; Systematic literature review; Systematic Review; Visual information; Learning systems},
	correspondence_address = {N. Valle; School of Teaching and Learning, University of Florida, Gainesville, United States; email: naterciavalle@gmail.com},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{Matcha2020226,
	author = {Matcha, Wannisa and Uzir, Noraayu Ahmad and Gasevic, Dragan and Pardo, Abelardo},
	title = {A Systematic Review of Empirical Studies on Learning Analytics Dashboards: A Self-Regulated Learning Perspective},
	year = {2020},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {13},
	number = {2},
	pages = {226 – 245},
	doi = {10.1109/TLT.2019.2916802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087489008&doi=10.1109%2fTLT.2019.2916802&partnerID=40&md5=e91f2bdafed292e0e2e4b13ee98f6e2f},
	affiliations = {School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; Faculty of Information Technology, Monash University, Clayton, 3800, VIC, Australia; Division of Information Technology Engineering and Environment, University of South Australia, Adelaide, 5000, SA, Australia},
	abstract = {This paper presents a systematic literature review of learning analytics dashboards (LADs) research that reports empirical findings to assess the impact on learning and teaching. Several previous literature reviews identified self-regulated learning as a primary focus of LADs. However, there has been much less understanding how learning analytics are grounded in the literature on self-regulated learning and how self-regulated learning is supported. To address this limitation, this review analyzed the existing empirical studies on LADs based on the well-known model of self-regulated learning proposed by Winne and Hadwin. The results show that existing LADs are rarely grounded in learning theory, cannot be suggested to support metacognition, do not offer any information about effective learning tactics and strategies, and have significant limitations in how their evaluation is conducted and reported. Based on the findings of the study and through the synthesis of the literature, the paper proposes that future research and development should not make any a priori design decisions about representation of data and analytic results in learning analytics systems such as LADs. To formalize this proposal, the paper defines the model for user-centered learning analytics systems (MULAS). The MULAS consists of the four dimensions that are cyclically and recursively interconnected including: theory, design, feedback, and evaluation. © 2008-2011 IEEE.},
	author_keywords = {Dashboards; empirical research; feedback; information visualization; learning analytics; self-regulated learning},
	keywords = {E-learning; Engineering; Effective learning; Empirical findings; Empirical studies; Learning and teachings; Literature reviews; Research and development; Self-regulated learning; Systematic literature review; Learning systems},
	correspondence_address = {D. Gasevic; Faculty of Information Technology, Monash University, Clayton, 3800, Australia; email: dragan.gasevic@monash.edu},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 157}
}

@CONFERENCE{2018,
	title = {ACM International Conference Proceeding Series},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046059060&partnerID=40&md5=b7007878f235d6ad9c378551de76bf7a},
	abstract = {The proceedings contain 60 papers. The topics discussed include: the half-life of MOOC knowledge: a randomized trial evaluating knowledge retention and retrieval practice in MOOCs; graph-based visual topic dependency models: supporting assessment design and delivery at scale; data-driven generation of rubric criteria from an educational programming environment; supporting teacher's intervention in students' virtual collaboration using a network based model; correlating affect and behavior in reasoning mind with state test achievement; license to evaluate: preparing learning analytics dashboards for educational practice; open learner models and learning analytics dashboards: a systematic review; multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in Flanders; a qualitative evaluation of a learning dashboard to support advisor-student dialogues; the classrooom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers; an application of participatory action research in advising-focused learning analytics; profiling students from their questions in a blended learning environment; recurrence quantification analysis as a method for studying text comprehension dynamics; towards a writing analytics framework for adult English language learners; epistemic network analysis of students' longer written assignments as formative/summative evaluation; and the influence of student's cognitive and motivational characteristics on student's use of a 4C/ID-based online learning environment and their learning gain.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2021,
	title = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127131129&partnerID=40&md5=ec64ebefb9873aac187f8ca9cf50d9eb},
	abstract = {The proceedings contain 99 papers. The topics discussed include: predicting student performance using feature selection algorithms for deep learning models; ‘prediction’ in educational research: a bibliographic mapping of academic production over time; tools, resources and techniques for active learning at COVID-19 - a look at the private Brazilian higher education network; teaching computational thinking and introduction to programming through robotics amid the COVID-19 pandemic - an experience report; constraints, effectiveness and solutions in using google classroom as a learning management system during COVID-19 pandemic: a systematic literature review; online collaborative learning: analysis of the current state; meaningful learning: towards a meta-regulated learning model in hybrid education; and systematic mapping of Moodle dashboards focused on learning analytics tasks.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {English},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ley20231397,
	author = {Ley, Tobias and Tammets, Kairit and Pishtari, Gerti and Chejara, Pankaj and Kasepalu, Reet and Khalil, Mohammad and Saar, Merike and Tuvi, Iiris and Väljataga, Terje and Wasson, Barbara},
	title = {Towards a partnership of teachers and intelligent learning technology: A systematic literature review of model-based learning analytics},
	year = {2023},
	journal = {Journal of Computer Assisted Learning},
	volume = {39},
	number = {5},
	pages = {1397 – 1417},
	doi = {10.1111/jcal.12844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160082028&doi=10.1111%2fjcal.12844&partnerID=40&md5=88bc6a6a1caee5e089859e79a36184a6},
	affiliations = {Center for Digitalization in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, Austria; Center for Educational Technology, Tallinn University, Tallinn, Estonia; Centre for the Science of Learning & Technology (SLATE), University of Bergen, Bergen, Norway; Institute of Psychology, University of Tartu, Tartu, Estonia},
	abstract = {Background: With increased use of artificial intelligence in the classroom, there is now a need to better understand the complementarity of intelligent learning technology and teachers to produce effective instruction. Objective: The paper reviews the current research on intelligent learning technology designed to make models of student learning and instruction transparent to teachers, an area we call model-based learning analytics. We intended to gain an insight into the coupling between the knowledge models that underpin the intelligent system and the knowledge used by teachers in their classroom decision making. Methods: Using a systematic literature review methodology, we first identified 42 papers, mainly from the domain of intelligent tutoring systems and learning analytics dashboards that conformed to our selection criteria. We then qualitatively analysed the context in which the systems were applied, models they used and benefits reported for teachers and learners. Results and Conclusions: A majority of papers used either domain or learner models, suggesting that instructional decisions are mostly left to teachers. Compared to previous reviews, our set of papers appeared to have a stronger focus on providing teachers with theory-driven insights and instructional decisions. This suggests that model-based learning analytics can address some of the shortcomings of the field, like meaningfulness and actionability of learning analytics tools. However, impact in the classroom still needs further research, as in half of the cases the reported benefits were not backed with evidence. Future research should focus on the dynamic interaction between teachers and technology and how learning analytics has an impact on learning and decision making by teachers and students. We offer a taxonomy of knowledge models that can serve as a starting point for designing such interaction. © 2023 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {adaptive learning technology; hybrid human-AI technologies; intelligent tutoring systems; learning analytics; systematic literature review; teacher dashboards},
	correspondence_address = {T. Ley; University for Continuing Education Krems, Krems an der Donau, Austria; email: tobias.ley@donau-uni.ac.at},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gauthier2022,
	author = {Gauthier, Andrea and Rizvi, Saman and Cukurova, Mutlu and Mavrikis, Manolis},
	title = {Is it time we get real? A systematic review of the potential of data-driven technologies to address teachers' implicit biases},
	year = {2022},
	journal = {Frontiers in Artificial Intelligence},
	volume = {5},
	doi = {10.3389/frai.2022.994967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140411402&doi=10.3389%2ffrai.2022.994967&partnerID=40&md5=1bdc8efa1793bac3416959863e54bb3a},
	affiliations = {UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom},
	abstract = {Data-driven technologies for education, such as artificial intelligence in education (AIEd) systems, learning analytics dashboards, open learner models, and other applications, are often created with an aspiration to help teachers make better, evidence-informed decisions in the classroom. Addressing gender, racial, and other biases inherent to data and algorithms in such applications is seen as a way to increase the responsibility of these systems and has been the focus of much of the research in the field, including systematic reviews. However, implicit biases can also be held by teachers. To the best of our knowledge, this systematic literature review is the first of its kind to investigate what kinds of teacher biases have been impacted by data-driven technologies, how or if these technologies were designed to challenge these biases, and which strategies were most effective at promoting equitable teaching behaviors and decision making. Following PRISMA guidelines, a search of five databases returned n = 359 records of which only n = 2 studies by a single research team were identified as relevant. The findings show that there is minimal evidence that data-driven technologies have been evaluated in their capacity for supporting teachers to make less biased decisions or promote equitable teaching behaviors, even though this capacity is often used as one of the core arguments for the use of data-driven technologies in education. By examining these two studies in conjunction with related studies that did not meet the eligibility criteria during the full-text review, we reveal the approaches that could play an effective role in mitigating teachers' biases, as well as ones that may perpetuate biases. We conclude by summarizing directions for future research that should seek to directly confront teachers' biases through explicit design strategies within teacher tools, to ensure that the impact of biases of both technology (including data, algorithms, models etc.) and teachers are minimized. We propose an extended framework to support future research and design in this area, through motivational, cognitive, and technological debiasing strategies. Copyright © 2022 Gauthier, Rizvi, Cukurova and Mavrikis.},
	author_keywords = {artificial intelligence in education; bias; decision support systems; equity; learning analytics (LA); teachers},
	correspondence_address = {A. Gauthier; UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom; email: andrea.gauthier@ucl.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jivet201782,
	author = {Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus},
	title = {Awareness is not enough: Pitfalls of learning analytics dashboards in the educational practice},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {82 – 96},
	doi = {10.1007/978-3-319-66610-5_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029587668&doi=10.1007%2f978-3-319-66610-5_7&partnerID=40&md5=520f0178139e3ade3fff9a41e75465d7},
	affiliations = {Open Universiteit, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; Goethe University Frankfurt, Frankfurt, Germany; German Institute for International Educational Research (DIPF), Frankfurt, Germany},
	abstract = {It has been long argued that learning analytics has the potential to act as a “middle space” between the learning sciences and data analytics, creating technical possibilities for exploring the vast amount of data generated in online learning environments. One common learning analytics intervention is the learning dashboard, a support tool for teachers and learners alike that allows them to gain insight into the learning process. Although several related works have scrutinised the state-of-the-art in the field of learning dashboards, none have addressed the theoretical foundation that should inform the design of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our critical examination reveals the most common educational concepts and the context in which they have been applied. We find evidence that current designs foster competition between learners rather than knowledge mastery, offering misguided frames of reference for comparison. © Springer International Publishing AG 2017.},
	author_keywords = {Competition; Learning analytics; Learning dashboards; Learning science; Learning theory; Social comparison; Systematic review},
	keywords = {Competition; Computer aided instruction; E-learning; Learning systems; Teaching; Learning analytics; Learning dashboards; Learning science; Learning Theory; Social comparison; Systematic Review; Education},
	correspondence_address = {I. Jivet; Open Universiteit, Heerlen, Valkenburgerweg 177, 6419 AT, Netherlands; email: ioana.jivet@ou.nl},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 111; All Open Access, Green Open Access}
}

@ARTICLE{Kaliisa2023,
	author = {Kaliisa, Rogers and Jivet, Ioana and Prinsloo, Paul},
	title = {A checklist to guide the planning, designing, implementation, and evaluation of learning analytics dashboards},
	year = {2023},
	journal = {International Journal of Educational Technology in Higher Education},
	volume = {20},
	number = {1},
	doi = {10.1186/s41239-023-00394-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158003907&doi=10.1186%2fs41239-023-00394-6&partnerID=40&md5=106b2f915d5f20a8a0304cccc10e6753},
	affiliations = {Department of Education, The University of Oslo, Blindern 0317, P.O. Box 1092, Oslo, Norway; DIPF & Goethe University Frankfurt, Frankfurt, Germany; Department of Business Management, University of South Africa, Pretoria, South Africa},
	abstract = {Higher education institutions are moving to design and implement teacher-facing learning analytics (LA) dashboards with the hope that instructors can extract deep insights about student learning and make informed decisions to improve their teaching. While much attention has been paid to developing teacher-facing dashboards, less is known about how they are designed, implemented and evaluated. This paper presents a systematic literature review of existing studies reporting on teacher-facing LA dashboards. Out of the 1968 articles retrieved from several databases, 50 articles were included in the final analysis. Guided by several frameworks, articles were coded based on the following dimensions: purpose, theoretical grounding, stakeholder involvement, ethics and privacy, design, implementation, and evaluation criteria. The findings show that most dashboards are designed to increase teachers’ awareness but with limited actionable insights to allow intervention. Moreover, while teachers are involved in the design process, this is mainly at the exploratory/problem definition stage, with little input beyond this stage. Most dashboards were prescriptive, less customisable, and implicit about the theoretical constructs behind their designs. In addition, dashboards are deployed at prototype and pilot stages, and the evaluation is dominated by self-reports and users’ reactions with limited focus on changes to teaching and learning. Besides, only one study considered privacy as a design requirement. Based on the findings of the study and synthesis of existing literature, we propose a four-dimensional checklist for planning, designing, implementing and evaluating LA dashboards. © 2023, The Author(s).},
	author_keywords = {Dashboard evaluation; Learning analytics; Systematic review; Teacher-facing dashboards},
	correspondence_address = {R. Kaliisa; Department of Education, The University of Oslo, Oslo, Blindern 0317, P.O. Box 1092, Norway; email: rogers.kaliisa@iped.uio.no},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23659440},
	language = {English},
	abbrev_source_title = {Int. j. educ. technol. high. educ.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2023,
	title = {Proceedings of the 5th European Conference on Software Engineering Education, ECSEE 2023},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163470474&partnerID=40&md5=4cfa3f4c03413c8edb4204d335a8151f},
	abstract = {The proceedings contain 32 papers. The topics discussed include: reflections on training next-gen industry workforce on secure software development; the gap between higher education and the software industry – a case study on technology differences; using automatic program assessment in a software development project course; using learning analytics to identify student learning profiles for software development courses; learning analytics dashboard for educators: proposed project to design with pedagogical background; towards learning style prediction based on personality; adaptive learning path sequencing based on learning styles within n-dimensional spaces; learning style classification by using Bayesian networks based on the index of learning style; systematic literature review for the use of AI based techniques in adaptive learning management systems; and flipped teaching in software engineering education: results of a long-term study.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039956-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Schwendimann201730,
	author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
	title = {Perceiving learning at a glance: A systematic literature review of learning dashboard research},
	year = {2017},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {10},
	number = {1},
	pages = {30 – 41},
	doi = {10.1109/TLT.2016.2599522},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017624978&doi=10.1109%2fTLT.2016.2599522&partnerID=40&md5=9710190a28a5f0a2b673680e6f968c1c},
	affiliations = {CHILI Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland; REACT Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland},
	abstract = {This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining. Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes. Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs). The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis. Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation. As the research field is still relatively young, most studies are exploratory and proof-of-concept. The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards. There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs. © 2008-2011 IEEE.},
	author_keywords = {dashboards; educational data mining; information visualization; Learning analytics; systematic review},
	keywords = {Data visualization; Education; Enterprise resource planning; Information systems; Online systems; dashboards; Educational data mining; Information visualization; Learning analytics; Systematic Review; Data mining},
	correspondence_address = {B.A. Schwendimann; CHILI Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland; email: beat.schwendimann@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 299}
}

@ARTICLE{2020LNCS,
	title = {7th International Conference on Learning and Collaboration Technologies, LCT 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12205 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089160143&partnerID=40&md5=0b4403462778b0052a8720eb0ddf2c06},
	abstract = {The proceedings contain 86 papers. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Reflective Journaling: A Theoretical Model and Digital Prototype for Developing Resilience and Creativity; prototyping a Touch-Optimized Modeling Tool for Co-located and Inverted Classroom Group Modeling Scenarios; evaluating Portable Touch Projectors in the Context of Digital Education; STEAM-X: An Exploratory Study Adding Interactive Physical Activity to the STEAM Model; usability Testing of a Digital Competence Assessment and Certification System; designing ‘Embodied’ Science Learning Experiences for Young Children; impact of Constant Work on the Students’ Academic Performance; Learning Analytics and MOOCs; on the Design of a Teachers’ Dashboard: Requirements and Insights; evaluation of the Virtual Mobility Learning Hub; mudpoint: Evaluating Instructor Perception on a Continuous and Non-specific Feedback System; characterization of Learners from Their Learning Activities on a Smart Learning Platform; AI-Driven Assessment of Students: Current Uses and Research Trends; generating Dashboards Using Fine-Grained Components: A Case Study for a PhD Programme; learning Analytics and Spelling Acquisition in German – The Path to Individualization in Learning; Building Student Interactions Outside the Classroom: Utilizing a Web-Based Application in a University Flipped Learning Course for EFL Learners; the Impact of Corpus Linguistics on Language Teaching in Russia’s Educational Context: Systematic Literature Review; framework of Manga Application for Teaching Japanese Language; Individualized Differentiated Spelling with Blogs - Implementing and Individualizing (IDeRBlog ii): An Example of a Learning Analytics Platform for the Text-Based Acquisition of Spelling Skills of Students in German.},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050512-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tretow-Fish202237,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin},
	title = {Evaluating Learning Analytics of Adaptive Learning Systems: A Work in Progress Systematic Review},
	year = {2022},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {435 LNICST},
	pages = {37 – 52},
	doi = {10.1007/978-3-031-06675-7_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131941380&doi=10.1007%2f978-3-031-06675-7_3&partnerID=40&md5=1f6f62698fa9028b553174c667cf4798},
	affiliations = {Department of Applied Mathematics and Computer Science at the Technical University of Denmark, Kongens Lyngby, Denmark},
	abstract = {There is currently no systematic overview of methods for evaluating Learning Analytics (LA) and Learning Analytics Dashboards (LAD) of Adaptive Learning Platforms (ALPs). 10 articles and 2 reviews are analyzed and synthesized. Focusing on the purposes of evaluation, methods used in the studies are grouped into five categories (C1-5): C1) evaluation of LA and LAD design and framework, C2) evaluation of performance with LA and LAD, C3) evaluation of adaptivity functions of the system, C4) evaluation of perceived value, and C5) Evaluation of pedagogical and didactic theory/context. While there is a relative high representation of evaluations in the C1-C4 categories of methods, which contribute to the design and development of the interaction and interface design features, the C5 category is not represented. The presence of pedagogical and didactical theory in the LA, LAD, and ALPs is lacking. Though traces of pedagogical theory is present none of the studies evaluates on its impact. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
	author_keywords = {Adaptive learning platforms; Evaluation; Learning analytics},
	keywords = {Learning systems; Adaptive learning; Adaptive learning platform; Adaptive learning systems; Evaluation; Evaluation methods; Learning analytic; Learning platform; Performance; Synthesised; Systematic Review; E-learning},
	correspondence_address = {T.A.B. Tretow-Fish; Department of Applied Mathematics and Computer Science at the Technical University of Denmark, Kongens Lyngby, Denmark; email: compute@compute.dtu.dk},
	editor = {Brooks E. and Sjöberg J. and Møller A.K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18678211},
	isbn = {978-303106674-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ramaswami2023959,
	author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha and Umer, Rahila},
	title = {Use of Predictive Analytics within Learning Analytics Dashboards: A Review of Case Studies},
	year = {2023},
	journal = {Technology, Knowledge and Learning},
	volume = {28},
	number = {3},
	pages = {959 – 980},
	doi = {10.1007/s10758-022-09613-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137037645&doi=10.1007%2fs10758-022-09613-x&partnerID=40&md5=8327c52c6e1d44af400d554cc6003d75},
	affiliations = {School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; Engineering and Management Sciences, Balochistan University of Information Technology, Quetta, Pakistan},
	abstract = {Learning analytics dashboards (LADs) provide educators and students with a comprehensive snapshot of the learning domain. Visualizations showcasing student learning behavioral patterns can help students gain greater self-awareness of their learning progression, and at the same time assist educators in identifying those students who may be facing learning difficulties. While LADs have gained popularity, existing LADs are still far behind when it comes to employing predictive analytics into their designs. Our systematic literature review has revealed limitations in the utilization of predictive analytics tools among existing LADs. We find that studies leveraging predictive analytics only go as far as identifying the at-risk students and do not employ model interpretation or explainability capabilities. This limits the ability of LADs to offer data-driven prescriptive advice to students that can offer them guidance on appropriate learning adjustments. Further, published studies have mostly described LADs that are still at prototype stages; hence, robust evaluations of how LADs affect student outcomes have not yet been conducted. The evaluations until now are limited to LAD functionalities and usability rather than their effectiveness as a pedagogical treatment. We conclude by making recommendations for the design of advanced dashboards that more fully take advantage of machine learning technologies, while using suitable visualizations to project only relevant information. Finally, we stress the importance of developing dashboards that are ultimately evaluated for their effectiveness. © 2022, The Author(s).},
	author_keywords = {Early warning system; Learning analytics dashboard; Student feedback system; Systematic review},
	keywords = {Learning systems; Students; Visualization; Behavioral patterns; Case-studies; Early Warning System; Feedback systems; Learning analytic dashboard; Self awareness; Student feedback; Student feedback system; Student learning; Systematic Review; Predictive analytics},
	correspondence_address = {G. Ramaswami; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; email: g.ramaswami@massey.ac.nz},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Tepgeç2022327,
	author = {Tepgeç, Mustafa and Ifenthaler, Dirk},
	title = {LEARNING ANALYTICS BASED INTERVENTIONS: A SYSTEMATIC REVIEW OF EXPERIMENTAL STUDIES},
	year = {2022},
	journal = {Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022},
	pages = {327 – 330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147522962&partnerID=40&md5=6510b88f15530b0a08ebc3724163d843},
	affiliations = {University of Mannheim, Mannheim, Germany; Curtin University, Australia},
	abstract = {Learning analytics includes interventions that will support learning and improve learning environments. Despite the fact that learning analytics is a promising field of study, the lack of empirical evidence on the effects of learning analytics-based interventions has been widely addressed in recent years. In this context, insights validated by experimental studies may play a crucial role. Therefore, there is a need for a report describing the methodological aspects and effects of current experimental interventions based on learning analytics. This systematic review provides an in-depth examination of learning analytics research that reports experimental findings to evaluate learning analytics-based interventions. The PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 protocol provided the basis for the work of this systematic review. This review contained 52 papers that met the inclusion and exclusion criteria. The results show that student-facing dashboards are the most common learning analytics-based intervention. Evidence from how user data is handled for interventions demonstrates that the most common method is the distillation of data for human judgment. This study confirms that a significant proportion of experimental studies employing learning analytics interventions have demonstrated significant effects on learning outcomes. The effectiveness of learning analytics-based interventions is also addressed in this review in terms of motivation, engagement, and system usage behaviors. The findings of this study will contribute to the literature in terms of describing the experimentally validated findings of learning analytics-based interventions in depth. © 2022 Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022. All rights reserved.},
	author_keywords = {Educational Data Mining; Experimental Studies; Intervention; Learning Analytics; Systematic Literature Review},
	keywords = {Computer aided instruction; Distillation; E-learning; Learning systems; 'current; Educational data mining; Experimental study; Intervention; Learning analytic; Learning environments; Methodological aspects; Support learning; Systematic literature review; Systematic Review; Data mining},
	editor = {Sampson D.G. and Sampson D.G. and Ifenthaler D. and Ifenthaler D. and Isaias P. and Rodrigues L.},
	publisher = {IADIS Press},
	isbn = {978-989870443-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Schwendimann2016532,
	author = {Schwendimann, Beat A. and Rodríguez-Triana, María Jesús and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
	title = {Understanding learning at a glance: An overview of learning dashboard studies},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {532 – 533},
	doi = {10.1145/2883851.2883930},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976507952&doi=10.1145%2f2883851.2883930&partnerID=40&md5=e854df569b89228218dd94170219b420},
	affiliations = {CHILI Group, EPFL, Station 20, Lausanne, 1015, Switzerland; REACT Group, EPFL, Station 9, Lausanne, 1015, Switzerland},
	abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the fnal analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dash-board design options. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Dashboards; Educational data mining; Information VI- sualization; Learning analytics; Systematic reVIew},
	keywords = {Education; Enterprise resource planning; Dashboards; Educational data mining; Information VI- sualization; Learning analytics; Systematic Review; Data mining},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; All Open Access, Green Open Access}
}

@CONFERENCE{Ifenthaler20221721,
	author = {Ifenthaler, Dirk and Yau, Jane Yin-Kim},
	title = {Analytics for Supporting Teaching Success in Higher Education: A Systematic Review},
	year = {2022},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2022-March},
	pages = {1721 – 1727},
	doi = {10.1109/EDUCON52537.2022.9766734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130446295&doi=10.1109%2fEDUCON52537.2022.9766734&partnerID=40&md5=261e8e9c480e549bba046ae967d49cec},
	affiliations = {University of Mannheim, Curtin University, Learning, Design and Technology, Mannheim, Germany; University of Mannheim, Dipf Leibniz Institute for Research and Information in Education, Mannheim, Germany},
	abstract = {Learning analytics are utilized to support learners' educational needs as well as to enhance their study success, for example, via the use of real-time prompts, motivational dashboards, and appropriate learning interventions, which have been shown to increase students' academic performance as well as their course retention rates. Yet, the perspective of higher education teachers in utilizing analytics to help analyze, reflect on, and improve their teaching design prior to delivery as well as to monitor and measure how the students engaged with their learning processes has been less recognized. In this paper, we present the results of a systematic review conducted from higher education teachers' perspective concerning how analytics can be deployed to adapt the curriculum to suit better students' educational needs in order to increase their study success. Thirty-five key studies were identified showing that analytics have been successful in influencing positively study success via teachers' academic curriculum intervention. Specifically, via analytics, higher education teachers could rapidly visualize common course pathways and identify any difficulties students experienced in real-time in order to increase their learning experiences and outcomes. © 2022 IEEE.},
	author_keywords = {higher education; learning analytics; systematic review; teacher},
	keywords = {Curricula; Teaching; Academic performance; Education teachers; Educational needs; High educations; Learning analytic; Real- time; Retention rate; Systematic Review; Teachers'; Teaching designs; Students},
	editor = {Jemni M. and Kallel I. and Akkari A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-166544434-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Salas-Pilco2023,
	author = {Salas-Pilco, Sdenka Zobeida and Xiao, Kejiang and Hu, Xinyun},
	title = {Correction to: Artificial Intelligence and Learning Analytics in Teacher Education: A Systematic Review (Education Sciences, (2022), 12, 8, (569), 10.3390/educsci12080569)},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {9},
	doi = {10.3390/educsci13090897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172161101&doi=10.3390%2feducsci13090897&partnerID=40&md5=f0d184858c5cd1fcbc0b9402af0a2458},
	affiliations = {Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Hubei Research Center for Educational Informatization, Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Faculty of Education and Human Development, The Education University of Hong Kong, Hong Kong},
	abstract = {There was an error in the original publication [1]. The authors have requested changes be made to the published paper as they describe Taiwan as a country in the article and hope to change the description to “Country/Region” and “China Taiwan”. A correction has been made to the first paragraph of Section 3. Results and Table 2: This review includes 30 studies based in 16 countries/regions, with the following distribution: Canada (3), China (8), Estonia (1), Germany (3), India (1), Indonesia (1), Japan (1), Korea (1), Malaysia (1), Morocco (1), Portugal (1), Rwanda (1), Spain (1) China Taiwan (1), Turkey (2), USA (3). The analysis guided by the research questions provides some insights into the impact of AI and LA on teacher education. Summary of the studies included in this review. Knowledge elaboration (K): discussion of topics and posts Behavior patterns (B): posting frequency; posts’ content Social interaction (S): network density, network cohesion, and network interactions Moodle platform LA dashboard Knowledge–Behavior–Social Dashboard tool (KBSD) DigComp framework (five dimensions): information and data literacy, communication and collaboration, digital content creation, safety, and problem solving AI tools: K-means clustering Video discourse data: number of words; number of turns; teacher–student turn-taking patterns Visualizing talk strategies: elaborating, reasoning, listening, and thinking with others Classroom discourse analyzer (CDA) is a VLA tool that automatically extracts and visualizes low-inference discourse information Short essays (500-word reflection) about the experience of solving a block-based visual programming scenario were analyzed Moodle platform Latent Dirichlet Allocation library in Python. Code.org Number of sessions, duration, number of actions, etc. Content access, content revision, discussion, assessment, help-seeking, and search MOOC R package AI tools: Expectation-maximization (EM) algorithm; Bayesian information criterion (BIC); TraMineR Access features: location, date, time, and regularity (average number of logins/week) Content features: screencasts; quizzes Moodle platform Video-based speech features: content, speech organization, appropriate word usage, proper etiquette, correct enunciation, fluent prosody, timing control Supervised algorithms: support-vector machine (SVM) classifier, logistic regression, random forests, and gradient-boosted decision trees Class, group, and individual work Student modalities: reading, writing, listening, and speaking Material: extended, minimal, native, or non-native Video on the ePortfolio in Moodle AI mobile communicative orientation of language teaching (COLT) scheme Discourse data: recordings of classroom conversations. Included variables: specificity, instructional talk, authentic questions, dialogic, cognitive level Random forests (RF) classifier and regression IBM Watson AI speech recognizer User action data: time, full names, event context, components, event names, activity, IP address and origin Performance data: grades Moodle platform R software Trustworthiness (0–100), novelty, and usefulness Actionability and receiving new information Level of experience CoTrack: a Raspberry-Pi-based prototype with microphones CoTrack’s dashboard showing speaking time and social networks Etherpad Discourse data and reflection elements: PSTs’ attitudes, experiences, device preferences, comments about the interface, and content and technical issues SimInClass: an AI-based-simulated virtual classroom Google Classroom learning platform Performance: GPA, math grade, TIMSS, age, gender, federal state, school type, type of student AI tools: SVM, LR, LR with elastic net regularization, and tree-based methods Behavior patterns: recordings of PSTs’ viewing a 360 degrees video with students’ actions Short writings: PSTs select one pivotal moment and explain why it is significant AI tools: machine learning algorithm Digital competence areas: Personal: age, gender, teaching experience, confidence, and years using digital technology in teaching Contextual: classroom equipment, students’ access to technology, network infrastructure, and curriculum Professional engagement: digital resources, assessment, empowering learners, and facilitating learners’ digital competence SPSS STATA, fast-and-frugal trees (FFTrees) classifier in machine learning ILDE dashboard: profile views, comments, created designs, re-used designs, and edits. The Integrated Learning Design Environment (ILDE) dashboard IBM SPSS 22 Heidi SQL and Tableau Self-regulated behaviors: Activating: online access location, day of the week, time of day Sustaining: access frequency Structuring: average logins per week, exam review patterns, number of reviewed quizzes/day Moodle platform Social bot: user intentions, bot messages System Usability Scale: frequency, ease of use, confidence, consistency Chatbots: Feedbot for self- study, Litbot for mentoring students’ reading Learning action logs about search terms, visited websites, time spent on each website, and the order in which sites were visited Thinking app (Chrome extension) that tracks online behaviors Psychological variables: Practical knowledge: educational beliefs, interpersonal relationships, teaching strategies, self-reflection Motivation: intrinsic motivation, extrinsic motivation, amotivation Other: gender, teaching experience, average academic performance The SLBM-TAIS educational module Based on the Indonesian Teacher Engagement Index (ITEI): positive psychology, positive education, teacher performance, nationalistic character, and leadership engagement Django: a website framework for Python Chart.js for data visualization. MongoDB as the database Discussion data Dimensions based on Bloom’s taxonomy: remember, understand, apply, analyze, evaluate, create MOOC platform Types of AI tasks: text recognition, sentiment analysis, image classification, categorical/numerical data IBM Watson AI model Mitsuku chatbot Google AI experiment named Emoji Scavenger Hunt Scratch Reflection elements: circumstances, description, evaluation, alternatives, consequences Doc2Vec features Four classifiers: decision trees, multinomial logistic regression, multinomial naïve Bayes, stochastic gradient descent Epistemic agency, democratic knowledge, improvable ideas, reflective and transformative assessment, and community knowledge Knowledge Forum (online notes) LMS log data: date, login frequency, views per week, participation in discussions Moodle LMS platform Based on the Teaching and Learning International Survey (TALIS) 2013: types of activities, participation rates, intensity of participation, mentoring and induction programs Group Mnet technique (glmnet package). R software PSTs’ teaching competency framework (six dimensions): professional foundation, instructional design, teaching implementation, technology application, teaching evaluation, reflective development AI tools: Back Propagation (BP) neural network Delphi and Analytic Hierarchy Process (AHP) methods Matlab software Discourse characteristics: number of posts per teacher, length of post per teacher, much or little new information, high or low topic relevance Word2vec toolkit to generate lexical vectors based on AI-NLP Vision-based mobile augmented reality from the university campus (e.g., plants, flowers, trees) through scene detection, retrieval, superposition, visualization, and interaction MobileNetV2 network: a lightweight convolutional neural network by Google for mobile devices Note. CDA = classroom discourse analyzer, DT = decision tree, FFTrees = fast-and-frugal trees, GBTD = gradient-boosted decision trees, KBSD = Knowledge–Behavior–Social Dashboard, ITEI = Indonesian Teacher Engagement Index, RF = random forests, NLP = natural language processing, SLBM-TAIS = service-learning-based module training AI subjects, SVM = support-vector machine, WISE = web-based inquiry science environment. The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the authors.},
	correspondence_address = {K. Xiao; Hubei Research Center for Educational Informatization, Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; email: xiaokj@ccnu.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Febriantoro202375,
	author = {Febriantoro, Wicaksono and Gauthier, Andrea and Cukurova, Mutlu},
	title = {The Promise of Physiological Data in Collaborative Learning: A Systematic Literature Review},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {75 – 88},
	doi = {10.1007/978-3-031-42682-7_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171976075&doi=10.1007%2f978-3-031-42682-7_6&partnerID=40&md5=a0ab4170933a95a0a625f3ef2ce93c5a},
	affiliations = {UCL Knowledge Lab, Institute of Education, University College London (UCL), London, United Kingdom},
	abstract = {Collaborative learning is an important approach in education. Researchers are increasingly interested in using physiological data, such as Electrodermal Activity (EDA), as an objective tool to measure bodily reactions during collaborative activities. However, it remains unclear how physiological data can contribute to our understanding, monitoring and support of the collaborative learning process. To address this gap, a Systematic Literature Review (SLR) was conducted, focusing on the contribution of physiological data to collaborative learning, the features of physiological data that correlate with effective outcomes, and interventions designed to support collaboration based on physiological data. The review identified 13 relevant publications that revealed physiological data can indeed be useful for detecting certain aspects of collaboration including students’ cognitive, behavioral, and affective (emotion and motivation) states. Physiological arousal in the form of EDA peaks and physiological synchrony (interdependence or associated activity between individuals’ physiological signals) were the most commonly used features. Surprisingly, only one publication presented a prototype of a learning analytics dashboard that used physiological data to guide student reflections. Furthermore, the review highlights the potential for integrating physiological measures with other data sources, such as speech, eye gaze, and facial expression, to uncover psychophysiological reactions and accompanying social and contextual processes related to collaborative learning. Future research should consider embedding methods for the physiological detection and modeling of learning constructs within explicit, feedback-driven interventions for collaborative learning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {collaborative learning; physiological data},
	keywords = {Psychophysiology; Collaborative activities; Collaborative learning; Collaborative learning process; Data-source; Electrodermal activity; Eye-gaze; Physiological data; Physiological measures; Physiological signals; Systematic literature review; Learning systems},
	correspondence_address = {W. Febriantoro; UCL Knowledge Lab, Institute of Education, University College London (UCL), London, United Kingdom; email: Wicaksono.febriantoro.21@ucl.ac.uk},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}