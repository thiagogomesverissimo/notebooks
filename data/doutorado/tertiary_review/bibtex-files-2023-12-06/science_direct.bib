@article{SWIECKI2022100075,
title = {Assessment in the age of artificial intelligence},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100075},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100075},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000303},
author = {Zachari Swiecki and Hassan Khosravi and Guanliang Chen and Roberto Martinez-Maldonado and Jason M. Lodge and Sandra Milligan and Neil Selwyn and Dragan Gašević},
abstract = {In this paper, we argue that a particular set of issues mars traditional assessment practices. They may be difficult for educators to design and implement; only provide discrete snapshots of performance rather than nuanced views of learning; be unadapted to the particular knowledge, skills, and backgrounds of participants; be tailored to the culture of schooling rather than the cultures schooling is designed to prepare students to enter; and assess skills that humans routinely use computers to perform. We review extant artificial intelligence approaches that–at least partially–address these issues and critically discuss whether these approaches present additional challenges for assessment practice.}
}
@article{QUADIR2021100034,
title = {Categorizing learning analytics models according to their goals and identifying their relevant components: A review of the learning analytics literature from 2011 to 2019},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100034},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100034},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2100028X},
author = {Benazir Quadir and Maiga Chang and Jie Chi Yang},
keywords = {learning Analytics category, Learning analytics components, Learning analytics models, Meta-analysis},
abstract = {This study aimed to categorize learning analytics (LA) models and identify their relevant components by analyzing LA-related articles published between 2011 and 2019 in international journals. A total of 101 articles discussing various LA models were selected. These models were characterized according to their goals and components. A qualitative content analysis approach was used to develop a coding scheme for analyzing the aforementioned models. The results reveal that the studied LA models belong to five categories, namely performance, meta-cognitive, interactivity, communication, and data models. The majority of the selected LA-related articles were data models, followed by performance models. This review also identified 16 components that were commonly used in the studied models. The results indicate that analytics was the most common component in the studied models (used in 10 LA models). Furthermore, visualization was the most relevant component in the studied communication models.}
}
@article{HERODOTOU2020100725,
title = {The scalable implementation of predictive learning analytics at a distance learning university: Insights from a longitudinal case study},
journal = {The Internet and Higher Education},
volume = {45},
pages = {100725},
year = {2020},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2020.100725},
url = {https://www.sciencedirect.com/science/article/pii/S1096751620300014},
author = {Christothea Herodotou and Bart Rienties and Martin Hlosta and Avinash Boroowa and Chrysoula Mangafa and Zdenek Zdrahal},
keywords = {Predictive Learning Analytics (PLA), Higher education, Distance learning, Scalable implementation, OU Analyse},
abstract = {A vast number of studies reported exciting innovations and practices in the field of Learning Analytics (LA). Whilst they provided substantial insights, most of these studies have been implemented in single-course or small-scale settings. There are only a few studies that are large-scale and institutional-wide adaptations of LA and have explored the stakeholders' perspectives (i.e., teachers, students, researchers, management) and involvement with LA. This study reports on one such large-scale and long-term implementation of Predictive Learning Analytics (PLA) spanning a period of 4 years at a distance learning university. OU Analyse (OUA) is the PLA system used in this study, providing predictive insights to teachers about students and their chance of passing a course. Over the last 4 years, OUA has been accessed by 1159 unique teachers and reached 23,180 students in 231 undergraduate online courses. The aim of this study is twofold: (a) to reflect on the macro-level of adoption by detailing usage, challenges, and factors facilitating adoption at an organisational level, and (b) to detail the micro-level of adoption, that is the teachers' perspectives about OUA. Amongst the factors shown to be critical to the scalable PLA implementation were: Faculty's engagement with OUA, teachers as “champions”, evidence generation and dissemination, digital literacy, and conceptions about teaching online.}
}
@article{TICKLE2022105476,
title = {The use of eportfolios in pre-registration health professional clinical education: An integrative review},
journal = {Nurse Education Today},
volume = {117},
pages = {105476},
year = {2022},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2022.105476},
url = {https://www.sciencedirect.com/science/article/pii/S026069172200212X},
author = {Nikki Tickle and Debra K. Creedy and Amanda G. Carter and Jenny Gamble},
keywords = {Student-centred learning, ePortfolio, Assessment feedback, Competency-based education, Online systems, Online education, Computer literacy, Digital technology},
abstract = {Introduction
ePortfolios are increasingly used in health professional clinical education. However, the nature of ePortfolios varies greatly amongst programs, as does the software, purpose, and institutional cost.
Objectives
An integrative review of the literature was conducted to determine how ePortfolios are being used in pre-registration health programs to enhance clinical learning.
Data sources
A systematic search of relevant databases (Cumulative Index of Nursing and Allied Health Literature, Education Resources Information Center, Cochrane, Medline, ProQuest, PubMed, Turning Research Into Practice, and Web of Science) was performed and reported according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Retrieved papers were assessed using the Critical Appraisal Skills Programme tool and findings were analysed.
Review methods
A total of 272 records were identified. Thirty papers were assessed in detail. Five themes were identified by content analysis; feedback and communication; student-centred learning; experiences and competencies; access, attitudes, and digital literacy; and technological support.
Conclusions
ePortfolios offer a range of pedagogical benefits. Clinical learning is enhanced by student-focused ePortfolio design which includes clear learning outcomes; development of relationships with peers and instructors via ongoing communication and feedback; use of templates; links to time-saving applications; and guided, assessed reflections. Poor technological support, negative attitudes by clinical supervisors, unreliable access, instructor-focused design, and excessive or repetitive documentation in ePortfolio design hindered clinical learning.}
}
@article{POGORSKIY2023100111,
title = {From procrastination to engagement? An experimental exploration of the effects of an adaptive virtual assistant on self-regulation in online learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {4},
pages = {100111},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100111},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000662},
author = {Eduard Pogorskiy and Jens F. Beckmann},
keywords = {MOOC, Self-regulated learning, Developmental vs compensatory shifts, Self ratings, Personality, Behavior traces},
abstract = {Compared to traditional classroom learning, success in online learning tends to depend more on the learner’s skill to self-regulate. Self-regulation is a complex meta-cognitive skill set that can be acquired. This study explores the effectiveness of a virtual learning assistant in terms of (a) developmental, (b) general compensatory, and (c) differential compensatory effects on learners’ self-regulatory skills in a sample of N = 157 online learners using an experimental intervention-control group design. Methods employed include behavioural trace data as well as self-reporting measures. Participants provided demographic information and responded to a 24-item self-regulation questionnaire and a 20-item personality trait questionnaire. Results indicate that the adaptive assistance did not lead to substantial developmental shifts as captured in learners’ perceived levels of self-regulation. However, various patterns of behavioural changes emerged in response to the intervention. This suggests that the virtual learning assistant has the potential to help online learners effectively compensate for deficits (in contrast to developmental shifts) in self-regulatory skills that might not yet have been developed.}
}
@article{VIEIRA2018119,
title = {Visual learning analytics of educational data: A systematic literature review and research agenda},
journal = {Computers & Education},
volume = {122},
pages = {119-135},
year = {2018},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2018.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0360131518300770},
author = {Camilo Vieira and Paul Parsons and Vetria Byrd},
keywords = {Visual analytics, Learning analytics, Educational data mining, Literature review},
abstract = {We present a systematic literature review of the emerging field of visual learning analytics. We review existing work in this field from two perspectives: First, we analyze existing approaches, audiences, purposes, contexts, and data sources—both individually and in relation to one another—that designers and researchers have used to visualize educational data. Second, we examine how established literature in the fields of information visualization and education has been used to inform the design of visual learning analytics tools and to discuss research findings. We characterize the reviewed literature based on three dimensions: (a) connection with visualization background; (b) connection with educational theory; and (c) sophistication of visualization(s). The results from this systematic review suggest that: (1) little work has been done to bring visual learning analytics tools into classroom settings; (2) few studies consider background information from the students, such as demographics or prior performance; (3) traditional statistical visualization techniques, such as bar plots and scatter plots, are still the most commonly used in learning analytics contexts, while more advanced or novel techniques are rarely used; (4) while some studies employ sophisticated visualizations, and some engage deeply with educational theories, there is a lack of studies that both employ sophisticated visualizations and engage deeply with educational theories. Finally, we present a brief research agenda for the field of visual learning analytics based on the findings of our literature review.}
}
@article{CAVALCANTI2021100027,
title = {Automatic feedback in online learning environments: A systematic literature review},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100027},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100027},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000217},
author = {Anderson Pinheiro Cavalcanti and Arthur Barbosa and Ruan Carvalho and Fred Freitas and Yi-Shan Tsai and Dragan Gašević and Rafael Ferreira Mello},
keywords = {Educational feedback, Automatic feedback, Systematic review, Online learning environments},
abstract = {Feedback is an essential component of scaffolding for learning. Feedback provides insights into the assistance of learners in terms of achieving learning goals and improving self-regulated skills. In online courses, feedback becomes even more critical since instructors and students are separated geographically and physically. In this context, feedback allows the instructor to customize learning content according to the students' needs. However, giving feedback is a challenging task for instructors, especially in contexts of large cohorts. As a result, several automatic feedback systems have been proposed to reduce the workload on the part of the instructor. Although these systems have started gaining research attention, there have been limited studies that systematically analyze the progress achieved so far as reported in the literature. Thus, this article presents a systematic literature review on automatic feedback generation in learning management systems. The main findings of this review are: (1) 65.07% of the studies demonstrate that automatic feedback increases student performance in activities; (2) 46.03% of the studies demonstrated that there is no evidence that automatic feedback eases instructors’ workload; (3) 82.53% of the studies showed that there is no evidence that manual feedback is more efficient than automatic feedback; and (4) the main method used for automatic feedback provision is the comparison with a desired answer in some subject (such as logic circuits or programming).}
}
@incollection{IFENTHALER2023331,
title = {Adoption of learning analytics},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {331-335},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.02052-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305020522},
author = {Dirk Ifenthaler},
keywords = {Learning analytics, Adoption, Change management, Data analytics},
abstract = {From a holistic perspective, educational organizations and involved stakeholders can derive multiple benefits from learning analytics. This article explores the adoption of learning analytics within educational organizations which depends on several factors including technological systems, regulations and guidelines, as well as professional development of involved stakeholders. The maturity level of available organization-wide learning analytics systems is still low. The adoption of learning analytics at educational organizations requires capabilities not yet fully developed as well as on-going rigorous research. Confirming sustainable benefits for learning-processes and improving learning environments will further encourage the adoption of learning analytics.}
}
@article{KUI202267,
title = {A survey of visual analytics techniques for online education},
journal = {Visual Informatics},
volume = {6},
number = {4},
pages = {67-77},
year = {2022},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2022.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X22000870},
author = {Xiaoyan Kui and Naiming Liu and Qiang Liu and Jingwei Liu and Xiaoqian Zeng and Chao Zhang},
keywords = {Visual analytics, Online education, Behavior analysis, Content analysis},
abstract = {Visual analytics techniques are widely utilized to facilitate the exploration of online educational data. To help researchers better understand the necessity and the efficiency of these techniques in online education, we systematically review related works of the past decade to provide a comprehensive view of the use of visualization in online education problems. We establish a taxonomy based on the analysis goal and classify the existing visual analytics techniques into four categories: learning behavior analysis, learning content analysis, analysis of interactions among students, and prediction and recommendation. The use of visual analytics techniques is summarized in each category to show their benefits in different analysis tasks. At last, we discuss the future research opportunities and challenges in the utilization of visual analytics techniques for online education.}
}
@article{CHEN2021100015,
title = {An interactive test dashboard with diagnosis and feedback mechanisms to facilitate learning performance},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100015},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100015},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000096},
author = {Chih-Ming Chen and Jung-Ying Wang and Li-Chieh Hsu},
keywords = {Digital dashboard for learning (DDL), Test dashboard with diagnosis and feedback, Computer-adaptive science assessment, Physics self-efficacy, Technology acceptance},
abstract = {This study developed an interactive test dashboard with diagnosis and feedback mechanisms (ITD-DFM) that can generate visualized, rich, and high-quality test feedback for each learner’s learning reflection and review based on simultaneously considering test response time and correctness to assist students’ learning. A quasi-experimental research was conducted with 50 Grade 8 students from two classes in a public junior high school in Taiwan to assess the learning performance of ITD-DFM. One class with 26 students was assigned to the experimental group using the ITD-DFM to support learning, whereas the other class with 24 students was assigned to the control group using the traditional test system without diagnosis and feedback mechanisms (TTS-NDFM). Experimental results reveal that the learning performance, physics self-efficacy, and technology acceptance of the experimental group were significantly better than those of the control group. The ITD-DFM has the same effect on promoting the learning performance of learners with different prior knowledge levels as well as learners with either high or low prior knowledge level in the experimental group exhibited significant improvement in physics self-efficacy, but no such results in the control group. The ITD-DFM provides more benefit in promoting the technology acceptance of learners with high prior knowledge level.}
}
@article{BROWN2019100691,
title = {Implementing online personalized social comparison nudges in a web-enabled coaching system},
journal = {The Internet and Higher Education},
volume = {43},
pages = {100691},
year = {2019},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2019.100691},
url = {https://www.sciencedirect.com/science/article/pii/S1096751618306092},
author = {Michael G. Brown and James Schiltz and Holly Derry and Caitlin Holman}
}
@article{FOREMAN2023103428,
title = {Establishment-level occupational safety analytics: Challenges and opportunities},
journal = {International Journal of Industrial Ergonomics},
volume = {94},
pages = {103428},
year = {2023},
issn = {0169-8141},
doi = {https://doi.org/10.1016/j.ergon.2023.103428},
url = {https://www.sciencedirect.com/science/article/pii/S0169814123000203},
author = {Anne M. Foreman and Jonathan E. Friedel and Timothy D. Ludwig and Maira E. Ezerins and Yalçin Açikgöz and Shawn M. Bergman and Oliver Wirth},
keywords = {Safety analytics, Big data, Occupational safety, Injuries, Near misses, Data culture},
abstract = {In occupational safety and health, big data and analytics show promise for the prediction and prevention of workplace injuries. Advances in computing power and analytical methods have allowed companies to reveal insights from the “big” data that previously would have gone undetected. Despite the promise, occupational safety has lagged behind other industries, such as supply chain management and healthcare, in terms of exploiting the potential of analytics and much of the data collected by organizations goes unanalyzed. The purpose of the present paper is to argue for the broader application of establishment-level safety analytics. This is accomplished by defining the terms, describing previous research, outlining the necessary components required, and describing knowledge gaps and future directions. The knowledge gaps and future directions for research in establishment-level analytics are categorized into readiness for analytics, analytics methods, technology integration, data culture, and impact of analytics.}
}
@article{LIU2024104951,
title = {Adopt or abandon: Facilitators and barriers of in-service teachers’ integration of game learning analytics in K–12 classrooms?},
journal = {Computers & Education},
volume = {209},
pages = {104951},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104951},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002282},
author = {Yiming Liu and Jeremy Tzi Dong Ng and Xiao Hu and Zhengyang Ma and Xiaoyan Lai},
keywords = {Data science applications in education, Games, Human-computer interface, Mobile learning},
abstract = {Game learning analytics (GLA) is an emerging technology that facilitates teachers’ evidence-based pedagogical design and assessments. Despite its affordances and potential in K–12 classrooms, teachers’ integration of GLA in teaching practices remains largely unexplored. This study implemented an educational game on collaborative problem solving (CPS) and a GLA system for assisting K–12 teachers in evaluating students’ CPS skills and processes and quest performance and engagement. Based on the integrative model of behavioural prediction, this study aimed to examine 1) the extent to which personal, environmental, and technological factors affected teachers’ usage intention and behaviour towards the GLA system, 2) the effects of moderators on the intention–behaviour relationship, and 3) how the structural model relationships differed across teachers with various individual characteristics. Survey data from 300 in-service teachers from Chinese primary and secondary schools were collected and analysed using partial least squares structural equation modelling. Results indicated that our model demonstrated strong in-sample and out-of-sample predictive power. In particular, teachers’ attitudes, subjective norms, and self-efficacy influenced their behavioural intention, while technological pedagogical content knowledge, school support, and behavioural intention predicted their actual behaviour. In addition, technostress acted as a significant moderator of the intention–behaviour relationship. Moreover, teachers’ gaming preferences, teaching subjects, and years of teaching explained the heterogeneity of their GLA usage. This study contributes to a theoretical understanding of and methodological advancements in studying teachers’ usage intention and behaviour on GLA and yields practical implications for the design and implementation of GLA in K–12 classrooms.}
}
@article{2022iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {207},
pages = {iii-xxviii},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(22)01439-9},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922014399}
}
@article{SAGGI2018758,
title = {A survey towards an integration of big data analytics to big insights for value-creation},
journal = {Information Processing & Management},
volume = {54},
number = {5},
pages = {758-790},
year = {2018},
note = {In (Big) Data we trust: Value creation in knowledge organizations},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2018.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0306457316307178},
author = {Mandeep Kaur Saggi and Sushma Jain},
keywords = {Big data, Data analytics, Machine learning, Big data visualization, Decision-making, Smart agriculture, Smart city application, Value-creation, Value-discover, Value-realization},
abstract = {Big Data Analytics (BDA) is increasingly becoming a trending practice that generates an enormous amount of data and provides a new opportunity that is helpful in relevant decision-making. The developments in Big Data Analytics provide a new paradigm and solutions for big data sources, storage, and advanced analytics. The BDA provide a nuanced view of big data development, and insights on how it can truly create value for firm and customer. This article presents a comprehensive, well-informed examination, and realistic analysis of deploying big data analytics successfully in companies. It provides an overview of the architecture of BDA including six components, namely: (i) data generation, (ii) data acquisition, (iii) data storage, (iv) advanced data analytics, (v) data visualization, and (vi) decision-making for value-creation. In this paper, seven V's characteristics of BDA namely Volume, Velocity, Variety, Valence, Veracity, Variability, and Value are explored. The various big data analytics tools, techniques and technologies have been described. Furthermore, it presents a methodical analysis for the usage of Big Data Analytics in various applications such as agriculture, healthcare, cyber security, and smart city. This paper also highlights the previous research, challenges, current status, and future directions of big data analytics for various application platforms. This overview highlights three issues, namely (i) concepts, characteristics and processing paradigms of Big Data Analytics; (ii) the state-of-the-art framework for decision-making in BDA for companies to insight value-creation; and (iii) the current challenges of Big Data Analytics as well as possible future directions.}
}
@incollection{FEIDAKIS2016217,
title = {Chapter 11 - A Review of Emotion-Aware Systems for e-Learning in Virtual Environments},
editor = {Santi Caballé and Robert Clarisó},
booktitle = {Formative Assessment, Learning Data Analytics and Gamification},
publisher = {Academic Press},
address = {Boston},
pages = {217-242},
year = {2016},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-12-803637-2},
doi = {https://doi.org/10.1016/B978-0-12-803637-2.00011-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128036372000117},
author = {M. Feidakis},
keywords = {e-Learning, Emotion, Affect, Detection, Emotion awareness, Recognition, Affective learning, Affective state, Emotion intelligence, Affective feedback},
abstract = {Current emotion-aware systems still strive to provide a means to effectively deal with important issues in e-learning such as: students’ lack of self-confidence, high dropout rates, low motivation and engagement, self-regulation and task performance. Consequently, many learning systems have been produced from current research in the areas of adaptive and personalized learning, which certainly need to consider and incorporate emotion-awareness features to enhance their ability to adapt to the real internal world of each student and to be capable of providing effective personalized feedback to a spectrum of student needs. The integration of emotion awareness can greatly advance the frontiers of educational technologies and provide an added value to enhance and improve the overall distance learning experience, as well as deliver cost-effective training programs.}
}
@article{KNIGHT2020100729,
title = {Implementing learning analytics for learning impact: Taking tools to task},
journal = {The Internet and Higher Education},
volume = {45},
pages = {100729},
year = {2020},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2020.100729},
url = {https://www.sciencedirect.com/science/article/pii/S1096751620300051},
author = {Simon Knight and Andrew Gibson and Antonette Shibani},
keywords = {Learning analytics, Implementation, Educational technology, Learning design},
abstract = {Learning analytics has the potential to impact student learning, at scale. Embedded in that claim are a set of assumptions and tensions around the nature of scale, impact on student learning, and the scope of infrastructure encompassed by ‘learning analytics’ as a socio-technical field. Drawing on our design experience of developing learning analytics and inducting others into its use, we present a model that we have used to address five key challenges we have encountered. In developing this model, we recommend: A focus on impact on learning through augmentation of existing practice; the centrality of tasks in implementing learning analytics for impact on learning; the commensurate centrality of learning in evaluating learning analytics; inclusion of co-design approaches in implementing learning analytics across sites; and an attention to both social and technical infrastructure.}
}
@article{2020iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {167},
pages = {iii-xvi},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(20)30921-2},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920309212}
}
@article{ALTAMEEMI20191120,
title = {Towards an Intelligent System to Improve Student Engagement and Retention},
journal = {Procedia Computer Science},
volume = {151},
pages = {1120-1127},
year = {2019},
note = {The 10th International Conference on Ambient Systems, Networks and Technologies (ANT 2019) / The 2nd International Conference on Emerging Data and Industry 4.0 (EDI40 2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.04.159},
url = {https://www.sciencedirect.com/science/article/pii/S187705091930626X},
author = {Ghaith Al-Tameemi and James Xue},
keywords = {Learning platform, Student activities, Data mining, Student Engagement},
abstract = {The impact of the learning platforms on student performance has always been a popular subject of research on improving student academic performance during the course study. A variety of research and studies have been conducted based on the student opinions to determine the effectiveness of the student engagement in learning platform on student performance. However, these opinions may not be accurately affected. In this paper, we will track the student activities inside the learning platform in real-time during their course study. Only the meaningful activities such as downloading assignments, lectures, viewing notification and visiting the resources will be extracted from the learning platform. An algorithm has been developed for mining and measuring student performance inside the learning platform.}
}
@article{COPURGENCTURK2023104963,
title = {The impact of an interactive, personalized computer-based teacher professional development program on student performance: A randomized controlled trial},
journal = {Computers & Education},
pages = {104963},
year = {2023},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104963},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002403},
author = {Yasemin Copur-Gencturk and Jingxian Li and Allan S. Cohen and Chandra Orrill},
keywords = {Teacher professional development, Distance learning and online learning, Teaching/learning strategies, Adult learning, Architectures for educational technology system},
abstract = {Scholars and practitioners have called for personalized and widely accessible professional development (PD) for teachers. Yet, a long-standing tension between customizing support and increasing access to such support has hindered the scale-up of high-quality PD for individual teachers. This study addresses this challenge by developing a computerized program for middle school mathematics teachers that provides frequent opportunities for teachers to interact with and obtain personalized and real-time feedback from a virtual facilitator based on natural language processing. Based on the data collected from 1727 middle school students in an experiment in which the teachers of these students were randomly assigned to the program or the business-as-usual condition (i.e., the control group), we found that the program had a statistically significant impact on students’ mathematics performance. These results demonstrate the potential of incorporating an automated, interactive feedback tool supported by artificial intelligence to create effective, scalable teacher PD.}
}
@article{TSAI201839,
title = {A parallel metaheuristic data clustering framework for cloud},
journal = {Journal of Parallel and Distributed Computing},
volume = {116},
pages = {39-49},
year = {2018},
note = {Towards the Internet of Data: Applications, Opportunities and Future Challenges},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517302964},
author = {Chun-Wei Tsai and Shi-Jui Liu and Yi-Chung Wang},
keywords = {Metaheuristic algorithm, Internet of things, Data clustering problem},
abstract = {A high performance data analytics for internet of things (IoT) has been a promising research subject in recent years because traditional data mining algorithms may not be applicable to big data of IoT. One of the main reasons is that the data that need to be analyzed may exceed the storage size of a single machine. The computation cost of data analysis tasks that is too high for a single computer system is another critical problem we have to confront when analyzing data from an IoT system. That is why an efficient data clustering framework for metaheuristic algorithm on a cloud computing environment is presented in this paper for data analytics, which explains how to divide mining tasks of a mining algorithm into different nodes (i.e., the Map process) and then aggregate the mining results from these nodes (i.e., Reduce process). We further attempted to use the proposed framework to implement data clustering algorithms (e.g., k-means, genetic k-means, and particle swarm optimization) on a standalone system and Spark. The experimental results show that the performance of the proposed framework makes it useful to develop data clustering algorithms on a cloud computing environment.}
}
@article{SUAREZ201838,
title = {A review of the types of mobile activities in mobile inquiry-based learning},
journal = {Computers & Education},
volume = {118},
pages = {38-55},
year = {2018},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2017.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0360131517302397},
author = {Ángel Suárez and Marcus Specht and Fleur Prinsen and Marco Kalz and Stefaan Ternier},
keywords = {Inquiry-based learning, Mobile technology, Types of mobile activities, Learners agency, Agency dimensions},
abstract = {Inquiry-based Learning is increasingly suggested as an efficient approach for fostering learners' curiosity and motivation. It helps learners to develop their ability to work in complex and unpredictable environments making them more critical thinkers and agentic learners. Although mobile technology is a suitable support for this learning process, there is a lack of practical strategies for educational practitioners to enact the right balance between enabling agency and supporting the students through the mobile technology. Thus, we conducted a literature review that analyzed 62 studies on mobile inquiry-based learning. The analysis focused on the level of agency supported by mobile technology. This review study provided two main results. The first result is a two-layer classification –with five types and twelve subtypes– of the most common mobile activities used in inquiry-based learning. The types and subtypes are: 1) Direct instruction formed by 1a) location guidance, 1b) procedural guidance and 1c) metacognitive guidance, 2) Access to content formed by 2a) fixed and 2b) dynamic content, 3) Data collection that consists of 3a) cooperative and 3b) collaborative data collection, 4) Peer-to-peer communication formed by 4a) asynchronous and 4b) synchronous social communications and 5) Contextual support that includes 5a) augmented experience, 5b) immersive experience and 5c) adaptive feedback. The second result consists of an analytical framework –based on six dimensions– to assess the level of agency supported by the different types of mobile activities. The learners' agency dimensions are: 1) Goals, 2) Content, 3) Actions, 4) Strategies, 5) Reflection and 6) Monitoring. Finally, the review presents insights on how this analytical framework can be used by educational practitioners to identify mobile activities that effectively balance learners’ agency with mobile technology.}
}
@article{HOWELL20188,
title = {Learning analytics messages: Impact of grade, sender, comparative information and message style on student affect and academic resilience},
journal = {Computers in Human Behavior},
volume = {89},
pages = {8-15},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218303431},
author = {Joel A. Howell and Lynne D. Roberts and Vincent O. Mancini},
keywords = {Learning analytics, Academic resilience, Feedback, Educational technology, Feedback recipience},
abstract = {Learning analytics enable automated feedback to students through dashboards, reports and alerts. The underlying untested assumption is that providing analytics will be sufficient to improve self-regulated learning. Working within a feedback recipience framework, we begin to test this assumption by examining the impact of learning analytics messages on student affect and academic resilience. Three hundred and twenty undergraduate students completed an online survey and were exposed to three randomly assigned learning analytics alerts (High Distinction, Pass, and Fail grades). Multivariate analyses of variance indicated significant differences between grade levels (large effects), with higher positive affect and lower resilience in response to High Distinction alerts than Pass or Fail alerts. Within each hypothetical grade level, there were no differences in student affect and academic resilience. Based upon systematic changes in feedback sender, message style or whether comparative peer achievement was included or not. These findings indicate that grade level has the largest impact on both affect and academic resilience. The failure of message and sender characteristics to impact on activities that promote self-regulated learning suggests we need to look beyond these characteristics of individual messages to identify drivers of engaging students in self-regulated learning.}
}
@article{OSAKWE2023100181,
title = {Reinforcement learning for automatic detection of effective strategies for self-regulated learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100181},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100181},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000607},
author = {Ikenna Osakwe and Guanliang Chen and Yizhou Fan and Mladen Rakovic and Xinyu Li and Shaveen Singh and Inge Molenaar and Maria Bannert and Dragan Gašević},
keywords = {Learning analytics, Self-regulated learning, Learning strategies, Reinforcement learning, Personalized (or: individualized or: adaptive) scaffolds},
abstract = {Self-regulated learning (SRL) is an essential skill for achieving one's learning goals, particularly in Digital Learning Environments (DLEs) where system support is often limited compared to traditional classroom settings. However, research has found that learners often struggle to adapt their behaviour to the self-regulatory demands of DLEs. Furthermore, existing SRL analysis tools have limited utility for real-time or individualized prescriptive support of a learner's SRL strategy during a study session. In response to these challenges, we propose a novel approach using reinforcement learning as a framework to optimize the sequence of SRL processes for a learning task. This framework allows us to model and optimize the SRL strategy as a sequential decision-making problem, where each decision corresponds to an SRL process. The goal is to find an optimal sequence of decisions that maximizes performance in learning outcomes such as assessment score or learning gains. We compare the performance of our reinforcement learning framework with other sequential machine learning tools, such as Long Short-Term Memory (LSTM) neural networks and Genetic Algorithms (GA). The results of our study show that our reinforcement learning model outperforms GA and LSTM models in optimizing SRL strategy. The contributions of this work can facilitate the development of a tool which can detect sub-optimal SRL strategy in real-time and enable individualized SRL focused scaffolding.}
}
@article{SAINT2022100060,
title = {Temporally-focused analytics of self-regulated learning: A systematic review of literature},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100060},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100060},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000157},
author = {John Saint and Yizhou Fan and Dragan Gašević and Abelardo Pardo},
keywords = {Self-regulated learning, Temporal analysis, Process analytics, Learning analytics},
abstract = {We present a systematic literature review of data-driven self-regulated learning (SRL) that emphasises the methodological importance of temporality and sequence, as opposed to conventional statistical analysis. Researchers seem unanimous in their view of the importance of SRL in modern online and blended educational settings; this is borne out by number of reviews of literature on the subject. There has, as yet, been no systematic treatment of SRL in the context of its conceptualisation as a phenomenon that unfolds in sequences over time. To address this limitation, this review explores the corpus of work (n = 53) in which SRL and its related dimensions are analysed through the lenses of temporality, sequence and order. The results show that, in the pursuit of validity and impact, key decisions need to be addressed in regard to theoretical grounding, data collection, and analytic methods. Based on these outcomes, we propose a framework of directives and questions to aid researchers who want to push forward the field. This framework comprises four sub-areas: i) methodological considerations, relating to data capture and analytic processes; ii) theoretical considerations, relating to the usage of models of self-regulated learning and their related dimensions; iii) validity considerations, relating to the robustness of the chosen analytic outcomes studied; and iv) temporal considerations, relating to the articulation of analytic outcomes in the context of temporality and sequence.}
}
@article{BANIHASHEM2022100489,
title = {A systematic review of the role of learning analytics in enhancing feedback practices in higher education},
journal = {Educational Research Review},
volume = {37},
pages = {100489},
year = {2022},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2022.100489},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X22000586},
author = {Seyyed Kazem Banihashem and Omid Noroozi and Stan {van Ginkel} and Leah P. Macfadyen and Harm J.A. Biemans},
keywords = {Conceptual framework, Higher education, Learning analytics, Feedback, Systematic review},
abstract = {Learning analytics (LA) offers new opportunities to enrich feedback practices in higher education, but little is understood about the ways different LA can enhance feedback practices for educators and students. This systematic literature review maps the current state of implementation of LA to improve feedback practices in technology-mediated learning environments in higher education. We used strict inclusion criteria to select relevant studies that have investigated the role of LA on feedback practices. To identify common features of LA for feedback studies, we coded relevant publications using an analytical framework that identifies four key dimensions of LA systems: what (types of data), how (analytic methods), why (objectives), and how educators and students are served by LA (stakeholders). Based on findings, we propose a conceptual framework that can guide the implementation of LA for feedback systems and also suggest future empirical research in this area.}
}
@article{MAIER2022100080,
title = {Personalized feedback in digital learning environments: Classification framework and literature review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100080},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000352},
author = {Uwe Maier and Christian Klotz},
keywords = {Personalized feedback, Adaptive feedback, Personalized education, Digital learning, Automated feedback},
abstract = {Digital learning technologies offer many opportunities to personalize instruction and learning in K-12 and higher education. In the last ten years, a growing body of research described personalized feedback implementations and investigated their effects on educational outcomes. Building on personalized education and adaptive learning systems models, this review provides an analytic framework to summarize key features of personalized feedback implementations and main empirical results. The systematic literature search resulted in 39 studies published in the last ten years. We found that scholars developed and investigated personalized feedback on the microscale, mesoscale, and macroscale of digital learning environments. However, the adaptive sources (To what is feedback adapted?) are mainly restricted to the current knowledge level and learning behavior data. Other interesting data sources for feedback adaptation remain underresearched, e.g., emotional state measures, progress measures, learning goals, or personality traits. Only a minority of the reviewed studies provided an empirical or theoretical rationale for assigning feedback messages to different types of students. Most studies report positive or at least mixed or neutral effects of personalized feedback on educational outcomes. This review discusses several implications for future directions in research on digitalized and personalized feedback. This study also adds to previous literature reviews on automatic and adaptive feedback that did not clearly distinguish task-adaptiveness and student-adaptiveness in digital feedback examples.}
}
@article{DELGOBBO2023101258,
title = {Automatic evaluation of open-ended questions for online learning. A systematic mapping},
journal = {Studies in Educational Evaluation},
volume = {77},
pages = {101258},
year = {2023},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2023.101258},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X2300024X},
author = {Emiliano {del Gobbo} and Alfonso Guarino and Barbara Cafarelli and Luca Grilli and Pierpaolo Limone},
keywords = {Literature review, Automatic grading, Short-answer assessment, Performance assessment in Higher Education, Educational technology, Students’ evaluation},
abstract = {The assessment of students’ performances in Higher Education is one of the essential components of teaching activities. Open-ended tasks allow a more in-depth assessment of students’ learning levels, but their evaluation and grading are time-consuming and prone to subjective bias. Since the Covid-19 pandemic, most traditional Higher Education courses converted to online courses; automatic grading and feedback tools and methods (AGFTM) have become critical components of online learning systems, especially with regards to short answers and essays assessment. This work frames the recent advancement in AGFTM through a systematic mapping of the research field and a literature review. This analysis gives an overview of the trends, specific goals, methods, quality of proposals, challenges and limitations in this research area. The results indicate that it is a growing research area, with a large set of techniques involved, but still not mature, where practical implementations have yet to come.}
}
@article{YACOBSON2023104960,
title = {Recommender systems for teachers: The relation between social ties and the effectiveness of socially-based features},
journal = {Computers & Education},
pages = {104960},
year = {2023},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104960},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002373},
author = {Elad Yacobson and Armando M. Toda and Alexandra I. Cristea and Giora Alexandron},
keywords = {Recommender systems, Social recommendations, Social recognition, Social network analysis, Open educational resources},
abstract = {Open Educational Resources (OER) repositories provide teachers with a wide range of learning resources (LRs), enabling them to design various learning sequences. However, search & select in large OER repositories can be a daunting task for teachers. Incorporating peer recommendations, as is common in online marketplaces, is becoming a popular solution that seeks to exploit the wisdom of the crowd for this task. However, teachers are often reluctant to take a contributory role and provide social recommendations. In addition, little is known about the actual value of social recommendations as a search aid. In this research, we implemented a “light-weight” socially-based recommender system (RS) within a large OER repository that includes social network features. We examined two aspects of the socially-based recommendation mechanisms. First, their utility as search aids that assist teachers in searching and selecting suitable LRs, and second, their impact on teachers' incentives to share recommendations that can assist fellow teachers. To study these two aspects, we examined two science teacher communities using this repository. The results demonstrated the incentivising power of social rewards, and the value of social recommendations as means for search & select. However, we also observed a heterogeneous effect of social features on teachers' behaviour. To explore the factors that may explain these differences, we employed a mixed-method approach, combining qualitative, quantitative, and Social Network Analysis methods. Triangulation of the findings underline the relation between the strength of the social ties within the teachers’ community and the effectiveness of socially-based features.}
}
@article{ZAMECNIK2022100427,
title = {The cohesion of small groups in technology-mediated learning environments: A systematic literature review},
journal = {Educational Research Review},
volume = {35},
pages = {100427},
year = {2022},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2021.100427},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X21000506},
author = {Andrew Zamecnik and Cristina Villa-Torrano and Vitomir Kovanović and Georg Grossmann and Srećko Joksimović and Yannis Dimitriadis and Abelardo Pardo},
keywords = {Higher education, Technology-mediated learning, Collaboration, Group cohesion, Small groups},
abstract = {The development of group cohesion for small groups in face-to-face educational learning settings has been widely studied for decades. The calibre of group cohesion within these contexts is typically associated with increases in performance, resulting in a productive collaboration that helps drive knowledge building and innovation within a learning environment. However, understanding and measuring cohesion in technology-mediated learning experiences still requires additional research. This paper reports on a systematic literature review of small groups in technology-mediated learning settings to explore the definitions of cohesion and the methodologies used for the measurements that have been identified arising in this area. Furthermore, the review provides a characterisation of the factors that impact collaborative learning in computer-supported environments, highlighting two important aspects: i) there is a significant gap in measuring cohesion using unobtrusive methods, such as relying on log or trace data and ii) there is a lack of longitudinal approaches to understand the emergence of cohesion. Finally, we discuss implications for future research in studying group cohesion.}
}
@article{MCLAUGHLIN20221319,
title = {An introduction to text analytics for educators},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {14},
number = {10},
pages = {1319-1325},
year = {2022},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S187712972200243X},
author = {Jacqueline E. McLaughlin and Kayley Lyons and Carly Lupton-Smith and Kathryn Fuller},
keywords = {Text mining, Text analytics, Sentiment analysis, Machine learning, Topic modelling},
abstract = {Our situation
Educators often find themselves in possession of large amounts of text-based materials, such as student reflections, narrative feedback, and assignments. While these materials can provide critical insight into topics of interest, they also require a substantial amount of time to read, interpret, and use. The purpose of this article is to describe and provide recommendations for text analytics.
Methodological literature review
An overview of text analytics is provided, including a brief history, common types of contemporary techniques, and the basic phases of text analytics. Several examples of common text analytics techniques are used to illustrate this approach.
Our recommendations and their applications
Practical recommendations are provided to support the use of text analytics in pharmacy education. These recommendations include: (1) clarify the purpose of the text analytics; (2) ensure the research questions are relevant and grounded in the literature; (3) develop a processing strategy and create a dictionary; (4) explore various tools for analysis and visualization; (5) establish tolerance for error; (6) train, calibrate, and validate the analytic strategy; and (7) collaborate and equip yourself.
Potential impact
Text analytics provide a systematic approach to generating information from text-based materials. Several benefits to this approach are apparent, such as improving the efficiency of analyzing text and elucidating new knowledge. Despite recent developments in text analytics techniques, limitations to this approach remain. Efforts to improve usability and accessibility of text analytics remain ongoing, and pharmacy educators should position their work within the context of these limitations.}
}
@article{ROSKOS201737,
title = {An analysis of e-book learning platforms: Affordances, architecture, functionality and analytics},
journal = {International Journal of Child-Computer Interaction},
volume = {12},
pages = {37-45},
year = {2017},
note = {Reading in the 21st century: how does digital book-reading influence the reading processes and outcomes for young children?},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212868916300484},
author = {Kathleen Roskos and Jeremy Brueck and Lisa Lenhart},
keywords = {Learning platforms, e-books, Curriculum evaluation, Independent reading},
abstract = {E-book learning platforms are increasingly used as curriculum resources for independent reading at school and home, although benefits for students’ reading motivation and skill are unclear. Using a set of analytic tools, this study describes two e-book learning platforms in terms of platform affordances, digital architecture of e-books, functionality of screen pages and dashboard analytics. Qualitative analyses reveal patterns of strength and weakness along each dimension. Affordances rated highest in content and administration characteristics, but largely unmet in accessibility and communication. Architecture tends to maximize text access, but minimize text/media integration and active reader engagement. Functionality suggests a word-focused pattern that favors word learning over text comprehension. Analytics tend to inform skill building over self-awareness and progress. Analytic tools were designed and/or refined to develop and improve technical adequacy. Findings lay the groundwork for more controlled studies of the effectiveness of e-book platforms as literacy curriculum resources and more active collaboration among publishers, IT developers and educators to improve e-book platform quality.}
}
@article{HU2021100403,
title = {A systematic review of visual representations for analyzing collaborative discourse},
journal = {Educational Research Review},
volume = {34},
pages = {100403},
year = {2021},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2021.100403},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X21000269},
author = {Liru Hu and Gaowei Chen},
keywords = {Visual representation, Collaborative discourse, Visual analytics, Systematic review},
abstract = {Visual analytics combines automated data analysis and human intelligence through visualisation techniques to address the complexity of current real-world problems. This review uses the lens of visual analytics to examine four dimensions of visual representations for analysing collaborative discourse: goals, data sources, visualisation designs, and analytical techniques based on 89 studies. We found visual analysis approaches to be suitable and advantageous for decomposing the temporality of collaborative discourse. However, it has been challenging for current research to simultaneously consider learning theories and follow visualisation design principles when adopting visualisations to analyse collaborative discourse. At the same time, existing visual analysis approaches have mainly targeted learners or researchers in online contexts and mainly focused on mirroring collaborative discourse rather than providing advanced affordances such as alerting or advising. Informed by these findings, we propose a possible future research agenda and offer suggestions for the features of successful collaboration to guide the design of advanced affordances.}
}
@article{OUYANG2021100020,
title = {Artificial intelligence in education: The three paradigms},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100020},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100020},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2100014X},
author = {Fan Ouyang and Pengcheng Jiao},
keywords = {Artificial intelligence in education, Paradigms, AI-Directed, Learner-as-recipient, AI-Supported, Learner-as-collaborator, AI-Empowered, Learner-as-leader},
abstract = {With the development of computing and information processing techniques, artificial intelligence (AI) has been extensively applied in education. Artificial intelligence in education (AIEd) opens new opportunities, potentials, and challenges in educational practices. In its short history, AIEd has been undergoing several paradigmatic shifts, which are characterized into three paradigms in this position paper: AI-directed, learner-as-recipient, AI-supported, learner-as-collaborator, and AI-empowered, learner-as-leader. In three paradigms, AI techniques are used to address educational and learning issues in varied ways. AI is used to represent knowledge models and direct cognitive learning while learners are recipients of AI service in Paradigm One; AI is used to support learning while learners work as collaborators with AI in Paradigm Two; AI is used to empower learning while learners take agency to learn in Paradigm Three. Overall, the development trend of AIEd has been developing to empower learner agency and personalization, enable learners to reflect on learning and inform AI systems to adapt accordingly, and lead to an iterative development of the learner-centered, data-driven, personalized learning.}
}
@article{MACAK2022100120,
title = {Process mining usage in cybersecurity and software reliability analysis: A systematic literature review},
journal = {Array},
volume = {13},
pages = {100120},
year = {2022},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2021.100120},
url = {https://www.sciencedirect.com/science/article/pii/S2590005621000576},
author = {Martin Macak and Lukas Daubner and Mohammadreza {Fani Sani} and Barbora Buhnova},
keywords = {Process mining, Cybersecurity, Software reliability, Systematic literature review},
abstract = {The digitalization of our society is only possible in the presence of secure and reliable software systems governing ongoing critical processes, so-called critical information infrastructures. The understanding of mutual interdependencies of events and processes is crucial for cybersecurity and software reliability. One of the promising ways to tackle these challenges is process mining, which is a set of techniques that aims to mine essential knowledge from processes, thus providing more perspectives and temporal context to data interpretation and process understanding. However, it is unclear how process mining can help and can be practically used in the context of cybersecurity and reliability. Therefore, in this work, we investigate the potential of process mining to aid in cybersecurity and software reliability to analyze and support research efforts in these areas. Concretely, we collect existing process mining applications, discuss current trends and promising research directions that can be used to tackle the current cybersecurity and software reliability challenges. To this end, we conduct a systematic literature review covering 35 relevant research approaches to examine how the process mining is currently used for these tasks and what are the research gaps and promising research directions in the area. This work is an extension of our previous work, which focused solely on the cybersecurity area, based on the observation of relative closeness and similar goals of those two fields, in which some approaches tend to overlap.}
}
@article{AZEVEDO2021100084,
title = {Learning Analytics: a bibliometric analysis of the literature over the last decade},
journal = {International Journal of Educational Research Open},
volume = {2},
pages = {100084},
year = {2021},
issn = {2666-3740},
doi = {https://doi.org/10.1016/j.ijedro.2021.100084},
url = {https://www.sciencedirect.com/science/article/pii/S2666374021000546},
author = {Ana Azevedo and Jose Manuel Azevedo},
keywords = {LA, Bibliometrics, Educational analytics, Co-authorship network analysis},
abstract = {Learning Analytics is a recent and dynamic area of research. It is important, after a decade of the first published article in the area, to get insights about it. This article presents a bibliometric study conducted in order to better know their main aspects. Data was collected from the Web of Science Core Collection. The analysis of the data was two-folded. On the one side, a descriptive analysis was performed using several bibliometric measures, namely, number of articles published by year, number of publications by year, number of citations by publication's age, countries of the publications, institutions of the publications, languages used, number of authors per publication, most productive authors, most cited authors. On the other side a co-authorship analysis was made considering authors, countries, and institutions as unit of analysis. The results obtained allowed to identify the evolution of the area, the main players in the area, namely authors, countries, and institutions. This article contributes to a deeper knowledge of the area of research Learning Analytics helping future researchers start their research in this area.}
}
@article{EZZAOUIA2020102411,
title = {Emodash: A dashboard supporting retrospective awareness of emotions in online learning},
journal = {International Journal of Human-Computer Studies},
volume = {139},
pages = {102411},
year = {2020},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102411},
url = {https://www.sciencedirect.com/science/article/pii/S1071581918305585},
author = {Mohamed Ez-zaouia and Aurélien Tabard and Elise Lavoué},
keywords = {Visualization, Dashboard, Awareness, Emotion, Online learning, Feedback},
abstract = {We present Emodash, an interactive dashboard supporting tutors’ retrospective awareness of learners’ emotions in a video-conferencing learning environment. Socio-affective relationships play an important role in learning processes and learning outcomes, but they are harder to develop in online-learning. This can be explained by a lack of emotion awareness due to the asynchronous interactions, technical challenges, and tutors’ focus on properly conducting the learning activity and gearing towards pedagogical outcomes. We conducted an eight-week long field study with five professional tutors on how they used Emodash while writing feedback to learners after language learning sessions. We found that Emodash led tutors who were already sensitive to learners’ emotions to incorporate more affective elements in their reports, suggesting a stronger awareness of learners’ emotions. Tutors also wrote more formative and less summative feedback. Furthermore, our results suggest that glanceable visualizations of learners’ emotions may be preferred and sufficient to foster tutors’ awareness of learners’ emotions. Finally, the dashboard led tutors to reflect on the way they conduct their lessons, using learners’ positive emotions as a proxy evaluation of their teaching.}
}
@article{CHEN20191957,
title = {Knowledge-Aware Learning Analytics for Smart Learning},
journal = {Procedia Computer Science},
volume = {159},
pages = {1957-1965},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.368},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919315698},
author = {Weiqin Chen},
keywords = {Knowledge, smart learning, learning analytics},
abstract = {With the increasing development and adoption of digital technologies for education, more data gathered from educational contexts are being analyzed to give actionable insights to stakeholders. As a data-driven approach for better understanding and optimizing learning and the learning environment, learning analytics has the potential to contribute to smart learning. However, current learning analytics lacks knowledge awareness, an important component in smart learning. This paper draws upon research in the domain of smart learning, reflects on current research on methods and processes in learning analytics, and proposes a framework for knowledge-aware learning analytics for smart learning.}
}
@article{RAES2020103682,
title = {Learning and instruction in the hybrid virtual classroom: An investigation of students’ engagement and the effect of quizzes},
journal = {Computers & Education},
volume = {143},
pages = {103682},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.103682},
url = {https://www.sciencedirect.com/science/article/pii/S0360131519302350},
author = {Annelies Raes and Pieter Vanneste and Marieke Pieters and Ine Windey and Wim {Van Den Noortgate} and Fien Depaepe},
keywords = {Hybrid virtual classroom, Engagement, Distance education, Self-determination theory, Mixed-methods},
abstract = {To deal with the current need for flexible learning trajectories giving access to a more diverse group of learners, synchronous hybrid virtual classrooms have been designed to connect both on-site students and remote students during synchronous teaching. Given synchronous blended learning is relatively new, there are only few studies that have investigated its use and effectiveness. Furthermore, the existing literature is mostly exploratory and qualitative in nature. This present study meets the need for empirical, theory-driven research. More specific, this study has set up an experiment to investigate how different learning settings can affect students' relatedness, intrinsic motivation and learning achievement in the context of a synchronous learning space. The Self-Determination Theory (SDT) namely stresses that relatedness is a contributing factor for intrinsic motivation and indirectly also predicts learning achievement. Although there are numerous studies using SDT in various contexts, only limited studies used this theory to examine learning in the hybrid virtual classroom comparing different learning settings and its effects on relatedness, intrinsic motivation and learning achievement. The educational setting depends on whether students are physically present and thus attend the lecture face-to-face (F2F) or remotely (virtual), and on whether the setting is the same for all students (pure) or mixed (hybrid). This study presents the results of an experimental within-subjects design study comparing the students' learning experiences as F2F versus virtual student in the pure or hybrid setting. A mixed-methods approach is used including real-time measurements of intrinsic motivation next to retrospective self-report surveys and interviews. Also the effect of quizzes has been consistently investigated. The results show that although the hybrid virtual classroom is promising regarding flexibility in education as it gives students the choice where to attend the course, it is also the most challenging one to teach in and to learn in as a remote participant. It has been found that both the relatedness to peers and the intrinsic motivation is the lowest in the hybrid-virtual setting. Yet, our results show that launching quizzes is positively related to all students’ motivation. Further research that implements different kinds of quizzes and at different time intervals is necessary to validate this finding in the context of the hybrid virtual classroom. Future research should also investigate how relatedness between the remote students and their on-campus counterparts can be improved by means of instructional interventions.}
}
@article{KALIISA2022100073,
title = {Social learning analytics in computer-supported collaborative learning environments: A systematic review of empirical studies},
journal = {Computers and Education Open},
volume = {3},
pages = {100073},
year = {2022},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2022.100073},
url = {https://www.sciencedirect.com/science/article/pii/S2666557322000015},
author = {Rogers Kaliisa and Bart Rienties and Anders I. Mørch and Anders Kluge},
keywords = {Social learning analytics, Computer-supported collaborative learning, Systematic review},
abstract = {Social learning analytics (SLA) is a promising approach for identifying students’ social learning processes in computer-supported collaborative learning (CSCL) environments. To identify the main characteristics of SLA, gaps and future opportunities for this emerging approach, we systematically identified and analyzed 36 SLA-related studies conducted between 2011 and 2020. We focus on SLA implementation and methodological characteristics, educational focus, and the studies’ theoretical perspectives. The results show the predominance of SLA in formal and fully online settings with social network analysis (SNA) a dominant analytical technique. Most SLA studies aimed to understand students’ learning processes and applied the social constructivist perspective as a lens to interpret students’ learning behaviors. However, (i) few studies involve teachers in developing SLA tools, and rarely share SLA visualizations with teachers to support teaching decisions; (ii) some SLA studies are atheoretical; and (iii) the number of SLA studies integrating more than one analytical approach remains limited. Moreover, (iv) few studies leveraged innovative network approaches (e.g., epistemic network analysis, multimodal network analysis), and (v) studies rarely focused on temporal patterns of students’ interactions to assess how students’ social and knowledge networks evolve over time. Based on the findings and the gaps identified, we present methodological, theoretical and practical recommendations for conducting research and creating tools that can advance the field of SLA.}
}
@article{OKAGBUE2023100655,
title = {A comprehensive overview of artificial intelligence and machine learning in education pedagogy: 21 Years (2000–2021) of research indexed in the scopus database},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100655},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100655},
url = {https://www.sciencedirect.com/science/article/pii/S2590291123002607},
author = {Ekene Francis Okagbue and Ujunwa Perpetua Ezeachikulo and Tosin Yinka Akintunde and Mustapha Bala Tsakuwa and Samuel Nchekwubemchukwu Ilokanulo and Kosiso Modest Obiasoanya and Chidiebere Emeka Ilodibe and Cheick Amadou Tidiane Ouattara},
keywords = {Bibliometrics, Education, Artificial intelligence, Pedagogy, Machine learning},
abstract = {The utilization of AI (artificial intelligence) and ML (machine learning) in education pedagogy will undoubtedly enhance transformative changes in academic pedagogical engagements. Most interestingly, they are perceived to transform traditional instructional activities into digitized and seamless ones for effective and efficient education. To further explore the discourse, this study tries to elucidate the dramatic rise in trends and the constant evolution of AI and ML in education pedagogy applying a bibliometrics analysis. Historically, since the emergence of AI, its influence, functions, and applications have been transcending from one form to another in the sequence of artificial intelligence (simple level of AI) to applied artificial intelligence, to machine learning, and to deep learning. From our study outcome, numerous scholars predicted that AI and ML will continue to transform beyond their current state to more sophisticated tools. A bibliometric analysis was performed with the extracted articles on artificial intelligence, machine learning, and education pedagogy from the Scopus database. The downloaded data were analyzed with bibliometrics research tools such as VOSviewer (Var 1.6.6) and R packages. For this study exploration, a total of one thousand, one hundred and thirty-eight (1138) documents were authored by two thousand, eight hundred (2800) researchers and published in six-hundred and thirty-five (635) journals from 2000 to 2021, with 5.984 as the average citations per document from sixty-two (62) countries. Our study concluded that school administrators should promote the use of AI and ML devices to promote quality pedagogical services in the academic environment. Most especially, education policymakers are advised to promulgate policies that will support the acceptability and usability of artificial intelligence and machine learning in academic environment.}
}
@article{AKCAPINAR20223818,
title = {Discovering the effects of learning analytics dashboard on students’ behavioral patterns using differential sequence mining},
journal = {Procedia Computer Science},
volume = {207},
pages = {3818-3825},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.443},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922013369},
author = {Gökhan Akçapınar and Mohammad Nehal Hasnine},
keywords = {Learning analytics, intervention, dashboard, temporal learning analytics, differential sequence mining},
abstract = {Interventions based on learning analytics have a very important place in closing the learning analytics loop. However, data-driven studies that test the effects of learning analytics-based interventions on students' online learning behaviors are very limited. In this study, the effect of the student-facing learning analytics dashboard (LAD) on the learning behavior of students in the online learning environment was investigated by using the differential pattern mining method. In a completely remote course, the learning behaviors of the participants before the introduction of the dashboard were compared with the learning behaviors they exhibited after the dashboard was introduced. In this way, it has become possible to analyze the behavior changes after the dashboard intervention. Wilcoxon signed-rank test was used to test whether these behavioral changes were statistically significant or not. According to the Wilcoxon signed-rank test results, while there is no significant difference in terms of students’ assignment and quiz interactions, it is seen that there is a statistically significant increase in terms of students’ forum-related activities such as reading other students’ posts, starting a new discussion, and replying others’ posts. Students’ SCORM interactions (e.g, launch, complete) were also increased after engaging with the LAD. In addition, it was found that the overall interaction of students in the online learning environment increased by 57% when the LAD was used.}
}
@article{TSAI2020103933,
title = {Learning analytics in European higher education—Trends and barriers},
journal = {Computers & Education},
volume = {155},
pages = {103933},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103933},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520301317},
author = {Yi-Shan Tsai and Diego Rates and Pedro Manuel Moreno-Marcos and Pedro J. Muñoz-Merino and Ioana Jivet and Maren Scheffel and Hendrik Drachsler and Carlos {Delgado Kloos} and Dragan Gašević},
keywords = {Learning analytics, Cultural and social implications, Data science applications in education, Cross-cultural projects, Post-secondary education},
abstract = {Learning analytics (LA) as a research field has grown rapidly over the last decade. However, adoption of LA is mostly found to be small in scale and isolated at the instructor level. This paper presents an exploratory study on institutional approaches to LA in European higher education and discusses prominent challenges that impede LA from reaching its potential. Based on a series of consultations with senior managers from 83 different higher education institutions in 24 European countries, we observe that LA is primarily perceived as a tool to enhance teaching and institutional management. As a result, teaching and support staff are found to be the main users of LA and the target audience of training support. In contrast, there is little evidence of active engagement with students or using LA to develop self-regulated learning skills. We highlight the importance of grounding LA in learning sciences and including students as a key stakeholder in the design and implementation of LA. This paper contributes to our understanding of the development of LA in European higher education and highlights areas to address in both practice and research.}
}
@article{KRECKO20231370,
title = {Enhancing the Value of Surgical Entrustable Professional Activities through Integrative Learning Analytics},
journal = {Journal of Surgical Education},
volume = {80},
number = {10},
pages = {1370-1377},
year = {2023},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2023.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S1931720423002726},
author = {Laura K. Krecko and Sarah Jung and Shaun Martin and Craig Krebsbach and Alexandra A. Rosser and Christopher Stahl and Patrick Varley and Jacob Greenberg and Rebecca M. Minter},
keywords = {competency-based education, learning analytics, entrustable professional activities, workplace-based assessment, data visualization},
abstract = {OBJECTIVE
To demonstrate the value of integrating surgical resident Entrustable Professional Activity (EPA) data into a learning analytics platform that provides meaningful feedback for formative and summative decision-making.
DESIGN
Description of the Surgical Entrustable Professional Activities (SEPA) analytics dashboard, and examples of summary analytics and intuitive display features.
SETTING
Department of Surgery, University of Wisconsin Hospital and Clinics.
PARTICIPANTS
Surgery residents, faculty, and residency program administrators.
RESULTS
We outline the major functionalities of the SEPA dashboard and offer concrete examples of how these features are utilized by various stakeholders to support progressive entrustment decisions for surgical residents.
CONCLUSIONS
Our intuitive analytics platform allows for seamless integration of SEPA microassessment data to support Clinical Competency Committee (CCC) decisions for resident evaluation and provides point of training feedback to faculty and trainees in support of progressive autonomy.}
}
@article{VIBERG201898,
title = {The current landscape of learning analytics in higher education},
journal = {Computers in Human Behavior},
volume = {89},
pages = {98-110},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218303492},
author = {Olga Viberg and Mathias Hatakka and Olof Bälter and Anna Mavroudi},
keywords = {Learning analytics, Literature review, Higher education, Research methods, Evidence},
abstract = {Learning analytics can improve learning practice by transforming the ways we support learning processes. This study is based on the analysis of 252 papers on learning analytics in higher education published between 2012 and 2018. The main research question is: What is the current scientific knowledge about the application of learning analytics in higher education? The focus is on research approaches, methods and the evidence for learning analytics. The evidence was examined in relation to four earlier validated propositions: whether learning analytics i) improve learning outcomes, ii) support learning and teaching, iii) are deployed widely, and iv) are used ethically. The results demonstrate that overall there is little evidence that shows improvements in students' learning outcomes (9%) as well as learning support and teaching (35%). Similarly, little evidence was found for the third (6%) and the forth (18%) proposition. Despite the fact that the identified potential for improving learner practice is high, we cannot currently see much transfer of the suggested potential into higher educational practice over the years. However, the analysis of the existing evidence for learning analytics indicates that there is a shift towards a deeper understanding of students’ learning experiences for the last years.}
}
@article{WANG2024114312,
title = {Determinants of effective HR analytics Implementation: An In-Depth review and a dynamic framework for future research},
journal = {Journal of Business Research},
volume = {170},
pages = {114312},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114312},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323006719},
author = {Lijun Wang and Yu Zhou and Karin Sanders and Janet H. Marler and Yunqing Zou},
keywords = {HR analytics, Implementation, Adaptive structuration theory, Determinants, Dynamic framework},
abstract = {Human resources (HR) analytics implementation is a field that continues to evolve, keeping pace with the increasing speed of digital innovation. However, despite its practical significance, there is a lack of knowledge of effective HR analytics implementation. Therefore, in this study, by conducting an in-depth analysis of 89 peer-reviewed HR analytics studies published during the past twenty years, we present a comprehensive summary of determinants of successfully implementing HR analytics in organizations. Furthermore, using adaptive structuration theory, we propose a dynamic framework of HR analytics implementation, offering guidance to both HR practitioners and HR scholars. Finally, we provide a research agenda aimed at stimulating future research endeavors in HR analytics.}
}
@article{DU2023104828,
title = {What can online traces tell us about students’ self-regulated learning? A systematic review of online trace data analysis},
journal = {Computers & Education},
volume = {201},
pages = {104828},
year = {2023},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104828},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523001057},
author = {Jiahui Du and Khe Foon Hew and Lejia Liu},
keywords = {Distance education and online learning, Evaluation methodologies, Teaching/learning strategies},
abstract = {“Self-regulated learning” (SRL) is defined as taking responsibility for one's own learning. Self-regulatory skills are crucial to learners' success in the online learning context. Although research on SRL is expanding in recent years, much of the literature has relied on self-reporting tools to measure SRL. Online trace data analysis, an emerging approach, provides the promise of greater authenticity and convenience in measuring SRL as compared to self-reports. We conducted a systematic review of online trace data analysis that measured SRL in various learning platforms to address three research questions: “How did previous studies use online trace data as indicators of SRL?“, “What approaches are being used to interpret the online trace data?“, and “What are the challenges of using online trace data to measure SRL?“. We systematically searched seven bibliographic databases with specific inclusion and exclusion criteria. A total of 38 empirical studies were eventually examined. We leveraged the two most cited SRL models as theoretical basis and mapped the various online trace data into relevant SRL process to answer the first research question. Two commonly adopted approaches to interpret the online trace data were identified. Three key challenges pertaining to the use of trace data to measure SRL were identified: time segmentation, generalization, and validity. We discussed these challenges and the possible means to mitigate them. Finally, we propose a flowchart to guide future studies in conducting online trace data analysis in SRL research.}
}
@article{BORTE2023100568,
title = {Prerequisites for teachers’ technology use in formative assessment practices: A systematic review},
journal = {Educational Research Review},
volume = {41},
pages = {100568},
year = {2023},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2023.100568},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X23000611},
author = {Kristin Børte and Sølvi Lillejord and Jessica Chan and Barbara Wasson and Samuel Greiff},
keywords = {Formative assessment, Teachers' technology use, Digital tool, Teachers as co-designers, Systematic review, Student active learning, Primary and secondary education},
abstract = {While researchers promote the interactive learning potential of digital tools, studies reveal that teachers adapt technology to existing practice instead of using the tools' potential for student active learning. Researchers also argue that formative assessment enhances students' learning, while studies find formative assessment difficult to implement. To investigate these paradoxes and better understand how teachers use digital tools in formative assessment and with what result, we conducted a systematic review of teachers' technology use in formative assessment practices in primary and secondary education. Systematic searches identified 22 relevant articles that are included in the review. We found unclear definitions of formative assessment across studies and document challenges teachers encounter when they use technology for formative assessment purposes. We conclude with three prerequisites for teachers' successful technology use in formative assessment practices: 1) clear definitions of formative assessment, 2) alignment between digital tools and pedagogical practice, and 3) data literacy to examine and interpret information and use this to improve students’ learning. The review also documents knowledge gaps in current research.}
}
@incollection{CATANIA2021293,
title = {7 - AI applications in prevalent diseases and disorders},
editor = {Louis J. Catania},
booktitle = {Foundations of Artificial Intelligence in Healthcare and Bioscience},
publisher = {Academic Press},
pages = {293-444},
year = {2021},
isbn = {978-0-12-824477-7},
doi = {https://doi.org/10.1016/B978-0-12-824477-7.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128244777000079},
author = {Louis J. Catania},
keywords = {Chronic inflammation, Immunology, Autoimmune disease, Gene editing, Gene replacement, Cancer, Cardiovascular disease, Cerebrovascular disease, Infectious disease, Chronic disease},
abstract = {Health care, biosciences and artificial intelligence (AI) represent a group of highly sophisticated and disruptive sciences and technologies. None, however, would mean much if they didn’t offer succor to the prevalent diseases and disorders that afflict humankind. Chapter 7 begins with the 2 biosciences of immunology and genetics that use AI to address chronic inflammation, autoimmune diseases, gene editing (CRISPR Cas9), gene replacement (CAR-T) and stem cell transplantation. The benefits discussed are incalculable as well as their value to all other prevailing diseases and disorders we face in health care. Some of those prevalent conditions and their AI applications are discussed throughout Chapter 7 and include cancer, cardio and cerebrovascular disease, diabetes, neurological disorders and the more common diseases of our bodily systems. Finally, AI’s role in prevalent issues like injury, infectious disease, chronic disease, mental health, depression, aging, exercise and nutrition are discussed.}
}
@article{DAI2022100087,
title = {Educational applications of artificial intelligence in simulation-based learning: A systematic mapping review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100087},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100087},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2200042X},
author = {Chih-Pu Dai and Fengfeng Ke},
keywords = {Artificial intelligence, Simulations, Virtual agents, Affective computing, Assessments},
abstract = {The field of education has experienced a transformation as artificial intelligence (AI) becomes increasingly applicable for learning purposes. AI has the potential to transform the social interactions in educational contexts among learners, teachers, and technologies. In this systematic mapping review, we focus on mapping and framing trends for educational applications of AI in simulation-based learning. Fifty-nine studies met the inclusion and exclusion criteria. We coded and analyzed six mapped categories in this literature review: (1) the year-of-study trend, (2) methods, (3) AI technologies, (4) simulation, (5) study trends, and (6) learning principles and theories. To provide nuanced details from the included literature, we also synthesized three thematic trends: (1) AI built in virtual agents for simulation-based learning, (2) AI infused in simulation-based learning with affective computing, and (3) AI leveraged in simulation-based learning for assessments. Trend One builds on a general acknowledgement of virtual agents as a guide for situated learning. Trend Two posits the role of affective states in learning trajectories and suggests the related machine learning approaches. Trend Three discusses machine learning techniques and multimodal computing used for assessment and feedback. The paper concludes with implications and suggestions for research and practice in AI in education using simulation-based learning.}
}
@article{WAHEED2023118868,
title = {Early prediction of learners at risk in self-paced education: A neural network approach},
journal = {Expert Systems with Applications},
volume = {213},
pages = {118868},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118868},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422018863},
author = {Hajra Waheed and Saeed-Ul Hassan and Raheel Nawaz and Naif R. Aljohani and Guanliang Chen and Dragan Gasevic},
keywords = {Early prediction, Machine learning, Deep learning, Long short-term memory (LSTM), Students at risk, Virtual learning environment (VLE)},
abstract = {To address the demands of modern education and increase flexibility, many higher education institutions are considering self-paced education programs. However, student retention is yet a widely recognized challenge faced in self-paced education. While many studies have examined the potential of the use of data about student interaction with learning technologies to predict student success, studies that focus on self-paced education are scarce. To address this gap in the literature, this paper reports on the findings of a study that has investigated the performance of a well-known deep learning technique i.e., Long Short-term Memory (LSTM), in the prediction of students at risk of failing a course offered in a self-paced mode of online education. The study has utilized a freely accessible Open University Learning Analytics Dataset comprising 22,437 students with 69 % pass, and 31 % failed instances. The deep LSTM shows the highest predictive power to classify between pass and fail students, compared to all other alternatives by achieving an accuracy of 84.57 %, precision of 82.24 % and recall of 79.43 %. Interestingly, with only first five weeks of course activity log data used for training, the receiver operating characteristic based diagnostic accuracy of the LSTM algorithm is achieved up to 71 %, that outperforms almost all other conventional algorithms - despite trained on the complete dataset collected for the entire duration of the course i.e. up to 38 weeks. Furthermore, this study has also employed a shapely additive explanation model to identify the most important predictors of student retention, e.g., assessment submission and attempted quizzes. This approach is essential in order to increase the interpretability of deep learning techniques and, thus, increase their potential to generate actionable insights.}
}
@article{VALLE2021104288,
title = {The influence of task-value scaffolding in a predictive learning analytics dashboard on learners' statistics anxiety, motivation, and performance},
journal = {Computers & Education},
volume = {173},
pages = {104288},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104288},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521001652},
author = {Natercia Valle and Pavlo Antonenko and Denis Valle and Kara Dawson and Anne Corinne Huggins-Manley and Benjamin Baiser},
keywords = {Data science applications in education, Distance education and online learning, Human-computer interface, Pedagogical issues, Post-secondary education},
abstract = {There is an increasing trend of learning analytics dashboards (LADs) being used to provide feedback to learners. However, there is little empirical evidence about the influence of their design features on learners' cognitive and affective outcomes, especially in high-anxiety courses such as statistics. To address this gap, this study employed a two-group experimental design applied to an authentic setting to assess the influence of task-value scaffolding in a LAD on learners' anxiety, motivation, and learning performance in an online statistics course. This semester-long experiment was implemented in two instances of the course offering (Fall/2019 and Spring/2020) and involved a total of 146 students. The results showed that task-value scaffolding had a negative impact on learners’ computation anxiety and attitudes towards statistics in comparison to the control group. On the other hand, the treatment had no significant influence on other aspects of statistics anxiety, motivation, and learning outcomes. Taken jointly, these results suggest that the use of task-value scaffolding embedded in LADs can have detrimental effects on learners. More experimental studies are necessary to understand the positive and negative effects of LADs with motivational scaffolding.}
}
@article{RODRIGUES201987,
title = {Tracking e-learning through published papers: A systematic review},
journal = {Computers & Education},
volume = {136},
pages = {87-98},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0360131519300715},
author = {Helena Rodrigues and Filomena Almeida and Vanessa Figueiredo and Sara L. Lopes},
keywords = {E-learning, Education, Systematic review, Semantic analysis, Leximancer},
abstract = {Electronic learning (e-learning) is a broader approach to learning that brings new opportunities for learning and teaching in many fields of education far from the traditional classroom environment. Over the past decades, research in the field indicates a proliferation of e-learning contents and discrepancies that affect interoperability patterns in education for students and teachers; however, little has been done to assess the usability of e-learning systems. From a different perspective, this study aims to provide information on the numerous findings relating to the cumulative results of e-learning in education. This systematic review uses a full protocol with the aim of standardizing and specifying all the procedures adopted to collect and code 99 academic articles from 2010 to 2018 with keywords: education and e-learning. The text analysis as conducted using the qualitative software Leximancer to extract meaning from the large number of articles retrieved. The results highlight four dominant themes, namely education systems and learning issues that in turn promote student behaviours and the use of online learning tools. This research contributes towards providing research propositions that can be used in a cogent theoretical framework and, based on the analysis, we also propose a new definition of e-learning.}
}
@article{LOPEZJIMENEZ2022106459,
title = {Taking the pulse of a classroom with a gamified audience response system},
journal = {Computer Methods and Programs in Biomedicine},
volume = {213},
pages = {106459},
year = {2022},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106459},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721005332},
author = {Juan J. López-Jiménez and José L. Fernández-Alemán and Laura López González and Ofelia González Sequeros and Begoña Moros Valle and José A. García-Berná and Ali Idri and Ambrosio Toval},
keywords = {E-learning, Human anatomy, Gamified audience response system, Heart rate variations, Experiment},
abstract = {Background and objective
This paper presents an empirical study of a gamified mobile-based assessment approach that can be used to engage students and improve their educational performance.
Method
A gamified audience response system called G-SIDRA was employed. Three gamification elements were used to motivate students in classroom activities: badges for achievements to increase engagement, points to indicate progression and performance in the subject and ranking for promoting competitiveness. A total of 90 medical students in a General and Descriptive Anatomy of the Locomotor System course were taught using G-SIDRA in the academic year 2019/2020. Smart bracelets were configured to collect heart rate measurements from 30 students with the aim of evaluating the impact of the gamification elements. The control group consisted of a sample of 110 students enrolled on the same course in the academic year 2016/2017 using non-gamified SIDRA.
Results
Statistically significant differences were found between multiple choice questions (MCQ) scores obtained by using SIDRA and G-SIDRA in the four experiments (U = 1.621,50, p < 0,01 for Exp1; U = 1.950,00, p < 0,01 for Exp2; U = 955,00, p < 0,01 for Exp3; U = 2.335,00, p < 0,01 for Exp4). In the students’ final exam grades, statistically significant differences between students that used G-SIDRA as opposed to SIDRA (T(157) = 3.992; p = 0.044) were obtained. Concerning gamification elements, statistically significantly differences were found in comparing the pulse increases after and before the badge event in the four experiments (U = 2.484,00, p = 0,038 for Exp1; U = 2.109,50, p = 0,046 for Exp2; U = 1.790,50, p = 0,025 for Exp3; U = 1.557,0, p = 0,048 for Exp4). However, there are not statistically significant differences between the pulse increases after and before the ranking event in the four experiments. In a 5-point Likert-type scale, the students expressed satisfaction with G-SIDRA (M = 4.552) and thought the system helped to better understand both theoretical and practical concepts (M = 4.092). Their global assessment of the G-SIDRA platform was 4.471.
Conclusions
Of the three gamification elements used in the study, only badge has an effect on heart rate. Better student responses and academic performance were achieved when using G-SIDRA. Nevertheless, more research is required to evaluate the impact of the gamification elements on the motivation, engagement and performance of students. Physiological measures are promising approaches for gamification elements evaluation.}
}
@article{2016S2,
title = {117th Annual Meeting of the American Association of Colleges of Pharmacy, Anaheim, California, July 23-27, 2016},
journal = {American Journal of Pharmaceutical Education},
volume = {80},
number = {5},
pages = {S2},
year = {2016},
issn = {0002-9459},
doi = {https://doi.org/10.5688/ajpe805S2},
url = {https://www.sciencedirect.com/science/article/pii/S0002945923012500}
}
@article{KHOSRAVI2022100074,
title = {Explainable Artificial Intelligence in education},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100074},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100074},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000297},
author = {Hassan Khosravi and Simon Buckingham Shum and Guanliang Chen and Cristina Conati and Yi-Shan Tsai and Judy Kay and Simon Knight and Roberto Martinez-Maldonado and Shazia Sadiq and Dragan Gašević},
keywords = {Explainable AI, AI in Education, Open learner models},
abstract = {There are emerging concerns about the Fairness, Accountability, Transparency, and Ethics (FATE) of educational interventions supported by the use of Artificial Intelligence (AI) algorithms. One of the emerging methods for increasing trust in AI systems is to use eXplainable AI (XAI), which promotes the use of methods that produce transparent explanations and reasons for decisions AI systems make. Considering the existing literature on XAI, this paper argues that XAI in education has commonalities with the broader use of AI but also has distinctive needs. Accordingly, we first present a framework, referred to as XAI-ED, that considers six key aspects in relation to explainability for studying, designing and developing educational AI tools. These key aspects focus on the stakeholders, benefits, approaches for presenting explanations, widely used classes of AI models, human-centred designs of the AI interfaces and potential pitfalls of providing explanations within education. We then present four comprehensive case studies that illustrate the application of XAI-ED in four different educational AI tools. The paper concludes by discussing opportunities, challenges and future research needs for the effective incorporation of XAI in education.}
}
@article{VANBECELAERE2020103680,
title = {The effects of two digital educational games on cognitive and non-cognitive math and reading outcomes},
journal = {Computers & Education},
volume = {143},
pages = {103680},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.103680},
url = {https://www.sciencedirect.com/science/article/pii/S0360131519302337},
author = {Stefanie Vanbecelaere and Katrien {Van den Berghe} and Frederik Cornillie and Delphine Sasanguie and Bert Reynvoet and Fien Depaepe},
keywords = {Elementary education, Improving classroom teaching, Interactive learning environments, Multimedia systems},
abstract = {Digital educational games play an increasingly important role in education. However, multiple questions about the effectiveness of educational games with respect to cognitive and non-cognitive effects remain unclear. The current study, a longitudinal, quasi-experiment with 336 first graders, examined the effects of two digital educational games, Number Sense Game (NSG) and Reading Game (RG). The NSG trained early numerical skills, the RG supported emergent reading. Children were pseudo-randomly assigned to either an experimental condition, comprising eight weeks of intensive game-based training, or a control condition in which they took part in regular education without game-based practice. A pretest-posttest design was used to examine the effects of the intervention on cognitive (digit comparison, number line estimation, letter knowledge, math and reading competence) and non-cognitive outcomes (math and reading anxiety). Delayed cognitive effects on math and reading competence were also investigated two months after the intervention. Furthermore, we examined variances of the impact of the training on cognitive outcomes as a consequence of differences in children's prior knowledge, prior affect and socio-economic status. For cognitive outcomes, results revealed that children who played a game performed better on number line estimation and reading competence, whereas no significant differences were observed for digit comparison, letter knowledge and math competence. Also, children who played a game showed better scores in the delayed reading posttest, but not in the delayed math posttest. For non-cognitive outcomes, game training did not affect math or reading anxiety. Regarding individual differences, children with less prior knowledge in the game play condition performed better on the number line estimation posttest compared to children in the control condition. Children with more prior knowledge in the game play condition still scored better on this test compared to the control condition, but the difference between the conditions was smaller.}
}
@article{KACZKO2023104662,
title = {Critical thinking in the community of inquiry framework: An analysis of the theoretical model and cognitive presence coding schemes},
journal = {Computers & Education},
volume = {193},
pages = {104662},
year = {2023},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104662},
url = {https://www.sciencedirect.com/science/article/pii/S0360131522002330},
author = {Éva Kaczkó and Annette Ostendorf},
keywords = {Critical thinking and cognitive presence, Community of inquiry, Distance education and online learning, Evaluation methodologies, Post-secondary education},
abstract = {The Community of Inquiry (CoI) framework has been widely used in online teaching in higher education over the past twenty years. Its goal is to support students' professional development while fostering their critical thinking. In this paper, we thematically analyze how the framework authors' interpretations of critical thinking translate into the construct of cognitive presence—operationalized in the Practical inquiry model—and its commonly used coding scheme(s). We show that the framework suffers from having become a “pragmatic” tool, thus compromising the intended dimension of fostering critical thinking. Furthermore, we draw attention to the “acting” role of coding schemes, which may have consequences for research and teaching practice. In a first step, we examine the theoretical assumptions based on Lipman's and Garrison and Archer's ideas about the target category of critical thinking incorporated in the CoI framework. Although the framework is informed by a community of inquiry in Lipman's sense, we show that the chief characteristic of critical thinking associated with facilitating good judgment is not sufficiently addressed. Critical thinking is conceptualized more as confirmation of knowledge structures and problem-solving thinking within the Practical Inquiry model. In a second step, we systematically analyze cognitive presence coding schemes as research tools for capturing critical thinking. We trace a narrowing view of critical thinking within the CoI framework and regarding the coding schemes that measure cognitive presence. Consequently, we raise awareness of the risks in educational research arising from the complexity-reducing modeling and operationalizing of multifaceted educational concerns, such as critical thinking in a community of inquiry.}
}
@article{POGORSKIY2022100094,
title = {Learners’ web navigation behaviour beyond learning management systems: A way into addressing procrastination in online learning?},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100094},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100094},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000492},
author = {Eduard Pogorskiy and Jens F. Beckmann},
keywords = {Web navigation behavior, Online learning, Procrastination, Web browser extension, Sequential pattern mining, Behavior visualization},
abstract = {The attractiveness of online games, social media, and mobile apps is frequently considered a challenge for online learners. Procrastinatory behaviour is often associated with a relative lack of self-regulatory skills that would otherwise help learners to resist distractions and to progress in learning. This paper reports a pilot study, conducted with 49 online learners, in which we describe the use of a virtual learning assistant as a tool for collecting online learners' web navigation behaviour. As this virtual learning assistant operates as an extension to the Chrome web browser, it is possible that data collection is achieved independently of, and beyond specific learning management systems. Furthermore, the study opens up the possibility of leveraging the collected dataset for visual learning analytics and pattern mining. To demonstrate the potential utility of the virtual learning assistant, we present an example for a detailed examination of a learner's web navigation behaviour. The results of the detailed examination of a single learner's web navigation behaviour over 333 days, presented as a case study, revealed the presence of seasonality in accessing certain web resources and stable sequential patterns in the learner's web navigation that can be associated with procrastinatory behaviour.}
}
@article{WAHEED2020106189,
title = {Predicting academic performance of students from VLE big data using deep learning models},
journal = {Computers in Human Behavior},
volume = {104},
pages = {106189},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.106189},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219304017},
author = {Hajra Waheed and Saeed-Ul Hassan and Naif Radi Aljohani and Julie Hardman and Salem Alelyani and Raheel Nawaz},
keywords = {Learning analytics, Predicting success, Educational data, Machine learning, Deep learning, Virtual learning environments (VLE)},
abstract = {The abundance of accessible educational data, supported by the technology-enhanced learning platforms, provides opportunities to mine learning behavior of students, addressing their issues, optimizing the educational environment, and enabling data-driven decision making. Virtual learning environments complement the learning analytics paradigm by effectively providing datasets for analysing and reporting the learning process of students and its reflection and contribution in their respective performances. This study deploys a deep artificial neural network on a set of unique handcrafted features, extracted from the virtual learning environments clickstream data, to predict at-risk students providing measures for early intervention of such cases. The results show the proposed model to achieve a classification accuracy of 84%–93%. We show that a deep artificial neural network outperforms the baseline logistic regression and support vector machine models. While logistic regression achieves an accuracy of 79.82%–85.60%, the support vector machine achieves 79.95%–89.14%. Aligned with the existing studies - our findings demonstrate the inclusion of legacy data and assessment-related data to impact the model significantly. Students interested in accessing the content of the previous lectures are observed to demonstrate better performance. The study intends to assist institutes in formulating a necessary framework for pedagogical support, facilitating higher education decision-making process towards sustainable education.}
}
@article{TSAI2021100794,
title = {Connecting the dots: An exploratory study on learning analytics adoption factors, experience, and priorities},
journal = {The Internet and Higher Education},
volume = {50},
pages = {100794},
year = {2021},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2021.100794},
url = {https://www.sciencedirect.com/science/article/pii/S1096751621000038},
author = {Yi-Shan Tsai and Vitomir Kovanović and Dragan Gašević},
keywords = {Epistemic network analysis, Higher education, Learning analytics, Adoption strategy, Adoption factors, adoption experience},
abstract = {Existing studies have shed light on policies and strategies for learning analytics (LA) adoption, yet there is limited understanding of associations among factors that influence adoption processes or the change in priorities when institutional experience with LA increases. This paper addresses this gap by presenting a study based on interviews with institutional leaders from 27 European higher education institutions. Results showed that experienced institutions demonstrated more interest in exploring learning behaviour and pedagogical reformation than simply measuring a phenomenon. Experienced institutions also paid more attention to methodological approaches to LA than data constraints, and demonstrated a broader involvement of teachers and students. This paper also identifies inter-related connections between prevailing challenges that impede the scaling of LA. Based on the results, we suggest regular evaluations of LA adoption to ensure the alignment of strategy and desired changes. We also identify three areas that require particular attention when forming short-term goals for LA at different phases of adoption}
}
@article{KIM2021104171,
title = {Exploring the structural relationships between course design factors, learner commitment, self-directed learning, and intentions for further learning in a self-paced MOOC},
journal = {Computers & Education},
volume = {166},
pages = {104171},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104171},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521000488},
author = {Dongho Kim and Eulho Jung and Meehyun Yoon and Yunjeong Chang and Sanghoon Park and Dongsim Kim and Fatih Demir},
keywords = {MOOC, Instructional design, Learner commitment, Self-directed learning, Continuance intention},
abstract = {The open and massive characteristics of Massive Open Online Course (MOOC) lead to a lack of instructor presence, which potentially hinders learners' commitment and learning processes. As a result, the effectiveness of MOOCs is contingent upon the extent to which learners direct their own learning. However, learners' self-directed learning and commitment are largely influenced by course design factors due to lack of direct learner-instructor interactions. In order to address the current gap in the literature with regard to how course design factors influence learning processes and outcomes, this study investigated the relationships between MOOC design factors, learner commitment, self-directed learning, and intentions for future learning, using survey responses collected from 664 learners who took a large-scale MOOC. We found that the transactional distance between learners and content was associated with students' self-directed learning. Course structure and organization predicted both students' self-directed learning and commitment to the MOOC. Importantly, self-directed learning mediated relationships between the course design factors and learners’ intentions for further learning. Based on our findings, we provide design strategies for effective learner-content interaction in large-scale self-paced MOOCs.}
}
@article{MISURACA2021100979,
title = {Using Opinion Mining as an educational analytic: An integrated strategy for the analysis of students’ feedback},
journal = {Studies in Educational Evaluation},
volume = {68},
pages = {100979},
year = {2021},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2021.100979},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X21000055},
author = {Michelangelo Misuraca and Germana Scepi and Maria Spano},
keywords = {Quantitative text analysis, Sentiment analysis, Polarity score detection},
abstract = {The analysis of students’ feedback written in natural language has been poorly considered in academic institutions, looking more frequently at students’ ratings as a base to evaluate courses and instructors. Statistical text analyses offer the possibility of exploring text collections from a quantitative viewpoint. Particularly interesting is Opinion Mining (OM), a family of techniques at the crossroads of Statistics, Linguistics and Computer Science. OM allows evaluating the sentiment of individual opinions, highlighting their semantic orientation. In an educational context, this approach allows processing students’ comments and creating powerful analytics. This paper aims at introducing readers to OM, presenting a strategy to compute the sentiment polarity of students’ comments. After explaining the rationale of the proposal and its mathematical formalisation, a toy example is presented to show how it works in practice. A discussion about theoretical and empirical implications offers some hints about its potentiality in a learning environment.}
}
@article{SHARMA20221,
title = {The design and evaluation of an AR-based serious game to teach programming},
journal = {Computers & Graphics},
volume = {103},
pages = {1-18},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0097849322000024},
author = {Vandit Sharma and Kaushal Kumar Bhagat and Huai-Hsuan Huang and Nian-Shing Chen},
keywords = {Augmented Reality, Computational thinking, Learning Analytics, Gamification, Feedback design, System usability},
abstract = {The ubiquity of smartphone and tablet devices, combined with the increasing availability of serious games, has enabled students to learn various abstract concepts in an appealing and convenient manner. While several researchers have explored the use of Augmented Reality (AR) in serious games, many of these games have not been critically explained or evaluated. To that end, we employed game-based learning methodologies and Game Learning Analytics (GLA) to systematize the design and evaluation of an AR-based serious game to teach programming. We evaluated our game for usability and effectiveness by conducting a user study on twenty-seven undergraduate students. The evaluation primarily consisted of a learning test conducted twice – before and after playing the game – along with a usability questionnaire that players completed after playing the game. Our results showed that players made significant progress after playing the game. The game helped players improve their basic programming skills, especially for the group having lower prior programming skills. The results highlighted various ways in which GLA can be used to benefit different stakeholders in the game. Based on players’ qualitative responses, we also identified several areas of improvement, most prominently the trade-off between ease of use and game complexity. We provide suggestions and discuss implications for future work.}
}
@article{OUHAICHI2023100136,
title = {Research trends in multimodal learning analytics: A systematic mapping study},
journal = {Computers and Education: Artificial Intelligence},
volume = {4},
pages = {100136},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100136},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000152},
author = {Hamza Ouhaichi and Daniel Spikol and Bahtijar Vogel},
keywords = {Multimodal learning analytics, Mapping study, Learning technologies, Artificial intelligence},
abstract = {Understanding and improving education are critical goals of learning analytics. However, learning is not always mediated or aided by a digital system that can capture digital traces. Learning in such environments can be studied by recording, processing, and analyzing different signals, including video and audio, so that traces of actors’ actions and interactions are captured. Multimodal Learning Analytics refers to analyzing these signals through the use and integration of these multiple modes. However, a need exists to evaluate how research is conducted in the emerging field of multimodal learning analytics to aid and evaluate how these systems work. With the growth of multimodal learning analytics, research trends and technologies are needed to support its development. We conducted a systematic mapping study based on established systematic literature practices to identify multimodal learning analytics research types, methodologies, and trending research themes. Most mapped papers presented different solutions and used evaluation-based research methods to demonstrate an increasing interest in multimodal learning analytics technologies. In addition, we identified 14 topics under four themes––learning context, learning process, systems and modality, and technologies––that can contribute to the growth of multimodal learning analytics.}
}
@article{SERGIS2019724,
title = {Using educational data from teaching and learning to inform teachers’ reflective educational design in inquiry-based STEM education},
journal = {Computers in Human Behavior},
volume = {92},
pages = {724-738},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217306945},
author = {Stylianos Sergis and Demetrios G. Sampson and María Jesús Rodríguez-Triana and Denis Gillet and Lina Pelliccione and Ton {de Jong}},
keywords = {Educational data analytics, Teaching and learning analytics, Teaching analytics, Learning analytics, Guidance, Inquiry-based teaching, STEM education},
abstract = {Science, Technology, Engineering and Mathematics (STEM) education is recognized as a top school education priority worldwide and Inquiry-based teaching and learning is identified as a promising approach. To effectively engage students in Inquiry tasks, appropriate guidance should be provided, usually by combining digital tools such online labs and modeling tools. This is a cumbersome task for teachers, since it involves manually assessing the type/level of tool-supported guidance to be provided and potentially refining these to meet guidance needs of individual students. In our research we target to investigate how to support this systematic reflection process with educational data analytics methods and tools from both the design and the delivery of Inquiry-based educational designs (IED). The contribution of this paper is to propose a novel “Teaching and Learning” Analytics method and research prototype tool, extending the scope of purely learning analytics methods, to analyze IED in terms of the tool-supported guidance they offer and relate these analyses to students' educational data that are already being collected by existing learning analytics systems, increasing teachers' awareness. A two-layer evaluation methodology positively assessed the capacity of our method to analyze IED and provided initial evidence that the insights generated offer statistically significant indicators that impact students' activity during the delivery of these IED. The insights of this work aim to contribute in the field of cognitive data analytics for teaching and learning, by investigating new ways to combine analyses of the educational design and students' activity, and inform teachers’ reflection from a holistic perspective.}
}
@article{DELGADOMARTIN2022100281,
title = {DEIFDC framework: Evaluation of digital education deployment in India in the midst of the Covid-19 pandemic},
journal = {Social Sciences & Humanities Open},
volume = {6},
number = {1},
pages = {100281},
year = {2022},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2022.100281},
url = {https://www.sciencedirect.com/science/article/pii/S2590291122000353},
author = {Ana Victoria {Delgado Martín} and José María {Larrú Ramos}},
keywords = {Digital education, Compound index, Developing countries, Digital economy},
abstract = {The Digital Education Index for Developing Countries (DEIFDC) is a compound index that considers nine different variables grouped in three main levers that have been researched relevant to assess the overall state of readiness of Digital Education deployment in a developing country. Digital Education has been approached from an instrumental point of view, focusing on the advantages that the introduction at an early stage of digital tools brings to the teaching and learning processes to ensure children can acquire the required 21st competencies of a future workforce. In the application for the Indian case, social, cultural, economic and educational data obtained through desk research during the first semester of 2021 has been taken into consideration. Despite significant Government efforts on scaling up Digital Education, primarily due to the Covid-19 pandemic school closure, the 0.596 DEIFDC score on a 0–1 possible range has shown Inadequate Digital Education Deployment, derived mainly from poor school infrastructure, limited pedagogical capabilities and modest students' skills. Furthermore, the socio-demographic differences observed among school children and the existent digital divide in rural and urban areas demonstrate that major effort needs to be undertaken to ensure vulnerable Indian population does not lag behind under the new rules of the Digital Economy.}
}
@article{SANCHEZPUCHOL2017542,
title = {Towards an Unified Information Systems Reference Model for Higher Education Institutions},
journal = {Procedia Computer Science},
volume = {121},
pages = {542-553},
year = {2017},
note = {CENTERIS 2017 - International Conference on ENTERprise Information Systems / ProjMAN 2017 - International Conference on Project MANagement / HCist 2017 - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN/HCist 2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.072},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917322718},
author = {Felix Sanchez-Puchol and Joan A. Pastor-Collado and Baptista Borrell},
keywords = {Information Systems Architecture, Reference Model, Higher Education Institutions, Enterprise Information Systems},
abstract = {Higher education institutions are currently facing many challenges that are making them to start compete strategically, like other not-for-profit firm. To adequately support such new approach, their information systems and business strategies should be totally aligned. However, the current existing landscape of heterogeneous information systems and applications deployed in many institutions can compromise such aim. Recently, reference architectures and models have emerged as instruments suitable to help company’s decision-makers to cope with such tensions. However, whilst many of such architectural models already exist for several industries, little has been done so far in higher education. In this paper, we briefly review major existing developments in such way before to inductively derive a unified information systems reference model tailored for higher education institutions.}
}
@article{CHENG201760,
title = {Analyzing gameplay data to inform feedback loops in The Radix Endeavor},
journal = {Computers & Education},
volume = {111},
pages = {60-73},
year = {2017},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2017.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0360131517300702},
author = {Meng-Tzu Cheng and Louisa Rosenheck and Chen-Yen Lin and Eric Klopfer},
abstract = {The purpose of this study is to explore some of the ways in which gameplay data can be analyzed to yield results that feed back into the learning ecosystem. There is a solid research base showing the positive impact that games can have on learning, and useful methods in educational data mining. However, there is still much to be explored in terms of what the results of gameplay data analysis can tell stakeholders and how those results can be used to improve learning. As one step toward addressing this, researchers in this study collected back-end data from high school students as they played an MMOG called The Radix Endeavor. Data from a specific genetics quest in the game were analyzed by using data mining techniques including the classification tree method. These techniques were used to examine the relationship between tool use and quest completion, how use of certain tools may influence content-related game choices, and the multiple pathways available to players in the game. The study identified that in this quest use of the trait examiner tool was most likely to lead to success, though a greater number of trait decoder tool uses could also lead to success, perhaps because in those cases players solving problems about genetic traits at an earlier point. These results also demonstrate the multiple strategies available to Radix players that provide different pathways to quest completion. Given these methods of analysis and quest-specific results, the study applies the findings to suggest ways to validate and refine the game design, and to provide useful feedback to students and teachers. The study suggests ways that analysis of gameplay data can be part of a feedback loop to improve a digital learning experience.}
}
@article{HOOSHYAR2020103878,
title = {Open learner models in supporting self-regulated learning in higher education: A systematic literature review},
journal = {Computers & Education},
volume = {154},
pages = {103878},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103878},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300774},
author = {Danial Hooshyar and Margus Pedaste and Katrin Saks and Äli Leijen and Emanuele Bardone and Minhong Wang},
keywords = {Open learner model, Systematic review, Self-regulated learning, Higher education},
abstract = {The open learner model (OLM) represents the knowledge or skill levels of learners in various ways, encouraging learners to actively participate in thinking about and crafting their own learning. Despite the important roles that OLMs play in higher education to support the learning process and self-regulated learning (SRL) in particular, there are few studies systematically reviewing OLM technology in higher education, and investigating their potential to foster self-regulated learning. Therefore, we carried out a systematic review of a 30-year sample of OLM studies in higher education and identified 64 articles that study the use of OLMs in supporting SRL. Our findings show that OLMs have been mainly used to support learners' cognition and a bit less metacognition and motivation; however, emotional support has been rarely provided. The most supported ones are Appraisal and Performance phases; Preparation of learning is enhanced by OLMs not so often. Although learners can edit or negotiate with their learning model in advanced ways, a simple inspectable OLM is more preferred. Reliance on unobservable nodes is less favored in modeling techniques in OLMs because such methods are highly dependent on expert authoring, thereby time-intensive and costly. Comparison and color-coding are two most-used features in OLMs, where the comparison feature is often used for enhancing learners’ engagement and motivation.}
}
@article{PIJEIRADIAZ2019188,
title = {Sympathetic arousal commonalities and arousal contagion during collaborative learning: How attuned are triad members?},
journal = {Computers in Human Behavior},
volume = {92},
pages = {188-197},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218305442},
author = {Héctor J. Pijeira-Díaz and Hendrik Drachsler and Sanna Järvelä and Paul A. Kirschner},
keywords = {Collaborative learning, Interpersonal physiology, Sympathetic arousal, Arousal contagion, Biosensors, Electrodermal activity},
abstract = {This article explores the dynamics of collaborative learning in the classroom from the perspective of the commonalities and interdependence in the degree of physiological activation from the sympathetic nervous system (i.e., sympathetic arousal) of group members. Using Empatica E4 wristbands, electrodermal activity—to derive arousal—was measured in 24 high school students working in groups of three (i.e., triads) during two runs of an advanced physics course. The participants met three times a week over six weeks for lessons of 75 min each. Most of the time (≈60–95% of the lesson) the triad members were at different arousal levels, and, when they were on the same level, it was mainly the low arousal (or deactivated) level. Less than 4% of the time were the triad members simultaneously in high arousal. Possible within-triad arousal contagion cases (71.3%) occurred mostly on a one-to-one basis and with a latency from within a few seconds up to 10 min, but usually within 1 min. This study supports the view that only small parts of group work are collaborative, as far as the synchronicity and coordination which collaboration presupposes. Although exploratory, results also illustrate the affordances of physiological measures to characterize collaborative processes.}
}
@article{RAYHAN2022100077,
title = {Appraisal of high-stake examinations during SARS-CoV-2 emergency with responsible and transparent AI: Evidence of fair and detrimental assessment},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100077},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100077},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000327},
author = {MD. Rayhan and MD. Golam Rabiul Alam and M. Ali Akber Dewan and M. Helal Uddin Ahmed},
keywords = {Evaluation methodologies, Automated assessment, Covid-19 education response, Explainable AI, High-stakes examination, AI in Education},
abstract = {In situations like the coronavirus pandemic, colleges and universities are forced to limit their offline and regular academic activities. Extended postponement of high-stakes exams due to health risk hereby reduces productivity and progress in later years. Several countries decided to organize the exams online. Since many other countries with large education boards had an inadequate infrastructure and insufficient resources during the emergency, education policy experts considered a solution to simultaneously protect public health and fully resume high-stakes exams -by canceling offline exam and introducing a uniform assessment process to be followed across the states and education boards. This research proposes a novel system using an AI model to accomplish the complex task of evaluating all students across education boards with maximum level of fairness and analyzes the ability to fairly appraise exam grades in the context of high-stakes examinations during SARS-CoV-2 emergency. Basically, a logistic regression classifier on top of a deep neural network is used to output predictions that are as fair as possible for all learners. The predictions of the proposed grade-awarding system are explained by the SHAP (SHapley Additive exPlanations) framework. SHAP allowed to identify the features of the students' portfolios that contributed most to the predicted grades. In the setting of an empirical analysis in one of the largest education systems in the Global South, 81.85% of learners were assigned fair scores while 3.12% of the scores were significantly smaller than the actual grades, which would have had a detrimental effect if it had been applied for real. Furthermore, SHAP allows policy-makers to debug the predictive model by identifying and measuring the importance of the factors involved in the model's final decision and removing those features that should not play a role in the model's “reasoning” process.}
}