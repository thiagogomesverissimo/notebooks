@unpublished{20240071151 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {LEARNING ANALYTICS DASHBOARDS FOR ADVISORS - A SYSTEMATIC LITERATURE REVIEW},
journal = {arXiv},
author = {Vemula, Suchith Reddy and Moraes, Marcia},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning Analytics Dashboard for Advisors is designed to provide data-driven insights and visualizations to support advisors in their decision-making regarding student academic progress, engagement, targeted support, and overall success. This study explores the current state of the art in learning analytics dashboards, focusing on specific requirements for advisors. By examining existing literature and case studies, this research investigates the key features and functionalities essential for an effective learning analytics dashboard tailored to advisor needs. This study also aims to provide a comprehensive understanding of the landscape of learning analytics dashboards for advisors, offering insights into the advancements, opportunities, and challenges in their development by synthesizing the current trends from a total of 21 research papers used for analysis. The findings will contribute to the design and implementation of new features in learning analytics dashboards that empower advisors to provide proactive and individualized support, ultimately fostering student retention and academic success.<br/></div> © 2024, CC BY-NC-ND.},
key = {Decision making},
keywords = {Learning systems;},
note = {'current;Advisor dashboard;And learning management system;Data driven;Decisions makings;Learning analytic;Learning management system;Self-regulated learning;State of the art;Systematic literature review;},
URL = {http://dx.doi.org/10.48550/arXiv.2402.01671},
} 


@inproceedings{20243116794928 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {A Systematic Review on Student-Facing Learning Analytics Dashboards: Reference Frames and Indicators},
journal = {Proceedings - 2024 6th International Conference on Computer Science and Technologies in Education, CSTE 2024},
author = {Kew, Si Na and Koh, Elizabeth and Choo, Zi Luan and Jonathan, Christin Rekha},
year = {2024},
pages = {45 - 50},
address = {Hybrid, Xi'an, China},
abstract = {<div data-language="eng" data-ev-field="abstract">As the integration of technology in education undergoes continuous development, Learning Analytics Dashboards (LADs) have become vital tools for both instructors and learners, facilitating the monitoring and optimization of the learning experience. Student-facing LADs have been designed with various reference frames which enable various feedback, comparisons and reflection. However, there has been limited examination of the reference frames and their indicators employed in student-facing LADs as well as its evaluation. This research aims to address this gap by conducting a systematic literature review using PRISMA to synthesize existing literature to identify and offer insights on reference frames and key indicators used in student-facing LADs. We identified 42 articles and analyzed that social reference frames as compared to progress reference frames are commonly employed in LADs. Key indicators include class performance average, class performance mean, average performance of the class, etc. These insights contribute to the ongoing development and best practices of LAD design. The knowledge and findings can help educators, researchers, system designers and policymakers decide how best to incorporate these tools into educational settings.<br/></div> © 2024 IEEE.},
key = {Facings},
keywords = {Petroleum reservoir evaluation;Students;},
note = {Continuous development;Development Learning;Key indicator;Learning analytic dashboard;Performance;PRISMA;Reference frame;Systematic literature review;Systematic Review;Technology in educations;},
URL = {http://dx.doi.org/10.1109/CSTE62025.2024.00015},
} 


@article{20211910314414 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Staying on target: A systematic literature review on learner-facing learning analytics dashboards},
journal = {British Journal of Educational Technology},
author = {Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and Huggins-Manley, Anne Corinne},
volume = {52},
number = {4},
year = {2021},
pages = {1724 - 1748},
issn = {00071013},
abstract = {<div data-language="eng" data-ev-field="abstract">The advances in technology to capture and process unprecedented amounts of educational data has boosted the interest in Learning Analytics Dashboard (LAD) applications as a way to provide meaningful visual information to administrators, parents, teachers and learners. Despite the frequent argument that LADs are useful to support target users and their goals to monitor and act upon the information provided, little is known about LADs’ theoretical underpinnings and the alignment (or lack thereof) between LADs intended outcomes and the measures used to evaluate their implementation. However, this knowledge is necessary to illuminate more efficient approaches in the development and implementation of LAD tools. Guided by the self-regulated learning perspective and using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, this systematic literature review addressed this gap by examining whether and how learner-facing LAD’s target outcomes align with the domain measures used to evaluate their implementations. Out of the 1297 papers retrieved from 15 databases, 28 were included in the final quantitative and qualitative analysis. Results suggested an intriguing lack of alignment between LADs’ intended outcomes (mostly cognitive domain) and their evaluation (mostly affective measures). Based on these results and on the premise that LADs are designed to support learners, a critical recommendation from this study is that LADs’ target outcomes should guide the selection of measures used to evaluate the efficacy of these tools. This alignment is critical to enable the construction of more robust guidelines to inform future endeavours in the field. Practitioner notes What is already known about this topic There has been an increased interest and investment in learning analytics dashboards to support learners as end-users. Learner-facing learning analytics dashboards are designed with different purposes, functionalities and types of data in an attempt to influence learners’ behaviour, achievement and skills. What this paper adds This paper reports trends and opportunities regarding the design of learner-facing learning analytics dashboards, contexts of implementation, as well as types and features of learner-facing learning analytics dashboard studies. The paper discusses how affect and motivation have been largely overlooked as target outcomes in learner-facing learning analytics dashboards. Implications for practice and/or policy Based on the evidence gathered through the review, this paper makes recommendations for theory (eg, inclusion of motivation as an important target outcome). The paper makes recommendations related to the design, implementation and evaluation of learning analytics dashboards. The paper also highlights the need for further integration between learner-facing learning analytics dashboards and open learner models.<br/></div> © 2021 British Educational Research Association.},
key = {Facings},
keywords = {Learning systems;Alignment;Motivation;},
note = {Affective measures;Cognitive domain;Open learner models;Quantitative and qualitative analysis;Self-regulated learning;Systematic literature review;Systematic Review;Visual information;},
URL = {http://dx.doi.org/10.1111/bjet.13089},
} 


@inproceedings{20242216154251 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Adaptation in Learning Analytics Dashboards: A Systematic Review},
journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
author = {Barbe, Remi and Encelle, Benoit and Sehaba, Karim},
volume = {2},
year = {2024},
pages = {75 - 86},
issn = {21845026},
address = {Angers, France},
abstract = {<div data-language="eng" data-ev-field="abstract">Although learning analytics dashboards (LAD) grow in numbers, they often fail to improve learner awareness as they lack adaptation capabilities. This paper presents a systematic review following the PRISMA statement, about the adaptation capabilities of LADs based on new definitions for LADs and learning indicators. A detailed analysis of 23 articles selected among 426 articles retrieved from databases was conducted based on a coding scheme, centered on adaptation and its dimensions, namely: to whom, what, to what, who, and how. The main result of this study is that there is more evidence of adaptable LADs than adaptive LADs. As a result, the road to adaptivity is worth exploring. The analysis of LAD’s common features led us to distinguish mainly 4 adaptable capabilities and 2 adaptive ones. Most of the adaptable capabilities consist of giving exploration power to the user and providing him with data filtering, zooming, or selection functionalities. In contrast, users have limited options when it comes to selecting indicators, their visualizations, and organization on the dashboard. Providing more flexible LADs could enhance their usability and increase learner awareness. Furthermore, the few adaptive features involve adaptations based on "if-then" rules and there are no reports of advanced computing techniques such as machine learning that could empower LAD’s adaptation.<br/></div> Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
key = {E-learning},
note = {Adaptation;Adaptive features;Adaptivity;Coding scheme;Common features;Data filtering;Learning analytic dashboard;Learning indicator;Power;Systematic Review;},
URL = {http://dx.doi.org/10.5220/0012628600003693},
} 


@inproceedings{20241115753455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
journal = {ACM International Conference Proceeding Series},
author = {Kaliisa, Rogers and Misiejuk, Kamila and Lopez-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
year = {2024},
pages = {295 - 304},
address = {Kyoto, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students' learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.<br/></div> © 2024 Owner/Author.},
key = {Motivation},
keywords = {Computer aided instruction;Learning systems;Students;},
note = {Achievement motivations;Impact;Learning analytic dashboard;Learning outcome;Research studies;Student achievement;Student attitudes;Student learning outcomes;Student motivation;Systematic Review;},
URL = {http://dx.doi.org/10.1145/3636555.3636884},
} 


@unpublished{20240011636 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
journal = {arXiv},
author = {Kaliisa, Rogers and Misiejuk, Kamila and Lopez-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
year = {2023},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students’ learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.<br/>MSC Codes 97U50, 97D60<br/></div> © 2023, CC BY.},
key = {Motivation},
keywords = {Computer aided instruction;Learning systems;Students;},
note = {Achievement motivations;Impact;Learning analytic dashboard;Learning outcome;Research studies;Student achievement;Student attitudes;Student learning outcomes;Student motivation;Systematic Review;},
URL = {http://dx.doi.org/10.48550/arXiv.2312.15042},
} 


@inproceedings{20233914787838 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {The Promise of Physiological Data in Collaborative Learning: A Systematic Literature Review},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Febriantoro, Wicaksono and Gauthier, Andrea and Cukurova, Mutlu},
volume = {14200 LNCS},
year = {2023},
pages = {75 - 88},
issn = {03029743},
address = {Aveiro, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">Collaborative learning is an important approach in education. Researchers are increasingly interested in using physiological data, such as Electrodermal Activity (EDA), as an objective tool to measure bodily reactions during collaborative activities. However, it remains unclear how physiological data can contribute to our understanding, monitoring and support of the collaborative learning process. To address this gap, a Systematic Literature Review (SLR) was conducted, focusing on the contribution of physiological data to collaborative learning, the features of physiological data that correlate with effective outcomes, and interventions designed to support collaboration based on physiological data. The review identified 13 relevant publications that revealed physiological data can indeed be useful for detecting certain aspects of collaboration including students’ cognitive, behavioral, and affective (emotion and motivation) states. Physiological arousal in the form of EDA peaks and physiological synchrony (interdependence or associated activity between individuals’ physiological signals) were the most commonly used features. Surprisingly, only one publication presented a prototype of a learning analytics dashboard that used physiological data to guide student reflections. Furthermore, the review highlights the potential for integrating physiological measures with other data sources, such as speech, eye gaze, and facial expression, to uncover psychophysiological reactions and accompanying social and contextual processes related to collaborative learning. Future research should consider embedding methods for the physiological detection and modeling of learning constructs within explicit, feedback-driven interventions for collaborative learning.<br/></div> © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
key = {Learning systems},
keywords = {Psychophysiology;},
note = {Collaborative activities;Collaborative learning;Collaborative learning process;Data-source;Electrodermal activity;Eye-gaze;Physiological data;Physiological measures;Physiological signals;Systematic literature review;},
URL = {http://dx.doi.org/10.1007/978-3-031-42682-7_6},
} 


@inproceedings{20244017130865 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {A Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barthakur, Abhinava and Marrone, Rebecca and Esnaashari, Shadi and Kovanovic, Vitomir and Dawson, Shane},
volume = {15159 LNCS},
year = {2024},
pages = {49 - 63},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Within the education sector, there is growing recognition of the importance of diverse data sets in aiding strategic decisions and supporting personalized learning. To date, this call for increased and more nuanced data has been translated into institutional use of data dashboards or learning analytics dashboards. While these dashboards have been extensively developed and adopted in higher education, there is limited research investigating the use of dashboards in K-12 education. To address this gap, this study presents a systematic literature review examining dashboards as a decision-making system in K-12 settings. Our analysis indicates significant underuse of data in these dashboards, with a concerning scarcity of implementations and evaluations in real-world classroom environments. To counteract these shortcomings, we propose a set of recommendations designed to enhance dashboard development by promoting the use of Learner Profiles (LPs). These guidelines aim to support educational outcomes and student success by informing the design and deployment of fine-grained dashboards aligned with the specific needs of K-12 education. By highlighting the current gaps and offering forward-looking recommendations, our study clarifies the present landscape and serves as a foundation for future research, with significant implications for educators, policymakers, and scholars interested in using LPs to improve student learning outcomes.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Contrastive Learning},
keywords = {Adversarial machine learning;Decision making;Federated learning;Students;Teaching;},
note = {Dashboard;Decision-making systems;Decisions makings;Education sectors;K-12;K-12 education;Learner profiles;Systematic literature review;Systematic Review;Teaching and learning;},
URL = {http://dx.doi.org/10.1007/978-3-031-72315-5_4},
} 


@article{20171603588045 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Perceiving learning at a glance: A systematic literature review of learning dashboard research},
journal = {IEEE Transactions on Learning Technologies},
author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
volume = {10},
number = {1},
year = {2017},
pages = {30 - 41},
issn = {19391382},
abstract = {This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining. Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes. Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs). The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis. Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation. As the research field is still relatively young, most studies are exploratory and proof-of-concept. The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards. There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs.<br/> © 2008-2011 IEEE.},
key = {Data mining},
keywords = {Online systems;Data visualization;Information systems;},
note = {dashboards;Educational data mining;Information visualization;Learning analytics;Systematic Review;},
URL = {http://dx.doi.org/10.1109/TLT.2016.2599522},
} 


@article{20223612680726 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Use of Predictive Analytics within Learning Analytics Dashboards: A Review of Case Studies},
journal = {Technology, Knowledge and Learning},
author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha and Umer, Rahila},
volume = {28},
number = {3},
year = {2023},
pages = {959 - 980},
issn = {22111662},
abstract = {<div data-language="eng" data-ev-field="abstract">Learning analytics dashboards (LADs) provide educators and students with a comprehensive snapshot of the learning domain. Visualizations showcasing student learning behavioral patterns can help students gain greater self-awareness of their learning progression, and at the same time assist educators in identifying those students who may be facing learning difficulties. While LADs have gained popularity, existing LADs are still far behind when it comes to employing predictive analytics into their designs. Our systematic literature review has revealed limitations in the utilization of predictive analytics tools among existing LADs. We find that studies leveraging predictive analytics only go as far as identifying the at-risk students and do not employ model interpretation or explainability capabilities. This limits the ability of LADs to offer data-driven prescriptive advice to students that can offer them guidance on appropriate learning adjustments. Further, published studies have mostly described LADs that are still at prototype stages; hence, robust evaluations of how LADs affect student outcomes have not yet been conducted. The evaluations until now are limited to LAD functionalities and usability rather than their effectiveness as a pedagogical treatment. We conclude by making recommendations for the design of advanced dashboards that more fully take advantage of machine learning technologies, while using suitable visualizations to project only relevant information. Finally, we stress the importance of developing dashboards that are ultimately evaluated for their effectiveness.<br/></div> © 2022, The Author(s).},
key = {Predictive analytics},
keywords = {Learning systems;Students;Visualization;},
note = {Behavioral patterns;Case-studies;Early Warning System;Feedback systems;Learning analytic dashboard;Self awareness;Student feedback;Student feedback system;Student learning;Systematic Review;},
URL = {http://dx.doi.org/10.1007/s10758-022-09613-x},
} 


@inproceedings{20181705111639 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {License to evaluate: Preparing learning analytics dashboards for educational practice},
journal = {ACM International Conference Proceeding Series},
author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
year = {2018},
pages = {31 - 40},
address = {Sydney, NSW, Australia},
abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners.<br/> © 2018 Copyright held by the owner/author(s).},
key = {Data Analytics},
keywords = {Computer aided instruction;Learning systems;},
note = {Evaluation;Learning analytics;Learning dashboards;Learning science;Learning Theory;Social comparison;Systematic Review;},
URL = {http://dx.doi.org/10.1145/3170358.3170421},
} 


@inproceedings{20173804194987 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Awareness is not enough: Pitfalls of learning analytics dashboards in the educational practice},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus},
volume = {10474 LNCS},
year = {2017},
pages = {82 - 96},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {It has been long argued that learning analytics has the potential to act as a "middle space" between the learning sciences and data analytics, creating technical possibilities for exploring the vast amount of data generated in online learning environments. One common learning analytics intervention is the learning dashboard, a support tool for teachers and learners alike that allows them to gain insight into the learning process. Although several related works have scrutinised the state-of-the-art in the field of learning dashboards, none have addressed the theoretical foundation that should inform the design of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our critical examination reveals the most common educational concepts and the context in which they have been applied. We find evidence that current designs foster competition between learners rather than knowledge mastery, offering misguided frames of reference for comparison.<br/> © Springer International Publishing AG 2017.},
key = {Computer aided instruction},
keywords = {Learning systems;Teaching;},
note = {Learning analytics;Learning dashboards;Learning science;Learning Theory;Social comparison;Systematic Review;},
URL = {http://dx.doi.org/10.1007/978-3-319-66610-5_7},
} 


@inproceedings{20162702561761 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Understanding learning at a glance: An overview of learning dashboard studies},
journal = {ACM International Conference Proceeding Series},
author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
volume = {25-29-April-2016},
year = {2016},
pages = {532 - 533},
address = {Edinburgh, United kingdom},
abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the fnal analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dash-board design options.<br/> © 2016 Copyright held by the owner/author(s).},
key = {Data mining},
note = {Dashboards;Educational data mining;Information VI- sualization;Learning analytics;Systematic Review;},
URL = {http://dx.doi.org/10.1145/2883851.2883930},
} 


@inproceedings{20244017130864 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Investigating Learning Dashboards Adaptation},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barbe, Remi and Encelle, Benoit and Sehaba, Karim},
volume = {15159 LNCS},
year = {2024},
pages = {34 - 48},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Although there is a growing number of learning analytics dashboards (LADs), they often fail to improve learning and learners’ awareness due to their lack of adaptation capabilities. This paper presents a systematic review that follows the PRISMA statement and analyzes the adaptation features of LADs and their potential effects on learning. 24 of the 462 articles retrieved were scrutinized using an analysis framework centered on adaptation. The main finding is that there is more evidence of adaptable LADs than adaptive LADs, suggesting that adaptivity is worth exploring. The results mainly highlight 3 common LADs adaptable capabilities - most of which offer data exploration features - and 2 adaptive ones that change or refresh indicators on dashboards. Only a few articles investigate the adaptation of indicator visualizations or organization on dashboards. Currently, there is no work on the use of advanced computing techniques such as machine learning for LADs adaptation. Additionally, only 5 articles provide some evidence of dashboards adaptation features evaluation. As a result, a preliminary research agenda on LADs adaptation is suggested for enhancing LADs adoption and utility.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Adversarial machine learning},
keywords = {Contrastive Learning;Federated learning;},
note = {Adaptation;Adaptive learning;Adaptivity;Analysis frameworks;Computing techniques;Data exploration;Learning analytic dashboard;Learning indicator;Potential effects;Systematic Review;},
URL = {http://dx.doi.org/10.1007/978-3-031-72315-5_3},
} 


@inproceedings{20183805824475 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Tools to Support Self-Regulated Learning in Online Environments: Literature Review},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Perez-alvarez, Ronald and Maldonado-Mahauad, Jorge and Perez-Sanagustin, Mar},
volume = {11082 LNCS},
year = {2018},
pages = {16 - 30},
issn = {03029743},
address = {Leeds, United kingdom},
abstract = {Self-regulated learning (SRL) skills are especially important in Massive Open Online Courses (MOOCs), where teacher guidance is scarce, and learners must engage in their learning process trying to succeed and achieve their learning goals. However, developing SRL strategies is difficult for learners given the autonomy that is required in this kind of courses. In order to support learners on this process, researchers have proposed a variety of tools designed to support certain aspects of self-regulation in online learning environments. Nevertheless, there is a lack of study to understand what the commonalities and differences in terms of design are, what the results in terms of the effect on learners’ self-regulation are and which of them could be applied in MOOCs. Those are the questions that should be further explored. In this paper we present a systematic literature review where 22 tools designed to support SRL in online environments were analyzed. Our findings indicate that: (1) most of the studies do not evaluate the effect on learners’ SRL strategies; (2) the use of interactive visualizations has a positive effect on learners’ motivation; (3) the use of the social comparison component has a positive effect on engagement and time management; and (4) there is a lack of models to match learners’ activity with the tools with SRL strategies. Finally, we present the lessons learned for guiding the community in the implementation of tools to support SRL strategies in MOOCs.<br/> © 2018, Springer Nature Switzerland AG.},
key = {Computer aided instruction},
keywords = {Curricula;E-learning;Deregulation;Learning systems;Visualization;},
note = {Dashboard;Learning analytics;Literature reviews;Massive open online course;MOOC;Online;Self-regulated learning;System;},
URL = {http://dx.doi.org/10.1007/978-3-319-98572-5_2},
} 


@inproceedings{20232614327136 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {Proceedings of the 5th European Conference on Software Engineering Education, ECSEE 2023},
journal = {ACM International Conference Proceeding Series},
year = {2023},
address = {Seeon/Bavaria, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 32 papers. The topics discussed include: reflections on training next-gen industry workforce on secure software development; the gap between higher education and the software industry – a case study on technology differences; using automatic program assessment in a software development project course; using learning analytics to identify student learning profiles for software development courses; learning analytics dashboard for educators: proposed project to design with pedagogical background; towards learning style prediction based on personality; adaptive learning path sequencing based on learning styles within n-dimensional spaces; learning style classification by using Bayesian networks based on the index of learning style; systematic literature review for the use of AI based techniques in adaptive learning management systems; and flipped teaching in software engineering education: results of a long-term study.<br/></div>},
} 


@inproceedings{20193507381532 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {CEUR Workshop Proceedings},
journal = {CEUR Workshop Proceedings},
volume = {2415},
year = {2019},
issn = {16130073},
address = {Vigo, Spain},
abstract = {The proceedings contain 9 papers. The topics discussed include: application of learning analytics techniques on blended learning environments for university students; using Simva to evaluate serious games and collect game learning analytics data; extending a dashboard metamodel to account for users' characteristics and goals for enhancing personalization; predicting student performance over time. a case study for a blended-learning engineering course; analyzing students’ persistence using an event-based model; a data value chain to support the processing of multimodal evidence in authentic learning scenarios; and predictors and early warning systems in higher education a systematic literature review.<br/>},
} 


@inproceedings{20203209028818 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {7th International Conference on Learning and Collaboration Technologies, LCT 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {12205 LNCS},
year = {2020},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {The proceedings contain 86 papers. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Reflective Journaling: A Theoretical Model and Digital Prototype for Developing Resilience and Creativity; prototyping a Touch-Optimized Modeling Tool for Co-located and Inverted Classroom Group Modeling Scenarios; evaluating Portable Touch Projectors in the Context of Digital Education; STEAM-X: An Exploratory Study Adding Interactive Physical Activity to the STEAM Model; usability Testing of a Digital Competence Assessment and Certification System; designing ‘Embodied’ Science Learning Experiences for Young Children; impact of Constant Work on the Students’ Academic Performance; Learning Analytics and MOOCs; on the Design of a Teachers’ Dashboard: Requirements and Insights; evaluation of the Virtual Mobility Learning Hub; mudpoint: Evaluating Instructor Perception on a Continuous and Non-specific Feedback System; characterization of Learners from Their Learning Activities on a Smart Learning Platform; AI-Driven Assessment of Students: Current Uses and Research Trends; generating Dashboards Using Fine-Grained Components: A Case Study for a PhD Programme; learning Analytics and Spelling Acquisition in German – The Path to Individualization in Learning; Building Student Interactions Outside the Classroom: Utilizing a Web-Based Application in a University Flipped Learning Course for EFL Learners; the Impact of Corpus Linguistics on Language Teaching in Russia’s Educational Context: Systematic Literature Review; framework of Manga Application for Teaching Japanese Language; Individualized Differentiated Spelling with Blogs - Implementing and Individualizing (IDeRBlog ii): An Example of a Learning Analytics Platform for the Text-Based Acquisition of Spelling Skills of Students in German.<br/>},
} 


@inproceedings{20244017130860 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {15159 LNCS},
year = {2024},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.<br/></div>},
} 


@inproceedings{20244017138399 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {15160 LNCS},
year = {2024},
issn = {03029743},
address = {Krems, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.<br/></div>},
} 


@inproceedings{20181705111632 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {ACM International Conference Proceeding Series},
journal = {ACM International Conference Proceeding Series},
year = {2018},
address = {Sydney, NSW, Australia},
abstract = {The proceedings contain 60 papers. The topics discussed include: the half-life of MOOC knowledge: a randomized trial evaluating knowledge retention and retrieval practice in MOOCs; graph-based visual topic dependency models: supporting assessment design and delivery at scale; data-driven generation of rubric criteria from an educational programming environment; supporting teacher's intervention in students' virtual collaboration using a network based model; correlating affect and behavior in reasoning mind with state test achievement; license to evaluate: preparing learning analytics dashboards for educational practice; open learner models and learning analytics dashboards: a systematic review; multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in Flanders; a qualitative evaluation of a learning dashboard to support advisor-student dialogues; the classrooom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers; an application of participatory action research in advising-focused learning analytics; profiling students from their questions in a blended learning environment; recurrence quantification analysis as a method for studying text comprehension dynamics; towards a writing analytics framework for adult English language learners; epistemic network analysis of students' longer written assignments as formative/summative evaluation; and the influence of student's cognitive and motivational characteristics on student's use of a 4C/ID-based online learning environment and their learning gain.<br/>},
} 


@inproceedings{20203108999623 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2024 Elsevier Inc.},

title = {8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {12203 LNCS},
year = {2020},
issn = {03029743},
address = {Copenhagen, Denmark},
abstract = {The proceedings contain 50 papers. The special focus in this conference is on Distributed, Ambient and Pervasive Interactions. The topics include: Designing an Interactive Platform for Intangible Cultural Heritage Knowledge of Taoyuan Woodcarving Craft; circuit Game: A Craft-Based Electronic Building Practice; going Beyond Computer-Assisted Vocabulary Learning: Research Synthesis and Frameworks; Returning to Nature: VR Mediated States of Enhanced Wellness; visualization and Analysis for Supporting Teachers Using Clickstream Data and Eye Movement Data; visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students; applying Deep Learning in Creative Re-creation of Changsha Kiln Cultural Relics; rethinking User Interaction with Smart Environments—A Comparative Study of Four Interaction Modalities; Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard; smart Learning in the Community: Supporting Citizen Digital Skills and Literacies; tele Echo Tube for Historic House Tojo-Tei in Matsudo International Science Art Festival 2018; motivating Physical Exercise in the Elderly with Mixed Reality Experiences; computer Vision on Wheelchairs: Detecting Sleeping Behavior of People with Intellectual Disabilities; factors Influencing the Acceptance and Usage of Smart City Services: A Systematic Review and Meta-analysis; civic Crowdsensing Through Location-Aware Virtual Monsters; participatory Governance in Smart Cities: Future Scenarios and Opportunities; Adaptability and Attuning in Smart Cities: Exploring the HCI Grand Challenge of Learning and Creativity; investigating Users Attitudes and Perceptions Towards the Usage of Smart City Apps; accessibility in Pervasive Systems: An Exploratory Study; digitally Enhancing Society Through Structuralism: Virtualizing Collective Human Eyesight and Hearing Capabilities as a Case Study; foreword.<br/>},
} 



