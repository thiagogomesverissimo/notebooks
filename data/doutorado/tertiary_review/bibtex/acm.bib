@inproceedings{10.1145/3636555.3636884,
author = {Kaliisa, Rogers and Misiejuk, Kamila and L\'{o}pez-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636884},
doi = {10.1145/3636555.3636884},
abstract = {While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students’ learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {295–304},
numpages = {10},
keywords = {Learning analytics dashboards (LADs), impact, learning outcomes, systematic review},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3170358.3170421,
author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
title = {License to evaluate: preparing learning analytics dashboards for educational practice},
year = {2018},
isbn = {9781450364003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170358.3170421},
doi = {10.1145/3170358.3170421},
abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners.},
booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge},
pages = {31–40},
numpages = {10},
keywords = {competition, evaluation, learning analytics, learning dashboards, learning science, learning theory, social comparison, systematic review},
location = {Sydney, New South Wales, Australia},
series = {LAK '18}
}

@inproceedings{10.1145/2883851.2883930,
author = {Schwendimann, Beat A. and Rodr\'{\i}guez-Triana, Mar\'{\i}a Jes\'{u}s and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
title = {Understanding learning at a glance: an overview of learning dashboard studies},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883930},
doi = {10.1145/2883851.2883930},
abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the final analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dashboard design options.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {532–533},
numpages = {2},
keywords = {dashboards, educational data mining, information visualization, learning analytics, systematic review},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

