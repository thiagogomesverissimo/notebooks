@article{matcha2019,
    author = "Matcha, Wannisa and Uzir, Nora’ayu and Gašević, Dragan and Pardo, Abelardo",
    type = "Journal Article",
    title = "A Systematic Review of Empirical Studies on Learning Analytics Dashboards: A Self-Regulated Learning Perspective",
    journal = "IEEE Transactions on Learning Technologies",
    publisher = "Institute of Electrical and Electronics Engineers",
    number = "2",
    doi = "10.1109/tlt.2019.2916802",
    volume = "13",
    pages = "226--245",
    url = "https://doi.org/10.1109/tlt.2019.2916802",
    keywords = "Learning Analytics | Data-driven Education | Empirical research | Self-regulated learning | Metacognition | Remote Learning | Collaborative Learning | Learning sciences",
    year = "2019",
    issn = "1939-1382",
    da = "2019-05-14",
    c1 = "[School of Informatics, University of Edinburgh, Edinburgh, U.K.], [School of Informatics, University of Edinburgh, Edinburgh, U.K.], Faculty of Information Technology, Monash University, Clayton, Australia, School of Informatics, University of Edinburgh, Edinburgh, U.K, [Division of Information Technology, Engineering and Environment, University of South Australia, Adelaide, SA, Australia]",
    la = "en"
}

@article{valle2021,
    author = "Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and Huggins‐Manley, Anne",
    type = "Journal Article",
    title = "Staying on target: A systematic literature review on learner‐facing learning analytics dashboards",
    journal = "British Journal of Educational Technology",
    publisher = "Wiley",
    number = "4",
    doi = "10.1111/bjet.13089",
    volume = "52",
    pages = "1724--1748",
    url = "https://doi.org/10.1111/bjet.13089",
    keywords = "Dashboard | Learning Analytics | Data-driven Education | Educational Technology | Educational Data Mining | Student Satisfaction | Argument (complex analysis)",
    year = "2021",
    issn = "0007-1013",
    da = "2021-05-07",
    c1 = "School of Teaching and Learning, University of Florida, Gainesville, FL, USA, School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, FL, USA, School of Teaching and Learning, University of Florida, Gainesville, FL, USA, School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, FL, USA, School of Teaching and Learning, University of Florida, Gainesville, FL, USA, School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, FL, USA",
    la = "en"
}

@incollection{sahin2021,
    author = "Şahi̇n, Muhittin and Ifenthaler, Dirk",
    type = "Book Section",
    title = "Visualizations and Dashboards for Learning Analytics: A Systematic Literature Review",
    booktitle = "Advances in analytics for learning and teaching",
    publisher = "Springer International Publishing",
    doi = "10.1007/978-3-030-81222-5\_1",
    pages = "3--22",
    url = "https://doi.org/10.1007/978-3-030-81222-5\_1",
    keywords = "Dashboard | Scope (computer science) | Learning Analytics | Data-driven Education | Educational Data Mining | Cultural analytics",
    year = "2021",
    abstract = "The purpose of this chapter is to present a summary of the dashboard and visualization studies carried out within the scope of learning analytics. Learning analytics dashboards are customizable control panels displaying personalized learning analytics features which adapt to the learning process in real time. Seventy six studies were selected as the primary studies. These studies consist of journal articles and conference papers. Detailed information about the conferences and journals of these papers is presented. Categories were determined which consist of (1) keywords, (2) stakeholders (target group) and year, (3) study group (participants), (4) visualization techniques, (5) method, (6) data collection tools, (7) variables, and (8) theoretical background. The findings of the eight categories are presented and discussed.",
    issn = "2662-2122",
    da = "2021-01-01",
    c1 = "Ege University, University of Mannheim, Curtin University, University of Mannheim",
    la = "en"
}

@article{paulsen2024,
    author = "Paulsen, Lucas and Lindsay, Euan",
    type = "Journal Article",
    title = "Learning analytics dashboards are increasingly becoming about learning and not just analytics - A systematic review",
    journal = "Education and Information Technologies",
    publisher = "Springer Science+Business Media",
    doi = "10.1007/s10639-023-12401-4",
    url = "https://doi.org/10.1007/s10639-023-12401-4",
    keywords = "Affordance | Learning Analytics | Cultural analytics | Data-driven Education | Educational Technology | Educational Data Mining | Software analytics",
    year = "2024",
    abstract = "Abstract This systematic review explores the emerging themes in the design and implementation of student-facing learning analytics dashboards in higher education. Learning Analytics has long been criticised for focusing too much on the analytics, and not enough on the learning. The review is then guided by an interest in whether these dashboards are still primarily analytics-driven or if they have become pedagogically informed over time. By mapping the identified themes of technological maturity, informing frameworks, affordances, data sources, and analytical levels over publications per year, the review identifies an emerging trajectory towards student-focused dashboards. These dashboards are informed by theory-oriented frameworks, designed to incorporate affordances that supporting student learning, and realised through integration of more than just activity data from learning management systems – allowing the dashboards to better support students' learnings processes. Based on this emerging trajectory, the review provides a series of design recommendations for student-focused dashboards that are connected to learning sciences as well as analytics.",
    issn = "1360-2357",
    da = "2024-01-05",
    c1 = "Department of Communication \& Psychology, Aalborg University, Aalborg, Denmark, Department of Sustainability and Planning, Aalborg University, Aalborg, Denmark",
    la = "en"
}

@article{tretow-fish2023,
    author = "Tretow-Fish, Tobias and Khalid, Saifuddin",
    type = "Journal Article",
    title = "Methods for Evaluating Learning Analytics and Learning Analytics Dashboards in Adaptive Learning Platforms: A Systematic Review",
    journal = "The Electronic Journal of e-Learning",
    publisher = "Academic Conferences and Publishing International",
    number = "5",
    doi = "10.34190/ejel.21.5.3088",
    volume = "21",
    pages = "430--449",
    url = "https://doi.org/10.34190/ejel.21.5.3088",
    keywords = "Learning Analytics",
    year = "2023",
    abstract = "This research paper highlights and addresses the lack of a systematic review of the methods used to evaluate Learning Analytics (LA) and Learning Analytics Dashboards (LAD) of Adaptive Learning Platforms (ALPs) in the current literature. Addressing this gap, the authors built upon the work of Tretow-Fish and Khalid (2022) and analyzed 32 papers, which were grouped into six categories (C1-6) based on their themes. The categories include C1) the evaluation of LA and LAD design and framework, C2) the evaluation of user performance with LA and LAD, C3) the evaluation of adaptivity, C4) the evaluation of ALPs through perceived value, C5) the evaluation of Multimodal methods, and C6) the evaluation of the pedagogical implementation of ALP’s LA and LAD. The results include a tabular summary of the papers including the categories, evaluation unit(s), methods, variables and purpose. While there are numerous studies in categories C1-4 that focus on the design, development, and impact assessment of ALP's LA and LAD, there are only a few studies in categories C5 and C6. For the category of C5), very few studies applied any evaluation methods assessing the multimodal features of LA and LADs on ALPs. Especially for C6), evaluating the pedagogical implementation of ALP's LA and LAD, the three dimensions of signature pedagogy are used to assess the level of pedagogy evaluation. Findings showed that no studies focus on evaluating the deep or implicit structure of ALP's LA. All studies examine the structural surface dimension of learning activities and interactions between students, teachers, and ALP's LA and LAD, as examined in categories C2-C5. No studies were exclusively categorized as a C6 category, indicating that all studies evaluate ALP's LA and LAD on the surface structure dimension of signature pedagogy. This review highlights the lack of pedagogical methodology and theory in ALP's LA and LAD, which are recommended to be emphasized in future research and ALP development and implementation.",
    issn = "1479-4403",
    da = "2023-12-19",
    c1 = "Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark, Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark",
    la = "en"
}

@article{kaliisa2024,
    author = "Kaliisa, Rogers and Misiejuk, Kamila and López‐Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed",
    type = "Journal Article",
    title = "Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude",
    doi = "10.1145/3636555.3636884",
    url = "https://doi.org/10.1145/3636555.3636884",
    keywords = "Dashboard | Learning Analytics | Data-driven Education | Student Performance Prediction | Educational Technology | Student Engagement",
    year = "2024",
    abstract = "While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students' learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.",
    da = "2024-03-05",
    c1 = "Department of Education, University of Oslo, Norway, Center for Science of Learning \&amp; Technology, University of Bergen, Norway, School of Computing, University of Eastern Finland, Finland, Center for Science of Learning \&amp; Technology, University of Bergen, Norway, School of Computing, University of Eastern Finland, Finland",
    la = "en"
}

@article{schwendimann1,
    author = "Schwendimann, Beat and Rodríguez‐Triana, María and Vozniuk, Andrii and Prieto, Luis and Boroujeni, Mina and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre",
    type = "Journal Article",
    title = "Perceiving Learning at a Glance: A Systematic Literature Review of Learning Dashboard Research",
    journal = "IEEE Transactions on Learning Technologies",
    publisher = "Institute of Electrical and Electronics Engineers",
    number = "1",
    doi = "10.1109/tlt.2016.2599522",
    volume = "10",
    pages = "30--41",
    url = "https://doi.org/10.1109/tlt.2016.2599522",
    keywords = "Dashboard | Learning Analytics | Educational Data Mining | Data-driven Education | Learning Management | Online Learning | Educational Technology | Open research | Exploratory research | Learning sciences",
    year = "2016",
    issn = "1939-1382",
    da = "2016-08-11",
    c1 = "CHILI Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, REACT Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, REACT Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, CHILI Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, CHILI Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, REACT Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, REACT Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland, CHILI Lab, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland",
    la = "en"
}

@article{jivet2018,
    author = "Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik",
    type = "Journal Article",
    title = "License to evaluate",
    doi = "10.1145/3170358.3170421",
    url = "https://doi.org/10.1145/3170358.3170421",
    keywords = "Learning Analytics | Data-driven Education | Dashboard | Cultural analytics | Educational Data Mining | Blended Learning | Educational Technology | Bridge (graph theory) | Learning sciences",
    year = "2018",
    abstract = "Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners.",
    da = "2018-03-06",
    c1 = "Open University of the Netherlands, Heerlen, the Netherlands, Open University of the Netherlands, Heerlen, the Netherlands, Open University of the Netherlands, Heerlen, the Netherlands, Goethe University Frankfurt/DIPF, Germany and Open University of the Netherlands, Heerlen, the Netherlands",
    la = "en"
}

@incollection{jivet2017,
    author = "Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus",
    type = "Book Section",
    title = "Awareness Is Not Enough: Pitfalls of Learning Analytics Dashboards in the Educational Practice",
    booktitle = "Lecture notes in computer science",
    publisher = "Springer Science+Business Media",
    doi = "10.1007/978-3-319-66610-5\_7",
    pages = "82--96",
    url = "https://doi.org/10.1007/978-3-319-66610-5\_7",
    keywords = "Learning Analytics | Dashboard | Data-driven Education | Educational Technology | Blended Learning | Educational Data Mining | Cultural analytics | Learning sciences",
    year = "2017",
    abstract = {It has been long argued that learning analytics has the potential to act as a "middle space" between the learning sciences and data analytics, creating technical possibilities for exploring the vast amount of data generated in online learning environments. One common learning analytics intervention is the learning dashboard, a support tool for teachers and learners alike that allows them to gain insight into the learning process. Although several related works have scrutinised the state-of-the-art in the field of learning dashboards, none have addressed the theoretical foundation that should inform the design of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our critical examination reveals the most common educational concepts and the context in which they have been applied. We find evidence that current designs foster competition between learners rather than knowledge mastery, offering misguided frames of reference for comparison.},
    issn = "0302-9743",
    da = "2017-01-01",
    c1 = "Open Universiteit, Valkenburgerweg 177, 6419 AT, Heerlen, Netherlands, Open Universiteit, Valkenburgerweg 177, 6419 AT, Heerlen, Netherlands, Open Universiteit, Valkenburgerweg 177, 6419 AT, Heerlen, Netherlands, Open Universiteit, Valkenburgerweg 177, 6419 AT, Heerlen, Netherlands",
    la = "en"
}

@article{bodily2018,
    author = "Bodily, Robert and Kay, Judy and Aleven, Vincent and Jivet, Ioana and Davis, Dan and Xhakaj, Françeska and Verbert, Katrien",
    type = "Journal Article",
    title = "Open learner models and learning analytics dashboards",
    doi = "10.1145/3170358.3170409",
    url = "https://doi.org/10.1145/3170358.3170409",
    keywords = "Learning Analytics | Bridge (graph theory) | Student Modeling | Collaborative Learning | Online Learning | Data-driven Education",
    year = "2018",
    abstract = "This paper aims to link student facing Learning Analytics Dashboards (LADs) to the corpus of research on Open Learner Models (OLMs), as both have similar goals. We conducted a systematic review of literature on OLMs and compared the results with a previously conducted review of LADs for learners in terms of (i) data use and modelling, (ii) key publication venues, (iii) authors and articles, (iv) key themes, and (v) system evaluation. We highlight the similarities and differences between the research on LADs and OLMs. Our key contribution is a bridge between these two areas as a foundation for building upon the strengths of each. We report the following key results from the review: in reports of new OLMs, almost 60\% are based on a single type of data; 33\% use behavioral metrics; 39\% support input from the user; 37\% have complex models; and just 6\% involve multiple applications. Key associated themes include intelligent tutoring systems, learning analytics, and self-regulated learning. Notably, compared with LADs, OLM research is more likely to be interactive (81\% of papers compared with 31\% for LADs), report evaluations (76\% versus 59\%), use assessment data (100\% versus 37\%), provide a comparison standard for students (52\% versus 38\%), but less likely to use behavioral metrics, or resource use data (33\% against 75\% for LADs). In OLM work, there was a heightened focus on learner control and access to their own data.",
    da = "2018-03-06",
    c1 = "Brigham Young University, University of Sydney, Australia, Carnegie Mellon University, Open University of the Netherlands, the Netherlands, Delft University of Technology, the Netherlands, Carnegie Mellon University, University of Leuven, Belgium",
    la = "en"
}

@article{schwendimann2016,
    author = "Schwendimann, Beat and Rodríguez‐Triana, María and Vozniuk, Andrii and Prieto, Luis and Boroujeni, Mina and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre",
    type = "Journal Article",
    title = "Understanding learning at a glance",
    doi = "10.1145/2883851.2883930",
    pages = "532--533",
    url = "https://doi.org/10.1145/2883851.2883930",
    keywords = "Dashboard | Educational Data Mining | Learning Analytics | Data-driven Education | Online Learning | Collaborative Learning | Exploratory research | Open research",
    year = "2016",
    abstract = "Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the final analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dashboard design options.",
    da = "2016-01-01",
    c1 = "EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland, EPFL, Lausanne, Switzerland",
    la = "en"
}

@article{barbe2024,
    author = "Barbé, Rémi and Encelle, Benoît and Sehaba, Karim",
    type = "Journal Article",
    title = "Adaptation in Learning Analytics Dashboards: A Systematic Review",
    doi = "10.5220/0012628600003693",
    pages = "75--86",
    url = "https://doi.org/10.5220/0012628600003693",
    keywords = "Learning Analytics | Predictive Analysis | Data-driven Education | Educational Data Mining | Machine Learning",
    year = "2024",
    da = "2024-01-01",
    c1 = "Univ. Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ. Lyon 2, LIRIS, UMR5205, F-69622 Villeurbanne, France, --- Select a Country ---, Univ. Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ. Lyon 2, LIRIS, UMR5205, F-69622 Villeurbanne, France, --- Select a Country ---, Univ. Lyon, Univ. Lyon 2, CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, F-69676 Bron, France, --- Select a Country ---",
    la = "en"
}

@article{kaliisa1,
    author = "Kaliisa, Rogers and Jivet, Ioana and Prinsloo, Paul",
    type = "Journal Article",
    title = "A checklist to guide the planning, designing, implementation, and evaluation of learning analytics dashboards",
    journal = "International Journal of Educational Technology in Higher Education",
    publisher = "Springer Nature",
    number = "1",
    doi = "10.1186/s41239-023-00394-6",
    volume = "20",
    url = "https://doi.org/10.1186/s41239-023-00394-6",
    keywords = "Learning Analytics | Data-driven Education | Exploratory research | Educational Data Mining | Educational Technology | Design science",
    year = "2023",
    abstract = "Abstract Higher education institutions are moving to design and implement teacher-facing learning analytics (LA) dashboards with the hope that instructors can extract deep insights about student learning and make informed decisions to improve their teaching. While much attention has been paid to developing teacher-facing dashboards, less is known about how they are designed, implemented and evaluated. This paper presents a systematic literature review of existing studies reporting on teacher-facing LA dashboards. Out of the 1968 articles retrieved from several databases, 50 articles were included in the final analysis. Guided by several frameworks, articles were coded based on the following dimensions: purpose, theoretical grounding, stakeholder involvement, ethics and privacy, design, implementation, and evaluation criteria. The findings show that most dashboards are designed to increase teachers’ awareness but with limited actionable insights to allow intervention. Moreover, while teachers are involved in the design process, this is mainly at the exploratory/problem definition stage, with little input beyond this stage. Most dashboards were prescriptive, less customisable, and implicit about the theoretical constructs behind their designs. In addition, dashboards are deployed at prototype and pilot stages, and the evaluation is dominated by self-reports and users’ reactions with limited focus on changes to teaching and learning. Besides, only one study considered privacy as a design requirement. Based on the findings of the study and synthesis of existing literature, we propose a four-dimensional checklist for planning, designing, implementing and evaluating LA dashboards.",
    issn = "2365-9440",
    da = "2023-05-02",
    c1 = "Department of Education, The University of Oslo, Blindern 0317, P.O. Box 1092, Oslo, Norway, DIPF \& Goethe University Frankfurt, Frankfurt, Germany, Department of Business Management, University of South Africa, Pretoria, South Africa",
    la = "en"
}

@article{ramaswami2022,
    author = "Ramaswami, Gomathy and Sušnjak, Teo and Mathrani, Anuradha and Umer, Rahila",
    type = "Journal Article",
    title = "Use of Predictive Analytics within Learning Analytics Dashboards: A Review of Case Studies",
    journal = "Technology Knowledge and Learning",
    publisher = "Springer Science+Business Media",
    number = "3",
    doi = "10.1007/s10758-022-09613-x",
    volume = "28",
    pages = "959--980",
    url = "https://doi.org/10.1007/s10758-022-09613-x",
    keywords = "Popularity | Learning Analytics | Predictive analytics | Predictive Analysis | Data-driven Education | Student Performance Prediction | Meta-Learning",
    year = "2022",
    abstract = "Abstract Learning analytics dashboards (LADs) provide educators and students with a comprehensive snapshot of the learning domain. Visualizations showcasing student learning behavioral patterns can help students gain greater self-awareness of their learning progression, and at the same time assist educators in identifying those students who may be facing learning difficulties. While LADs have gained popularity, existing LADs are still far behind when it comes to employing predictive analytics into their designs. Our systematic literature review has revealed limitations in the utilization of predictive analytics tools among existing LADs. We find that studies leveraging predictive analytics only go as far as identifying the at-risk students and do not employ model interpretation or explainability capabilities. This limits the ability of LADs to offer data-driven prescriptive advice to students that can offer them guidance on appropriate learning adjustments. Further, published studies have mostly described LADs that are still at prototype stages; hence, robust evaluations of how LADs affect student outcomes have not yet been conducted. The evaluations until now are limited to LAD functionalities and usability rather than their effectiveness as a pedagogical treatment. We conclude by making recommendations for the design of advanced dashboards that more fully take advantage of machine learning technologies, while using suitable visualizations to project only relevant information. Finally, we stress the importance of developing dashboards that are ultimately evaluated for their effectiveness.",
    issn = "2211-1662",
    da = "2022-08-26",
    c1 = "School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand, School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand, School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand, Engineering and Management Sciences, Balochistan University of Information Technology, Quetta, Pakistan",
    la = "en"
}

@article{kew2024,
    author = "Kew, Si and Koh, Elizabeth and Choo, Zi and Jonathan, Christin",
    type = "Journal Article",
    title = "A Systematic Review on Student-Facing Learning Analytics Dashboards: Reference Frames and Indicators",
    doi = "10.1109/cste62025.2024.00015",
    url = "https://doi.org/10.1109/cste62025.2024.00015",
    keywords = "Learning Analytics | Student Performance Prediction | Educational Data Mining | Data-driven Education | Predictive Analysis",
    year = "2024",
    da = "2024-04-19",
    c1 = "Universiti Teknologi Malaysia,Faculty of Social Sciences and Humanities,Malaysia, National Institute of Education, Nanyang Technological University,Singapore, Universiti Teknologi Malaysia,Faculty of Social Sciences and Humanities,Malaysia, National Institute of Education, Nanyang Technological University,Singapore",
    la = "en"
}

@article{kaliisa2023,
    author = "Kaliisa, Rogers and Misiejuk, Kamila and López‐Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed",
    type = "Journal Article",
    title = "Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude",
    journal = "arXiv (Cornell University)",
    publisher = "Cornell University",
    doi = "10.48550/arxiv.2312.15042",
    url = "https://doi.org/10.48550/arxiv.2312.15042",
    keywords = "Dashboard | Learning Analytics | Data-driven Education | Student Performance Prediction | Student Satisfaction | Student Engagement",
    year = "2023",
    abstract = "While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike.",
    da = "2023-01-01",
    la = "en"
}

@incollection{liu2021,
    author = "Liu, Min and Han, Songhee and Shao, Peixia and Cai, Ying and Pan, Zilong",
    type = "Book Section",
    title = "The Current Landscape of Research and Practice on Visualizations and Dashboards for Learning Analytics",
    booktitle = "Advances in analytics for learning and teaching",
    publisher = "Springer International Publishing",
    doi = "10.1007/978-3-030-81222-5\_2",
    pages = "23--46",
    url = "https://doi.org/10.1007/978-3-030-81222-5\_2",
    keywords = "Dashboard | Learning Analytics | Information Visualization | Visual Analytics | Interactive Visualization | Graph Visualization",
    year = "2021",
    abstract = "While the research on learning analytics (LA) has increased rapidly in recent years, many inquiries remain insufficiently answered including how to effectively visualize data to better promote teaching and learning. First, this chapter provides a systematic literature review on the current research and practice of using visualizations as an analytic technique in LA research and explores the practice of dashboard designs as a means to communicate the research findings to stakeholders. The findings of this review show researchers use visualization or dashboard as a research methodology for analytical purposes and to enlighten their inquiry processes in research, while instructors and learners use it as a means of communication tools to inform about their educational practices. This chapter also describes a case study that uses visualization as a research tool to analyze data and communicate research findings and provides examples of designing a dashboard for teachers to support their teaching. This case illustrates an example of how visualizations and a dashboard are used in research and practice in support of the review conducted.",
    issn = "2662-2122",
    da = "2021-01-01",
    c1 = "The University of Texas at Austin, Austin, USA, The University of Texas at Austin, Austin, USA, The University of Texas at Austin, Austin, USA, The University of Texas at Austin, Austin, USA, The University of Texas at Austin, Austin, USA",
    la = "en"
}

@article{ley2023,
    author = "Ley, Tobias and Tammets, Kairit and Pishtari, Gerti and Chejara, Pankaj and Kasepalu, Reet and Khalil, Mohammad and Saar, Merike and Tuvi, Iiris and Väljataga, Terje and Wasson, Barbara",
    type = "Journal Article",
    title = "Towards a partnership of teachers and intelligent learning technology: A systematic literature review of model‐based learning analytics",
    journal = "Journal of Computer Assisted Learning",
    publisher = "Wiley",
    number = "5",
    doi = "10.1111/jcal.12844",
    volume = "39",
    pages = "1397--1417",
    url = "https://doi.org/10.1111/jcal.12844",
    keywords = "Learning Analytics | Intelligent Tutoring Systems | Educational Technology | Data-driven Education | Educational Data Mining",
    year = "2023",
    abstract = "Abstract Background With increased use of artificial intelligence in the classroom, there is now a need to better understand the complementarity of intelligent learning technology and teachers to produce effective instruction. Objective The paper reviews the current research on intelligent learning technology designed to make models of student learning and instruction transparent to teachers, an area we call model‐based learning analytics. We intended to gain an insight into the coupling between the knowledge models that underpin the intelligent system and the knowledge used by teachers in their classroom decision making. Methods Using a systematic literature review methodology, we first identified 42 papers, mainly from the domain of intelligent tutoring systems and learning analytics dashboards that conformed to our selection criteria. We then qualitatively analysed the context in which the systems were applied, models they used and benefits reported for teachers and learners. Results and Conclusions A majority of papers used either domain or learner models, suggesting that instructional decisions are mostly left to teachers. Compared to previous reviews, our set of papers appeared to have a stronger focus on providing teachers with theory‐driven insights and instructional decisions. This suggests that model‐based learning analytics can address some of the shortcomings of the field, like meaningfulness and actionability of learning analytics tools. However, impact in the classroom still needs further research, as in half of the cases the reported benefits were not backed with evidence. Future research should focus on the dynamic interaction between teachers and technology and how learning analytics has an impact on learning and decision making by teachers and students. We offer a taxonomy of knowledge models that can serve as a starting point for designing such interaction.",
    issn = "0266-4909",
    da = "2023-06-29",
    c1 = "Center for Digitalization in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, Austria, Center for Educational Technology, Tallinn University, Tallinn, Estonia, Center for Educational Technology, Tallinn University, Tallinn, Estonia, Center for Digitalization in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, Austria, Center for Educational Technology, Tallinn University, Tallinn, Estonia, Center for Educational Technology, Tallinn University, Tallinn, Estonia, Centre for the Science of Learning \&amp; Technology (SLATE) University of Bergen Bergen Norway, Center for Educational Technology, Tallinn University, Tallinn, Estonia, Institute of Psychology, University of Tartu, Tartu, Estonia, Center for Educational Technology, Tallinn University, Tallinn, Estonia, Centre for the Science of Learning \&amp; Technology (SLATE) University of Bergen Bergen Norway",
    la = "en"
}

@article{masiello2024,
    author = "Masiello, Italo and Mohseni, Zeynab and Palma, Francis and Nordmark, Susanna and Augustsson, Hanna and Rundquist, Rebecka",
    type = "Journal Article",
    title = "A Current Overview of the Use of Learning Analytics Dashboards",
    journal = "Education Sciences",
    publisher = "Multidisciplinary Digital Publishing Institute",
    number = "1",
    doi = "10.3390/educsci14010082",
    volume = "14",
    pages = "82--82",
    url = "https://doi.org/10.3390/educsci14010082",
    keywords = "Learning Analytics | Data-driven Education | Educational Technology | Educational Data Mining | Blended Learning | Value (mathematics) | Cultural analytics | Data analysis",
    year = "2024",
    abstract = "The promise of Learning Analytics Dashboards in education is to collect, analyze, and visualize data with the ultimate ambition of improving students’ learning. Our overview of the latest systematic reviews on the topic shows a number of research trends: learning analytics research is growing rapidly; it brings to the front inequality and inclusiveness measures; it reveals an unclear path to data ownership and privacy; it provides predictions which are not clearly translated into pedagogical actions; and the possibility of self-regulated learning and game-based learning are not capitalized upon. However, as learning analytics research progresses, greater opportunities lie ahead, and a better integration between information science and learning sciences can bring added value of learning analytics dashboards in education.",
    issn = "2227-7102",
    da = "2024-01-11",
    c1 = "Department of Computer Science and Media Technology, Linnaeus University, 352 52 Växjö, Sweden, Department of Computer Science and Media Technology, Linnaeus University, 352 52 Växjö, Sweden, Faculty of Computer Science, University of New Brunswick, Fredericton, NB E3B 5A3, Canada, Department of Computer Science and Media Technology, Linnaeus University, 352 52 Växjö, Sweden, Department of Learning, Informatics, Management and Ethics, Karolinska Institutet, 171 77 Solna, Sweden, Department of Pedagogy and Learning, Linnaeus University, 352 52 Växjö, Sweden",
    la = "en"
}

@article{scheneider2020,
    author = "Scheneider, Thais and Lemos, Robson",
    type = "Journal Article",
    title = "Use of Learning Analytics Interactive Dashboards in Serious Games",
    journal = "Deleted Journal",
    number = "3",
    doi = "10.31686/ijier.vol8.iss3.2220",
    volume = "8",
    pages = "150--174",
    url = "https://doi.org/10.31686/ijier.vol8.iss3.2220",
    keywords = "Learning Analytics | Cultural analytics | Data-driven Education | Educational Games | Game-Based Learning | Educational Data Mining",
    year = "2020",
    abstract = "The learning analytics in serious games, corresponds to a subject in increasing demand in the educational field. In this context, there is a need to study how data visualizations found in the literature are adopted in learning analytics in serious games. This paper presents a Systematic Literature Review (SLR) on how the evolution of studies associated with the use of learning analytics interactive dashboards in serious games is processed, seeking to investigate the characteristics of using dashboards for viewing educational data. A bibliometric analysis was carried out in which 75 relevant studies were selected from the Scopus, Web of Science, and IEEExplore databases. From the data analysis, it was observed that in the current literature there is a reduced number of studies containing the main actors in the learning process, as follows: teachers/instructors, students/participants, game developers/designers, and managers/researchers. In the vast majority of investigated studies, data visualization algorithms are used, where the main focus takes into account only actors, such as teachers/instructors and students/participants.",
    da = "2020-03-01",
    c1 = "Federal University of Santa Catarina (UFSC), Federal University of Santa Catarina",
    la = "en"
}

@article{hooshyar2023,
    author = "Hooshyar, Danial and Tammets, Kairit and Ley, Tobias and Aus, Kati and Kollom, Kaire",
    type = "Journal Article",
    title = "Learning Analytics in Supporting Student Agency: A Systematic Review",
    journal = "Sustainability",
    publisher = "Multidisciplinary Digital Publishing Institute",
    number = "18",
    doi = "10.3390/su151813662",
    volume = "15",
    pages = "13662--13662",
    url = "https://doi.org/10.3390/su151813662",
    keywords = "Learning Analytics | Student Performance Prediction | Student Engagement | Data-driven Education | Online Learning",
    year = "2023",
    abstract = "Student agency, or agency for learning, refers to an individual’s ability to act and cause changes during the learning process. Recently, learning analytics (LA) has demonstrated its potential in promoting agency, as it enables students to take an active role in their learning process and supports the development of their self-regulatory skills. Despite the growing interest and potential for supporting student agency, there have yet to be any studies reviewing the extant works dealing with the use of LA in supporting student agency. We systematically reviewed the existing related works in eight major international databases and identified 15 articles. Analysis of these articles revealed that most of the studies aimed to investigate student or educators’ agency experiences, propose design principles for LA, and to a lesser extent, develop LA methods/dashboards to support agency. Of those studies developing LA, none initially explored student agency experiences and then utilized their findings to develop evidence-based LA methods and dashboards for supporting student agency. Moreover, we found that the included articles largely rely on descriptive and diagnostic analytics, paying less attention to predictive analytics and completely overlooking the potential of prescriptive learning analytics in supporting agency. Our findings also shed light on nine key design elements for effective LA support of student agency, including customization, decision-making support, consideration of transparency and privacy, and facilitation of co-design. Surprisingly, we found that no studies have considered the use of LA to support student agency in K–12 education, while higher education has been the focal point of the LA community. Finally, we highlighted the fields of study and data visualization types that the studies mostly targeted and, more importantly, identified eight crucial challenges facing LA in its support of student agency.",
    issn = "2071-1050",
    da = "2023-09-13",
    c1 = "Centre for Educational Technology, Tallinn University, 10120 Tallinn, Estonia;, Centre for Educational Technology, Tallinn University, 10120 Tallinn, Estonia;, Center for Digitalisation in Lifelong Learning, University for Continuing Education Krems, 3500 Krems an der Donau, Austria;, School of Educational Sciences, Tallinn University, 10120 Tallinn, Estonia;, Centre for Educational Technology, Tallinn University, 10120 Tallinn, Estonia;",
    la = "en"
}

@incollection{chaudy2018,
    author = "Chaudy, Yaëlle and Connolly, Thomas",
    type = "Book Section",
    title = "Integrating Assessment, Feedback, and Learning Analytics in Educational Games",
    booktitle = "Advances in higher education and professional development book series",
    publisher = "IGI Global",
    doi = "10.4018/978-1-5225-5936-8.ch006",
    pages = "127--169",
    url = "https://doi.org/10.4018/978-1-5225-5936-8.ch006",
    keywords = "Dashboard | Educational game | Educational Games | Learning Analytics | Game-Based Learning | Educational Data Mining | Intelligent Tutoring Systems | Game engine",
    year = "2018",
    issn = "2327-6983",
    da = "2018-08-16",
    c1 = "University of the West of Scotland, UK, DS Partnership, UK",
    la = "en"
}

@article{gauthier2022,
    author = "Gauthier, A. and Rizvi, Saman and Cukurova, Mutlu and Mavrikis, Manolis",
    type = "Journal Article",
    title = "Is it time we get real? A systematic review of the potential of data-driven technologies to address teachers' implicit biases",
    journal = "Frontiers in Artificial Intelligence",
    publisher = "Frontiers Media",
    doi = "10.3389/frai.2022.994967",
    volume = "5",
    url = "https://doi.org/10.3389/frai.2022.994967",
    keywords = "Data-driven Education | Educational Data Mining | Learning Analytics | Virtual Teaching | E-Learning | Emerging technologies",
    year = "2022",
    abstract = "Data-driven technologies for education, such as artificial intelligence in education (AIEd) systems, learning analytics dashboards, open learner models, and other applications, are often created with an aspiration to help teachers make better, evidence-informed decisions in the classroom. Addressing gender, racial, and other biases inherent to data and algorithms in such applications is seen as a way to increase the responsibility of these systems and has been the focus of much of the research in the field, including systematic reviews. However, implicit biases can also be held by teachers. To the best of our knowledge, this systematic literature review is the first of its kind to investigate what kinds of teacher biases have been impacted by data-driven technologies, how or if these technologies were designed to challenge these biases, and which strategies were most effective at promoting equitable teaching behaviors and decision making. Following PRISMA guidelines, a search of five databases returned n = 359 records of which only n = 2 studies by a single research team were identified as relevant. The findings show that there is minimal evidence that data-driven technologies have been evaluated in their capacity for supporting teachers to make less biased decisions or promote equitable teaching behaviors, even though this capacity is often used as one of the core arguments for the use of data-driven technologies in education. By examining these two studies in conjunction with related studies that did not meet the eligibility criteria during the full-text review, we reveal the approaches that could play an effective role in mitigating teachers' biases, as well as ones that may perpetuate biases. We conclude by summarizing directions for future research that should seek to directly confront teachers' biases through explicit design strategies within teacher tools, to ensure that the impact of biases of both technology (including data, algorithms, models etc.) and teachers are minimized. We propose an extended framework to support future research and design in this area, through motivational, cognitive, and technological debiasing strategies.",
    issn = "2624-8212",
    da = "2022-10-11",
    c1 = "UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom, UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom, UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom, UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom",
    la = "en"
}

@article{ifenthaler2022,
    author = "Ifenthaler, Dirk and Yau, Jane",
    type = "Journal Article",
    title = "Analytics for Supporting Teaching Success in Higher Education: A Systematic Review",
    journal = "2022 IEEE Global Engineering Education Conference (EDUCON)",
    doi = "10.1109/educon52537.2022.9766734",
    volume = "57",
    pages = "1721--1727",
    url = "https://doi.org/10.1109/educon52537.2022.9766734",
    keywords = "Learning Analytics | Student Performance Prediction | Data-driven Education | Educational Technology | Educational Data Mining",
    year = "2022",
    da = "2022-03-28",
    c1 = "Learning, Design and Technology, University of Mannheim, Curtin University, Mannheim, DIPF Leibniz Institute for Research and Information in Education, University of Mannheim, Mannheim, Germany",
    la = "en"
}

@incollection{febriantoro2023,
    author = "Febriantoro, Wicaksono and Gauthier, A. and Cukurova, Mutlu",
    type = "Book Section",
    title = "The Promise of Physiological Data in Collaborative Learning: A Systematic Literature Review",
    booktitle = "Lecture notes in computer science",
    publisher = "Springer Science+Business Media",
    doi = "10.1007/978-3-031-42682-7\_6",
    pages = "75--88",
    url = "https://doi.org/10.1007/978-3-031-42682-7\_6",
    keywords = "Dashboard | Collaborative Learning | Data-driven Education | Cooperative Learning | Educational Data Mining | Educational Technology",
    year = "2023",
    issn = "0302-9743",
    da = "2023-01-01",
    c1 = "UCL Knowledge Lab, Institute of Education, University College London (UCL), London, UK, UCL Knowledge Lab, Institute of Education, University College London (UCL), London, UK, UCL Knowledge Lab, Institute of Education, University College London (UCL), London, UK",
    la = "en"
}

@article{pishtari2023,
    author = "Pishtari, Gerti and Ley, Tobias and Khalil, Mohammad and Kasepalu, Reet and Tuvi, Iiris",
    type = "Journal Article",
    title = "Model-Based Learning Analytics for a Partnership of Teachers and Intelligent Systems: A Bibliometric Systematic Review",
    journal = "Education Sciences",
    publisher = "Multidisciplinary Digital Publishing Institute",
    number = "5",
    doi = "10.3390/educsci13050498",
    volume = "13",
    pages = "498--498",
    url = "https://doi.org/10.3390/educsci13050498",
    keywords = "Learning Analytics | Collaborative Learning | Intelligent Tutoring Systems | Orchestration | Educational Data Mining | Student Modeling | Learning sciences",
    year = "2023",
    abstract = "This paper presents a bibliometric systematic review on model-based learning analytics (MbLA), which enable coupling between teachers and intelligent systems to support the learning process. This is achieved through systems that make their models of student learning and instruction transparent to teachers. We use bibliometric network analysis and topic modelling to explore the synergies between the related research groups and the main research topics considered in the 42 reviewed papers. Network analysis depicts an early stage community, made up of several research groups, mainly from the fields of learning analytics and intelligent tutoring systems, which have had little explicit and implicit collaboration but do share a common core literature. Th resulting topics from the topic modelling can be grouped into the ones related to teacher practices, such as awareness and reflection, learning orchestration, or assessment frameworks, and the ones related to the technology used to open up the models to teachers, such as dashboards or adaptive learning architectures. Moreover, results show that research in MbLA has taken an individualistic approach to student learning and instruction, neglecting social aspects and elements of collaborative learning. To advance research in MbLA, future research should focus on hybrid teacher–AI approaches that foster the partnership between teachers and technology to support the learning process, involve teachers in the development cycle from an early stage, and follow an interdisciplinary approach.",
    issn = "2227-7102",
    da = "2023-05-15",
    c1 = "Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems (Danube University Krems), 3500 Krems an der Donau, Austria, Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems (Danube University Krems), 3500 Krems an der Donau, Austria, School of Educational Sciences, Tallinn University, 10120 Tallinn, Estonia, Centre for the Science of Learning \& Technology (SLATE), Faculty of Psychology, University of Bergen, 5007 Bergen, Norway, School of Educational Sciences, Tallinn University, 10120 Tallinn, Estonia, Faculty of Information Technology and Communication Sciences, Tampere University, 33100 Tampere, Finland",
    la = "en"
}

@article{yau2018,
    author = "Yau, Jane and Mah, Dana-Kristin and Ifenthaler, Dirk",
    type = "Journal Article",
    title = "Utilising learning analytics for study success: A systematic review of five years of research (2013-17)",
    keywords = "Learning Analytics | Data-driven Education | Student Performance Prediction | Educational Data Mining | Predictive Analysis | Empirical research | Empirical evidence",
    year = "2018",
    da = "2018-01-01",
    la = "en"
}

@incollection{chaudy2021,
    author = "Chaudy, Yaëlle and Connolly, Thomas",
    type = "Book Section",
    title = "Integrating Assessment, Feedback, and Learning Analytics in Educational Games",
    booktitle = "IGI Global eBooks",
    publisher = "IGI Global",
    doi = "10.4018/978-1-6684-3710-0.ch088",
    pages = "1803--1846",
    url = "https://doi.org/10.4018/978-1-6684-3710-0.ch088",
    keywords = "Dashboard | Educational game | Educational Games | Learning Analytics | Game-Based Learning | Educational Data Mining | Intelligent Tutoring Systems | Game engine",
    year = "2021",
    da = "2021-11-26",
    c1 = "University of the West of Scotland, UK, University of the West of Scotland, UK",
    la = "en"
}

@article{munim2023,
    author = "Munim, Ziaul and Kim, Taeeun",
    type = "Journal Article",
    title = "A Review of Learning Analytics Dashboard and a Novel Application in Maritime Simulator Training",
    journal = "AHFE international",
    doi = "10.54941/ahfe1003158",
    url = "https://doi.org/10.54941/ahfe1003158",
    keywords = "Dashboard | Learning analytics | Predictive Analytics | Analytics | Performance indicator",
    year = "2023",
    abstract = "Developing a Learning Analytics Dashboard (LAD) to evaluate maritime simulation training performance based on key performance indicators (KPIs) of maritime navigational competence can improve learning efficiency and effectiveness. Relevant data needs to be fed from simulation training logs and other sources, analysed using appropriate visualization and artificial intelligence approaches, and reported in a single window with valuable insights for trainees and instructors. This study provides a Systematic Literature Review (SLR) of published literature on LADs using scientometric tools and techniques. The findings reveal six research clusters and publication trends in LAD research. An example of a novel application of Automated Machine Learning (AutoML) analysing data from maritime desktop simulator training is presented for future maritime LAD development.",
    issn = "2771-0718",
    da = "2023-01-01",
    c1 = "Faculty of Technology, Natural, and Maritime Sciences, University of South-Eastern Norway, Campus Vestfold, 3184 Horten, Norway, Department of Technology and Safety, University of Tromsø (UiT)-The Arctic University of Norway, 9019, Tromsø, Norway",
    la = "en"
}

@incollection{tepgec2024,
    author = "Tepgeç, Mustafa and Ifenthaler, Dirk",
    type = "Book Section",
    title = "From Data to Outcomes: Experimental Learning Analytics Insights",
    booktitle = "Cognition and exploratory learning in the digital age",
    publisher = "Springer International Publishing",
    doi = "10.1007/978-3-031-54207-7\_2",
    pages = "19--37",
    url = "https://doi.org/10.1007/978-3-031-54207-7\_2",
    keywords = "Learning Analytics | Data-driven Education | Educational Data Mining | Adaptive Learning Environments | Predictive Analysis | Data analysis",
    year = "2024",
    issn = "2662-5628",
    da = "2024-01-01",
    c1 = "University of Mannheim, Mannheim, Germany, University of Mannheim, Mannheim, Germany",
    la = "en"
}

@article{gonzalez2024,
    author = "Gonzalez, N. and Laverde, Andrés",
    type = "Journal Article",
    title = "Learning analytics and personalization of learning: a review",
    journal = "Ensaio Avaliação e Políticas Públicas em Educação",
    publisher = "Cesgranrio Foundation",
    number = "122",
    doi = "10.1590/s0104-40362024003204234",
    volume = "32",
    url = "https://doi.org/10.1590/s0104-40362024003204234",
    keywords = "Learning Analytics | Data-driven Education | Educational Technology | Educational Data Mining | Online Learning",
    year = "2024",
    abstract = "Abstract Education in the 21 st century is increasingly mediated by digital technologies in a context in which enormous amounts of information are daily generated. Regarding this and considering the imminent application of emerging trends such as “Internet of Things” (IoT), the study of its educational effects becomes a matter of great relevance for both educational researchers and practitioners. In this context, “Learning Analytics” takes on special importance as a perspective to approach the aforementioned issue, especially from a very relevant topic: the personalization of learning. In this sense, a systematic review of literature about learning analytics published in the last two decades was carried out to identify its potential as a factor in strengthening the personalization of learning. The results show a set of key factors that include aspects related to assessment, the use of dashboards, social learning networks, and intelligent tutoring, and the importance of monitoring, feedback, and support.",
    issn = "0104-4036",
    da = "2024-02-02",
    c1 = "Universidad de La Sabana,  Colombia, Universidad de La Sabana,  Colombia",
    la = "en"
}

@article{mahmud2023,
    author = "Mahmud, Malissa and Ramli, Nor and Zakaria, Siti and Rusli, Rusreena and Manap, Mohammad and Wong, Shiau",
    type = "Journal Article",
    title = "Learning analytics and tech-tools: Insights of the practical implications for stakeholders’ perspectives",
    journal = "International Journal of Asian Social Science",
    number = "10",
    doi = "10.55493/5007.v13i10.4896",
    volume = "13",
    pages = "293--304",
    url = "https://doi.org/10.55493/5007.v13i10.4896",
    keywords = "Dashboard | Learning Analytics | Educational Technology | Data-driven Education | Educational Data Mining | Technology Integration | Learning Management",
    year = "2023",
    abstract = "The aim of the current study is to perform a systematic review of the literature to determine how learning analytics and technological tools used in education relate to one another. The review looked at 30 samples from 15 (n=15) academic databases, and found that the recent learning analytics research typically used web-based applications, Web 2.0 tools, dashboard and visualization tools, and eye-tracking devices. These technological tools, such as learning management systems and social networking websites, are widely employed in order to facilitate online learning and communication as well as to analyze and visualize data for informed decision-making. One of the practical implications of this research for learning analytics stakeholders, such as educators, policymakers, and researchers, is the ability to use these technologies tools to enhance teaching and learning. By utilizing these tools, policymakers can learn information that can be applied to the development of strategies and policies relating to the integration of technology in education. Researchers can utilize these tools to generate data that will aid in the study of teaching and learning, which will lead to the development of new teaching strategies and technological advancements. Stakeholders must establish appropriate policies and practices, be aware of the potential risks and limitations associated with their usage, and work to ensure that these tools are used in the classroom in an ethical and efficient manner. This study shows, in general, how effectively these technological tools can enhance teaching and learning when used in educational settings.",
    issn = "2224-4441",
    da = "2023-10-20",
    c1 = "Sunway University, Malaysia., University Teknologi MARA, Malaysia., University Teknologi MARA, Malaysia., University Teknologi MARA, Malaysia., University Teknologi MARA, Malaysia., Sunway University, Malaysia.",
    la = "en"
}

@misc{mohseni2024,
    author = "Mohseni, Zeynab",
    type = "Thesis",
    title = "Development of Visual Learning Analytic Tools to Explore Performance and Engagement of Students in Primary, Secondary, and Higher Education",
    doi = "10.15626/lud.532.2024",
    url = "https://doi.org/10.15626/lud.532.2024",
    keywords = "Student Performance Prediction | Student Engagement | Data-driven Education | Learning Analytics | Educational Data Mining | Primary (astronomy)",
    year = "2024",
    abstract = "Schools and educational institutions collect large amounts of data about students and their learning, including text, grades, quizzes, timestamps, and other activities. However, in primary and secondary education, this data is often dispersed across different digital platforms, lacking standardized methods for collection, processing, analysis, and presentation. These issues hinder teachers and students from making informed decisions or strategic and effective use of data. This presents a significant obstacle to progress in education and the effective development of Educational Technology (EdTech) products. Visual Learning Analytics (VLA) tools, also known as Learning Analytics Dashboards (LADs), are designed to visualize student data to support pedagogical decision-making. Despite their potential, the effectiveness of these tools remains limited. Addressing these challenges requires both technical solutions and thoughtful design considerations, as explored in Papers 1 through 5 of this thesis. Paper 1 examines the design aspects of VLA tools by evaluating higher education data and various visualization and Machine Learning (ML) techniques. Paper 2 provides broader insights into the VLA landscape through a systematic review, mapping key concepts and research gaps in VLA and emphasizing the potential of VLA tools to enhance pedagogical decisions and learning outcomes. Meanwhile, Paper 3 delves into a technical solution (data pipeline and data standard) considering a secure Swedish warehouse, SUNET. This includes a data standard for integrating educational data into SUNET, along with customized scripts to reformat, merge, and hash multiple student datasets. Papers 4 and 5 focus on design aspects, with Paper 4 discussing the proposed Human-Centered Design (HCD) approach involving teachers in co-designing a simple VLA tool. Paper 5 introduces a scenario-based framework for Multiple Learning Analytics Dashboards (MLADs) development, stressing user engagement for tailored LADs that facilitate informed decision-making in education. The dissertation offers a comprehensive approach to advancing VLA tools, integrating technical solutions with user-centric design principles. By addressing data integration challenges and involving users in tool development, these efforts aim to empower teachers in leveraging educational data for improved teaching and learning experiences.",
    da = "2024-08-20",
    la = "en"
}
