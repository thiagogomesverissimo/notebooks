Scopus
EXPORT DATE: 19 October 2024

@ARTICLE{Hooshyar2023,
	author = {Hooshyar, Danial and Tammets, Kairit and Ley, Tobias and Aus, Kati and Kollom, Kaire},
	title = {Learning Analytics in Supporting Student Agency: A Systematic Review},
	year = {2023},
	journal = {Sustainability (Switzerland)},
	volume = {15},
	number = {18},
	doi = {10.3390/su151813662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173036349&doi=10.3390%2fsu151813662&partnerID=40&md5=c6e67c3fdc5dcf81077ccd2bf6c01291},
	affiliations = {Centre for Educational Technology, Tallinn University, Tallinn, 10120, Estonia; Center for Digitalisation in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, 3500, Austria; School of Educational Sciences, Tallinn University, Tallinn, 10120, Estonia},
	abstract = {Student agency, or agency for learning, refers to an individual’s ability to act and cause changes during the learning process. Recently, learning analytics (LA) has demonstrated its potential in promoting agency, as it enables students to take an active role in their learning process and supports the development of their self-regulatory skills. Despite the growing interest and potential for supporting student agency, there have yet to be any studies reviewing the extant works dealing with the use of LA in supporting student agency. We systematically reviewed the existing related works in eight major international databases and identified 15 articles. Analysis of these articles revealed that most of the studies aimed to investigate student or educators’ agency experiences, propose design principles for LA, and to a lesser extent, develop LA methods/dashboards to support agency. Of those studies developing LA, none initially explored student agency experiences and then utilized their findings to develop evidence-based LA methods and dashboards for supporting student agency. Moreover, we found that the included articles largely rely on descriptive and diagnostic analytics, paying less attention to predictive analytics and completely overlooking the potential of prescriptive learning analytics in supporting agency. Our findings also shed light on nine key design elements for effective LA support of student agency, including customization, decision-making support, consideration of transparency and privacy, and facilitation of co-design. Surprisingly, we found that no studies have considered the use of LA to support student agency in K–12 education, while higher education has been the focal point of the LA community. Finally, we highlighted the fields of study and data visualization types that the studies mostly targeted and, more importantly, identified eight crucial challenges facing LA in its support of student agency. © 2023 by the authors.},
	author_keywords = {learning analytics; student agency; systematic review; technology-enhanced learning},
	keywords = {decision support system; facilitation; higher education; learning; student; visualization},
	correspondence_address = {D. Hooshyar; Centre for Educational Technology, Tallinn University, Tallinn, 10120, Estonia; email: danial@tlu.ee},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{Kaliisa2024295,
	author = {Kaliisa, Rogers and Misiejuk, Kamila and López-Pernas, Sonsoles and Khalil, Mohammad and Saqr, Mohammed},
	title = {Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students' Achievement, Motivation, Participation and Attitude},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {295 – 304},
	doi = {10.1145/3636555.3636884},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187557446&doi=10.1145%2f3636555.3636884&partnerID=40&md5=2955f134832b3876d0d55b1d416c61b2},
	affiliations = {Department of Education, University of Oslo, Norway; Centre for the Science of Learning and Technology (SLATE), University of Bergen, Norway; School of Computing, University of Eastern Finland, Finland},
	abstract = {While learning analytics dashboards (LADs) are the most common form of LA intervention, there is limited evidence regarding their impact on students' learning outcomes. This systematic review synthesizes the findings of 38 research studies to investigate the impact of LADs on students' learning outcomes, encompassing achievement, participation, motivation, and attitudes. As we currently stand, there is no evidence to support the conclusion that LADs have lived up to the promise of improving academic achievement. Most studies reported negligible or small effects, with limited evidence from well-powered controlled experiments. Many studies merely compared users and non-users of LADs, confounding the dashboard effect with student engagement levels. Similarly, the impact of LADs on motivation and attitudes appeared modest, with only a few exceptions demonstrating significant effects. Small sample sizes in these studies highlight the need for larger-scale investigations to validate these findings. Notably, LADs showed a relatively substantial impact on student participation. Several studies reported medium to large effect sizes, suggesting that LADs can promote engagement and interaction in online learning environments. However, methodological shortcomings, such as reliance on traditional evaluation methods, self-selection bias, the assumption that access equates to usage, and a lack of standardized assessment tools, emerged as recurring issues. To advance the research line for LADs, researchers should use rigorous assessment methods and establish clear standards for evaluating learning constructs. Such efforts will advance our understanding of the potential of LADs to enhance learning outcomes and provide valuable insights for educators and researchers alike. © 2024 Owner/Author.},
	author_keywords = {impact; Learning analytics dashboards (LADs); learning outcomes; systematic review},
	keywords = {Computer aided instruction; Learning systems; Students; Achievement motivations; Impact; Learning analytic dashboard; Learning outcome; Research studies; Student achievement; Student attitudes; Student learning outcomes; Student motivation; Systematic Review; Motivation},
	correspondence_address = {R. Kaliisa; Department of Education, University of Oslo, Norway; email: rogers.kaliisa@iped.uio.no},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071618-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 14th International Conference on Learning Analytics and Knowledge, LAK 2024; Conference date: 18 March 2024 through 22 March 2024; Conference code: 197803; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2019,
	title = {CEUR Workshop Proceedings},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071473110&partnerID=40&md5=60d53aa0a952cdae9caef8fb9f9a5876},
	abstract = {The proceedings contain 9 papers. The topics discussed include: application of learning analytics techniques on blended learning environments for university students; using Simva to evaluate serious games and collect game learning analytics data; extending a dashboard metamodel to account for users' characteristics and goals for enhancing personalization; predicting student performance over time. a case study for a blended-learning engineering course; analyzing students’ persistence using an event-based model; a data value chain to support the processing of multimodal evidence in authentic learning scenarios; and predictors and early warning systems in higher education a systematic literature review.},
	editor = {Caeiro-Rodriguez M. and University of Vigo, Department of Telematics Engineering, Campus Lagoas-Marcosende, Vigo and Munoz-Merino P.J. and Universidad Carlos III de Madrid, Department of Telematics Engineering, Av. Universidad 30, Leganes, Madrid and Hernandez-Garcia A. and Universidad Politecnica de Madrid, Departamento de Ingenieria de Organizacion, Administracion de Empresas y Estadistica, Escuela Tecnica Superior de Ingenieros de Telecomunicacion, Av. Complutense 30, Madrid},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2019 Learning Analytics Summer Institute Spain: Learning Analytics in Higher Education, LASI-SPAIN 2019; Conference date: 27 June 2019 through 28 June 2019; Conference code: 149812}
}

@CONFERENCE{Jivet201831,
	author = {Jivet, Ioana and Scheffel, Maren and Specht, Marcus and Drachsler, Hendrik},
	title = {License to evaluate: Preparing learning analytics dashboards for educational practice},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {31 – 40},
	doi = {10.1145/3170358.3170421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045910955&doi=10.1145%2f3170358.3170421&partnerID=40&md5=f74d0c71750252e72c17a38c5dc42ad8},
	affiliations = {Open University of the Netherlands, Heerlen, Netherlands; Goethe University Frankfurt/DIPF Germany, Open University of the Netherlands, Heerlen, Netherlands},
	abstract = {Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners. © 2018 Copyright held by the owner/author(s).},
	author_keywords = {Competition; Evaluation; Learning analytics; Learning dashboards; Learning science; Learning theory; Social comparison; Systematic review},
	keywords = {Competition; Computer aided instruction; Teaching; Evaluation; Learning analytics; Learning dashboards; Learning science; Learning Theory; Social comparison; Systematic Review; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 208; Conference name: 8th International Conference on Learning Analytics and Knowledge, LAK 2018; Conference date: 5 March 2018 through 9 March 2018; Conference code: 135442; All Open Access, Bronze Open Access}
}

@CONFERENCE{Bodily201841,
	author = {Bodily, Robert and Kay, Judy and Aleven, Vincent and Jivet, Ioana and Davis, Dan and Xhakaj, Franceska and Verbert, Katrien},
	title = {Open learner models and learning analytics dashboards: A systematic review},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {41 – 50},
	doi = {10.1145/3170358.3170409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045874117&doi=10.1145%2f3170358.3170409&partnerID=40&md5=e6a71082257743b6aa99cedba60c86a5},
	affiliations = {Brigham Young University, United States; University of Sydney, Australia; Carnegie Mellon University, United States; Open University of the Netherlands, Netherlands; Delft University of Technology, Netherlands; University of Leuven, Belgium},
	abstract = {This paper aims to link student facing Learning Analytics Dashboards (LADs) to the corpus of research on Open Learner Models (OLMs), as both have similar goals. We conducted a systematic review of literature on OLMs and compared the results with a previously conducted review of LADs for learners in terms of (i) data use and modelling, (ii) key publication venues, (iii) authors and articles, (iv) key themes, and (v) system evaluation. We highlight the similarities and differences between the research on LADs and OLMs. Our key contribution is a bridge between these two areas as a foundation for building upon the strengths of each. We report the following key results from the review: in reports of new OLMs, almost 60% are based on a single type of data; 33% use behavioral metrics; 39% support input from the user; 37% have complex models; and just 6% involve multiple applications. Key associated themes include intelligent tutoring systems, learning analytics, and self-regulated learning. Notably, compared with LADs, OLM research is more likely to be interactive (81% of papers compared with 31% for LADs), report evaluations (76% versus 59%), use assessment data (100% versus 37%), provide a comparison standard for students (52% versus 38%), but less likely to use behavioral metrics, or resource use data (33% against 75% for LADs). In OLM work, there was a heightened focus on learner control and access to their own data. © 2018 Association for Computing Machinery.},
	author_keywords = {Learning analytics dashboards; Literature review; Open learner models; Open student models},
	keywords = {Access control; Computer aided instruction; Students; Comparison standard; Intelligent tutoring system; Learning analytics; Literature reviews; Multiple applications; Open learner models; Open student models; Self-regulated learning; Learning systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 115; Conference name: 8th International Conference on Learning Analytics and Knowledge, LAK 2018; Conference date: 5 March 2018 through 9 March 2018; Conference code: 135442; All Open Access, Green Open Access}
}

@ARTICLE{Mohseni202491,
	author = {Mohseni, Zeynab Artemis and Masiello, Italo and Martins, Rafael M. and Nordmark, Susanna},
	title = {Visual Learning Analytics for Educational Interventions in Primary and Secondary Schools: A Scoping Review},
	year = {2024},
	journal = {Journal of Learning Analytics},
	volume = {11},
	number = {2},
	pages = {91 – 111},
	doi = {10.18608/jla.2024.8309},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202576381&doi=10.18608%2fjla.2024.8309&partnerID=40&md5=8ed220c07ea21fe182936061be6bfeda},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden},
	abstract = {Visual Learning Analytics (VLA) uses analytics to monitor and assess educational data by combining visual and automated analysis to provide educational explanations. Such tools could aid teachers in primary and secondary schools in making pedagogical decisions, however, the evidence of their effectiveness and benefits is still limited. With this scoping review, we provide a comprehensive overview of related research on proposed VLA methods, as well as identifying any gaps in the literature that could assist in describing new and helpful directions to the field. This review searched all relevant articles in five accessible databases — Scopus, Web of Science, ERIC, ACM, and IEEE Xplore — using 40 keywords. These studies were mapped, categorized, and summarized based on their objectives, the collected data, the intervention approaches employed, and the results obtained. The results determined what affordances the VLA tools allowed, what kind of visualizations were used to inform teachers and students, and, more importantly, positive evidence of educational interventions. We conclude that there are moderate-to-clear learning improvements within the limit of the studies’ interventions to support the use of VLA tools. More systematic research is needed to determine whether any learning gains are translated into long-term improvements. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.},
	author_keywords = {educational interventions; learning analytics dashboard; primary school; scoping review; secondary school; systematic review; Visual learning analytics},
	correspondence_address = {Z.A. Mohseni; Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden; email: zeynab.mohseni@lnu.se},
	publisher = {Society for Learning Analytics Research (SOLAR)},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2020a,
	title = {8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12203 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088805510&partnerID=40&md5=516462f552de8a6a63bb65179826560d},
	abstract = {The proceedings contain 50 papers. The special focus in this conference is on Distributed, Ambient and Pervasive Interactions. The topics include: Designing an Interactive Platform for Intangible Cultural Heritage Knowledge of Taoyuan Woodcarving Craft; circuit Game: A Craft-Based Electronic Building Practice; going Beyond Computer-Assisted Vocabulary Learning: Research Synthesis and Frameworks; Returning to Nature: VR Mediated States of Enhanced Wellness; visualization and Analysis for Supporting Teachers Using Clickstream Data and Eye Movement Data; visualizing Studying Activities for a Learning Dashboard Supporting Meta-cognition for Students; applying Deep Learning in Creative Re-creation of Changsha Kiln Cultural Relics; rethinking User Interaction with Smart Environments—A Comparative Study of Four Interaction Modalities; Learning Analytics Data Flow and Visualizing for Ubiquitous Learning Logs in LMS and Learning Analytics Dashboard; smart Learning in the Community: Supporting Citizen Digital Skills and Literacies; tele Echo Tube for Historic House Tojo-Tei in Matsudo International Science Art Festival 2018; motivating Physical Exercise in the Elderly with Mixed Reality Experiences; computer Vision on Wheelchairs: Detecting Sleeping Behavior of People with Intellectual Disabilities; factors Influencing the Acceptance and Usage of Smart City Services: A Systematic Review and Meta-analysis; civic Crowdsensing Through Location-Aware Virtual Monsters; participatory Governance in Smart Cities: Future Scenarios and Opportunities; Adaptability and Attuning in Smart Cities: Exploring the HCI Grand Challenge of Learning and Creativity; investigating Users Attitudes and Perceptions Towards the Usage of Smart City Apps; accessibility in Pervasive Systems: An Exploratory Study; digitally Enhancing Society Through Structuralism: Virtualizing Collective Human Eyesight and Hearing Capabilities as a Case Study; foreword.},
	editor = {Streitz N. and Konomi S.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050343-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 242499}
}

@ARTICLE{Masiello2024,
	author = {Masiello, Italo and Mohseni, Zeynab and Palma, Francis and Nordmark, Susanna and Augustsson, Hanna and Rundquist, Rebecka},
	title = {A Current Overview of the Use of Learning Analytics Dashboards},
	year = {2024},
	journal = {Education Sciences},
	volume = {14},
	number = {1},
	doi = {10.3390/educsci14010082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183134033&doi=10.3390%2feducsci14010082&partnerID=40&md5=c0664ad1bff3b7feaea5edfb1f82a7d8},
	affiliations = {Department of Computer Science and Media Technology, Linnaeus University, Växjö, 352 52, Sweden; Faculty of Computer Science, University of New Brunswick, Fredericton, E3B 5A3, NB, Canada; Department of Learning, Informatics, Management and Ethics, Karolinska Institutet, Solna, 171 77, Sweden; Department of Pedagogy and Learning, Linnaeus University, Växjö, 352 52, Sweden},
	abstract = {The promise of Learning Analytics Dashboards in education is to collect, analyze, and visualize data with the ultimate ambition of improving students’ learning. Our overview of the latest systematic reviews on the topic shows a number of research trends: learning analytics research is growing rapidly; it brings to the front inequality and inclusiveness measures; it reveals an unclear path to data ownership and privacy; it provides predictions which are not clearly translated into pedagogical actions; and the possibility of self-regulated learning and game-based learning are not capitalized upon. However, as learning analytics research progresses, greater opportunities lie ahead, and a better integration between information science and learning sciences can bring added value of learning analytics dashboards in education. © 2024 by the authors.},
	author_keywords = {LAD; learning analytics dashboards; trends},
	correspondence_address = {I. Masiello; Department of Computer Science and Media Technology, Linnaeus University, Växjö, 352 52, Sweden; email: italo.masiello@lnu.se},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Gonzalez2024,
	author = {Gonzalez, Nubia Andrea del Pilar and Chiappe, Andrés},
	title = {Learning analytics and personalization of learning: a review; [Análise de aprendizagem e personalização de aprendizagem: uma revisão]; [Análisis de aprendizaje y personalización del aprendizaje: una revisión]},
	year = {2024},
	journal = {Ensaio},
	volume = {32},
	number = {122},
	doi = {10.1590/S0104-40362024003204234},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187151456&doi=10.1590%2fS0104-40362024003204234&partnerID=40&md5=a278551cfb1994e04e23081ef8826d3c},
	affiliations = {Universidad de La Sabana, Chía, Colombia; Universidad de La Sabana, Chía, Colombia},
	abstract = {Education in the 21st century is increasingly mediated by digital technologies in a context in which enormous amounts of information are daily generated. Regarding this and considering the imminent application of emerging trends such as “Internet of Things” (IoT), the study of its educational effects becomes a matter of great relevance for both educational researchers and practitioners. In this context, “Learning Analytics” takes on special importance as a perspective to approach the aforementioned issue, especially from a very relevant topic: the personalization of learning. In this sense, a systematic review of literature about learning analytics published in the last two decades was carried out to identify its potential as a factor in strengthening the personalization of learning. The results show a set of key factors that include aspects related to assessment, the use of dashboards, social learning networks, and intelligent tutoring, and the importance of monitoring, feedback, and support. © (2024), (SciELO-Scientific Electronic Library Online). All Rights Reserved.},
	author_keywords = {21st-Century Skills; Data Science Applications in Education; Evaluation Methodologies; Information Literacy; Pedagogical Issues},
	publisher = {Fundacao Cesgranrio},
	issn = {01044036},
	language = {English},
	abbrev_source_title = {Ensaio},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Pishtari2023,
	author = {Pishtari, Gerti and Ley, Tobias and Khalil, Mohammad and Kasepalu, Reet and Tuvi, Iiris},
	title = {Model-Based Learning Analytics for a Partnership of Teachers and Intelligent Systems: A Bibliometric Systematic Review},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {5},
	doi = {10.3390/educsci13050498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160032427&doi=10.3390%2feducsci13050498&partnerID=40&md5=45381239f920c885e6bdfa4a9d31beb9},
	affiliations = {Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems, Danube University Krems, Krems an der Donau, 3500, Austria; School of Educational Sciences, Tallinn University, Tallinn, 10120, Estonia; Centre for the Science of Learning & Technology (SLATE), Faculty of Psychology, University of Bergen, Bergen, 5007, Norway; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, 33100, Finland},
	abstract = {This paper presents a bibliometric systematic review on model-based learning analytics (MbLA), which enable coupling between teachers and intelligent systems to support the learning process. This is achieved through systems that make their models of student learning and instruction transparent to teachers. We use bibliometric network analysis and topic modelling to explore the synergies between the related research groups and the main research topics considered in the 42 reviewed papers. Network analysis depicts an early stage community, made up of several research groups, mainly from the fields of learning analytics and intelligent tutoring systems, which have had little explicit and implicit collaboration but do share a common core literature. Th resulting topics from the topic modelling can be grouped into the ones related to teacher practices, such as awareness and reflection, learning orchestration, or assessment frameworks, and the ones related to the technology used to open up the models to teachers, such as dashboards or adaptive learning architectures. Moreover, results show that research in MbLA has taken an individualistic approach to student learning and instruction, neglecting social aspects and elements of collaborative learning. To advance research in MbLA, future research should focus on hybrid teacher–AI approaches that foster the partnership between teachers and technology to support the learning process, involve teachers in the development cycle from an early stage, and follow an interdisciplinary approach. © 2023 by the authors.},
	author_keywords = {adaptive learning technology; bibliometric analysis; dashboards; intelligent tutoring systems; model-based learning analytics; topic modelling},
	correspondence_address = {G. Pishtari; Department for Continuing Education Research and Educational Technologies, University for Continuing Education Krems, Danube University Krems, Krems an der Donau, 3500, Austria; email: gerti.pishtari@donau-uni.ac.at},
	publisher = {MDPI},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@BOOK{Chaudy20211803,
	author = {Chaudy, Yaëlle and Connolly, Thomas M.},
	title = {Integrating assessment, feedback, and learning analytics in educational games: Literature review and design of an assessment engine},
	year = {2021},
	journal = {Research Anthology on Developments in Gamification and Game-Based Learning},
	volume = {4-4},
	pages = {1803 – 1846},
	doi = {10.4018/978-1-6684-3710-0.ch088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163656150&doi=10.4018%2f978-1-6684-3710-0.ch088&partnerID=40&md5=8cc5632e76753fcde156628adf17d03e},
	affiliations = {University of the West of Scotland, United Kingdom},
	abstract = {Assessment is a crucial aspect of any teaching and learning process. New tools such as educational games offer promising advantages: they can personalize feedback to students and save educators time by automating the assessment process. However, while many teachers agree that educational games increase motivation, learning, and retention, few are ready to fully trust them as an assessment tool. A likely reason behind this lack of trust is that educational games are distributed as black boxes, unmodifiable by educators and not providing enough insight about the gameplay. This chapter presents three systematic literature reviews looking into the integration of assessment, feedback, and learning analytics in educational games. It then proposes a framework and present a fully developed engine. The engine is used by both developers and educators. Designed to separate game and assessment, it allows teachers to modify the assessment after distribution and visualize gameplay data via a learning analytics dashboard. © 2022, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-166843711-7; 978-166843710-0},
	language = {English},
	abbrev_source_title = {Res. Anthol. on Dev. in Gamification and Game-Based Learn.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pérez-Álvarez201816,
	author = {Pérez-Álvarez, Ronald and Maldonado-Mahauad, Jorge and Pérez-Sanagustín, Mar},
	title = {Tools to Support Self-Regulated Learning in Online Environments: Literature Review},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11082 LNCS},
	pages = {16 – 30},
	doi = {10.1007/978-3-319-98572-5_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053175970&doi=10.1007%2f978-3-319-98572-5_2&partnerID=40&md5=78564dd16be2591661e019ed0b1938e7},
	affiliations = {Department of Computer Science, Pontificia Universidad Católica de Chile, Santiago, Chile; University of Costa Rica, Sede Regional del Pacífico, Puntarenas, Costa Rica; Department of Computer Science, University of Cuenca, Cuenca, Ecuador; Université Toulouse III Paul Sabatier, Toulouse, France},
	abstract = {Self-regulated learning (SRL) skills are especially important in Massive Open Online Courses (MOOCs), where teacher guidance is scarce, and learners must engage in their learning process trying to succeed and achieve their learning goals. However, developing SRL strategies is difficult for learners given the autonomy that is required in this kind of courses. In order to support learners on this process, researchers have proposed a variety of tools designed to support certain aspects of self-regulation in online learning environments. Nevertheless, there is a lack of study to understand what the commonalities and differences in terms of design are, what the results in terms of the effect on learners’ self-regulation are and which of them could be applied in MOOCs. Those are the questions that should be further explored. In this paper we present a systematic literature review where 22 tools designed to support SRL in online environments were analyzed. Our findings indicate that: (1) most of the studies do not evaluate the effect on learners’ SRL strategies; (2) the use of interactive visualizations has a positive effect on learners’ motivation; (3) the use of the social comparison component has a positive effect on engagement and time management; and (4) there is a lack of models to match learners’ activity with the tools with SRL strategies. Finally, we present the lessons learned for guiding the community in the implementation of tools to support SRL strategies in MOOCs. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Dashboard; Learning analytics; Literature review; Massive Open Online Courses; MOOC; Online; Self-Regulated Learning; System; Tools},
	keywords = {Computer aided instruction; Curricula; Deregulation; Engineering education; Learning systems; Teaching; Tools; Visualization; Dashboard; Learning analytics; Literature reviews; Massive open online course; MOOC; Online; Self-regulated learning; System; E-learning},
	correspondence_address = {R. Pérez-Álvarez; Department of Computer Science, Pontificia Universidad Católica de Chile, Santiago, Chile; email: raperez13@uc.cl},
	editor = {Elferink R. and Drachsler H. and Pammer-Schindler V. and Perez-Sanagustin M. and Scheffel M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331998571-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 54; Conference name: 13th European Conference on Technology Enhanced Learning, EC-TEL 2018; Conference date: 3 September 2018 through 6 September 2018; Conference code: 217579}
}

@ARTICLE{Valle20211724,
	author = {Valle, Natercia and Antonenko, Pavlo and Dawson, Kara and Huggins-Manley, Anne Corinne},
	title = {Staying on target: A systematic literature review on learner-facing learning analytics dashboards},
	year = {2021},
	journal = {British Journal of Educational Technology},
	volume = {52},
	number = {4},
	pages = {1724 – 1748},
	doi = {10.1111/bjet.13089},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105201830&doi=10.1111%2fbjet.13089&partnerID=40&md5=52b5f2b1d1986f68fd04d2b9c868df6e},
	affiliations = {School of Teaching and Learning, University of Florida, Gainesville, FL, United States; School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, FL, United States},
	abstract = {The advances in technology to capture and process unprecedented amounts of educational data has boosted the interest in Learning Analytics Dashboard (LAD) applications as a way to provide meaningful visual information to administrators, parents, teachers and learners. Despite the frequent argument that LADs are useful to support target users and their goals to monitor and act upon the information provided, little is known about LADs’ theoretical underpinnings and the alignment (or lack thereof) between LADs intended outcomes and the measures used to evaluate their implementation. However, this knowledge is necessary to illuminate more efficient approaches in the development and implementation of LAD tools. Guided by the self-regulated learning perspective and using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, this systematic literature review addressed this gap by examining whether and how learner-facing LAD’s target outcomes align with the domain measures used to evaluate their implementations. Out of the 1297 papers retrieved from 15 databases, 28 were included in the final quantitative and qualitative analysis. Results suggested an intriguing lack of alignment between LADs’ intended outcomes (mostly cognitive domain) and their evaluation (mostly affective measures). Based on these results and on the premise that LADs are designed to support learners, a critical recommendation from this study is that LADs’ target outcomes should guide the selection of measures used to evaluate the efficacy of these tools. This alignment is critical to enable the construction of more robust guidelines to inform future endeavours in the field. Practitioner notes What is already known about this topic There has been an increased interest and investment in learning analytics dashboards to support learners as end-users. Learner-facing learning analytics dashboards are designed with different purposes, functionalities and types of data in an attempt to influence learners’ behaviour, achievement and skills. What this paper adds This paper reports trends and opportunities regarding the design of learner-facing learning analytics dashboards, contexts of implementation, as well as types and features of learner-facing learning analytics dashboard studies. The paper discusses how affect and motivation have been largely overlooked as target outcomes in learner-facing learning analytics dashboards. Implications for practice and/or policy Based on the evidence gathered through the review, this paper makes recommendations for theory (eg, inclusion of motivation as an important target outcome). The paper makes recommendations related to the design, implementation and evaluation of learning analytics dashboards. The paper also highlights the need for further integration between learner-facing learning analytics dashboards and open learner models. © 2021 British Educational Research Association.},
	author_keywords = {evaluation; learning analytics dashboards; systematic literature review; target outcomes},
	keywords = {Alignment; Facings; Motivation; Affective measures; Cognitive domain; Open learner models; Quantitative and qualitative analysis; Self-regulated learning; Systematic literature review; Systematic Review; Visual information; Learning systems},
	correspondence_address = {N. Valle; School of Teaching and Learning, University of Florida, Gainesville, United States; email: naterciavalle@gmail.com},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071013},
	coden = {BJETD},
	language = {English},
	abbrev_source_title = {Br J Educ Technol},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@ARTICLE{Matcha2020226,
	author = {Matcha, Wannisa and Uzir, Noraayu Ahmad and Gasevic, Dragan and Pardo, Abelardo},
	title = {A Systematic Review of Empirical Studies on Learning Analytics Dashboards: A Self-Regulated Learning Perspective},
	year = {2020},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {13},
	number = {2},
	pages = {226 – 245},
	doi = {10.1109/TLT.2019.2916802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087489008&doi=10.1109%2fTLT.2019.2916802&partnerID=40&md5=e91f2bdafed292e0e2e4b13ee98f6e2f},
	affiliations = {School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; Faculty of Information Technology, Monash University, Clayton, 3800, VIC, Australia; Division of Information Technology Engineering and Environment, University of South Australia, Adelaide, 5000, SA, Australia},
	abstract = {This paper presents a systematic literature review of learning analytics dashboards (LADs) research that reports empirical findings to assess the impact on learning and teaching. Several previous literature reviews identified self-regulated learning as a primary focus of LADs. However, there has been much less understanding how learning analytics are grounded in the literature on self-regulated learning and how self-regulated learning is supported. To address this limitation, this review analyzed the existing empirical studies on LADs based on the well-known model of self-regulated learning proposed by Winne and Hadwin. The results show that existing LADs are rarely grounded in learning theory, cannot be suggested to support metacognition, do not offer any information about effective learning tactics and strategies, and have significant limitations in how their evaluation is conducted and reported. Based on the findings of the study and through the synthesis of the literature, the paper proposes that future research and development should not make any a priori design decisions about representation of data and analytic results in learning analytics systems such as LADs. To formalize this proposal, the paper defines the model for user-centered learning analytics systems (MULAS). The MULAS consists of the four dimensions that are cyclically and recursively interconnected including: theory, design, feedback, and evaluation. © 2008-2011 IEEE.},
	author_keywords = {Dashboards; empirical research; feedback; information visualization; learning analytics; self-regulated learning},
	keywords = {E-learning; Engineering; Effective learning; Empirical findings; Empirical studies; Learning and teachings; Literature reviews; Research and development; Self-regulated learning; Systematic literature review; Learning systems},
	correspondence_address = {D. Gasevic; Faculty of Information Technology, Monash University, Clayton, 3800, Australia; email: dragan.gasevic@monash.edu},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 227}
}

@CONFERENCE{2018,
	title = {ACM International Conference Proceeding Series},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046059060&partnerID=40&md5=b7007878f235d6ad9c378551de76bf7a},
	abstract = {The proceedings contain 60 papers. The topics discussed include: the half-life of MOOC knowledge: a randomized trial evaluating knowledge retention and retrieval practice in MOOCs; graph-based visual topic dependency models: supporting assessment design and delivery at scale; data-driven generation of rubric criteria from an educational programming environment; supporting teacher's intervention in students' virtual collaboration using a network based model; correlating affect and behavior in reasoning mind with state test achievement; license to evaluate: preparing learning analytics dashboards for educational practice; open learner models and learning analytics dashboards: a systematic review; multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in Flanders; a qualitative evaluation of a learning dashboard to support advisor-student dialogues; the classrooom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers; an application of participatory action research in advising-focused learning analytics; profiling students from their questions in a blended learning environment; recurrence quantification analysis as a method for studying text comprehension dynamics; towards a writing analytics framework for adult English language learners; epistemic network analysis of students' longer written assignments as formative/summative evaluation; and the influence of student's cognitive and motivational characteristics on student's use of a 4C/ID-based online learning environment and their learning gain.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036400-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 8th International Conference on Learning Analytics and Knowledge, LAK 2018; Conference date: 5 March 2018 through 9 March 2018; Conference code: 135442}
}

@ARTICLE{2024a,
	title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205105826&partnerID=40&md5=22b3be799700285565dc06b4e080e3d1},
	abstract = {The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 19th European Conference on Technology Enhanced Learning, EC-TEL 2024; Conference date: 16 September 2024 through 20 September 2024; Conference code: 319189}
}

@CONFERENCE{2021,
	title = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	year = {2021},
	journal = {Proceedings - 2021 16th Latin American Conference on Learning Technologies, LACLO 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127131129&partnerID=40&md5=ec64ebefb9873aac187f8ca9cf50d9eb},
	abstract = {The proceedings contain 99 papers. The topics discussed include: predicting student performance using feature selection algorithms for deep learning models; ‘prediction’ in educational research: a bibliographic mapping of academic production over time; tools, resources and techniques for active learning at COVID-19 - a look at the private Brazilian higher education network; teaching computational thinking and introduction to programming through robotics amid the COVID-19 pandemic - an experience report; constraints, effectiveness and solutions in using google classroom as a learning management system during COVID-19 pandemic: a systematic literature review; online collaborative learning: analysis of the current state; meaningful learning: towards a meta-regulated learning model in hybrid education; and systematic mapping of Moodle dashboards focused on learning analytics tasks.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166542358-8},
	language = {English},
	abbrev_source_title = {Proc. - Lat. American Conf. Learn. Technol., LACLO},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th Latin American Conference on Learning Technologies, LACLO 2021; Conference date: 19 October 2021 through 21 October 2021; Conference code: 177612}
}

@ARTICLE{Ley20231397,
	author = {Ley, Tobias and Tammets, Kairit and Pishtari, Gerti and Chejara, Pankaj and Kasepalu, Reet and Khalil, Mohammad and Saar, Merike and Tuvi, Iiris and Väljataga, Terje and Wasson, Barbara},
	title = {Towards a partnership of teachers and intelligent learning technology: A systematic literature review of model-based learning analytics},
	year = {2023},
	journal = {Journal of Computer Assisted Learning},
	volume = {39},
	number = {5},
	pages = {1397 – 1417},
	doi = {10.1111/jcal.12844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160082028&doi=10.1111%2fjcal.12844&partnerID=40&md5=88bc6a6a1caee5e089859e79a36184a6},
	affiliations = {Center for Digitalization in Lifelong Learning, University for Continuing Education Krems, Krems an der Donau, Austria; Center for Educational Technology, Tallinn University, Tallinn, Estonia; Centre for the Science of Learning & Technology (SLATE), University of Bergen, Bergen, Norway; Institute of Psychology, University of Tartu, Tartu, Estonia},
	abstract = {Background: With increased use of artificial intelligence in the classroom, there is now a need to better understand the complementarity of intelligent learning technology and teachers to produce effective instruction. Objective: The paper reviews the current research on intelligent learning technology designed to make models of student learning and instruction transparent to teachers, an area we call model-based learning analytics. We intended to gain an insight into the coupling between the knowledge models that underpin the intelligent system and the knowledge used by teachers in their classroom decision making. Methods: Using a systematic literature review methodology, we first identified 42 papers, mainly from the domain of intelligent tutoring systems and learning analytics dashboards that conformed to our selection criteria. We then qualitatively analysed the context in which the systems were applied, models they used and benefits reported for teachers and learners. Results and Conclusions: A majority of papers used either domain or learner models, suggesting that instructional decisions are mostly left to teachers. Compared to previous reviews, our set of papers appeared to have a stronger focus on providing teachers with theory-driven insights and instructional decisions. This suggests that model-based learning analytics can address some of the shortcomings of the field, like meaningfulness and actionability of learning analytics tools. However, impact in the classroom still needs further research, as in half of the cases the reported benefits were not backed with evidence. Future research should focus on the dynamic interaction between teachers and technology and how learning analytics has an impact on learning and decision making by teachers and students. We offer a taxonomy of knowledge models that can serve as a starting point for designing such interaction. © 2023 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.},
	author_keywords = {adaptive learning technology; hybrid human-AI technologies; intelligent tutoring systems; learning analytics; systematic literature review; teacher dashboards},
	correspondence_address = {T. Ley; University for Continuing Education Krems, Krems an der Donau, Austria; email: tobias.ley@donau-uni.ac.at},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Barbé202475,
	author = {Barbé, Rémi and Encelle, Benoît and Sehaba, Karim},
	title = {Adaptation in Learning Analytics Dashboards: A Systematic Review},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {75 – 86},
	doi = {10.5220/0012628600003693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193924496&doi=10.5220%2f0012628600003693&partnerID=40&md5=e291e9fa537fc7b1ab8db06b3c931edc},
	affiliations = {Univ. Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ. Lyon 2, LIRIS, UMR5205, Villeurbanne, F-69622, France; Univ. Lyon, Univ. Lyon 2, CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Bron, F-69676, France},
	abstract = {Although learning analytics dashboards (LAD) grow in numbers, they often fail to improve learner awareness as they lack adaptation capabilities. This paper presents a systematic review following the PRISMA statement, about the adaptation capabilities of LADs based on new definitions for LADs and learning indicators. A detailed analysis of 23 articles selected among 426 articles retrieved from databases was conducted based on a coding scheme, centered on adaptation and its dimensions, namely: to whom, what, to what, who, and how. The main result of this study is that there is more evidence of adaptable LADs than adaptive LADs. As a result, the road to adaptivity is worth exploring. The analysis of LAD’s common features led us to distinguish mainly 4 adaptable capabilities and 2 adaptive ones. Most of the adaptable capabilities consist of giving exploration power to the user and providing him with data filtering, zooming, or selection functionalities. In contrast, users have limited options when it comes to selecting indicators, their visualizations, and organization on the dashboard. Providing more flexible LADs could enhance their usability and increase learner awareness. Furthermore, the few adaptive features involve adaptations based on “if-then” rules and there are no reports of advanced computing techniques such as machine learning that could empower LAD’s adaptation. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Adaptation; Learning Analytics Dashboards; Learning Indicators; Systematic Review},
	keywords = {Adaptation; Adaptive features; Adaptivity; Coding scheme; Common features; Data filtering; Learning analytic dashboard; Learning indicator; Power; Systematic Review; E-learning},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 16th International Conference on Computer Supported Education, CSEDU 2024; Conference date: 2 May 2024 through 4 May 2024; Conference code: 199597; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gauthier2022,
	author = {Gauthier, Andrea and Rizvi, Saman and Cukurova, Mutlu and Mavrikis, Manolis},
	title = {Is it time we get real? A systematic review of the potential of data-driven technologies to address teachers' implicit biases},
	year = {2022},
	journal = {Frontiers in Artificial Intelligence},
	volume = {5},
	doi = {10.3389/frai.2022.994967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140411402&doi=10.3389%2ffrai.2022.994967&partnerID=40&md5=1bdc8efa1793bac3416959863e54bb3a},
	affiliations = {UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom},
	abstract = {Data-driven technologies for education, such as artificial intelligence in education (AIEd) systems, learning analytics dashboards, open learner models, and other applications, are often created with an aspiration to help teachers make better, evidence-informed decisions in the classroom. Addressing gender, racial, and other biases inherent to data and algorithms in such applications is seen as a way to increase the responsibility of these systems and has been the focus of much of the research in the field, including systematic reviews. However, implicit biases can also be held by teachers. To the best of our knowledge, this systematic literature review is the first of its kind to investigate what kinds of teacher biases have been impacted by data-driven technologies, how or if these technologies were designed to challenge these biases, and which strategies were most effective at promoting equitable teaching behaviors and decision making. Following PRISMA guidelines, a search of five databases returned n = 359 records of which only n = 2 studies by a single research team were identified as relevant. The findings show that there is minimal evidence that data-driven technologies have been evaluated in their capacity for supporting teachers to make less biased decisions or promote equitable teaching behaviors, even though this capacity is often used as one of the core arguments for the use of data-driven technologies in education. By examining these two studies in conjunction with related studies that did not meet the eligibility criteria during the full-text review, we reveal the approaches that could play an effective role in mitigating teachers' biases, as well as ones that may perpetuate biases. We conclude by summarizing directions for future research that should seek to directly confront teachers' biases through explicit design strategies within teacher tools, to ensure that the impact of biases of both technology (including data, algorithms, models etc.) and teachers are minimized. We propose an extended framework to support future research and design in this area, through motivational, cognitive, and technological debiasing strategies. Copyright © 2022 Gauthier, Rizvi, Cukurova and Mavrikis.},
	author_keywords = {artificial intelligence in education; bias; decision support systems; equity; learning analytics (LA); teachers},
	correspondence_address = {A. Gauthier; UCL Knowledge Lab, Department of Culture, Communication and Media, IOE UCL's Faculty of Education and Society, University College London, London, United Kingdom; email: andrea.gauthier@ucl.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Jivet201782,
	author = {Jivet, Ioana and Scheffel, Maren and Drachsler, Hendrik and Specht, Marcus},
	title = {Awareness is not enough: Pitfalls of learning analytics dashboards in the educational practice},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10474 LNCS},
	pages = {82 – 96},
	doi = {10.1007/978-3-319-66610-5_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029587668&doi=10.1007%2f978-3-319-66610-5_7&partnerID=40&md5=520f0178139e3ade3fff9a41e75465d7},
	affiliations = {Open Universiteit, Valkenburgerweg 177, Heerlen, 6419 AT, Netherlands; Goethe University Frankfurt, Frankfurt, Germany; German Institute for International Educational Research (DIPF), Frankfurt, Germany},
	abstract = {It has been long argued that learning analytics has the potential to act as a “middle space” between the learning sciences and data analytics, creating technical possibilities for exploring the vast amount of data generated in online learning environments. One common learning analytics intervention is the learning dashboard, a support tool for teachers and learners alike that allows them to gain insight into the learning process. Although several related works have scrutinised the state-of-the-art in the field of learning dashboards, none have addressed the theoretical foundation that should inform the design of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our critical examination reveals the most common educational concepts and the context in which they have been applied. We find evidence that current designs foster competition between learners rather than knowledge mastery, offering misguided frames of reference for comparison. © Springer International Publishing AG 2017.},
	author_keywords = {Competition; Learning analytics; Learning dashboards; Learning science; Learning theory; Social comparison; Systematic review},
	keywords = {Competition; Computer aided instruction; E-learning; Learning systems; Teaching; Learning analytics; Learning dashboards; Learning science; Learning Theory; Social comparison; Systematic Review; Education},
	correspondence_address = {I. Jivet; Open Universiteit, Heerlen, Valkenburgerweg 177, 6419 AT, Netherlands; email: ioana.jivet@ou.nl},
	editor = {Broisin J. and Lavoue E. and Drachsler H. and Verbert K. and Perez-Sanagustin M.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331966609-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 149; Conference name: 12th European Conference on Technology Enhanced Learning, EC-TEL 2017; Conference date: 12 September 2017 through 15 September 2017; Conference code: 197899}
}

@ARTICLE{Kaliisa2023,
	author = {Kaliisa, Rogers and Jivet, Ioana and Prinsloo, Paul},
	title = {A checklist to guide the planning, designing, implementation, and evaluation of learning analytics dashboards},
	year = {2023},
	journal = {International Journal of Educational Technology in Higher Education},
	volume = {20},
	number = {1},
	doi = {10.1186/s41239-023-00394-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158003907&doi=10.1186%2fs41239-023-00394-6&partnerID=40&md5=106b2f915d5f20a8a0304cccc10e6753},
	affiliations = {Department of Education, The University of Oslo, Blindern 0317, P.O. Box 1092, Oslo, Norway; DIPF & Goethe University Frankfurt, Frankfurt, Germany; Department of Business Management, University of South Africa, Pretoria, South Africa},
	abstract = {Higher education institutions are moving to design and implement teacher-facing learning analytics (LA) dashboards with the hope that instructors can extract deep insights about student learning and make informed decisions to improve their teaching. While much attention has been paid to developing teacher-facing dashboards, less is known about how they are designed, implemented and evaluated. This paper presents a systematic literature review of existing studies reporting on teacher-facing LA dashboards. Out of the 1968 articles retrieved from several databases, 50 articles were included in the final analysis. Guided by several frameworks, articles were coded based on the following dimensions: purpose, theoretical grounding, stakeholder involvement, ethics and privacy, design, implementation, and evaluation criteria. The findings show that most dashboards are designed to increase teachers’ awareness but with limited actionable insights to allow intervention. Moreover, while teachers are involved in the design process, this is mainly at the exploratory/problem definition stage, with little input beyond this stage. Most dashboards were prescriptive, less customisable, and implicit about the theoretical constructs behind their designs. In addition, dashboards are deployed at prototype and pilot stages, and the evaluation is dominated by self-reports and users’ reactions with limited focus on changes to teaching and learning. Besides, only one study considered privacy as a design requirement. Based on the findings of the study and synthesis of existing literature, we propose a four-dimensional checklist for planning, designing, implementing and evaluating LA dashboards. © 2023, The Author(s).},
	author_keywords = {Dashboard evaluation; Learning analytics; Systematic review; Teacher-facing dashboards},
	correspondence_address = {R. Kaliisa; Department of Education, The University of Oslo, Oslo, Blindern 0317, P.O. Box 1092, Norway; email: rogers.kaliisa@iped.uio.no},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23659440},
	language = {English},
	abbrev_source_title = {Int. j. educ. technol. high. educ.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access}
}

@CONFERENCE{Kew202445,
	author = {Kew, Si Na and Koh, Elizabeth and Choo, Zi Luan and Jonathan, Christin Rekha},
	title = {A Systematic Review on Student-Facing Learning Analytics Dashboards: Reference Frames and Indicators},
	year = {2024},
	journal = {Proceedings - 2024 6th International Conference on Computer Science and Technologies in Education, CSTE 2024},
	pages = {45 – 50},
	doi = {10.1109/CSTE62025.2024.00015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199983737&doi=10.1109%2fCSTE62025.2024.00015&partnerID=40&md5=670b7f743cf5ea1f74b3fb235d6ec0cf},
	affiliations = {Universiti Teknologi Malaysia, Faculty of Social Sciences and Humanities, Malaysia; National Institute of Education, Nanyang Technological University, Singapore},
	abstract = {As the integration of technology in education undergoes continuous development, Learning Analytics Dashboards (LADs) have become vital tools for both instructors and learners, facilitating the monitoring and optimization of the learning experience. Student-facing LADs have been designed with various reference frames which enable various feedback, comparisons and reflection. However, there has been limited examination of the reference frames and their indicators employed in student-facing LADs as well as its evaluation. This research aims to address this gap by conducting a systematic literature review using PRISMA to synthesize existing literature to identify and offer insights on reference frames and key indicators used in student-facing LADs. We identified 42 articles and analyzed that social reference frames as compared to progress reference frames are commonly employed in LADs. Key indicators include class performance average, class performance mean, average performance of the class, etc. These insights contribute to the ongoing development and best practices of LAD design. The knowledge and findings can help educators, researchers, system designers and policymakers decide how best to incorporate these tools into educational settings.  © 2024 IEEE.},
	author_keywords = {indicators; learning analytics dashboard; PRISMA; reference frame; systematic literature review},
	keywords = {Petroleum reservoir evaluation; Students; Continuous development; Development Learning; Key indicator; Learning analytic dashboard; Performance; PRISMA; Reference frame; Systematic literature review; Systematic Review; Technology in educations; Facings},
	correspondence_address = {S.N. Kew; Universiti Teknologi Malaysia, Faculty of Social Sciences and Humanities, Malaysia; email: snkew@utm.my},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035180-4},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Comput. Sci. Technol. Educ., CSTE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th International Conference on Computer Science and Technologies in Education, CSTE 2024; Conference date: 19 April 2024 through 21 April 2024; Conference code: 201142}
}

@CONFERENCE{2023,
	title = {Proceedings of the 5th European Conference on Software Engineering Education, ECSEE 2023},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163470474&partnerID=40&md5=4cfa3f4c03413c8edb4204d335a8151f},
	abstract = {The proceedings contain 32 papers. The topics discussed include: reflections on training next-gen industry workforce on secure software development; the gap between higher education and the software industry – a case study on technology differences; using automatic program assessment in a software development project course; using learning analytics to identify student learning profiles for software development courses; learning analytics dashboard for educators: proposed project to design with pedagogical background; towards learning style prediction based on personality; adaptive learning path sequencing based on learning styles within n-dimensional spaces; learning style classification by using Bayesian networks based on the index of learning style; systematic literature review for the use of AI based techniques in adaptive learning management systems; and flipped teaching in software engineering education: results of a long-term study.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039956-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th European Conference on Software Engineering Education, ECSEE 2023; Conference date: 19 June 2023 through 21 June 2023; Conference code: 189271}
}

@ARTICLE{Schwendimann201730,
	author = {Schwendimann, Beat A. and Rodriguez-Triana, Maria Jesus and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
	title = {Perceiving learning at a glance: A systematic literature review of learning dashboard research},
	year = {2017},
	journal = {IEEE Transactions on Learning Technologies},
	volume = {10},
	number = {1},
	pages = {30 – 41},
	doi = {10.1109/TLT.2016.2599522},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017624978&doi=10.1109%2fTLT.2016.2599522&partnerID=40&md5=9710190a28a5f0a2b673680e6f968c1c},
	affiliations = {CHILI Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland; REACT Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland},
	abstract = {This paper presents a systematic literature review of the state-of-the-art of research on learning dashboards in the fields of Learning Analytics and Educational Data Mining. Research on learning dashboards aims to identify what data is meaningful to different stakeholders and how data can be presented to support sense-making processes. Learning dashboards are becoming popular due to the increased use of educational technologies, such as Learning Management Systems (LMS) and Massive Open Online Courses (MOOCs). The initial search of five main academic databases and GScholar resulted in 346 papers out of which 55 papers were included in the final analysis. Our review distinguishes different kinds of research studies as well as various aspects of learning dashboards and their maturity regarding evaluation. As the research field is still relatively young, most studies are exploratory and proof-of-concept. The review concludes by offering a definition for learning dashboards and by outlining open issues and future lines of work in the area of learning dashboards. There is a need for longitudinal research in authentic settings and studies that systematically compare different dashboard designs. © 2008-2011 IEEE.},
	author_keywords = {dashboards; educational data mining; information visualization; Learning analytics; systematic review},
	keywords = {Data visualization; Education; Enterprise resource planning; Information systems; Online systems; dashboards; Educational data mining; Information visualization; Learning analytics; Systematic Review; Data mining},
	correspondence_address = {B.A. Schwendimann; CHILI Lab, Ecole Polytechnique Federale de Lausanne, Lausanne, 1015, Switzerland; email: beat.schwendimann@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers},
	issn = {19391382},
	language = {English},
	abbrev_source_title = {IEEE Trans. Learn. Technol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 364}
}

@ARTICLE{Barthakur202449,
	author = {Barthakur, Abhinava and Marrone, Rebecca and Esnaashari, Shadi and Kovanovic, Vitomir and Dawson, Shane},
	title = {A Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	pages = {49 – 63},
	doi = {10.1007/978-3-031-72315-5_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205123908&doi=10.1007%2f978-3-031-72315-5_4&partnerID=40&md5=dda1262269879cd573d67eff08b30bce},
	affiliations = {University of South Australia, Adelaide, Australia; Johns Hopkins University, Maryland, United States},
	abstract = {Within the education sector, there is growing recognition of the importance of diverse data sets in aiding strategic decisions and supporting personalized learning. To date, this call for increased and more nuanced data has been translated into institutional use of data dashboards or learning analytics dashboards. While these dashboards have been extensively developed and adopted in higher education, there is limited research investigating the use of dashboards in K-12 education. To address this gap, this study presents a systematic literature review examining dashboards as a decision-making system in K-12 settings. Our analysis indicates significant underuse of data in these dashboards, with a concerning scarcity of implementations and evaluations in real-world classroom environments. To counteract these shortcomings, we propose a set of recommendations designed to enhance dashboard development by promoting the use of Learner Profiles (LPs). These guidelines aim to support educational outcomes and student success by informing the design and deployment of fine-grained dashboards aligned with the specific needs of K-12 education. By highlighting the current gaps and offering forward-looking recommendations, our study clarifies the present landscape and serves as a foundation for future research, with significant implications for educators, policymakers, and scholars interested in using LPs to improve student learning outcomes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Dashboards; Decision-making; K-12; Learner Profiles; Systematic literature review},
	keywords = {Adversarial machine learning; Decision making; Federated learning; Students; Teaching; Dashboard; Decision-making systems; Decisions makings; Education sectors; K-12; K-12 education; Learner profiles; Systematic literature review; Systematic Review; Teaching and learning; Contrastive Learning},
	correspondence_address = {A. Barthakur; University of South Australia, Adelaide, Australia; email: abhinava.barthakur@mymail.unisa.edu.au},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 19th European Conference on Technology Enhanced Learning, EC-TEL 2024; Conference date: 16 September 2024 through 20 September 2024; Conference code: 319189}
}

@ARTICLE{2020b,
	title = {7th International Conference on Learning and Collaboration Technologies, LCT 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12205 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089160143&partnerID=40&md5=0b4403462778b0052a8720eb0ddf2c06},
	abstract = {The proceedings contain 86 papers. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Reflective Journaling: A Theoretical Model and Digital Prototype for Developing Resilience and Creativity; prototyping a Touch-Optimized Modeling Tool for Co-located and Inverted Classroom Group Modeling Scenarios; evaluating Portable Touch Projectors in the Context of Digital Education; STEAM-X: An Exploratory Study Adding Interactive Physical Activity to the STEAM Model; usability Testing of a Digital Competence Assessment and Certification System; designing ‘Embodied’ Science Learning Experiences for Young Children; impact of Constant Work on the Students’ Academic Performance; Learning Analytics and MOOCs; on the Design of a Teachers’ Dashboard: Requirements and Insights; evaluation of the Virtual Mobility Learning Hub; mudpoint: Evaluating Instructor Perception on a Continuous and Non-specific Feedback System; characterization of Learners from Their Learning Activities on a Smart Learning Platform; AI-Driven Assessment of Students: Current Uses and Research Trends; generating Dashboards Using Fine-Grained Components: A Case Study for a PhD Programme; learning Analytics and Spelling Acquisition in German – The Path to Individualization in Learning; Building Student Interactions Outside the Classroom: Utilizing a Web-Based Application in a University Flipped Learning Course for EFL Learners; the Impact of Corpus Linguistics on Language Teaching in Russia’s Educational Context: Systematic Literature Review; framework of Manga Application for Teaching Japanese Language; Individualized Differentiated Spelling with Blogs - Implementing and Individualizing (IDeRBlog ii): An Example of a Learning Analytics Platform for the Text-Based Acquisition of Spelling Skills of Students in German.},
	editor = {Zaphiris P. and Ioannou A. and Ioannou A.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050512-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Learning and Collaboration Technologies, LCT 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 242339}
}

@ARTICLE{Tretow-Fish202237,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin},
	title = {Evaluating Learning Analytics of Adaptive Learning Systems: A Work in Progress Systematic Review},
	year = {2022},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {435 LNICST},
	pages = {37 – 52},
	doi = {10.1007/978-3-031-06675-7_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131941380&doi=10.1007%2f978-3-031-06675-7_3&partnerID=40&md5=1f6f62698fa9028b553174c667cf4798},
	affiliations = {Department of Applied Mathematics and Computer Science at the Technical University of Denmark, Kongens Lyngby, Denmark},
	abstract = {There is currently no systematic overview of methods for evaluating Learning Analytics (LA) and Learning Analytics Dashboards (LAD) of Adaptive Learning Platforms (ALPs). 10 articles and 2 reviews are analyzed and synthesized. Focusing on the purposes of evaluation, methods used in the studies are grouped into five categories (C1-5): C1) evaluation of LA and LAD design and framework, C2) evaluation of performance with LA and LAD, C3) evaluation of adaptivity functions of the system, C4) evaluation of perceived value, and C5) Evaluation of pedagogical and didactic theory/context. While there is a relative high representation of evaluations in the C1-C4 categories of methods, which contribute to the design and development of the interaction and interface design features, the C5 category is not represented. The presence of pedagogical and didactical theory in the LA, LAD, and ALPs is lacking. Though traces of pedagogical theory is present none of the studies evaluates on its impact. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
	author_keywords = {Adaptive learning platforms; Evaluation; Learning analytics},
	keywords = {Learning systems; Adaptive learning; Adaptive learning platform; Adaptive learning systems; Evaluation; Evaluation methods; Learning analytic; Learning platform; Performance; Synthesised; Systematic Review; E-learning},
	correspondence_address = {T.A.B. Tretow-Fish; Department of Applied Mathematics and Computer Science at the Technical University of Denmark, Kongens Lyngby, Denmark; email: compute@compute.dtu.dk},
	editor = {Brooks E. and Sjöberg J. and Møller A.K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18678211},
	isbn = {978-303106674-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 6th EAI International Conference on Design, Learning, and Innovation, DLI 2021; Conference date: 10 December 2021 through 11 December 2021; Conference code: 278319}
}

@ARTICLE{Barbé202434,
	author = {Barbé, Rémi and Encelle, Benoît and Sehaba, Karim},
	title = {Investigating Learning Dashboards Adaptation},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15159 LNCS},
	pages = {34 – 48},
	doi = {10.1007/978-3-031-72315-5_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205111148&doi=10.1007%2f978-3-031-72315-5_3&partnerID=40&md5=8ccfeed1b8d2675445a8eb2205cb6a63},
	affiliations = {Univ Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ Lyon 2, LIRIS, UMR5205, Villeurbanne, 69622, France; Univ Lyon, Univ Lyon 2, CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Bron, 69676, France},
	abstract = {Although there is a growing number of learning analytics dashboards (LADs), they often fail to improve learning and learners’ awareness due to their lack of adaptation capabilities. This paper presents a systematic review that follows the PRISMA statement and analyzes the adaptation features of LADs and their potential effects on learning. 24 of the 462 articles retrieved were scrutinized using an analysis framework centered on adaptation. The main finding is that there is more evidence of adaptable LADs than adaptive LADs, suggesting that adaptivity is worth exploring. The results mainly highlight 3 common LADs adaptable capabilities - most of which offer data exploration features - and 2 adaptive ones that change or refresh indicators on dashboards. Only a few articles investigate the adaptation of indicator visualizations or organization on dashboards. Currently, there is no work on the use of advanced computing techniques such as machine learning for LADs adaptation. Additionally, only 5 articles provide some evidence of dashboards adaptation features evaluation. As a result, a preliminary research agenda on LADs adaptation is suggested for enhancing LADs adoption and utility. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Adaptation; Learning Analytics Dashboards; Learning Indicators; Systematic Review},
	keywords = {Contrastive Learning; Federated learning; Adaptation; Adaptive learning; Adaptivity; Analysis frameworks; Computing techniques; Data exploration; Learning analytic dashboard; Learning indicator; Potential effects; Systematic Review; Adversarial machine learning},
	correspondence_address = {R. Barbé; Univ Lyon, UCBL, CNRS, INSA Lyon, Centrale Lyon, Univ Lyon 2, LIRIS, UMR5205, Villeurbanne, 69622, France; email: remi.barbe@liris.cnrs.fr},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172314-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 19th European Conference on Technology Enhanced Learning, EC-TEL 2024; Conference date: 16 September 2024 through 20 September 2024; Conference code: 319189}
}

@ARTICLE{Ramaswami2023959,
	author = {Ramaswami, Gomathy and Susnjak, Teo and Mathrani, Anuradha and Umer, Rahila},
	title = {Use of Predictive Analytics within Learning Analytics Dashboards: A Review of Case Studies},
	year = {2023},
	journal = {Technology, Knowledge and Learning},
	volume = {28},
	number = {3},
	pages = {959 – 980},
	doi = {10.1007/s10758-022-09613-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137037645&doi=10.1007%2fs10758-022-09613-x&partnerID=40&md5=8327c52c6e1d44af400d554cc6003d75},
	affiliations = {School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; Engineering and Management Sciences, Balochistan University of Information Technology, Quetta, Pakistan},
	abstract = {Learning analytics dashboards (LADs) provide educators and students with a comprehensive snapshot of the learning domain. Visualizations showcasing student learning behavioral patterns can help students gain greater self-awareness of their learning progression, and at the same time assist educators in identifying those students who may be facing learning difficulties. While LADs have gained popularity, existing LADs are still far behind when it comes to employing predictive analytics into their designs. Our systematic literature review has revealed limitations in the utilization of predictive analytics tools among existing LADs. We find that studies leveraging predictive analytics only go as far as identifying the at-risk students and do not employ model interpretation or explainability capabilities. This limits the ability of LADs to offer data-driven prescriptive advice to students that can offer them guidance on appropriate learning adjustments. Further, published studies have mostly described LADs that are still at prototype stages; hence, robust evaluations of how LADs affect student outcomes have not yet been conducted. The evaluations until now are limited to LAD functionalities and usability rather than their effectiveness as a pedagogical treatment. We conclude by making recommendations for the design of advanced dashboards that more fully take advantage of machine learning technologies, while using suitable visualizations to project only relevant information. Finally, we stress the importance of developing dashboards that are ultimately evaluated for their effectiveness. © 2022, The Author(s).},
	author_keywords = {Early warning system; Learning analytics dashboard; Student feedback system; Systematic review},
	keywords = {Learning systems; Students; Visualization; Behavioral patterns; Case-studies; Early Warning System; Feedback systems; Learning analytic dashboard; Self awareness; Student feedback; Student feedback system; Student learning; Systematic Review; Predictive analytics},
	correspondence_address = {G. Ramaswami; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; email: g.ramaswami@massey.ac.nz},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22111662},
	coden = {ICMLF},
	language = {English},
	abbrev_source_title = {Tech. Knowl. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2024b,
	title = {Proceedings of the 16th International Conference on Computer Supported Education, CSEDU 2024},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193939211&partnerID=40&md5=56229edd20cce24304e02781bd40a76d},
	abstract = {The proceedings contain 158 papers. The topics discussed include: students want to experiment while teachers care more about assessment! exploring how novices and experts engage in course design; exploring the impact of Covid-19 pandemic on the online learning experience of higher education students in Morocco; bridging skills and scenarios: initial steps towards using faded worked examples as personalized exercises in vocational education; the role of privacy and security concerns and trust in online teaching: experiences of higher education students in the kingdom of Saudi Arabia; large language models in civic education on the supervision and risk assessment of public works; on few-shot prompting for controllable question-answer generation in narrative comprehension; adaptation in learning analytics dashboards: a systematic review; analyzing learner strategies in programming using clickstream data; and predicting students’ final exam scores based on their regularity of engagement with pre-class activities in a flipped classroom.},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 16th International Conference on Computer Supported Education, CSEDU 2024; Conference date: 2 May 2024 through 4 May 2024; Conference code: 199597}
}

@CONFERENCE{Tepgeç2022327,
	author = {Tepgeç, Mustafa and Ifenthaler, Dirk},
	title = {LEARNING ANALYTICS BASED INTERVENTIONS: A SYSTEMATIC REVIEW OF EXPERIMENTAL STUDIES},
	year = {2022},
	journal = {Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022},
	pages = {327 – 330},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147522962&partnerID=40&md5=6510b88f15530b0a08ebc3724163d843},
	affiliations = {University of Mannheim, Mannheim, Germany; Curtin University, Australia},
	abstract = {Learning analytics includes interventions that will support learning and improve learning environments. Despite the fact that learning analytics is a promising field of study, the lack of empirical evidence on the effects of learning analytics-based interventions has been widely addressed in recent years. In this context, insights validated by experimental studies may play a crucial role. Therefore, there is a need for a report describing the methodological aspects and effects of current experimental interventions based on learning analytics. This systematic review provides an in-depth examination of learning analytics research that reports experimental findings to evaluate learning analytics-based interventions. The PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 protocol provided the basis for the work of this systematic review. This review contained 52 papers that met the inclusion and exclusion criteria. The results show that student-facing dashboards are the most common learning analytics-based intervention. Evidence from how user data is handled for interventions demonstrates that the most common method is the distillation of data for human judgment. This study confirms that a significant proportion of experimental studies employing learning analytics interventions have demonstrated significant effects on learning outcomes. The effectiveness of learning analytics-based interventions is also addressed in this review in terms of motivation, engagement, and system usage behaviors. The findings of this study will contribute to the literature in terms of describing the experimentally validated findings of learning analytics-based interventions in depth. © 2022 Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022. All rights reserved.},
	author_keywords = {Educational Data Mining; Experimental Studies; Intervention; Learning Analytics; Systematic Literature Review},
	keywords = {Computer aided instruction; Distillation; E-learning; Learning systems; 'current; Educational data mining; Experimental study; Intervention; Learning analytic; Learning environments; Methodological aspects; Support learning; Systematic literature review; Systematic Review; Data mining},
	editor = {Sampson D.G. and Sampson D.G. and Ifenthaler D. and Ifenthaler D. and Isaias P. and Rodrigues L.},
	publisher = {IADIS Press},
	isbn = {978-989870443-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 19th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2022; Conference date: 8 November 2022 through 10 November 2022; Conference code: 186161}
}

@CONFERENCE{Schwendimann2016532,
	author = {Schwendimann, Beat A. and Rodríguez-Triana, María Jesús and Vozniuk, Andrii and Prieto, Luis P. and Boroujeni, Mina Shirvani and Holzer, Adrian and Gillet, Denis and Dillenbourg, Pierre},
	title = {Understanding learning at a glance: An overview of learning dashboard studies},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {25-29-April-2016},
	pages = {532 – 533},
	doi = {10.1145/2883851.2883930},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976507952&doi=10.1145%2f2883851.2883930&partnerID=40&md5=e854df569b89228218dd94170219b420},
	affiliations = {CHILI Group, EPFL, Station 20, Lausanne, 1015, Switzerland; REACT Group, EPFL, Station 9, Lausanne, 1015, Switzerland},
	abstract = {Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the fnal analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dash-board design options. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Dashboards; Educational data mining; Information VI- sualization; Learning analytics; Systematic reVIew},
	keywords = {Education; Enterprise resource planning; Dashboards; Educational data mining; Information VI- sualization; Learning analytics; Systematic Review; Data mining},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034190-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; Conference name: 6th International Conference on Learning Analytics and Knowledge, LAK 2016; Conference date: 25 April 2016 through 29 April 2016; Conference code: 121386; All Open Access, Green Open Access}
}

@ARTICLE{2024c,
	title = {19th European Conference on Technology Enhanced Learning, EC-TEL 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15160 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205289233&partnerID=40&md5=2837101108a17fc39a69174e5b40c6cf},
	abstract = {The proceedings contain 72 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Investigating Learning Dashboards Adaptation; a Systematic Review of Studies on Decision-Making Systems for Teaching and Learning in K-12; A Study of LLM Generated Line-by-Line Explanations in the Context of Conversational Program Comprehension Tutoring Systems; A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance; synchrony Between Facial Expressions and Heart Rate Variability During Game-Based Learning: Insights from Cross-Wavelet Transformation; an Experimental Study of Facial Expressions in Collaborative Teams that Quit a Game-Based Learning Task: Within-Team Competition vs. No Within-Team Competition; addressing Mind Wandering in Video-Based Learning: A Comparative Study on the Impact of Interpolated Testing and Self-explanation; exploring Learners’ Self-reflection and Intended Actions After Consulting Learning Analytics Dashboards in an Authentic Learning Setting; Students’ Experiences and Challenges During the COVID-19 Pandemic: A Multi-method Exploration; evaluating Productivity of Learning Habits Using Math Learning Logs: Do K12 Learners Manage Their Time Effectively?; exploring Situation-Specific Skills to Boost Teachers’ Use of Analytics; development and Evaluation of Learning Scenarios for Technostress in Schools; integration of a Teacher Dashboard in a Hybrid Support Approach for Constructing Qualitative Representations; FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages; a Framework for Generators of Varied and Adapted Training Game Activities; teacher-Mediated and Student-Led Interaction with a Physics Simulation: Effects on the Learning Experience; the Challenge of Modeling the Complexity of Use for the Measurement of Digital Maturity in Education; AI or Human? Evaluating Student Feedback Perceptions in Higher Education; math Teachers’ In-Class Information Needs and Usage for Effective Design of Classroom Orchestration Tools.},
	editor = {Ferreira Mello R. and Rummel N. and Jivet I. and Pishtari G. and Ruipérez Valiente J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172311-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 19th European Conference on Technology Enhanced Learning, EC-TEL 2024; Conference date: 16 September 2024 through 20 September 2024; Conference code: 319189}
}

@CONFERENCE{Ifenthaler20221721,
	author = {Ifenthaler, Dirk and Yau, Jane Yin-Kim},
	title = {Analytics for Supporting Teaching Success in Higher Education: A Systematic Review},
	year = {2022},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2022-March},
	pages = {1721 – 1727},
	doi = {10.1109/EDUCON52537.2022.9766734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130446295&doi=10.1109%2fEDUCON52537.2022.9766734&partnerID=40&md5=261e8e9c480e549bba046ae967d49cec},
	affiliations = {University of Mannheim, Curtin University, Learning, Design and Technology, Mannheim, Germany; University of Mannheim, Dipf Leibniz Institute for Research and Information in Education, Mannheim, Germany},
	abstract = {Learning analytics are utilized to support learners' educational needs as well as to enhance their study success, for example, via the use of real-time prompts, motivational dashboards, and appropriate learning interventions, which have been shown to increase students' academic performance as well as their course retention rates. Yet, the perspective of higher education teachers in utilizing analytics to help analyze, reflect on, and improve their teaching design prior to delivery as well as to monitor and measure how the students engaged with their learning processes has been less recognized. In this paper, we present the results of a systematic review conducted from higher education teachers' perspective concerning how analytics can be deployed to adapt the curriculum to suit better students' educational needs in order to increase their study success. Thirty-five key studies were identified showing that analytics have been successful in influencing positively study success via teachers' academic curriculum intervention. Specifically, via analytics, higher education teachers could rapidly visualize common course pathways and identify any difficulties students experienced in real-time in order to increase their learning experiences and outcomes. © 2022 IEEE.},
	author_keywords = {higher education; learning analytics; systematic review; teacher},
	keywords = {Curricula; Teaching; Academic performance; Education teachers; Educational needs; High educations; Learning analytic; Real- time; Retention rate; Systematic Review; Teachers'; Teaching designs; Students},
	editor = {Jemni M. and Kallel I. and Akkari A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-166544434-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 13th IEEE Global Engineering Education Conference, EDUCON 2022; Conference date: 28 March 2022 through 31 March 2022; Conference code: 179170}
}

@CONFERENCE{2024d,
	title = {Proceedings of the 16th International Conference on Computer Supported Education, CSEDU 2024},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193919367&partnerID=40&md5=c320e1020e470f4dc2f052a4e5112c86},
	abstract = {The proceedings contain 158 papers. The topics discussed include: students want to experiment while teachers care more about assessment! exploring how novices and experts engage in course design; exploring the impact of Covid-19 pandemic on the online learning experience of higher education students in Morocco; bridging skills and scenarios: initial steps towards using faded worked examples as personalized exercises in vocational education; the role of privacy and security concerns and trust in online teaching: experiences of higher education students in the kingdom of Saudi Arabia; large language models in civic education on the supervision and risk assessment of public works; on few-shot prompting for controllable question-answer generation in narrative comprehension; adaptation in learning analytics dashboards: a systematic review; analyzing learner strategies in programming using clickstream data; and predicting students’ final exam scores based on their regularity of engagement with pre-class activities in a flipped classroom.},
	editor = {Poquet O. and Ortega-Arranz A. and Viberg O. and Chounta I.-A. and McLaren B. and Jovanovic J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21845026},
	isbn = {978-989758697-2},
	language = {English},
	abbrev_source_title = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 16th International Conference on Computer Supported Education, CSEDU 2024; Conference date: 2 May 2024 through 4 May 2024; Conference code: 199597}
}

@ARTICLE{Paulsen202414279,
	author = {Paulsen, Lucas and Lindsay, Euan},
	title = {Learning analytics dashboards are increasingly becoming about learning and not just analytics - A systematic review},
	year = {2024},
	journal = {Education and Information Technologies},
	volume = {29},
	number = {11},
	pages = {14279 – 14308},
	doi = {10.1007/s10639-023-12401-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181498996&doi=10.1007%2fs10639-023-12401-4&partnerID=40&md5=016e883f872b0f990c24a6acba972636},
	affiliations = {Department of Communication & Psychology, Aalborg University, Aalborg, Denmark; Department of Sustainability and Planning, Aalborg University, Aalborg, Denmark},
	abstract = {This systematic review explores the emerging themes in the design and implementation of student-facing learning analytics dashboards in higher education. Learning Analytics has long been criticised for focusing too much on the analytics, and not enough on the learning. The review is then guided by an interest in whether these dashboards are still primarily analytics-driven or if they have become pedagogically informed over time. By mapping the identified themes of technological maturity, informing frameworks, affordances, data sources, and analytical levels over publications per year, the review identifies an emerging trajectory towards student-focused dashboards. These dashboards are informed by theory-oriented frameworks, designed to incorporate affordances that supporting student learning, and realised through integration of more than just activity data from learning management systems – allowing the dashboards to better support students' learnings processes. Based on this emerging trajectory, the review provides a series of design recommendations for student-focused dashboards that are connected to learning sciences as well as analytics. © The Author(s) 2024.},
	author_keywords = {Dashboards; Higher education; Learning analytics; Systematic review; Trajectories},
	correspondence_address = {L. Paulsen; Department of Communication & Psychology, Aalborg University, Aalborg, Denmark; email: lupa@ikp.aau.dk},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tretow-Fish2023430,
	author = {Tretow-Fish, Tobias Alexander Bang and Khalid, Md. Saifuddin},
	title = {Methods for Evaluating Learning Analytics and Learning Analytics Dashboards in Adaptive Learning Platforms: A Systematic Review},
	year = {2023},
	journal = {Electronic Journal of e-Learning},
	volume = {21},
	number = {5},
	pages = {430 – 449},
	doi = {10.34190/ejel.21.5.3088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180458888&doi=10.34190%2fejel.21.5.3088&partnerID=40&md5=5e219839d7380ae5a69ec9e26ba7d59a},
	affiliations = {Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark},
	abstract = {This research paper highlights and addresses the lack of a systematic review of the methods used to evaluate Learning Analytics (LA) and Learning Analytics Dashboards (LAD) of Adaptive Learning Platforms (ALPs) in the current literature. Addressing this gap, the authors built upon the work of Tretow-Fish and Khalid (2022) and analyzed 32 papers, which were grouped into six categories (C1-6) based on their themes. The categories include C1) the evaluation of LA and LAD design and framework, C2) the evaluation of user performance with LA and LAD, C3) the evaluation of adaptivity, C4) the evaluation of ALPs through perceived value, C5) the evaluation of Multimodal methods, and C6) the evaluation of the pedagogical implementation of ALP’s LA and LAD. The results include a tabular summary of the papers including the categories, evaluation unit(s), methods, variables and purpose. While there are numerous studies in categories C1-4 that focus on the design, development, and impact assessment of ALP's LA and LAD, there are only a few studies in categories C5 and C6. For the category of C5), very few studies applied any evaluation methods assessing the multimodal features of LA and LADs on ALPs. Especially for C6), evaluating the pedagogical implementation of ALP's LA and LAD, the three dimensions of signature pedagogy are used to assess the level of pedagogy evaluation. Findings showed that no studies focus on evaluating the deep or implicit structure of ALP's LA. All studies examine the structural surface dimension of learning activities and interactions between students, teachers, and ALP's LA and LAD, as examined in categories C2-C5. No studies were exclusively categorized as a C6 category, indicating that all studies evaluate ALP's LA and LAD on the surface structure dimension of signature pedagogy. This review highlights the lack of pedagogical methodology and theory in ALP's LA and LAD, which are recommended to be emphasized in future research and ALP development and implementation. © The Authors.},
	author_keywords = {Adaptive Learning Platform; Learning Analytics; Methods of evaluation; Systematic literature review},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {14794403},
	language = {English},
	abbrev_source_title = {Electron. J. e-Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Salas-Pilco2023,
	author = {Salas-Pilco, Sdenka Zobeida and Xiao, Kejiang and Hu, Xinyun},
	title = {Correction to: Artificial Intelligence and Learning Analytics in Teacher Education: A Systematic Review (Education Sciences, (2022), 12, 8, (569), 10.3390/educsci12080569)},
	year = {2023},
	journal = {Education Sciences},
	volume = {13},
	number = {9},
	doi = {10.3390/educsci13090897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172161101&doi=10.3390%2feducsci13090897&partnerID=40&md5=f0d184858c5cd1fcbc0b9402af0a2458},
	affiliations = {Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Hubei Research Center for Educational Informatization, Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; Faculty of Education and Human Development, The Education University of Hong Kong, Hong Kong},
	abstract = {There was an error in the original publication [1]. The authors have requested changes be made to the published paper as they describe Taiwan as a country in the article and hope to change the description to “Country/Region” and “China Taiwan”. A correction has been made to the first paragraph of Section 3. Results and Table 2: This review includes 30 studies based in 16 countries/regions, with the following distribution: Canada (3), China (8), Estonia (1), Germany (3), India (1), Indonesia (1), Japan (1), Korea (1), Malaysia (1), Morocco (1), Portugal (1), Rwanda (1), Spain (1) China Taiwan (1), Turkey (2), USA (3). The analysis guided by the research questions provides some insights into the impact of AI and LA on teacher education. Summary of the studies included in this review. Knowledge elaboration (K): discussion of topics and posts Behavior patterns (B): posting frequency; posts’ content Social interaction (S): network density, network cohesion, and network interactions Moodle platform LA dashboard Knowledge–Behavior–Social Dashboard tool (KBSD) DigComp framework (five dimensions): information and data literacy, communication and collaboration, digital content creation, safety, and problem solving AI tools: K-means clustering Video discourse data: number of words; number of turns; teacher–student turn-taking patterns Visualizing talk strategies: elaborating, reasoning, listening, and thinking with others Classroom discourse analyzer (CDA) is a VLA tool that automatically extracts and visualizes low-inference discourse information Short essays (500-word reflection) about the experience of solving a block-based visual programming scenario were analyzed Moodle platform Latent Dirichlet Allocation library in Python. Code.org Number of sessions, duration, number of actions, etc. Content access, content revision, discussion, assessment, help-seeking, and search MOOC R package AI tools: Expectation-maximization (EM) algorithm; Bayesian information criterion (BIC); TraMineR Access features: location, date, time, and regularity (average number of logins/week) Content features: screencasts; quizzes Moodle platform Video-based speech features: content, speech organization, appropriate word usage, proper etiquette, correct enunciation, fluent prosody, timing control Supervised algorithms: support-vector machine (SVM) classifier, logistic regression, random forests, and gradient-boosted decision trees Class, group, and individual work Student modalities: reading, writing, listening, and speaking Material: extended, minimal, native, or non-native Video on the ePortfolio in Moodle AI mobile communicative orientation of language teaching (COLT) scheme Discourse data: recordings of classroom conversations. Included variables: specificity, instructional talk, authentic questions, dialogic, cognitive level Random forests (RF) classifier and regression IBM Watson AI speech recognizer User action data: time, full names, event context, components, event names, activity, IP address and origin Performance data: grades Moodle platform R software Trustworthiness (0–100), novelty, and usefulness Actionability and receiving new information Level of experience CoTrack: a Raspberry-Pi-based prototype with microphones CoTrack’s dashboard showing speaking time and social networks Etherpad Discourse data and reflection elements: PSTs’ attitudes, experiences, device preferences, comments about the interface, and content and technical issues SimInClass: an AI-based-simulated virtual classroom Google Classroom learning platform Performance: GPA, math grade, TIMSS, age, gender, federal state, school type, type of student AI tools: SVM, LR, LR with elastic net regularization, and tree-based methods Behavior patterns: recordings of PSTs’ viewing a 360 degrees video with students’ actions Short writings: PSTs select one pivotal moment and explain why it is significant AI tools: machine learning algorithm Digital competence areas: Personal: age, gender, teaching experience, confidence, and years using digital technology in teaching Contextual: classroom equipment, students’ access to technology, network infrastructure, and curriculum Professional engagement: digital resources, assessment, empowering learners, and facilitating learners’ digital competence SPSS STATA, fast-and-frugal trees (FFTrees) classifier in machine learning ILDE dashboard: profile views, comments, created designs, re-used designs, and edits. The Integrated Learning Design Environment (ILDE) dashboard IBM SPSS 22 Heidi SQL and Tableau Self-regulated behaviors: Activating: online access location, day of the week, time of day Sustaining: access frequency Structuring: average logins per week, exam review patterns, number of reviewed quizzes/day Moodle platform Social bot: user intentions, bot messages System Usability Scale: frequency, ease of use, confidence, consistency Chatbots: Feedbot for self- study, Litbot for mentoring students’ reading Learning action logs about search terms, visited websites, time spent on each website, and the order in which sites were visited Thinking app (Chrome extension) that tracks online behaviors Psychological variables: Practical knowledge: educational beliefs, interpersonal relationships, teaching strategies, self-reflection Motivation: intrinsic motivation, extrinsic motivation, amotivation Other: gender, teaching experience, average academic performance The SLBM-TAIS educational module Based on the Indonesian Teacher Engagement Index (ITEI): positive psychology, positive education, teacher performance, nationalistic character, and leadership engagement Django: a website framework for Python Chart.js for data visualization. MongoDB as the database Discussion data Dimensions based on Bloom’s taxonomy: remember, understand, apply, analyze, evaluate, create MOOC platform Types of AI tasks: text recognition, sentiment analysis, image classification, categorical/numerical data IBM Watson AI model Mitsuku chatbot Google AI experiment named Emoji Scavenger Hunt Scratch Reflection elements: circumstances, description, evaluation, alternatives, consequences Doc2Vec features Four classifiers: decision trees, multinomial logistic regression, multinomial naïve Bayes, stochastic gradient descent Epistemic agency, democratic knowledge, improvable ideas, reflective and transformative assessment, and community knowledge Knowledge Forum (online notes) LMS log data: date, login frequency, views per week, participation in discussions Moodle LMS platform Based on the Teaching and Learning International Survey (TALIS) 2013: types of activities, participation rates, intensity of participation, mentoring and induction programs Group Mnet technique (glmnet package). R software PSTs’ teaching competency framework (six dimensions): professional foundation, instructional design, teaching implementation, technology application, teaching evaluation, reflective development AI tools: Back Propagation (BP) neural network Delphi and Analytic Hierarchy Process (AHP) methods Matlab software Discourse characteristics: number of posts per teacher, length of post per teacher, much or little new information, high or low topic relevance Word2vec toolkit to generate lexical vectors based on AI-NLP Vision-based mobile augmented reality from the university campus (e.g., plants, flowers, trees) through scene detection, retrieval, superposition, visualization, and interaction MobileNetV2 network: a lightweight convolutional neural network by Google for mobile devices Note. CDA = classroom discourse analyzer, DT = decision tree, FFTrees = fast-and-frugal trees, GBTD = gradient-boosted decision trees, KBSD = Knowledge–Behavior–Social Dashboard, ITEI = Indonesian Teacher Engagement Index, RF = random forests, NLP = natural language processing, SLBM-TAIS = service-learning-based module training AI subjects, SVM = support-vector machine, WISE = web-based inquiry science environment. The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the authors.},
	correspondence_address = {K. Xiao; Hubei Research Center for Educational Informatization, Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, 430079, China; email: xiaokj@ccnu.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277102},
	language = {English},
	abbrev_source_title = {Educ. Sci.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Febriantoro202375,
	author = {Febriantoro, Wicaksono and Gauthier, Andrea and Cukurova, Mutlu},
	title = {The Promise of Physiological Data in Collaborative Learning: A Systematic Literature Review},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14200 LNCS},
	pages = {75 – 88},
	doi = {10.1007/978-3-031-42682-7_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171976075&doi=10.1007%2f978-3-031-42682-7_6&partnerID=40&md5=a0ab4170933a95a0a625f3ef2ce93c5a},
	affiliations = {UCL Knowledge Lab, Institute of Education, University College London (UCL), London, United Kingdom},
	abstract = {Collaborative learning is an important approach in education. Researchers are increasingly interested in using physiological data, such as Electrodermal Activity (EDA), as an objective tool to measure bodily reactions during collaborative activities. However, it remains unclear how physiological data can contribute to our understanding, monitoring and support of the collaborative learning process. To address this gap, a Systematic Literature Review (SLR) was conducted, focusing on the contribution of physiological data to collaborative learning, the features of physiological data that correlate with effective outcomes, and interventions designed to support collaboration based on physiological data. The review identified 13 relevant publications that revealed physiological data can indeed be useful for detecting certain aspects of collaboration including students’ cognitive, behavioral, and affective (emotion and motivation) states. Physiological arousal in the form of EDA peaks and physiological synchrony (interdependence or associated activity between individuals’ physiological signals) were the most commonly used features. Surprisingly, only one publication presented a prototype of a learning analytics dashboard that used physiological data to guide student reflections. Furthermore, the review highlights the potential for integrating physiological measures with other data sources, such as speech, eye gaze, and facial expression, to uncover psychophysiological reactions and accompanying social and contextual processes related to collaborative learning. Future research should consider embedding methods for the physiological detection and modeling of learning constructs within explicit, feedback-driven interventions for collaborative learning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {collaborative learning; physiological data},
	keywords = {Psychophysiology; Collaborative activities; Collaborative learning; Collaborative learning process; Data-source; Electrodermal activity; Eye-gaze; Physiological data; Physiological measures; Physiological signals; Systematic literature review; Learning systems},
	correspondence_address = {W. Febriantoro; UCL Knowledge Lab, Institute of Education, University College London (UCL), London, United Kingdom; email: Wicaksono.febriantoro.21@ucl.ac.uk},
	editor = {Viberg O. and Jivet I. and Muñoz-Merino P.J. and Perifanou M. and Papathoma T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303142681-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Proceedings of the 18th European Conference on Technology Enhanced Learning, ECTEL 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 299989}
}
